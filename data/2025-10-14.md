<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 78]
- [cs.HC](#cs.HC) [Total: 26]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Enhancing Diffusion Policy with Classifier-Free Guidance for Temporal Robotic Tasks](https://arxiv.org/abs/2510.09786)
*Yuang Lu,Song Wang,Xiao Han,Xuri Zhang,Yucong Wu,Zhicheng He*

Main category: cs.RO

TL;DR: 引入CFG-DP框架，结合无分类器引导方法，提升人形机器人在时序任务中的控制效果，尤其在减少重复动作和确保任务完结方面表现优秀。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有扩散策略在处理时序任务时面临的缺乏时间上下文导致的局部最优与重复行为的问题。

Method: 通过引入无分类器引导与条件及无条件模型结合，以时间步输入跟踪任务进展，并动态调整基于任务阶段的动作预测。

Result: 提出了一种无分类器引导的扩散策略（CFG-DP），能够有效提升人形机器人在时序任务上的表现，减少局部最优和重复动作问题。

Conclusion: CFG-DP框架显著改善了序列机器人任务的确定性控制和执行可靠性。

Abstract: Temporal sequential tasks challenge humanoid robots, as existing Diffusion
Policy (DP) and Action Chunking with Transformers (ACT) methods often lack
temporal context, resulting in local optima traps and excessive repetitive
actions. To address these issues, this paper introduces a Classifier-Free
Guidance-Based Diffusion Policy (CFG-DP), a novel framework to enhance DP by
integrating Classifier-Free Guidance (CFG) with conditional and unconditional
models. Specifically, CFG leverages timestep inputs to track task progression
and ensure precise cycle termination. It dynamically adjusts action predictions
based on task phase, using a guidance factor tuned to balance temporal
coherence and action accuracy. Real-world experiments on a humanoid robot
demonstrate high success rates and minimal repetitive actions. Furthermore, we
assessed the model's ability to terminate actions and examined how different
components and parameter adjustments affect its performance. This framework
significantly enhances deterministic control and execution reliability for
sequential robotic tasks.

</details>


### [2] [Cross-Sensor Touch Generation](https://arxiv.org/abs/2510.09817)
*Samanta Rodriguez,Yiming Dou,Miquel Oller,Andrew Owens,Nima Fazeli*

Main category: cs.RO

TL;DR: 本文介绍了两种针对跨传感器图像生成的方法，分别是基于配对数据的Touch2Touch和不需要配对数据的T2D2，二者可在多种传感器间进行有效的模型转换和应用。


<details>
  <summary>Details</summary>
Motivation: 由于多数模型依赖特定的传感器设计，迫切需要开发一种通用的触觉表示，以适应多样的传感器设计。

Method: 提出了两种方法：Touch2Touch（基于配对数据）和T2D2（基于中间深度表示），后者不依赖于配对数据。

Result: 本文提出了两种跨传感器图像生成的方法，旨在解决当前多种形状和尺寸的视觉触觉传感器所带来的一般性触觉表示开发的挑战。

Conclusion: 本文的方法在各类下游任务中有效地实现了不同传感器之间模型的成功迁移，展示了其跨传感器触觉生成的有效性。

Abstract: Today's visuo-tactile sensors come in many shapes and sizes, making it
challenging to develop general-purpose tactile representations. This is because
most models are tied to a specific sensor design. To address this challenge, we
propose two approaches to cross-sensor image generation. The first is an
end-to-end method that leverages paired data (Touch2Touch). The second method
builds an intermediate depth representation and does not require paired data
(T2D2: Touch-to-Depth-to-Touch). Both methods enable the use of sensor-specific
models across multiple sensors via the cross-sensor touch generation process.
Together, these models offer flexible solutions for sensor translation,
depending on data availability and application needs. We demonstrate their
effectiveness on downstream tasks such as in-hand pose estimation and behavior
cloning, successfully transferring models trained on one sensor to another.
Project page: https://samantabelen.github.io/cross_sensor_touch_generation.

</details>


### [3] [VG-Mapping: Variation-Aware 3D Gaussians for Online Semi-static Scene Mapping](https://arxiv.org/abs/2510.09962)
*Yicheng He,Jingwen Yu,Guangcheng Chen,Hong Zhang*

Main category: cs.RO

TL;DR: 本论文提出了一种基于3D Gaussian Splatting的在线地图重建系统VG-Mapping，针对半静态场景实现高效变化区域更新。


<details>
  <summary>Details</summary>
Motivation: 快速更新机器人周围环境的地图以防止因未及时更新变化区域而导致的定位及操作效率下降。

Method: 提出了一种混合表示方法，结合3DGS与TSDF体素地图，采用变异感知密度控制策略对变化区域进行高效更新。

Result: VG-Mapping系统显著提升了半静态场景中的渲染质量和地图更新效率。

Conclusion: VG-Mapping通过结合3DGS与TSDF体素地图，在变化检测上表现出色，提升了动态环境下的地图质量与更新速度。

Abstract: Maintaining an up-to-date map that accurately reflects recent changes in the
environment is crucial, especially for robots that repeatedly traverse the same
space. Failing to promptly update the changed regions can degrade map quality,
resulting in poor localization, inefficient operations, and even lost robots.
3D Gaussian Splatting (3DGS) has recently seen widespread adoption in online
map reconstruction due to its dense, differentiable, and photorealistic
properties, yet accurately and efficiently updating the regions of change
remains a challenge. In this paper, we propose VG-Mapping, a novel online
3DGS-based mapping system tailored for such semi-static scenes. Our approach
introduces a hybrid representation that augments 3DGS with a TSDF-based voxel
map to efficiently identify changed regions in a scene, along with a
variation-aware density control strategy that inserts or deletes Gaussian
primitives in regions undergoing change. Furthermore, to address the absence of
public benchmarks for this task, we construct a RGB-D dataset comprising both
synthetic and real-world semi-static environments. Experimental results
demonstrate that our method substantially improves the rendering quality and
map update efficiency in semi-static scenes. The code and dataset are available
at https://github.com/heyicheng-never/VG-Mapping.

</details>


### [4] [LLM-HBT: Dynamic Behavior Tree Construction for Adaptive Coordination in Heterogeneous Robots](https://arxiv.org/abs/2510.09963)
*Chaoran Wang,Jingyuan Sun,Yanhui Zhang,Mingyu Zhang,Changju Wu*

Main category: cs.RO

TL;DR: 提出一种新颖的自动行为树构建框架，利用大语言模型提高异构多机器人系统在动态环境中的适应性和鲁棒性，经过验证，表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 解决传统机器人在动态环境中任务失败后的适应性差和策略重构效率低的问题。

Method: 利用大语言模型生成和扩展行为树，结合任务初始化、任务分配、行为树更新和故障节点检测等模块，形成闭环系统。

Result: 本研究提出了一种新颖的自动行为树构建框架，旨在提高异构多机器人系统在动态环境中的适应性和鲁棒性。通过利用大语言模型（LLMs），我们能够动态生成和扩展行为树，以应对任务失败和环境变化所带来的挑战。该框架包含任务初始化、任务分配、行为树更新和故障节点检测四个模块，形成闭环操作。机器人在执行过程中检查行为树，并在遇到故障节点时，能够选择在本地扩展树或调用中央虚拟协调者（Alex）重新分配子任务与同步行为树。该设计实现了异构团队的长期合作执行。实验结果表明，该方法在任务成功率、鲁棒性和可扩展性上均优于基线方法，证明其在复杂场景下的多机器人协作中的有效性。

Conclusion: 该框架有效提高了多机器人系统在动态环境中的协作能力，具有良好的适应性与鲁棒性。

Abstract: We introduce a novel framework for automatic behavior tree (BT) construction
in heterogeneous multi-robot systems, designed to address the challenges of
adaptability and robustness in dynamic environments. Traditional robots are
limited by fixed functional attributes and cannot efficiently reconfigure their
strategies in response to task failures or environmental changes. To overcome
this limitation, we leverage large language models (LLMs) to generate and
extend BTs dynamically, combining the reasoning and generalization power of
LLMs with the modularity and recovery capability of BTs. The proposed framework
consists of four interconnected modules task initialization, task assignment,
BT update, and failure node detection which operate in a closed loop. Robots
tick their BTs during execution, and upon encountering a failure node, they can
either extend the tree locally or invoke a centralized virtual coordinator
(Alex) to reassign subtasks and synchronize BTs across peers. This design
enables long-term cooperative execution in heterogeneous teams. We validate the
framework on 60 tasks across three simulated scenarios and in a real-world cafe
environment with a robotic arm and a wheeled-legged robot. Results show that
our method consistently outperforms baseline approaches in task success rate,
robustness, and scalability, demonstrating its effectiveness for multi-robot
collaboration in complex scenarios.

</details>


### [5] [FORM: Fixed-Lag Odometry with Reparative Mapping utilizing Rotating LiDAR Sensors](https://arxiv.org/abs/2510.09966)
*Easton R. Potokar,Taylor Pool,Daniel McGann,Michael Kaess*

Main category: cs.RO

TL;DR: 介绍了一种新的光学里程计方法FORM，能够提高手术精确度和实时性能。


<details>
  <summary>Details</summary>
Motivation: 解决以往方法中因子地图固定导致的错误传播和轨迹抖动问题，从而实现高效且精确的状态估计。

Method: 通过在一个密集连接的因子图上进行平滑，同时利用单一的迭代地图进行匹配。

Result: 提出了一种新的LiDAR测量配置--FORM，旨在提高机械状态估计的性能和实时性。

Conclusion: FORM方法在多种数据集上表现出色，提供了稳定、准确的轨迹估计，并优于现有的光学里程计技术。

Abstract: Light Detection and Ranging (LiDAR) sensors have become a de-facto sensor for
many robot state estimation tasks, spurring development of many LiDAR Odometry
(LO) methods in recent years. While some smoothing-based LO methods have been
proposed, most require matching against multiple scans, resulting in
sub-real-time performance. Due to this, most prior works estimate a single
state at a time and are ``submap''-based. This architecture propagates any
error in pose estimation to the fixed submap and can cause jittery trajectories
and degrade future registrations. We propose Fixed-Lag Odometry with Reparative
Mapping (FORM), a LO method that performs smoothing over a densely connected
factor graph while utilizing a single iterative map for matching. This allows
for both real-time performance and active correction of the local map as pose
estimates are further refined. We evaluate on a wide variety of datasets to
show that FORM is robust, accurate, real-time, and provides smooth trajectory
estimates when compared to prior state-of-the-art LO methods.

</details>


### [6] [ATRos: Learning Energy-Efficient Agile Locomotion for Wheeled-legged Robots](https://arxiv.org/abs/2510.09980)
*Jingyuan Sun,Hongyu Ji,Zihan Qu,Chaoran Wang,Mingyu Zhang*

Main category: cs.RO

TL;DR: ATRos框架通过强化学习实现了轮腿机器人的混合运动，提高了其对地形适应性和能效。


<details>
  <summary>Details</summary>
Motivation: 研究轮腿机器人混合机动性，结合了腿部机动的灵活性和轮式移动的高效性，但其整体控制仍然具有挑战性。

Method: 利用强化学习构建预测策略网络，根据本体感觉信息估算外部环境状态，并使用演员评论家网络生成最佳关节命令。

Result: 提出了一种基于强化学习的混合机动框架ATRos，能够实现轮腿机器人在不同地形上的混合行走和驾驶运动。

Conclusion: 该框架在多种未见地形上表现出强大的通用性，验证了其实际应用的可行性。

Abstract: Hybrid locomotion of wheeled-legged robots has recently attracted increasing
attention due to their advantages of combining the agility of legged locomotion
and the efficiency of wheeled motion. But along with expanded performance, the
whole-body control of wheeled-legged robots remains challenging for hybrid
locomotion. In this paper, we present ATRos, a reinforcement learning
(RL)-based hybrid locomotion framework to achieve hybrid walking-driving
motions on the wheeled-legged robot. Without giving predefined gait patterns,
our planner aims to intelligently coordinate simultaneous wheel and leg
movements, thereby achieving improved terrain adaptability and improved energy
efficiency. Based on RL techniques, our approach constructs a prediction policy
network that could estimate external environmental states from proprioceptive
sensory information, and the outputs are then fed into an actor critic network
to produce optimal joint commands. The feasibility of the proposed framework is
validated through both simulations and real-world experiments across diverse
terrains, including flat ground, stairs, and grassy surfaces. The hybrid
locomotion framework shows robust performance over various unseen terrains,
highlighting its generalization capability.

</details>


### [7] [Hybrid Robotic Meta-gripper for Tomato Harvesting: Analysis of Auxetic Structures with Lattice Orientation Variations](https://arxiv.org/abs/2510.10016)
*Shahid Ansari,Vivek Gupta,Bishakh Bhattacharya*

Main category: cs.RO

TL;DR: 本研究提出了一种新型混合抓手，结合了刚性外框和软性吸附格子，系统研究了不同格子结构取向对抓取性能的影响，为精准农业中的自动化策略提供了新的见解。


<details>
  <summary>Details</summary>
Motivation: 随着全球食品需求的不断增长，农业部门亟需通过自动化来提高效率并减少收获过程中果蔬处理的劳动强度和损失。

Method: 本研究结合实验验证、2D数字图像相关（DIC）和非线性有限元分析（FEA），系统评估了不同结构取向的吸附格子的抓取力、变形响应和电动机扭矩要求。

Result: 不同的吸附结构取向在抓取性能和能源效率方面表现出明显的优势，强调了定制化吸附几何体以优化机械抓手性能的创新框架。

Conclusion: 研究表明，聚合物的结构取向对抓取性能、接触力和能量效率有显著影响，为优化机器人抓手性能提供了新的见解。

Abstract: The agricultural sector is rapidly evolving to meet growing global food
demands, yet tasks like fruit and vegetable handling remain labor-intensive,
causing inefficiencies and post-harvest losses. Automation, particularly
selective harvesting, offers a viable solution, with soft robotics emerging as
a key enabler. This study introduces a novel hybrid gripper for tomato
harvesting, incorporating a rigid outer frame with a soft auxetic internal
lattice. The six-finger, 3D caging-effect design enables gentle yet secure
grasping in unstructured environments. Uniquely, the work investigates the
effect of auxetic lattice orientation on grasping conformability, combining
experimental validation with 2D Digital Image Correlation (DIC) and nonlinear
finite element analysis (FEA). Auxetic configurations with unit cell
inclinations of 0 deg, 30 deg, 45 deg, and 60 deg are evaluated, and their
grasping forces, deformation responses, and motor torque requirements are
systematically compared. Results demonstrate that lattice orientation strongly
influences compliance, contact forces, and energy efficiency, with distinct
advantages across configurations. This comparative framework highlights the
novelty of tailoring auxetic geometries to optimize robotic gripper
performance. The findings provide new insights into soft-rigid hybrid gripper
design, advancing automation strategies for precision agriculture while
minimizing crop damage.

</details>


### [8] [LOMORO: Long-term Monitoring of Dynamic Targets with Minimum Robotic Fleet under Resource Constraints](https://arxiv.org/abs/2510.10046)
*Mingke Lu,Shuaikang Wang,Meng Guo*

Main category: cs.RO

TL;DR: 本研究开发了LOMORO方案，通过多机器人协作有效监测动态目标，处理资源约束并应对不确定性，经过大规模仿真实证其有效性。


<details>
  <summary>Details</summary>
Motivation: 长时间监测动态目标对于人类和单一机器人都过于繁重，使用机器人舰队能够更有效地协同工作，但协调过程面临目标行为未知和机器人资源有限的挑战。

Method: 提出了三大核心组件，包括多机器人任务分配模型、资源感知任务协调算法和在线适应算法。

Result: 本研究提出了一种新的在线协调方案LOMORO，用于多机器人协作监测动态目标。该方案通过资源和监测间隔的约束建模多机器人任务分配问题，提出了资源感知任务协调算法，并设计在线适应算法应对不可预知的目标行为和机器人故障。

Conclusion: LOMORO方案有效提升了多机器人协作监测的效率和鲁棒性，确保资源的合理分配和监测的持续性。

Abstract: Long-term monitoring of numerous dynamic targets can be tedious for a human
operator and infeasible for a single robot, e.g., to monitor wild flocks,
detect intruders, search and rescue. Fleets of autonomous robots can be
effective by acting collaboratively and concurrently. However, the online
coordination is challenging due to the unknown behaviors of the targets and the
limited perception of each robot. Existing work often deploys all robots
available without minimizing the fleet size, or neglects the constraints on
their resources such as battery and memory. This work proposes an online
coordination scheme called LOMORO for collaborative target monitoring, path
routing and resource charging. It includes three core components: (I) the
modeling of multi-robot task assignment problem under the constraints on
resources and monitoring intervals; (II) the resource-aware task coordination
algorithm iterates between the high-level assignment of dynamic targets and the
low-level multi-objective routing via the Martin's algorithm; (III) the online
adaptation algorithm in case of unpredictable target behaviors and robot
failures. It ensures the explicitly upper-bounded monitoring intervals for all
targets and the lower-bounded resource levels for all robots, while minimizing
the average number of active robots. The proposed methods are validated
extensively via large-scale simulations against several baselines, under
different road networks, robot velocities, charging rates and monitoring
intervals.

</details>


### [9] [Ionospheric and Plasmaspheric Delay Characterization for Lunar Terrestrial GNSS Receivers with Global Core Plasma Model](https://arxiv.org/abs/2510.10059)
*Keidai Iiyama,Grace Gao*

Main category: cs.RO

TL;DR: 本文分析了在月球利用地面GNSS信号定位时，电离层和等离子层延迟的特征，提出影响定位精度的关键因素和相应的设计建议。


<details>
  <summary>Details</summary>
Motivation: 研究探讨如何利用地面GNSS信号进行月球航天器的定位和定时，尤其是解决影响定位精度的电离层和等离子层延迟问题。

Method: 使用GCPM和光线追踪算法，模拟和分析了不同太阳和地磁条件下GNSS信号的时延特征。

Result: 通过GCPM和自定义的低成本光线追踪算法，定量分析了GNSS信号在不同条件下的传播延迟，并提出了影响定位的主要因素。

Conclusion: 电离层和等离子层延迟显著影响月球GNSS导航，提出的建模方法和结果能够为未来的定位和定时算法设计提供重要参考。

Abstract: Recent advancements in lunar positioning, navigation, and timing (PNT) have
demonstrated that terrestrial GNSS signals, including weak sidelobe
transmissions, can be exploited for lunar spacecraft positioning and timing.
While GNSS-based navigation at the Moon has been validated recently, unmodeled
ionospheric and plasmaspheric delays remain a significant error source,
particularly given the unique signal geometry and extended propagation paths.
This paper characterizes these delays using the Global Core Plasma Model (GCPM)
and a custom low-cost ray-tracing algorithm that iteratively solves for bent
signal paths. We simulate first-, second-, and third-order group delays, as
well as excess path length from ray bending, for GNSS signals received at both
lunar orbit and the lunar south pole under varying solar and geomagnetic
conditions. Results show that mean group delays are typically on the order of 1
m, but can exceed 100 m for low-altitude ray paths during high solar activity,
while bending delays are generally smaller but non-negligible for low-altitude
ray paths. We also quantify the influence of signal frequency, geomagnetic
$K_p$ index, and solar R12 index. These findings inform the design of robust
positioning and timing algorithms that utilize terrestrial GNSS signals.

</details>


### [10] [Beyond ADE and FDE: A Comprehensive Evaluation Framework for Safety-Critical Prediction in Multi-Agent Autonomous Driving Scenarios](https://arxiv.org/abs/2510.10086)
*Feifei Liu,Haozhe Wang,Zejun Wei,Qirong Lu,Yiyang Wen,Xiaoyu Tang,Jingyan Jiang,Zhijian He*

Main category: cs.RO

TL;DR: 本论文提出了一种新的自动驾驶预测模型评估框架，强调需要考虑复杂场景和代理交互，以提升模型的安全性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前的自动驾驶预测模型评估方法过于依赖简单指标，不足以捕捉复杂驾驶场景中的细微行为，因此需要一种新的评估方法。

Method: 提出一种新的测试框架，评估在不同场景结构下的预测性能，包括地图上下文、代理密度和空间分布。

Result: 通过实证分析，量化了代理接近度对目标轨迹预测的影响，并识别了传统指标未能揭示的特定场景故障案例。

Conclusion: 该论文提出的测试框架为自动驾驶预测模型的评估提供了更细致的方法，并强调了情景意识评估在识别故障案例和提高模型鲁棒性方面的重要性。

Abstract: Current evaluation methods for autonomous driving prediction models rely
heavily on simplistic metrics such as Average Displacement Error (ADE) and
Final Displacement Error (FDE). While these metrics offer basic performance
assessments, they fail to capture the nuanced behavior of prediction modules
under complex, interactive, and safety-critical driving scenarios. For
instance, existing benchmarks do not distinguish the influence of nearby versus
distant agents, nor systematically test model robustness across varying
multi-agent interactions. This paper addresses this critical gap by proposing a
novel testing framework that evaluates prediction performance under diverse
scene structures, saying, map context, agent density and spatial distribution.
Through extensive empirical analysis, we quantify the differential impact of
agent proximity on target trajectory prediction and identify scenario-specific
failure cases that are not exposed by traditional metrics. Our findings
highlight key vulnerabilities in current state-of-the-art prediction models and
demonstrate the importance of scenario-aware evaluation. The proposed framework
lays the groundwork for rigorous, safety-driven prediction validation,
contributing significantly to the identification of failure-prone corner cases
and the development of robust, certifiable prediction systems for autonomous
vehicles.

</details>


### [11] [Ctrl-World: A Controllable Generative World Model for Robot Manipulation](https://arxiv.org/abs/2510.10125)
*Yanjiang Guo,Lucy Xiaoyang Shi,Jianyu Chen,Chelsea Finn*

Main category: cs.RO

TL;DR: 本文提出了一种可控的多视角世界模型，能够在想象空间中评估和改善通用机器人策略的指令遵循能力。


<details>
  <summary>Details</summary>
Motivation: 现有通用机器人策略虽然能执行多种操作技能，但在处理陌生物体和指令时的评估与改进仍然是一个挑战。

Method: 引入一种可控的多视角世界模型来评估和改善通用机器人策略的指令遵循能力

Result: 我们的模型在新场景和新相机位置下生成空间和时间一致的轨迹，并且能够在没有真实机器人操作的情况下准确排名策略性能。

Conclusion: 通过在想象中合成成功轨迹并进行监督微调，我们的方法可以提升策略成功率44.7%。

Abstract: Generalist robot policies can now perform a wide range of manipulation
skills, but evaluating and improving their ability with unfamiliar objects and
instructions remains a significant challenge. Rigorous evaluation requires a
large number of real-world rollouts, while systematic improvement demands
additional corrective data with expert labels. Both of these processes are
slow, costly, and difficult to scale. World models offer a promising, scalable
alternative by enabling policies to rollout within imagination space. However,
a key challenge is building a controllable world model that can handle
multi-step interactions with generalist robot policies. This requires a world
model compatible with modern generalist policies by supporting multi-view
prediction, fine-grained action control, and consistent long-horizon
interactions, which is not achieved by previous works. In this paper, we make a
step forward by introducing a controllable multi-view world model that can be
used to evaluate and improve the instruction-following ability of generalist
robot policies. Our model maintains long-horizon consistency with a
pose-conditioned memory retrieval mechanism and achieves precise action control
through frame-level action conditioning. Trained on the DROID dataset (95k
trajectories, 564 scenes), our model generates spatially and temporally
consistent trajectories under novel scenarios and new camera placements for
over 20 seconds. We show that our method can accurately rank policy performance
without real-world robot rollouts. Moreover, by synthesizing successful
trajectories in imagination and using them for supervised fine-tuning, our
approach can improve policy success by 44.7\%.

</details>


### [12] [CompassNav: Steering From Path Imitation To Decision Understanding In Navigation](https://arxiv.org/abs/2510.10154)
*LinFeng Li,Jian Zhao,Yuan Xie,Xin Tan,Xuelong Li*

Main category: cs.RO

TL;DR: 本文提出了一种新范式：从路径模仿转向决策理解，通过引入Compass-Data-22k数据集和动态适应反馈的混合奖励函数，提升导航智能，从而开发出更理解导航的智能体。


<details>
  <summary>Details</summary>
Motivation: 当前大多数大型视觉语言模型（LVLMs）的导航训练依赖于模仿专家轨迹，这限制了代理探索和泛化的能力。

Method: 通过引入Compass-Data-22k数据集和基于决策确定性的混合奖励函数，采用SFT-然后-RFT的训练流程，将智能体训练为评估所有可能移动的相对质量，从而形成内在的方向感。

Result: 提出了CompassNav代理，该代理在目标导航基准上设定了新的最先进性能，甚至超越了更大的专有模型，并在物理机器人上实现了稳健的实际目标导航。

Conclusion: 我们的方法使7B代理能够理解导航决策，展现了超越传统路径模仿的强大能力，适用于真实世界的目标导航。

Abstract: The dominant paradigm for training Large Vision-Language Models (LVLMs) in
navigation relies on imitating expert trajectories. This approach reduces the
complex navigation task to a sequence-to-sequence replication of a single
correct path, fundamentally limiting the agent's ability to explore and
generalize. In this work, we argue for and introduce a new paradigm: a shift
from Path Imitation to Decision Understanding. The goal of this paradigm is to
build agents that do not just follow, but truly understand how to navigate. We
materialize this through two core contributions: first, we introduce
Compass-Data-22k, a novel 22k-trajectory dataset.Its Reinforcement Fine-Tuning
(RFT) subset provides a panoramic view of the decision landscape by annotating
all feasible actions with A* geodesic distances. Second, we design a novel
gap-aware hybrid reward function that dynamically adapts its feedback to
decision certainty, shifting between decisive signals for optimal actions and
nuanced scores to encourage exploration. Integrated into an SFT-then-RFT
recipe, our CompassNav agent is trained not to memorize static routes, but to
develop an internal ``compass'' that constantly intuits the direction to the
goal by evaluating the relative quality of all possible moves. This approach
enables our 7B agent to set a new state-of-the-art on Goal navigation
benchmarks, outperforming even larger proprietary models, and achieve robust
real-world goal navigation on a physical robot.

</details>


### [13] [Dejavu: Post-Deployment Learning for Embodied Agents via Experience Feedback](https://arxiv.org/abs/2510.10181)
*Shaokai Wu,Yanbiao Ji,Qiuchang Li,Zhiyi Zhang,Qichen He,Wenyuan Xie,Guodong Zhang,Bayram Bayramli,Yue Ding,Hongtao Lu*

Main category: cs.RO

TL;DR: Dejavu是一个后部署学习框架，通过经验反馈网络自动识别成功的行动经验，以提升具身代理的适应性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的具身代理在实际环境中执行特定任务后，无法获取新的有用知识来提升任务表现。

Method: EFN采用强化学习方法，并结合语义相似性奖励，确保预测的行动与当前观测下的成功行为一致，同时不断丰富记忆以适应新环境。

Result: 提出了一种通用的后部署学习框架Dejavu，利用经验反馈网络（EFN）和执行记忆来增强固定的视觉-语言-行动策略。

Conclusion: 实验表明，EFN在多种具身任务中显著提高了代理的适应性、鲁棒性和成功率，展示了具身代理持续改进行为的潜力。

Abstract: Embodied agents face a fundamental limitation: once deployed in real-world
environments to perform specific tasks, they are unable to acquire new useful
knowledge to enhance task performance. In this paper, we propose a general
post-deployment learning framework called Dejavu, which employs an Experience
Feedback Network (EFN) and augments the frozen Vision-Language-Action (VLA)
policy with retrieved execution memories. EFN automatically identifies
contextually successful prior action experiences and conditions action
prediction on this retrieved guidance. We adopt reinforcement learning with
semantic similarity rewards on EFN to ensure that the predicted actions align
with past successful behaviors under current observations. During deployment,
EFN continually enriches its memory with new trajectories, enabling the agent
to exhibit "learning from experience" despite fixed weights. Experiments across
diverse embodied tasks show that EFN significantly improves adaptability,
robustness, and success rates over frozen baselines. These results highlight a
promising path toward embodied agents that continually refine their behavior
after deployment.

</details>


### [14] [It Takes Two: Learning Interactive Whole-Body Control Between Humanoid Robots](https://arxiv.org/abs/2510.10206)
*Zuhong Liu,Junhao Ge,Minhao Xiong,Jiahao Gu,Bowei Tang,Wei Jing,Siheng Chen*

Main category: cs.RO

TL;DR: Harmanoid 是一种双人形机器人运动模仿框架，能更好地捕捉人类互动行为，改善了单人形机器人方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 探索人形机器人在多主体间的互动潜力，以实现更真实的社会互动。

Method: 通过接触感知的运动重新定位和互动驱动的运动控制器，实现机器人之间的协调运动。

Result: Harmanoid 框架在两个人形机器人间成功转移互动动作，保持运动的真实感和动力学一致性。

Conclusion: Harmanoid 显著提升了交互动作模仿的效果，超越了现有的单人形机器人框架。

Abstract: The true promise of humanoid robotics lies beyond single-agent autonomy: two
or more humanoids must engage in physically grounded, socially meaningful
whole-body interactions that echo the richness of human social interaction.
However, single-humanoid methods suffer from the isolation issue, ignoring
inter-agent dynamics and causing misaligned contacts, interpenetrations, and
unrealistic motions. To address this, we present Harmanoid , a dual-humanoid
motion imitation framework that transfers interacting human motions to two
robots while preserving both kinematic fidelity and physical realism. Harmanoid
comprises two key components: (i) contact-aware motion retargeting, which
restores inter-body coordination by aligning SMPL contacts with robot vertices,
and (ii) interaction-driven motion controller, which leverages
interaction-specific rewards to enforce coordinated keypoints and physically
plausible contacts. By explicitly modeling inter-agent contacts and
interaction-aware dynamics, Harmanoid captures the coupled behaviors between
humanoids that single-humanoid frameworks inherently overlook. Experiments
demonstrate that Harmanoid significantly improves interactive motion imitation,
surpassing existing single-humanoid frameworks that largely fail in such
scenarios.

</details>


### [15] [UF-RNN: Real-Time Adaptive Motion Generation Using Uncertainty-Driven Foresight Prediction](https://arxiv.org/abs/2510.10217)
*Hyogo Hiruma,Hiroshi Ito,Tetsuya Ogata*

Main category: cs.RO

TL;DR: 提出了一种UF-RNN模型，通过不确定性驱动的预测和内部模拟，以改进机器人在复杂环境中的操作能力。


<details>
  <summary>Details</summary>
Motivation: 解决在不确定状态下（如模糊对象属性或不可预测的互动）操作机器人的挑战，尤其是模仿学习方法在失败场景中的缺陷。

Method: Uncertainty-driven Foresight Recurrent Neural Network (UF-RNN)

Result: UF-RNN在模拟和真实机器人环境下进行开门任务评估，表现出良好的适应性，通过自诱发的混沌动态推动探索行为，提高成功率。

Conclusion: 将不确定性驱动的前瞻性整合入模仿学习流程可以显著提升机器人应对不可预测环境的能力。

Abstract: Training robots to operate effectively in environments with uncertain states,
such as ambiguous object properties or unpredictable interactions, remains a
longstanding challenge in robotics. Imitation learning methods typically rely
on successful examples and often neglect failure scenarios where uncertainty is
most pronounced. To address this limitation, we propose the Uncertainty-driven
Foresight Recurrent Neural Network (UF-RNN), a model that combines standard
time-series prediction with an active "Foresight" module. This module performs
internal simulations of multiple future trajectories and refines the hidden
state to minimize predicted variance, enabling the model to selectively explore
actions under high uncertainty. We evaluate UF-RNN on a door-opening task in
both simulation and a real-robot setting, demonstrating that, despite the
absence of explicit failure demonstrations, the model exhibits robust
adaptation by leveraging self-induced chaotic dynamics in its latent space.
When guided by the Foresight module, these chaotic properties stimulate
exploratory behaviors precisely when the environment is ambiguous, yielding
improved success rates compared to conventional stochastic RNN baselines. These
findings suggest that integrating uncertainty-driven foresight into imitation
learning pipelines can significantly enhance a robot's ability to handle
unpredictable real-world conditions.

</details>


### [16] [A3RNN: Bi-directional Fusion of Bottom-up and Top-down Process for Developmental Visual Attention in Robots](https://arxiv.org/abs/2510.10221)
*Hyogo Hiruma,Hiroshi Ito,Hiroki Mori,Tetsuya Ogata*

Main category: cs.RO

TL;DR: 本研究探讨了机器人学习中自上而下和自下而上的视觉注意力之间的发展互动，提出了一种新的注意力模型通过双向注意力架构整合了预测性和基于显著性的注意信号。


<details>
  <summary>Details</summary>
Motivation: 研究旨在理解自上而下与自下而上的注意机制如何通过相互适应在时间上发展出结构化的类人注意力行为。

Method: 提出了一个新颖的注意力模型A^3 RNN，通过双向注意力架构结合预测性和显著性基础的注意信号，进行模仿学习的机器人操作任务评估。

Result: 实验结果表明，注意力行为在训练过程中进化，从以显著性驱动的探索转变为以预测驱动的指引，最终表现出更连贯和可解释的注意力模式。

Conclusion: 我们的模型通过自我组织的注意力机制促进了更强稳健的注意力形成，展示了认知科学和自由能框架的原则。

Abstract: This study investigates the developmental interaction between top-down (TD)
and bottom-up (BU) visual attention in robotic learning. Our goal is to
understand how structured, human-like attentional behavior emerges through the
mutual adaptation of TD and BU mechanisms over time. To this end, we propose a
novel attention model $A^3 RNN$ that integrates predictive TD signals and
saliency-based BU cues through a bi-directional attention architecture.
  We evaluate our model in robotic manipulation tasks using imitation learning.
Experimental results show that attention behaviors evolve throughout training,
from saliency-driven exploration to prediction-driven direction. Initially, BU
attention highlights visually salient regions, which guide TD processes, while
as learning progresses, TD attention stabilizes and begins to reshape what is
perceived as salient. This trajectory reflects principles from cognitive
science and the free-energy framework, suggesting the importance of
self-organizing attention through interaction between perception and internal
prediction. Although not explicitly optimized for stability, our model exhibits
more coherent and interpretable attention patterns than baselines, supporting
the idea that developmental mechanisms contribute to robust attention
formation.

</details>


### [17] [Integration of the TIAGo Robot into Isaac Sim with Mecanum Drive Modeling and Learned S-Curve Velocity Profiles](https://arxiv.org/abs/2510.10273)
*Vincent Schoenbach,Marvin Wiedemann,Raphael Memmesheimer,Malte Mosbach,Sven Behnke*

Main category: cs.RO

TL;DR: 本文介绍了一种新的TIAGo++ Omni机器人模型，并提供了两种不同的控制模型以促进机器人在多种环境下的学习控制实验。


<details>
  <summary>Details</summary>
Motivation: 高效的物理模拟推动了机器人研究的发展，特别是在抓取和组装等应用中。引入新的机器人模型以支持学习驱动的控制是本文的主要动机。

Method: 提出了一个物理准确的控制模型和一个轻量级的基于速度的控制模型，同时引入了一种学习基于的校准方法。

Result: 本文介绍了一个TIAGo++ Omni机器人的模型，该模型被校准以近似真实机器人的行为，特别关注其全向驱动动态。我们提出了两种控制模型：一种是物理精确模型，能够复制现实世界的车轮动力学；另一种是轻量级的基于速度的模型，优化用于学习应用。引入的基于学习的校准方法可以使用最少的轨迹数据记录来近似真实机器人的S形速度曲线，旨在帮助研究人员在多种环境中进行高效的学习控制实验。

Conclusion: 通过引入此模型，研究人员可以更有效地在不同环境中进行机器人控制的学习和实验。

Abstract: Efficient physics simulation has significantly accelerated research progress
in robotics applications such as grasping and assembly. The advent of
GPU-accelerated simulation frameworks like Isaac Sim has particularly empowered
learning-based methods, enabling them to tackle increasingly complex tasks. The
PAL Robotics TIAGo++ Omni is a versatile mobile manipulator equipped with a
mecanum-wheeled base, allowing omnidirectional movement and a wide range of
task capabilities. However, until now, no model of the robot has been available
in Isaac Sim. In this paper, we introduce such a model, calibrated to
approximate the behavior of the real robot, with a focus on its omnidirectional
drive dynamics. We present two control models for the omnidirectional drive: a
physically accurate model that replicates real-world wheel dynamics and a
lightweight velocity-based model optimized for learning-based applications.
With these models, we introduce a learning-based calibration approach to
approximate the real robot's S-shaped velocity profile using minimal trajectory
data recordings. This simulation should allow researchers to experiment with
the robot and perform efficient learning-based control in diverse environments.
We provide the integration publicly at https://github.com/AIS-Bonn/tiago_isaac.

</details>


### [18] [X-VLA: Soft-Prompted Transformer as Scalable Cross-Embodiment Vision-Language-Action Model](https://arxiv.org/abs/2510.10274)
*Jinliang Zheng,Jianxiong Li,Zhihao Wang,Dongxiu Liu,Xirui Kang,Yuchun Feng,Yinan Zheng,Jiayin Zou,Yilun Chen,Jia Zeng,Ya-Qin Zhang,Jiangmiao Pang,Jingjing Liu,Tai Wang,Xianyuan Zhan*

Main category: cs.RO

TL;DR: 提出了一种新的Soft Prompt方法来提升通用视觉-语言-动作模型，借助不同数据源的可调嵌入，以实现高性能的跨体现学习。


<details>
  <summary>Details</summary>
Motivation: 为了有效利用不同机器人平台的多样化数据，提高视觉-语言-动作模型的泛化能力和性能。

Method: 采用软提示的标准Transformer编码器，结合可学习的嵌入来处理跨体现特征。

Result: 在6个模拟和3个真实机器人上测试，X-VLA-0.9B实现了当前最先进的性能。

Conclusion: X-VLA模型在多个基准测试中表现出色，展示了其在灵活性和快速适应方面的优势。

Abstract: Successful generalist Vision-Language-Action (VLA) models rely on effective
training across diverse robotic platforms with large-scale, cross-embodiment,
heterogeneous datasets. To facilitate and leverage the heterogeneity in rich,
diverse robotic data sources, we propose a novel Soft Prompt approach with
minimally added parameters, by infusing prompt learning concepts into
cross-embodiment robot learning and introducing separate sets of learnable
embeddings for each distinct data source. These embeddings serve as
embodiment-specific prompts, which in unity empower VLA models with effective
exploitation of varying cross-embodiment features. Our new X-VLA, a neat
flow-matching-based VLA architecture, relies exclusively on soft-prompted
standard Transformer encoders, enjoying both scalability and simplicity.
Evaluated across 6 simulations as well as 3 real-world robots, our 0.9B
instantiation-X-VLA-0.9B simultaneously achieves SOTA performance over a sweep
of benchmarks, demonstrating superior results on a wide axes of capabilities,
from flexible dexterity to quick adaptation across embodiments, environments,
and tasks. Website: https://thu-air-dream.github.io/X-VLA/

</details>


### [19] [Towards Safe Maneuvering of Double-Ackermann-Steering Robots with a Soft Actor-Critic Framework](https://arxiv.org/abs/2510.10332)
*Kohio Deflesselle,Mélodie Daniel,Aly Magassouba,Miguel Aranda,Olivier Ly*

Main category: cs.RO

TL;DR: 提出了一种基于软演员评论家框架的深度强化学习方法，旨在提高双Ackermann转向移动机器人在复杂环境中的安全精确操控。


<details>
  <summary>Details</summary>
Motivation: 面对复杂环境中的强动力学约束，现有的经典规划方法效果不佳，因此需要一种新的框架来提升移动机器人的操作能力。

Method: 基于深度强化学习，利用软 actor-critic 和 Hindsight Experience Replay 以及 CrossQ 覆盖来训练机器人策略。

Result: 仿真结果显示，学习到的策略可在避开障碍物的同时，稳健地到达97%的目标位置。

Conclusion: 该框架有效地提高了双Ackermann转向移动机器人在复杂环境中的安全精确操控能力。

Abstract: We present a deep reinforcement learning framework based on Soft Actor-Critic
(SAC) for safe and precise maneuvering of double-Ackermann-steering mobile
robots (DASMRs). Unlike holonomic or simpler non-holonomic robots such as
differential-drive robots, DASMRs face strong kinematic constraints that make
classical planners brittle in cluttered environments. Our framework leverages
the Hindsight Experience Replay (HER) and the CrossQ overlay to encourage
maneuvering efficiency while avoiding obstacles. Simulation results with a
heavy four-wheel-steering rover show that the learned policy can robustly reach
up to 97% of target positions while avoiding obstacles. Our framework does not
rely on handcrafted trajectories or expert demonstrations.

</details>


### [20] [Rise of the Robochemist](https://arxiv.org/abs/2510.10337)
*Jihong Zhu,Kefeng Huang,Jonathon Pipe,Chris Horbaczewsky,Andy Tyrrell,Ian J. S. Fairlamb*

Main category: cs.RO

TL;DR: 机器人和人工智能的结合将改变化学研究，创建‘robo-chemist’，与人类化学家协作，提高实验效率与创新。


<details>
  <summary>Details</summary>
Motivation: 推动化学的进步，提高实验效率和创新速度

Method: 综述当代机器人及人工智能在化学领域的应用

Result: 提出了‘robo-chemist’概念，强调机器人与人类化学家的协作关系

Conclusion: 化学的未来依赖于人类与机器人之间的共生合作，结合人类的直觉和机器的精准。

Abstract: Chemistry, a long-standing discipline, has historically relied on manual and
often time-consuming processes. While some automation exists, the field is now
on the cusp of a significant evolution driven by the integration of robotics
and artificial intelligence (AI), giving rise to the concept of the
robochemist: a new paradigm where autonomous systems assist in designing,
executing, and analyzing experiments. Robochemists integrate mobile
manipulators, advanced perception, teleoperation, and data-driven protocols to
execute experiments with greater adaptability, reproducibility, and safety.
Rather than a fully automated replacement for human chemists, we envisioned the
robochemist as a complementary partner that works collaboratively to enhance
discovery, enabling a more efficient exploration of chemical space and
accelerating innovation in pharmaceuticals, materials science, and sustainable
manufacturing. This article traces the technologies, applications, and
challenges that define this transformation, highlighting both the opportunities
and the responsibilities that accompany the emergence of the robochemist.
Ultimately, the future of chemistry is argued to lie in a symbiotic partnership
where human intuition and expertise is amplified by robotic precision and
AI-driven insight.

</details>


### [21] [sqrtVINS: Robust and Ultrafast Square-Root Filter-based 3D Motion Tracking](https://arxiv.org/abs/2510.10346)
*Yuxiang Peng,Chuchu Chen,Kejian Wu,Guoquan Huang*

Main category: cs.RO

TL;DR: 提出了一种新的视觉惯性导航系统，具有高效性和鲁棒性，并开源实现。


<details>
  <summary>Details</summary>
Motivation: 解决嵌入式系统中视觉惯性导航的资源约束和数值不稳定性问题。

Method: 使用基于Cholesky分解的平方根滤波更新方法，结合快速鲁棒的动态初始化策略。

Result: 本论文提出了一种基于平方根滤波器的视觉惯性导航系统（sqrtVINS），具有超快的速度和数字稳定性，能够在极端条件下动态初始化。

Conclusion: sqrtVINS在多种场景下展现了卓越的效率和可靠性，对于未来的研究与应用具有重要意义。

Abstract: In this paper, we develop and open-source, for the first time, a square-root
filter (SRF)-based visual-inertial navigation system (VINS), termed sqrtVINS,
which is ultra-fast, numerically stable, and capable of dynamic initialization
even under extreme conditions (i.e., extremely small time window). Despite
recent advancements in VINS, resource constraints and numerical instability on
embedded (robotic) systems with limited precision remain critical challenges. A
square-root covariance-based filter offers a promising solution by providing
numerical stability, efficient memory usage, and guaranteed positive
semi-definiteness. However, canonical SRFs suffer from inefficiencies caused by
disruptions in the triangular structure of the covariance matrix during
updates. The proposed method significantly improves VINS efficiency with a
novel Cholesky decomposition (LLT)-based SRF update, by fully exploiting the
system structure to preserve the structure. Moreover, we design a fast, robust,
dynamic initialization method, which first recovers the minimal states without
triangulating 3D features and then efficiently performs iterative SRF update to
refine the full states, enabling seamless VINS operation. The proposed
LLT-based SRF is extensively verified through numerical studies, demonstrating
superior numerical stability and achieving robust efficient performance on
32-bit single-precision floats, operating at twice the speed of
state-of-the-art (SOTA) methods. Our initialization method, tested on both
mobile workstations and Jetson Nano computers, achieving a high success rate of
initialization even within a 100 ms window under minimal conditions. Finally,
the proposed sqrtVINS is extensively validated across diverse scenarios,
demonstrating strong efficiency, robustness, and reliability. The full
open-source implementation is released to support future research and
applications.

</details>


### [22] [Learning to Throw-Flip](https://arxiv.org/abs/2510.10357)
*Yang Liu,Bruno Da Costa,Aude Billard*

Main category: cs.RO

TL;DR: 提出了一种能够准确投掷物体至特定落地姿态的机器人方法，显著提高物流操作的速度和灵活性。


<details>
  <summary>Details</summary>
Motivation: 动力学操作在物流中正越来越受到重视，但现有研究主要关注物体落地位置，而忽视其最终方向。

Method: 通过设计一系列抛掷运动以有效解耦寄生旋转，并结合物理模型和基于回归的学习方法来考虑未建模影响。

Result: 本研究提出了一种新方法，使机器人能够准确地将物体"投掷翻转"到期望的落地姿态（位置和方向）。

Conclusion: 通过采用冲击动量原则和物理模型结合学习方法，我们的方法显著提高了机器人的投掷精度并减少了样本复杂性。

Abstract: Dynamic manipulation, such as robot tossing or throwing objects, has recently
gained attention as a novel paradigm to speed up logistic operations. However,
the focus has predominantly been on the object's landing location, irrespective
of its final orientation. In this work, we present a method enabling a robot to
accurately "throw-flip" objects to a desired landing pose (position and
orientation). Conventionally, objects thrown by revolute robots suffer from
parasitic rotation, resulting in highly restricted and uncontrollable landing
poses. Our approach is based on two key design choices: first, leveraging the
impulse-momentum principle, we design a family of throwing motions that
effectively decouple the parasitic rotation, significantly expanding the
feasible set of landing poses. Second, we combine a physics-based model of free
flight with regression-based learning methods to account for unmodeled effects.
Real robot experiments demonstrate that our framework can learn to throw-flip
objects to a pose target within ($\pm$5 cm, $\pm$45 degrees) threshold in
dozens of trials. Thanks to data assimilation, incorporating projectile
dynamics reduces sample complexity by an average of 40% when throw-flipping to
unseen poses compared to end-to-end learning methods. Additionally, we show
that past knowledge on in-hand object spinning can be effectively reused,
accelerating learning by 70% when throwing a new object with a Center of Mass
(CoM) shift. A video summarizing the proposed method and the hardware
experiments is available at https://youtu.be/txYc9b1oflU.

</details>


### [23] [RobotFleet: An Open-Source Framework for Centralized Multi-Robot Task Planning](https://arxiv.org/abs/2510.10379)
*Rohan Gupta,Trevor Asbery,Zain Merchant,Abrar Anwar,Jesse Thomason*

Main category: cs.RO

TL;DR: RobotFleet是一个开源框架，旨在通过集中式多机器人任务规划和调度来简化异构机器人车队的管理，实现多个任务。


<details>
  <summary>Details</summary>
Motivation: 在多机器人系统中协调异构机器人车队以实现多个目标是一个挑战。

Method: 通过模块化自治堆栈的各个层，并利用大规模语言模型进行开放世界推理，支持任务执行和重新规划。

Result: RobotFleet降低了构建可扩展多机器人系统的门槛，并提供了一套开源可扩展框架。

Conclusion: RobotFleet为异构机器人车队任务规划和调度提供了一种集中式框架，简化了多机器人系统的管理和扩展。

Abstract: Coordinating heterogeneous robot fleets to achieve multiple goals is
challenging in multi-robot systems. We introduce an open-source and extensible
framework for centralized multi-robot task planning and scheduling that
leverages LLMs to enable fleets of heterogeneous robots to accomplish multiple
tasks. RobotFleet provides abstractions for planning, scheduling, and execution
across robots deployed as containerized services to simplify fleet scaling and
management. The framework maintains a shared declarative world state and
two-way communication for task execution and replanning. By modularizing each
layer of the autonomy stack and using LLMs for open-world reasoning, RobotFleet
lowers the barrier to building scalable multi-robot systems. The code can be
found here: https://github.com/therohangupta/robot-fleet.

</details>


### [24] [MicroRoboScope: A Portable and Integrated Mechatronic Platform for Magnetic and Acoustic Microrobotic Experimentation](https://arxiv.org/abs/2510.10392)
*Max Sokolich,Yanda Yang,Subrahmanyam Cherukumilli,Fatma Ceren Kirmizitas,Sambeeta Das*

Main category: cs.RO

TL;DR: 本文介绍了一种名为MicroRoboScope的便携式微型机器人实验平台，该平台集成了多种设备和定制软件，旨在降低微型机器人实验的入门门槛，拓展其在多个领域的应用。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是设计一种便携、紧凑、多功能的微型机器人实验平台，旨在实现实时闭环控制，以促进微型机器人实验在各个领域的应用。

Method: 本研究通过集成嵌入式计算机、显微镜、电源和控制电路，开发了一种低成本的微型机器人实验平台，使用Python和Arduino C++编写定制控制软件，处理视频采集、机器人跟踪及控制信号生成。

Result: 该平台的多模态驱动特点使其不仅适合专业研究实验室，同时也适用于教育和推广环境。

Conclusion: MicroRoboScope系统降低了微型机器人实验的入门门槛，为生物医学、组织工程和机器人等领域的研究、教育和转化应用创造了新机会。

Abstract: This paper presents MicroRoboScope, a portable, compact, and versatile
microrobotic experimentation platform designed for real-time, closed-loop
control of both magnetic and acoustic microrobots. The system integrates an
embedded computer, microscope, power supplies, and control circuitry into a
single, low-cost and fully integrated apparatus. Custom control software
developed in Python and Arduino C++ handles live video acquisition, microrobot
tracking, and generation of control signals for electromagnetic coils and
acoustic transducers. The platform's multi-modal actuation, accessibility, and
portability make it suitable not only for specialized research laboratories but
also for educational and outreach settings. By lowering the barrier to entry
for microrobotic experimentation, this system enables new opportunities for
research, education, and translational applications in biomedicine, tissue
engineering, and robotics.

</details>


### [25] [Hierarchical Planning for Long-Horizon Multi-Target Tracking Under Target Motion Uncertainty](https://arxiv.org/abs/2510.10421)
*Junbin Yuan,Brady Moon,Muqing Cao,Sebastian Scherer*

Main category: cs.RO

TL;DR: 本文提出了一种分层路径规划算法，以改善无人机在大范围内追踪多个动态目标的能力，克服了现有算法在长时间和大范围环境中的不足。


<details>
  <summary>Details</summary>
Motivation: 传统单机器人系统面临在大的空间区域内持久追踪多个动态目标的挑战，尤其在目标超出视野时，跟踪变得更加困难。

Method: 本方法整合运动模型与不确定性传播，利用低级覆盖规划器与评估方法，将多目标跟踪任务转化为马尔可夫决策过程，并使用基于树的算法求解子任务序列。

Result: 该算法在模拟验证中表现出比现有规划算法更优越的性能，尤其在不同环境中有效降低了不确定性。

Conclusion: 通过在模拟中验证，所提出的规划算法在主动目标跟踪任务中表现优异，相较于现有方法减少了11-70%的最终不确定性。

Abstract: Achieving persistent tracking of multiple dynamic targets over a large
spatial area poses significant challenges for a single-robot system with
constrained sensing capabilities. As the robot moves to track different
targets, the ones outside the field of view accumulate uncertainty, making them
progressively harder to track. An effective path planning algorithm must manage
uncertainty over a long horizon and account for the risk of permanently losing
track of targets that remain unseen for too long. However, most existing
approaches rely on short planning horizons and assume small, bounded
environments, resulting in poor tracking performance and target loss in
large-scale scenarios. In this paper, we present a hierarchical planner for
tracking multiple moving targets with an aerial vehicle. To address the
challenge of tracking non-static targets, our method incorporates motion models
and uncertainty propagation during path execution, allowing for more informed
decision-making. We decompose the multi-target tracking task into sub-tasks of
single target search and detection, and our proposed pipeline consists a novel
low-level coverage planner that enables searching for a target in an evolving
belief area, and an estimation method to assess the likelihood of success for
each sub-task, making it possible to convert the active target tracking task to
a Markov decision process (MDP) that we solve with a tree-based algorithm to
determine the sequence of sub-tasks. We validate our approach in simulation,
demonstrating its effectiveness compared to existing planners for active target
tracking tasks, and our proposed planner outperforms existing approaches,
achieving a reduction of 11-70% in final uncertainty across different
environments.

</details>


### [26] [Towards Dynamic Quadrupedal Gaits: A Symmetry-Guided RL Hierarchy Enables Free Gait Transitions at Varying Speeds](https://arxiv.org/abs/2510.10455)
*Jiayu Ding,Xulin Chen,Garrett E. Katz,Zhenyu Gan*

Main category: cs.RO

TL;DR: 本研究通过一种强化学习框架，利用对称性提高了四足机器人的步态适应性，简化了步态生成过程。


<details>
  <summary>Details</summary>
Motivation: 传统的步态生成方法依赖专业调优多个变量，过程繁琐，因此需要一种更有效的方法来生成四足机器人的多样化步态。

Method: 利用内在对称性和动态腿部系统的速度-周期关系，提出了一种对称性导向的奖励函数设计，专注于保持对称性和自然动态。

Result: 在Unitree Go2机器人上实施后，方法在模拟和硬件测试中表现稳健，丰富了步态转换，且无需广泛的奖励调优或明确的足部位置控制。

Conclusion: 该研究提出了一种统一的强化学习框架，显著提高了四足机器人在不同速度下的步态适应能力，强调了对称性在机器人步态设计中的重要性。

Abstract: Quadrupedal robots exhibit a wide range of viable gaits, but generating
specific footfall sequences often requires laborious expert tuning of numerous
variables, such as touch-down and lift-off events and holonomic constraints for
each leg. This paper presents a unified reinforcement learning framework for
generating versatile quadrupedal gaits by leveraging the intrinsic symmetries
and velocity-period relationship of dynamic legged systems. We propose a
symmetry-guided reward function design that incorporates temporal,
morphological, and time-reversal symmetries. By focusing on preserved
symmetries and natural dynamics, our approach eliminates the need for
predefined trajectories, enabling smooth transitions between diverse locomotion
patterns such as trotting, bounding, half-bounding, and galloping. Implemented
on the Unitree Go2 robot, our method demonstrates robust performance across a
range of speeds in both simulations and hardware tests, significantly improving
gait adaptability without extensive reward tuning or explicit foot placement
control. This work provides insights into dynamic locomotion strategies and
underscores the crucial role of symmetries in robotic gait design.

</details>


### [27] [Galilean Symmetry in Robotics](https://arxiv.org/abs/2510.10468)
*Robert Mahony,Jonathan Kelly,Stephan Weiss*

Main category: cs.RO

TL;DR: 本文将伽利略对称性引入机器人领域，讨论其与刚体变换的关系，并通过实例展示其在现代机器人问题中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 尽管刚体对称性在机器人学中得到了广泛应用，但在机器人领域对伽利略对称性的处理相对较少。

Method: 介绍伽利略对称性，并结合机器人领域的刚性体变换和姿态表示进行讨论。

Result: 通过伽利略矩阵李群，提出两种不同的姿态表示方法，并在惯性导航、机械臂运动学和传感器数据融合等方面提供示例，展示其实用性。

Conclusion: 机器人社区应重新发现和扩展经典的伽利略对称性，并将其应用于现代问题。

Abstract: Galilean symmetry is the natural symmetry of inertial motion that underpins
Newtonian physics. Although rigid-body symmetry is one of the most established
and fundamental tools in robotics, there appears to be no comparable treatment
of Galilean symmetry for a robotics audience. In this paper, we present a
robotics-tailored exposition of Galilean symmetry that leverages the
community's familiarity with and understanding of rigid-body transformations
and pose representations. Our approach contrasts with common treatments in the
physics literature that introduce Galilean symmetry as a stepping stone to
Einstein's relativity. A key insight is that the Galilean matrix Lie group can
be used to describe two different pose representations, Galilean frames, that
use inertial velocity in the state definition, and extended poses, that use
coordinate velocity. We provide three examples where applying the Galilean
matrix Lie-group algebra to robotics problems is straightforward and yields
significant insights: inertial navigation above the rotating Earth, manipulator
kinematics, and sensor data fusion under temporal uncertainty. We believe that
the time is right for the robotics community to benefit from rediscovering and
extending this classical material and applying it to modern problems.

</details>


### [28] [SuperEx: Enhancing Indoor Mapping and Exploration using Non-Line-of-Sight Perception](https://arxiv.org/abs/2510.10506)
*Kush Garg,Akshat Dave*

Main category: cs.RO

TL;DR: 本文提出了一种新的机器人探索框架SuperEx，利用非视线感知提高室内环境映射的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 当前机器人感知主要依赖视线，无法有效探索被遮挡的区域。本研究希望通过NLOS感知提升机器人在未知环境中的探索能力。

Method: 本研究通过单光子LiDAR捕捉时间飞行直方图，结合物理基础和数据驱动的方法，改进了映射探索循环。

Result: 该论文介绍了SuperEx，一个将非视线感知(NLOS)引入机器人探索和映射的框架。通过利用单光子LiDAR技术，SuperEx提升了机器人在未知室内环境中的探索和映射效率。

Conclusion: SuperEx显著提高了在复杂环境下的映射准确性和探索效率，为突破现有的映射技术提供了新的思路。

Abstract: Efficient exploration and mapping in unknown indoor environments is a
fundamental challenge, with high stakes in time-critical settings. In current
systems, robot perception remains confined to line-of-sight; occluded regions
remain unknown until physically traversed, leading to inefficient exploration
when layouts deviate from prior assumptions. In this work, we bring
non-line-of-sight (NLOS) sensing to robotic exploration. We leverage
single-photon LiDARs, which capture time-of-flight histograms that encode the
presence of hidden objects - allowing robots to look around blind corners.
Recent single-photon LiDARs have become practical and portable, enabling
deployment beyond controlled lab settings. Prior NLOS works target 3D
reconstruction in static, lab-based scenarios, and initial efforts toward
NLOS-aided navigation consider simplified geometries. We introduce SuperEx, a
framework that integrates NLOS sensing directly into the mapping-exploration
loop. SuperEx augments global map prediction with beyond-line-of-sight cues by
(i) carving empty NLOS regions from timing histograms and (ii) reconstructing
occupied structure via a two-step physics-based and data-driven approach that
leverages structural regularities. Evaluations on complex simulated maps and
the real-world KTH Floorplan dataset show a 12% gain in mapping accuracy under
< 30% coverage and improved exploration efficiency compared to line-of-sight
baselines, opening a path to reliable mapping beyond direct visibility.

</details>


### [29] [Population-Coded Spiking Neural Networks for High-Dimensional Robotic Control](https://arxiv.org/abs/2510.10516)
*Kanishkha Jaisankar,Xiaoyang Jiang,Feifan Liao,Jeethu Sreenivas Amuthan*

Main category: cs.RO

TL;DR: 本论文提出了一种将群体编码脉冲神经网络和深度强化学习相结合的框架，优化了资源受限环境下的电机控制，且在能效和性能上均有显著提升。


<details>
  <summary>Details</summary>
Motivation: 在资源受限环境中，开发能效高且性能卓越的电机控制系统是机器人技术面临的主要挑战，尤其是在高维连续控制任务中，深度强化学习(DRL)的计算需求和能耗问题尤为突出。

Method: 开发了人口编码脉冲演员网络(PopSAN)，通过梯度更新实现最优策略学习，并在艾萨克健身平台上对复杂机器人操作任务进行了评估。

Result: 提出了一种新的框架，将基于群体编码的脉冲神经网络(SNN)与深度强化学习(DRL)相结合，显著提高了能效和控制性能。

Conclusion: 基于群体编码的脉冲神经网络为资源受限应用中的能效高、性能优越的机器人控制提供了有前景的解决方案，促进了真实世界机器人系统的可扩展部署。

Abstract: Energy-efficient and high-performance motor control remains a critical
challenge in robotics, particularly for high-dimensional continuous control
tasks with limited onboard resources. While Deep Reinforcement Learning (DRL)
has achieved remarkable results, its computational demands and energy
consumption limit deployment in resource-constrained environments. This paper
introduces a novel framework combining population-coded Spiking Neural Networks
(SNNs) with DRL to address these challenges. Our approach leverages the
event-driven, asynchronous computation of SNNs alongside the robust policy
optimization capabilities of DRL, achieving a balance between energy efficiency
and control performance. Central to this framework is the Population-coded
Spiking Actor Network (PopSAN), which encodes high-dimensional observations
into neuronal population activities and enables optimal policy learning through
gradient-based updates. We evaluate our method on the Isaac Gym platform using
the PixMC benchmark with complex robotic manipulation tasks. Experimental
results on the Franka robotic arm demonstrate that our approach achieves energy
savings of up to 96.10% compared to traditional Artificial Neural Networks
(ANNs) while maintaining comparable control performance. The trained SNN
policies exhibit robust finger position tracking with minimal deviation from
commanded trajectories and stable target height maintenance during
pick-and-place operations. These results position population-coded SNNs as a
promising solution for energy-efficient, high-performance robotic control in
resource-constrained applications, paving the way for scalable deployment in
real-world robotics systems.

</details>


### [30] [Decoupled Scaling 4ch Bilateral Control on the Cartesian coordinate by 6-DoF Manipulator using Rotation Matrix](https://arxiv.org/abs/2510.10545)
*Koki Yamane,Sho Sakaino,Toshiaki Tsuji*

Main category: cs.RO

TL;DR: 提出了一种四通道双边控制方法，通过在笛卡尔坐标系中解耦各维度，提高远程操作的有效性。


<details>
  <summary>Details</summary>
Motivation: 为了提高远程控制在接触密集任务中的操作性，特别是在处理不同结构的操纵器时。

Method: 通过独立调节笛卡尔坐标系中的每个维度，来实现四通道双边控制。

Result: 该方法增强了远程控制的可操作性，提供了直观的用户体验。

Conclusion: 本文提出了一种四通道双边控制方法，能在笛卡尔坐标系中解耦各维度，达到期望的动态效果。

Abstract: Four-channel bilateral control is a method for achieving remote control with
force feedback and adjustment operability by synchronizing the positions and
forces of two manipulators. This is expected to significantly improve the
operability of the remote control in contact-rich tasks. Among these, 4-channel
bilateral control on the Cartesian coordinate system is advantageous owing to
its suitability for manipulators with different structures and because it
allows the dynamics in the Cartesian coordinate system to be adjusted by
adjusting the control parameters, thus achieving intuitive operability for
humans. This paper proposes a 4-channel bilateral control method that achieves
the desired dynamics by decoupling each dimension in the Cartesian coordinate
system regardless of the scaling factor.

</details>


### [31] [A Modular AIoT Framework for Low-Latency Real-Time Robotic Teleoperation in Smart Cities](https://arxiv.org/abs/2510.11421)
*Shih-Chieh Sun,Yun-Cheng Tsai*

Main category: cs.RO

TL;DR: 本论文提出了一种基于AI的物联网机器人遥控系统，旨在实现实时远程操作和智能视觉监控，特别适合智慧城市应用。


<details>
  <summary>Details</summary>
Motivation: 论文的动机是开发一个适用于智慧城市的高效实时遥控系统，增强公共设施的操作效率。

Method: 系统架构结合了基于Flutter的移动界面、MQTT控制信令和WebRTC视频流，采用YOLOv11-nano进行实时目标检测，控制命令通过MQTT发送至ESP8266驱动的执行节点。

Result: 实验结果表明，在本地及国际VPN场景下，执行器响应时间低至0.2秒，总视频延迟在1.2秒以内。

Conclusion: 该系统通过低延迟和模块化设计确保响应迅速与鲁棒的性能，适合于智慧城市的各种场景。

Abstract: This paper presents an AI-driven IoT robotic teleoperation system designed
for real-time remote manipulation and intelligent visual monitoring, tailored
for smart city applications. The architecture integrates a Flutter-based
cross-platform mobile interface with MQTT-based control signaling and WebRTC
video streaming via the LiveKit framework. A YOLOv11-nano model is deployed for
lightweight object detection, enabling real-time perception with annotated
visual overlays delivered to the user interface. Control commands are
transmitted via MQTT to an ESP8266-based actuator node, which coordinates
multi-axis robotic arm motion through an Arduino Mega2560 controller. The
backend infrastructure is hosted on DigitalOcean, ensuring scalable cloud
orchestration and stable global communication. Latency evaluations conducted
under both local and international VPN scenarios (including Hong Kong, Japan,
and Belgium) demonstrate actuator response times as low as 0.2 seconds and
total video latency under 1.2 seconds, even across high-latency networks. This
low-latency dual-protocol design ensures responsive closed-loop interaction and
robust performance in distributed environments. Unlike conventional
teleoperation platforms, the proposed system emphasizes modular deployment,
real-time AI sensing, and adaptable communication strategies, making it
well-suited for smart city scenarios such as remote infrastructure inspection,
public equipment servicing, and urban automation. Future enhancements will
focus on edge-device deployment, adaptive routing, and integration with
city-scale IoT networks to enhance resilience and scalability.

</details>


### [32] [Reinforcement Learning-based Dynamic Adaptation for Sampling-Based Motion Planning in Agile Autonomous Driving](https://arxiv.org/abs/2510.10567)
*Alexander Langmann,Yevhenii Tokarev,Mattia Piccinini,Korbinian Moller,Johannes Betz*

Main category: cs.RO

TL;DR: 提出了一种通过强化学习动态调整成本函数参数的轨迹规划方法，以优化自主驾驶的性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有采样基轨迹规划器在处理多种场景时，手动调节的静态权重导致的次优表现。

Method: 利用强化学习的代理在运行时动态切换低层次轨迹规划器的成本函数参数。

Result: 在自主赛车模拟中，RL规划器实现了0%的碰撞率，并将超车时间减少了最多60%。

Conclusion: 通过强化学习的高层选择器解决了自主赛车规划中的安全和竞争性之间的固有权衡，并为更广泛的自主驾驶应用提供了适应性和可解释的运动规划途径。

Abstract: Sampling-based trajectory planners are widely used for agile autonomous
driving due to their ability to generate fast, smooth, and kinodynamically
feasible trajectories. However, their behavior is often governed by a cost
function with manually tuned, static weights, which forces a tactical
compromise that is suboptimal across the wide range of scenarios encountered in
a race. To address this shortcoming, we propose using a Reinforcement Learning
(RL) agent as a high-level behavioral selector that dynamically switches the
cost function parameters of an analytical, low-level trajectory planner during
runtime. We show the effectiveness of our approach in simulation in an
autonomous racing environment where our RL-based planner achieved 0% collision
rate while reducing overtaking time by up to 60% compared to state-of-the-art
static planners. Our new agent now dynamically switches between aggressive and
conservative behaviors, enabling interactive maneuvers unattainable with static
configurations. These results demonstrate that integrating reinforcement
learning as a high-level selector resolves the inherent trade-off between
safety and competitiveness in autonomous racing planners. The proposed
methodology offers a pathway toward adaptive yet interpretable motion planning
for broader autonomous driving applications.

</details>


### [33] [Coordinated Strategies in Realistic Air Combat by Hierarchical Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2510.11474)
*Ardian Selmonaj,Giacomo Del Rio,Adrian Schneider,Alessandro Antonucci*

Main category: cs.RO

TL;DR: 提出了一种新型的3D多智能体空战环境和分层多智能体强化学习框架，以应对现实空战中的挑战。


<details>
  <summary>Details</summary>
Motivation: 应对不完美的情境意识和非线性飞行动态，旨在实现空战模拟任务目标。

Method: 结合异质智能体动态、课程学习、联赛对抗及新的训练算法，决策过程分为两个抽象层次：低层次政策学习精确控制，高层次政策基于任务目标发布战术指令。

Result: 实证结果显示，分层方法在复杂空战场景中显著提升了学习效率和战斗表现。

Conclusion: 分层方法提高了复杂空战场景中的学习效率和战斗表现。

Abstract: Achieving mission objectives in a realistic simulation of aerial combat is
highly challenging due to imperfect situational awareness and nonlinear flight
dynamics. In this work, we introduce a novel 3D multi-agent air combat
environment and a Hierarchical Multi-Agent Reinforcement Learning framework to
tackle these challenges. Our approach combines heterogeneous agent dynamics,
curriculum learning, league-play, and a newly adapted training algorithm. To
this end, the decision-making process is organized into two abstraction levels:
low-level policies learn precise control maneuvers, while high-level policies
issue tactical commands based on mission objectives. Empirical results show
that our hierarchical approach improves both learning efficiency and combat
performance in complex dogfight scenarios.

</details>


### [34] [Fast Vision in the Dark: A Case for Single-Photon Imaging in Planetary Navigation](https://arxiv.org/abs/2510.10597)
*David Rodríguez-Martínez,C. J. Pérez del Pulgar*

Main category: cs.RO

TL;DR: 本研究提出了一种使用SPAD相机的行星导航新方法，以克服传统相机在复杂光照条件下的局限性。


<details>
  <summary>Details</summary>
Motivation: 改善机器人导航对拓展探测范围和提高操作效率至关重要，传统相机在复杂光照条件下面临挑战。

Method: 提出了一种新颖的行星导航方法，利用单光子雪崩二极管（SPAD）相机的独特成像能力。

Result: 提供了单光子成像作为被动传感技术的首次全面评估，特别针对高纬度月球区域的探索任务。

Conclusion: 评估了SPAD相机在即将到来的月球探索任务中应对关键感知挑战的优势和局限性，并在代表性光照条件下基准测试其性能。

Abstract: Improving robotic navigation is critical for extending exploration range and
enhancing operational efficiency. Vision-based navigation relying on
traditional CCD or CMOS cameras faces major challenges when complex
illumination conditions are paired with motion, limiting the range and
accessibility of mobile planetary robots. In this study, we propose a novel
approach to planetary navigation that leverages the unique imaging capabilities
of Single-Photon Avalanche Diode (SPAD) cameras. We present the first
comprehensive evaluation of single-photon imaging as an alternative passive
sensing technology for robotic exploration missions targeting perceptually
challenging locations, with a special emphasis on high-latitude lunar regions.
We detail the operating principles and performance characteristics of SPAD
cameras, assess their advantages and limitations in addressing key perception
challenges of upcoming exploration missions to the Moon, and benchmark their
performance under representative illumination conditions.

</details>


### [35] [SpikeGrasp: A Benchmark for 6-DoF Grasp Pose Detection from Stereo Spike Streams](https://arxiv.org/abs/2510.10602)
*Zhuoheng Gao,Jiyao Zhang,Zhiyong Xie,Hao Dong,Zhaofei Yu,Rongmei Chen,Guozhang Chen,Tiejun Huang*

Main category: cs.RO

TL;DR: 本论文提出了一种新颖的神经启发式抓取检测框架SpikeGrasp，通过处理立体脉冲相机的原始异步事件，直接推断抓取姿态，而无需重建点云，展示了比传统方法更优的性能。


<details>
  <summary>Details</summary>
Motivation: 通过模仿生物视觉运动通路，探索一种新的6自由度抓取检测方法，避免传统的点云重建步骤。

Method: SpikeGrasp框架

Result: SpikeGrasp在复杂和无纹理场景中超越了传统的基于点云的基线，显示出显著的数据效率。

Conclusion: SpikeGrasp验证了端到端神经启发方法的可行性，为未来自然界高效流畅的人机交互系统奠定基础，特别是在处理动态物体时。

Abstract: Most robotic grasping systems rely on converting sensor data into explicit 3D
point clouds, which is a computational step not found in biological
intelligence. This paper explores a fundamentally different, neuro-inspired
paradigm for 6-DoF grasp detection. We introduce SpikeGrasp, a framework that
mimics the biological visuomotor pathway, processing raw, asynchronous events
from stereo spike cameras, similarly to retinas, to directly infer grasp poses.
Our model fuses these stereo spike streams and uses a recurrent spiking neural
network, analogous to high-level visual processing, to iteratively refine grasp
hypotheses without ever reconstructing a point cloud. To validate this
approach, we built a large-scale synthetic benchmark dataset. Experiments show
that SpikeGrasp surpasses traditional point-cloud-based baselines, especially
in cluttered and textureless scenes, and demonstrates remarkable data
efficiency. By establishing the viability of this end-to-end, neuro-inspired
approach, SpikeGrasp paves the way for future systems capable of the fluid and
efficient manipulation seen in nature, particularly for dynamic objects.

</details>


### [36] [High-Fidelity Simulated Data Generation for Real-World Zero-Shot Robotic Manipulation Learning with Gaussian Splatting](https://arxiv.org/abs/2510.10637)
*Haoyu Zhao,Cheng Zeng,Linghao Zhuang,Yaxi Zhao,Shengke Xue,Hao Wang,Xingyue Zhao,Zhongyu Li,Kehan Li,Siteng Huang,Mingxiu Chen,Xin Li,Deli Zhao,Hua Zou*

Main category: cs.RO

TL;DR: RoboSimGS是一种新的框架，通过将真实图像转换为高保真仿真环境，以帮助机器人操作的训练，实现了有效的模拟到现实的转移。


<details>
  <summary>Details</summary>
Motivation: 解决机器人学习中实际数据收集成本和劳动的瓶颈，同时克服模拟数据在现实世界中的泛化问题。

Method: RoboSimGS框架将多视角的现实世界图像转换为可扩展的高保真物理交互仿真环境。

Result: 使用RoboSimGS生成的数据使得在多种现实世界操作任务中实现成功的零-shot模拟到现实转移，并提升了现有最优方法的性能和泛化能力。

Conclusion: RoboSimGS被验证为弥合模拟与现实之间差距的强大且可扩展的解决方案。

Abstract: The scalability of robotic learning is fundamentally bottlenecked by the
significant cost and labor of real-world data collection. While simulated data
offers a scalable alternative, it often fails to generalize to the real world
due to significant gaps in visual appearance, physical properties, and object
interactions. To address this, we propose RoboSimGS, a novel Real2Sim2Real
framework that converts multi-view real-world images into scalable,
high-fidelity, and physically interactive simulation environments for robotic
manipulation. Our approach reconstructs scenes using a hybrid representation:
3D Gaussian Splatting (3DGS) captures the photorealistic appearance of the
environment, while mesh primitives for interactive objects ensure accurate
physics simulation. Crucially, we pioneer the use of a Multi-modal Large
Language Model (MLLM) to automate the creation of physically plausible,
articulated assets. The MLLM analyzes visual data to infer not only physical
properties (e.g., density, stiffness) but also complex kinematic structures
(e.g., hinges, sliding rails) of objects. We demonstrate that policies trained
entirely on data generated by RoboSimGS achieve successful zero-shot
sim-to-real transfer across a diverse set of real-world manipulation tasks.
Furthermore, data from RoboSimGS significantly enhances the performance and
generalization capabilities of SOTA methods. Our results validate RoboSimGS as
a powerful and scalable solution for bridging the sim-to-real gap.

</details>


### [37] [UniCoD: Enhancing Robot Policy via Unified Continuous and Discrete Representation Learning](https://arxiv.org/abs/2510.10642)
*Jianke Zhang,Yucheng Hu,Yanjiang Guo,Xiaoyu Chen,Yichen Liu,Wenna Chen,Chaochao Lu,Jianyu Chen*

Main category: cs.RO

TL;DR: 本研究提出了一种新的通用机器人策略学习框架UniCoD，利用大规模预训练数据从而提高机器人处理多样任务的能力。


<details>
  <summary>Details</summary>
Motivation: 考虑到视觉语言理解和视觉生成预训练的语义理解与视觉动态建模对机器人具有重要性，因此结合理解、规划和未来表示学习的优势是有必要的。

Method: UniCoD通过预训练于超过100万个互联网规模的操作视频来建模高维视觉特征，并在机器人具体化后进行微调，以学习预测表示和行动符号之间的映射。

Result: 实验表明，UniCoD在不同测试环境下的表现比基线方法提升了9%到12%。

Conclusion: UniCoD在模拟环境和现实世界的出区间任务中均优于基线方法，验证了其有效性。

Abstract: Building generalist robot policies that can handle diverse tasks in
open-ended environments is a central challenge in robotics. To leverage
knowledge from large-scale pretraining, prior work has typically built
generalist policies either on top of vision-language understanding models
(VLMs) or generative models. However, both semantic understanding from
vision-language pretraining and visual dynamics modeling from visual-generation
pretraining are crucial for embodied robots. Recent unified models of
generation and understanding have demonstrated strong capabilities in both
comprehension and generation through large-scale pretraining. We posit that
robotic policy learning can likewise benefit from the combined strengths of
understanding, planning and continuous future representation learning. Building
on this insight, we introduce UniCoD, which acquires the ability to dynamically
model high-dimensional visual features through pretraining on over 1M
internet-scale instructional manipulation videos. Subsequently, UniCoD is
fine-tuned on data collected from the robot embodiment, enabling the learning
of mappings from predictive representations to action tokens. Extensive
experiments show our approach consistently outperforms baseline methods in
terms of 9\% and 12\% across simulation environments and real-world
out-of-distribution tasks.

</details>


### [38] [Deployment and Development of a Cognitive Teleoreactive Framework for Deep Sea Autonomy](https://arxiv.org/abs/2510.10716)
*Christopher Thierauf*

Main category: cs.RO

TL;DR: DINOS-R 是一种新的 AUV 任务规划软件，它结合了符号决策与机器学习，旨在提供灵活的任务和行为规范，并已在实际和模拟案例中测试。


<details>
  <summary>Details</summary>
Motivation: 为了替代现有的 MC 架构，开发 DINOS-R 以统一符号决策与机器学习技术，从而提升 AUV 的现场执行能力和研究灵活性。

Method: 使用 Python3 开发，DINOS-R 设计为可扩展、模块化和可重用，支持非专家使用，且能够灵活指定任务和行为。

Result: DINOS-R 是一个新开发的 AUV 任务规划和执行软件，经过在 AUV Sentry 上的测试，旨在取代传统的 MC 架构。其主要特点是将符号决策与机器学习技术相结合，以实现海洋平台的现场应用能力。

Conclusion: DINOS-R 的测试结果表明，它在任务规划和执行方面表现出色，具备良好的灵活性和可扩展性，适用于未来的海洋研究和机器人算法。

Abstract: A new AUV mission planning and execution software has been tested on AUV
Sentry. Dubbed DINOS-R, it draws inspiration from cognitive architectures and
AUV control systems to replace the legacy MC architecture. Unlike these
existing architectures, however, DINOS-R is built from the ground-up to unify
symbolic decision making (for understandable, repeatable, provable behavior)
with machine learning techniques and reactive behaviors, for field-readiness
across oceanographic platforms. Implemented primarily in Python3, DINOS-R is
extensible, modular, and reusable, with an emphasis on non-expert use as well
as growth for future research in oceanography and robot algorithms. Mission
specification is flexible, and can be specified declaratively. Behavior
specification is similarly flexible, supporting simultaneous use of real-time
task planning and hard-coded user specified plans. These features were
demonstrated in the field on Sentry, in addition to a variety of simulated
cases. These results are discussed, and future work is outlined.

</details>


### [39] [Controllable Generative Trajectory Prediction via Weak Preference Alignment](https://arxiv.org/abs/2510.10731)
*Yongxi Cao,Julian F. Schumann,Jens Kober,Joni Pajarinen,Arkady Zgonnikov*

Main category: cs.RO

TL;DR: 提出了一种改进的条件变分自编码器（PrefCVAE），用于生成可控的多样化轨迹，提高自动驾驶车辆的安全规划能力。


<details>
  <summary>Details</summary>
Motivation: 在自动驾驶车辆规划中，除了准确性，轨迹的多样性同样重要，因此需要一种能够生成可控多样化轨迹的方法。

Method: 使用增强的条件变分自编码器框架，通过弱标记的偏好对潜在变量进行语义属性的赋值。

Result: PrefCVAE展示了偏好监督作为一种成本效益高的方式，显著增强采样生成模型的效果。

Conclusion: PrefCVAE利用弱标签的偏好对潜在变量进行语义属性赋予，展示了可控、语义有意义的预测效果，而不降低准确性。

Abstract: Deep generative models such as conditional variational autoencoders (CVAEs)
have shown great promise for predicting trajectories of surrounding agents in
autonomous vehicle planning. State-of-the-art models have achieved remarkable
accuracy in such prediction tasks. Besides accuracy, diversity is also crucial
for safe planning because human behaviors are inherently uncertain and
multimodal. However, existing methods generally lack a scheme to generate
controllably diverse trajectories, which is arguably more useful than randomly
diversified trajectories, to the end of safe planning. To address this, we
propose PrefCVAE, an augmented CVAE framework that uses weakly labeled
preference pairs to imbue latent variables with semantic attributes. Using
average velocity as an example attribute, we demonstrate that PrefCVAE enables
controllable, semantically meaningful predictions without degrading baseline
accuracy. Our results show the effectiveness of preference supervision as a
cost-effective way to enhance sampling-based generative models.

</details>


### [40] [Gain Tuning Is Not What You Need: Reward Gain Adaptation for Constrained Locomotion Learning](https://arxiv.org/abs/2510.10759)
*Arthicha Srisuchinnawong,Poramate Manoonpong*

Main category: cs.RO

TL;DR: 本研究提出了一种动态调整的奖励加权增益方案，显著提升了机器人学习性能与约束满足能力，简化了调节过程，适用于真实环境中的机器人学习。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人运动学习技术在训练过程中对奖励加权增益的离线选择依赖性强，且无法保证约束的满足，因此需要寻求改进方法。

Method: 通过在线调整奖励加权增益，依据机器人在交互过程中的惩罚，动态控制正奖励与负奖励的比率。

Result: ROGER在60千克的四足机器人上实现了近零的约束违反，相较于传统方法，其获得的正奖励提高了50%，并在MuJoCo基准测试中表现出最高可达100%的性能提升和60%的扭矩使用减少。

Conclusion: 本研究提出的ROGER方法在保证约束满足的前提下，提升了四足机器人学习的性能，并简化了奖励权重调节的过程，展示了其在真实世界应用中的潜力。

Abstract: Existing robot locomotion learning techniques rely heavily on the offline
selection of proper reward weighting gains and cannot guarantee constraint
satisfaction (i.e., constraint violation) during training. Thus, this work aims
to address both issues by proposing Reward-Oriented Gains via Embodied
Regulation (ROGER), which adapts reward-weighting gains online based on
penalties received throughout the embodied interaction process. The ratio
between the positive reward (primary reward) and negative reward (penalty)
gains is automatically reduced as the learning approaches the constraint
thresholds to avoid violation. Conversely, the ratio is increased when learning
is in safe states to prioritize performance. With a 60-kg quadruped robot,
ROGER achieved near-zero constraint violation throughout multiple learning
trials. It also achieved up to 50% more primary reward than the equivalent
state-of-the-art techniques. In MuJoCo continuous locomotion benchmarks,
including a single-leg hopper, ROGER exhibited comparable or up to 100% higher
performance and 60% less torque usage and orientation deviation compared to
those trained with the default reward function. Finally, real-world locomotion
learning of a physical quadruped robot was achieved from scratch within one
hour without any falls. Therefore, this work contributes to
constraint-satisfying real-world continual robot locomotion learning and
simplifies reward weighting gain tuning, potentially facilitating the
development of physical robots and those that learn in the real world.

</details>


### [41] [Real2USD: Scene Representations in Universal Scene Description Language](https://arxiv.org/abs/2510.10778)
*Christopher D. Hsu,Pratik Chaudhari*

Main category: cs.RO

TL;DR: 本文提出了一种基于Universal Scene Description (USD)语言的系统，旨在帮助机器人通过自然语言推理抽象任务规范。


<details>
  <summary>Details</summary>
Motivation: 不同的任务需要不同的环境表示，而USD作为一种通用表示，可以满足这些需求。

Method: 通过Real to USD系统，使用Unitree Go2四足机器人配备LiDAR和RGB摄像头构建室内环境的USD表示，并使用Google的Gemini解析USD。

Result: 成功构建了复杂的室内环境USD表示，并展示了场景理解、复杂推理和规划能力。

Conclusion: USD作为一种通用的场景表示方法，可以有效支持基于大型语言模型的机器人任务。

Abstract: Large Language Models (LLMs) can help robots reason about abstract task
specifications. This requires augmenting classical representations of the
environment used by robots with natural language-based priors. There are a
number of existing approaches to doing so, but they are tailored to specific
tasks, e.g., visual-language models for navigation, language-guided neural
radiance fields for mapping, etc. This paper argues that the Universal Scene
Description (USD) language is an effective and general representation of
geometric, photometric and semantic information in the environment for
LLM-based robotics tasks. Our argument is simple: a USD is an XML-based scene
graph, readable by LLMs and humans alike, and rich enough to support
essentially any task -- Pixar developed this language to store assets, scenes
and even movies. We demonstrate a ``Real to USD'' system using a Unitree Go2
quadruped robot carrying LiDAR and a RGB camera that (i) builds an explicit USD
representation of indoor environments with diverse objects and challenging
settings with lots of glass, and (ii) parses the USD using Google's Gemini to
demonstrate scene understanding, complex inferences, and planning. We also
study different aspects of this system in simulated warehouse and hospital
settings using Nvidia's Issac Sim. Code is available at
https://github.com/grasp-lyrl/Real2USD .

</details>


### [42] [Two-Layer Voronoi Coverage Control for Hybrid Aerial-Ground Robot Teams in Emergency Response: Implementation and Analysis](https://arxiv.org/abs/2510.10781)
*Douglas Hutchings,Luai Abuelsamen,Karthik Rajgopal*

Main category: cs.RO

TL;DR: 本文提出了一种新型的两层Voronoi覆盖控制方法，有效提高了空中和地面机器人在危险物质应急响应中的协调能力。


<details>
  <summary>Details</summary>
Motivation: 解决传统Voronoi覆盖控制方法在紧急情况下面临的三大限制：异构代理能力、聚集部署配置，以及紧迫的时间要求。

Method: 使用解耦的两层架构，分别优化空中和地面机器人的位置，通过空投将地面传感器送至高优先级位置。

Result: 提出了一种全面的两层Voronoi覆盖控制方法，用于协调混合空中-地面机器人团队在危险物质应急响应中的应用。

Conclusion: 通过改进的Voronoi控制策略，显著提升了应急响应的效率，实现在25秒内达成目标传感器覆盖。

Abstract: We present a comprehensive two-layer Voronoi coverage control approach for
coordinating hybrid aerial-ground robot teams in hazardous material emergency
response scenarios. Traditional Voronoi coverage control methods face three
critical limitations in emergency contexts: heterogeneous agent capabilities
with vastly different velocities, clustered initial deployment configurations,
and urgent time constraints requiring rapid response rather than eventual
convergence. Our method addresses these challenges through a decoupled
two-layer architecture that separately optimizes aerial and ground robot
positioning, with aerial agents delivering ground sensors via airdrop to
high-priority locations. We provide detailed implementation of bounded Voronoi
cell computation, efficient numerical integration techniques for
importance-weighted centroids, and robust control strategies that prevent agent
trapping. Simulation results demonstrate an 88% reduction in response time,
achieving target sensor coverage (18.5% of initial sensor loss) in 25 seconds
compared to 220 seconds for ground-only deployment. Complete implementation
code is available at https://github.com/dHutchings/ME292B.

</details>


### [43] [Representing Data in Robotic Tactile Perception -- A Review](https://arxiv.org/abs/2510.10804)
*Alessandro Albini,Mohsen Kaboli,Giorgio Cannata,Perla Maiolino*

Main category: cs.RO

TL;DR: 本文探讨机器人触觉感知中的数据表示问题，分析各种硬件与表示方式的关系。


<details>
  <summary>Details</summary>
Motivation: 提升机器人的触觉感知能力，优化数据表示以提高任务执行效果。

Method: 通过综述以往研究，识别触觉信息表示的六种常用结构，并分析它们与硬件和高层计算方法的关系。

Result: 确定了六种常用的数据表示结构，并提供了选择时的指导建议。

Conclusion: 本文提出了合理选择数据表示方法的讨论和指导，这对于提高触觉感知和任务执行的有效性至关重要。

Abstract: Robotic tactile perception is a complex process involving several
computational steps performed at different levels. Tactile information is
shaped by the interplay of robot actions, the mechanical properties of its
body, and the software that processes the data. In this respect, high-level
computation, required to process and extract information, is commonly performed
by adapting existing techniques from other domains, such as computer vision,
which expects input data to be properly structured. Therefore, it is necessary
to transform tactile sensor data to match a specific data structure. This
operation directly affects the tactile information encoded and, as a
consequence, the task execution. This survey aims to address this specific
aspect of the tactile perception pipeline, namely Data Representation. The
paper first clearly defines its contributions to the perception pipeline and
then reviews how previous studies have dealt with the problem of representing
tactile information, investigating the relationships among hardware,
representations, and high-level computation methods. The analysis has led to
the identification of six structures commonly used in the literature to
represent data. The manuscript provides discussions and guidelines for properly
selecting a representation depending on operating conditions, including the
available hardware, the tactile information required to be encoded, and the
task at hand.

</details>


### [44] [Contact Sensing via Joint Torque Sensors and a Force/Torque Sensor for Legged Robots](https://arxiv.org/abs/2510.10843)
*Jared Grinberg,Yanran Ding*

Main category: cs.RO

TL;DR: 本研究提出了一种新的机器人腿部接触检测和定位的方法，利用关节扭矩传感器和力-扭矩传感器，达到高精度的接触力和位置测量。


<details>
  <summary>Details</summary>
Motivation: 提出一种低成本的基于应变计的关节扭矩传感器，能够直接测量扭矩，避免使用复杂的摩擦模型，提供比基于电机电流估算更准确的扭矩读数。

Method: 使用分布式关节扭矩传感器和单个臀部安装的力-扭矩传感器检测和定位机器人腿部接触，采用广义动量观测器框架。

Result: 在浮动式二维关节机器人腿的仿真研究中，验证了该框架能准确恢复大腿和小腿链接的接触力和位置；经过标定程序后，扭矩传感器相对于真实测量值达到了96.4%的平均准确度；在二维操纵器上的硬件实验显示，接触定位精度在亚厘米级，力误差低于0.2 N。

Conclusion: 所提出的基于扭矩传感器的方法显著提高了机器人腿部的接触力和位置感知精度。

Abstract: This paper presents a method for detecting and localizing contact along robot
legs using distributed joint torque sensors and a single hip-mounted
force-torque (FT) sensor using a generalized momentum-based observer framework.
We designed a low-cost strain-gauge-based joint torque sensor that can be
installed on every joint to provide direct torque measurements, eliminating the
need for complex friction models and providing more accurate torque readings
than estimation based on motor current. Simulation studies on a floating-based
2-DoF robot leg verified that the proposed framework accurately recovers
contact force and location along the thigh and shin links. Through a
calibration procedure, our torque sensor achieved an average 96.4% accuracy
relative to ground truth measurements. Building upon the torque sensor, we
performed hardware experiments on a 2-DoF manipulator, which showed
sub-centimeter contact localization accuracy and force errors below 0.2 N.

</details>


### [45] [Preference-Conditioned Multi-Objective RL for Integrated Command Tracking and Force Compliance in Humanoid Locomotion](https://arxiv.org/abs/2510.10851)
*Tingxuan Leng,Yushi Wang,Tinglong Zheng,Changsheng Luo,Mingguo Zhao*

Main category: cs.RO

TL;DR: 本文提出了一个平衡命令跟踪和外部力顺应性的人形机器人行走多目标优化框架。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习方法主要强调鲁棒性，缺乏对外部力量的顺应性，因此需要一个新的方法来平衡这些目标。

Method: 通过将人形 locomotion 形式化为一个多目标优化问题，引入偏好条件的多目标强化学习框架，利用编码-解码结构进行训练。

Result: 本文提出了一种新的多目标强化学习框架，以改进人形机器人在行走时对外部力量的响应能力。

Conclusion: 验证结果表明，该框架在适应性和收敛性方面优于标准方法，实现了可部署的偏好条件化人形 locomotion。

Abstract: Humanoid locomotion requires not only accurate command tracking for
navigation but also compliant responses to external forces during human
interaction. Despite significant progress, existing RL approaches mainly
emphasize robustness, yielding policies that resist external forces but lack
compliance-particularly challenging for inherently unstable humanoids. In this
work, we address this by formulating humanoid locomotion as a multi-objective
optimization problem that balances command tracking and external force
compliance. We introduce a preference-conditioned multi-objective RL (MORL)
framework that integrates rigid command following and compliant behaviors
within a single omnidirectional locomotion policy. External forces are modeled
via velocity-resistance factor for consistent reward design, and training
leverages an encoder-decoder structure that infers task-relevant privileged
features from deployable observations. We validate our approach in both
simulation and real-world experiments on a humanoid robot. Experimental results
indicate that our framework not only improves adaptability and convergence over
standard pipelines, but also realizes deployable preference-conditioned
humanoid locomotion.

</details>


### [46] [GRIP: A Unified Framework for Grid-Based Relay and Co-Occurrence-Aware Planning in Dynamic Environments](https://arxiv.org/abs/2510.10865)
*Ahmed Alanazi,Duy Ho,Yugyung Lee*

Main category: cs.RO

TL;DR: GRIP是一个模块化的机器人导航框架，通过融合感知和符号推理，显著提高了在复杂环境中的导航能力。


<details>
  <summary>Details</summary>
Motivation: 机器人在动态、杂乱和语义复杂的环境中导航，必须整合感知、符号推理和空间规划，以便在多样化的布局和物体类别中进行推广。

Method: 提出了GRIP（基于网格的中介规划），该框架有三种可扩展的变体，结合了动态2D网格构建、开放词汇物体定位、共现意识的符号规划和混合政策执行。

Result: 实验结果证明，GRIP在AI2-THOR和RoboTHOR基准测试中实现了高达9.6%的成功率提升，并在长时间任务中路径效率提高超过两倍。

Conclusion: GRIP是一个强大的、可扩展的和可解释的框架，能够有效地在模拟和现实世界的导航任务中工作。

Abstract: Robots navigating dynamic, cluttered, and semantically complex environments
must integrate perception, symbolic reasoning, and spatial planning to
generalize across diverse layouts and object categories. Existing methods often
rely on static priors or limited memory, constraining adaptability under
partial observability and semantic ambiguity. We present GRIP, Grid-based Relay
with Intermediate Planning, a unified, modular framework with three scalable
variants: GRIP-L (Lightweight), optimized for symbolic navigation via semantic
occupancy grids; GRIP-F (Full), supporting multi-hop anchor chaining and
LLM-based introspection; and GRIP-R (Real-World), enabling physical robot
deployment under perceptual uncertainty. GRIP integrates dynamic 2D grid
construction, open-vocabulary object grounding, co-occurrence-aware symbolic
planning, and hybrid policy execution using behavioral cloning, D* search, and
grid-conditioned control. Empirical results on AI2-THOR and RoboTHOR benchmarks
show that GRIP achieves up to 9.6% higher success rates and over $2\times$
improvement in path efficiency (SPL and SAE) on long-horizon tasks. Qualitative
analyses reveal interpretable symbolic plans in ambiguous scenes. Real-world
deployment on a Jetbot further validates GRIP's generalization under sensor
noise and environmental variation. These results position GRIP as a robust,
scalable, and explainable framework bridging simulation and real-world
navigation.

</details>


### [47] [QuayPoints: A Reasoning Framework to Bridge the Information Gap Between Global and Local Planning in Autonomous Racing](https://arxiv.org/abs/2510.10886)
*Yashom Dighe,Youngjin Kim,Karthik Dantu*

Main category: cs.RO

TL;DR: 本论文提出一种通过QuayPoints提升局部规划器决策能力的方法，以改善自动赛车中的超车表现。


<details>
  <summary>Details</summary>
Motivation: 提高自动赛车中的决策效率，减少标准自治管道中信息丢失的问题，以便在复杂场景中优化决策过程。

Method: 将QuayPoints整合到现有的规划系统中，通过提供时间最优性信息来增强局部规划能力。

Result: 通过四个不同的赛道实验证明，集成QuayPoints后的规划器能够在速度达到自车75%的情况下持续实现超车。

Conclusion: 引入QuayPoints可以帮助局部规划器在偏离最佳赛车路径时做出更明智的决策，从而实现更有效的超车。

Abstract: Autonomous racing requires tight integration between perception, planning and
control to minimize latency as well as timely decision making. A standard
autonomy pipeline comprising a global planner, local planner, and controller
loses information as the higher-level racing context is sequentially propagated
downstream into specific task-oriented context. In particular, the global
planner's understanding of optimality is typically reduced to a sparse set of
waypoints, leaving the local planner to make reactive decisions with limited
context. This paper investigates whether additional global insights,
specifically time-optimality information, can be meaningfully passed to the
local planner to improve downstream decisions. We introduce a framework that
preserves essential global knowledge and conveys it to the local planner
through QuayPoints regions where deviations from the optimal raceline result in
significant compromises to optimality. QuayPoints enable local planners to make
more informed global decisions when deviating from the raceline, such as during
strategic overtaking. To demonstrate this, we integrate QuayPoints into an
existing planner and show that it consistently overtakes opponents traveling at
up to 75% of the ego vehicle's speed across four distinct race tracks.

</details>


### [48] [An Adaptive Transition Framework for Game-Theoretic Based Takeover](https://arxiv.org/abs/2510.10893)
*Dikshant Shehmar,Matthew E. Taylor,Ehsan Hashemi*

Main category: cs.RO

TL;DR: 本文提出了一种自适应控制权转移策略，动态根据司机表现调整控制权，从而改善自动驾驶系统中的驾驶者响应效果。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统中的控制转移至关重要，尤其是在司机准备不足的情况下，这会加大反应时间。目前的接管策略主要基于固定的时间段，无法有效适应实时的驾驶表现变化。

Method: 通过建模共享控制为一个合作微分博弈，利用时间变化的目标函数调控控制权，并引入司机特定的状态跟踪矩阵。

Result: 提出了一种自适应转移策略，通过时间和司机轨迹跟踪能力动态调整控制权，使用了一种合作微分博弈模型，以确保更自然的接管。

Conclusion: 通过比较多种转移策略，结果表明自适应转移在减少轨迹偏差和驾驶者控制努力方面优于传统策略，并增强了接管过程中的车辆稳定性。

Abstract: The transition of control from autonomous systems to human drivers is
critical in automated driving systems, particularly due to the out-of-the-loop
(OOTL) circumstances that reduce driver readiness and increase reaction times.
Existing takeover strategies are based on fixed time-based transitions, which
fail to account for real-time driver performance variations. This paper
proposes an adaptive transition strategy that dynamically adjusts the control
authority based on both the time and tracking ability of the driver trajectory.
Shared control is modeled as a cooperative differential game, where control
authority is modulated through time-varying objective functions instead of
blending control torques directly. To ensure a more natural takeover, a
driver-specific state-tracking matrix is introduced, allowing the transition to
align with individual control preferences. Multiple transition strategies are
evaluated using a cumulative trajectory error metric. Human-in-the-loop control
scenarios of the standardized ISO lane change maneuvers demonstrate that
adaptive transitions reduce trajectory deviations and driver control effort
compared to conventional strategies. Experiments also confirm that continuously
adjusting control authority based on real-time deviations enhances vehicle
stability while reducing driver effort during takeover.

</details>


### [49] [Towards a Unified Understanding of Robot Manipulation: A Comprehensive Survey](https://arxiv.org/abs/2510.10903)
*Shuanghao Bai,Wenxuan Song,Jiayi Chen,Yuheng Ji,Zhide Zhong,Jin Yang,Han Zhao,Wanqi Zhou,Wei Zhao,Zhe Li,Pengxiang Ding,Cheng Chi,Haoang Li,Chang Xu,Xiaolong Zheng,Donglin Wang,Shanghang Zhang,Badong Chen*

Main category: cs.RO

TL;DR: 本文综述了机器人操作的现状，提出了一种新的分类法，并讨论了关键瓶颈以及实际应用。


<details>
  <summary>Details</summary>
Motivation: 由于机器人操作在多模态系统中扮演着重要角色，提出更为细致的分类及瓶颈分析是为了推动该领域的进步。

Method: 通过扩展传统的高层规划与低层控制的划分，提出综合考虑语言、代码、动作、可及性及3D表示的高层规划，以及基于不同训练范式的低层学习控制的新分类。

Result: 这篇论文的综述展示了机器人操作的全面背景，包括基础知识、任务组织的基准和数据集，以及现有方法的统一分类。

Conclusion: 论文为新手提供了入门指南，也为资深研究者提供了结构化参考。

Abstract: Embodied intelligence has witnessed remarkable progress in recent years,
driven by advances in computer vision, natural language processing, and the
rise of large-scale multimodal models. Among its core challenges, robot
manipulation stands out as a fundamental yet intricate problem, requiring the
seamless integration of perception, planning, and control to enable interaction
within diverse and unstructured environments. This survey presents a
comprehensive overview of robotic manipulation, encompassing foundational
background, task-organized benchmarks and datasets, and a unified taxonomy of
existing methods. We extend the classical division between high-level planning
and low-level control by broadening high-level planning to include language,
code, motion, affordance, and 3D representations, while introducing a new
taxonomy of low-level learning-based control grounded in training paradigms
such as input modeling, latent learning, and policy learning. Furthermore, we
provide the first dedicated taxonomy of key bottlenecks, focusing on data
collection, utilization, and generalization, and conclude with an extensive
review of real-world applications. Compared with prior surveys, our work offers
both a broader scope and deeper insight, serving as an accessible roadmap for
newcomers and a structured reference for experienced researchers. All related
resources, including research papers, open-source datasets, and projects, are
curated for the community at
https://github.com/BaiShuanghao/Awesome-Robotics-Manipulation.

</details>


### [50] [More than A Point: Capturing Uncertainty with Adaptive Affordance Heatmaps for Spatial Grounding in Robotic Tasks](https://arxiv.org/abs/2510.10912)
*Xinyu Shao,Yanzhe Tang,Pengwei Xie,Kaiwen Zhou,Yuzheng Zhuang,Xingyue Quan,Jianye Hao,Long Zeng,Xiu Li*

Main category: cs.RO

TL;DR: RoboMAP框架通过将空间目标表示为连续的自适应可供性热图，解决了语言引导机器人系统在空间推理中面临的脆弱性问题。


<details>
  <summary>Details</summary>
Motivation: 解决机器人系统在处理空间推理时因离散化处理带来的感知噪声和语义模糊问题。

Method: RoboMAP框架将空间目标表示为连续、适应性强的可供性热图，捕捉空间定位中的不确定性。

Result: RoboMAP在大多数基准测试中超过了现有技术，以最高50倍的速度提升，展示了强大的零样本泛化能力。

Conclusion: RoboMAP显著提高了任务成功率和可解释性，在真实世界操作中取得82%的成功率，并在多个基准测试中超越了现有技术。

Abstract: Many language-guided robotic systems rely on collapsing spatial reasoning
into discrete points, making them brittle to perceptual noise and semantic
ambiguity. To address this challenge, we propose RoboMAP, a framework that
represents spatial targets as continuous, adaptive affordance heatmaps. This
dense representation captures the uncertainty in spatial grounding and provides
richer information for downstream policies, thereby significantly enhancing
task success and interpretability. RoboMAP surpasses the previous
state-of-the-art on a majority of grounding benchmarks with up to a 50x speed
improvement, and achieves an 82\% success rate in real-world manipulation.
Across extensive simulated and physical experiments, it demonstrates robust
performance and shows strong zero-shot generalization to navigation. More
details and videos can be found at https://robo-map.github.io.

</details>


### [51] [Game-Theoretic Risk-Shaped Reinforcement Learning for Safe Autonomous Driving](https://arxiv.org/abs/2510.10960)
*Dong Hu,Fenqing Hu,Lidong Yang,Chao Huang*

Main category: cs.RO

TL;DR: 提出了一种新颖的博弈论风险形状强化学习框架（GTR2L），用于提高自动驾驶的安全性，特别是在复杂的交通环境中。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习方法在安全性、效率和适应性方面存在不足，特别是在动态复杂的交通环境中难以平衡风险和奖励。

Method: GTR2L结合多层次博弈论世界模型，动态预测周围车辆的互动行为及其风险，并采用不确定性感知障碍机制和风险建模方法。

Result: GTR2L在多种安全关键的交通场景中，成功率提高，碰撞和违规事件减少，驾驶效率显著提升。

Conclusion: 通过GTR2L框架，自动驾驶在成功率、碰撞和违规减少、驾驶效率方面明显优于现有基线，包括人类驾驶员。

Abstract: Ensuring safety in autonomous driving (AD) remains a significant challenge,
especially in highly dynamic and complex traffic environments where diverse
agents interact and unexpected hazards frequently emerge. Traditional
reinforcement learning (RL) methods often struggle to balance safety,
efficiency, and adaptability, as they primarily focus on reward maximization
without explicitly modeling risk or safety constraints. To address these
limitations, this study proposes a novel game-theoretic risk-shaped RL (GTR2L)
framework for safe AD. GTR2L incorporates a multi-level game-theoretic world
model that jointly predicts the interactive behaviors of surrounding vehicles
and their associated risks, along with an adaptive rollout horizon that adjusts
dynamically based on predictive uncertainty. Furthermore, an uncertainty-aware
barrier mechanism enables flexible modulation of safety boundaries. A dedicated
risk modeling approach is also proposed, explicitly capturing both epistemic
and aleatoric uncertainty to guide constrained policy optimization and enhance
decision-making in complex environments. Extensive evaluations across diverse
and safety-critical traffic scenarios show that GTR2L significantly outperforms
state-of-the-art baselines, including human drivers, in terms of success rate,
collision and violation reduction, and driving efficiency. The code is
available at https://github.com/DanielHu197/GTR2L.

</details>


### [52] [RoVer: Robot Reward Model as Test-Time Verifier for Vision-Language-Action Model](https://arxiv.org/abs/2510.10975)
*Mingtong Dai,Lingbo Liu,Yongjie Bai,Yang Liu,Zhouxia Wang,Rui SU,Chunjie Chen,Liang Lin,Xinyu Wu*

Main category: cs.RO

TL;DR: RoVer是一个提升VLA模型性能的框架，通过测试时扩展和过程奖励模型，实现更优的动作决策，无需额外训练。


<details>
  <summary>Details</summary>
Motivation: 当前的VLA模型在性能提升上受限于数据和模型的规模，RoVer旨在通过优化测试阶段的动作决策，避免高昂的训练成本和数据收集的限制。

Method: RoVer采用了机器人过程奖励模型（PRM）来给候选动作分配过程奖励，并预测动作空间方向，从而帮助扩展和选择最优行为。

Result: 提出了一种新的框架RoVer，旨在提升Vision-Language-Action（VLA）模型的性能，而无需增加训练数据和模型规模。此框架通过引入机器人过程奖模型（PRM），在测试阶段为VLA模型提供支持，从而改进动作决策过程，优化行动选择，而无须修改模型架构或权重。

Conclusion: RoVer有效地提升了现有VLA模型的决策能力，表明在不增加训练成本的前提下，通过优化测试阶段的资源利用，可以实现更好的行动推荐。

Abstract: Vision-Language-Action (VLA) models have become a prominent paradigm for
embodied intelligence, yet further performance improvements typically rely on
scaling up training data and model size -- an approach that is prohibitively
expensive for robotics and fundamentally limited by data collection costs.We
address this limitation with $\mathbf{RoVer}$, an embodied test-time scaling
framework that uses a $\mathbf{Ro}$bot Process Reward Model (PRM) as a
Test-Time $\mathbf{Ver}$ifier to enhance the capabilities of existing VLA
models without modifying their architectures or weights. Specifically, RoVer
(i) assigns scalar-based process rewards to evaluate the reliability of
candidate actions, and (ii) predicts an action-space direction for candidate
expansion/refinement. During inference, RoVer generates multiple candidate
actions concurrently from the base policy, expands them along PRM-predicted
directions, and then scores all candidates with PRM to select the optimal
action for execution. Notably, by caching shared perception features, it can
amortize perception cost and evaluate more candidates under the same test-time
computational budget. Essentially, our approach effectively transforms
available computing resources into better action decision-making, realizing the
benefits of test-time scaling without extra training overhead. Our
contributions are threefold: (1) a general, plug-and-play test-time scaling
framework for VLAs; (2) a PRM that jointly provides scalar process rewards and
an action-space direction to guide exploration; and (3) an efficient
direction-guided sampling strategy that leverages a shared perception cache to
enable scalable candidate generation and selection during inference.

</details>


### [53] [AMO-HEAD: Adaptive MARG-Only Heading Estimation for UAVs under Magnetic Disturbances](https://arxiv.org/abs/2510.10979)
*Qizhi Guo,Siyuan Yang,Junning Lyu,Jianjun Sun,Defu Lin,Shaoming He*

Main category: cs.RO

TL;DR: 本研究提出了一种适用于强磁干扰环境的AMO-HEAD航向估计方法，具有高效性和准确性，经过实验验证显示出良好的性能。


<details>
  <summary>Details</summary>
Motivation: 在复杂的室内环境中，无人机的航向估计准确性受到严重的磁干扰影响，因此需要一种可靠的解决方案来提升航向估计的准确性。

Method: 基于扩展卡尔曼滤波框架，引入加速度计和磁力计数据，通过自适应过程噪声协方差方法进行补偿，并利用实时磁偏差检测来减轻外部磁干扰的影响。

Result: 经过大量实验验证，该算法能够在磁干扰条件下提供精确的航向估计。

Conclusion: 提出的AMO-HEAD方法在磁干扰环境中能够有效提供准确的航向估计。

Abstract: Accurate and robust heading estimation is crucial for unmanned aerial
vehicles (UAVs) when conducting indoor inspection tasks. However, the cluttered
nature of indoor environments often introduces severe magnetic disturbances,
which can significantly degrade heading accuracy. To address this challenge,
this paper presents an Adaptive MARG-Only Heading (AMO-HEAD) estimation
approach for UAVs operating in magnetically disturbed environments. AMO-HEAD is
a lightweight and computationally efficient Extended Kalman Filter (EKF)
framework that leverages inertial and magnetic sensors to achieve reliable
heading estimation. In the proposed approach, gyroscope angular rate
measurements are integrated to propagate the quaternion state, which is
subsequently corrected using accelerometer and magnetometer data. The corrected
quaternion is then used to compute the UAV's heading. An adaptive process noise
covariance method is introduced to model and compensate for gyroscope
measurement noise, bias drift, and discretization errors arising from the Euler
method integration. To mitigate the effects of external magnetic disturbances,
a scaling factor is applied based on real-time magnetic deviation detection. A
theoretical observability analysis of the proposed AMO-HEAD is performed using
the Lie derivative. Extensive experiments were conducted in real world indoor
environments with customized UAV platforms. The results demonstrate the
effectiveness of the proposed algorithm in providing precise heading estimation
under magnetically disturbed conditions.

</details>


### [54] [Into the Unknown: Towards using Generative Models for Sampling Priors of Environment Uncertainty for Planning in Configuration Spaces](https://arxiv.org/abs/2510.11014)
*Subhransu S. Bhattacharjee,Hao Lu,Dylan Campbell,Rahul Shome*

Main category: cs.RO

TL;DR: 本研究提出一种新方法，通过预训练生成模型在部分观察条件下生成能帮助机器人规划的概率先验。


<details>
  <summary>Details</summary>
Motivation: 在部分可观察性下进行规划时，先验知识至关重要，但实际上难以获得。

Method: 利用预训练的生成模型，根据部分观察结果恢复完整的RGB-D点云样本，形成直接可用于配置空间规划的先验知识。

Result: 提出了一种基于采样的管道，利用大规模预训练生成模型产生捕捉环境不确定性和时空语义关系的概率先验。

Conclusion: 实验表明，该方法生成的3D点云在运动规划中有效，展示了生成模型作为机器人规划先验的潜力。

Abstract: Priors are vital for planning under partial observability, yet difficult to
obtain in practice. We present a sampling-based pipeline that leverages
large-scale pretrained generative models to produce probabilistic priors
capturing environmental uncertainty and spatio-semantic relationships in a
zero-shot manner. Conditioned on partial observations, the pipeline recovers
complete RGB-D point cloud samples with occupancy and target semantics,
formulated to be directly useful in configuration-space planning. We establish
a Matterport3D benchmark of rooms partially visible through doorways, where a
robot must navigate to an unobserved target object. Effective priors for this
setting must represent both occupancy and target-location uncertainty in
unobserved regions. Experiments show that our approach recovers commonsense
spatial semantics consistent with ground truth, yielding diverse, clean 3D
point clouds usable in motion planning, highlight the promise of generative
models as a rich source of priors for robotic planning.

</details>


### [55] [Refinery: Active Fine-tuning and Deployment-time Optimization for Contact-Rich Policies](https://arxiv.org/abs/2510.11019)
*Bingjie Tang,Iretiayo Akinola,Jie Xu,Bowen Wen,Dieter Fox,Gaurav S. Sukhatme,Fabio Ramos,Abhishek Gupta,Yashraj Narang*

Main category: cs.RO

TL;DR: 本论文提出的Refinery框架有效缩小了模拟学习与工业标准之间的性能差距，提高了装配任务的成功率。


<details>
  <summary>Details</summary>
Motivation: 现有的基于模拟的学习策略在多样化初始条件下表现不稳定，难以满足行业标准。

Method: 通过贝叶斯优化引导的微调和高斯混合模型采样来选择初始状态。

Result: Refinery提升了成功率10.98%，在模拟中达到了91.51%的成功率，且在真实场景中表现相当。

Conclusion: Refinery框架显著提高了机器人装配的成功率，并支持长时间、多部分的装配任务。

Abstract: Simulation-based learning has enabled policies for precise, contact-rich
tasks (e.g., robotic assembly) to reach high success rates (~80%) under high
levels of observation noise and control error. Although such performance may be
sufficient for research applications, it falls short of industry standards and
makes policy chaining exceptionally brittle. A key limitation is the high
variance in individual policy performance across diverse initial conditions. We
introduce Refinery, an effective framework that bridges this performance gap,
robustifying policy performance across initial conditions. We propose Bayesian
Optimization-guided fine-tuning to improve individual policies, and Gaussian
Mixture Model-based sampling during deployment to select initializations that
maximize execution success. Using Refinery, we improve mean success rates by
10.98% over state-of-the-art methods in simulation-based learning for robotic
assembly, reaching 91.51% in simulation and comparable performance in the real
world. Furthermore, we demonstrate that these fine-tuned policies can be
chained to accomplish long-horizon, multi-part
assembly$\unicode{x2013}$successfully assembling up to 8 parts without
requiring explicit multi-step training.

</details>


### [56] [XGrasp: Gripper-Aware Grasp Detection with Multi-Gripper Data Generation](https://arxiv.org/abs/2510.11036)
*Yeonseo Lee,Jungwook Mun,Hyosup Shin,Guebin Hwang,Junhee Nam,Taeyeop Lee,Sungho Jo*

Main category: cs.RO

TL;DR: XGrasp框架解决了多种抓取器配置的实时检测问题，并实现了数据的系统性增强。


<details>
  <summary>Details</summary>
Motivation: 目前多数抓取方法仅针对单一抓取器，限制了其在需要多样化末端执行器的实际场景中的适用性。

Method: XGrasp采用了分层的两阶段架构：第一阶段的抓取点预测器（GPP）基于全球场景信息和抓取器规格识别最佳位置；第二阶段的角度宽度预测器（AWP）使用局部特征细化抓取的角度和宽度。

Result: XGrasp是一种实时的抓取检测框架，能够高效处理多种抓取配置。

Conclusion: 实验结果表明，XGrasp在不同抓取器类型中表现出竞争力的抓取成功率，并在推理速度上相较于现有方法有显著提升。

Abstract: Most robotic grasping methods are typically designed for single gripper
types, which limits their applicability in real-world scenarios requiring
diverse end-effectors. We propose XGrasp, a real-time gripper-aware grasp
detection framework that efficiently handles multiple gripper configurations.
The proposed method addresses data scarcity by systematically augmenting
existing datasets with multi-gripper annotations. XGrasp employs a hierarchical
two-stage architecture. In the first stage, a Grasp Point Predictor (GPP)
identifies optimal locations using global scene information and gripper
specifications. In the second stage, an Angle-Width Predictor (AWP) refines the
grasp angle and width using local features. Contrastive learning in the AWP
module enables zero-shot generalization to unseen grippers by learning
fundamental grasping characteristics. The modular framework integrates
seamlessly with vision foundation models, providing pathways for future
vision-language capabilities. The experimental results demonstrate competitive
grasp success rates across various gripper types, while achieving substantial
improvements in inference speed compared to existing gripper-aware methods.
Project page: https://sites.google.com/view/xgrasp

</details>


### [57] [Unveiling Uncertainty-Aware Autonomous Cooperative Learning Based Planning Strategy](https://arxiv.org/abs/2510.11041)
*Shiyao Zhang,Liwei Deng,Shuyu Zhang,Weijie Yuan,Hong Zhang*

Main category: cs.RO

TL;DR: 提出了一种基于深度强化学习的自适应合作规划框架，以有效应对多车辆交互中的不确定性，并在多个场景中表现优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 提高多车辆交互的有效性和安全性，解决现有ACP策略中的多种不确定性。

Method: 深度强化学习（DRL）和软演员评论者（SAC），结合门控递归单元（GRUs）。

Result: 提出的DRLACP框架在面对各种不确定性时，能够有效学习和执行合作规划，表现优于其他基线方法。

Conclusion: DRLACP框架能够有效应对规划、通信和感知不确定性，实现高效的合作交通规划。

Abstract: In future intelligent transportation systems, autonomous cooperative planning
(ACP), becomes a promising technique to increase the effectiveness and security
of multi-vehicle interactions. However, multiple uncertainties cannot be fully
addressed for existing ACP strategies, e.g. perception, planning, and
communication uncertainties. To address these, a novel deep reinforcement
learning-based autonomous cooperative planning (DRLACP) framework is proposed
to tackle various uncertainties on cooperative motion planning schemes.
Specifically, the soft actor-critic (SAC) with the implementation of gate
recurrent units (GRUs) is adopted to learn the deterministic optimal
time-varying actions with imperfect state information occurred by planning,
communication, and perception uncertainties. In addition, the real-time actions
of autonomous vehicles (AVs) are demonstrated via the Car Learning to Act
(CARLA) simulation platform. Evaluation results show that the proposed DRLACP
learns and performs cooperative planning effectively, which outperforms other
baseline methods under different scenarios with imperfect AV state information.

</details>


### [58] [PhysHSI: Towards a Real-World Generalizable and Natural Humanoid-Scene Interaction System](https://arxiv.org/abs/2510.11072)
*Huayi Wang,Wentao Zhang,Runyi Yu,Tao Huang,Junli Ren,Feiyu Jia,Zirui Wang,Xiaojie Niu,Xiao Chen,Jiahe Chen,Qifeng Chen,Jingbo Wang,Jiangmiao Pang*

Main category: cs.RO

TL;DR: 本研究提出了一种名为PhysHSI的系统，使类人机器人能够在真实环境中执行互动任务，具备自然的行为和强大的场景感知能力。


<details>
  <summary>Details</summary>
Motivation: 为了解决类人机器人在真实环境中互动时运动自然性和场景感知的挑战。

Method: 采用对抗性运动先验的策略学习进行模拟训练，并引入粗到细的物体定位模块结合LiDAR和相机输入进行场景感知。

Result: PhysHSI在四个代表性的互动任务中取得了高成功率和强通用性。

Conclusion: PhysHSI在模拟和实际环境中对四项互动任务的成功率和自然运动模式表现出色，验证了其有效性和通用性。

Abstract: Deploying humanoid robots to interact with real-world environments--such as
carrying objects or sitting on chairs--requires generalizable, lifelike motions
and robust scene perception. Although prior approaches have advanced each
capability individually, combining them in a unified system is still an ongoing
challenge. In this work, we present a physical-world humanoid-scene interaction
system, PhysHSI, that enables humanoids to autonomously perform diverse
interaction tasks while maintaining natural and lifelike behaviors. PhysHSI
comprises a simulation training pipeline and a real-world deployment system. In
simulation, we adopt adversarial motion prior-based policy learning to imitate
natural humanoid-scene interaction data across diverse scenarios, achieving
both generalization and lifelike behaviors. For real-world deployment, we
introduce a coarse-to-fine object localization module that combines LiDAR and
camera inputs to provide continuous and robust scene perception. We validate
PhysHSI on four representative interactive tasks--box carrying, sitting, lying,
and standing up--in both simulation and real-world settings, demonstrating
consistently high success rates, strong generalization across diverse task
goals, and natural motion patterns.

</details>


### [59] [Flow Matching-Based Autonomous Driving Planning with Advanced Interactive Behavior Modeling](https://arxiv.org/abs/2510.11083)
*Tianyi Tan,Yinan Zheng,Ruiming Liang,Zexu Wang,Kexin Zheng,Jinliang Zheng,Jianxiong Li,Xianyuan Zhan,Jingjing Liu*

Main category: cs.RO

TL;DR: Flow Planner通过创新的数据建模、模型架构和学习方案，提升了复杂驾驶场景中交互行为的建模能力。


<details>
  <summary>Details</summary>
Motivation: 弥补现有学习方法在复杂场景中对交互行为建模能力的不足，并应对交互驾驶数据稀缺的问题。

Method: 提出Flow Planner，通过细粒度轨迹标记、优化架构和流匹配来建模交互驾驶行为。

Result: 在大规模nuPlan数据集和挑战性的interactive interPlan数据集上，Flow Planner在学习方法中达到了最先进的性能，同时有效建模复杂驾驶场景中的交互行为。

Conclusion: Flow Planner在建模复杂驾驶场景的交互行为上提供了显著的性能提升，为自动驾驶规划带来了新的思路。

Abstract: Modeling interactive driving behaviors in complex scenarios remains a
fundamental challenge for autonomous driving planning. Learning-based
approaches attempt to address this challenge with advanced generative models,
removing the dependency on over-engineered architectures for representation
fusion. However, brute-force implementation by simply stacking transformer
blocks lacks a dedicated mechanism for modeling interactive behaviors that are
common in real driving scenarios. The scarcity of interactive driving data
further exacerbates this problem, leaving conventional imitation learning
methods ill-equipped to capture high-value interactive behaviors. We propose
Flow Planner, which tackles these problems through coordinated innovations in
data modeling, model architecture, and learning scheme. Specifically, we first
introduce fine-grained trajectory tokenization, which decomposes the trajectory
into overlapping segments to decrease the complexity of whole trajectory
modeling. With a sophisticatedly designed architecture, we achieve efficient
temporal and spatial fusion of planning and scene information, to better
capture interactive behaviors. In addition, the framework incorporates flow
matching with classifier-free guidance for multi-modal behavior generation,
which dynamically reweights agent interactions during inference to maintain
coherent response strategies, providing a critical boost for interactive
scenario understanding. Experimental results on the large-scale nuPlan dataset
and challenging interactive interPlan dataset demonstrate that Flow Planner
achieves state-of-the-art performance among learning-based approaches while
effectively modeling interactive behaviors in complex driving scenarios.

</details>


### [60] [Design and Koopman Model Predictive Control of A Soft Exoskeleton Based on Origami-Inspired Pneumatic Actuator for Knee Rehabilitation](https://arxiv.org/abs/2510.11094)
*Junxiang Wang,Han Zhang,Zehao Wang,Huaiyuan Chen,Pu Wang,Weidong Chen*

Main category: cs.RO

TL;DR: 本研究提出了一种基于深度Koopman网络的软性机器人控制方法，实现了有效的康复训练，并超越了传统控制方法。


<details>
  <summary>Details</summary>
Motivation: 针对传统刚性外骨骼重量大和安全控制挑战的问题，提出设计一种舒适易穿的软性外骨骼，并有效控制其人机交互动态。

Method: 基于深度Koopman网络模型和模型预测控制（MPC），控制软性机器人的实时康复训练。

Result: 实验表明将EMG信号引入Koopman模型后，模型精度显著提高，个性化Koopman模型的表现优于非个性化模型，且控制框架在被动和主动训练模式下均优于传统PID控制。

Conclusion: 该研究提出了一种新的控制框架，用于软性康复机器人，超越了传统的PID控制，实现了更好的康复训练效果。

Abstract: Effective rehabilitation methods are essential for the recovery of lower limb
dysfunction caused by stroke. Nowadays, robotic exoskeletons have shown great
potentials in rehabilitation. Nevertheless, traditional rigid exoskeletons are
usually heavy and need a lot of work to help the patients to put them on.
Moreover, it also requires extra compliance control to guarantee the safety. In
contrast, soft exoskeletons are easy and comfortable to wear and have intrinsic
compliance, but their complex nonlinear human-robot interaction dynamics would
pose significant challenges for control. In this work, based on the pneumatic
actuators inspired by origami, we design a rehabilitation exoskeleton for knee
that is easy and comfortable to wear. To guarantee the control performance and
enable a nice human-robot interaction, we first use Deep Koopman Network to
model the human-robot interaction dynamics. In particular, by viewing the
electromyography (EMG) signals and the duty cycle of the PWM wave that controls
the pneumatic robot's valves and pump as the inputs, the linear Koopman model
accurately captures the complex human-robot interaction dynamics. Next, based
on the obtained Koopman model, we further use Model Predictive Control (MPC) to
control the soft robot and help the user to do rehabilitation training in
real-time. The goal of the rehabilitation training is to track a given
reference signal shown on the screen. Experiments show that by integrating the
EMG signals into the Koopman model, we have improved the model accuracy to
great extent. In addition, a personalized Koopman model trained from the
individual's own data performs better than the non-personalized model.
Consequently, our control framework outperforms the traditional PID control in
both passive and active training modes. Hence the proposed method provides a
new control framework for soft rehabilitation robots.

</details>


### [61] [A Primer on SO(3) Action Representations in Deep Reinforcement Learning](https://arxiv.org/abs/2510.11103)
*Martin Schuck,Sherif Samy,Angela P. Schoellig*

Main category: cs.RO

TL;DR: 本文系统评估了SO(3)动作表示对不同连续控制算法的影响，提出了简明的实施指南，发现切向量表示效果最佳。


<details>
  <summary>Details</summary>
Motivation: 许多机器人控制任务需要在SO(3)上进行决策，但其几何性质使得这一过程较为复杂。

Method: 评估SO(3)动作表示在连续控制算法中的表现

Result: 通过系统评估，我们发现采用切向量作为动作表示在不同算法中表现出更可靠的结果。

Conclusion: 不同的动作表示对探索和优化有显著影响，适当的表示选择可以提高算法的性能和稳定性。

Abstract: Many robotic control tasks require policies to act on orientations, yet the
geometry of SO(3) makes this nontrivial. Because SO(3) admits no global,
smooth, minimal parameterization, common representations such as Euler angles,
quaternions, rotation matrices, and Lie algebra coordinates introduce distinct
constraints and failure modes. While these trade-offs are well studied for
supervised learning, their implications for actions in reinforcement learning
remain unclear. We systematically evaluate SO(3) action representations across
three standard continuous control algorithms, PPO, SAC, and TD3, under dense
and sparse rewards. We compare how representations shape exploration, interact
with entropy regularization, and affect training stability through empirical
studies and analyze the implications of different projections for obtaining
valid rotations from Euclidean network outputs. Across a suite of robotics
benchmarks, we quantify the practical impact of these choices and distill
simple, implementation-ready guidelines for selecting and using rotation
actions. Our results highlight that representation-induced geometry strongly
influences exploration and optimization and show that representing actions as
tangent vectors in the local frame yields the most reliable results across
algorithms.

</details>


### [62] [DemoHLM: From One Demonstration to Generalizable Humanoid Loco-Manipulation](https://arxiv.org/abs/2510.11258)
*Yuhui Fu,Feiyang Xie,Chaoyi Xu,Jing Xiong,Haoqi Yuan,Zongqing Lu*

Main category: cs.RO

TL;DR: 提出了一种新的DemoHLM框架，可在真实人形机器人上实现基于模拟的运动操控，融合了全身控制和操控策略，表现出高效的数据使用和良好的任务执行能力。


<details>
  <summary>Details</summary>
Motivation: 尽管人形机器人的全身控制已有显著进展，但运动操控仍未充分探索，常需依赖硬编码任务定义或昂贵的实地数据收集，限制了自主性和泛化能力。

Method: DemoHLM结合低级的全身控制器和高级的操控策略，通过数据生成和模仿学习的方式进行操控政策的学习，并使用闭环视觉反馈来执行任务。

Result: 通过在Unitree G1机器人上的真实实验，验证了DemoHLM的模拟到真实的可转移性，并在十个运动操控任务中表现出稳健的性能。

Conclusion: DemoHLM框架能够在真实的人形机器人上从单一的模拟演示中实现通用的运动操控，且其方法在各种任务中展现出良好的数据传输能力和高效性。

Abstract: Loco-manipulation is a fundamental challenge for humanoid robots to achieve
versatile interactions in human environments. Although recent studies have made
significant progress in humanoid whole-body control, loco-manipulation remains
underexplored and often relies on hard-coded task definitions or costly
real-world data collection, which limits autonomy and generalization. We
present DemoHLM, a framework for humanoid loco-manipulation that enables
generalizable loco-manipulation on a real humanoid robot from a single
demonstration in simulation. DemoHLM adopts a hierarchy that integrates a
low-level universal whole-body controller with high-level manipulation policies
for multiple tasks. The whole-body controller maps whole-body motion commands
to joint torques and provides omnidirectional mobility for the humanoid robot.
The manipulation policies, learned in simulation via our data generation and
imitation learning pipeline, command the whole-body controller with closed-loop
visual feedback to execute challenging loco-manipulation tasks. Experiments
show a positive correlation between the amount of synthetic data and policy
performance, underscoring the effectiveness of our data generation pipeline and
the data efficiency of our approach. Real-world experiments on a Unitree G1
robot equipped with an RGB-D camera validate the sim-to-real transferability of
DemoHLM, demonstrating robust performance under spatial variations across ten
loco-manipulation tasks.

</details>


### [63] [Rotor-Failure-Aware Quadrotors Flight in Unknown Environments](https://arxiv.org/abs/2510.11306)
*Xiaobin Zhou,Miao Wang,Chengao Li,Can Cui,Ruibin Zhang,Yongchao Wang,Chao Xu,Fei Gao*

Main category: cs.RO

TL;DR: 本论文提出了一种针对旋翼失效的四旋翼导航系统，通过在线故障检测、规划与控制技术，在复杂环境中实现了自主飞行。


<details>
  <summary>Details</summary>
Motivation: 由于旋翼失效导致的高旋转速度和振动对自主飞行造成重大挑战，而现有的主要解决方案尚未实现对未知和复杂环境中的旋翼失效进行在线检测和诊断、轨迹规划与故障容错控制。

Method: 设计了一种复合故障检测与诊断(FDD)的非线性模型预测控制器(NMPC)，结合电机动态，以确保快速故障检测和飞行稳定性，并设计了基于FDD结果和时空联合优化的故障感知规划器。

Result: 提出的方法在处理旋翼失效（包括螺旋桨卸载和电机停转）时表现优越，实验结果首次表明，能在复杂环境中实现自主四旋翼飞行。

Conclusion: 实验结果证明，所提方法能有效减轻旋翼失效对四旋翼飞行的影响，尤其在杂乱房间和未知森林等挑战性环境中显示出卓越的性能。

Abstract: Rotor failures in quadrotors may result in high-speed rotation and vibration
due to rotor imbalance, which introduces significant challenges for autonomous
flight in unknown environments. The mainstream approaches against rotor
failures rely on fault-tolerant control (FTC) and predefined trajectory
tracking. To the best of our knowledge, online failure detection and diagnosis
(FDD), trajectory planning, and FTC of the post-failure quadrotors in unknown
and complex environments have not yet been achieved. This paper presents a
rotor-failure-aware quadrotor navigation system designed to mitigate the
impacts of rotor imbalance. First, a composite FDD-based nonlinear model
predictive controller (NMPC), incorporating motor dynamics, is designed to
ensure fast failure detection and flight stability. Second, a
rotor-failure-aware planner is designed to leverage FDD results and
spatial-temporal joint optimization, while a LiDAR-based quadrotor platform
with four anti-torque plates is designed to enable reliable perception under
high-speed rotation. Lastly, extensive benchmarks against state-of-the-art
methods highlight the superior performance of the proposed approach in
addressing rotor failures, including propeller unloading and motor stoppage.
The experimental results demonstrate, for the first time, that our approach
enables autonomous quadrotor flight with rotor failures in challenging
environments, including cluttered rooms and unknown forests.

</details>


### [64] [Adap-RPF: Adaptive Trajectory Sampling for Robot Person Following in Dynamic Crowded Environments](https://arxiv.org/abs/2510.11308)
*Weixi Situ,Hanjing Ye,Jianwei Peng,Yu Zhan,Hong Zhang*

Main category: cs.RO

TL;DR: 本研究提出一种新的人跟随机器人轨迹生成方法，有效应对动态环境下的遮挡问题。


<details>
  <summary>Details</summary>
Motivation: 解决动态和拥挤环境中人跟随机器人面临的遮挡挑战

Method: 自适应轨迹采样方法和预测感知模型预测路径积分(MPPI)控制器

Result: 提出的方法在轨迹平滑性、安全性、稳健性和人类舒适度方面优于目前最先进的基线，且在实时场景中表现有效

Conclusion: 所提方法在真实场景中证明了其优越性，为人机交互领域的机器人应用提供了新思路。

Abstract: Robot person following (RPF) is a core capability in human-robot interaction,
enabling robots to assist users in daily activities, collaborative work, and
other service scenarios. However, achieving practical RPF remains challenging
due to frequent occlusions, particularly in dynamic and crowded environments.
Existing approaches often rely on fixed-point following or sparse
candidate-point selection with oversimplified heuristics, which cannot
adequately handle complex occlusions caused by moving obstacles such as
pedestrians. To address these limitations, we propose an adaptive trajectory
sampling method that generates dense candidate points within socially aware
zones and evaluates them using a multi-objective cost function. Based on the
optimal point, a person-following trajectory is estimated relative to the
predicted motion of the target. We further design a prediction-aware model
predictive path integral (MPPI) controller that simultaneously tracks this
trajectory and proactively avoids collisions using predicted pedestrian
motions. Extensive experiments show that our method outperforms
state-of-the-art baselines in smoothness, safety, robustness, and human
comfort, with its effectiveness further demonstrated on a mobile robot in
real-world scenarios.

</details>


### [65] [HiMaCon: Discovering Hierarchical Manipulation Concepts from Unlabeled Multi-Modal Data](https://arxiv.org/abs/2510.11321)
*Ruizhe Liu,Pei Zhou,Qian Luo,Li Sun,Jun Cen,Yibing Song,Yanchao Yang*

Main category: cs.RO

TL;DR: 通过无需人类注释的自监督学习，提出了一种框架，能有效提升机器人操作性能。


<details>
  <summary>Details</summary>
Motivation: 有效的机器人操作通常需要捕捉跨环境和任务的 invariant 交互模式。

Method: 结合跨模态相关网络与多时间尺度预测器，以层次化方式学习操作概念。

Result: 提出了一种自监督框架，用于学习层次化的操作概念，以获取跨环境和任务的非变异交互模式。

Conclusion: 所提出的框架显著提高了机器人在复杂场景中的操作表现，并且所学概念与人类可理解的操作原理相似。

Abstract: Effective generalization in robotic manipulation requires representations
that capture invariant patterns of interaction across environments and tasks.
We present a self-supervised framework for learning hierarchical manipulation
concepts that encode these invariant patterns through cross-modal sensory
correlations and multi-level temporal abstractions without requiring human
annotation. Our approach combines a cross-modal correlation network that
identifies persistent patterns across sensory modalities with a multi-horizon
predictor that organizes representations hierarchically across temporal scales.
Manipulation concepts learned through this dual structure enable policies to
focus on transferable relational patterns while maintaining awareness of both
immediate actions and longer-term goals. Empirical evaluation across simulated
benchmarks and real-world deployments demonstrates significant performance
improvements with our concept-enhanced policies. Analysis reveals that the
learned concepts resemble human-interpretable manipulation primitives despite
receiving no semantic supervision. This work advances both the understanding of
representation learning for manipulation and provides a practical approach to
enhancing robotic performance in complex scenarios.

</details>


### [66] [Path and Motion Optimization for Efficient Multi-Location Inspection with Humanoid Robots](https://arxiv.org/abs/2510.11401)
*Jiayang Wu,Jiongye Li,Shibowen Zhang,Zhicheng He,Zaijin Wang,Xiaokun Leng,Hangxin Liu,Jingwen Zhang,Jiayi Wang,Song-Chun Zhu,Yao Su*

Main category: cs.RO

TL;DR: 该论文提出了一种新颖框架，结合分层规划、时间最优站立位置生成和集成的模型预测控制，以实现高速度和精度的检查任务。


<details>
  <summary>Details</summary>
Motivation: 提高人形机器人在工业检查任务中的效率和精度，以适应复杂的工作环境和高要求的操作。

Method: 采用分层规划、时间最优位置生成和集成模型预测控制，优化机器人执行检查任务的效率和精度。

Result: 提出了一种新框架，使人形机器人能够以高效率和毫米级精度执行检查任务。

Conclusion: 通过模拟和在Kuavo 4Pro人形平台上的实验验证，该框架在多地点任务中表现出低时间成本和高成功率，能够高效精准地执行复杂工业操作。

Abstract: This paper proposes a novel framework for humanoid robots to execute
inspection tasks with high efficiency and millimeter-level precision. The
approach combines hierarchical planning, time-optimal standing position
generation, and integrated \ac{mpc} to achieve high speed and precision. A
hierarchical planning strategy, leveraging \ac{ik} and \ac{mip}, reduces
computational complexity by decoupling the high-dimensional planning problem. A
novel MIP formulation optimizes standing position selection and trajectory
length, minimizing task completion time. Furthermore, an MPC system with
simplified kinematics and single-step position correction ensures
millimeter-level end-effector tracking accuracy. Validated through simulations
and experiments on the Kuavo 4Pro humanoid platform, the framework demonstrates
low time cost and a high success rate in multi-location tasks, enabling
efficient and precise execution of complex industrial operations.

</details>


### [67] [A Faster and More Reliable Middleware for Autonomous Driving Systems](https://arxiv.org/abs/2510.11448)
*Yuankai He,Hanlin Chen,Weisong Shi*

Main category: cs.RO

TL;DR: 提出了一种名为Sensor-in-Memory (SIM) 的共享内存传输方案，显著减少高速度自主车辆中的数据传输延迟，以提高安全性和效率。


<details>
  <summary>Details</summary>
Motivation: 在高速度自主车辆中，确保安全性需要减少感知到控制执行的延迟，而现有的中间件在多个节点共享计算单元时会引入额外的延迟。

Method: 通过共享内存设计的锁-free 双缓冲方案、原生内存布局以及与 ROS 2 的集成，SIM 优化了数据传输。

Result: 在测试中，SIM 将数据传输延迟减少高达98%，并在真实应用中提升了本地化频率和降低了感知到决策的平均延迟。

Conclusion: SIM 在高速自主车辆的感知到决策延迟方面表现优异，能够有效降低数据传输延迟，提升车辆安全性。

Abstract: Ensuring safety in high-speed autonomous vehicles requires rapid control
loops and tightly bounded delays from perception to actuation. Many open-source
autonomy systems rely on ROS 2 middleware; when multiple sensor and control
nodes share one compute unit, ROS 2 and its DDS transports add significant
(de)serialization, copying, and discovery overheads, shrinking the available
time budget. We present Sensor-in-Memory (SIM), a shared-memory transport
designed for intra-host pipelines in autonomous vehicles. SIM keeps sensor data
in native memory layouts (e.g., cv::Mat, PCL), uses lock-free bounded double
buffers that overwrite old data to prioritize freshness, and integrates into
ROS 2 nodes with four lines of code. Unlike traditional middleware, SIM
operates beside ROS 2 and is optimized for applications where data freshness
and minimal latency outweigh guaranteed completeness. SIM provides sequence
numbers, a writer heartbeat, and optional checksums to ensure ordering,
liveness, and basic integrity. On an NVIDIA Jetson Orin Nano, SIM reduces
data-transport latency by up to 98% compared to ROS 2 zero-copy transports such
as FastRTPS and Zenoh, lowers mean latency by about 95%, and narrows
95th/99th-percentile tail latencies by around 96%. In tests on a
production-ready Level 4 vehicle running Autoware.Universe, SIM increased
localization frequency from 7.5 Hz to 9.5 Hz. Applied across all
latency-critical modules, SIM cut average perception-to-decision latency from
521.91 ms to 290.26 ms, reducing emergency braking distance at 40 mph (64 km/h)
on dry concrete by 13.6 ft (4.14 m).

</details>


### [68] [Constraint-Aware Reinforcement Learning via Adaptive Action Scaling](https://arxiv.org/abs/2510.11491)
*Murad Dawood,Usama Ahmed Siddiquie,Shahram Khorshidi,Maren Bennewitz*

Main category: cs.RO

TL;DR: 本文提出了一种模块化的成本感知调节器，通过预测约束违反来调整代理动作，从而在保障安全的同时维持探索。


<details>
  <summary>Details</summary>
Motivation: 现有安全强化学习方法通常依赖于单一策略优化奖励和安全，导致不稳定或需要先验知识的外部安全过滤器。

Method: 提出的调节器通过平滑动作调制来调整代理的行动，避免了冲突的目标带来的不稳定性，同时与现有的离线RL方法无缝集成。

Result: 在Safety Gym的运动任务中，此方法显著减少了约束违反，最多达126倍，同时返回提升超过一个数量级。

Conclusion: 该方法在安全训练中能够显著降低约束违反，并提高任务回报，尤其在稀疏成本的情况下表现出色。

Abstract: Safe reinforcement learning (RL) seeks to mitigate unsafe behaviors that
arise from exploration during training by reducing constraint violations while
maintaining task performance. Existing approaches typically rely on a single
policy to jointly optimize reward and safety, which can cause instability due
to conflicting objectives, or they use external safety filters that override
actions and require prior system knowledge. In this paper, we propose a modular
cost-aware regulator that scales the agent's actions based on predicted
constraint violations, preserving exploration through smooth action modulation
rather than overriding the policy. The regulator is trained to minimize
constraint violations while avoiding degenerate suppression of actions. Our
approach integrates seamlessly with off-policy RL methods such as SAC and TD3,
and achieves state-of-the-art return-to-cost ratios on Safety Gym locomotion
tasks with sparse costs, reducing constraint violations by up to 126 times
while increasing returns by over an order of magnitude compared to prior
methods.

</details>


### [69] [DQ-NMPC: Dual-Quaternion NMPC for Quadrotor Flight](https://arxiv.org/abs/2510.11525)
*Luis F. Recalde,Dhruv Agrawal,Jon Arrizabalaga,Guanrui Li*

Main category: cs.RO

TL;DR: 本文提出了一种基于双四元数的NMPC框架，以提高四旋翼在复杂环境中的控制精度和性能，通过实验验证表现出显著的优越性。


<details>
  <summary>Details</summary>
Motivation: 四旋翼的敏捷性使其在复杂任务中具有巨大潜力，但由于欠驱动特性和动力学的强耦合性，精准控制仍然面临挑战。

Method: 通过在双四元数流形上直接表示四旋翼动态和姿态误差，构建了紧凑且全局非奇异的框架。

Result: 相较于传统基线NMPC方法，该方法在位置和方向误差上分别减少了56.11%和56.77%，在收紧空间内成功完成了最大速度13.66 m/s和加速度4.2 g的攻击性轨迹。

Conclusion: 该研究提出的基于双四元数（DQ-NMPC）的NMPC框架显著提高了四旋翼飞行控制的精度和稳定性，特别是在复杂和动态环境中。

Abstract: MAVs have great potential to assist humans in complex tasks, with
applications ranging from logistics to emergency response. Their agility makes
them ideal for operations in complex and dynamic environments. However,
achieving precise control in agile flights remains a significant challenge,
particularly due to the underactuated nature of quadrotors and the strong
coupling between their translational and rotational dynamics. In this work, we
propose a novel NMPC framework based on dual-quaternions (DQ-NMPC) for
quadrotor flight. By representing both quadrotor dynamics and the pose error
directly on the dual-quaternion manifold, our approach enables a compact and
globally non-singular formulation that captures the quadrotor coupled dynamics.
We validate our approach through simulations and real-world experiments,
demonstrating better numerical conditioning and significantly improved tracking
performance, with reductions in position and orientation errors of up to 56.11%
and 56.77%, compared to a conventional baseline NMPC method. Furthermore, our
controller successfully handles aggressive trajectories, reaching maximum
speeds up to 13.66 m/s and accelerations reaching 4.2 g within confined space
conditions of dimensions 11m x 4.5m x 3.65m under which the baseline controller
fails.

</details>


### [70] [IntersectioNDE: Learning Complex Urban Traffic Dynamics based on Interaction Decoupling Strategy](https://arxiv.org/abs/2510.11534)
*Enli Lin,Ziyuan Yang,Qiujing Lu,Jianming Hu,Shuo Feng*

Main category: cs.RO

TL;DR: 提出了City Crossings Dataset (CiCross) 和 IntersectioNDE模拟器，以提升城市交叉口的交通模拟准确性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决现有模拟器在城市交叉口高度密集和多样化互动建模的不足，确保自动驾驶汽车的安全和可靠性。

Method: 采用Interaction Decoupling Strategy和场景感知的Transformer网络，训练数据驱动的交通模拟模型。

Result: 实验表明，IntersectioNDE在模拟逼真度、稳定性以及复杂交通动态再现方面表现优异。

Conclusion: IntersectioNDE在模拟准确性和稳定性方面优于基线方法，成功模拟复杂的城市交通动态。

Abstract: Realistic traffic simulation is critical for ensuring the safety and
reliability of autonomous vehicles (AVs), especially in complex and diverse
urban traffic environments. However, existing data-driven simulators face two
key challenges: a limited focus on modeling dense, heterogeneous interactions
at urban intersections - which are prevalent, crucial, and practically
significant in countries like China, featuring diverse agents including
motorized vehicles (MVs), non-motorized vehicles (NMVs), and pedestrians - and
the inherent difficulty in robustly learning high-dimensional joint
distributions for such high-density scenes, often leading to mode collapse and
long-term simulation instability. We introduce City Crossings Dataset
(CiCross), a large-scale dataset collected from a real-world urban
intersection, uniquely capturing dense, heterogeneous multi-agent interactions,
particularly with a substantial proportion of MVs, NMVs and pedestrians. Based
on this dataset, we propose IntersectioNDE (Intersection Naturalistic Driving
Environment), a data-driven simulator tailored for complex urban intersection
scenarios. Its core component is the Interaction Decoupling Strategy (IDS), a
training paradigm that learns compositional dynamics from agent subsets,
enabling the marginal-to-joint simulation. Integrated into a scene-aware
Transformer network with specialized training techniques, IDS significantly
enhances simulation robustness and long-term stability for modeling
heterogeneous interactions. Experiments on CiCross show that IntersectioNDE
outperforms baseline methods in simulation fidelity, stability, and its ability
to replicate complex, distribution-level urban traffic dynamics.

</details>


### [71] [Simultaneous Calibration of Noise Covariance and Kinematics for State Estimation of Legged Robots via Bi-level Optimization](https://arxiv.org/abs/2510.11539)
*Denglin Cheng,Jiarong Kang,Xiaobin Xiong*

Main category: cs.RO

TL;DR: 提出了一种通过双层优化框架提升机器人状态估计精度的方法。


<details>
  <summary>Details</summary>
Motivation: 在动态和不确定的环境中，腿行机器人和空中机器人对准确状态估计的需求很高，但传统的噪声协方差调整复杂且不易。

Method: 上层将噪声协方差和模型参数视为优化变量，下层执行全信息估计器，通过估计器导数进行优化。

Result: 提出了一种双层优化框架，可以在估计器循环中联合校准协方差矩阵和运动学参数。

Conclusion: 我们的模型在四足和类人机器人上经过验证，显著提高了状态估计的准确性和不确定性校准。

Abstract: Accurate state estimation is critical for legged and aerial robots operating
in dynamic, uncertain environments. A key challenge lies in specifying process
and measurement noise covariances, which are typically unknown or manually
tuned. In this work, we introduce a bi-level optimization framework that
jointly calibrates covariance matrices and kinematic parameters in an
estimator-in-the-loop manner. The upper level treats noise covariances and
model parameters as optimization variables, while the lower level executes a
full-information estimator. Differentiating through the estimator allows direct
optimization of trajectory-level objectives, resulting in accurate and
consistent state estimates. We validate our approach on quadrupedal and
humanoid robots, demonstrating significantly improved estimation accuracy and
uncertainty calibration compared to hand-tuned baselines. Our method unifies
state estimation, sensor, and kinematics calibration into a principled,
data-driven framework applicable across diverse robotic platforms.

</details>


### [72] [NaviGait: Navigating Dynamically Feasible Gait Libraries using Deep Reinforcement Learning](https://arxiv.org/abs/2510.11542)
*Neil C. Janwani,Varun Madabushi,Maegan Tucker*

Main category: cs.RO

TL;DR: NaviGait是结合轨迹优化与RL的分层框架，通过丰富的运动先验简化奖励设计，提高步态控制的稳健性和训练效率。


<details>
  <summary>Details</summary>
Motivation: RL在双足运动控制中表现出色，但复杂的奖励设计使得行为调整困难，因此需要一种更易于调整和解释的方法。

Method: NaviGait框架结合了离线优化步态库与层次化的RL策略，通过平滑插值产生连续参考运动并进行指令调整。

Result: 实验结果表明，NaviGait的训练速度相比传统和模仿基的RL更快，且生成的运动更接近原始参考步态。

Conclusion: NaviGait通过将轨迹优化结构与RL的适应性结合，提供了一种可扩展且具有高度稳健性的步态控制方法。

Abstract: Reinforcement learning (RL) has emerged as a powerful method to learn robust
control policies for bipedal locomotion. Yet, it can be difficult to tune
desired robot behaviors due to unintuitive and complex reward design. In
comparison, offline trajectory optimization methods, like Hybrid Zero Dynamics,
offer more tuneable, interpretable, and mathematically grounded motion plans
for high-dimensional legged systems. However, these methods often remain
brittle to real-world disturbances like external perturbations.
  In this work, we present NaviGait, a hierarchical framework that combines the
structure of trajectory optimization with the adaptability of RL for robust and
intuitive locomotion control. NaviGait leverages a library of offline-optimized
gaits and smoothly interpolates between them to produce continuous reference
motions in response to high-level commands. The policy provides both
joint-level and velocity command residual corrections to modulate and stabilize
the reference trajectories in the gait library. One notable advantage of
NaviGait is that it dramatically simplifies reward design by encoding rich
motion priors from trajectory optimization, reducing the need for finely tuned
shaping terms and enabling more stable and interpretable learning. Our
experimental results demonstrate that NaviGait enables faster training compared
to conventional and imitation-based RL, and produces motions that remain
closest to the original reference. Overall, by decoupling high-level motion
generation from low-level correction, NaviGait offers a more scalable and
generalizable approach for achieving dynamic and robust locomotion.

</details>


### [73] [Robot Soccer Kit: Omniwheel Tracked Soccer Robots for Education](https://arxiv.org/abs/2510.11552)
*Gregoire Passault,Clement Gaspard,Olivier Ly*

Main category: cs.RO

TL;DR: 本文介绍了一种教育性全自主机器人套件，该套件配备外部跟踪系统，突破了现有机器人在感知方面的局限，适用于高阶机器人问题的教学。


<details>
  <summary>Details</summary>
Motivation: 随着可编程组件的成本下降和模块化增强，教育机器人在学校中的应用日益普及，旨在通过实用应用和项目导向的教学来提升学生的多学科技能。

Method: 通过引入外部跟踪系统，降低了对嵌入式系统的约束，同时保留了探索高阶机器人概念的能力。

Result: 该研究成功开发了一种新的机器人套件，提供了更强大的学习工具，使学生可以接触更复杂的机器人任务。

Conclusion: 教育性全自主机器人套件能够有效增强机器人教学的广度与深度，促进学生掌握更高阶的机器人技能。

Abstract: Recent developments of low cost off-the-shelf programmable components, their
modularity, and also rapid prototyping made educational robotics flourish, as
it is accessible in most schools today. They allow to illustrate and embody
theoretical problems in practical and tangible applications, and gather
multidisciplinary skills. They also give a rich natural context for
project-oriented pedagogy. However, most current robot kits all are limited to
egocentric aspect of the robots perception. This makes it difficult to access
more high-level problems involving e.g. coordinates or navigation. In this
paper we introduce an educational holonomous robot kit that comes with an
external tracking system, which lightens the constraint on embedded systems,
but allows in the same time to discover high-level aspects of robotics,
otherwise unreachable.

</details>


### [74] [SCOOP'D: Learning Mixed-Liquid-Solid Scooping via Sim2Real Generative Policy](https://arxiv.org/abs/2510.11566)
*Kuanning Wang,Yongchong Gu,Yuqian Fu,Zeyu Shangguan,Sicheng He,Xiangyang Xue,Yanwei Fu,Daniel Seita*

Main category: cs.RO

TL;DR: SCOOP'D是一个用于自主机器人挖掘的创新方法，基于OmniGibson平台的仿真，通过学习示例和生成策略实现高效的挖掘任务。


<details>
  <summary>Details</summary>
Motivation: 开发一种通用且自主的机器人挖掘策略，克服复杂工具-物体交互和可变形物体操作的挑战。

Method: 使用OmniGibson进行仿真，收集示例并采用基于扩散的生成策略进行模仿。

Result: 我们提出SCOOP'D方法，它利用OmniGibson平台的仿真，通过算法程序收集使用工具时的挖掘示例，进而使用扩散生成策略通过观察输入来模仿这些示例。该方法在不同真实场景中的零次部署表现出色，显示了获取机器人挖掘技能的潜力。

Conclusion: SCOOP'D在各种真实场景中的表现超越了所有基线，并表明该方法具有获取机器人挖掘技能的潜力。

Abstract: Scooping items with tools such as spoons and ladles is common in daily life,
ranging from assistive feeding to retrieving items from environmental disaster
sites. However, developing a general and autonomous robotic scooping policy is
challenging since it requires reasoning about complex tool-object interactions.
Furthermore, scooping often involves manipulating deformable objects, such as
granular media or liquids, which is challenging due to their
infinite-dimensional configuration spaces and complex dynamics. We propose a
method, SCOOP'D, which uses simulation from OmniGibson (built on NVIDIA
Omniverse) to collect scooping demonstrations using algorithmic procedures that
rely on privileged state information. Then, we use generative policies via
diffusion to imitate demonstrations from observational input. We directly apply
the learned policy in diverse real-world scenarios, testing its performance on
various item quantities, item characteristics, and container types. In
zero-shot deployment, our method demonstrates promising results across 465
trials in diverse scenarios, including objects of different difficulty levels
that we categorize as "Level 1" and "Level 2." SCOOP'D outperforms all
baselines and ablations, suggesting that this is a promising approach to
acquiring robotic scooping skills. Project page is at
https://scoopdiff.github.io/.

</details>


### [75] [Calibrated Dynamic Modeling for Force and Payload Estimation in Hydraulic Machinery](https://arxiv.org/abs/2510.11574)
*Lennart Werner,Pol Eyschen,Sean Costello,Pierluigi Micarelli,Marco Hutter*

Main category: cs.RO

TL;DR: 本文提出了一种高精度、可 retrofittable 的2D力和载荷估计算法，在挖掘机上具有优越的准确性和精度，且不需特定的动态特性知识。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够实时准确估计液压挖掘机末端执行器相互作用力的算法，以便于改善重型机械的自动化和操作精度。

Method: 提出了一种高精度的2D力和载荷估计算法，通过压力和惯性测量实现在线力测量。

Result: 在标准25吨挖掘机上实现了满载精度为1%的载荷估计，并且力的方向精度为13度，大小精度为383N。

Conclusion: 该算法在准确性和精度上优于传统的准静态方法和市售系统，适用于不同类型和重量等级的挖掘机。

Abstract: Accurate real-time estimation of end effector interaction forces in hydraulic
excavators is a key enabler for advanced automation in heavy machinery.
Accurate knowledge of these forces allows improved, precise grading and digging
maneuvers. To address these challenges, we introduce a high-accuracy,
retrofittable 2D force- and payload estimation algorithm that does not impose
additional requirements on the operator regarding trajectory, acceleration or
the use of the slew joint. The approach is designed for retrofittability,
requires minimal calibration and no prior knowledge of machine-specific dynamic
characteristics. Specifically, we propose a method for identifying a dynamic
model, necessary to estimate both end effector interaction forces and bucket
payload during normal operation. Our optimization-based payload estimation
achieves a full-scale payload accuracy of 1%. On a standard 25 t excavator, the
online force measurement from pressure and inertial measurements achieves a
direction accuracy of 13 degree and a magnitude accuracy of 383 N. The method's
accuracy and generalization capability are validated on two excavator platforms
of different type and weight classes. We benchmark our payload estimation
against a classical quasistatic method and a commercially available system. Our
system outperforms both in accuracy and precision.

</details>


### [76] [ManiAgent: An Agentic Framework for General Robotic Manipulation](https://arxiv.org/abs/2510.11660)
*Yi Yang,Kefan Gu,Yuqing Wen,Hebei Li,Yucheng Zhao,Tiancai Wang,Xudong Liu*

Main category: cs.RO

TL;DR: ManiAgent通过多代理协同工作解决复杂操作任务，展示出高成功率和接近人类标注数据集的性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有VLA模型在复杂推理和长远任务规划中因为数据稀缺和模型能力受限的问题。

Method: 引入多个代理通过相互通信来处理操作任务，包括环境感知、子任务分解和行动生成。

Result: 在SimplerEnv基准上达到86.8%的成功率，现实世界拾取和放置任务上达到95.8%的成功率。

Conclusion: ManiAgent框架提升了机器人操作能力，并在环境感知和行动生成上表现出色。

Abstract: While Vision-Language-Action (VLA) models have demonstrated impressive
capabilities in robotic manipulation, their performance in complex reasoning
and long-horizon task planning is limited by data scarcity and model capacity.
To address this, we introduce ManiAgent, an agentic architecture for general
manipulation tasks that achieves end-to-end output from task descriptions and
environmental inputs to robotic manipulation actions. In this framework,
multiple agents involve inter-agent communication to perform environmental
perception, sub-task decomposition and action generation, enabling efficient
handling of complex manipulation scenarios. Evaluations show ManiAgent achieves
an 86.8% success rate on the SimplerEnv benchmark and 95.8% on real-world
pick-and-place tasks, enabling efficient data collection that yields VLA models
with performance comparable to those trained on human-annotated datasets.The
project webpage is available at https://yi-yang929.github.io/ManiAgent/.

</details>


### [77] [Ego-Vision World Model for Humanoid Contact Planning](https://arxiv.org/abs/2510.11682)
*Hang Liu,Yuman Gao,Sangli Teng,Yufeng Chi,Yakun Sophia Shao,Zhongyu Li,Maani Ghaffari,Koushil Sreenath*

Main category: cs.RO

TL;DR: 提出了一种结合学习模型和MPC的方法，以提高类人机器人的接触利用能力和数据效率。


<details>
  <summary>Details</summary>
Motivation: 使类人机器人能够利用物理接触以提高在复杂环境中的自主能力

Method: 结合学习的世界模型与基于采样的模型预测控制（MPC）

Result: 在真实的类人机器人上实现了稳健的实时接触规划，支持多任务能力

Conclusion: 该系统在类人机器人上成功应用，显示出在接触任务中的优势和高效性。

Abstract: Enabling humanoid robots to exploit physical contact, rather than simply
avoid collisions, is crucial for autonomy in unstructured environments.
Traditional optimization-based planners struggle with contact complexity, while
on-policy reinforcement learning (RL) is sample-inefficient and has limited
multi-task ability. We propose a framework combining a learned world model with
sampling-based Model Predictive Control (MPC), trained on a demonstration-free
offline dataset to predict future outcomes in a compressed latent space. To
address sparse contact rewards and sensor noise, the MPC uses a learned
surrogate value function for dense, robust planning. Our single, scalable model
supports contact-aware tasks, including wall support after perturbation,
blocking incoming objects, and traversing height-limited arches, with improved
data efficiency and multi-task capability over on-policy RL. Deployed on a
physical humanoid, our system achieves robust, real-time contact planning from
proprioception and ego-centric depth images. Website:
https://ego-vcp.github.io/

</details>


### [78] [Phys2Real: Fusing VLM Priors with Interactive Online Adaptation for Uncertainty-Aware Sim-to-Real Manipulation](https://arxiv.org/abs/2510.11689)
*Maggie Wang,Stephen Tian,Aiden Swann,Ola Shorinwa,Jiajun Wu,Mac Schwager*

Main category: cs.RO

TL;DR: Phys2Real是一个结合视觉语言模型和不确定性感知融合的RL管道，以优化机器人操控策略的转移过程。


<details>
  <summary>Details</summary>
Motivation: 在现实世界中直接学习机器人操控策略的成本高且耗时，实际应用中从模拟到现实的迁移尤为困难，因此需要一种高效的策略优化流程。

Method: 该方法包括三大核心组件：高保真几何重建，视觉语言模型推断的物理参数先验分布，以及基于交互数据的在线物理参数估计。

Result: 本文提出了一种名为Phys2Real的RL管道，以实现有效的现实世界到模拟再到现实世界的迁移，特别适用于对动态要求精确的任务。

Conclusion: 实验结果表明，Phys2Real在多个推理任务中显著提升了成功率和任务完成速度，关键在于结合了视觉语言模型与交互数据，提供了有效的物理参数估计。

Abstract: Learning robotic manipulation policies directly in the real world can be
expensive and time-consuming. While reinforcement learning (RL) policies
trained in simulation present a scalable alternative, effective sim-to-real
transfer remains challenging, particularly for tasks that require precise
dynamics. To address this, we propose Phys2Real, a real-to-sim-to-real RL
pipeline that combines vision-language model (VLM)-inferred physical parameter
estimates with interactive adaptation through uncertainty-aware fusion. Our
approach consists of three core components: (1) high-fidelity geometric
reconstruction with 3D Gaussian splatting, (2) VLM-inferred prior distributions
over physical parameters, and (3) online physical parameter estimation from
interaction data. Phys2Real conditions policies on interpretable physical
parameters, refining VLM predictions with online estimates via ensemble-based
uncertainty quantification. On planar pushing tasks of a T-block with varying
center of mass (CoM) and a hammer with an off-center mass distribution,
Phys2Real achieves substantial improvements over a domain randomization
baseline: 100% vs 79% success rate for the bottom-weighted T-block, 57% vs 23%
in the challenging top-weighted T-block, and 15% faster average task completion
for hammer pushing. Ablation studies indicate that the combination of VLM and
interaction information is essential for success. Project website:
https://phys2real.github.io/ .

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [79] [Network Traffic as a Scalable Ethnographic Lens for Understanding University Students' AI Tool Practices](https://arxiv.org/abs/2510.09763)
*Donghan Hu,Rameen Mahmood,Annabelle David,Danny Yuxing Huang*

Main category: cs.HC

TL;DR: 本文介绍了一种基于VPN网络流量分析的新方法，旨在无偏见地理解学生与AI工具的互动，结合传统自我报告数据，揭示了短期、分散的互动模式。


<details>
  <summary>Details</summary>
Motivation: 理解AI工具在学生学习与创作中的使用方式，并克服传统研究方法的局限性。

Method: 通过对VPN网络流量进行分析，捕获匿名元数据，而非内容，以保护个人信息，同时进行细致的行为追踪。

Result: 为期三周的实地研究显示，学生与AI工具的互动短暂且分散，学习活动与学术周期高度相关。

Conclusion: 网络流量分析展现出作为大规模数字人类学的新机会，特别是在技术实践方面。

Abstract: AI-driven applications have become woven into students' academic and creative
workflows, influencing how they learn, write, and produce ideas. Gaining a
nuanced understanding of these usage patterns is essential, yet conventional
survey and interview methods remain limited by recall bias, self-presentation
effects, and the underreporting of habitual behaviors. While ethnographic
methods offer richer contextual insights, they often face challenges of scale
and reproducibility. To bridge this gap, we introduce a privacy-conscious
approach that repurposes VPN-based network traffic analysis as a scalable
ethnographic technique for examining students' real-world engagement with AI
tools. By capturing anonymized metadata rather than content, this method
enables fine-grained behavioral tracing while safeguarding personal
information, thereby complementing self-report data. A three-week field
deployment with university students reveals fragmented, short-duration
interactions across multiple tools and devices, with intense bursts of activity
coinciding with exam periods-patterns mirroring institutional rhythms of
academic life. We conclude by discussing methodological, ethical, and empirical
implications, positioning network traffic analysis as a promising avenue for
large-scale digital ethnography on technology-in-practice.

</details>


### [80] [PRAXA: A Framework for What-If Analysis](https://arxiv.org/abs/2510.09791)
*Sneha Gathani,Kevin Li,Raghav Thind,Sirui Zeng,Matthew Xu,Peter J. Haas,Cagatay Demiralp,Zhicheng Liu*

Main category: cs.HC

TL;DR: 本文回顾了141篇出版物，提出了'假如分析'的统一框架和标准化词汇，明确了其动机、核心成分及应用挑战。


<details>
  <summary>Details</summary>
Motivation: 提出统一的框架，以明确定义情景模拟等各种分析技术的动机、核心组成部分和不同类型。

Method: 系统回顾了2014至2024年间在视觉分析和人机交互领域的141篇出版物，分析了假如分析的相关方法和挑战。

Result: 建立了一个名为Praxa的结构化框架，识别出'假如分析'的基本组成部分并表征其不同类型。

Conclusion: 我们的研究结果为跨领域的一致性使用提供了基础，促进了概念性清晰的交流，并指出未来的研究方向。

Abstract: Various analytical techniques-such as scenario modeling, sensitivity
analysis, perturbation-based analysis, counterfactual analysis, and parameter
space analysis-are used across domains to explore hypothetical scenarios,
examine input-output relationships, and identify pathways to desired results.
Although termed differently, these methods share common concepts and methods,
suggesting unification under what-if analysis. Yet a unified framework to
define motivations, core components, and its distinct types is lacking. To
address this gap, we reviewed 141 publications from leading visual analytics
and HCI venues (2014-2024). Our analysis (1) outlines the motivations for
what-if analysis, (2) introduces Praxa, a structured framework that identifies
its fundamental components and characterizes its distinct types, and (3)
highlights challenges associated with the application and implementation.
Together, our findings establish a standardized vocabulary and structural
understanding, enabling more consistent use across domains and communicate with
greater conceptual clarity. Finally, we identify open research problems and
future directions to advance what-if analysis.

</details>


### [81] [ROBOPSY PL[AI]: Using Role-Play to Investigate how LLMs Present Collective Memory](https://arxiv.org/abs/2510.09874)
*Margarete Jahrmann,Thomas Brandstetter,Stefan Glasauer*

Main category: cs.HC

TL;DR: 本研究首次探讨了大型语言模型在集体记忆呈现方面的表现，通过角色扮演游戏和用户互动分析来揭示不同LLM在历史内容呈现上的差异。


<details>
  <summary>Details</summary>
Motivation: 旨在揭示大型语言模型在历史内容呈现中的角色，以增进对这些技术如何影响集体记忆认知的理解。

Method: 通过公共安装和用户互动，结合定性与定量分析的方法，研究LLM在角色扮演游戏中的表现和用户反馈。

Result: 这项研究首次探讨了大型语言模型如何策划与呈现集体记忆。在2025年于维也纳的公共展览中，访客们可以与五种不同的大型语言模型互动，这些模型作为叙述者进行了一场围绕奥地利哲学家莫里茨·施里克1936年谋杀案的角色扮演游戏。研究结果包括游戏期间LLM与用户的互动协议及游戏体验后的定性访谈，获取玩家对游戏的反应。通过自然语言处理技术，对115个角色扮演的引导文本进行了定量分析，发现不同LLM在呈现历史内容上存在显著差异。

Conclusion: 本研究为分析大型语言模型的表现提供了新的视角，并提出了一种以轻松方式向公众传播这些分析结果的方法。

Abstract: The paper presents the first results of an artistic research project
investigating how Large Language Models (LLMs) curate and present collective
memory. In a public installation exhibited during two months in Vienna in 2025,
visitors could interact with five different LLMs (ChatGPT with GPT 4o and GPT
4o mini, Mistral Large, DeepSeek-Chat, and a locally run Llama 3.1 model),
which were instructed to act as narrators, implementing a role-playing game
revolving around the murder of Austrian philosopher Moritz Schlick in 1936.
Results of the investigation include protocols of LLM-user interactions during
the game and qualitative conversations after the play experience to get insight
into the players' reactions to the game. In a quantitative analysis 115
introductory texts for role-playing generated by the LLMs were examined by
different methods of natural language processing, including semantic similarity
and sentiment analysis. While the qualitative player feedback allowed to
distinguish three distinct types of users, the quantitative text analysis
showed significant differences between how the different LLMs presented the
historical content. Our study thus adds to ongoing efforts to analyse LLM
performance, but also suggests a way of how these efforts can be disseminated
in a playful way to a general audience.

</details>


### [82] [Read the Room or Lead the Room: Understanding Socio-Cognitive Dynamics in Human-AI Teaming](https://arxiv.org/abs/2510.09944)
*Jaeyoon Choi,Mohammad Amin Samadi,Spencer JaQuay,Seehee Park,Nia Nixon*

Main category: cs.HC

TL;DR: 研究AI团队成员对人类-AI协作的社会认知动态影响，发现AI主要承担主导角色，但社会互动方面存在不足。


<details>
  <summary>Details</summary>
Motivation: 探讨当AI成为团队成员时，团队动态会如何变化，尤其在进行协作问题解决时人类与AI的互动。

Method: 通过人类-AI团队实验收集话语数据，并使用自然语言处理方法LIWC和GCA进行分析。

Result: AI作为团队成员通常扮演主导认知促进者的角色，但以社会上更为脱节的方式，推动议程时表现出冗长和重复的倾向。

Conclusion: 本研究揭示了学习分析在理解人类-人工智能协作的社会认知动态中的重要性。

Abstract: Research on Collaborative Problem Solving (CPS) has traditionally examined
how humans rely on one another cognitively and socially to accomplish tasks
together. With the rapid advancement of AI and large language models, however,
a new question emerge: what happens to team dynamics when one of the
"teammates" is not human? In this study, we investigate how the integration of
an AI teammate -- a fully autonomous GPT-4 agent with social, cognitive, and
affective capabilities -- shapes the socio-cognitive dynamics of CPS. We
analyze discourse data collected from human-AI teaming (HAT) experiments
conducted on a novel platform specifically designed for HAT research. Using two
natural language processing (NLP) methods, specifically Linguistic Inquiry and
Word Count (LIWC) and Group Communication Analysis (GCA), we found that AI
teammates often assumed the role of dominant cognitive facilitators, guiding,
planning, and driving group decision-making. However, they did so in a socially
detached manner, frequently pushing agenda in a verbose and repetitive way. By
contrast, humans working with AI used more language reflecting social
processes, suggesting that they assumed more socially oriented roles. Our study
highlights how learning analytics can provide critical insights into the
socio-cognitive dynamics of human-AI collaboration.

</details>


### [83] ["Can I Decorate My Teeth With Diamonds?": Exploring Multi-Stakeholder Perspectives on Using VR to Reduce Children's Dental Anxiety](https://arxiv.org/abs/2510.10019)
*Yaxuan Mao,Yanheng Li,Duo Gong,Pengcheng An,Yuhan Luo*

Main category: cs.HC

TL;DR: 本研究探讨了虚拟现实技术在缓解儿童牙科焦虑中的应用潜力及多方需求的相互影响。


<details>
  <summary>Details</summary>
Motivation: 儿童牙科焦虑普遍存在，可能导致治疗缺失及对心理健康的负面影响，因而寻找有效的缓解方法具有重要意义。

Method: 通过对13名10至12岁儿童的联合设计工作坊和对13名家长及两名牙医的访谈进行研究。

Result: 研究发现，儿童期待VR提供即时的心理慰藉与社交支持，家长希望VR能增强孩子对口腔健康的知识，而牙医则关注治疗的效率与安全性。

Conclusion: 虚拟现实（VR）技术有望通过满足儿童、家长和牙医的不同需求，帮助管理儿童的牙科焦虑。此外，VR的应用可扩展至其他治疗环境。

Abstract: Dental anxiety is prevalent among children, often leading to missed treatment
and potential negative effects on their mental well-being. While several
interventions (e.g., pharmacological and psychotherapeutic techniques) have
been introduced for anxiety alleviation, the recently emerged virtual reality
(VR) technology, with its immersive and playful nature, opened new
opportunities for complementing and enhancing the therapeutic effects of
existing interventions. In this light, we conducted a series of co-design
workshops with 13 children aged 10-12 to explore how they envisioned using VR
to address their fear and stress associated with dental visits, followed by
interviews with parents (n = 13) and two dentists. Our findings revealed that
children expected VR to provide immediate relief, social support, and a sense
of control during dental treatment, parents sought educational opportunities
for their children to learn about oral health, and dentists prioritized
treatment efficiency and safety issues. Drawing from the findings, we discuss
the considerations of multi-stakeholders for developing VR-assisted anxiety
management applications for children within and beyond dental settings.

</details>


### [84] [Between Knowledge and Care: Evaluating Generative AI-Based IUI in Type 2 Diabetes Management Through Patient and Physician Perspectives](https://arxiv.org/abs/2510.10048)
*Yibo Meng,Ruiqi Chen,Zhiming Liu,Xiaolan Ding,Yan Guan*

Main category: cs.HC

TL;DR: 本研究通过两部分混合方法，分析患者和医生对生成健康信息的评估，总结出AI在指导方面的优缺点，并提出设计应有的改进建议。


<details>
  <summary>Details</summary>
Motivation: 探讨病人和医生如何评估生成的健康信息的质量和可用性

Method: 两部分混合方法研究

Result: 发现AI在事实和生活方式指导方面存在优势，但在药物解读、情境推理和同理心方面存在显著不足。

Conclusion: 研究结果为交互式健康系统的设计提供了依据，建议多模型 orchestration、风险意识的回退机制，以及情感上更加贴合的沟通方式，以确保AI在慢性病护理中的可信赖性。

Abstract: Generative AI systems are increasingly adopted by patients seeking everyday
health guidance, yet their reliability and clinical appropriateness remain
uncertain. Taking Type 2 Diabetes Mellitus (T2DM) as a representative chronic
condition, this paper presents a two-part mixed-methods study that examines how
patients and physicians in China evaluate the quality and usability of
AI-generated health information. Study~1 analyzes 784 authentic patient
questions to identify seven core categories of informational needs and five
evaluation dimensions -- \textit{Accuracy, Safety, Clarity, Integrity}, and
\textit{Action Orientation}. Study~2 involves seven endocrinologists who assess
responses from four mainstream AI models across these dimensions. Quantitative
and qualitative findings reveal consistent strengths in factual and lifestyle
guidance but significant weaknesses in medication interpretation, contextual
reasoning, and empathy. Patients view AI as an accessible ``pre-visit
educator,'' whereas clinicians highlight its lack of clinical safety and
personalization. Together, the findings inform design implications for
interactive health systems, advocating for multi-model orchestration,
risk-aware fallback mechanisms, and emotionally attuned communication to ensure
trustworthy AI assistance in chronic disease care.

</details>


### [85] [ALLOY: Generating Reusable Agent Workflows from User Demonstration](https://arxiv.org/abs/2510.10049)
*Jiawen Li,Zheng Ning,Yuan Tian,Toby Jia-jun Li*

Main category: cs.HC

TL;DR: ALLOY系统通过自然演示提高了用户在复杂任务中的操作灵活性，超越了传统提示方法，展现了基于演示的交互的优势。


<details>
  <summary>Details</summary>
Motivation: 解决用户在指定复杂任务程序化要求时的困难，特别是在涉及个人偏好的任务中，例如社交媒体内容发布或旅行规划。

Method: 使用基于演示的交互方法，结合视觉化工作流程，增强用户在创建基于大型语言模型的网站代理的适应能力。

Result: 在与12名参与者的研究中，ALLOY的演示基础方法在捕捉用户意图和程序偏好方面超越了提示基础代理和手动工作流程。

Conclusion: ALLOY系统通过基于演示的方法在理解用户意图和程序偏好方面优于传统的提示基础方法，提供了更高的可适应性与操作透明度。

Abstract: Large language models (LLMs) enable end-users to delegate complex tasks to
autonomous agents through natural language. However, prompt-based interaction
faces critical limitations: Users often struggle to specify procedural
requirements for tasks, especially those that don't have a factually correct
solution but instead rely on personal preferences, such as posting social media
content or planning a trip. Additionally, a ''successful'' prompt for one task
may not be reusable or generalizable across similar tasks. We present ALLOY, a
system inspired by classical HCI theories on Programming by Demonstration
(PBD), but extended to enhance adaptability in creating LLM-based web agents.
ALLOY enables users to express procedural preferences through natural
demonstrations rather than prompts, while making these procedures transparent
and editable through visualized workflows that can be generalized across task
variations. In a study with 12 participants, ALLOY's demonstration--based
approach outperformed prompt-based agents and manual workflows in capturing
user intent and procedural preferences in complex web tasks. Insights from the
study also show how demonstration--based interaction complements the
traditional prompt-based approach.

</details>


### [86] [How AI Companionship Develops: Evidence from a Longitudinal Study](https://arxiv.org/abs/2510.10079)
*Angel Hsing-Chi Hwang,Fiona Li,Jacy Reese Anthis,Hayoun Noh*

Main category: cs.HC

TL;DR: 探讨AI伴侣对心理健康的影响，研究用户的心理模型如何影响伴侣体验，发现这些体验会在时间推移中演变。


<details>
  <summary>Details</summary>
Motivation: 研究AI伴侣对心理健康和社会关系的风险，以及人类与伴侣互动的因素如何相互作用和发展。

Method: Survey and longitudinal study

Result: 心理模型、拟人互动和参与感等变量相互关联，影响AI伴侣的体验；参与者对通用聊天机器人的看法在3周内大幅融入自身伴侣的感知。

Conclusion: 提出了一个关于AI陪伴发展的纵向模型，并展示了研究人类-人工智能伴侣关系的实证方法。

Abstract: The quickly growing popularity of AI companions poses risks to mental health,
personal wellbeing, and social relationships. Past work has identified many
individual factors that can drive human-companion interaction, but we know
little about how these factors interact and evolve over time. In Study 1, we
surveyed AI companion users (N = 303) to map the psychological pathway from
users' mental models of the agent to parasocial experiences, social
interaction, and the psychological impact of AI companions. Participants'
responses foregrounded multiple interconnected variables (agency, parasocial
interaction, and engagement) that shape AI companionship. In Study 2, we
conducted a longitudinal study with a subset of participants (N = 110) using a
new generic chatbot. Participants' perceptions of the generic chatbot
significantly converged to perceptions of their own companions by Week 3. These
results suggest a longitudinal model of AI companionship development and
demonstrate an empirical method to study human-AI companionship.

</details>


### [87] [BrainForm: a Serious Game for BCI Training and Data Collection](https://arxiv.org/abs/2510.10169)
*Michele Romani,Devis Zanoni,Elisabetta Farella,Luca Turchet*

Main category: cs.HC

TL;DR: BrainForm是一个易于使用的游戏化脑机接口训练系统，能有效提高用户参与度并促进技能学习。


<details>
  <summary>Details</summary>
Motivation: 开发一种可扩展的脑机接口训练系统，以便进行数据收集并提高用户参与度。

Method: 通过多轮实验和任务复杂度调整，对用户在不同视觉刺激下的表现和反馈进行分析。

Result: 验证了用户在重复训练中的BCI控制技能发展，以及不同视觉刺激纹理对感知和性能的影响。

Conclusion: BrainForm作为一种可扩展的BCI研究工具，展现了其用户友好性，并提出了促进持续参与和减少训练疲劳的建议。

Abstract: $\textit{BrainForm}$ is a gamified Brain-Computer Interface (BCI) training
system designed for scalable data collection using consumer hardware and a
minimal setup. We investigated (1) how users develop BCI control skills across
repeated sessions and (2) perceptual and performance effects of two visual
stimulation textures. Game Experience Questionnaire (GEQ) scores for Flow},
Positive Affect, Competence and Challenge were strongly positive, indicating
sustained engagement. A within-subject study with multiple runs, two task
complexities, and post-session questionnaires revealed no significant
performance differences between textures but increased ocular irritation over
time. Online metrics$\unicode{x2013}$Task Accuracy, Task Time, and Information
Transfer Rate$\unicode{x2013}$improved across sessions, confirming learning
effects for symbol spelling, even under pressure conditions. Our results
highlight the potential of $\textit{BrainForm}$ as a scalable, user-friendly
BCI research tool and offer guidance for sustained engagement and reduced
training fatigue.

</details>


### [88] [Chord Colourizer: A Near Real-Time System for Visualizing Musical Key](https://arxiv.org/abs/2510.10173)
*Paul Haimes*

Main category: cs.HC

TL;DR: 本研究介绍了一个名为Chord Colourizer的系统，它通过色彩可视化音乐和声，具有创新和实时的用户互动特点，但面临延迟和和弦复杂性检测的挑战。


<details>
  <summary>Details</summary>
Motivation: 旨在通过将音乐音高与色彩关联，提升用户对和声内容的互动，并为教育和艺术表演提供创新的可能性。

Method: 使用常数Q变换（CQT）色度特征进行和弦估计及可视化，结合基于阈值的过滤和音调增强。

Result: 系统能够实时检测音频信号的音乐调性，并通过视觉表示和 LED 显示提供多模态反馈，增强用户体验。

Conclusion: Chord Colourizer 展示了一种创新的多模态系统，能够以动态和直观的方式展示音乐和色彩的关系，但仍需解决某些限制以增强其功能。

Abstract: This paper introduces Chord Colourizer, a near real-time system that detects
the musical key of an audio signal and visually represents it through a novel
graphical user interface (GUI). The system assigns colours to musical notes
based on Isaac Newton's original colour wheel, preserving historical links
between pitch and hue, and also integrates an Arduino-controlled LED display
using 3D-printed star-shaped diffusers to offer a physical ambient media
representation. The method employs Constant-Q Transform (CQT) chroma features
for chord estimation and visualization, followed by threshold-based filtering
and tonal enhancement to isolate the root, third, and fifth. A confidence score
is computed for each detection to ensure reliability, and only chords with
moderate to very strong certainty are visualized. The graphical interface
dynamically updates a colour-coded keyboard layout, while the LED display
provides the same colour information via spatial feedback. This multi-modal
system enhances user interaction with harmonic content, offering innovative
possibilities for education and artistic performance. Limitations include
slight latency and the inability to detect extended chords, which future
development will aim to address through refined filtering, adaptive thresholds,
and support for more complex harmonies such as sevenths and augmented chords.
Future work will also explore integration with alternative visualization
styles, and the comparison of audio analysis libraries to improve detection
speed and precision. Plans also include formal user testing to evaluate
perception, usability, and cross-cultural interpretations of colour-pitch
mappings.

</details>


### [89] [Revisiting Trust in the Era of Generative AI: Factorial Structure and Latent Profiles](https://arxiv.org/abs/2510.10199)
*Haocan Sun,Weizi Liu,Di Wu,Guoming Yu,Mike Yao*

Main category: cs.HC

TL;DR: 本研究开发了HAITS量表，整合信任的理性与情感维度，为生成式AI的信任测量提供了新的方法和见解。


<details>
  <summary>Details</summary>
Motivation: 研究信任在人工智能（AI）采用和依赖中的重要性，特别是社交和情感维度在生成式AI系统中的相关性。

Method: 通过对信任理论的回顾、定性访谈和两轮大规模调查，利用探索性和验证性因素分析识别信任的四个关键维度，并应用潜在剖面分析分类用户的信任特征。

Result: 提出并验证了人机信任量表（HAITS），能够同时捕捉理性和关系性的信任维度。

Conclusion: 该研究为测量生成式AI中的信任提供了一个有效且具有文化敏感性的工具，并为信任在人工智能互动中的演变提供了新见解。

Abstract: Trust is one of the most important factors shaping whether and how people
adopt and rely on artificial intelligence (AI). Yet most existing studies
measure trust in terms of functionality, focusing on whether a system is
reliable, accurate, or easy to use, while giving less attention to the social
and emotional dimensions that are increasingly relevant for today's generative
AI (GenAI) systems. These systems do not just process information; they
converse, respond, and collaborate with users, blurring the line between tool
and partner. In this study, we introduce and validate the Human-AI Trust Scale
(HAITS), a new measure designed to capture both the rational and relational
aspects of trust in GenAI. Drawing on prior trust theories, qualitative
interviews, and two waves of large-scale surveys in China and the United
States, we used exploratory (n = 1,546) and confirmatory (n = 1,426) factor
analyses to identify four key dimensions of trust: Affective Trust, Competence
Trust, Benevolence & Integrity, and Perceived Risk. We then applied latent
profile analysis to classify users into six distinct trust profiles, revealing
meaningful differences in how affective-competence trust and trust-distrust
frameworks coexist across individuals and cultures. Our findings offer a
validated, culturally sensitive tool for measuring trust in GenAI and provide
new insight into how trust evolves in human-AI interaction. By integrating
instrumental and relational perspectives of trust, this work lays the
foundation for more nuanced research and design of trustworthy AI systems.

</details>


### [90] [Exploration of Embodied Space Experience through Umbilical Interaction: A Grounded Theory Approach](https://arxiv.org/abs/2510.10258)
*Shuai Guo,Dawei Liu,Tiantian Zheng*

Main category: cs.HC

TL;DR: 本研究批判人本设计局限，提出Umbilink作为新接口设计，探索其在疗愈、冥想和睡眠中的应用


<details>
  <summary>Details</summary>
Motivation: 批判人本中心设计的局限，倡导接口中心设计转变

Method: 通过半结构化访谈与扎根理论分析参与者体验

Result: 提出了Umbilical Interaction这一新型接口类型，并阐明了物质化接口在人与接口环境关系中的认知价值

Conclusion: 此设计为未来接口研究提供了一种具想象力的工具，并暗示出新的应用方向。

Abstract: This paper critiques the limits of human-centered design in HCI, proposing a
shift toward Interface-Centered Design. Drawing on Hookway's philosophy of
interfaces, phenomenology, and embodied interaction, we created Umbilink, an
umbilical interaction device simulating a uterine environment with tactile
sensors and rhythmic feedback to induce a pre-subjectivized state of sensory
reduction. Participants' experiences were captured through semi-structured
interviews and analyzed with grounded theory. Our contributions are: (1)
introducing the novel interface type of Umbilical Interaction; (2)
demonstrating the cognitive value of materialized interfaces in a
human-interface-environment relation; (3) highlighting the design role of
wearing rituals as liminal experiences. As a pilot study, this design suggests
imaginative applications in healing, meditation, and sleep, while offering a
speculative tool for future interface research.

</details>


### [91] [Unveiling Gamer Archetypes through Multi modal feature Correlations and Unsupervised Learning](https://arxiv.org/abs/2510.10263)
*Moona Kanwal,Muhammad Sami Siddiqui,Syed Anael Ali*

Main category: cs.HC

TL;DR: 本研究提出了一种新颖的数据驱动框架，结合心理和行为分析，通过机器学习识别游戏玩家的不同类型，实现更好的游戏设计和玩家支持。


<details>
  <summary>Details</summary>
Motivation: 提供关于游戏玩家的重要见解，以便进行自适应游戏设计、行为理解和数字健康管理

Method: 结合心理测量、行为分析和机器学习的集成数据驱动框架

Result: 识别出四种游戏玩家原型：沉浸社交寻求者、纪律优化者、战略系统导航者和竞争团队建设者

Conclusion: 该研究提供了一个可重现的分析管道，将相关性驱动的网络洞见与无监督学习结合，不仅提高了分类准确性，还能全面联系游戏动机与心理健康结果。

Abstract: Profiling gamers provides critical insights for adaptive game design,
behavioral understanding, and digital well-being. This study proposes an
integrated, data-driven framework that combines psychological measures,
behavioral analytics, and machine learning to reveal underlying gamer personas.
A structured survey of 250 participants, including 113 active gamers, captured
multidimensional behavioral, motivational, and social data. The analysis
pipeline integrated feature engineering, association-network, knowledge-graph
analysis, and unsupervised clustering to extract meaningful patterns.
Correlation statistics uses Cramers V, Tschuprows T, Theils U, and Spearmans
quantified feature associations, and network centrality guided feature
selection. Dimensionality-reduction techniques such as PCA, SVD, t-SNE are
coupled with clustering algorithms like K-Means, Agglomerative, Spectral,
DBSCAN, evaluated using Silhouette, Calinski Harabasz, and Davies Bouldin
indices. The PCA with K-Means with k = 4 model achieved optimal cluster quality
with Silhouette = 0.4, identifying four archetypes as Immersive Social
Story-Seekers, Disciplined Optimizers, Strategic Systems Navigators, and
Competitive Team-Builders. This research contributes a reproducible pipeline
that links correlation-driven network insights with unsupervised learning. The
integration of behavioral correlation networks with clustering not only
enhances classification accuracy but also offers a holistic lens to connect
gameplay motivations with psychological and wellness outcomes.

</details>


### [92] [Measuring What Matters: Connecting AI Ethics Evaluations to System Attributes, Hazards, and Harms](https://arxiv.org/abs/2510.10339)
*Shalaleh Rismani,Renee Shelby,Leah Davis,Negar Rostamzadeh,AJung Moon*

Main category: cs.HC

TL;DR: 本文检视AI系统评估措施的片面性，提出需要更系统的整体理解来评估道德与社会影响。


<details>
  <summary>Details</summary>
Motivation: 评估AI系统的社会和伦理影响的现有措施存在碎片化的问题，亟需明确其在AI系统中的定位。

Method: 进行了范围审查，分析了近800个与11个AI伦理原则相关的衡量标准。

Result: 发现大多数措施侧重于公平性、透明性、隐私和信任等四个原则，主要评估模型或输出系统组件。

Conclusion: 当前的评估实践仍然支离破碎，仅从零散的角度衡量，而未能捕捉到在整个系统中出现的伤害。

Abstract: Over the past decade, an ecosystem of measures has emerged to evaluate the
social and ethical implications of AI systems, largely shaped by high-level
ethics principles. These measures are developed and used in fragmented ways,
without adequate attention to how they are situated in AI systems. In this
paper, we examine how existing measures used in the computing literature map to
AI system components, attributes, hazards, and harms. Our analysis draws on a
scoping review resulting in nearly 800 measures corresponding to 11 AI ethics
principles. We find that most measures focus on four principles - fairness,
transparency, privacy, and trust - and primarily assess model or output system
components. Few measures account for interactions across system elements, and
only a narrow set of hazards is typically considered for each harm type. Many
measures are disconnected from where harm is experienced and lack guidance for
setting meaningful thresholds. These patterns reveal how current evaluation
practices remain fragmented, measuring in pieces rather than capturing how
harms emerge across systems. Framing measures with respect to system
attributes, hazards, and harms can strengthen regulatory oversight, support
actionable practices in industry, and ground future research in systems-level
understanding.

</details>


### [93] [Personalized Motion Guidance Framework for Athlete-Centric Coaching](https://arxiv.org/abs/2510.10496)
*Ryota Takamidoa,Chiharu Suzukia,Hiroki Nakamoto*

Main category: cs.HC

TL;DR: 本研究开发了一种个性化运动指导框架（PMGF），利用生成性人工智能技术为运动员生成个性化的运动优化指导，以提升运动表现。


<details>
  <summary>Details</summary>
Motivation: 当今体育科学面临将实验室数据转化为个性化运动指导的挑战，本研究旨在缩小这一差距。

Method: 研究利用垂直自编码器编码运动序列，结合两种操控策略（光滑插值与局部优化），生成个性化运动指导。

Result: 验证实验表明，PMGF在1275对投手中成功生成运动模式的平滑过度，且改变后的特征与已知的提升运动表现的特征相符。

Conclusion: PMGF能有效生成运动模式之间的平滑过渡，并引入生物力学上合理的改进特征，表明其在运动指导中的实用性和潜力。

Abstract: A critical challenge in contemporary sports science lies in filling the gap
between group-level insights derived from controlled hypothesis-driven
experiments and the real-world need for personalized coaching tailored to
individual athletes' unique movement patterns. This study developed a
Personalized Motion Guidance Framework (PMGF) to enhance athletic performance
by generating individualized motion-refinement guides using generative
artificial intelligence techniques. PMGF leverages a vertical autoencoder to
encode motion sequences into athlete-specific latent representations, which can
then be directly manipulated to generate meaningful guidance motions. Two
manipulation strategies were explored: (1) smooth interpolation between the
learner's motion and a target (e.g., expert) motion to facilitate observational
learning, and (2) shifting the motion pattern in an optimal direction in the
latent space using a local optimization technique. The results of the
validation experiment with data from 51 baseball pitchers revealed that (1)
PMGF successfully generated smooth transitions in motion patterns between
individuals across all 1,275 pitcher pairs, and (2) the features significantly
altered through PMGF manipulations reflected known performance-enhancing
characteristics, such as increased stride length and knee extension associated
with higher ball velocity, indicating that PMGF induces biomechanically
plausible improvements. We propose a future extension called general-PMGF to
enhance the applicability of this framework. This extension incorporates
bodily, environmental, and task constraints into the generation process, aiming
to provide more realistic and versatile guidance across diverse sports
contexts.

</details>


### [94] [Assessing Policy Updates: Toward Trust-Preserving Intelligent User Interfaces](https://arxiv.org/abs/2510.10616)
*Matan Solomon,Ofra Amir,Omer Ben-Porat*

Main category: cs.HC

TL;DR: 研究探讨了强化学习中如何通过不同展示策略评估模型更新的有效性，发现显著对比显示策略最有效。


<details>
  <summary>Details</summary>
Motivation: 强化学习中人类反馈的更新可能不可靠，因此评估更新效果成为设计智能用户界面时的重要挑战。

Method: 通过在一个网格世界中，参与者给代理提供反馈，并比较其原始和更新后的策略，评估不同的展示策略。

Result: 本研究探讨了在强化学习中使用人类反馈更新模型时可能面临的挑战，尤其是如何评估多模型更新而不仅仅是单一模型。通过一个控制实验，研究者评估了四种不同的更新展示策略，并发现显著对比展示能够有效提高参与者对模型更新效果的判断能力。

Conclusion: 显著对比展示不仅提高了参与者识别更新是否有益的能力，还帮助修正了他们对反馈的信任偏差。

Abstract: Reinforcement learning agents are often updated with human feedback, yet such
updates can be unreliable: reward misspecification, preference conflicts, or
limited data may leave policies unchanged or even worse. Because policies are
difficult to interpret directly, users face the challenge of deciding whether
an update has truly helped. We propose that assessing model updates -- not just
a single model -- is a critical design challenge for intelligent user
interfaces. In a controlled study, participants provided feedback to an agent
in a gridworld and then compared its original and updated policies. We
evaluated four strategies for communicating updates: no demonstration,
same-context, random-context, and salient-contrast demonstrations designed to
highlight informative differences. Salient-contrast demonstrations
significantly improved participants' ability to detect when updates helped or
harmed performance, mitigating participants' bias towards assuming that
feedback is always beneficial, and supported better trust calibration across
contexts.

</details>


### [95] [Informative Keyboard and its Application to Raise Awareness of Smartphone Use](https://arxiv.org/abs/2510.10710)
*Jaroslaw Domaszewicz,Damian Sienicki,Michal Obirek*

Main category: cs.HC

TL;DR: 本论文提出了一种创新的智能手机键盘，允许用户在输入文本时接收其设备使用情况的反馈，旨在简化对使用量的管理。


<details>
  <summary>Details</summary>
Motivation: 为了解决智能手机过度使用带来的个人和社会问题，提供一种无需复杂配置的解决方案。

Method: 通过智能手机的键盘提供与使用量相关的实时反馈。

Result: 提出了一种新的键盘交互方式，用户在输入时能够获得智能手机使用的高层次、定性的反馈。

Conclusion: 这种信息丰富的键盘方法为智能手机使用管理提供了一种新颖且低认知负担的方式，具有潜在的多种应用。

Abstract: Excessive smartphone use is now widely considered a personal and societal
problem. It is recognized by application and smartphone makers, who provide
tools to track the amount of use, set limits, or block certain services at
predefined times. These tools, while powerful, may require significant
cognitive effort to operate: configuration parameters need to be set, and
captured statistics need to be analyzed. To offer a complementary solution, we
propose a radically different approach. We employ the keyboard of a smartphone
as an output device. With each press of a key, the user is given a high-level,
qualitative, color-encoded estimate of the amount of recent smartphone use. The
technique, dubbed the informative keyboard, is a case of implicit interaction:
the user's intention is to enter text but, while typing, they receive the
feedback. In the paper, we elaborate the concept, identify design decisions,
describe our implementation, present the outcome of a questionnaire-based
evaluation, and point to some other applications of the informative keyboard.

</details>


### [96] [Therapeutic AI and the Hidden Risks of Over-Disclosure: An Embedded AI-Literacy Framework for Mental Health Privacy](https://arxiv.org/abs/2510.10805)
*Soraya S. Anvari,Rina R. Wehbe*

Main category: cs.HC

TL;DR: 大型语言模型的心理健康应用虽提高了可达性，但也带来了隐私和安全挑战，需通过AI素养干预来增强用户信任和保障信息披露安全。


<details>
  <summary>Details</summary>
Motivation: 确定大型语言模型在心理健康应用中的隐私和安全挑战，尤其是在缺乏临床指导的情况下用户可能过度披露个人信息的问题。

Method: 提出了一个框架，计划通过研究评估AI素养干预对用户在心理健康对话系统中的体验影响。

Result: 识别出LLM在心理健康领域使用时的隐私风险、潜在偏见和数据误用问题，强调了加强用户对AI的理解的重要性。

Conclusion: 提出在心理健康对话系统中嵌入人工智能素养干预的框架，并计划评估其对信息披露安全、信任及用户体验的影响。

Abstract: Large Language Models (LLMs) are increasingly deployed in mental health
contexts, from structured therapeutic support tools to informal chat-based
well-being assistants. While these systems increase accessibility, scalability,
and personalization, their integration into mental health care brings privacy
and safety challenges that have not been well-examined. Unlike traditional
clinical interactions, LLM-mediated therapy often lacks a clear structure for
what information is collected, how it is processed, and how it is stored or
reused. Users without clinical guidance may over-disclose personal information,
which is sometimes irrelevant to their presenting concern, due to misplaced
trust, lack of awareness of data risks, or the conversational design of the
system. This overexposure raises privacy concerns and also increases the
potential for LLM bias, misinterpretation, and long-term data misuse. We
propose a framework embedding Artificial Intelligence (AI) literacy
interventions directly into mental health conversational systems, and outline a
study plan to evaluate their impact on disclosure safety, trust, and user
experience.

</details>


### [97] [SusBench: An Online Benchmark for Evaluating Dark Pattern Susceptibility of Computer-Use Agents](https://arxiv.org/abs/2510.11035)
*Longjie Guo,Chenjie Yuan,Mingyuan Zhong,Robert Wolfe,Ruican Zhong,Yue Xu,Bingbing Wen,Hua Shen,Lucy Lu Wang,Alexis Hiniker*

Main category: cs.HC

TL;DR: 本文介绍了SusBench，一个评估计算机使用代理对用户界面黑暗模式脆弱性的在线基准，发现参与者和代理对某些黑暗模式特别敏感，研究结果对开发可信的CUAs和在线环境的监管具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 随着基于LLM的计算机使用代理越来越多地与现实世界界面进行自主交互，理解它们对操控性界面设计的脆弱性变得至关重要。

Method: 我们开发了一个基于代码注入的方法，在真实消费者网站上构建了313个黑暗模式评估任务，并使用29名参与者进行了研究。

Result: 本研究引入了SusBench，一个在线基准，用于评估基于大语言模型的计算机使用代理（CUAs）在面对用户界面（UI）黑暗模式时的脆弱性。我们设计了一种方法，通过代码注入在真实世界的消费者网站上构建可信的黑暗模式，并在55个网站上设计了313个评估任务。参与者的研究显示，人类对我们的黑暗模式注入的感知高度真实，大多数参与者没有意识到这些模式是研究团队注入的。我们评估了五种最先进的CUAs，并发现人工参与者和代理特别容易受到预选、技巧用词和隐性信息这些黑暗模式的影响，而对其他明显的黑暗模式则表现出较强的抵抗力。

Conclusion: 我们的研究结果为开发更可信的计算机使用代理提供了重要的见解，并对如何评估和规制日益由自主代理导航的在线环境提出了建议。

Abstract: As LLM-based computer-use agents (CUAs) begin to autonomously interact with
real-world interfaces, understanding their vulnerability to manipulative
interface designs becomes increasingly critical. We introduce SusBench, an
online benchmark for evaluating the susceptibility of CUAs to UI dark patterns,
designs that aim to manipulate or deceive users into taking unintentional
actions. Drawing nine common dark pattern types from existing taxonomies, we
developed a method for constructing believable dark patterns on real-world
consumer websites through code injections, and designed 313 evaluation tasks
across 55 websites. Our study with 29 participants showed that humans perceived
our dark pattern injections to be highly realistic, with the vast majority of
participants not noticing that these had been injected by the research team. We
evaluated five state-of-the-art CUAs on the benchmark. We found that both human
participants and agents are particularly susceptible to the dark patterns of
Preselection, Trick Wording, and Hidden Information, while being resilient to
other overt dark patterns. Our findings inform the development of more
trustworthy CUAs, their use as potential human proxies in evaluating deceptive
designs, and the regulation of an online environment increasingly navigated by
autonomous agents.

</details>


### [98] [UXer-AI Collaboration Process for Enhancing Trust](https://arxiv.org/abs/2510.11087)
*Harin Yoon,Dongwhan Kim,Changhoon Oh,Soojin Jun*

Main category: cs.HC

TL;DR: 本研究开发了TW-AI模型，以提升UX设计中的AI合作效率，通过增强的验证措施解决信任问题，并制定相关的设计指南和框架。


<details>
  <summary>Details</summary>
Motivation: 为了解决当前AI在UX设计中应用不足的问题，尤其是信任和支持的缺失，通过有效的UX者与AI合作策略提升设计效率。

Method: 通过用户研究和参与式设计工作坊，识别UX者与AI合作的主要障碍，并开发了TW-AI模型进行验证。

Result: TW-AI模型在任务表现、信任度、工作效率和决策时间上都有显著提升，尤其是源功能通过RAG技术增强了AI工具的可靠性。

Conclusion: 本研究提出了一种有效的UX者与AI协作的新模型TW-AI，显著提升了用户的信任度和工作效率，实现了更好的决策和控制能力。

Abstract: In recent years, discussions on integrating Artificial Intelligence (AI) into
UX design have intensified. However, the practical application of AI tools in
design is limited by their operation within overly simplified scenarios,
inherent complexity and unpredictability, and a general lack of relevant
education. This study proposes an effective UXer-AI collaboration process to
address these issues and seeks to identify efficient AI collaboration
strategies through a series of user studies. In a preliminary study, two
participatory design workshops identified major barriers to UXer-AI
collaboration, including unfamiliarity with AI, inadequate internal support,
and trust issues. To address the particularly critical issue of diminished
trust, this study developed a new AI prototype model, TW-AI, that incorporates
verification and decision-making processes to enhance trust and operational
efficiency in UX design tasks. Task performance experiments and in-depth
interviews evaluated the TW-AI model, revealing significant improvements in
practitioners' trust, work efficiency, understanding of usage timing, and
controllability. The "Source" function, based on Retrieval-Augmented Generation
(RAG) technology, notably enhanced the reliability of the AI tool. Participants
noted improved communication efficiency and reduced decision-making time,
attributing these outcomes to the model's comprehensive verification features
and streamlined approach to complex verification tasks. This study advances
UXer-AI collaboration by providing key insights, bridging research and practice
with actionable strategies, and establishing guidelines for AI tool designs
tailored to UX. It contributes to the HCI community by outlining a scalable
UXer-AI collaboration framework that addresses immediate operational challenges
and lays the foundation for future advancements in AI-driven UX methodologies.

</details>


### [99] [Principles of Safe AI Companions for Youth: Parent and Expert Perspectives](https://arxiv.org/abs/2510.11185)
*Yaman Yu,Mohi,Aishi Debroy,Xin Cao,Karen Rudolph,Yang Wang*

Main category: cs.HC

TL;DR: 研究探讨了父母和专家对青少年与AI伴侣互动的评估，强调风险因素和介入建议。


<details>
  <summary>Details</summary>
Motivation: 随着AI伴侣在青少年中日益流行，亟需了解家长和专家如何看待这些互动及所需的保护措施。

Method: 通过对26个半结构化访谈的分析，研究了父母和专家对青少年与GenAI伴侣对话的评估和建议。

Result: 本研究揭示了父母和发展心理学专家在评估青少年与AI伴侣互动时的不同关注点和建议。

Conclusion: 本研究为AI伴侣设计中的安全嵌入提供了方向，强调了父母和专家在风险评估和介入方面的不同看法。

Abstract: AI companions are increasingly popular among teenagers, yet current platforms
lack safeguards to address developmental risks and harmful normalization.
Despite growing concerns, little is known about how parents and developmental
psychology experts assess these interactions or what protections they consider
necessary. We conducted 26 semi structured interviews with parents and experts,
who reviewed real world youth GenAI companion conversation snippets. We found
that stakeholders assessed risks contextually, attending to factors such as
youth maturity, AI character age, and how AI characters modeled values and
norms. We also identified distinct logics of assessment: parents flagged single
events, such as a mention of suicide or flirtation, as high risk, whereas
experts looked for patterns over time, such as repeated references to self harm
or sustained dependence. Both groups proposed interventions, with parents
favoring broader oversight and experts preferring cautious, crisis-only
escalation paired with youth facing safeguards. These findings provide
directions for embedding safety into AI companion design.

</details>


### [100] [Learning Hanzi Character Through VR-Based Mortise-Tenon](https://arxiv.org/abs/2510.11264)
*Conglin Ma,Jiatong Li,Sen-Zhe Xu,Ju Dai,Jie Liu,Feng Zhou*

Main category: cs.HC

TL;DR: 本文介绍了一种新颖的虚拟现实系统，通过将汉字的学习与传统工艺相结合，提升了对汉字的理解和记忆保持，同时有助于无形文化遗产的保护。


<details>
  <summary>Details</summary>
Motivation: 解决数字学习中汉字字符记忆抽象化的挑战，通过互动性来加深学习者的理解和记忆。

Method: 采用VR技术结合传统的榫卯结构，以交互式的方式让学习者组装汉字的笔画序列，利用6DoF空间跟踪和语言模型进行形态分析。

Result: 增强了学习者的参与感和记忆保持率，同时保护了无形文化遗产。

Conclusion: 该系统通过创新的VR体验与传统工艺相结合，增强了学习者对汉字构造的理解，从而提升了记忆保持率，并促进了对文化遗产的传承。

Abstract: This paper introduces a novel VR-based system that redefines the acquisition
of Hanzi character literacy by integrating traditional mortise-tenon joinery
principles (HVRMT).Addressing the challenge of abstract character memorization
in digital learning,our system deconstructs Hanzi components into interactive
"structural radicals"akin to wooden joint modules.Leveraging PICO's 6DoF
spatial tracking and LLM's morphological analysis,learners assemble stroke
sequences with haptic feedback simulating wood-to-wood friction.Our system also
supports multiplayer online experiences, enhancing engagement and memory
retention while preserving intangible cultural heritage. This innovative
approach not only enhances engagement and memory retention but also
reconstructs the craft wisdom embedded in Chinese writing systems, offering new
pathways for preserving intangible cultural heritage in digital ecosystems.For
the demo,please refer to this link{https://youtu.be/oUwfFTRpFyo}.

</details>


### [101] [Proceedings of the Access InContext Workshop @ CHI'25 Conference on Human Factors in Computing Systems](https://arxiv.org/abs/2510.11280)
*Patricia Piedade*

Main category: cs.HC

TL;DR: 本文记录了2025年CHI'25会议上Access InContext研讨会的内容。


<details>
  <summary>Details</summary>
Motivation: 本研讨会旨在探讨人机交互中的可获取性问题，促进学术界和产业界的深入交流。

Method: 会议记录总结了与会者的发言和讨论，涵盖了多种相关议题。

Result: 这篇论文是关于2025年在日本横滨举行的CHI'25人机交互领域会议的Access InContext研讨会的会议记录。

Conclusion: 该研讨会为人机交互领域的研究提供了新的视角和主题，促进了相关领域的交流与合作。

Abstract: This is the Proceedings of the Access InContext Workshop, which was held at
the CHI'25 Conference on Human Factors in Computing Systems, in Yokohama,
Japan, on April 26th 2025.

</details>


### [102] [Beyond touch-based HMI: Control your machines in natural language by utilizing large language models and OPC UA](https://arxiv.org/abs/2510.11300)
*Bernd Hofmann,Sven Kreitlein,Joerg Franke,Patrick Bruendl*

Main category: cs.HC

TL;DR: 本研究提出了一种基于大型语言模型和OPC UA标准的自然语言交互方法，成功提高了机器控制的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 旨在替代当前的触摸交互方式，通过语音或文本与机器互动，实现更直观的用户操作体验。

Method: 通过使用大型语言模型与OPC UA通信标准，结合预定义工具选择来控制机器，进行自然语言交互。

Result: 评估结果表明，专有的GPT 5模型准确率在96.0%至98.0%之间，开放权重模型达到90.0%的准确率，显示了高成功率。

Conclusion: 提出的基于代理的方法在工业人机界面中，促进了更自然的交互方式，提高了指令执行的准确性。

Abstract: This paper proposes an agent-based approach toward a more natural interface
between humans and machines. Large language models equipped with tools and the
communication standard OPC UA are utilized to control machines in natural
language. Instead of touch interaction, which is currently the state-of-the-art
medium for interaction in operations, the proposed approach enables operators
to talk or text with machines. This allows commands such as 'Please decrease
the temperature by 20 % in machine 1 and set the motor speed to 5000 rpm in
machine 2.' The large language model receives the user input and selects one of
three predefined tools that connect to an OPC UA server and either change or
read the value of a node. Afterwards, the result of the tool execution is
passed back to the language model, which then provides a final response to the
user. The approach is universally designed and can therefore be applied to any
machine that supports the OPC UA standard. The large language model is neither
fine-tuned nor requires training data, only the relevant machine credentials
and a parameter dictionary are included within the system prompt. The approach
is evaluated on a Siemens S7-1500 programmable logic controller with four
machine parameters in a case study of fifty synthetically generated commands on
five different models. The results demonstrate high success rate, with
proprietary GPT 5 models achieving accuracies between 96.0 % and 98.0 %, and
open-weight models reaching up to 90.0 %. The proposed approach of this
empirical study contributes to advancing natural interaction in industrial
human-machine interfaces.

</details>


### [103] [Exploring Artificial Intelligence and Culture: Methodology for a comparative study of AI's impact on norms, trust, and problem-solving across academic and business environments](https://arxiv.org/abs/2510.11530)
*Matthias Huemmer,Theophile Shyiramunda,Michelle J. Cummings-Koether*

Main category: cs.HC

TL;DR: 本论文研究AI与人类认知、问题解决及文化适应的双向关系，采用纵向研究设计探讨AI知识、信任及文化反应的变化，揭示AI采用的不同阶段及其对学术和商业环境的影响。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在填补关键空白，探讨在学术和商业背景下，AI如何改变认知过程以及文化和制度因素如何影响其采纳和信任。

Method: 研究采用三波纵向设计，结合定量纵向建模与定性主题分析，捕捉AI采纳中的时间、结构和文化模式。

Result: 本研究提出了一个严格的框架，以研究人工智能（AI）、人类认知、问题解决和文化适应之间的双向关系。其核心内容探讨了AI如何重新塑造认知过程和组织规范，以及文化价值观和制度背景如何影响AI的采用、信任和使用。

Conclusion: 通过追踪AI的文化适应过程，本研究揭示了不同环境下的信任曲线和问题解决策略，为人本、文化响应的AI战略提供了可操作的基础，支持基于证据的政策、培训和治理。

Abstract: This paper proposes a rigorous framework to examine the two-way relationship
between artificial intelligence (AI), human cognition, problem-solving, and
cultural adaptation across academic and business settings. It addresses a key
gap by asking how AI reshapes cognitive processes and organizational norms, and
how cultural values and institutional contexts shape AI adoption, trust, and
use over time. We employ a three-wave longitudinal design that tracks AI
knowledge, perceived competence, trust trajectories, and cultural responses.
Participants span academic institutions and diverse firms, enabling contextual
comparison. A dynamic sample continuous, intermittent, and wave-specific
respondents mirrors real organizational variability and strengthens ecological
validity. Methodologically, the study integrates quantitative longitudinal
modeling with qualitative thematic analysis to capture temporal, structural,
and cultural patterns in AI uptake. We trace AI acculturation through phases of
initial resistance, exploratory adoption, and cultural embedding, revealing
distinctive trust curves and problem-solving strategies by context: academic
environments tend to collaborative, deliberative integration; business
environments prioritize performance, speed, and measurable outcomes. Framing
adoption as bidirectional challenges deterministic views: AI both reflects and
reconfigures norms, decision-making, and cognitive engagement. As the first
comparative longitudinal study of its kind, this work advances methodological
rigor and offers actionable foundations for human-centred, culturally
responsive AI strategies-supporting evidence-based policies, training, and
governance that align cognitive performance, organizational goals, and ethical
commitments.

</details>


### [104] [GlobalizeEd: A Multimodal Translation System that Preserves Speaker Identity in Academic Lectures](https://arxiv.org/abs/2510.11596)
*Hoang-Son Vo,Karina Kolmogortseva,Ngumimi Karen Iyortsuun,Hong-Duyen Vo,Soo-Hyung Kim*

Main category: cs.HC

TL;DR: 研究表明GlobalizeEds的配音格式在认知负担和沉浸式学习体验上优于传统字幕，尽管学习效果相当，但所有参与者都重视保持讲者声音的能力，增强了真实性。


<details>
  <summary>Details</summary>
Motivation: 解决仅以原语言发布的学术内容对全球学生社区的获取障碍，尤其是在历史、文化和艺术等领域。

Method: 通过包含36名参与者的混合方法研究，评估不同翻译格式对学习体验的影响。

Result: GlobalizeEds的配音格式显著降低了认知负担，提供了比传统字幕更沉浸的学习体验，参与者对保留讲者声音的能力评价较高。

Conclusion: 提出了一种以人为本的AI框架用于跨语言教育，展示了多模态翻译系统如何在语言忠实性和文化适应性之间找到平衡，从而创造更具包容性的全球学习体验。

Abstract: A large amount of valuable academic content is only available in its original
language, creating a significant access barrier for the global student
community. This is a challenge for translating in several subjects, such as
history, culture, and the arts, where current automated subtitle tools fail to
convey the appropriate pedagogical tone and specialized meaning. In addition,
reading traditional automated subtitles increases cognitive load and leads to a
disconnected learning experience. Through a mixed-methods study involving 36
participants, we found that GlobalizeEds dubbed formats significantly reduce
cognitive load and offer a more immersive learning experience compared to
traditional subtitles. Although learning effectiveness was comparable between
high-quality subtitles and dubbed formats, both groups valued GlobalizeEds
ability to preserve the speakers voice, which enhanced perceived authenticity.
Instructors rated translation accuracy and vocal naturalness, whereas students
reported that synchronized, identity-preserving outputs fostered engagement and
trust. This work contributes a novel human-centered AI framework for
cross-lingual education, demonstrating how multimodal translation systems can
balance linguistic fidelity, cultural adaptability, and user control to create
more inclusive global learning experiences.

</details>
