<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 12]
- [cs.HC](#cs.HC) [Total: 10]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Fairness risk and its privacy-enabled solution in AI-driven robotic applications](https://arxiv.org/abs/2601.08953)
*Le Liu,Bangguo Yu,Nynke Vellinga,Ming Cao*

Main category: cs.RO

TL;DR: 提出了一种效用导向的公平性度量标准，分析了机器人决策中的公平性与用户隐私的关系，发现隐私预算可助力实现公平性目标，为AI的伦理使用铺平道路。


<details>
  <summary>Details</summary>
Motivation: 探讨自主机器和算法的复杂决策对未来社会的基础性影响，尤其是生成式AI的应用。

Method: 提出一个基于效用的公平性度量标准，并分析用户数据隐私与公平性之间的关系，建立统一框架，定量化公平性及其与隐私的相互作用，通过机器人导航任务进行测试。

Result: 发现隐私预算可以与公平性目标联合使用，能够满足法律要求及提升机器人系统的用户信任。

Conclusion: 在伦理使用AI的过程中，综合考虑公平性和隐私性是提高自主机器人在日常环境中信任度的重要一步。

Abstract: Complex decision-making by autonomous machines and algorithms could underpin the foundations of future society. Generative AI is emerging as a powerful engine for such transitions. However, we show that Generative AI-driven developments pose a critical pitfall: fairness concerns. In robotic applications, although intuitions about fairness are common, a precise and implementable definition that captures user utility and inherent data randomness is missing. Here we provide a utility-aware fairness metric for robotic decision making and analyze fairness jointly with user-data privacy, deriving conditions under which privacy budgets govern fairness metrics. This yields a unified framework that formalizes and quantifies fairness and its interplay with privacy, which is tested in a robot navigation task. In view of the fact that under legal requirements, most robotic systems will enforce user privacy, the approach shows surprisingly that such privacy budgets can be jointly used to meet fairness targets. Addressing fairness concerns in the creative combined consideration of privacy is a step towards ethical use of AI and strengthens trust in autonomous robots deployed in everyday environments.

</details>


### [2] [Generalizable Geometric Prior and Recurrent Spiking Feature Learning for Humanoid Robot Manipulation](https://arxiv.org/abs/2601.09031)
*Xuetao Li,Wenke Huang,Mang Ye,Jifeng Xuan,Bo Du,Sheng Liu,Miao Li*

Main category: cs.RO

TL;DR: 本研究提出RGMP-S方法，通过精确的3D场景理解与高效的运动合成，解决了人类级别任务中机器人操作的关键挑战，实验验证了其优越性与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 人类机器人操作的复杂性要求提升场景理解与从示范中学习的效率，以提高现有框架的适用性和普遍性。

Method: 提出一种新的RGMP-S方法，利用轻量级二维几何归纳偏见实现3D场景理解，结合长时间几何优先技能选择器与递归自适应脉冲网络，提升机器人操作的高效性与准确性。

Result: 在Maniskill仿真基准和三种不同的真实机器人系统上进行的实验表明，该方法在多种泛化场景中优于现有最先进的方法。

Conclusion: RGMP-S方法能够在未见环境下实现鲁棒性泛化，充分利用人类演示进行高效学习，并具备出色的数据效率与运动合成能力。

Abstract: Humanoid robot manipulation is a crucial research area for executing diverse human-level tasks, involving high-level semantic reasoning and low-level action generation. However, precise scene understanding and sample-efficient learning from human demonstrations remain critical challenges, severely hindering the applicability and generalizability of existing frameworks. This paper presents a novel RGMP-S, Recurrent Geometric-prior Multimodal Policy with Spiking features, facilitating both high-level skill reasoning and data-efficient motion synthesis. To ground high-level reasoning in physical reality, we leverage lightweight 2D geometric inductive biases to enable precise 3D scene understanding within the vision-language model. Specifically, we construct a Long-horizon Geometric Prior Skill Selector that effectively aligns the semantic instructions with spatial constraints, ultimately achieving robust generalization in unseen environments. For the data efficiency issue in robotic action generation, we introduce a Recursive Adaptive Spiking Network. We parameterize robot-object interactions via recursive spiking for spatiotemporal consistency, fully distilling long-horizon dynamic features while mitigating the overfitting issue in sparse demonstration scenarios. Extensive experiments are conducted across the Maniskill simulation benchmark and three heterogeneous real-world robotic systems, encompassing a custom-developed humanoid, a desktop manipulator, and a commercial robotic platform. Empirical results substantiate the superiority of our method over state-of-the-art baselines and validate the efficacy of the proposed modules in diverse generalization scenarios. To facilitate reproducibility, the source code and video demonstrations are publicly available at https://github.com/xtli12/RGMP-S.git.

</details>


### [3] [Design Methodology of Hydraulically-driven Soft Robotic Gripper for a Large and Heavy Object](https://arxiv.org/abs/2601.09104)
*Ko Yamamoto,Kyosuke Ishibashi,Hiroki Ishikawa,Osamu Azami*

Main category: cs.RO

TL;DR: 本研究提出一种新型液压驱动的软机器人抓手，能够抓取重达20公斤的物体，有效提升了抓取能力。


<details>
  <summary>Details</summary>
Motivation: 现有的气动驱动软抓手在抓取大重物时力不足，迫切需要一种新的解决方案。

Method: 开发一种液压驱动的软机器人抓手，基于数学模型确定设计参数，并进行材料选择和实验验证。

Result: 成功抓取20公斤重的物体，并实现手指弯曲角度的闭环控制。

Conclusion: 液压驱动软抓手能够有效抓取重物，具有优于气动驱动抓手的输出力。

Abstract: This paper presents a design methodology of a hydraulically-driven soft robotic gripper for grasping a large and heavy object -- approximately 10 - 20 kg with 20 - 30 cm diameter. Most existing soft grippers are pneumatically actuated with several hundred kPa pressure, and cannot generate output force sufficient for such a large and heavy object. Instead of pneumatic actuation, hydraulic actuation has a potential to generate much larger power by several MPa pressure. In this study, we develop a hydraulically-driven soft gripper, in which its basic design parameters are determined based on a mathematical model that represents the relationship among the driving pressure, bending angle, object mass and grasping force. Moreover, we selected materials suitable for grasping a heavier object, based on the finite element analysis result of the detailed design. We report experimental results on a 20 kg object grasping and closed-loop control of the finger bending angle.

</details>


### [4] [CEI: A Unified Interface for Cross-Embodiment Visuomotor Policy Learning in 3D Space](https://arxiv.org/abs/2601.09163)
*Tong Wu,Shoujie Li,Junhao Gong,Changqing Guo,Xingting Li,Shilong Mu,Wenbo Ding*

Main category: cs.RO

TL;DR: 本文提出了交叉体现接口（CEI）框架，解决了机器学习模型在机器人操作中的过拟合问题，支持不同机器人结构之间的运动策略和数据迁移。


<details>
  <summary>Details</summary>
Motivation: 当前的机器人基础模型常常因数据集偏见而过拟合于特定的视角和抓取工具，因此需要一种新方法来提高模型的广泛适应性和迁移能力。

Method: 提出交叉体现接口（CEI）框架，通过功能相似性量化、梯度优化对机器人轨迹进行对齐，并为未见过的机器人手臂和末端执行器合成观察与动作。

Result: CEI在仿真实验中成功地将Franka Panda机器人的数据和策略迁移到16种不同的机器人结构，在6项真实世界任务中实现了82.4%的平均迁移比率。

Conclusion: 通过引入交叉体现学习框架，	extit{CEI} 有效地解决了因数据集偏见导致的机器人操作策略过拟合问题，实现了机器人运动策略和数据在不同机器人结构之间的成功迁移。

Abstract: Robotic foundation models trained on large-scale manipulation datasets have shown promise in learning generalist policies, but they often overfit to specific viewpoints, robot arms, and especially parallel-jaw grippers due to dataset biases. To address this limitation, we propose Cross-Embodiment Interface (\CEI), a framework for cross-embodiment learning that enables the transfer of demonstrations across different robot arm and end-effector morphologies. \CEI introduces the concept of \textit{functional similarity}, which is quantified using Directional Chamfer Distance. Then it aligns robot trajectories through gradient-based optimization, followed by synthesizing observations and actions for unseen robot arms and end-effectors. In experiments, \CEI transfers data and policies from a Franka Panda robot to \textbf{16} different embodiments across \textbf{3} tasks in simulation, and supports bidirectional transfer between a UR5+AG95 gripper robot and a UR5+Xhand robot across \textbf{6} real-world tasks, achieving an average transfer ratio of 82.4\%. Finally, we demonstrate that \CEI can also be extended with spatial generalization and multimodal motion generation capabilities using our proposed techniques. Project website: https://cross-embodiment-interface.github.io/

</details>


### [5] [Vision-Conditioned Variational Bayesian Last Layer Dynamics Models](https://arxiv.org/abs/2601.09178)
*Paul Brunzema,Thomas Lew,Ray Zhang,Takeru Shirasawa,John Subosits,Marcus Greiff*

Main category: cs.RO

TL;DR: 提出了一种视觉条件的动态预测模型，能在变化环境下优化自动驾驶控制器。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统在迅速变化的环境中维持安全性与性能的挑战，强调了主动适应的重要性。

Method: 利用视觉信息训练变分贝叶斯模型，集成入车辆控制器，通过特征的仿射变换提升动态预测能力。

Result: 在变化环境下，基于视觉的变分贝叶斯动态模型能够有效预判环境变化，从而实现主动适应，保证了自动驾驶系统的安全性和性能。

Conclusion: 通过集成视觉条件的动态预测模型，优化控制器可以在高性能条件下保持车辆控制，解决了传统方法在快速变化环境中的局限性。

Abstract: Agile control of robotic systems often requires anticipating how the environment affects system behavior. For example, a driver must perceive the road ahead to anticipate available friction and plan actions accordingly. Achieving such proactive adaptation within autonomous frameworks remains a challenge, particularly under rapidly changing conditions. Traditional modeling approaches often struggle to capture abrupt variations in system behavior, while adaptive methods are inherently reactive and may adapt too late to ensure safety. We propose a vision-conditioned variational Bayesian last-layer dynamics model that leverages visual context to anticipate changes in the environment. The model first learns nominal vehicle dynamics and is then fine-tuned with feature-wise affine transformations of latent features, enabling context-aware dynamics prediction. The resulting model is integrated into an optimal controller for vehicle racing. We validate our method on a Lexus LC500 racing through water puddles. With vision-conditioning, the system completed all 12 attempted laps under varying conditions. In contrast, all baselines without visual context consistently lost control, demonstrating the importance of proactive dynamics adaptation in high-performance applications.

</details>


### [6] [Online Trajectory Optimization for Arbitrary-Shaped Mobile Robots via Polynomial Separating Hypersurfaces](https://arxiv.org/abs/2601.09231)
*Shuoye Li,Zhiyuan Song,Yulin Li,Zhihai Bi,Jun Ma*

Main category: cs.RO

TL;DR: 本文提出了一种非线性分离超曲面，能够在不依赖于保守凸近似的情况下，实现机器人轨迹优化与碰撞避免。


<details>
  <summary>Details</summary>
Motivation: 现有的基于线性分离器的轨迹优化方法在复杂环境中表现出保守性，限制了机器人的性能。

Method: 通过引入由多项式函数参数化的非线性分离超曲面，并将其应用于一个联合优化的问题，优化机器人的轨迹和分离多项式的系数。

Result: 经过模拟和真实世界实验，展示了该方法在非凸机器人及其操作环境中能够实现流畅、无碰撞的机动。

Conclusion: 该方法有效地在复杂环境中实现了平滑、无碰撞的机动，而无需依赖保守的凸近似。

Abstract: An emerging class of trajectory optimization methods enforces collision avoidance by jointly optimizing the robot's configuration and a separating hyperplane. However, as linear separators only apply to convex sets, these methods require convex approximations of both the robot and obstacles, which becomes an overly conservative assumption in cluttered and narrow environments. In this work, we unequivocally remove this limitation by introducing nonlinear separating hypersurfaces parameterized by polynomial functions. We first generalize the classical separating hyperplane theorem and prove that any two disjoint bounded closed sets in Euclidean space can be separated by a polynomial hypersurface, serving as the theoretical foundation for nonlinear separation of arbitrary geometries. Building on this result, we formulate a nonlinear programming (NLP) problem that jointly optimizes the robot's trajectory and the coefficients of the separating polynomials, enabling geometry-aware collision avoidance without conservative convex simplifications. The optimization remains efficiently solvable using standard NLP solvers. Simulation and real-world experiments with nonconvex robots demonstrate that our method achieves smooth, collision-free, and agile maneuvers in environments where convex-approximation baselines fail.

</details>


### [7] [Feedback-Based Mobile Robot Navigation in 3-D Environments Using Artificial Potential Functions Technical Report](https://arxiv.org/abs/2601.09318)
*Ro'i Lang,Elon Rimon*

Main category: cs.RO

TL;DR: 本报告探讨了在复杂三维环境中使用多项式导航函数进行运动规划的问题，提出了避免局部最小值的条件，并通过仿真验证了理论的有效性。


<details>
  <summary>Details</summary>
Motivation: 研究三维工作空间中的运动规划问题，尤其是在复杂障碍物（球形和柱形）存在下的有效路径规划。

Method: 构建光滑多项式隐式函数的导航函数，并分析其在目标位置的唯一非退化最小值的条件，使用梯度和海森矩阵分析。

Result: 在含有交叉障碍物的情况下，推动导航函数在目标位置达到唯一非退化最小值，避免局部最小值。通过数值仿真验证了理论结果。

Conclusion: 所提出的多项式导航函数能有效实现复杂环境中的运动规划，并且在遇到障碍物时表现出良好的性能。

Abstract: This technical report presents the construction and analysis of polynomial navigation functions for motion planning in 3-D workspaces populated by spherical and cylindrical obstacles. The workspace is modeled as a bounded spherical region, and obstacles are encoded using smooth polynomial implicit functions. We establish conditions under which the proposed navigation functions admit a unique non-degenerate minimum at the target while avoiding local minima, including in the presence of pairwise intersecting obstacles. Gradient and Hessian analyses are provided, and the theoretical results are validated through numerical simulations in obstacle rich 3-D environments.

</details>


### [8] [ReflexDiffusion: Reflection-Enhanced Trajectory Planning for High-lateral-acceleration Scenarios in Autonomous Driving](https://arxiv.org/abs/2601.09377)
*Xuemei Yao,Xiao Yang,Jianbin Sun,Liuwei Xie,Xuebin Shao,Xiyu Fang,Hang Su,Kewei Yang*

Main category: cs.RO

TL;DR: 本文提出的ReflexDiffusion通过反射调整机制提高了基于扩散的轨迹规划器的性能，在高横向加速度的场景下，成功弥补了训练数据不足的问题，提升了车辆安全性。


<details>
  <summary>Details</summary>
Motivation: 在长尾场景中，为自主车辆生成安全且可靠的轨迹，尤其是在高横向加速度操作下，仍然是一个重大挑战。现有轨迹规划器在这些关键安全情境中表现不佳，导致轨迹预测不准确或不安全。

Method: ReflexDiffusion框架通过在迭代去噪过程中执行基于梯度的调整机制，增强了基于扩散的轨迹规划器的性能。每次标准轨迹更新后，计算条件噪声和无条件噪声预测之间的梯度，以强调关键的调节信号。

Result: 在nuPlan Test14-hard基准测试中的评估结果显示，ReflexDiffusion在高横向加速度场景中比现有的最先进（SOTA）方法提高了14.1%的驾驶得分。

Conclusion: ReflexDiffusion在高横向加速度场景中优于现有方法，展示了其在提升自主车辆安全性方面的有效性。

Abstract: Generating safe and reliable trajectories for autonomous vehicles in long-tail scenarios remains a significant challenge, particularly for high-lateral-acceleration maneuvers such as sharp turns, which represent critical safety situations. Existing trajectory planners exhibit systematic failures in these scenarios due to data imbalance. This results in insufficient modelling of vehicle dynamics, road geometry, and environmental constraints in high-risk situations, leading to suboptimal or unsafe trajectory prediction when vehicles operate near their physical limits. In this paper, we introduce ReflexDiffusion, a novel inference-stage framework that enhances diffusion-based trajectory planners through reflective adjustment. Our method introduces a gradient-based adjustment mechanism during the iterative denoising process: after each standard trajectory update, we compute the gradient between the conditional and unconditional noise predictions to explicitly amplify critical conditioning signals, including road curvature and lateral vehicle dynamics. This amplification enforces strict adherence to physical constraints, particularly improving stability during high-lateral-acceleration maneuvers where precise vehicle-road interaction is paramount. Evaluated on the nuPlan Test14-hard benchmark, ReflexDiffusion achieves a 14.1% improvement in driving score for high-lateral-acceleration scenarios over the state-of-the-art (SOTA) methods. This demonstrates that inference-time trajectory optimization can effectively compensate for training data sparsity by dynamically reinforcing safety-critical constraints near handling limits. The framework's architecture-agnostic design enables direct deployment to existing diffusion-based planners, offering a practical solution for improving autonomous vehicle safety in challenging driving conditions.

</details>


### [9] [Data Scaling for Navigation in Unknown Environments](https://arxiv.org/abs/2601.09444)
*Lauri Suomela,Naoki Takahata,Sasanka Kuruppu Arachchige,Harry Edelman,Joni-Kristian Kämäräinen*

Main category: cs.RO

TL;DR: 本研究探讨了数据量与多样性对实际环境中视觉导航政策的一体化学习的影响，表明多样性比数量更重要。


<details>
  <summary>Details</summary>
Motivation: 解决模仿学习导航政策在未见环境中的泛化能力问题。

Method: 使用跨161个地点搜集的4,565小时的众包数据集，训练点目标导航政策，并评估其在四个国家的自驾机器人上的闭环控制性能。

Result: 通过大规模的数据训练，导航政策能够在未知环境中实现零-shot导航，接近于使用特定环境示范训练的政策的性能。

Conclusion: 大数据的多样性对导航政策的泛化能力影响更为显著，增加新地理位置的数据会显著降低导航误差，而现有位置的数据量增加的效果则逐渐减弱。

Abstract: Generalization of imitation-learned navigation policies to environments unseen in training remains a major challenge. We address this by conducting the first large-scale study of how data quantity and data diversity affect real-world generalization in end-to-end, map-free visual navigation. Using a curated 4,565-hour crowd-sourced dataset collected across 161 locations in 35 countries, we train policies for point goal navigation and evaluate their closed-loop control performance on sidewalk robots operating in four countries, covering 125 km of autonomous driving.
  Our results show that large-scale training data enables zero-shot navigation in unknown environments, approaching the performance of policies trained with environment-specific demonstrations. Critically, we find that data diversity is far more important than data quantity. Doubling the number of geographical locations in a training set decreases navigation errors by ~15%, while performance benefit from adding data from existing locations saturates with very little data. We also observe that, with noisy crowd-sourced data, simple regression-based models outperform generative and sequence-based architectures. We release our policies, evaluation setup and example videos on the project page.

</details>


### [10] [CLARE: Continual Learning for Vision-Language-Action Models via Autonomous Adapter Routing and Expansion](https://arxiv.org/abs/2601.09512)
*Ralf Römer,Yi Zhang,Angela P. Schoellig*

Main category: cs.RO

TL;DR: CLARE是一个无示例的持续学习框架，能在新任务中保持高性能且不会遗忘旧知识。


<details>
  <summary>Details</summary>
Motivation: 现有的预训练视-语-行动模型在特定任务上的微调不适合长期在真实世界中操作，因其无法持续适应新任务和环境而不忘记已学知识。

Method: 提出CLARE，一个通用的、参数高效的框架，实现无示例持续学习，使用轻量级模块适配器和自动编码器路由机制。

Result: 在LIBERO基准上的大量实验显示，CLARE在新任务上表现优异且未出现灾难性遗忘，显著优于基于示例的方法。

Conclusion: CLARE有效解决长期操作中的持续学习问题，具有较好的适应性和性能。

Abstract: To teach robots complex manipulation tasks, it is now a common practice to fine-tune a pre-trained vision-language-action model (VLA) on task-specific data. However, since this recipe updates existing representations, it is unsuitable for long-term operation in the real world, where robots must continually adapt to new tasks and environments while retaining the knowledge they have already acquired. Existing continual learning methods for robotics commonly require storing previous data (exemplars), struggle with long task sequences, or rely on task identifiers for deployment. To address these limitations, we propose CLARE, a general, parameter-efficient framework for exemplar-free continual learning with VLAs. CLARE introduces lightweight modular adapters into selected feedforward layers and autonomously expands the model only where necessary when learning a new task, guided by layer-wise feature similarity. During deployment, an autoencoder-based routing mechanism dynamically activates the most relevant adapters without requiring task labels. Through extensive experiments on the LIBERO benchmark, we show that CLARE achieves high performance on new tasks without catastrophic forgetting of earlier tasks, significantly outperforming even exemplar-based methods. Code and data are available at https://tum-lsy.github.io/clare.

</details>


### [11] [Learning Whole-Body Human-Humanoid Interaction from Human-Human Demonstrations](https://arxiv.org/abs/2601.09518)
*Wei-Jin Huang,Yue-Yi Zhang,Yi-Lin Wei,Zhi-Wei Xia,Juantao Tan,Yuan-Ming Li,Zhilin Zhao,Wei-Shi Zheng*

Main category: cs.RO

TL;DR: 提出了一种名为PAIR的物理感知互动重定向方法和D-STAR的分解时空动作推理政策，以改进人形机器人与人类的交互能力，并在模拟中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 高质量的人-人形互动数据稀缺，传统的重定向方法未能保留关键接触，因此需要开发新的方法以提高人形机器人与人类的互动能力。

Method: 本研究采用了两阶段管道PAIR，专注于接触语义，并引入D-STAR以分解互动中的时空行为，使得机器人能够更好地进行同步协作。

Result: 通过系统的模拟实验，证明了所提框架在复杂全身互动的学习上有显著的性能提升。

Conclusion: 我们的框架通过广泛的模拟验证，展示了相较于基线方法的显著性能提升，并提供了一种有效的从人类互动数据中学习复杂全身互动的完整管道。

Abstract: Enabling humanoid robots to physically interact with humans is a critical frontier, but progress is hindered by the scarcity of high-quality Human-Humanoid Interaction (HHoI) data. While leveraging abundant Human-Human Interaction (HHI) data presents a scalable alternative, we first demonstrate that standard retargeting fails by breaking the essential contacts. We address this with PAIR (Physics-Aware Interaction Retargeting), a contact-centric, two-stage pipeline that preserves contact semantics across morphology differences to generate physically consistent HHoI data. This high-quality data, however, exposes a second failure: conventional imitation learning policies merely mimic trajectories and lack interactive understanding. We therefore introduce D-STAR (Decoupled Spatio-Temporal Action Reasoner), a hierarchical policy that disentangles when to act from where to act. In D-STAR, Phase Attention (when) and a Multi-Scale Spatial module (where) are fused by the diffusion head to produce synchronized whole-body behaviors beyond mimicry. By decoupling these reasoning streams, our model learns robust temporal phases without being distracted by spatial noise, leading to responsive, synchronized collaboration. We validate our framework through extensive and rigorous simulations, demonstrating significant performance gains over baseline approaches and a complete, effective pipeline for learning complex whole-body interactions from HHI data.

</details>


### [12] [Multimodal Signal Processing For Thermo-Visible-Lidar Fusion In Real-time 3D Semantic Mapping](https://arxiv.org/abs/2601.09578)
*Jiajun Sun,Yangyi Ou,Haoyuan Zheng,Chao yang,Yue Ma*

Main category: cs.RO

TL;DR: 本文提出了一种新颖的方法，通过将可见光和红外图像进行像素级融合，增强三维点云地图的语义信息，利用热源特征识别高温目标，提升自主机器人在复杂环境中的导航和感知能力。


<details>
  <summary>Details</summary>
Motivation: 在复杂环境中，自主机器人的导航和环境感知对SLAM技术提出了更高要求，亟需新的方法来增强地图语义信息。

Method: 该方法首先进行可见光和红外图像的像素级融合，然后将实时激光雷达点云投影到融合的图像流上，最后在热通道中分割热源特征以识别高温目标，并将其温度信息添加为三维地图的语义层。

Result: 使用该方法生成的地图不仅具备准确的几何信息，还拥有对环境的关键语义理解，从而提升了复杂环境中机器人的表现。

Conclusion: 本研究提出的结合热信息的三维点云地图显著提高了环境感知能力，特别适用于快速灾后评估和工业预防维护等应用。

Abstract: In complex environments, autonomous robot navigation and environmental perception pose higher requirements for SLAM technology. This paper presents a novel method for semantically enhancing 3D point cloud maps with thermal information. By first performing pixel-level fusion of visible and infrared images, the system projects real-time LiDAR point clouds onto this fused image stream. It then segments heat source features in the thermal channel to instantly identify high temperature targets and applies this temperature information as a semantic layer on the final 3D map. This approach generates maps that not only have accurate geometry but also possess a critical semantic understanding of the environment, making it highly valuable for specific applications like rapid disaster assessment and industrial preventive maintenance.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [13] [Leveraging learning analytics to enhance immersive teacher simulations: Challenges and opportunities](https://arxiv.org/abs/2601.08954)
*Sumin Hong,Jewoong Moon,Taeyeon Eom,Juno Hwang,Jibeom Seo*

Main category: cs.HC

TL;DR: 本章探讨如何利用数据分析提升沉浸式教师模拟，强调分析工具在教育反思中的重要性，并总结了教师教育中的研究挑战和设计意义。


<details>
  <summary>Details</summary>
Motivation: 探讨数据分析在沉浸式教师模拟中如何为教师专业学习提供支持，进而改进教学实践。

Method: 通过分析来自TeacherGen@i模拟的多模态数据，展示了教育话语和互动模式的认知分布。

Result: 通过数据分析提升沉浸式教师模拟的研究，展示了分析工具是如何将模拟体验与反思教学实践相连接的。

Conclusion: 沉浸式教师模拟为对学习分析和教师专业学习的结合提供了重要的实验基础，揭示了教师教育中面临的研究挑战和设计意义。

Abstract: This chapter examines how data analytics can be leveraged to enhance immersive teacher simulations, situating this inquiry within the broader learning sciences discourse on embodied cognition, data-informed feedback, and teacher professional learning. It explores both conceptual foundations and empirical cases to illustrate how analytics serve as mediational tools that connect immersive experiences with reflective teaching practice. The chapter unfolds in multiple sections: (1) The Innovation Journey: An Overview of Immersive Teacher Simulations outlines the evolution from traditional simulations to XR-based environments, highlighting the need for professional decision-making under realistic constraints. (2) Innovation in Existing Research and Practice situates teacher analytics within the trajectory from descriptive observation to multimodal and predictive modeling. (3) Study Approach and Design details how multimodal data-discourse, behavior, and gaze-from the TeacherGen@i simulation were collected and organized to reveal cognitive distribution of pedagogical discourse and interaction patterns. (4) Findings present the cognitive distribution of preservice teachers' pedagogical discourse and the sequential interaction patterns that emerge in exchange, illustrating how multimodal analytics make pedagogical reasoning processes visible within immersive simulations. (5) Understanding Innovative Practices in Teacher Education examines teaching analytics to enhance immersive teacher simulation based on the findings of the study. (6) Key Takeaways of the Innovation Journey identifies research challenges and design implications for scalable, analytics-enhanced teacher education. Together, these sections position immersive teacher simulations as a pivotal testbed for aligning learning analytics, professional learning, and next-generation immersive learning environment design.

</details>


### [14] [Exploring the Effects of Generative AI Assistance on Writing Self-Efficacy](https://arxiv.org/abs/2601.09033)
*Yejoon Song,Bandi Kim,Yeju Kwon,Sung Park*

Main category: cs.HC

TL;DR: 本研究探讨了不同级别的生成性AI支持对大学生写作自我效能的影响，结果显示，AI支持的配置方式对自我效能有显著影响，而不仅仅是支持的数量。


<details>
  <summary>Details</summary>
Motivation: 随着生成性AI在学术写作中的日益普及，理解其对学生写作自我效能的影响变得重要。

Method: 采用2x2实验设计，针对韩国本科生在完成论述性写作任务时进行不同类型的AI支持：创意阶段、句子阶段、完整过程和无支持。

Result: 结果表明，AI支持对自我效能的影响并不一致，全面AI支持产生高但稳定的自我效能，句子级AI支持导致自我效能持续下降，而创意级AI支持则与高自我效能和积极的纵向变化相关。

Conclusion: AI干预的位置，而不是支持的数量，在提升写作自我效能和保留学习者自主性方面至关重要。

Abstract: Generative AI (GenAI) is increasingly used in academic writing, yet its effects on students' writing self-efficacy remain contingent on how assistance is configured. This pilot study investigates how ideation-level, sentence-level, full-process, and no AI support differentially shape undergraduate writers' self-efficacy using a 2 by 2 experimental design with Korean undergraduates completing argumentative writing tasks. Results indicate that AI assistance does not uniformly enhance self-efficacy full AI support produced high but stable self-efficacy alongside signs of reduced ownership, sentence-level AI support led to consistent self-efficacy decline, and ideation-level AI support was associated with both high self-efficacy and positive longitudinal change. These findings suggest that the locus of AI intervention, rather than the amount of assistance, is critical in fostering writing self-efficacy while preserving learner agency.

</details>


### [15] [Exploring Organizational Readiness and Ecosystem Coordination for Industrial XR](https://arxiv.org/abs/2601.09045)
*Hasan Tarik Akbaba,Efe Bozkir,Anna Puhl,Süleyman Özdel,Enkelejda Kasneci*

Main category: cs.HC

TL;DR: 本研究分析了工业XR推广中的"Pilot Trap"现象，发现组织准备度是主要障碍，建议采取组织变革方法以推动XR应用。


<details>
  <summary>Details</summary>
Motivation: 尽管XR在工业中的应用潜力巨大，但广泛采纳仍然滞后，因此需要研究影响XR普及的障碍和驱动因素。

Method: 通过对17位专家的定性访谈，进行生态系统分析以识别XR采纳中的关键障碍和促进因素。

Result: 本研究通过对17位专家的访谈，识别并分析了工业扩展现实（XR）在推广中的"Pilot Trap"现象，指出成功的XR场景往往难以在组织中大规模实施。研究结果显示，关键的障碍已从技术成熟度转向组织准备度，如变更管理和政治阻力等。

Conclusion: 成功的工业XR采纳需要从以技术为中心的试点转向以问题为导向的组织变革方法，强调生态系统层面的协调。

Abstract: Extended Reality (XR) offers transformative potential for industrial support, training, and maintenance; yet, widespread adoption lags despite demonstrated occupational value and hardware maturity. Organizations successfully implement XR in isolated pilots, yet struggle to scale these into sustained operational deployment, a phenomenon we characterize as the ``Pilot Trap.'' This study examines this phenomenon through a qualitative ecosystem analysis of 17 expert interviews across technology providers, solution integrators, and industrial adopters. We identify a ``Great Inversion'' in adoption barriers: critical constraints have shifted from technological maturity to organizational readiness (e.g., change management, key performance indicator alignment, and political resistance). While hardware ergonomics and usability remain relevant, our findings indicate that systemic misalignments between stakeholder incentives are the primary cause of friction preventing enterprise integration. We conclude that successful industrial XR adoption requires a shift from technology-centric piloting to a problem-first, organizational transformation approach, necessitating explicit ecosystem-level coordination.

</details>


### [16] [Immersive XR That Moves People: How XR Advertising Transforms Comprehension, Empathy, and Behavioural Intention](https://arxiv.org/abs/2601.09048)
*Yuki Kobayashi,Koichi Toida*

Main category: cs.HC

TL;DR: 研究表明，沉浸式的XR广告比传统2D广告能更好地提高用户对产品的共情，这种共情进一步激励了购买意图。


<details>
  <summary>Details</summary>
Motivation: 探讨XR所引发的心理过程以及这些过程如何影响后续的购买意图，填补传统信息传递方式与XR间空白的研究。

Method: 使用重复测量的双因素方差分析（ANOVA）比较非沉浸式的2D广告和沉浸式XR广告; 进行中介分析验证共鸣和理解在购买意图中的作用。

Result: XR广告在所有评估维度上给予了更高的评分，其中同情心在购买意图的提升中起到了中介作用，而理解在此次研究中未显示出显著的中介效果。

Conclusion: 沉浸式的XR体验能够增强对虚拟产品的共鸣，而这种增强的共鸣在塑造后续的行为意图中扮演了关键角色。

Abstract: Extended Reality (XR) affords an enhanced sense of bodily presence that supports experiential modes of comprehension and affective engagement which exceed the possibilities of conventional information delivery. Nevertheless, the psychological processes engendered by XR, and the manner in which these processes inform subsequent behavioural intentions, remain only partially delineated. The present study addresses this issue within an applied context by comparing non-immersive 2D viewing advertising with immersive XR experiential advertising. We examined whether XR strengthens internal responses to a product, specifically perceived comprehension and empathy, and whether these responses, in turn, influence the behavioural outcome of purchase intention. A repeated-measures two-way ANOVA demonstrated a significant main effect of advertising modality, with XR yielding higher ratings on all evaluative dimensions. Mediation analysis further indicated that the elevation in purchase intention was mediated by empathy, whereas no significant mediating effect was observed for comprehension within the scope of this study. These findings suggest that immersive XR experiences augment empathic engagement with virtual products, and that this enhanced empathy plays a pivotal role in shaping subsequent behavioural intentions.

</details>


### [17] [Evaluating local large language models for structured extraction from endometriosis-specific transvaginal ultrasound reports](https://arxiv.org/abs/2601.09053)
*Haiyi Li,Yutong Li,Yiheng Chi,Alison Deslandes,Mathew Leonardi,Shay Freger,Yuan Zhang,Jodie Avery,M. Louise Hull,Hsiang-Ting Chen*

Main category: cs.HC

TL;DR: 本研究评估了一种本地部署的大型语言模型，将非结构化的内膜异位症经阴道超声扫描报告转化为结构化数据。20B模型达到了86.02%的平均准确率，显著优于较小的模型，同时强调了人机协作的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着影像信息学工作流的需求增加，需将非结构化的临床文本转化为结构化数据，以提升数据的可用性和分析能力。

Method: 研究中比较了三种不同参数的模型（7B/8B和20B）在49份eTVUS报告上的表现，并与人类专家的提取结果进行比较。

Result: 20B模型在语法一致性方面表现优于人类专家，整体准确率为86.02%。然而，LLM在语义理解上存在基本局限，需结合人类专家进行验证。

Conclusion: 本研究支持人机协作的工作流程，其中本地部署的大型语言模型作为协作工具，而非完全替代。

Abstract: In this study, we evaluate a locally-deployed large-language model (LLM) to convert unstructured endometriosis transvaginal ultrasound (eTVUS) scan reports into structured data for imaging informatics workflows. Across 49 eTVUS reports, we compared three LLMs (7B/8B and a 20B-parameter model) against expert human extraction. The 20B model achieved a mean accuracy of 86.02%, substantially outperforming smaller models and confirming the importance of scale in handling complex clinical text. Crucially, we identified a highly complementary error profile: the LLM excelled at syntactic consistency (e.g., date/numeric formatting) where humans faltered, while human experts provided superior semantic and contextual interpretation. We also found that the LLM's semantic errors were fundamental limitations that could not be mitigated by simple prompt engineering. These findings strongly support a human-in-the-loop (HITL) workflow in which the on-premise LLM serves as a collaborative tool, not a full replacement. It automates routine structuring and flags potential human errors, enabling imaging specialists to focus on high-level semantic validation. We discuss implications for structured reporting and interactive AI systems in clinical practice.

</details>


### [18] [World Craft: Agentic Framework to Create Visualizable Worlds via Text](https://arxiv.org/abs/2601.09150)
*Jianwen Sun,Yukang Feng,Kaining Ying,Chuanhao Li,Zizhen Li,Fanrui Zhang,Jiaxin Ai,Yifan Chang,Yu Dai,Yifei Huang,Kaipeng Zhang*

Main category: cs.HC

TL;DR: 提出了一种通过用户文本描述创建可视化AI城镇的框架World Craft，显著提升了生成效率和质量。


<details>
  <summary>Details</summary>
Motivation: 为了帮助非专业人士和缺乏编程技能的用户更轻松地自定义动态世界。

Method: 介绍了一个名为World Craft的框架，旨在通过用户文本描述创建可执行和可视化的AI城镇。

Result: 通过两个主要模块World Scaffold和World Guild，加上高质量的错误修正数据集，显著提高了布局生成的稳定性和可控性，并在场景构建和叙事意图传达方面超越了现有的商业代码代理和大型语言模型。

Conclusion: 该框架为环境创建的民主化提供了一种可扩展的解决方案，能够让非专家用户能够轻松定制视觉化环境。

Abstract: Large Language Models (LLMs) motivate generative agent simulation (e.g., AI Town) to create a ``dynamic world'', holding immense value across entertainment and research. However, for non-experts, especially those without programming skills, it isn't easy to customize a visualizable environment by themselves. In this paper, we introduce World Craft, an agentic world creation framework to create an executable and visualizable AI Town via user textual descriptions. It consists of two main modules, World Scaffold and World Guild. World Scaffold is a structured and concise standardization to develop interactive game scenes, serving as an efficient scaffolding for LLMs to customize an executable AI Town-like environment. World Guild is a multi-agent framework to progressively analyze users' intents from rough descriptions, and synthesizes required structured contents (\eg environment layout and assets) for World Scaffold . Moreover, we construct a high-quality error-correction dataset via reverse engineering to enhance spatial knowledge and improve the stability and controllability of layout generation, while reporting multi-dimensional evaluation metrics for further analysis. Extensive experiments demonstrate that our framework significantly outperforms existing commercial code agents (Cursor and Antigravity) and LLMs (Qwen3 and Gemini-3-Pro). in scene construction and narrative intent conveyance, providing a scalable solution for the democratization of environment creation.

</details>


### [19] [Mikasa: A Character-Driven Emotional AI Companion Inspired by Japanese Oshi Culture](https://arxiv.org/abs/2601.09208)
*Miki Ueno*

Main category: cs.HC

TL;DR: 提出Mikasa，强调情感AI陪伴者的角色一致性和关系定义对用户体验的重要性。


<details>
  <summary>Details</summary>
Motivation: 解决传统AI陪伴者在长期互动中用户满意度不足的问题，重点放在角色设计和用户-AI关系的清晰定义上。

Method: 案例研究，设计以角色为驱动的AI陪伴者，并通过探索性评估分析用户互动体验。

Result: 提出Mikasa，一个情感AI陪伴者，展示角色一致性和关系定义如何影响交互质量。

Conclusion: 角色设计是AI陪伴系统的重要组成部分，不仅是装饰，能显著提高用户满意度和参与度。

Abstract: Recent progress in large language models and multimodal interaction has made it possible to develop AI companions that can have fluent and emotionally expressive conversations. However, many of these systems have problems keeping users satisfied and engaged over long periods. This paper argues that these problems do not come mainly from weak models, but from poor character design and unclear definitions of the user-AI relationship. I present Mikasa, an emotional AI companion inspired by Japanese Oshi culture-specifically its emphasis on long-term, non-exclusive commitment to a stable character-as a case study of character-driven companion design. Mikasa does not work as a general-purpose assistant or a chatbot that changes roles. Instead, Mikasa is designed as a coherent character with a stable personality and a clearly defined relationship as a partner. This relationship does not force exclusivity or obligation. Rather, it works as a reference point that stabilizes interaction norms and reduces the work users must do to keep redefining the relationship. Through an exploratory evaluation, I see that users describe their preferences using surface-level qualities such as conversational naturalness, but they also value relationship control and imaginative engagement in ways they do not state directly. These results suggest that character coherence and relationship definition work as latent structural elements that shape how good the interaction feels, without users recognizing them as main features. The contribution of this work is to show that character design is a functional part of AI companion systems, not just decoration. Mikasa is one example based on a specific cultural context, but the design principles-commitment to a consistent personality and clear relationship definition-can be used for many emotionally grounded AI companions.

</details>


### [20] [Technological Advances in Two Generations of Consumer-Grade VR Systems: Effects on User Experience and Task Performance](https://arxiv.org/abs/2601.09610)
*Marie Luisa Fiedler,Christian Merz,Jonathan Tschanter,Carolin Wienrich,Marc Erich Latoschik*

Main category: cs.HC

TL;DR: 本研究比较了两代集成虚拟现实系统，结果表明硬件进步对用户体验影响有限，先前研究的有效性得以支持。


<details>
  <summary>Details</summary>
Motivation: 尽管消费者级集成虚拟现实系统已经存在十年，但其对用户体验的实际影响仍不明确，激励了对其重要性的研究。

Method: 进行用户中心的研究，比较两代相似的集成虚拟现实系统性能

Result: 通过评估用户的存在感、化身感、外观与行为的可信度、工作负载、任务表现等，发现两代系统没有显著差异，只有小的效应大小。

Conclusion: 10年技术进步的硬件改善对用户体验和任务表现的好处有限，这支持了先前工作的有效性，并强调了较旧配置在化身虚拟现实研究中的适用性。

Abstract: Integrated VR (IVR) systems consist of a head-mounted display (HMD) and body-tracking capabilities. They enable users to translate their physical movements into corresponding avatar movements in real-time, allowing them to perceive their avatars via the displays. Consumer-grade IVR systems have been available for 10 years, significantly fostering VR research worldwide. However, the effects of even apparently significant technological advances of IVR systems on user experience and the overall validity of prior embodiment research using such systems often remain unclear. We ran a user-centered study comparing two comparable IVR generations: a nearly 10-year-old hardware (HTC Vive, 6-point tracking) and a modern counterpart (HTC Vive Pro 2, 6-point tracking). To ensure ecological validity, we evaluated the systems in their commercially available, as-is configurations. In a 2x5 mixed design, participants completed five tasks covering different use cases on either the old or new system. We assessed presence, sense of embodiment, appearance and behavior plausibility, workload, task performance, and gathered qualitative feedback. Results showed no significant system differences, with only small effect sizes. Bayesian analysis further supported the null hypothesis, suggesting that the investigated generational hardware improvements offer limited benefits for user experience and task performance. For the 10-year generational step examined here, excluding potential technological progress in the necessary software components, this supports the validity of conclusions from prior work and underscores the applicability of older configurations for research in embodied VR.

</details>


### [21] [Full Disclosure, Less Trust? How the Level of Detail about AI Use in News Writing Affects Readers' Trust](https://arxiv.org/abs/2601.09620)
*Pooja Prajod,Hannes Cools,Thomas Röggla,Karthikeya Puttur Venkatraj,Amber Kusters,Alia ElKattan,Pablo Cesar,Abdallah El Ali*

Main category: cs.HC

TL;DR: 本研究探讨了AI披露的详细程度对新闻读者信任的影响，发现细节披露可能导致信任下降，而一行披露提升了信息核实行为。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能融入新闻生产，公众对透明度的呼声日益增高，但AI披露的效果尚不明确，特别是在信任问题上。

Method: 采用3×2×2的混合因子设计，进行了一项包含40名参与者的实证研究，分析不同级别的AI披露对政治和生活方式新闻中信任及决策行为的影响。

Result: 本研究发现，在新闻内容中，当AI披露详细信息时，读者的信任度下降。但在提供一行描述时，读者对消息源的核实行为增加，同时，其信任度未明显下降。 

Conclusion: 不同详细程度的AI披露对新闻读者的信任和决策行为有显著影响，详细披露可能导致信任下降，而简短披露刺激了核实行为。

Abstract: As artificial intelligence (AI) is increasingly integrated into news production, calls for transparency about the use of AI have gained considerable traction. Recent studies suggest that AI disclosures can lead to a ``transparency dilemma'', where disclosure reduces readers' trust. However, little is known about how the \textit{level of detail} in AI disclosures influences trust and contributes to this dilemma within the news context. In this 3$\times$2$\times$2 mixed factorial study with 40 participants, we investigate how three levels of AI disclosures (none, one-line, detailed) across two types of news (politics and lifestyle) and two levels of AI involvement (low and high) affect news readers' trust. We measured trust using the News Media Trust questionnaire, along with two decision behaviors: source-checking and subscription decisions. Questionnaire responses and subscription rates showed a decline in trust only for detailed AI disclosures, whereas source-checking behavior increased for both one-line and detailed disclosures, with the effect being more pronounced for detailed disclosures. Insights from semi-structured interviews suggest that source-checking behavior was primarily driven by interest in the topic, followed by trust, whereas trust was the main factor influencing subscription decisions. Around two-thirds of participants expressed a preference for detailed disclosures, while most participants who preferred one-line indicated a need for detail-on-demand disclosure formats. Our findings show that not all AI disclosures lead to a transparency dilemma, but instead reflect a trade-off between readers' desire for more transparency and their trust in AI-assisted news content.

</details>


### [22] [Perceptually-Guided Adjusted Teleporting: Perceptual Thresholds for Teleport Displacements in Virtual Environments](https://arxiv.org/abs/2601.09632)
*Rose Connolly,Victor Zordan,Rachel McDonnell*

Main category: cs.HC

TL;DR: 本研究探讨了虚拟现实中传送技术的感知特性，发现用户对传送目标位置的调整具有一定的未察觉阈值。


<details>
  <summary>Details</summary>
Motivation: 研究虚拟现实中传送方式的感知属性以提高用户体验和设计灵活性。

Method: 通过重复测量实验，采用心理物理阶梯法和二选一强制选择任务评估传送目标位置的调整阈值。

Result: 发现用户对传送目标的调整可在不被察觉的情况下进行，且对向后调整和长距离传送的容忍度更高。

Conclusion: 研究结果为重新定向传送设定了感知极限，为虚拟现实中的适应性和社交意识移动系统提供了新机会。

Abstract: Teleportation is one of the most common locomotion techniques in virtual reality, yet its perceptual properties remain underexplored. While redirected walking research has shown that users' movements can be subtly manipulated without detection, similar imperceptible adjustments for teleportation have not been systematically investigated. This study examines the thresholds at which teleportation displacements become noticeable to users. We conducted a repeated-measures experiment in which participants' selected teleport destinations were altered in both direction (forwards, backwards) and at different ranges (small, large). Detection thresholds for these positional adjustments were estimated using a psychophysical staircase method with a two-alternative forced choice (2AFC) task. Results show that teleport destinations can be shifted without detection, with larger tolerances for backward adjustments and across longer teleport ranges. These findings establish baseline perceptual limits for redirected teleportation and highlight its potential as a design technique. Applications include supporting interpersonal distance management in social VR, guiding players toward objectives in games, and assisting novice users with navigation. By identifying the limits of imperceptible teleportation adjustments, this work extends redirection principles beyond walking to teleportation and opens new opportunities for adaptive and socially aware VR locomotion systems.

</details>
