<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 26]
- [cs.HC](#cs.HC) [Total: 16]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Translating Milli/Microrobots with A Value-Centered Readiness Framework](https://arxiv.org/abs/2510.12090)
*Hakan Ceylan,Edoardo Sinibaldi,Sanjay Misra,Pankaj J. Pasricha,Dietmar W. Hutmacher*

Main category: cs.RO

TL;DR: 移动毫微型机器人在介入医学中具有巨大潜力，但许多技术仍局限于实验室，文中提出了一个mTRL框架，旨在加速其临床应用。


<details>
  <summary>Details</summary>
Motivation: 探索移动毫微型机器人在介入医学中的潜力，以及如何将实验室的创新推广到临床应用中。

Method: 分析当前技术与临床应用之间的差距，提出mTRL框架，通过里程碑和分阶段活动指导技术发展。

Result: 提出了一个新的技术成熟度框架(mTRL)，旨在加速毫微型机器人的临床采用。

Conclusion: 推动毫微型机器人向临床转化需与未满足的医疗需求对齐，确保其实际应用的可行性，融入现有的临床流程。

Abstract: Untethered mobile milli/microrobots hold transformative potential for
interventional medicine by enabling more precise and entirely non-invasive
diagnosis and therapy. Realizing this promise requires bridging the gap between
groundbreaking laboratory demonstrations and successful clinical integration.
Despite remarkable technical progress over the past two decades, most
millirobots and microrobots remain confined to laboratory proof-of-concept
demonstrations, with limited real-world feasibility. In this Review, we
identify key factors that slow translation from bench to bedside, focusing on
the disconnect between technical innovation and real-world application. We
argue that the long-term impact and sustainability of the field depend on
aligning development with unmet medical needs, ensuring applied feasibility,
and integrating seamlessly into existing clinical workflows, which are
essential pillars for delivering meaningful patient outcomes. To support this
shift, we introduce a strategic milli/microrobot Technology Readiness Level
framework (mTRL), which maps system development from initial conceptualization
to clinical adoption through clearly defined milestones and their associated
stepwise activities. The mTRL model provides a structured gauge of
technological maturity, a common language for cross-disciplinary collaboration
and actionable guidance to accelerate translational development toward new,
safer and more efficient interventions.

</details>


### [2] [Gaussian Semantic Field for One-shot LiDAR Global Localization](https://arxiv.org/abs/2510.12101)
*Pengyu Yin,Shenghai Yuan,Haozhi Cao,Xingyu Ji,Ruofei Bai,Siyu Chen,Lihua Xie*

Main category: cs.RO

TL;DR: 本论文提出了一种新的全局定位算法Outram-GSF，通过基于高斯过程的语义建模，显著改善了定位性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统地标语义注册方法中地标重复和误导性的问题，提高全局定位的准确性。

Method: 提出了一种基于轻量级三层场景图的全局定位算法，使用高斯过程学习的连续函数建模语义分布。

Result: 通过对公开数据集进行广泛的实验验证了算法的优越性能。

Conclusion: Outram-GSF算法在全球定位任务中表现优越，优于现有的最先进技术。

Abstract: We present a one-shot LiDAR global localization algorithm featuring semantic
disambiguation ability based on a lightweight tri-layered scene graph. While
landmark semantic registration-based methods have shown promising performance
improvements in global localization compared with geometric-only methods,
landmarks can be repetitive and misleading for correspondence establishment. We
propose to mitigate this problem by modeling semantic distributions with
continuous functions learned from a population of Gaussian processes. Compared
with discrete semantic labels, the continuous functions capture finer-grained
geo-semantic information and also provide more detailed metric information for
correspondence establishment. We insert this continuous function as the middle
layer between the object layer and the metric-semantic layer, forming a
tri-layered 3D scene graph, serving as a light-weight yet performant backend
for one-shot localization. We term our global localization pipeline Outram-GSF
(Gaussian semantic field) and conduct a wide range of experiments on publicly
available data sets, validating the superior performance against the current
state-of-the-art.

</details>


### [3] [Hybrid Terrain-Aware Path Planning: Integrating VD--RRT\(^{*}\) Exploration and VD--D\(^{*}\) Lite Repair](https://arxiv.org/abs/2510.12169)
*Akshay Naik,William R. Norris,Dustin Nottage,Ahmet Soylemezoglu*

Main category: cs.RO

TL;DR: 本研究提出了一种结合土壤强度和坡度的路径规划方法，实现在非结构化环境中的自主导航。


<details>
  <summary>Details</summary>
Motivation: 为了解决自主地面车辆在非公路环境中的路径规划问题，考虑土壤强度和坡度风险的实时动态变化。

Method: 使用基于状态成本度量的路径规划方法，结合Bekker压力-沉降模型及坡度惩罚，采用Vehicle-Dynamics RRT*进行全局探索和D* Lite进行局部修复。

Result: 通过实验，展示了在软土和坡度过渡下的实时导航能力，表明该框架的有效性。

Conclusion: 该框架在非结构化环境中实现了可靠的自主导航，能够有效处理软土和坡度过渡。

Abstract: Autonomous ground vehicles operating off-road must plan curvature-feasible
paths while accounting for spatially varying soil strength and slope hazards in
real time. We present a continuous state--cost metric that combines a Bekker
pressure--sinkage model with elevation-derived slope and attitude penalties.
The resulting terrain cost field is analytic, bounded, and monotonic in soil
modulus and slope, ensuring well-posed discretization and stable updates under
sensor noise. This metric is evaluated on a lattice with exact steering
primitives: Dubins and Reeds--Shepp motions for differential drive and
time-parameterized bicycle arcs for Ackermann steering. Global exploration is
performed using Vehicle-Dynamics RRT\(^{*}\), while local repair is managed by
Vehicle-Dynamics D\(^{*}\) Lite, enabling millisecond-scale replanning without
heuristic smoothing. By separating the terrain--vehicle model from the planner,
the framework provides a reusable basis for deterministic, sampling-based, or
learning-driven planning in deformable terrain. Hardware trials on an off-road
platform demonstrate real-time navigation across soft soil and slope
transitions, supporting reliable autonomy in unstructured environments.

</details>


### [4] [Controllable Collision Scenario Generation via Collision Pattern Prediction](https://arxiv.org/abs/2510.12206)
*Pin-Lun Chen,Chi-Hsi Kung,Che-Han Chang,Wei-Chen Chiu,Yi-Ting Chen*

Main category: cs.RO

TL;DR: 本文提出一种可控碰撞场景生成方法，通过COLLIDE数据集生成多样化的碰撞场景，提升了自动驾驶车辆的安全性。


<details>
  <summary>Details</summary>
Motivation: 现实中收集碰撞场景不安全且罕见，因此需要在仿真中生成安全关键场景。

Method: 提出一种新的任务——可控碰撞场景生成，利用COLLIDE数据集生成期望的碰撞场景。

Result: 作者的方法在碰撞率和可控性上超越了强基线，生成的场景提高了规划器的失败率，揭示了现有规划器的局限性，并通过微调规划器提高了鲁棒性。

Conclusion: 生成的碰撞场景能够帮助改善自动驾驶车辆的规划性能，从而为不同碰撞场景下的安全部署做出贡献。

Abstract: Evaluating the safety of autonomous vehicles (AVs) requires diverse,
safety-critical scenarios, with collisions being especially important yet rare
and unsafe to collect in the real world. Therefore, the community has been
focusing on generating safety-critical scenarios in simulation. However,
controlling attributes such as collision type and time-to-accident (TTA)
remains challenging. We introduce a new task called controllable collision
scenario generation, where the goal is to produce trajectories that realize a
user-specified collision type and TTA, to investigate the feasibility of
automatically generating desired collision scenarios. To support this task, we
present COLLIDE, a large-scale collision scenario dataset constructed by
transforming real-world driving logs into diverse collisions, balanced across
five representative collision types and different TTA intervals. We propose a
framework that predicts Collision Pattern, a compact and interpretable
representation that captures the spatial configuration of the ego and the
adversarial vehicles at impact, before rolling out full adversarial
trajectories. Experiments show that our approach outperforms strong baselines
in both collision rate and controllability. Furthermore, generated scenarios
consistently induce higher planner failure rates, revealing limitations of
existing planners. We demonstrate that these scenarios fine-tune planners for
robustness improvements, contributing to safer AV deployment in different
collision scenarios.

</details>


### [5] [Learning Social Navigation from Positive and Negative Demonstrations and Rule-Based Specifications](https://arxiv.org/abs/2510.12215)
*Chanwoo Kim,Jihwan Yoon,Hyeonseong Kim,Taemoon Jeong,Changwoo Yoo,Seungbeen Lee,Soohwan Byeon,Hoon Chung,Matthew Pan,Jean Oh,Kyungjae Lee,Sungjoon Choi*

Main category: cs.RO

TL;DR: 该研究提出了一种结合数据驱动奖励和规则基础目标的移动机器人导航框架，以平衡适应性和安全性。


<details>
  <summary>Details</summary>
Motivation: 在动态人类环境中，移动机器人需要在适应性和安全性之间找到平衡，以应对多样化的行为和安全约束。

Method: 使用密度基础奖励学习和规则基础目标增强的策略，结合采样基础前瞻控制器生成安全和适应性的监督行为。

Result: 实验表明，与基线相比，成功率和时间效率显著提高，且在真实场景中验证了该方法的实用性。

Conclusion: 通过合成和真实实验，证明了该框架在动态人类环境中导航的有效性和安全性。

Abstract: Mobile robot navigation in dynamic human environments requires policies that
balance adaptability to diverse behaviors with compliance to safety
constraints. We hypothesize that integrating data-driven rewards with
rule-based objectives enables navigation policies to achieve a more effective
balance of adaptability and safety. To this end, we develop a framework that
learns a density-based reward from positive and negative demonstrations and
augments it with rule-based objectives for obstacle avoidance and goal
reaching. A sampling-based lookahead controller produces supervisory actions
that are both safe and adaptive, which are subsequently distilled into a
compact student policy suitable for real-time operation with uncertainty
estimates. Experiments in synthetic and elevator co-boarding simulations show
consistent gains in success rate and time efficiency over baselines, and
real-world demonstrations with human participants confirm the practicality of
deployment. A video illustrating this work can be found on our project page
https://chanwookim971024.github.io/PioneeR/.

</details>


### [6] [Spatial Forcing: Implicit Spatial Representation Alignment for Vision-language-action Model](https://arxiv.org/abs/2510.12276)
*Fuhao Li,Wenxuan Song,Han Zhao,Jingbo Wang,Pengxiang Ding,Donglin Wang,Long Zeng,Haoang Li*

Main category: cs.RO

TL;DR: 本文提出了空间强制（SF）方法，增强VLA模型的空间理解能力，取得了优异的实验结果。


<details>
  <summary>Details</summary>
Motivation: 当前的VLA模型在2D数据上预训练，缺乏在3D物理世界中的空间意识，本文旨在通过SF方法弥补这一不足。

Method: 本文提出了一种名为空间强制（SF）的对齐策略，通过在中间层强制对齐VLA的视觉嵌入与预训练的3D基础模型生成的几何表示来提升空间理解能力。

Result: 本文提出了一种新的空间强制（SF）方法，通过隐式对齐视觉嵌入来提高视觉-语言-动作（VLA）模型的空间理解能力，而无需依赖显式的3D输入或深度估计器，实验证明SF在模拟和真实环境中均取得了优异的成果。

Conclusion: SF方法有效提升了VLA模型的空间表示，超越了现有的2D和3D基准，并显著加速了训练和提高了数据效率。

Abstract: Vision-language-action (VLA) models have recently shown strong potential in
enabling robots to follow language instructions and execute precise actions.
However, most VLAs are built upon vision-language models pretrained solely on
2D data, which lack accurate spatial awareness and hinder their ability to
operate in the 3D physical world. Existing solutions attempt to incorporate
explicit 3D sensor inputs such as depth maps or point clouds, but these
approaches face challenges due to sensor noise, hardware heterogeneity, and
incomplete depth coverage in existing datasets. Alternative methods that
estimate 3D cues from 2D images also suffer from the limited performance of
depth estimators.We propose Spatial Forcing (SF), a simple yet effective
alignment strategy that implicitly forces VLA models to develop spatial
comprehension capabilities without relying on explicit 3D inputs or depth
estimators. SF aligns intermediate visual embeddings of VLAs with geometric
representations produced by pretrained 3D foundation models. By enforcing
alignment at intermediate layers, SF guides VLAs to encode richer spatial
representations that enhance action precision.Extensive experiments in
simulation and real-world environments demonstrate that SF achieves
state-of-the-art results, surpassing both 2D- and 3D-based VLAs. SF further
accelerates training by up to 3.8x and improves data efficiency across diverse
robotic tasks. Project page is at https://spatial-forcing.github.io/

</details>


### [7] [Shape-Aware Whole-Body Control for Continuum Robots with Application in Endoluminal Surgical Robotics](https://arxiv.org/abs/2510.12332)
*Mohammadreza Kasaei,Mostafa Ghobadi,Mohsen Khadem*

Main category: cs.RO

TL;DR: 提出了一种形状感知的控制框架，改善了微创手术中的导航精度和安全性。


<details>
  <summary>Details</summary>
Motivation: 针对传统尖端控制在狭窄复杂解剖结构中导致的直接接触和创伤问题，提出一种形状感知的整体控制框架。

Method: 结合物理信息的基础模型与增广神经常微分方程（ODE），实现精确形状估计和高效雅可比计算，同时使用基于采样的模型预测路径积分（MPPI）控制器进行优化。

Result: 仿真研究展示了毫米级的精确度，真实机器人实验验证了框架能有效提高准确性并降低壁面接触。

Conclusion: 该框架在微创内腔手术中提高了安全性、可靠性和操作效率，并具备更广泛的应用潜力。

Abstract: This paper presents a shape-aware whole-body control framework for
tendon-driven continuum robots with direct application to endoluminal surgical
navigation. Endoluminal procedures, such as bronchoscopy, demand precise and
safe navigation through tortuous, patient-specific anatomy where conventional
tip-only control often leads to wall contact, tissue trauma, or failure to
reach distal targets. To address these challenges, our approach combines a
physics-informed backbone model with residual learning through an Augmented
Neural ODE, enabling accurate shape estimation and efficient Jacobian
computation. A sampling-based Model Predictive Path Integral (MPPI) controller
leverages this representation to jointly optimize tip tracking, backbone
conformance, and obstacle avoidance under actuation constraints. A task manager
further enhances adaptability by allowing real-time adjustment of objectives,
such as wall clearance or direct advancement, during tele-operation. Extensive
simulation studies demonstrate millimeter-level accuracy across diverse
scenarios, including trajectory tracking, dynamic obstacle avoidance, and
shape-constrained reaching. Real-robot experiments on a bronchoscopy phantom
validate the framework, showing improved lumen-following accuracy, reduced wall
contacts, and enhanced adaptability compared to joystick-only navigation and
existing baselines. These results highlight the potential of the proposed
framework to increase safety, reliability, and operator efficiency in minimally
invasive endoluminal surgery, with broader applicability to other confined and
safety-critical environments.

</details>


### [8] [Achieving Meaningful Collaboration: Worker-centered Design of a Physical Human-Robot Collaborative Blending Task](https://arxiv.org/abs/2510.12340)
*Nicky Mol,Luka Peternel,Alessandro Ianniello,Denis Zatyagov,Auke Nachenius,Stephan Balvert,J. Micah Prendergast,Sara Muscolo,Olger Siebinga,Eva Verhoef,Deborah Forster,David A. Abbink*

Main category: cs.RO

TL;DR: 论文主张在工业场所应采用跨学科的方法，特别是机器人在飞机发动机维修中的应用，以应对社会挑战并提升员工福祉。


<details>
  <summary>Details</summary>
Motivation: 应对劳动力短缺、老龄化及生产需求不断增加的社会挑战，推动工业机器人使用日益增长。

Method: 通过多方面的努力，结合学术研究、实践经验及员工福祉等价值观，探讨协作机器人在工作场所的应用。

Result: 研究显示通过跨学科的方法可以提升工人福祉和工作的吸引力，同时在飞机发动机修理和维护过程中展示协作机器人的潜力。

Conclusion: 采用跨学科的方法可以有效提升机器人在工业环境中的应用，特别是在飞机发动机维修领域。

Abstract: The use of robots in industrial settings continues to grow, driven by the
need to address complex societal challenges such as labor shortages, aging
populations, and ever-increasing production demands. In this abstract, we
advocate for (and demonstrate) a transdisciplinary approach when considering
robotics in the workplace. Transdisciplinarity emphasizes the integration of
academic research with pragmatic expertise and embodied experiential knowledge,
that prioritize values such as worker wellbeing and job attractiveness. In the
following, we describe an ongoing multi-pronged effort to explore the potential
of collaborative robots in the context of airplane engine repair and
maintenance operations.

</details>


### [9] [PolygMap: A Perceptive Locomotion Framework for Humanoid Robot Stair Climbing](https://arxiv.org/abs/2510.12346)
*Bingquan Li,Ning Wang,Tianwei Zhang,Zhicheng He,Yucong Wu*

Main category: cs.RO

TL;DR: 本文提出了一种称为PolyMap的框架，实现了人形机器人在楼梯攀爬中的有效和鲁棒的运动规划。


<details>
  <summary>Details</summary>
Motivation: 为了模拟人类行走，机器人需要在未知空间中准确地步入视觉所及的点。

Method: PolyMap感知基础的运动规划框架，利用多传感器融合构建实时多边形楼梯平面语义图。

Result: 在NVIDIA Orin上的实施，能够每秒进行20-30次全身运动规划输出。

Conclusion: 通过室内外真实场景实验，验证了该方法在 humanoid robot 阶梯攀爬中的高效性和稳定性。

Abstract: Recently, biped robot walking technology has been significantly developed,
mainly in the context of a bland walking scheme. To emulate human walking,
robots need to step on the positions they see in unknown spaces accurately. In
this paper, we present PolyMap, a perception-based locomotion planning
framework for humanoid robots to climb stairs. Our core idea is to build a
real-time polygonal staircase plane semantic map, followed by a footstep planar
using these polygonal plane segments. These plane segmentation and visual
odometry are done by multi-sensor fusion(LiDAR, RGB-D camera and IMUs). The
proposed framework is deployed on a NVIDIA Orin, which performs 20-30 Hz
whole-body motion planning output. Both indoor and outdoor real-scene
experiments indicate that our method is efficient and robust for humanoid robot
stair climbing.

</details>


### [10] [Pretraining in Actor-Critic Reinforcement Learning for Robot Motion Control](https://arxiv.org/abs/2510.12363)
*Jiale Fan,Andrei Cramariuc,Tifanny Portela,Marco Hutter*

Main category: cs.RO

TL;DR: 本文提出了一种在机器人运动控制中利用预训练模型快速启动强化学习过程的方法，显著提升了样本效率和任务性能。


<details>
  <summary>Details</summary>
Motivation: 在机器人运动控制的强化学习领域，个体技能通常是从零开始学习，而这可能忽视了机器人身上共享的一些可推广知识。

Method: 通过收集多样化的动态过渡数据，训练一个知觉逆动态模型（PIDM），并将预训练权重加载到演员和评论网络中以快速启动策略优化。

Result: 在七个不同的机器人运动控制任务上验证了所提方法，平均提高样本效率40.1%和任务性能7.5%。

Conclusion: 系统验证表明，该初始化策略在多任务中显著提升了学习效率和性能。

Abstract: The pretraining-finetuning paradigm has facilitated numerous transformative
advancements in artificial intelligence research in recent years. However, in
the domain of reinforcement learning (RL) for robot motion control, individual
skills are often learned from scratch despite the high likelihood that some
generalizable knowledge is shared across all task-specific policies belonging
to a single robot embodiment. This work aims to define a paradigm for
pretraining neural network models that encapsulate such knowledge and can
subsequently serve as a basis for warm-starting the RL process in classic
actor-critic algorithms, such as Proximal Policy Optimization (PPO). We begin
with a task-agnostic exploration-based data collection algorithm to gather
diverse, dynamic transition data, which is then used to train a Proprioceptive
Inverse Dynamics Model (PIDM) through supervised learning. The pretrained
weights are loaded into both the actor and critic networks to warm-start the
policy optimization of actual tasks. We systematically validated our proposed
method on seven distinct robot motion control tasks, showing significant
benefits to this initialization strategy. Our proposed approach on average
improves sample efficiency by 40.1% and task performance by 7.5%, compared to
random initialization. We further present key ablation studies and empirical
analyses that shed light on the mechanisms behind the effectiveness of our
method.

</details>


### [11] [Controlling Intent Expressiveness in Robot Motion with Diffusion Models](https://arxiv.org/abs/2510.12370)
*Wenli Shi,Clemence Grislain,Olivier Sigaud,Mohamed Chetouani*

Main category: cs.RO

TL;DR: 本研究提出了一种新颖的运动生成框架，通过控制清晰度，实现机器人与人类之间更好的意图表达，提升了人机交互体验。


<details>
  <summary>Details</summary>
Motivation: 改善人机交互中机器人动作的清晰度，使人类能够快速推断机器人的意图，因此不仅关注效率，也重视上下文中的意图表达。

Method: 提出了一种基于信息势场的建模方法，为轨迹分配连续的清晰度评分，并构建了一个两阶段扩散框架，先生成指定清晰度水平的路径，然后将其转换为可执行的机器人动作。

Result: 在2D和3D任务中的实验表明，该方法可以生成多样化和可控的动作，具有不同的清晰度。

Conclusion: 该框架能够生成多样化且可控的动作，具备不同的清晰度，并且其表现可与现有最先进技术相媲美。

Abstract: Legibility of robot motion is critical in human-robot interaction, as it
allows humans to quickly infer a robot's intended goal. Although traditional
trajectory generation methods typically prioritize efficiency, they often fail
to make the robot's intentions clear to humans. Meanwhile, existing approaches
to legible motion usually produce only a single "most legible" trajectory,
overlooking the need to modulate intent expressiveness in different contexts.
In this work, we propose a novel motion generation framework that enables
controllable legibility across the full spectrum, from highly legible to highly
ambiguous motions. We introduce a modeling approach based on an Information
Potential Field to assign continuous legibility scores to trajectories, and
build upon it with a two-stage diffusion framework that first generates paths
at specified legibility levels and then translates them into executable robot
actions. Experiments in both 2D and 3D reaching tasks demonstrate that our
approach produces diverse and controllable motions with varying degrees of
legibility, while achieving performance comparable to SOTA. Code and project
page: https://legibility-modulator.github.io.

</details>


### [12] [Improving Generative Behavior Cloning via Self-Guidance and Adaptive Chunking](https://arxiv.org/abs/2510.12392)
*Junhyuk So,Chiwoong Lee,Shinyoung Lee,Jungseul Ok,Eunhyeok Park*

Main category: cs.RO

TL;DR: 我们提出了一种改进的生成行为克隆框架，增强了扩散策略在复杂任务中的一致性和反应性。


<details>
  <summary>Details</summary>
Motivation: 针对现有生成行为克隆(GBC)方法在多任务环境中表现良好但存在随机性和反应延迟的问题。

Method: 提出了自我指导和自适应分块两种技术，分别提高了动作保真度和反应性。

Result: 实验表明，我们的方法在多种机器人操作任务中表现出显著的性能提升。

Conclusion: 我们的方法显著提高了多种模拟和真实世界机器人操作任务中生成行为克隆(GBC)的性能。

Abstract: Generative Behavior Cloning (GBC) is a simple yet effective framework for
robot learning, particularly in multi-task settings. Recent GBC methods often
employ diffusion policies with open-loop (OL) control, where actions are
generated via a diffusion process and executed in multi-step chunks without
replanning. While this approach has demonstrated strong success rates and
generalization, its inherent stochasticity can result in erroneous action
sampling, occasionally leading to unexpected task failures. Moreover, OL
control suffers from delayed responses, which can degrade performance in noisy
or dynamic environments. To address these limitations, we propose two novel
techniques to enhance the consistency and reactivity of diffusion policies: (1)
self-guidance, which improves action fidelity by leveraging past observations
and implicitly promoting future-aware behavior; and (2) adaptive chunking,
which selectively updates action sequences when the benefits of reactivity
outweigh the need for temporal consistency. Extensive experiments show that our
approach substantially improves GBC performance across a wide range of
simulated and real-world robotic manipulation tasks. Our code is available at
https://github.com/junhyukso/SGAC

</details>


### [13] [Robot Learning: A Tutorial](https://arxiv.org/abs/2510.12403)
*Francesco Capuano,Caroline Pascal,Adil Zouitine,Thomas Wolf,Michel Aractingi*

Main category: cs.RO

TL;DR: 本教程介绍了现代机器人学习的发展，目标是为研究人员和从业者提供必要的概念理解和实用工具。


<details>
  <summary>Details</summary>
Motivation: 推动机器人学习发展，受益于机器学习和大型机器人数据的快速进展。

Method: 机器人学习的现代教程

Result: 梳理了从强化学习到通用语言条件模型的现代机器人学习的概念和工具。

Conclusion: 环境中多任务的通用模型和实施的实例能够帮助研究人员积极参与机器人学习的进展。

Abstract: Robot learning is at an inflection point, driven by rapid advancements in
machine learning and the growing availability of large-scale robotics data.
This shift from classical, model-based methods to data-driven, learning-based
paradigms is unlocking unprecedented capabilities in autonomous systems. This
tutorial navigates the landscape of modern robot learning, charting a course
from the foundational principles of Reinforcement Learning and Behavioral
Cloning to generalist, language-conditioned models capable of operating across
diverse tasks and even robot embodiments. This work is intended as a guide for
researchers and practitioners, and our goal is to equip the reader with the
conceptual understanding and practical tools necessary to contribute to
developments in robot learning, with ready-to-use examples implemented in
$\texttt{lerobot}$.

</details>


### [14] [M3D-skin: Multi-material 3D-printed Tactile Sensor with Hierarchical Infill Structures for Pressure Sensing](https://arxiv.org/abs/2510.12419)
*Shunnosuke Yoshimura,Kento Kawaharazuka,Kei Okada*

Main category: cs.RO

TL;DR: 本研究提出了一种可通过3D打印便捷制造的多功能触觉传感器M3D-skin，能够在多种领域内得到应用。


<details>
  <summary>Details</summary>
Motivation: 触觉传感器在机器人抓取和人类运动测量等领域有广泛应用，简化其制造和集成将扩展其应用范围。

Method: 利用多材料熔融沉积建模（FDM）3D打印机的填充模式制造触觉传感器

Result: 提出了一种名为M3D-skin的触觉传感器，可以通过层次结构的特定填充模式轻松制作和应用，演示了其在足底运动模式测量、与机器人手集成以及基于触觉的机器人操作中的有效性。

Conclusion: 实验结果验证了所提出的触觉传感器的有效性，表明其在多种应用场景中的潜力。

Abstract: Tactile sensors have a wide range of applications, from utilization in
robotic grippers to human motion measurement. If tactile sensors could be
fabricated and integrated more easily, their applicability would further
expand. In this study, we propose a tactile sensor-M3D-skin-that can be easily
fabricated with high versatility by leveraging the infill patterns of a
multi-material fused deposition modeling (FDM) 3D printer as the sensing
principle. This method employs conductive and non-conductive flexible filaments
to create a hierarchical structure with a specific infill pattern. The flexible
hierarchical structure deforms under pressure, leading to a change in
electrical resistance, enabling the acquisition of tactile information. We
measure the changes in characteristics of the proposed tactile sensor caused by
modifications to the hierarchical structure. Additionally, we demonstrate the
fabrication and use of a multi-tile sensor. Furthermore, as applications, we
implement motion pattern measurement on the sole of a foot, integration with a
robotic hand, and tactile-based robotic operations. Through these experiments,
we validate the effectiveness of the proposed tactile sensor.

</details>


### [15] [A Task-Efficient Reinforcement Learning Task-Motion Planner for Safe Human-Robot Cooperation](https://arxiv.org/abs/2510.12477)
*Gaoyuan Liu,Joris de Winter,Kelly Merckaert,Denis Steckelmacher,Ann Nowe,Bram Vanderborght*

Main category: cs.RO

TL;DR: 提出了一种新的混合增强学习规划框架，提高机器人在与人合作时的安全性和任务效率。


<details>
  <summary>Details</summary>
Motivation: 在机器人与人类合作环境中，安全性和效率是评估机器人性能的核心属性，但安全机制往往会妨碍任务效率。

Method: 提出了一种混合增强学习规划框架，包含交互式运动规划器和增强学习任务规划器。

Result: 验证了该框架在仿真和真实世界中的效果，显示能够应对不确定的人类动作，并减少重复失败的命令次数和总重规划请求数量。

Conclusion: 该规划框架能有效提升人机合作中的安全性和效率，避免危险任务并确保任务安全执行。

Abstract: In a Human-Robot Cooperation (HRC) environment, safety and efficiency are the
two core properties to evaluate robot performance. However, safety mechanisms
usually hinder task efficiency since human intervention will cause backup
motions and goal failures of the robot. Frequent motion replanning will
increase the computational load and the chance of failure. In this paper, we
present a hybrid Reinforcement Learning (RL) planning framework which is
comprised of an interactive motion planner and a RL task planner. The RL task
planner attempts to choose statistically safe and efficient task sequences
based on the feedback from the motion planner, while the motion planner keeps
the task execution process collision-free by detecting human arm motions and
deploying new paths when the previous path is not valid anymore. Intuitively,
the RL agent will learn to avoid dangerous tasks, while the motion planner
ensures that the chosen tasks are safe. The proposed framework is validated on
the cobot in both simulation and the real world, we compare the planner with
hard-coded task motion planning methods. The results show that our planning
framework can 1) react to uncertain human motions at both joint and task
levels; 2) reduce the times of repeating failed goal commands; 3) reduce the
total number of replanning requests.

</details>


### [16] [Fast Visuomotor Policy for Robotic Manipulation](https://arxiv.org/abs/2510.12483)
*Jingkai Jia,Tong Yang,Xueyao Chen,Chenhuan Liu,Wenqiang Zhang*

Main category: cs.RO

TL;DR: 提出了一种快速有效的机器人操作政策框架——Energy Policy，专门针对高频操作和资源受限系统。


<details>
  <summary>Details</summary>
Motivation: 旨在提高机器人操作的精确性和速度，特别是在资源限制的情况下。

Method: 采用能量评分作为学习目标，使用能量多层感知机实现多模态动作建模。

Result: 在MimicGen基准测试中，Energy Policy在推理速度上领先，性能优于现有技术。

Conclusion: Energy Policy在模拟和现实环境中表现优异，显著减少计算开销，性能超越现有方法。

Abstract: We present a fast and effective policy framework for robotic manipulation,
named Energy Policy, designed for high-frequency robotic tasks and
resource-constrained systems. Unlike existing robotic policies, Energy Policy
natively predicts multimodal actions in a single forward pass, enabling
high-precision manipulation at high speed. The framework is built upon two core
components. First, we adopt the energy score as the learning objective to
facilitate multimodal action modeling. Second, we introduce an energy MLP to
implement the proposed objective while keeping the architecture simple and
efficient. We conduct comprehensive experiments in both simulated environments
and real-world robotic tasks to evaluate the effectiveness of Energy Policy.
The results show that Energy Policy matches or surpasses the performance of
state-of-the-art manipulation methods while significantly reducing
computational overhead. Notably, on the MimicGen benchmark, Energy Policy
achieves superior performance with at a faster inference compared to existing
approaches.

</details>


### [17] [Automated Behavior Planning for Fruit Tree Pruning via Redundant Robot Manipulators: Addressing the Behavior Planning Challenge](https://arxiv.org/abs/2510.12509)
*Gaoyuan Liu,Bas Boom,Naftali Slob,Yuri Durodié,Ann Nowé,Bram Vanderborght*

Main category: cs.RO

TL;DR: 本研究提出了一种集成感知、建模和规划的机器人修剪综合工作流程，显著提高了机器手的性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统修剪任务中的感知不足及操控复杂性

Method: 综合规划工作流程

Result: 在真实机器人上实现了提出的工作流程，证明了全面规划方法的有效性

Conclusion: 此工作补充了机器人修剪的研究，并激励未来在修剪应用的规划研究与开发。

Abstract: Pruning is an essential agricultural practice for orchards. Proper pruning
can promote healthier growth and optimize fruit production throughout the
orchard's lifespan. Robot manipulators have been developed as an automated
solution for this repetitive task, which typically requires seasonal labor with
specialized skills. While previous research has primarily focused on the
challenges of perception, the complexities of manipulation are often
overlooked. These challenges involve planning and control in both joint and
Cartesian spaces to guide the end-effector through intricate, obstructive
branches. Our work addresses the behavior planning challenge for a robotic
pruning system, which entails a multi-level planning problem in environments
with complex collisions. In this paper, we formulate the planning problem for a
high-dimensional robotic arm in a pruning scenario, investigate the system's
intrinsic redundancies, and propose a comprehensive pruning workflow that
integrates perception, modeling, and holistic planning. In our experiments, we
demonstrate that more comprehensive planning methods can significantly enhance
the performance of the robotic manipulator. Finally, we implement the proposed
workflow on a real-world robot. As a result, this work complements previous
efforts on robotic pruning and motivates future research and development in
planning for pruning applications.

</details>


### [18] [Two-stream network-driven vision-based tactile sensor for object feature extraction and fusion perception](https://arxiv.org/abs/2510.12528)
*Muxing Huang,Zibin Chen,Weiliang Xu,Zilan Li,Yuanzhi Zhou,Guoyuan Zhou,Wenjing Chen,Xinming Li*

Main category: cs.RO

TL;DR: 采用双流网络特征提取与融合策略，改善视觉触觉系统在物体识别中的表现，硬度识别准确率达98.0%。


<details>
  <summary>Details</summary>
Motivation: 改善现有单维提取和特征融合不足的问题，以提高机器人在物体识别过程中的准确性。

Method: 该方法使用卷积神经网络（CNN）提取物体内部及外部特征，通过深度图信息和接触力数据获取物体的物理属性，并进行加权融合。

Result: 本研究提出了一种用于视觉触觉系统的双流网络特征提取和融合感知策略，显著提高了物体识别的准确性。

Conclusion: 通过融合算法，物体在实际抓取场景中的识别准确率超过98.5%，有效提升了人工触觉系统从感知到认知的能力。

Abstract: Tactile perception is crucial for embodied intelligent robots to recognize
objects. Vision-based tactile sensors extract object physical attributes
multidimensionally using high spatial resolution; however, this process
generates abundant redundant information. Furthermore, single-dimensional
extraction, lacking effective fusion, fails to fully characterize object
attributes. These challenges hinder the improvement of recognition accuracy. To
address this issue, this study introduces a two-stream network feature
extraction and fusion perception strategy for vision-based tactile systems.
This strategy employs a distributed approach to extract internal and external
object features. It obtains depth map information through three-dimensional
reconstruction while simultaneously acquiring hardness information by measuring
contact force data. After extracting features with a convolutional neural
network (CNN), weighted fusion is applied to create a more informative and
effective feature representation. In standard tests on objects of varying
shapes and hardness, the force prediction error is 0.06 N (within a 12 N
range). Hardness recognition accuracy reaches 98.0%, and shape recognition
accuracy reaches 93.75%. With fusion algorithms, object recognition accuracy in
actual grasping scenarios exceeds 98.5%. Focused on object physical attributes
perception, this method enhances the artificial tactile system ability to
transition from perception to cognition, enabling its use in embodied
perception applications.

</details>


### [19] [Learning Robust Agile Flight Control with Stability Guarantees](https://arxiv.org/abs/2510.12611)
*Lukas Pries,Markus Ryll*

Main category: cs.RO

TL;DR: 论文提出了一种新型神经增强反馈控制器，旨在提高四旋翼的轨迹跟踪精度和鲁棒性，尤其在极端条件下表现优异。


<details>
  <summary>Details</summary>
Motivation: 实现高效、精确的四旋翼轨迹跟踪，特别是在激进飞行和干扰环境下。

Method: 神经增强反馈控制器

Result: 提出的控制器在超出执行器可行性的情况下，实现了高精度轨迹跟踪，并提供了通用的稳定性保障。

Conclusion: 该控制器能够在无需额外训练的情况下，直接应用于现实世界平台，展示出较强的实用性和效率。

Abstract: In the evolving landscape of high-speed agile quadrotor flight, achieving
precise trajectory tracking at the platform's operational limits is paramount.
Controllers must handle actuator constraints, exhibit robustness to
disturbances, and remain computationally efficient for safety-critical
applications. In this work, we present a novel neural-augmented feedback
controller for agile flight control. The controller addresses individual
limitations of existing state-of-the-art control paradigms and unifies their
strengths. We demonstrate the controller's capabilities, including the accurate
tracking of highly aggressive trajectories that surpass the feasibility of the
actuators. Notably, the controller provides universal stability guarantees,
enhancing its robustness and tracking performance even in exceedingly
disturbance-prone settings. Its nonlinear feedback structure is highly
efficient enabling fast computation at high update rates. Moreover, the
learning process in simulation is both fast and stable, and the controller's
inherent robustness allows direct deployment to real-world platforms without
the need for training augmentations or fine-tuning.

</details>


### [20] [Designing Tools with Control Confidence](https://arxiv.org/abs/2510.12630)
*Ajith Anil Meera,Abian Torres,Pablo Lanillos*

Main category: cs.RO

TL;DR: 本文提出了一种优化框架，在工具设计中引入控制置信度，提高了工具的鲁棒性，并且优化策略在迭代中表现优越。


<details>
  <summary>Details</summary>
Motivation: 当前的自主工具设计框架仅依赖性能优化，未考虑工具在重复使用中的使用者信心。

Method: 定义了一种针对任务条件的自主手工具设计优化框架，并将神经灵感的控制置信度引入优化程序。

Result: 通过对机器人手臂的严格模拟，设计的工具对环境不确定性的鲁棒性优于纯准确性驱动的目标。

Conclusion: 我们的CMAES基础进化优化策略在最少的迭代中设计出最佳工具，表现优于其他最先进的优化器。

Abstract: Prehistoric humans invented stone tools for specialized tasks by not just
maximizing the tool's immediate goal-completion accuracy, but also increasing
their confidence in the tool for later use under similar settings. This factor
contributed to the increased robustness of the tool, i.e., the least
performance deviations under environmental uncertainties. However, the current
autonomous tool design frameworks solely rely on performance optimization,
without considering the agent's confidence in tool use for repeated use. Here,
we take a step towards filling this gap by i) defining an optimization
framework for task-conditioned autonomous hand tool design for robots, where
ii) we introduce a neuro-inspired control confidence term into the optimization
routine that helps the agent to design tools with higher robustness. Through
rigorous simulations using a robotic arm, we show that tools designed with
control confidence as the objective function are more robust to environmental
uncertainties during tool use than a pure accuracy-driven objective. We further
show that adding control confidence to the objective function for tool design
provides a balance between the robustness and goal accuracy of the designed
tools under control perturbations. Finally, we show that our CMAES-based
evolutionary optimization strategy for autonomous tool design outperforms other
state-of-the-art optimizers by designing the optimal tool within the fewest
iterations. Code: https://github.com/ajitham123/Tool_design_control_confidence.

</details>


### [21] [Maximal Adaptation, Minimal Guidance: Permissive Reactive Robot Task Planning with Humans in the Loop](https://arxiv.org/abs/2510.12662)
*Oz Gitelson,Satya Prakash Nayak,Ritam Raha,Anne-Kathrin Schmuck*

Main category: cs.RO

TL;DR: 提出了一种新的人机逻辑互动框架，机器人能够在执行任务时灵活适应，并与人类协作，验证结果显示优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 构建一个能让机器人在执行任务的同时，与追求独立任务的人类有效协作的框架。

Method: 通过最大适应能力和最少可调反馈的结合，实现机器人与人类的有效合作。

Result: 在真实的块操作任务和Overcooked-AI基准测试中验证了该方法的有效性，显示出丰富的涌现协作行为。

Conclusion: 该框架在实际任务中展现出超越现有方法的协作行为，并确保了任务满意度和人机自主性。

Abstract: We present a novel framework for human-robot \emph{logical} interaction that
enables robots to reliably satisfy (infinite horizon) temporal logic tasks
while effectively collaborating with humans who pursue independent and unknown
tasks. The framework combines two key capabilities: (i) \emph{maximal
adaptation} enables the robot to adjust its strategy \emph{online} to exploit
human behavior for cooperation whenever possible, and (ii) \emph{minimal
tunable feedback} enables the robot to request cooperation by the human online
only when necessary to guarantee progress. This balance minimizes human-robot
interference, preserves human autonomy, and ensures persistent robot task
satisfaction even under conflicting human goals. We validate the approach in a
real-world block-manipulation task with a Franka Emika Panda robotic arm and in
the Overcooked-AI benchmark, demonstrating that our method produces rich,
\emph{emergent} cooperative behaviors beyond the reach of existing approaches,
while maintaining strong formal guarantees.

</details>


### [22] [Autonomous Legged Mobile Manipulation for Lunar Surface Operations via Constrained Reinforcement Learning](https://arxiv.org/abs/2510.12684)
*Alvaro Belmonte-Baeza,Miguel Cazorla,Gabriel J. García,Carlos J. Pérez-Del-Pulgar,Jorge Pomares*

Main category: cs.RO

TL;DR: 本文研究了一种面向月球环境的四足机器人自适应控制框架，提升了在复杂和恶劣条件下的自主移动和操作能力，实验结果表明性能优越，具备未来探月任务的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 随着太阳系探索和月球基地建设的需求，对能够在恶劣月球地形中进行导航和操控的机器人的需求日益增加。

Method: 本文提出了一种针对在月球环境中操作的四足移动操纵器的约束强化学习框架，集成了全身运动和操控能力，并关注安全约束如碰撞避免、动态稳定性和能效。

Result: 实验结果显示，框架在实现精确的6D任务空间末端执行器姿态跟踪方面取得了有效性，平均位置精度为4厘米，方向精度为8.1度，且系统始终遵循软约束和硬约束。

Conclusion: 该研究有效地将自适应学习与重要的任务关键安全要求结合起来，从而为未来的月球任务提供了先进的自主机器人探索平台。

Abstract: Robotics plays a pivotal role in planetary science and exploration, where
autonomous and reliable systems are crucial due to the risks and challenges
inherent to space environments. The establishment of permanent lunar bases
demands robotic platforms capable of navigating and manipulating in the harsh
lunar terrain. While wheeled rovers have been the mainstay for planetary
exploration, their limitations in unstructured and steep terrains motivate the
adoption of legged robots, which offer superior mobility and adaptability. This
paper introduces a constrained reinforcement learning framework designed for
autonomous quadrupedal mobile manipulators operating in lunar environments. The
proposed framework integrates whole-body locomotion and manipulation
capabilities while explicitly addressing critical safety constraints, including
collision avoidance, dynamic stability, and power efficiency, in order to
ensure robust performance under lunar-specific conditions, such as reduced
gravity and irregular terrain. Experimental results demonstrate the framework's
effectiveness in achieving precise 6D task-space end-effector pose tracking,
achieving an average positional accuracy of 4 cm and orientation accuracy of
8.1 degrees. The system consistently respects both soft and hard constraints,
exhibiting adaptive behaviors optimized for lunar gravity conditions. This work
effectively bridges adaptive learning with essential mission-critical safety
requirements, paving the way for advanced autonomous robotic explorers for
future lunar missions.

</details>


### [23] [Reflection-Based Task Adaptation for Self-Improving VLA](https://arxiv.org/abs/2510.12710)
*Baicheng Li,Dong Wu,Zike Yan,Xinchen Liu,Zecui Zeng,Lusong Li,Hongbin Zha*

Main category: cs.RO

TL;DR: 本研究提出了一种新的自适应框架，能迅速且高效地使机器人适应新环境，提升任务完成率。


<details>
  <summary>Details</summary>
Motivation: 虽然预训练的视觉-语言-行动模型在通用机器人中展示了良好的潜力，但在特定任务中高效适应依然面临挑战。

Method: 提出了反思性自适应框架，该框架包含一个双通道架构，应用失败驱动的反思强化学习和成功驱动的质量指导自监督学习方法。

Result: 实验结果表明，所提框架在操作任务中相比基准方法具有更快的收敛速度和更高的成功率。

Conclusion: 本研究提出了一种高效可靠的自我改进代理，能够有效适应新环境。

Abstract: Pre-trained Vision-Language-Action (VLA) models represent a major leap
towards general-purpose robots, yet efficiently adapting them to novel,
specific tasks in-situ remains a significant hurdle. While reinforcement
learning (RL) is a promising avenue for such adaptation, the process often
suffers from low efficiency, hindering rapid task mastery. We introduce
Reflective Self-Adaptation, a framework for rapid, autonomous task adaptation
without human intervention. Our framework establishes a self-improving loop
where the agent learns from its own experience to enhance both strategy and
execution.
  The core of our framework is a dual-pathway architecture that addresses the
full adaptation lifecycle. First, a Failure-Driven Reflective RL pathway
enables rapid learning by using the VLM's causal reasoning to automatically
synthesize a targeted, dense reward function from failure analysis. This
provides a focused learning signal that significantly accelerates policy
exploration. However, optimizing such proxy rewards introduces a potential risk
of "reward hacking," where the agent masters the reward function but fails the
actual task. To counteract this, our second pathway, Success-Driven
Quality-Guided SFT, grounds the policy in holistic success. It identifies and
selectively imitates high-quality successful trajectories, ensuring the agent
remains aligned with the ultimate task goal. This pathway is strengthened by a
conditional curriculum mechanism to aid initial exploration.
  We conduct experiments in challenging manipulation tasks. The results
demonstrate that our framework achieves faster convergence and higher final
success rates compared to representative baselines. Our work presents a robust
solution for creating self-improving agents that can efficiently and reliably
adapt to new environments.

</details>


### [24] [Residual MPC: Blending Reinforcement Learning with GPU-Parallelized Model Predictive Control](https://arxiv.org/abs/2510.12717)
*Se Hwan Jeon,Ho Jae Lee,Seungwoo Hong,Sangbae Kim*

Main category: cs.RO

TL;DR: 本研究提出了一种结合模型预测控制与强化学习的新架构，提升了运动控制的鲁棒性与灵活性。


<details>
  <summary>Details</summary>
Motivation: 在实现可解释性和适应性之间取得平衡，解决MPC在模型不匹配和实时计算限制下的鲁棒性问题，以及RL在可解释性和奖励工程方面的不足。

Method: 使用GPU并行化残差架构，将MPC和RL的输出在扭矩控制层面结合。

Result: 相较于传统MPC或端到端RL，该方法在样本效率、最终奖励、可跟踪速度命令的范围、以及对新步态与不平坦地形的零-shot适应方面都有显著提升。

Conclusion: 该方法结合了MPC和RL的优点，具有更高的样本效率和适应性。

Abstract: Model Predictive Control (MPC) provides interpretable, tunable locomotion
controllers grounded in physical models, but its robustness depends on frequent
replanning and is limited by model mismatch and real-time computational
constraints. Reinforcement Learning (RL), by contrast, can produce highly
robust behaviors through stochastic training but often lacks interpretability,
suffers from out-of-distribution failures, and requires intensive reward
engineering. This work presents a GPU-parallelized residual architecture that
tightly integrates MPC and RL by blending their outputs at the torque-control
level. We develop a kinodynamic whole-body MPC formulation evaluated across
thousands of agents in parallel at 100 Hz for RL training. The residual policy
learns to make targeted corrections to the MPC outputs, combining the
interpretability and constraint handling of model-based control with the
adaptability of RL. The model-based control prior acts as a strong bias,
initializing and guiding the policy towards desirable behavior with a simple
set of rewards. Compared to standalone MPC or end-to-end RL, our approach
achieves higher sample efficiency, converges to greater asymptotic rewards,
expands the range of trackable velocity commands, and enables zero-shot
adaptation to unseen gaits and uneven terrain.

</details>


### [25] [T(R,O) Grasp: Efficient Graph Diffusion of Robot-Object Spatial Transformation for Cross-Embodiment Dexterous Grasping](https://arxiv.org/abs/2510.12724)
*Xin Fei,Zhixuan Xu,Huaicong Fang,Tianrui Zhang,Lin Shao*

Main category: cs.RO

TL;DR: 提出了T(R,O) Grasp框架，能高效生成机器人手抓取，成功率和推理速度优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决机器人在多维状态和行动空间中的灵巧抓取挑战，提高抓取的准确性和多样性。

Method: 利用图扩散模型和逆向运动学求解器，在统一图模型基础上进行无条件和有条件的抓取合成。

Result: T(R,O) Grasp是一个基于扩散的框架，能够有效生成准确和多样化的抓取动作，具有94.83%的成功率和0.21秒的推理速度。

Conclusion: T(R,O) Grasp展示了在灵巧抓取中的巨大潜力，能成为未来灵巧抓取的基础模型，具备高效、强大的泛化能力。

Abstract: Dexterous grasping remains a central challenge in robotics due to the
complexity of its high-dimensional state and action space. We introduce T(R,O)
Grasp, a diffusion-based framework that efficiently generates accurate and
diverse grasps across multiple robotic hands. At its core is the T(R,O) Graph,
a unified representation that models spatial transformations between robotic
hands and objects while encoding their geometric properties. A graph diffusion
model, coupled with an efficient inverse kinematics solver, supports both
unconditioned and conditioned grasp synthesis. Extensive experiments on a
diverse set of dexterous hands show that T(R,O) Grasp achieves average success
rate of 94.83%, inference speed of 0.21s, and throughput of 41 grasps per
second on an NVIDIA A100 40GB GPU, substantially outperforming existing
baselines. In addition, our approach is robust and generalizable across
embodiments while significantly reducing memory consumption. More importantly,
the high inference speed enables closed-loop dexterous manipulation,
underscoring the potential of T(R,O) Grasp to scale into a foundation model for
dexterous grasping.

</details>


### [26] [HYPE: Hybrid Planning with Ego Proposal-Conditioned Predictions](https://arxiv.org/abs/2510.12733)
*Hang Yu,Julian Jordan,Julian Schmidt,Silvan Lindner,Alessandro Canevaro,Wilhelm Stork*

Main category: cs.RO

TL;DR: HYPE是一种新的运动规划方法，集成了多模态轨迹提案和预测模型，以提高复杂城市环境中的安全性和适应性。


<details>
  <summary>Details</summary>
Motivation: 在复杂的城市环境中进行安全且可解释的运动规划，尤其需要考虑双向多智能体的交互及其费用估计。

Method: HYPE结合了来自学习的提案模型的多模态轨迹提案，作为启发式先验，融入蒙特卡洛树搜索的优化过程。

Result: HYPE在nuPlan和DeepUrban这两个大型实际基准上的评估显示，其在安全性和适应性方面达到了目前的先进水平。

Conclusion: 通过考虑提案驱动的指导，HYPE在优化过程中简化了成本函数设计，显示出良好的性能。

Abstract: Safe and interpretable motion planning in complex urban environments needs to
reason about bidirectional multi-agent interactions. This reasoning requires to
estimate the costs of potential ego driving maneuvers. Many existing planners
generate initial trajectories with sampling-based methods and refine them by
optimizing on learned predictions of future environment states, which requires
a cost function that encodes the desired vehicle behavior. Designing such a
cost function can be very challenging, especially if a wide range of complex
urban scenarios has to be considered. We propose HYPE: HYbrid Planning with Ego
proposal-conditioned predictions, a planner that integrates multimodal
trajectory proposals from a learned proposal model as heuristic priors into a
Monte Carlo Tree Search (MCTS) refinement. To model bidirectional interactions,
we introduce an ego-conditioned occupancy prediction model, enabling
consistent, scene-aware reasoning. Our design significantly simplifies cost
function design in refinement by considering proposal-driven guidance,
requiring only minimalistic grid-based cost terms. Evaluations on large-scale
real-world benchmarks nuPlan and DeepUrban show that HYPE effectively achieves
state-of-the-art performance, especially in safety and adaptability.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [27] [Generative Multi-Sensory Meditation: Exploring Immersive Depth and Activation in Virtual Reality](https://arxiv.org/abs/2510.11830)
*Yuyang Jiang,Binzhu Xie,Lina Xu,Xiaokang Lei,Shi Qiu,Luwen Yu,Pan Hui*

Main category: cs.HC

TL;DR: MindfulVerse通过个性化冥想体验和用户动态调整内容，提高情绪调节和自我调节能力。


<details>
  <summary>Details</summary>
Motivation: 现有的冥想应用框架缺乏个性化设计，不能适应不同用户的心理状态和健康状况。

Method: 构建了一种新颖的代理，通过动态调整冥想内容来满足用户的个体需求，同时进行了探索性用户研究和比较评估。

Result: 用户研究结果显示，生成的冥想内容能够提升自我调节能力的神经激活，并对情绪调节和参与度产生积极影响。

Conclusion: MindfulVerse应用程序通过个性化和沉浸式的冥想体验，能够有效改善用户的情绪调节和自我调节能力。

Abstract: Mindfulness meditation has seen increasing applications in diverse domains as
an effective practice to improve mental health. However, the standardized
frameworks adopted by most applications often fail to cater to users with
various psychological states and health conditions. This limitation arises
primarily from the lack of personalization and adaptive content design. To
address this, we propose MindfulVerse, an AI-Generated Content (AIGC)-driven
application to create personalized and immersive mindfulness experiences. By
developing a novel agent, the system can dynamically adjust the meditation
content based on the ideas of individual users. Furthermore, we conducted
exploratory user studies and comparative evaluations to assess the application
scenarios and performance of our novel generative meditation tool in VR
environments. The results of this user study indicate that generative
meditation improves neural activation in self-regulation and shows a positive
impact on emotional regulation and participation. Our approach offers a
generative meditation procedure that provides users with an application that
better suits their preferences and states.

</details>


### [28] [A Longitudinal Study on Different Annotator Feedback Loops in Complex RAG Tasks](https://arxiv.org/abs/2510.11897)
*Sara Rosenthal,Maeda Hanafi,Yannis Katsis,Lucian Popa,Marina Danilevsky*

Main category: cs.HC

TL;DR: 本研究对内部和外部人类标注者在创建多轮RAG对话的研究，揭示了不同反馈循环对对话质量的影响，并提供了复杂标注任务的最佳利用方式。


<details>
  <summary>Details</summary>
Motivation: 为了确保基于大型语言模型的对话系统真实可靠，避免提供错误信息，同时评估其在多轮对话生成任务中的表现。

Method: 进行一项纵向研究，比较内部和外部人类标注者在创建多轮RAG对话方面的反馈循环，分析对话和进行问卷调查。

Result: 分析结果显示，内部与外部标注者在创建对话质量、数量和多样性方面存在差异；紧密的反馈循环提高了对话质量，但降低了数量和多样性。

Conclusion: 本研究展示了不同人类标注者群体在复杂标注任务中的优势和反馈循环的影响，为复杂的标注任务提供了指导。

Abstract: Grounding conversations in existing passages, known as Retrieval-Augmented
Generation (RAG), is an important aspect of Chat-Based Assistants powered by
Large Language Models (LLMs) to ensure they are faithful and don't provide
misinformation. Several benchmarks have been created to measure the performance
of LLMs on this task. We present a longitudinal study comparing the feedback
loop of an internal and external human annotator group for the complex
annotation task of creating multi-turn RAG conversations for evaluating LLMs.
We analyze the conversations produced by both groups and provide results of a
survey comparing their experiences. Our study highlights the advantages of each
annotator population and the impact of the different feedback loops; a closer
loop creates higher quality conversations with a decrease in quantity and
diversity. Further, we present guidance for how to best utilize two different
population groups when performing annotation tasks, particularly when the task
is complex.

</details>


### [29] [Evaluating Line Chart Strategies for Mitigating Density of Temporal Data: The Impact on Trend, Prediction, and Decision-Making](https://arxiv.org/abs/2510.11912)
*Rifat Ara Proma,Ghulam Jilani Quadri,Paul Rosen*

Main category: cs.HC

TL;DR: 本研究比较了聚合、网格和螺旋线图与标准线图在趋势识别、预测和决策中的表现，发现聚合图的效果优于其他图表。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统线图在展示时间序列数据时的不足，特别是当数据密集时，它们可能导致趋势模糊和预测困难。

Method: 通过用户研究比较了三种替代线图与标准线图在趋势识别、预测和决策任务中的表现。

Result: 本研究旨在比较不同类型线性图表在趋势识别和决策制定中的效果，特别是针对时间序列数据的可视化挑战。

Conclusion: 聚合线图在趋势识别和预测方面表现良好，值得推荐用于密集时间数据的可视化；而网格和螺旋线图则表现较差，尤其是在决策信任方面。

Abstract: Overplotted line charts can obscure trends in temporal data and hinder
prediction. We conduct a user study comparing three alternatives-aggregated,
trellis, and spiral line charts against standard line charts on tasks involving
trend identification, making predictions, and decision-making. We found
aggregated charts performed similarly to standard charts and support more
accurate trend recognition and prediction; trellis and spiral charts generally
lag. We also examined the impact on decision-making via a trust game. The
results showed similar trust in standard and aggregated charts, varied trust in
spiral charts, and a lean toward distrust in trellis charts. These findings
provide guidance for practitioners choosing visualization strategies for dense
temporal data.

</details>


### [30] [Visual Stenography: Feature Recreation and Preservation in Sketches of Noisy Line Charts](https://arxiv.org/abs/2510.11927)
*Rifat Ara Proma,Michael Correll,Ghulam Jilani Quadri,Paul Rosen*

Main category: cs.HC

TL;DR: 本研究探讨了视觉混杂对时间序列数据特征优先级的影响，识别出了三种重绘策略。


<details>
  <summary>Details</summary>
Motivation: 探索时间序列数据中视觉混杂对特征优先级的影响

Method: 视觉隐写任务，参与者重绘折线图以获取重要视觉特征的信息

Result: 识别出三种主要策略，分别为Replicator、Trend Keeper和De-noiser，且参与者在保留重要趋势时表现出一致性。

Conclusion: 结果表明需要更灵活、人性化的数据呈现和处理方式。

Abstract: Line charts surface many features in time series data, from trends to
periodicity to peaks and valleys. However, not every potentially important
feature in the data may correspond to a visual feature which readers can detect
or prioritize. In this study, we conducted a visual stenography task, where
participants re-drew line charts to solicit information about the visual
features they believed to be important. We systematically varied noise levels
(SNR ~5-30 dB) across line charts to observe how visual clutter influences
which features people prioritize in their sketches. We identified three key
strategies that correlated with the noise present in the stimuli: the
Replicator attempted to retain all major features of the line chart including
noise; the Trend Keeper prioritized trends disregarding periodicity and peaks;
and the De-noiser filtered out noise while preserving other features. Further,
we found that participants tended to faithfully retain trends and peaks and
valleys when these features were present, while periodicity and noise were
represented in more qualitative or gestural ways: semantically rather than
accurately. These results suggest a need to consider more flexible and
human-centric ways of presenting, summarizing, pre-processing, or clustering
time series data.

</details>


### [31] [Refashion: Reconfigurable Garments via Modular Design](https://arxiv.org/abs/2510.11941)
*Rebecca Lin,Michal Lukáč,Mackenzie Leake*

Main category: cs.HC

TL;DR: 提出了一种模块化服装设计方法，可以适应身体变化和潮流变化，通过数字工具支持修改与重用。


<details>
  <summary>Details</summary>
Motivation: 现有服装尺寸与风格固定，无法适应身体变化和潮流变化，传统的修改方式耗时且不可逆，因此需要一种新的设计方式。

Method: 模块化服装设计

Result: 提出了一套紧凑的模块和连接器，能够作为模块化服装的构建块，并利用整数线性规划方法将服装分解成模块，以及支持模块化服装设计和仿真的数字设计工具。

Conclusion: 用户评价建议该模块化设计方法能够支持多样化服装的创建，并帮助用户在不同尺寸和风格之间进行转换，同时重用相同的构建块。

Abstract: While bodies change over time and trends vary, most store-bought clothing
comes in fixed sizes and styles and fails to adapt to these changes.
Alterations can enable small changes to otherwise static garments, but these
changes often require sewing and are non-reversible. We propose a modular
approach to garment design that considers resizing, restyling, and reuse
earlier in the design process. Our contributions include a compact set of
modules and connectors that form the building blocks of modular garments, a
method to decompose a garment into modules via integer linear programming, and
a digital design tool that supports modular garment design and simulation. Our
user evaluation suggests that our approach to modular design can support the
creation of a wide range of garments and can help users transform them across
sizes and styles while reusing the same building blocks.

</details>


### [32] [VizCopilot: Fostering Appropriate Reliance on Enterprise Chatbots with Context Visualization](https://arxiv.org/abs/2510.11954)
*Sam Yu-Te Lee,Jingya Chen,Albert Calzaretto,Richard Lee,Alice Ferng,Mihaela Vorvoreanu*

Main category: cs.HC

TL;DR: VizCopilot原型通过可视化技术增强了用户在上下文对齐中的参与，提升了信息检索的相关性，并指出了未来在个性化和人机合作方面的设计方向。


<details>
  <summary>Details</summary>
Motivation: 为了解决企业聊天机器人在信息合成任务中因上下文不一致而导致的无关响应问题，提出了一种结合可视化的解决方案。

Method: 通过研究-设计的方式进行了VizCopilot的评估，探讨了可视化在上下文对齐中的作用。

Result: 使用VizCopilot后，用户能够更有效地检测并纠正上下文的不一致，还能够调整提示策略，从而提高系统检索相关上下文的能力。

Conclusion: 本研究展示了可视化技术在上下文对齐中的重要性，并指出了未来设计的信息丰富性和用户适应性的潜在方向。

Abstract: Enterprise chatbots show promise in supporting knowledge workers in
information synthesis tasks by retrieving context from large, heterogeneous
databases before generating answers. However, when the retrieved context
misaligns with user intentions, the chatbot often produces "irrelevantly right"
responses that provide little value. In this work, we introduce VizCopilot, a
prototype that incorporates visualization techniques to actively involve
end-users in context alignment. By combining topic modeling with document
visualization, VizCopilot enables human oversight and modification of retrieved
context while keeping cognitive overhead manageable. We used VizCopilot as a
design probe in a Research-through-Design study to evaluate the role of
visualization in context alignment and to surface future design opportunities.
Our findings show that visualization not only helps users detect and correct
misaligned context but also encourages them to adapt their prompting
strategies, enabling the system to retrieve more relevant context from the
outset. At the same time, the study reveals limitations in verification support
regarding close-reading and trust in AI summaries. We outline future directions
for visualization-enhanced chatbots, focusing on personalization, proactivity,
and sustainable human-AI collaboration.

</details>


### [33] [Choose Your Own Solution: Supporting Optional Blocks in Block Ordering Problems](https://arxiv.org/abs/2510.11999)
*Skyler Oakeson,David H. Smith IV,Jaxton Winder,Seth Poulsen*

Main category: cs.HC

TL;DR: 论文扩展了区块排序问题，引入可选区块，提供了实现算法和教学实例，旨在提高学生对复杂解法的理解与应用。


<details>
  <summary>Details</summary>
Motivation: 旨在增强区块排序问题的复杂度与灵活性，使学生能接触到多种解决方案，并提高他们的实践能力。

Method: 通过使用多重图结构表示区块之间的互斥依赖关系，并将其转化为多个有向无环图(DAG)，从而应用现有算法进行评分。

Result: 该论文扩展了区块排序问题的功能，增加了可选区块，并介绍了算法实现及其在教学中的使用经验。这一特性使得教学人员能够设计更复杂的区块排序问题，给出多种正确解法，使学生能参与到有多种有效解的问答中。

Conclusion: 可选区块特性可以支持教学中更加灵活多样的评估方式，促进学生对多解题目的理解。

Abstract: This paper extends the functionality of block ordering problems (such as
Parsons problems and Proof Blocks) to include optional blocks. We detail the
algorithms used to implement the optional block feature and present usage
experiences from instructors who have integrated it into their curriculum. The
optional blocks feature enables instructors to create more complex Parsons
problems with multiple correct solutions utilizing omitted or optional blocks.
This affords students a method to engage with questions that have several valid
solutions composed of different answer components. Instructors can specify
blocks with multiple mutually exclusive dependencies, which we represent using
a multigraph structure. This multigraph is then collapsed into multiple
directed acyclic graphs (DAGs), allowing us to reuse existing algorithms for
grading block ordering problems represented as a DAG. We present potential use
cases for this feature across various domains, including helping students learn
Git workflows, shell command sequences, mathematical proofs, and Python
programming concepts.

</details>


### [34] [Social Simulation for Integrating Self-Care: Measuring the Effects of Contextual Environments in Augmented Reality for Mental Health Practice](https://arxiv.org/abs/2510.12081)
*Anna Fang,Jiayang Shi,Hriday Chhabria,Bosi Li,Haiyi Zhu*

Main category: cs.HC

TL;DR: 本研究表明，通过增强现实技术提供的现实情境模拟可以更有效地提升心理健康技能的实际应用。


<details>
  <summary>Details</summary>
Motivation: 探讨现实社交模拟如何更好地支持心理健康技能的转移与应用。

Method: 进行了一项为期14天的用户研究，比较增强现实干预与匹配的非情境控制在公众演讲环境中的效果。

Result: 在情境环境中练习心理健康技能的参与者在模拟面对面任务中表现出更高的自我护理技巧应用的可能性和更大的生理压力降低。

Conclusion: 我们的研究提供了现实压力模拟效果的实证依据，并为心理健康技术的设计提供了支持有效技能转移到现实世界的启示。

Abstract: Despite growing interest in virtual and augmented reality (VR/AR) for mental
well-being, prior work using immersive interventions to teach mental health
skills has largely focused on calming or abstract settings. As a result, little
is known about how realistic social simulation may better support the transfer
and application of skills to in-person environments. In this work, we present a
14-day user study with 43-participants comparing an augmented reality
intervention simulating a realistic contextual environment against a matched
non-contextual control, applied to the public speaking context. We found that
participants who practice mental health skills in the contextual environment
showed significantly greater likelihood to apply self-care techniques and
greater physiological stress reduction when using skills in mock in-person
tasks. Overall, our work provides empirical evidence for the effects of
realistic stressor simulation, and offers design implications for mental health
technology that supports effective transfer of skills to the real-world.

</details>


### [35] [KnowledgeTrail: Generative Timeline for Exploration and Sensemaking of Historical Events and Knowledge Formation](https://arxiv.org/abs/2510.12113)
*Sangho Suh,Rahul Hingorani,Bryan Wang,Tovi Grossman*

Main category: cs.HC

TL;DR: 我们提出了生成性时间线的概念，通过KnowledgeTrail系统，增强用户的探索性和发现能力，同时提出了设计平衡随机发现和可信度的见解。


<details>
  <summary>Details</summary>
Motivation: 当前的互动系统向动态、生成性体验转变，但静态的时间线限制了用户的主动性和好奇心。

Method: 通过两个用户研究，检验KnowledgeTrail对探索和发现的促进作用，以及其引用功能对来源可信度的影响。

Result: 提出了生成性时间线的概念，并通过KnowledgeTrail系统进行了实例化，支持用户共同构建历史事件和知识形成过程的时间线。

Conclusion: 生成性时间线作为新型探索界面的愿景与设计见解，有助于提升用户在知识探索中的参与感与可信度感。

Abstract: The landscape of interactive systems is shifting toward dynamic, generative
experiences that empower users to explore and construct knowledge in real time.
Yet, timelines -- a fundamental tool for representing historical and conceptual
development -- remain largely static, limiting user agency and curiosity. We
introduce the concept of a generative timeline: an AI-powered timeline that
adapts to users' evolving questions by expanding or contracting in response to
input. We instantiate this concept through KnowledgeTrail, a system that
enables users to co-construct timelines of historical events and knowledge
formation processes. Two user studies showed that KnowledgeTrail fosters
curiosity-driven exploration, serendipitous discovery, and the ability to trace
complex relationships between ideas and events, while citation features
supported verification yet revealed fragile trust shaped by perceptions of
source credibility. We contribute a vision for generative timelines as a new
class of exploratory interface, along with design insights for balancing
serendipity and credibility.

</details>


### [36] [Lowering Barriers to CAD Adoption: A Comparative Study of Augmented Reality-Based CAD (AR-CAD) and a Traditional CAD tool](https://arxiv.org/abs/2510.12146)
*Muhammad Talha,Abdullah Mohiuddin,Sehrish Javed,Ahmed Jawad Qureshi*

Main category: cs.HC

TL;DR: 研究比较了增强现实CAD与传统CAD在用户体验上的差异，发现AR-CAD在新手中表现优越，而经验丰富用户更喜欢传统CAD。


<details>
  <summary>Details</summary>
Motivation: 探索增强现实对计算机辅助设计的影响，尤其是对新手用户的支持和高级用户的偏好。

Method: 通过用户研究比较AR-CAD与传统CAD（SolidWorks）的应用效果，涉及20名不同技能水平的参与者。

Result:  AR-CAD在降低认知负担和提高新手完成率方面表现较好，但经验丰富用户更倾向于传统CAD的功能。

Conclusion: AR-CAD在新手设计师中表现更佳，而传统CAD更受经验丰富用户的欢迎，提示两者的优缺点不同。

Abstract: The paper presents a comparative user study between an Augmented
Reality-based Computer-Aided Design (AR-CAD) system and a traditional
computer-based CAD modeling software, SolidWorks. Twenty participants of
varying skill levels performed 3D modeling tasks using both systems. The
results showed that while the average task completion time is comparable for
both groups, novice designers had a higher completion rate in AR-CAD than in
the traditional CAD interface, and experienced designers had a similar
completion rate in both systems. A statistical comparison of task completion
rate, time, and NASA Task Load Index (TLX) showed that AR-CAD slightly reduced
cognitive load while favoring a high task completion rate. Higher scores on the
System Usability Scale (SUS) by novices indicated that AR-CAD was superior and
worthwhile for reducing barriers to entering CAD. In contrast, the Traditional
CAD interface was favored by experienced users for its advanced capabilities,
while many viewed AR-CAD as a valid means for rapid concept development,
education, and an initial critique of designs. This opens up the need for
future research on the needed refinement of AR-CAD with a focus on
high-precision input tools and its evaluation of complex design processes. This
research highlights the potential for immersive interfaces to enhance design
practice, bridging the gap between novice and experienced CAD users.

</details>


### [37] [Embodied Natural Language Interaction (NLI): Speech Input Patterns in Immersive Analytics](https://arxiv.org/abs/2510.12156)
*Hyemi Song,Matthew Johnson,Kirsten Whitley,Eric Krokos,Amitabh Varshney*

Main category: cs.HC

TL;DR: 本文研究了用户在沉浸式分析中的言语模式和具身线索的相互作用，识别出五种言语输入模式，并提出与这些模式相关的设计启示。


<details>
  <summary>Details</summary>
Motivation: 探讨用户在沉浸式分析中通过语言表达意图时的言语模式及其与具身线索的关系，以缩小用户意图与分析系统之间的差距。

Method: 使用乌兹法进行用户研究，并对1280个言语行为进行轴向编码分析。

Result: 识别出五种言语输入模式，表明用户根据数据分析任务和具身依赖程度动态地融合具身与非具身言语行为。

Conclusion: 提出了与五种识别出的言语输入模式对齐的设计启示，以促进沉浸式分析中的自然语言交互。

Abstract: Embodiment shapes how users verbally express intent when interacting with
data through speech interfaces in immersive analytics. Despite growing interest
in Natural Language Interaction (NLI) for visual analytics in immersive
environments, users' speech patterns and their use of embodiment cues in speech
remain underexplored. Understanding their interplay is crucial to bridging the
gap between users' intent and an immersive analytic system. To address this, we
report the results from 15 participants in a user study conducted using the
Wizard of Oz method. We performed axial coding on 1,280 speech acts derived
from 734 utterances, examining how analysis tasks are carried out with
embodiment and linguistic features. Next, we measured speech input uncertainty
for each analysis task using the semantic entropy of utterances, estimating how
uncertain users' speech inputs appear to an analytic system. Through these
analyses, we identified five speech input patterns, showing that users
dynamically blend embodied and non-embodied speech acts depending on data
analysis tasks, phases, and embodiment reliance driven by the counts and types
of embodiment cues in each utterance. We then examined how these patterns align
with user reflections on factors that challenge speech interaction during the
study. Finally, we propose design implications aligned with the five patterns.

</details>


### [38] [How Far I'll Go: Imagining Futures of Conversational AI with People with Visual Impairments Through Design Fiction](https://arxiv.org/abs/2510.12268)
*Jeanne Choi,Dasom Choi,Sejun Jeong,Hwajung Hong,Joseph Seering*

Main category: cs.HC

TL;DR: 本文研究视觉障碍人士如何设想未来与对话式人工智能的生活，揭示了其对自主性、包容性和探索机会的关注。


<details>
  <summary>Details</summary>
Motivation: 探索具有视觉障碍的人士如何设想与对话式人工智能（CAI）共存的未来，而不是仅关注CAI的技术能力。

Method: 通过对14位视觉障碍参与者进行参与式研究，使用基于音频的设计虚构探测器，进行关于未来CAI的假设性对话。

Result: 研究发现，视觉障碍人士希望利用CAI拓展自身边界，但同时也对自主性、视力损失的多样性和提升社会包容性表示担忧。

Conclusion: 设计CAI时，应考虑视觉障碍人士的未来生活愿景，以支持其真实的自主权。

Abstract: People with visual impairments (PVI) use a variety of assistive technologies
to navigate their daily lives, and conversational AI (CAI) tools are a growing
part of this toolset. Much existing HCI research has focused on the technical
capabilities of current CAI tools, but in this paper, we instead examine how
PVI themselves envision potential futures for living with CAI. We conducted a
study with 14 participants with visual impairments using an audio-based Design
Fiction probe featuring speculative dialogues between participants and a future
CAI. Participants imagined using CAI to expand their boundaries by exploring
new opportunities or places, but also voiced concerns about balancing reliance
on CAI with maintaining autonomy, the need to consider diverse levels of
vision-loss, and enhancing visibility of PVI for greater inclusion. We discuss
implications for designing CAI that support genuine agency for PVI based on the
future lives they envisioned.

</details>


### [39] [Hey Dashboard!: Supporting Voice, Text, and Pointing Modalities in Dashboard Onboarding](https://arxiv.org/abs/2510.12386)
*Vaishali Dhanoa,Gabriela Molina León,Eve Hoggan,Eduard Gröller,Marc Streit,Niklas Elmqvist*

Main category: cs.HC

TL;DR: DIANA是一个多模态仪表板助手，旨在支持用户自助导入仪表板，结合多种交互方式改善用户体验。


<details>
  <summary>Details</summary>
Motivation: 帮助用户更有效地进行仪表板的自助导入，减少时间和劳动成本。

Method: 多模态交互助手（DIANA）的设计与实施

Result: DIANA通过聊天、音频和鼠标交互方式，提升了仪表板用户的导航和分析体验。

Conclusion: DIANA设计能够通过多种交互模式提高用户的仪表板使用效率，适应不同的导入任务和复杂性。

Abstract: Visualization dashboards are regularly used for data exploration and
analysis, but their complex interactions and interlinked views often require
time-consuming onboarding sessions from dashboard authors. Preparing these
onboarding materials is labor-intensive and requires manual updates when
dashboards change. Recent advances in multimodal interaction powered by large
language models (LLMs) provide ways to support self-guided onboarding. We
present DIANA (Dashboard Interactive Assistant for Navigation and Analysis), a
multimodal dashboard assistant that helps users for navigation and guided
analysis through chat, audio, and mouse-based interactions. Users can choose
any interaction modality or a combination of them to onboard themselves on the
dashboard. Each modality highlights relevant dashboard features to support user
orientation. Unlike typical LLM systems that rely solely on text-based chat,
DIANA combines multiple modalities to provide explanations directly in the
dashboard interface. We conducted a qualitative user study to understand the
use of different modalities for different types of onboarding tasks and their
complexities.

</details>


### [40] [Gauging the Competition: Understanding Social Comparison and Anxiety through Eye-tracking in Virtual Reality Group Interview](https://arxiv.org/abs/2510.12590)
*Shi-Ting Ni,Kairong Fang,Yuyang Wang,Pan Hui*

Main category: cs.HC

TL;DR: 本研究探讨虚拟现实在小组面试中的应用，发现同行表现对参与者自我概念的影响，并提出提高虚拟训练效果的设计建议。


<details>
  <summary>Details</summary>
Motivation: 探讨小组面试中的心理动态，例如社会比较，填补这一领域的研究空白。

Method: 开发一个沉浸式虚拟现实小组面试系统，并通过眼动追踪研究73名参与者。

Result: 研究发现了'大鱼小池效应'，显示高成就同伴行为的增加会提高参与者的社会比较信息处理，并显著降低其自我评估。

Conclusion: 研究为虚拟环境的设计提供了重要的见解，考虑到了复杂的社会动态，以创造更有效的训练环境。

Abstract: Virtual Reality (VR) is a promising tool for interview training, yet the
psychological dynamics of group interviews, such as social comparison, remain
underexplored. We investigate this phenomenon by developing an immersive VR
group interview system and conducting an eye-tracking study with 73
participants. We manipulated peer performance using ambiguous behavioral cues
(e.g., hand-raising) and objective information (public test scores) to measure
their effect on participants' attention and self-concept. Our results
demonstrate a "Big-Fish-Little-Pond Effect" in VR: an increase in
high-achieving peer behaviors heightened participants' processing of social
comparison information and significantly lowered their self-assessments. The
introduction of objective scores further intensified these comparative
behaviors. We also found that lower perceived realism of the VR environment
correlated with higher anxiety. These findings offer key insights and design
considerations for creating more effective and psychologically-aware virtual
training environments that account for complex social dynamics.

</details>


### [41] [Who is a Better Matchmaker? Human vs. Algorithmic Judge Assignment in a High-Stakes Startup Competition](https://arxiv.org/abs/2510.12692)
*Sarina Xi,Orelia Pi,Miaomiao Zhang,Becca Xiong,Jacqueline Ng Lane,Nihar B. Shah*

Main category: cs.HC

TL;DR: 本研究开发的AI算法在法官分配中表现出与人类专家相当的匹配质量，同时提高了效率和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 为了探索在需要语义理解和领域专业知识的情况下，算法与人类判断之间的比较，特别是在高风险决策环境中的法官分配问题。

Method: 开发了一种基于人工智能的法官分配算法，即混合词汇-语义相似度集成（HLSE），并在哈佛大学总统创新挑战赛中部署该算法来进行法官分配。

Result: 通过对309对法官和创业项目的盲评分进行评估，发现算法与人工专家分配之间在匹配质量上没有显著差异，且算法能够在数小时内完成以前需要一周的人工分配工作。

Conclusion: HLSE算法展示了AI驱动的解决方案在高风险设置中支持和提升人类决策的潜力。

Abstract: There is growing interest in applying artificial intelligence (AI) to
automate and support complex decision-making tasks. However, it remains unclear
how algorithms compare to human judgment in contexts requiring semantic
understanding and domain expertise. We examine this in the context of the judge
assignment problem, matching submissions to suitably qualified judges.
Specifically, we tackled this problem at the Harvard President's Innovation
Challenge, the university's premier venture competition awarding over \$500,000
to student and alumni startups. This represents a real-world environment where
high-quality judge assignment is essential. We developed an AI-based
judge-assignment algorithm, Hybrid Lexical-Semantic Similarity Ensemble (HLSE),
and deployed it at the competition. We then evaluated its performance against
human expert assignments using blinded match-quality scores from judges on
$309$ judge-venture pairs. Using a Mann-Whitney U statistic based test, we
found no statistically significant difference in assignment quality between the
two approaches ($AUC=0.48, p=0.40$); on average, algorithmic matches are rated
$3.90$ and manual matches $3.94$ on a 5-point scale, where 5 indicates an
excellent match. Furthermore, manual assignments that previously required a
full week could be automated in several hours by the algorithm during
deployment. These results demonstrate that HLSE achieves human-expert-level
matching quality while offering greater scalability and efficiency,
underscoring the potential of AI-driven solutions to support and enhance human
decision-making for judge assignment in high-stakes settings.

</details>


### [42] [Data-Model Co-Evolution: Growing Test Sets to Refine LLM Behavior](https://arxiv.org/abs/2510.12728)
*Minjae Lee,Minsuk Kahng*

Main category: cs.HC

TL;DR: 本研究提出了一种互动系统，促进数据与模型指令的共同进化，并优化指令修订流程，以提高大语言模型的应用质量。


<details>
  <summary>Details</summary>
Motivation: 应对数据和模型迭代中的细微领域特定政策编码的挑战

Method: 开发一种交互式系统

Result: 用户研究表明，该工作流程帮助参与者系统性地优化指令，并更清楚地指定模糊政策

Conclusion: 通过人机协作开发，促进了更强健和负责任的LLM应用.

Abstract: A long-standing challenge in machine learning has been the rigid separation
between data work and model refinement, enforced by slow fine-tuning cycles.
The rise of Large Language Models (LLMs) overcomes this historical barrier,
allowing applications developers to instantly govern model behavior by editing
prompt instructions. This shift enables a new paradigm: data-model
co-evolution, where a living test set and a model's instructions evolve in
tandem. We operationalize this paradigm in an interactive system designed to
address the critical challenge of encoding subtle, domain-specific policies
into prompt instructions. The system's structured workflow guides people to
discover edge cases, articulate rationales for desired behavior, and
iteratively evaluate instruction revisions against a growing test set. A user
study shows our workflow helps participants refine instructions systematically
and specify ambiguous policies more concretely. This work points toward more
robust and responsible LLM applications through human-in-the-loop development
aligned with local preferences and policies.

</details>
