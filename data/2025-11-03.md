<div id=toc></div>

# Table of Contents

- [cs.HC](#cs.HC) [Total: 10]
- [cs.RO](#cs.RO) [Total: 22]


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [1] [AIOT based Smart Education System: A Dual Layer Authentication and Context-Aware Tutoring Framework for Learning Environments](https://arxiv.org/abs/2510.26999)
*Adithya Neelakantan,Pratik Satpute,Prerna Shinde,Tejas Manjunatha Devang*

Main category: cs.HC

TL;DR: AIoT基础的智能教育系统通过整合人工智能和物联网，提供安全可靠的学习环境，解决考勤欺诈和资源利用等问题，促进学生参与和教育创新。


<details>
  <summary>Details</summary>
Motivation: 旨在解决当代课堂中的持续挑战，例如考勤欺诈、缺乏个性化、学生 disengagement 和资源使用效率低下。

Method: 将人工智能与物联网结合，设计了四个核心模块，包括双因素认证系统、AI助手、自动化测试生成器和EcoSmart校园模块。

Result: 模拟评估表明该系统在实时监控、促进包容性参与、预防欺诈行为和支持操作可扩展性方面的有效性。

Conclusion: AIoT-based智能教育系统提供了安全、灵活和高效的学习环境，为未来的教育创新和改善学生成果提供了可扩展的蓝图。

Abstract: The AIoT-Based Smart Education System integrates Artificial Intelligence and
IoT to address persistent challenges in contemporary classrooms: attendance
fraud, lack of personalization, student disengagement, and inefficient resource
use. The unified platform combines four core modules: (1) a dual-factor
authentication system leveraging RFID-based ID scans and WiFi verification for
secure, fraud-resistant attendance; (2) an AI-powered assistant that provides
real-time, context-aware support and dynamic quiz generation based on
instructor-supplied materials; (3) automated test generators to streamline
adaptive assessment and reduce administrative overhead; and (4) the EcoSmart
Campus module, which autonomously regulates classroom lighting, air quality,
and temperature using IoT sensors and actuators. Simulated evaluations
demonstrate the system's effectiveness in delivering robust real-time
monitoring, fostering inclusive engagement, preventing fraudulent practices,
and supporting operational scalability. Collectively, the AIoT-Based Smart
Education System offers a secure, adaptive, and efficient learning environment,
providing a scalable blueprint for future educational innovation and improved
student outcomes through the synergistic application of artificial intelligence
and IoT technologies.

</details>


### [2] [Adaptive Human-Computer Interaction Strategies Through Reinforcement Learning in Complex](https://arxiv.org/abs/2510.27058)
*Rui Liu,Yifan Zhuang,Runsheng Zhang*

Main category: cs.HC

TL;DR: 本研究提出了一种强化学习方法来优化人机交互，通过马尔可夫决策过程建模，结果表明该方法在提升任务完成率和交互效率方面显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 研究目的在于解决智能人机交互中的动态与复杂性问题，以提高长期回报和整体体验。

Method: 本研究提出了一种基于强化学习的优化框架，通过将人机交互建模为马尔可夫决策过程，结合策略函数、价值函数和优势函数，利用策略梯度不断调整参数，以平衡即时反馈和长期收益。

Result: 实验结果表明，所提框架在任务成功率、策略稳定性等方面表现优于现有方法，特别是在交互效率和长期回报方面显示显著优势。

Conclusion: 所提方法在多个指标上超过了现有方法，在任务完成率和策略稳定性方面表现优异，强化学习在优化人机交互中的重要价值得以验证。

Abstract: This study addresses the challenges of dynamics and complexity in intelligent
human-computer interaction and proposes a reinforcement learning-based
optimization framework to improve long-term returns and overall experience.
Human-computer interaction is modeled as a Markov decision process, with state
space, action space, reward function, and discount factor defined to capture
the dynamics of user input, system feedback, and interaction environment. The
method combines policy function, value function, and advantage function,
updates parameters through policy gradient, and continuously adjusts during
interaction to balance immediate feedback and long-term benefits. To validate
the framework, multimodal dialog and scene-aware datasets are used as the
experimental platform, with multiple sensitivity experiments conducted on key
factors such as discount factor, exploration rate decay, environmental noise,
and data imbalance. Evaluation is carried out using cumulative reward, average
episode reward, convergence speed, and task success rate. Results show that the
proposed method outperforms existing approaches across several metrics,
achieving higher task completion while maintaining strategy stability.
Comparative experiments further confirm its advantages in interaction
efficiency and long-term return, demonstrating the significant value of
reinforcement learning in optimizing human-computer interaction.

</details>


### [3] [Functional connectivity guided deep neural network for decoding high-level visual imagery](https://arxiv.org/abs/2510.27075)
*Byoung-Hee Kwon,Minji Lee,Seong-Whan Lee*

Main category: cs.HC

TL;DR: 本研究提出了一种新型脑机接口技术，通过高级视觉想象和深度学习，增强了机器臂控制的精确性和实时性，推动了BCI系统的多样化应用。


<details>
  <summary>Details</summary>
Motivation: 提出了一种新颖的非侵入性脑电图（EEG）通信方法，通过高水平的视觉想象经验，提升BCI技术在复杂任务中的应用潜力，尤其是机器人手臂控制。

Method: 开发了一种高级深度学习架构，将功能连接性指标与卷积神经网络-图像变换器结合，能够解码用户的细微意图并有效翻译成精准的机器人手臂控制指令。

Result: 我们的离线和伪在线评估表明，该框架在实时应用中的有效性，尤其是在机器臂的细致控制方面，得到了验证。

Conclusion: 本研究展示了高级视觉想象和深度学习在提升BCI系统可用性和适应性方面的变革性影响，特别是在机器人手臂操控中。

Abstract: This study introduces a pioneering approach in brain-computer interface (BCI)
technology, featuring our novel concept of high-level visual imagery for
non-invasive electroencephalography (EEG)-based communication. High-level
visual imagery, as proposed in our work, involves the user engaging in the
mental visualization of complex upper limb movements. This innovative approach
significantly enhances the BCI system, facilitating the extension of its
applications to more sophisticated tasks such as EEG-based robotic arm control.
By leveraging this advanced form of visual imagery, our study opens new
horizons for intricate and intuitive mind-controlled interfaces. We developed
an advanced deep learning architecture that integrates functional connectivity
metrics with a convolutional neural network-image transformer. This framework
is adept at decoding subtle user intentions, addressing the spatial variability
in high-level visual tasks, and effectively translating these into precise
commands for robotic arm control. Our comprehensive offline and pseudo-online
evaluations demonstrate the framework's efficacy in real-time applications,
including the nuanced control of robotic arms. The robustness of our approach
is further validated through leave-one-subject-out cross-validation, marking a
significant step towards versatile, subject-independent BCI applications. This
research highlights the transformative impact of advanced visual imagery and
deep learning in enhancing the usability and adaptability of BCI systems,
particularly in robotic arm manipulation.

</details>


### [4] [AURA: A Reinforcement Learning Framework for AI-Driven Adaptive Conversational Surveys](https://arxiv.org/abs/2510.27126)
*Jinwen Tang,Yi Shang*

Main category: cs.HC

TL;DR: AURA通过强化学习改善了调查聊天机器人的个性化和适应性，提升了参与者的回答质量和互动体验。


<details>
  <summary>Details</summary>
Motivation: 传统在线调查缺乏个性化，导致参与者的低参与度和肤浅的回答，现有AI聊天机器人仍然依赖固定对话树，无法适应个体用户。

Method: 采用强化学习框架AURA，利用LSDE四维指标量化回答质量，并通过ε-贪婪策略选择后续问题类型。

Result: 在控制评估中，AURA实现了响应质量平均提升0.12，并在统计上显著优于非适应性基线（p=0.044, d=0.66），同时减少规格提示63%并提高验证行为10倍。

Conclusion: 强化学习能够显著提升调查聊天机器人的适应性，将静态问卷转变为互动的自我改进评估系统。

Abstract: Conventional online surveys provide limited personalization, often resulting
in low engagement and superficial responses. Although AI survey chatbots
improve convenience, most are still reactive: they rely on fixed dialogue trees
or static prompt templates and therefore cannot adapt within a session to fit
individual users, which leads to generic follow-ups and weak response quality.
We address these limitations with AURA (Adaptive Understanding through
Reinforcement Learning for Assessment), a reinforcement learning framework for
AI-driven adaptive conversational surveys. AURA quantifies response quality
using a four-dimensional LSDE metric (Length, Self-disclosure, Emotion, and
Specificity) and selects follow-up question types via an epsilon-greedy policy
that updates the expected quality gain within each session. Initialized with
priors extracted from 96 prior campus-climate conversations (467 total
chatbot-user exchanges), the system balances exploration and exploitation
across 10-15 dialogue exchanges, dynamically adapting to individual
participants in real time. In controlled evaluations, AURA achieved a +0.12
mean gain in response quality and a statistically significant improvement over
non-adaptive baselines (p=0.044, d=0.66), driven by a 63% reduction in
specification prompts and a 10x increase in validation behavior. These results
demonstrate that reinforcement learning can give survey chatbots improved
adaptivity, transforming static questionnaires into interactive, self-improving
assessment systems.

</details>


### [5] [Reconstructing Unseen Sentences from Speech-related Biosignals for Open-vocabulary Neural Communication](https://arxiv.org/abs/2510.27247)
*Deok-Seon Kim,Seo-Hyun Lee,Kang Yin,Seong-Whan Lee*

Main category: cs.HC

TL;DR: 本研究探讨了如何通过高密度EEG信号提取音素信息，实现开放词汇的神经通信，通过生物信号合成未见句子，为患者提供个性化的交流解决方案。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在实现开放词汇神经通信，使其能够与自然人类互动相媲美，同时有效整合来自语音的多种信号，以满足患者个性化和适应性神经通信及康复方案的需求。

Method: 本研究通过利用从高密度脑电图(EEG)信号中提取的音素级信息，以及与肌电图(EMG)信号的结合，探讨了在各种语音模式下为前所未见的句子进行语音合成的潜力。

Result: 研究结果强调了基于生物信号的句子级语音合成在重构未见句子中的可行性，为开发适应患者的神经通信系统提供了重要的支持，同时对EEG解码技术的发展也提供了有意义的见解。

Conclusion: 本研究强调了基于生物信号的句子级语音合成在重构未见句子方面的可行性，为开发适应不同患者需求的开放词汇神经通信系统迈出了重要一步。

Abstract: Brain-to-speech (BTS) systems represent a groundbreaking approach to human
communication by enabling the direct transformation of neural activity into
linguistic expressions. While recent non-invasive BTS studies have largely
focused on decoding predefined words or sentences, achieving open-vocabulary
neural communication comparable to natural human interaction requires decoding
unconstrained speech. Additionally, effectively integrating diverse signals
derived from speech is crucial for developing personalized and adaptive neural
communication and rehabilitation solutions for patients. This study
investigates the potential of speech synthesis for previously unseen sentences
across various speech modes by leveraging phoneme-level information extracted
from high-density electroencephalography (EEG) signals, both independently and
in conjunction with electromyography (EMG) signals. Furthermore, we examine the
properties affecting phoneme decoding accuracy during sentence reconstruction
and offer neurophysiological insights to further enhance EEG decoding for more
effective neural communication solutions. Our findings underscore the
feasibility of biosignal-based sentence-level speech synthesis for
reconstructing unseen sentences, highlighting a significant step toward
developing open-vocabulary neural communication systems adapted to diverse
patient needs and conditions. Additionally, this study provides meaningful
insights into the development of communication and rehabilitation solutions
utilizing EEG-based decoding technologies.

</details>


### [6] [Inferring trust in recommendation systems from brain, behavioural, and physiological data](https://arxiv.org/abs/2510.27272)
*Vincent K. M. Cheung,Pei-Cheng Shih,Masato Hirano,Masataka Goto,Shinichi Furuya*

Main category: cs.HC

TL;DR: 本研究探讨了用户对自动化系统信任的神经和认知过程，提出了一种基于神经的信任校准框架，强调了多模态方法对开发可信AI系统的潜力。


<details>
  <summary>Details</summary>
Motivation: 随着人们越来越依赖人工智能进行信息筛选和决策，评估对自动化系统的信任变得愈发重要，而现有的信任测量方法主要依赖主观自我报告，这影响了用户体验。

Method: 使用音乐推荐作为模型，结合强化学习模型分析用户的奖励编码过程，利用EEG记录神经活动和瞳孔直径的变化。

Result: 发现系统准确性与用户信任直接相关，并调节了推荐线索对音乐偏好的影响；同时系统的准确性、期望奖励和预测误差与通过EEG记录的神经振荡活动和瞳孔直径变化相关。

Conclusion: 本研究为建立可信的自动化系统提供了基于神经的信任校准框架，并强调了多模态方法在开发可信AI系统中的潜力。

Abstract: As people nowadays increasingly rely on artificial intelligence (AI) to
curate information and make decisions, assigning the appropriate amount of
trust in automated intelligent systems has become ever more important. However,
current measurements of trust in automation still largely rely on self-reports
that are subjective and disruptive to the user. Here, we take music
recommendation as a model to investigate the neural and cognitive processes
underlying trust in automation. We observed that system accuracy was directly
related to users' trust and modulated the influence of recommendation cues on
music preference. Modelling users' reward encoding process with a reinforcement
learning model further revealed that system accuracy, expected reward, and
prediction error were related to oscillatory neural activity recorded via EEG
and changes in pupil diameter. Our results provide a neurally grounded account
of calibrating trust in automation and highlight the promises of a multimodal
approach towards developing trustable AI systems.

</details>


### [7] ["Koyi Sawaal Nahi Hai": Reimagining Maternal Health Chatbots for Collective, Culturally Grounded Care](https://arxiv.org/abs/2510.27401)
*Imaan Hameed,Huma Umar,Fozia Umber,Maryam Mustafa*

Main category: cs.HC

TL;DR: 本研究探索了在低资源环境中采用妊娠健康聊天机器人的障碍，提出了关系聊天机器人设计语法（RCDG），以支持文化背景下的集体护理和决策。


<details>
  <summary>Details</summary>
Motivation: 这项研究旨在解决 LLM 基础妊娠健康聊天机器人在低资源环境中应用时忽视现实环境带来的挑战，尤其是针对电话共享、有限识字率和家庭共同决策的情况。

Method: 通过在巴基斯坦拉合尔对48名孕妇进行WhatsApp基础的妊娠健康聊天机器人部署，结合与产科临床医生的焦点小组讨论。

Result: 研究发现采用情况受到代理同意和家庭调解、不稳定的手机访问、对提问的沉默、基础设施缺陷及争议权威的影响。

Conclusion: 本研究提出了关系聊天机器人设计语法（RCDG），以指导在具有文化背景的情况下设计妊娠健康聊天机器人，强调集体决策和对脆弱性的认识。

Abstract: In recent years, LLM-based maternal health chatbots have been widely deployed
in low-resource settings, but they often ignore real-world contexts where women
may not own phones, have limited literacy, and share decision-making within
families. Through the deployment of a WhatsApp-based maternal health chatbot
with 48 pregnant women in Lahore, Pakistan, we examine barriers to use in
populations where phones are shared, decision-making is collective, and
literacy varies. We complement this with focus group discussions with obstetric
clinicians. Our findings reveal how adoption is shaped by proxy consent and
family mediation, intermittent phone access, silence around asking questions,
infrastructural breakdowns, and contested authority. We frame barriers to
non-use as culturally conditioned rather than individual choices, and introduce
the Relational Chatbot Design Grammar (RCDG): four commitments that enable
mediated decision-making, recognize silence as engagement, support episodic
use, and treat fragility as baseline to reorient maternal health chatbots
toward culturally grounded, collective care.

</details>


### [8] [Independent Clinical Evaluation of General-Purpose LLM Responses to Signals of Suicide Risk](https://arxiv.org/abs/2510.27521)
*Nick Judd,Alexandre Vaz,Kevin Paeth,Layla Inés Davis,Milena Esherick,Jason Brand,Inês Amaro,Tony Rousmaniere*

Main category: cs.HC

TL;DR: 本文研究了大型语言模型在面临自杀风险信号时的反应，发现其行为偏离了临床最佳实践，可能会抑制用户的求助意愿。


<details>
  <summary>Details</summary>
Motivation: 越来越多的人利用大型语言模型作为心理健康资源，然而目前的研究在将临床指南有效推广到LLM使用案例上存在不足，因此需要提出适应性的方法。

Method: 进行了一项实证研究，采用由临床医生创建并验证的代码本，通过志愿参与的治疗师和学员的标注，对OLMo-2-32b进行评估，并使用广义线性混合效应模型进行统计分析。

Result: 研究发现，OLMo-2-32b在检测到用户情绪风险信号时，其与临床指导不符的响应方式可能导致用户不愿意继续对话，并且对于不同风险因素的表达响应也存在差异。

Conclusion: OLMo-2-32b在多轮对话中对自杀风险信号的响应方式与临床最佳实践相悖，可能导致用户感觉被忽视或放弃，降低寻求帮助的意愿。

Abstract: We introduce findings and methods to facilitate evidence-based discussion
about how large language models (LLMs) should behave in response to user
signals of risk of suicidal thoughts and behaviors (STB). People are already
using LLMs as mental health resources, and several recent incidents implicate
LLMs in mental health crises. Despite growing attention, few studies have been
able to effectively generalize clinical guidelines to LLM use cases, and fewer
still have proposed methodologies that can be iteratively applied as knowledge
improves about the elements of human-AI interaction most in need of study. We
introduce an assessment of LLM alignment with guidelines for ethical
communication, adapted from clinical principles and applied to expressions of
risk factors for STB in multi-turn conversations. Using a codebook created and
validated by clinicians, mobilizing the volunteer participation of practicing
therapists and trainees (N=43) based in the U.S., and using generalized linear
mixed-effects models for statistical analysis, we assess a single fully
open-source LLM, OLMo-2-32b. We show how to assess when a model deviates from
clinically informed guidelines in a way that may pose a hazard and (thanks to
its open nature) facilitates future investigation as to why. We find that
contrary to clinical best practice, OLMo-2-32b, and, possibly by extension,
other LLMs, will become less likely to invite continued dialog as users send
more signals of STB risk in multi-turn settings. We also show that OLMo-2-32b
responds differently depending on the risk factor expressed. This empirical
evidence highlights that just as chatbots pose hazards if their responses
reinforce delusions or assist in suicidal acts, they may also discourage
further help-seeking or cause feelings of dismissal or abandonment by
withdrawing from conversations when STB risk is expressed.

</details>


### [9] [Beyond Visualization: Building Decision Intelligence Through Iterative Dashboard Refinement](https://arxiv.org/abs/2510.27572)
*Likitha Tadakala,Muskan Saraf,Sajjad Rezvani Boroujeni,Hossein Abedi,Tom Bush*

Main category: cs.HC

TL;DR: 本研究提出了一种基于反馈的迭代改进方法，分析了一个虚构零售公司的盈利能力下降，并展示了如何通过结构化的改进提升商业智能仪表板的决策支持能力。


<details>
  <summary>Details</summary>
Motivation: 解决商业智能实践中缺乏结构性改进框架的问题，以提升仪表板的有效性。

Method: 使用四阶段的迭代改进方法，通过协作审查来识别并解决分析上的不足。

Result: 发现家具的利润率低于技术产品，折扣达到20%后利润下降，以及未收回的运费达到135万美元。

Conclusion: 该研究展示了反馈驱动的迭代方法在商业智能仪表板的发展中如何产生显著的决策支持工具。

Abstract: Effective business intelligence (BI) dashboards evolve through iterative
refinement rather than single-pass design. Addressing the lack of structured
improvement frameworks in BI practice, this study documents the four-stage
evolution of a Power BI dashboard analyzing profitability decline in a
fictional retail firm, Global Superstore. Using a dataset of \$12.64 million in
sales across seven markets and three product categories, the project
demonstrates how feedback-driven iteration and gap analysis convert exploratory
visuals into decision-support tools. Guided by four executive questions on
profitability, market prioritization, discount effects, and shipping costs,
each iteration resolved analytical or interpretive shortcomings identified
through collaborative review. Key findings include margin erosion in furniture
(6.94% vs. 13.99% for technology), a 20% discount threshold beyond which
profitability declined, and \$1.35 million in unrecovered shipping costs.
Contributions include: (a) a replicable feedback-driven methodology grounded in
iterative gap analysis; (b) DAX-based technical enhancements improving
interpretive clarity; (c) an inductively derived six-element narrative
framework; and (d) evidence that narrative coherence emerges organically
through structured refinement. The methodology suggests transferable value for
both BI practitioners and educators, pending validation across diverse
organizational contexts.

</details>


### [10] [Personalized AI Scaffolds Synergistic Multi-Turn Collaboration in Creative Work](https://arxiv.org/abs/2510.27681)
*Sean Kelley,David De Cremer,Christoph Riedl*

Main category: cs.HC

TL;DR: 个性化AI通过理解用户特征来提升营销任务表现，增强人机协作效果，未来设计应最大化协同效应并支持人类创造潜力。


<details>
  <summary>Details</summary>
Motivation: 随着AI在知识工作中的深入应用，创建支持人类创造力和专业知识的助手变得尤为重要，然而实现人机协作的协同作用并不容易。

Method: 采用个性化LLM助手，结合用户心理特征和工作风格的AI指导访谈，进行随机对照实验，比较不同个性化程度的AI对营销任务表现的影响。

Result: 参与个性化AI的用户在营销活动中表现出更高的质量和创造力，个性化AI提高了用户的帮助感和反馈水平，增加了信任和信心。

Conclusion: 个性化AI能显著提升用户营销任务的质量和创造力，并通过增强集体记忆、注意力和推理来间接改善人机互动绩效。

Abstract: As AI becomes more deeply embedded in knowledge work, building assistants
that support human creativity and expertise becomes more important. Yet
achieving synergy in human-AI collaboration is not easy. Providing AI with
detailed information about a user's demographics, psychological attributes,
divergent thinking, and domain expertise may improve performance by scaffolding
more effective multi-turn interactions. We implemented a personalized LLM-based
assistant, informed by users' psychometric profiles and an AI-guided interview
about their work style, to help users complete a marketing task for a fictional
startup. We randomized 331 participants to work with AI that was either generic
(n = 116), partially personalized (n = 114), or fully personalized (n=101).
Participants working with personalized AI produce marketing campaigns of
significantly higher quality and creativity, beyond what AI alone could have
produced. Compared to generic AI, personalized AI leads to higher self-reported
levels of assistance and feedback, while also increasing participant trust and
confidence. Causal mediation analysis shows that personalization improves
performance indirectly by enhancing collective memory, attention, and reasoning
in the human-AI interaction. These findings provide a theory-driven framework
in which personalization functions as external scaffolding that builds common
ground and shared partner models, reducing uncertainty and enhancing joint
cognition. This informs the design of future AI assistants that maximize
synergy and support human creative potential while limiting negative
homogenization.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [11] [Force Characterization of Insect-Scale Aquatic Propulsion Based on Fluid-Structure Interaction](https://arxiv.org/abs/2510.26837)
*Conor K. Trygstad,Nestor O. Perez-Arancibia*

Main category: cs.RO

TL;DR: 本文介绍了两种新开发的昆虫尺度推进器的力特性，首次测量其瞬时推力，为微机器人推动的流体-结构相互作用提供了重要见解。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在系统性地研究新开发的两种昆虫尺度推进器的力特性，尽管它们在微机器人水下运动中表现良好，但相关的力特征尚未被系统研究。

Method: 采用基于反应力的理论框架，并利用定制的微牛顿级力传感器收集实验数据。

Result: 测试的单尾推进器最大和平均力分别为0.45 mN和2.97微牛顿，而双尾推进器则分别为0.61 mN和22.6微牛顿。

Conclusion: 此研究首次测量了昆虫尺度推进器所产生的瞬时推力，为高效的微机器人推进提供了见解。

Abstract: We present force characterizations of two newly developed insect-scale
propulsors--one single-tailed and one double-tailed--for microrobotic swimmers
that leverage fluid-structure interaction (FSI) to generate thrust. The designs
of these two devices were inspired by anguilliform swimming and are driven by
soft tails excited by high-work-density (HWD) actuators powered by shape-memory
alloy (SMA) wires. While these propulsors have been demonstrated to be suitable
for microrobotic aquatic locomotion and controllable with simple architectures
for trajectory tracking in the two-dimensional (2D) space, the characteristics
and magnitudes of the associated forces have not been studied systematically.
In the research presented here, we adopted a theoretical framework based on the
notion of reactive forces and obtained experimental data for characterization
using a custom-built micro-N-resolution force sensor. We measured maximum and
cycle-averaged force values with multi-test means of respectively 0.45 mN and
2.97 micro-N, for the tested single-tail propulsor. For the dual-tail
propulsor, we measured maximum and cycle-averaged force values with multi-test
means of 0.61 mN and 22.6 micro-N, respectively. These results represent the
first measurements of the instantaneous thrust generated by insect-scale
propulsors of this type and provide insights into FSI for efficient
microrobotic propulsion.

</details>


### [12] [Leveraging Foundation Models for Enhancing Robot Perception and Action](https://arxiv.org/abs/2510.26855)
*Reihaneh Mirjalili*

Main category: cs.RO

TL;DR: 本论文探讨基础模型如何提升机器人在复杂环境中的定位、交互与操控能力，形成语义感知的机器人智能框架。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是提升机器人在复杂环境中的定位、交互及操控能力。

Method: 通过四个核心研究方向，逐步探讨机器人技术面临的挑战。

Result: 研究结果表明，基础模型的应用能有效提高机器人在非结构化环境中的性能。

Conclusion: 本研究提出了一种系统地利用基础模型的方法，以增强机器人在非结构化环境中的能力，通过语义感知的机器人智能框架来解决基本挑战。

Abstract: This thesis investigates how foundation models can be systematically
leveraged to enhance robotic capabilities, enabling more effective
localization, interaction, and manipulation in unstructured environments. The
work is structured around four core lines of inquiry, each addressing a
fundamental challenge in robotics while collectively contributing to a cohesive
framework for semantics-aware robotic intelligence.

</details>


### [13] [Design for One, Deploy for Many: Navigating Tree Mazes with Multiple Agents](https://arxiv.org/abs/2510.26900)
*Jahir Argote-Gerald,Genki Miyauchi,Julian Rau,Paul Trodden,Roderich Gross*

Main category: cs.RO

TL;DR: 提出了一种新的分布式多智能体迷宫遍历算法，解决了复杂环境下的多个机器人协调问题，在仿真和实际实验中表现优越。


<details>
  <summary>Details</summary>
Motivation: 针对多机器人在复杂环境中的协调问题提供解决方案，尤其是通信限制和拥堵问题。

Method: 提出了一种基于领导者切换机制的分布式多智能体迷宫遍历算法，适用于无环图表示的环境。

Result: 算法在多达300个智能体的仿真实验中表现优异，与原始策略和全局通信策略相比，在某些方面超越了简单策略。

Conclusion: 该算法在实际环境中表现良好，并在某些指标上优于简单策略，适用于复杂的多机器人迷宫导航问题。

Abstract: Maze-like environments, such as cave and pipe networks, pose unique
challenges for multiple robots to coordinate, including communication
constraints and congestion. To address these challenges, we propose a
distributed multi-agent maze traversal algorithm for environments that can be
represented by acyclic graphs. It uses a leader-switching mechanism where one
agent, assuming a head role, employs any single-agent maze solver while the
other agents each choose an agent to follow. The head role gets transferred to
neighboring agents where necessary, ensuring it follows the same path as a
single agent would. The multi-agent maze traversal algorithm is evaluated in
simulations with groups of up to 300 agents, various maze sizes, and multiple
single-agent maze solvers. It is compared against strategies that are na\"ive,
or assume either global communication or full knowledge of the environment. The
algorithm outperforms the na\"ive strategy in terms of makespan and
sum-of-fuel. It is superior to the global-communication strategy in terms of
makespan but is inferior to it in terms of sum-of-fuel. The findings suggest it
is asymptotically equivalent to the full-knowledge strategy with respect to
either metric. Moreover, real-world experiments with up to 20 Pi-puck robots
confirm the feasibility of the approach.

</details>


### [14] [NaviTrace: Evaluating Embodied Navigation of Vision-Language Models](https://arxiv.org/abs/2510.26909)
*Tim Windecker,Manthan Patel,Moritz Reuss,Richard Schwarzkopf,Cesar Cadena,Rudolf Lioutikov,Marco Hutter,Jonas Frey*

Main category: cs.RO

TL;DR: NaviTrace是一个新的视觉问答导航基准，系统性评估视觉语言模型在机器人导航中的表现，发现与人类表现存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 将视觉语言模型集成到机器人导航系统中，以推动构建通用机器人，但评估这些模型的导航能力受到现有评估方法的限制。

Method: 通过引入NaviTrace基准，系统性地评估了八个最先进的视觉语言模型在1000个场景和3000多个专家轨迹下的导航能力，采用了一种新的语义感知轨迹评分方法。

Result: 评估结果表明，目前的模型在空间定位和目标定位方面存在缺陷，表现与人类的期望存在一致差距。

Conclusion: NaviTrace建立了一个可扩展且可重复的真实世界机器人导航基准，揭示了现有视觉语言模型在空间定位和目标定位方面与人类表现之间的一致差距。

Abstract: Vision-language models demonstrate unprecedented performance and
generalization across a wide range of tasks and scenarios. Integrating these
foundation models into robotic navigation systems opens pathways toward
building general-purpose robots. Yet, evaluating these models' navigation
capabilities remains constrained by costly real-world trials, overly simplified
simulations, and limited benchmarks. We introduce NaviTrace, a high-quality
Visual Question Answering benchmark where a model receives an instruction and
embodiment type (human, legged robot, wheeled robot, bicycle) and must output a
2D navigation trace in image space. Across 1000 scenarios and more than 3000
expert traces, we systematically evaluate eight state-of-the-art VLMs using a
newly introduced semantic-aware trace score. This metric combines Dynamic Time
Warping distance, goal endpoint error, and embodiment-conditioned penalties
derived from per-pixel semantics and correlates with human preferences. Our
evaluation reveals consistent gap to human performance caused by poor spatial
grounding and goal localization. NaviTrace establishes a scalable and
reproducible benchmark for real-world robotic navigation. The benchmark and
leaderboard can be found at
https://leggedrobotics.github.io/navitrace_webpage/.

</details>


### [15] [Heterogeneous Robot Collaboration in Unstructured Environments with Grounded Generative Intelligence](https://arxiv.org/abs/2510.26915)
*Zachary Ravichandran,Fernando Cladera,Ankit Prabhu,Jason Hughes,Varun Murali,Camillo Taylor,George J. Pappas,Vijay Kumar*

Main category: cs.RO

TL;DR: SPINE-HT框架针对异构机器人团队在开放环境中进行复杂任务的能力进行了增强，显著提高了成功率，达到了87%。


<details>
  <summary>Details</summary>
Motivation: 在不确定、开放的无先验地图环境中，异构机器人团队需要进行复杂的合作任务，并有效适应在线获取的信息。

Method: SPINE-HT框架通过三阶段过程将LLM的推理能力与异构机器人团队的上下文相结合，根据语言描述的任务目标和团队能力，生成能够实现的子任务，并基于能力（如可穿越性或感知）分配给 robots ，经过反馈不断精炼。

Result: 通过模拟实验和实际团队实验，我们的方法在不同机器人参与的任务中表现出色，尤其是在需要基于机器人能力进行推理和优化子任务的情况下。

Conclusion: 我们的框架在实际实验中取得了87%的成功率，相较于之前的LLM增强的异构团队方法，成功率几乎翻倍。

Abstract: Heterogeneous robot teams operating in realistic settings often must
accomplish complex missions requiring collaboration and adaptation to
information acquired online. Because robot teams frequently operate in
unstructured environments -- uncertain, open-world settings without prior maps
-- subtasks must be grounded in robot capabilities and the physical world.
While heterogeneous teams have typically been designed for fixed
specifications, generative intelligence opens the possibility of teams that can
accomplish a wide range of missions described in natural language. However,
current large language model (LLM)-enabled teaming methods typically assume
well-structured and known environments, limiting deployment in unstructured
environments. We present SPINE-HT, a framework that addresses these limitations
by grounding the reasoning abilities of LLMs in the context of a heterogeneous
robot team through a three-stage process. Given language specifications
describing mission goals and team capabilities, an LLM generates grounded
subtasks which are validated for feasibility. Subtasks are then assigned to
robots based on capabilities such as traversability or perception and refined
given feedback collected during online operation. In simulation experiments
with closed-loop perception and control, our framework achieves nearly twice
the success rate compared to prior LLM-enabled heterogeneous teaming
approaches. In real-world experiments with a Clearpath Jackal, a Clearpath
Husky, a Boston Dynamics Spot, and a high-altitude UAV, our method achieves an
87\% success rate in missions requiring reasoning about robot capabilities and
refining subtasks with online feedback. More information is provided at
https://zacravichandran.github.io/SPINE-HT.

</details>


### [16] [RepV: Safety-Separable Latent Spaces for Scalable Neurosymbolic Plan Verification](https://arxiv.org/abs/2510.26935)
*Yunhao Yang,Neel P. Bhatt,Pranay Samineni,Rohan Siva,Zhanyang Wang,Ufuk Topcu*

Main category: cs.RO

TL;DR: RepV是一种神经符号验证器，结合形式方法与深度学习，通过学习潜在空间来实现安全计划的验证，提高合规性预测准确率，同时减少模型参数。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统迁移到安全关键领域，确保其行动符合规定的挑战不断增大，既有的形式方法和深度学习方法各有局限。

Method: RepV采用了一种轻量级投影器，将标记计划和由语言模型生成的推理嵌入到低维空间中，并利用冻结的线性边界对未见的自然语言规则进行合规性验证。

Result: RepV使合规性预测准确率比基线方法提高了最高15%，且在不同规划领域的精细化框架上表现超过普通微调基线。

Conclusion: RepV通过学习潜在空间，实现了安全和不安全计划的线性可分性，并且在合规性预测方面超越了基准方法，为神经符号计划验证提供了可扩展和可靠的工具。

Abstract: As AI systems migrate to safety-critical domains, verifying that their
actions comply with well-defined rules remains a challenge. Formal methods
provide provable guarantees but demand hand-crafted temporal-logic
specifications, offering limited expressiveness and accessibility. Deep
learning approaches enable evaluation of plans against natural-language
constraints, yet their opaque decision process invites misclassifications with
potentially severe consequences. We introduce RepV, a neurosymbolic verifier
that unifies both views by learning a latent space where safe and unsafe plans
are linearly separable. Starting from a modest seed set of plans labeled by an
off-the-shelf model checker, RepV trains a lightweight projector that embeds
each plan, together with a language model-generated rationale, into a
low-dimensional space; a frozen linear boundary then verifies compliance for
unseen natural-language rules in a single forward pass.
  Beyond binary classification, RepV provides a probabilistic guarantee on the
likelihood of correct verification based on its position in the latent space.
This guarantee enables a guarantee-driven refinement of the planner, improving
rule compliance without human annotations. Empirical evaluations show that RepV
improves compliance prediction accuracy by up to 15% compared to baseline
methods while adding fewer than 0.2M parameters. Furthermore, our refinement
framework outperforms ordinary fine-tuning baselines across various planning
domains. These results show that safety-separable latent spaces offer a
scalable, plug-and-play primitive for reliable neurosymbolic plan verification.
Code and data are available at: https://repv-project.github.io/.

</details>


### [17] [A Hermetic, Transparent Soft Growing Vine Robot System for Pipe Inspection](https://arxiv.org/abs/2510.27010)
*William E. Heap,Yimeng Qin,Kai Hammond,Anish Bayya,Haonon Kong,Allison M. Okamura*

Main category: cs.RO

TL;DR: 本文介绍了一种新的封闭和透明的软生长藤状机器人系统，用于管道的视觉状态评估和映射，经过现场验证，显示出良好的应用前景。


<details>
  <summary>Details</summary>
Motivation: 随着老化管道的修复需求增加，准确的状态评估和内部映射变得尤为重要，但现有的软生长藤机器人系统未能在工业环境中进行有效验证。

Method: 设计、建模和测试了一种被动适应的封闭尖端支架，结合了机械和电气组件的封闭设计。

Result: 在污水管道中的实际条件评估和映射任务中验证了该系统的效果，展示了其在管道检查中的应用潜力。

Conclusion: 该研究开发了一种稳健且经过现场验证的软生长藤状机器人系统，适用于管道检查，推动了该技术的进一步开发和应用。

Abstract: Rehabilitation of aging pipes requires accurate condition assessment and
mapping far into the pipe interiors. Soft growing vine robot systems are
particularly promising for navigating confined, sinuous paths such as in pipes,
but are currently limited by complex subsystems and a lack of validation in
real-world industrial settings. In this paper, we introduce the concept and
implementation of a hermetic and transparent vine robot system for visual
condition assessment and mapping within non-branching pipes. This design
encloses all mechanical and electrical components within the vine robot's soft,
airtight, and transparent body, protecting them from environmental interference
while enabling visual sensing. Because this approach requires an enclosed
mechanism for transporting sensors, we developed, modeled, and tested a
passively adapting enclosed tip mount. Finally, we validated the hermetic and
transparent vine robot system concept through a real-world condition assessment
and mapping task in a wastewater pipe. This work advances the use of
soft-growing vine robots in pipe inspection by developing and demonstrating a
robust, streamlined, field-validated system suitable for continued development
and deployment.

</details>


### [18] [Preliminary Prototyping of Avoidance Behaviors Triggered by a User's Physical Approach to a Robot](https://arxiv.org/abs/2510.27436)
*Tomoko Yonezawa,Hirotake Yamazoe,Atsuo Fujino,Daigo Suhara,Takaya Tamamoto,Yuto Nishiguchi*

Main category: cs.RO

TL;DR: 本研究探讨并实现了机器人在人员接近时的拒绝和回避行为，基于人际距离模型设计，展示了机器人如何在互动中灵活表达不适感。


<details>
  <summary>Details</summary>
Motivation: 研究人机交互中，机器人如何有效地表达拒绝和回避，特别是在近距离接触时的互动反应。

Method: 通过建立不适感累积和衰减的模型，结合PAD情感模型的主导性轴，模拟了机器人的拒绝状态和回避行为，并在机械臂上实现了这些行为的表达。

Result: 研究结果展示了内部状态参数到渐变耐受动作的完整流程，并在超过极限时表现出回避行为，验证了模型的有效性。

Conclusion: 该研究成功设计并实现了一种机器人拒绝和回避行为的模型，能够根据人际距离调整机器人与人之间的互动方式。

Abstract: Human-robot interaction frequently involves physical proximity or contact. In
human-human settings, people flexibly accept, reject, or tolerate such
approaches depending on the relationship and context. We explore the design of
a robot's rejective internal state and corresponding avoidance behaviors, such
as withdrawing or pushing away, when a person approaches. We model the
accumulation and decay of discomfort as a function of interpersonal distance,
and implement tolerance (endurance) and limit-exceeding avoidance driven by the
Dominance axis of the PAD affect model. The behaviors and their intensities are
realized on an arm robot. Results illustrate a coherent pipeline from internal
state parameters to graded endurance motions and, once a limit is crossed, to
avoidance actions.

</details>


### [19] [A Multi-Modal Neuro-Symbolic Approach for Spatial Reasoning-Based Visual Grounding in Robotics](https://arxiv.org/abs/2510.27033)
*Simindokht Jahangard,Mehrzad Mohammadi,Abhinav Dhall,Hamid Rezatofighi*

Main category: cs.RO

TL;DR: 我们提出了一个新的神经符号框架，通过结合全景图像和3D点云信息，改善了视觉模型在复杂环境中的空间推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型在细粒度空间推理方面表现不佳，因此我们希望通过整合神经感知和符号推理来改善这一问题。

Method: 我们的方法结合了全景图像和3D点云信息，包括感知模块和推理模块，通过构建结构化场景图来支持精确的查询。

Result: 在JRDB-Reasoning数据集上评估，我们的方法在拥挤的人造环境中展现了更优越的性能和可靠性。

Conclusion: 我们提出的神经符号框架在复杂环境中的空间推理任务上表现优越，适合用于机器人和具身人工智能应用。

Abstract: Visual reasoning, particularly spatial reasoning, is a challenging cognitive
task that requires understanding object relationships and their interactions
within complex environments, especially in robotics domain. Existing
vision_language models (VLMs) excel at perception tasks but struggle with
fine-grained spatial reasoning due to their implicit, correlation-driven
reasoning and reliance solely on images. We propose a novel neuro_symbolic
framework that integrates both panoramic-image and 3D point cloud information,
combining neural perception with symbolic reasoning to explicitly model spatial
and logical relationships. Our framework consists of a perception module for
detecting entities and extracting attributes, and a reasoning module that
constructs a structured scene graph to support precise, interpretable queries.
Evaluated on the JRDB-Reasoning dataset, our approach demonstrates superior
performance and reliability in crowded, human_built environments while
maintaining a lightweight design suitable for robotics and embodied AI
applications.

</details>


### [20] [SpikeATac: A Multimodal Tactile Finger with Taxelized Dynamic Sensing for Dexterous Manipulation](https://arxiv.org/abs/2510.27048)
*Eric T. Chang,Peter Ballentine,Zhanpeng He,Do-Gon Kim,Kai Jiang,Hua-Hsuan Liang,Joaquin Palacios,William Wang,Pedro Piacenza,Ioannis Kymissis,Matei Ciocarlie*

Main category: cs.RO

TL;DR: SpikeATac是一种新型触觉传感器，结合多种感应方法，实现了灵巧的物体操控，特别适合处理脆弱物体。


<details>
  <summary>Details</summary>
Motivation: 开发一种高灵敏度的触觉传感器，以提高机器人手指在操控脆弱和可变形物体上的能力。

Method: 结合了PVDF动态传感器和电容静态传感器的SpikeATac手指，采用强化学习与触觉反馈的学习框架进行调优。

Result: SpikeATac能够快速、精确地抓取和操控脆弱物体，实现之前未能完成的复杂任务。

Conclusion: SpikeATac展示了其在处理脆弱物体时的高灵敏度和控制能力，成功实现了手指在接触丰富的环境中的灵巧操作。

Abstract: In this work, we introduce SpikeATac, a multimodal tactile finger combining a
taxelized and highly sensitive dynamic response (PVDF) with a static
transduction method (capacitive) for multimodal touch sensing. Named for its
`spiky' response, SpikeATac's 16-taxel PVDF film sampled at 4 kHz provides
fast, sensitive dynamic signals to the very onset and breaking of contact. We
characterize the sensitivity of the different modalities, and show that
SpikeATac provides the ability to stop quickly and delicately when grasping
fragile, deformable objects. Beyond parallel grasping, we show that SpikeATac
can be used in a learning-based framework to achieve new capabilities on a
dexterous multifingered robot hand. We use a learning recipe that combines
reinforcement learning from human feedback with tactile-based rewards to
fine-tune the behavior of a policy to modulate force. Our hardware platform and
learning pipeline together enable a difficult dexterous and contact-rich task
that has not previously been achieved: in-hand manipulation of fragile objects.
Videos are available at
\href{https://roamlab.github.io/spikeatac/}{roamlab.github.io/spikeatac}.

</details>


### [21] [Learning Generalizable Visuomotor Policy through Dynamics-Alignment](https://arxiv.org/abs/2510.27114)
*Dohyeok Lee,Jung Min Lee,Munkyung Kim,Seokhun Ju,Jin Woo Koo,Kyungjae Lee,Dohyeong Kim,TaeHyun Cho,Jungwoo Lee*

Main category: cs.RO

TL;DR: 本研究提出了一种新的策略，通过将动态预测融入策略学习，提高了机器人在操纵任务中的泛化能力，特别是在面对视觉和光照变换的干扰时。


<details>
  <summary>Details</summary>
Motivation: 行为克隆方法因专家演示数据支持有限而在机器人学习中泛化能力差，因此本研究寻求提高机器人在复杂任务中的泛化性能。

Method: 引入了一种新颖的架构，在行动生成过程中，策略模型和动态模型之间提供相互纠正反馈，以实现自我修正和提高泛化能力。

Result: 在真实机器人操纵任务中的实验验证表明，所提出的方法在泛化性能上优于基线方法，特别是在视觉干扰和光照变化等OOD场景中表现出色。

Conclusion: 提出的动力对齐流匹配策略（DAP）在真实世界的机器人操纵任务中显示出优越的泛化性能，尤其在OOD（过度外推）场景下表现出强大的鲁棒性。

Abstract: Behavior cloning methods for robot learning suffer from poor generalization
due to limited data support beyond expert demonstrations. Recent approaches
leveraging video prediction models have shown promising results by learning
rich spatiotemporal representations from large-scale datasets. However, these
models learn action-agnostic dynamics that cannot distinguish between different
control inputs, limiting their utility for precise manipulation tasks and
requiring large pretraining datasets. We propose a Dynamics-Aligned Flow
Matching Policy (DAP) that integrates dynamics prediction into policy learning.
Our method introduces a novel architecture where policy and dynamics models
provide mutual corrective feedback during action generation, enabling
self-correction and improved generalization. Empirical validation demonstrates
generalization performance superior to baseline methods on real-world robotic
manipulation tasks, showing particular robustness in OOD scenarios including
visual distractions and lighting variations.

</details>


### [22] [Confined Space Underwater Positioning Using Collaborative Robots](https://arxiv.org/abs/2510.27151)
*Xueliang Cheng,Kanzhong Yao,Andrew West,Ognjen Marjanovic,Barry Lennox,Keir Groves*

Main category: cs.RO

TL;DR: CAP系统为水下机器人提供了一种无需基础设施的高效定位方法。


<details>
  <summary>Details</summary>
Motivation: 在受限和杂乱的环境中进行水下机器人的定位仍然是一个关键挑战，而现有系统在开放水域环境中效果更好。

Method: CAP系统使用移动领导者帮助水下机器人进行定位，并在大型测试水槽中进行了验证。

Result: 实验结果显示，CAP实现了70毫米的均方根误差，且无需固定基础设施、大规模校准或依赖环境特征。

Conclusion: CAP系统通过结合合作机器人技术和传感器融合，提供了一种在无GPS和高度受限环境中有效的水下定位解决方案。

Abstract: Positioning of underwater robots in confined and cluttered spaces remains a
key challenge for field operations. Existing systems are mostly designed for
large, open-water environments and struggle in industrial settings due to poor
coverage, reliance on external infrastructure, and the need for feature-rich
surroundings. Multipath effects from continuous sound reflections further
degrade signal quality, reducing accuracy and reliability. Accurate and easily
deployable positioning is essential for repeatable autonomous missions;
however, this requirement has created a technological bottleneck limiting
underwater robotic deployment. This paper presents the Collaborative Aquatic
Positioning (CAP) system, which integrates collaborative robotics and sensor
fusion to overcome these limitations. Inspired by the "mother-ship" concept,
the surface vehicle acts as a mobile leader to assist in positioning a
submerged robot, enabling localization even in GPS-denied and highly
constrained environments. The system is validated in a large test tank through
repeatable autonomous missions using CAP's position estimates for real-time
trajectory control. Experimental results demonstrate a mean Euclidean distance
(MED) error of 70 mm, achieved in real time without requiring fixed
infrastructure, extensive calibration, or environmental features. CAP leverages
advances in mobile robot sensing and leader-follower control to deliver a step
change in accurate, practical, and infrastructure-free underwater localization.

</details>


### [23] [MobiDock: Design and Control of A Modular Self Reconfigurable Bimanual Mobile Manipulator via Robotic Docking](https://arxiv.org/abs/2510.27178)
*Xuan-Thuan Nguyen,Khac Nam Nguyen,Ngoc Duy Tran,Thi Thoa Mac,Anh Nguyen,Hoang Hiep Ly,Tung D. Ta*

Main category: cs.RO

TL;DR: 本研究提出的MobiDock系统通过物理重构简化了多机器人控制，提高了动态稳定性和操作效率。


<details>
  <summary>Details</summary>
Motivation: 多机器人系统在协同控制和动态稳定性方面面临挑战，尤其是移动操控器。

Method: 提出了MobiDock，一个模块化自我重构的移动操控器系统，利用计算机视觉和新的螺纹锁定机制进行自主对接。

Result: 与两个独立合作的机器人相比，合并系统在动态稳定性和操作效率上表现更好，具有更低的均方根加速度和抖动值、更高的角度精度，且任务完成速度显著提高。

Conclusion: 物理重构是一种强大的设计原则，它简化了协同控制，提高了复杂任务在现实环境中的稳定性和性能。

Abstract: Multi-robot systems, particularly mobile manipulators, face challenges in
control coordination and dynamic stability when working together. To address
this issue, this study proposes MobiDock, a modular self-reconfigurable mobile
manipulator system that allows two independent robots to physically connect and
form a unified mobile bimanual platform. This process helps transform a complex
multi-robot control problem into the management of a simpler, single system.
The system utilizes an autonomous docking strategy based on computer vision
with AprilTag markers and a new threaded screw-lock mechanism. Experimental
results show that the docked configuration demonstrates better performance in
dynamic stability and operational efficiency compared to two independently
cooperating robots. Specifically, the unified system has lower Root Mean Square
(RMS) Acceleration and Jerk values, higher angular precision, and completes
tasks significantly faster. These findings confirm that physical
reconfiguration is a powerful design principle that simplifies cooperative
control, improving stability and performance for complex tasks in real-world
environments.

</details>


### [24] [Hybrid Gripper Finger Enabling In-Grasp Friction Modulation Using Inflatable Silicone Pockets](https://arxiv.org/abs/2510.27184)
*Hoang Hiep Ly,Cong-Nhat Nguyen,Doan-Quang Tran,Quoc-Khanh Dang,Ngoc Duy Tran,Thi Thoa Mac,Anh Nguyen,Xuan-Thuan Nguyen,Tung D. Ta*

Main category: cs.RO

TL;DR: 本文提出一种混合抓手手指，使用气囊调节摩擦力，增强抓取重、滑及易碎物体的能力，无需施加过大的力。


<details>
  <summary>Details</summary>
Motivation: 解决传统抓手在处理重、滑、易碎物体时所面临的挑战，避免因施加高正常力导致的物体损坏。

Method: 通过使用刚性结构外壳与柔性气囊结合的抓手设计，控制内部空气压力来调节表面摩擦力。

Result: 实验结果表明，内部压力的增加与有效摩擦系数的提高成正比，使得抓手能够安全稳定地抓取各种物体。

Conclusion: 该混合抓手手指提供了一种增强灵活性的解决方案，可以安全地处理各种不同性质的物体，而无需依赖于高的正常力量。

Abstract: Grasping objects with diverse mechanical properties, such as heavy, slippery,
or fragile items, remains a significant challenge in robotics. Conventional
grippers often rely on applying high normal forces, which can cause damage to
objects. To address this limitation, we present a hybrid gripper finger that
combines a rigid structural shell with a soft, inflatable silicone pocket. The
gripper finger can actively modulate its surface friction by controlling the
internal air pressure of the silicone pocket. Results from fundamental
experiments indicate that increasing the internal pressure results in a
proportional increase in the effective coefficient of friction. This enables
the gripper to stably lift heavy and slippery objects without increasing the
gripping force and to handle fragile or deformable objects, such as eggs,
fruits, and paper cups, with minimal damage by increasing friction rather than
applying excessive force. The experimental results demonstrate that the hybrid
gripper finger with adaptable friction provides a robust and safer alternative
to relying solely on high normal forces, thereby enhancing the gripper
flexibility in handling delicate, fragile, and diverse objects.

</details>


### [25] [Vectorized Online POMDP Planning](https://arxiv.org/abs/2510.27191)
*Marcus Hoerger,Muhammad Sudrajat,Hanna Kurniawati*

Main category: cs.RO

TL;DR: VOPP是一个新型的并行在线POMDP求解器，通过矢量化计算提高了效率，并显著超越了传统求解器的性能。


<details>
  <summary>Details</summary>
Motivation: 在部分可观察的环境中，规划对于自主机器人至关重要。现有的POMDP求解器在并行化时面临依赖性和同步瓶颈的问题，这限制了其计算效率。

Method: 提出了矢量化的在线POMDP规划器（VOPP），通过最近的POMDP公式分析解决部分优化组件，只保留期望值的数值计算，并将所有规划相关的数据结构表示为张量集合，实现全矢量化计算。

Result: 实验结果表明，与现有的最先进并行在线求解器相比，VOPP在计算近似最优解的效率上至少提高了20倍。

Conclusion: VOPP是一种新型的并行在线POMDP求解器，能够高效计算近似最优解，并且在并行计算中提升了效率，没有依赖和同步瓶颈。

Abstract: Planning under partial observability is an essential capability of autonomous
robots. The Partially Observable Markov Decision Process (POMDP) provides a
powerful framework for planning under partial observability problems, capturing
the stochastic effects of actions and the limited information available through
noisy observations. POMDP solving could benefit tremendously from massive
parallelization of today's hardware, but parallelizing POMDP solvers has been
challenging. They rely on interleaving numerical optimization over actions with
the estimation of their values, which creates dependencies and synchronization
bottlenecks between parallel processes that can quickly offset the benefits of
parallelization. In this paper, we propose Vectorized Online POMDP Planner
(VOPP), a novel parallel online solver that leverages a recent POMDP
formulation that analytically solves part of the optimization component,
leaving only the estimation of expectations for numerical computation. VOPP
represents all data structures related to planning as a collection of tensors
and implements all planning steps as fully vectorized computations over this
representation. The result is a massively parallel solver with no dependencies
and synchronization bottlenecks between parallel computations. Experimental
results indicate that VOPP is at least 20X more efficient in computing
near-optimal solutions compared to an existing state-of-the-art parallel online
solver.

</details>


### [26] [A Modular and Scalable System Architecture for Heterogeneous UAV Swarms Using ROS 2 and PX4-Autopilot](https://arxiv.org/abs/2510.27327)
*Robert Pommeranz,Kevin Tebbe,Ralf Heynicke,Gerd Scholl*

Main category: cs.RO

TL;DR: 本论文提出了一种基于PX4-Autopilot和ROS 2框架的模块化异构反无人机系统架构，验证了其在群体协调和计算机视觉集成方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 面对反无人机需求，设计一种可以有效协调和管理多架无人机的系统。

Method: 采用PX4-Autopilot和ROS 2框架，建立模块化和可扩展的异构群体反无人机系统架构。

Result: 通过仿真和实测验证了群体无人机系统架构的核心功能，包括领导跟随、编队飞行及集成计算机视觉算法。

Conclusion: 所提出的架构在Gazebo模拟环境和实际演示中得到了验证，证明了其有效性与可行性。

Abstract: In this paper a modular and scalable architecture for heterogeneous
swarm-based Counter Unmanned Aerial Systems (C-UASs) built on PX4-Autopilot and
Robot Operating System 2 (ROS 2) framework is presented. The proposed
architecture emphasizes seamless integration of hardware components by
introducing independent ROS 2 nodes for each component of a Unmanned Aerial
Vehicle (UAV). Communication between swarm participants is abstracted in
software, allowing the use of various technologies without architectural
changes. Key functionalities are supported, e.g. leader following and formation
flight to maneuver the swarm. The system also allows computer vision algorithms
to be integrated for the detection and tracking of UAVs. Additionally, a ground
station control is integrated for the coordination of swarm operations.
Swarm-based Unmanned Aerial System (UAS) architecture is verified within a
Gazebo simulation environment but also in real-world demonstrations.

</details>


### [27] [Modified-Emergency Index (MEI): A Criticality Metric for Autonomous Driving in Lateral Conflict](https://arxiv.org/abs/2510.27333)
*Hao Cheng,Yanbo Jiang,Qingyuan Shi,Qingwen Meng,Keyu Chen,Wenhao Yu,Jianqiang Wang,Sifa Zheng*

Main category: cs.RO

TL;DR: 本文提出MEI，用于改进自动驾驶安全评估，特别是在城市环境中的横向冲突。


<details>
  <summary>Details</summary>
Motivation: 现有的安全评估指标主要关注纵向冲突，难以准确量化城市环境中的横向冲突风险。

Method: 提出了修改后的紧急指标（MEI），用于量化横向冲突中的回避努力，并通过对比验证。

Result: MEI在准确量化重要性和捕捉风险演变方面稳步超越了ACT和PET指标。

Conclusion: MEI是一种有前景的量化城市冲突的重要性指标，有助于提升自动驾驶安全评估框架。

Abstract: Effective, reliable, and efficient evaluation of autonomous driving safety is
essential to demonstrate its trustworthiness. Criticality metrics provide an
objective means of assessing safety. However, as existing metrics primarily
target longitudinal conflicts, accurately quantifying the risks of lateral
conflicts - prevalent in urban settings - remains challenging. This paper
proposes the Modified-Emergency Index (MEI), a metric designed to quantify
evasive effort in lateral conflicts. Compared to the original Emergency Index
(EI), MEI refines the estimation of the time available for evasive maneuvers,
enabling more precise risk quantification. We validate MEI on a public lateral
conflict dataset based on Argoverse-2, from which we extract over 1,500
high-quality AV conflict cases, including more than 500 critical events. MEI is
then compared with the well-established ACT and the widely used PET metrics.
Results show that MEI consistently outperforms them in accurately quantifying
criticality and capturing risk evolution. Overall, these findings highlight MEI
as a promising metric for evaluating urban conflicts and enhancing the safety
assessment framework for autonomous driving. The open-source implementation is
available at https://github.com/AutoChengh/MEI.

</details>


### [28] [Towards a Multi-Embodied Grasping Agent](https://arxiv.org/abs/2510.27420)
*Roman Freiberg,Alexander Qualmann,Ngo Anh Vien,Gerhard Neumann*

Main category: cs.RO

TL;DR: 本文提出了一种数据高效的多式样抓取方法，能够处理不同自由度的夹具，并通过JAX平台改进学习和推理性能。


<details>
  <summary>Details</summary>
Motivation: 当前多式样抓取方法在应对多样的夹具设计时，面临数据量不足及运动学结构学习困难的问题。

Method: 利用流式、等变的抓取合成架构，将各模块迁移到JAX平台上，支持针对场景、夹具和抓取的批处理能力。

Result: 开发了一种能够处理多种夹具的抓取架构，使用25,000个场景和20百万个抓取，显著提升了学习效率和推理速度。

Conclusion: 该方法通过一种数据高效、流式的等变抓取合成架构，能够处理不同类型和自由度的夹具，充分利用潜在的运动学模型，从而提高了抓取性能和推理速度。

Abstract: Multi-embodiment grasping focuses on developing approaches that exhibit
generalist behavior across diverse gripper designs. Existing methods often
learn the kinematic structure of the robot implicitly and face challenges due
to the difficulty of sourcing the required large-scale data. In this work, we
present a data-efficient, flow-based, equivariant grasp synthesis architecture
that can handle different gripper types with variable degrees of freedom and
successfully exploit the underlying kinematic model, deducing all necessary
information solely from the gripper and scene geometry. Unlike previous
equivariant grasping methods, we translated all modules from the ground up to
JAX and provide a model with batching capabilities over scenes, grippers, and
grasps, resulting in smoother learning, improved performance and faster
inference time. Our dataset encompasses grippers ranging from humanoid hands to
parallel yaw grippers and includes 25,000 scenes and 20 million grasps.

</details>


### [29] [Learning Soft Robotic Dynamics with Active Exploration](https://arxiv.org/abs/2510.27428)
*Hehui Zheng,Bhavya Sukhija,Chenhao Li,Klemens Iten,Andreas Krause,Robert K. Katzschmann*

Main category: cs.RO

TL;DR: 本文介绍了一种新颖的主动探索框架SoftAE，旨在提高软机器人的动态建模能力，克服现有方法的局限性，实现更高效、通用的控制能力。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动方法在应对软机器人系统的非线性动态建模时，因任务演示范围狭窄或随机探索低效而难以推广。

Method: SoftAE采用概率集成模型来估计认知不确定性，主动引导探索未充分代表的状态-动作空间区域。

Result: SoftAE在三种模拟软机器人平台（如连续臂、流体中的关节鱼和混合驱动的肌肉骨骼腿）以及真实世界的气动驱动连续软臂上进行了评估，相比随机探索和任务特定的基于模型的强化学习，SoftAE能产生更准确的动力学模型，并在未见任务上实现更优的零-shot控制，同时在感知噪声、驱动延迟和非线性材料效应下保持鲁棒性。

Conclusion: 不确定性驱动的主动探索框架SoftAE能有效地学习通用且可再利用的动力学模型，为软机器人控制提供了一种向自主、适应性强和数据效率高的方向发展。

Abstract: Soft robots offer unmatched adaptability and safety in unstructured
environments, yet their compliant, high-dimensional, and nonlinear dynamics
make modeling for control notoriously difficult. Existing data-driven
approaches often fail to generalize, constrained by narrowly focused task
demonstrations or inefficient random exploration. We introduce SoftAE, an
uncertainty-aware active exploration framework that autonomously learns
task-agnostic and generalizable dynamics models of soft robotic systems. SoftAE
employs probabilistic ensemble models to estimate epistemic uncertainty and
actively guides exploration toward underrepresented regions of the state-action
space, achieving efficient coverage of diverse behaviors without task-specific
supervision. We evaluate SoftAE on three simulated soft robotic platforms -- a
continuum arm, an articulated fish in fluid, and a musculoskeletal leg with
hybrid actuation -- and on a pneumatically actuated continuum soft arm in the
real world. Compared with random exploration and task-specific model-based
reinforcement learning, SoftAE produces more accurate dynamics models, enables
superior zero-shot control on unseen tasks, and maintains robustness under
sensing noise, actuation delays, and nonlinear material effects. These results
demonstrate that uncertainty-driven active exploration can yield scalable,
reusable dynamics models across diverse soft robotic morphologies, representing
a step toward more autonomous, adaptable, and data-efficient control in
compliant robots.

</details>


### [30] [EBT-Policy: Energy Unlocks Emergent Physical Reasoning Capabilities](https://arxiv.org/abs/2510.27545)
*Travis Davies,Yiqi Huang,Alexi Gladstone,Yunxin Liu,Xiang Chen,Heng Ji,Huxian Liu,Luhui Hu*

Main category: cs.RO

TL;DR: EBT-Policy通过新架构超越扩散政策，减少计算需求并展现出新的能力，向增强机器人行为的鲁棒性迈出重要一步。


<details>
  <summary>Details</summary>
Motivation: 现有的隐式策略由于计算成本高、暴露偏差和不稳定推断动态，在分布变化下表现不佳，需要一种更鲁棒的策略。

Method: 引入了一种名为EBT-Policy的能量基础架构，解决机器人和现实世界设置中的核心问题。

Result: EBT-Policy在多个任务中稳定优于扩散基础政策，并在某些任务中在仅两次推断步骤内收敛。

Conclusion: EBT-Policy在模拟和现实任务中表现优异，显著减少训练和推理计算，展现出独特能力，提供了对抗分布偏移的潜力。

Abstract: Implicit policies parameterized by generative models, such as Diffusion
Policy, have become the standard for policy learning and Vision-Language-Action
(VLA) models in robotics. However, these approaches often suffer from high
computational cost, exposure bias, and unstable inference dynamics, which lead
to divergence under distribution shifts. Energy-Based Models (EBMs) address
these issues by learning energy landscapes end-to-end and modeling equilibrium
dynamics, offering improved robustness and reduced exposure bias. Yet, policies
parameterized by EBMs have historically struggled to scale effectively. Recent
work on Energy-Based Transformers (EBTs) demonstrates the scalability of EBMs
to high-dimensional spaces, but their potential for solving core challenges in
physically embodied models remains underexplored. We introduce a new
energy-based architecture, EBT-Policy, that solves core issues in robotic and
real-world settings. Across simulated and real-world tasks, EBT-Policy
consistently outperforms diffusion-based policies, while requiring less
training and inference computation. Remarkably, on some tasks it converges
within just two inference steps, a 50x reduction compared to Diffusion Policy's
100. Moreover, EBT-Policy exhibits emergent capabilities not seen in prior
models, such as zero-shot recovery from failed action sequences using only
behavior cloning and without explicit retry training. By leveraging its scalar
energy for uncertainty-aware inference and dynamic compute allocation,
EBT-Policy offers a promising path toward robust, generalizable robot behavior
under distribution shifts.

</details>


### [31] [Toward Accurate Long-Horizon Robotic Manipulation: Language-to-Action with Foundation Models via Scene Graphs](https://arxiv.org/abs/2510.27558)
*Sushil Samuel Dinesh,Shinkyu Park*

Main category: cs.RO

TL;DR: 该论文提出了一个框架，可以在无需特定领域训练的情况下，利用预训练基础模型进行机器人操作，展示了其在机器人系统开发中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 目标是提高机器人操作的灵活性和效率，减少对特定领域训练的依赖。

Method: 通过整合现成模型，结合多模态感知和通用推理模型，动态维护场景图以实现空间意识和环境推理。

Result: 通过一系列桌面机器人操作实验评估框架，结果显示其能够直接基于现成基础模型构建机器人操作系统。

Conclusion: 该框架能有效利用预训练基础模型进行机器人操作，且无需特定领域的训练，这显示了其在机器人系统开发中的潜力。

Abstract: This paper presents a framework that leverages pre-trained foundation models
for robotic manipulation without domain-specific training. The framework
integrates off-the-shelf models, combining multimodal perception from
foundation models with a general-purpose reasoning model capable of robust task
sequencing. Scene graphs, dynamically maintained within the framework, provide
spatial awareness and enable consistent reasoning about the environment. The
framework is evaluated through a series of tabletop robotic manipulation
experiments, and the results highlight its potential for building robotic
manipulation systems directly on top of off-the-shelf foundation models.

</details>


### [32] [Whole-Body Proprioceptive Morphing: A Modular Soft Gripper for Robust Cross-Scale Grasping](https://arxiv.org/abs/2510.27666)
*Dong Heon Han,Xiaohao Xu,Yuxi Chen,Yusheng Zhou,Xinqi Zhang,Jiaqi Wang,Daniel Bruder,Xiaonan Huang*

Main category: cs.RO

TL;DR: 本研究提出了一种低成本、易于制造的模块化软抓手，通过整合自感应反馈，实现了机器人在抓取过程中生物级别的灵活性。


<details>
  <summary>Details</summary>
Motivation: 受到章鱼等生物系统跨尺度操作能力的启发，研究旨在克服传统软抓手在形态上的限制，寻求更灵活的抓取能力。

Method: 设计了一种分布式网络模块化自感应气动执行器，使抓手能够智能地重新配置其整个拓扑结构，控制不同的多边形形状。

Result: 实验表明，该方法能够扩展抓取包容性，提高对各种物体几何形状和规模的适应性，并实现新型操作模式，如多物体和内部钩抓取。

Conclusion: 该研究提出了一种模块化软抓手架构，能够实现与生物系统类似的灵活性和多样性的抓取模式，扩展了机器人操作的能力。

Abstract: Biological systems, such as the octopus, exhibit masterful cross-scale
manipulation by adaptively reconfiguring their entire form, a capability that
remains elusive in robotics. Conventional soft grippers, while compliant, are
mostly constrained by a fixed global morphology, and prior shape-morphing
efforts have been largely confined to localized deformations, failing to
replicate this biological dexterity. Inspired by this natural exemplar, we
introduce the paradigm of collaborative, whole-body proprioceptive morphing,
realized in a modular soft gripper architecture. Our design is a distributed
network of modular self-sensing pneumatic actuators that enables the gripper to
intelligently reconfigure its entire topology, achieving multiple morphing
states that are controllable to form diverse polygonal shapes. By integrating
rich proprioceptive feedback from embedded sensors, our system can seamlessly
transition from a precise pinch to a large envelope grasp. We experimentally
demonstrate that this approach expands the grasping envelope and enhances
generalization across diverse object geometries (standard and irregular) and
scales (up to 10$\times$), while also unlocking novel manipulation modalities
such as multi-object and internal hook grasping. This work presents a low-cost,
easy-to-fabricate, and scalable framework that fuses distributed actuation with
integrated sensing, offering a new pathway toward achieving biological levels
of dexterity in robotic manipulation.

</details>
