<div id=toc></div>

# Table of Contents

- [cs.HC](#cs.HC) [Total: 20]
- [cs.RO](#cs.RO) [Total: 22]


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [1] [An extended reality-based framework for user risk training in urban built environment](https://arxiv.org/abs/2511.02837)
*Sotirios Konstantakos,Sotirios Asparagkathos,Moatasim Mahmoud,Stamatia Rizou,Enrico Quagliarini,Gabriele Bernardini*

Main category: cs.HC

TL;DR: 本文提出一个基于XR的框架，以提升城市环境中各利益相关者的风险培训效果，特别针对气候变化引发的洪水风险，强调参与和定制化的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着城市风险增大，尤其是气候变化引发的洪水，亟需提高各方的风险意识和准备能力。

Method: 通过用户流映射、场景选择和性能评估等方法实施XR框架，进行试点应用。

Result: XR框架通过沉浸式技术模拟真实的紧急场景，有助于提高用户参与度和对潜在危险的理解。

Conclusion: XR技术有潜力转变城市风险培训，促进应对城市危害的准备和韧性文化。

Abstract: In the context of increasing urban risks, particularly from climate
change-induced flooding, this paper presents an extended Reality (XR)-based
framework to improve user risk training within urban built environments. The
framework is designed to improve risk awareness and preparedness among various
stakeholders, including citizens, local authorities, and emergency responders.
Using immersive XR technologies, the training experience simulates real-world
emergency scenarios, contributing to active participation and a deeper
understanding of potential hazards and especially for floods. The framework
highlights the importance of stakeholder participation in its development,
ensuring that training modules are customized to address the specific needs of
different user groups. The iterative approach of the framework supports ongoing
refinement through user feedback and performance data, thus improving the
overall effectiveness of risk training initiatives. This work outlines the
methodological phases involved in the framework's implementation, including i)
user flow mapping, ii) scenario selection, and iii) performance evaluation,
with a focus on the pilot application in Senigallia, Italy. The findings
underscore the potential of XR technologies to transform urban risk training,
promoting a culture of preparedness and resilience against urban hazards.

</details>


### [2] [How ChatGPT and Gemini View the Elements of Communication Competence of Large Language Models: A Pilot Study](https://arxiv.org/abs/2511.02838)
*Goran Bubas*

Main category: cs.HC

TL;DR: 本文回顾沟通能力理论模型，并通过案例研究分析先进AI对模型的理解。


<details>
  <summary>Details</summary>
Motivation: 探讨语言学、人际沟通、第二语言使用和人机交互领域的沟通能力理论模型。

Method: 通过两个案例研究，调查先进的AI工具如何解释两种沟通能力理论的元素。

Result: 研究发现，ChatGPT和Gemini能够在大语言模型互动中解释这些沟通能力理论。

Conclusion: 两种理论模型都适合于更好地理解LLM与用户的互动。

Abstract: A concise overview is provided of selected theoretical models of
communication competence in the fields of linguistics, interpersonal
communication, second language use, and human-robot interaction. The following
practical research consisted of two case studies with the goals of
investigating how advanced AI tools like ChatGPT and Gemini interpret elements
of two communication competence theories in the context of Large Language Model
(LLM) interactions with users. The focus was on these theoretical approaches:
(1) an integrated linguistic-interpersonal model and (2) an interpersonal
"human-humanoid" interaction model. The conclusion is that both approaches are
suitable for a better understanding of LLM-user interaction.

</details>


### [3] [Evaluating Generative AI as an Educational Tool for Radiology Resident Report Drafting](https://arxiv.org/abs/2511.02839)
*Antonio Verdone,Aidan Cardall,Fardeen Siddiqui,Motaz Nashawaty,Danielle Rigau,Youngjoon Kwon,Mira Yousef,Shalin Patel,Alex Kieturakis,Eric Kim,Laura Heacock,Beatriu Reig,Yiqiu Shen*

Main category: cs.HC

TL;DR: 本研究评估了GPT-4o系统在放射科住院医师乳腺影像报告中的反馈能力，结果表明GPT-4o能够有效识别教育错误，并被认为有教育价值。


<details>
  <summary>Details</summary>
Motivation: 放射科住院医师需要及时的个性化反馈，以提高图像分析和报告技能，但临床工作负荷增加限制了主治医师的指导能力。

Method: 分析来自多家美国医疗系统的5000对住院医师与主治医师的报告对，使用GPT-4o识别常见错误并提供反馈。

Result: 成功识别三种常见错误类型，且GPT-4o与主治医师的一致性较高，反馈被大部分案例评为有帮助。

Conclusion: ChatGPT-4o能够可靠地识别关键教育错误，可能成为支持放射科教育的可扩展工具。

Abstract: Objective: Radiology residents require timely, personalized feedback to
develop accurate image analysis and reporting skills. Increasing clinical
workload often limits attendings' ability to provide guidance. This study
evaluates a HIPAA-compliant GPT-4o system that delivers automated feedback on
breast imaging reports drafted by residents in real clinical settings.
  Methods: We analyzed 5,000 resident-attending report pairs from routine
practice at a multi-site U.S. health system. GPT-4o was prompted with clinical
instructions to identify common errors and provide feedback. A reader study
using 100 report pairs was conducted. Four attending radiologists and four
residents independently reviewed each pair, determined whether predefined error
types were present, and rated GPT-4o's feedback as helpful or not. Agreement
between GPT and readers was assessed using percent match. Inter-reader
reliability was measured with Krippendorff's alpha. Educational value was
measured as the proportion of cases rated helpful.
  Results: Three common error types were identified: (1) omission or addition
of key findings, (2) incorrect use or omission of technical descriptors, and
(3) final assessment inconsistent with findings. GPT-4o showed strong agreement
with attending consensus: 90.5%, 78.3%, and 90.4% across error types.
Inter-reader reliability showed moderate variability ({\alpha} = 0.767, 0.595,
0.567), and replacing a human reader with GPT-4o did not significantly affect
agreement ({\Delta} = -0.004 to 0.002). GPT's feedback was rated helpful in
most cases: 89.8%, 83.0%, and 92.0%.
  Discussion: ChatGPT-4o can reliably identify key educational errors. It may
serve as a scalable tool to support radiology education.

</details>


### [4] [Interview Survey on Attractivenesses of Place Re-creation Toward Developing a Virtual Twin Design Theory](https://arxiv.org/abs/2511.02840)
*Saizo Aoyagi*

Main category: cs.HC

TL;DR: 本研究通过访谈分析探讨现实世界地点再创造的吸引力，旨在建立虚拟双胞胎设计的理论框架。


<details>
  <summary>Details</summary>
Motivation: 揭示现实世界地点再创造的共同吸引力尚不清晰，研究旨在明确这种吸引力。

Method: 通过定性分析的访谈研究，探索地点再创造的吸引力及其结构。

Result: 基于对物理再创造和计算机生成再创造的实例分析，提出了相关理论框架。

Conclusion: 建立了一个理论框架，用于虚拟双胞胎的设计。

Abstract: It is often seen that real-world locations are re-created using models,
metaverse technology, or computer graphics. Although the surface-level purposes
of these re-creations vary, the author hypothesizes that there exists an
underlying common attractiveness that remains unclear. This research aims to
clarify the attractiveness and its structures of place re-creations through an
interview study with qualitative analysis. The interviews used examples of
physical re-creations, such as the model in Komazawa University's Zen Culture
History Museum and some dioramas of Tokyo, as well as computer-generated
re-creations of Shibuya using platforms like Minecraft and Project Plateau's 3D
city model. Using insights gained from this investigation, this study seeks to
establish a theoretical framework for designing virtual twins.

</details>


### [5] [Digital Transformation Chatbot (DTchatbot): Integrating Large Language Model-based Chatbot in Acquiring Digital Transformation Needs](https://arxiv.org/abs/2511.02842)
*Jiawei Zheng,Gokcen Yilmaz,Ji Han,Saeema Ahmed-Kristensen*

Main category: cs.HC

TL;DR: 本研究探讨了使用大型语言模型驱动的聊天机器人以满足组织数字化转型需求，评估其功能和实施效果。


<details>
  <summary>Details</summary>
Motivation: 为了提高组织的运营效率，减少人工工作和优化流程，通过全面了解其独特需求来实现数字化转型。

Method: 使用大型语言模型（LLM）驱动的聊天机器人进行用户访谈，结合工作流指导与LLM的规划和推理能力。

Result: 初步评估表明，聊天机器人能够有效地遵循预定义的工作流程，并支持用户互动，同时也指出了改进的空间。

Conclusion: 使用聊天机器人获取用户信息具有潜力和局限性。

Abstract: Many organisations pursue digital transformation to enhance operational
efficiency, reduce manual efforts, and optimise processes by automation and
digital tools. To achieve this, a comprehensive understanding of their unique
needs is required. However, traditional methods, such as expert interviews,
while effective, face several challenges, including scheduling conflicts,
resource constraints, inconsistency, etc. To tackle these issues, we
investigate the use of a Large Language Model (LLM)-powered chatbot to acquire
organisations' digital transformation needs. Specifically, the chatbot
integrates workflow-based instruction with LLM's planning and reasoning
capabilities, enabling it to function as a virtual expert and conduct
interviews. We detail the chatbot's features and its implementation. Our
preliminary evaluation indicates that the chatbot performs as designed,
effectively following predefined workflows and supporting user interactions
with areas for improvement. We conclude by discussing the implications of
employing chatbots to elicit user information, emphasizing their potential and
limitations.

</details>


### [6] [A Survey of Driver Distraction and Inattention in Popular Commercial Software-Defined Vehicles](https://arxiv.org/abs/2511.02891)
*Lingyu Zhao,Yuankai He*

Main category: cs.HC

TL;DR: 本论文研究汽车用户界面设计对驾驶分心的影响，指出现有设计未充分考虑驾驶员认知负担，并提供改进策略以提升行车安全。


<details>
  <summary>Details</summary>
Motivation: 随着汽车行业越来越多地采用软件定义车辆 (SDVs)，设计针对用户界面的 UI 设计在确保驾驶安全中的重要性逐渐凸显。

Method: 通过对流行商用车辆的调查，识别出潜在增加认知负担的 UI 特征，并评估相应的设计策略。

Result: 研究结果表明，当前许多商用车辆的 UI 实现未能充分考虑驾驶分心与注意力缺失 (DDI)，需要在高级软件功能与驾驶员认知人体工学之间找到平衡。

Conclusion: 本研究强调了 UI 设计在减少驾驶分心和注意力缺失中的重要性，并提供了设计策略以改善汽车用户界面，同时提高行车安全。

Abstract: As the automotive industry embraces software-defined vehicles (SDVs), the
role of user interface (UI) design in ensuring driver safety has become
increasingly significant. In crashes related to distracted driving, over 90%
did not involve cellphone use but were related to UI controls. However, many of
the existing UI SDV implementations do not consider Drive Distraction and
Inattention (DDI), which is reflected in many popular commercial vehicles. This
paper investigates the impact of UI designs on driver distraction and
inattention within the context of SDVs. Through a survey of popular commercial
vehicles, we identify UI features that potentially increase cognitive load and
evaluate design strategies to mitigate these risks. This survey highlights the
need for UI designs that balance advanced software functionalities with
driver-cognitive ergonomics. Findings aim to provide valuable guidance to
researchers and OEMs to contribute to the field of automotive UI, contributing
to the broader discussion on enhancing vehicular safety in the software-centric
automotive era.

</details>


### [7] [Systematizing LLM Persona Design: A Four-Quadrant Technical Taxonomy for AI Companion Applications](https://arxiv.org/abs/2511.02979)
*Esther Sun,Zichu Wu*

Main category: cs.HC

TL;DR: 本文提出了一种四象限技术分类法，以统一AI陪伴应用的设计与分析，涵盖虚拟与具身、情感与功能等多个维度。


<details>
  <summary>Details</summary>
Motivation: 基于大型语言模型的陪伴者设计和应用领域发展迅速，但存在严重的碎片化，急需统一框架。

Method: 通过分析不同类型的AI陪伴应用，建立起一个基于虚拟与具身、情感陪伴与功能增强的技术分类法。

Result: 提出了一个包括虚拟陪伴、功能虚拟助手和具身智能的四象限技术分类法，系统探讨了相关应用的挑战和技术需求。

Conclusion: 提出的四象限技术分类法为AI陪伴应用提供了系统性框架，并为政策制定者识别不同应用场景中的独特风险奠定了基础。

Abstract: The design and application of LLM-based personas in AI companionship is a
rapidly expanding but fragmented field, spanning from virtual emotional
companions and game NPCs to embodied functional robots. This diversity in
objectives, modality, and technical stacks creates an urgent need for a unified
framework. To address this gap, this paper systematizes the field by proposing
a Four-Quadrant Technical Taxonomy for AI companion applications. The framework
is structured along two critical axes: Virtual vs. Embodied and Emotional
Companionship vs. Functional Augmentation. Quadrant I (Virtual Companionship)
explores virtual idols, romantic companions, and story characters, introducing
a four-layer technical framework to analyze their challenges in maintaining
long-term emotional consistency. Quadrant II (Functional Virtual Assistants)
analyzes AI applications in work, gaming, and mental health, highlighting the
shift from "feeling" to "thinking and acting" and pinpointing key technologies
like enterprise RAG and on-device inference. Quadrants III & IV (Embodied
Intelligence) shift from the virtual to the physical world, analyzing home
robots and vertical-domain assistants, revealing core challenges in symbol
grounding, data privacy, and ethical liability. This taxonomy provides not only
a systematic map for researchers and developers to navigate the complex persona
design space but also a basis for policymakers to identify and address the
unique risks inherent in different application scenarios.

</details>


### [8] [Tracing Generative AI in Digital Art: A Longitudinal Study of Chinese Painters' Attitudes, Practices, and Identity Negotiation](https://arxiv.org/abs/2511.03117)
*Yibo Meng,Ruiqi Chen,Xin Chen,Zhiming Liu,Yan Guan*

Main category: cs.HC

TL;DR: 本研究探讨中国数字画家在生成性人工智能影响下的态度变化，强调身份与价值的协商过程，为未来人机协作系统的设计提供启示。


<details>
  <summary>Details</summary>
Motivation: 研究数字艺术家如何在生成性人工智能的影响下，调整他们的创作态度和实践。

Method: 进行了为期五年的纵向混合方法研究，参与者为17位中国数字艺术家。

Result: 研究发现，艺术家的态度由抵抗和防御转向务实采纳，并最终实现反思重构，同时揭示了版权和创作劳动的持久关注。

Conclusion: 本研究提供了对中国数字画家在面对生成性人工智能的态度与实践演变的深入理解，强调身份与价值的持续协商。

Abstract: This study presents a five-year longitudinal mixed-methods study of 17
Chinese digital painters, examining how their attitudes and practices evolved
in response to generative AI. Our findings reveal a trajectory from resistance
and defensiveness, to pragmatic adoption, and ultimately to reflective
reconstruction, shaped by strong peer pressures and shifting emotional
experiences. Persistent concerns around copyright and creative labor highlight
the ongoing negotiation of identity and values. This work contributes by
offering rare longitudinal empirical data, advancing a theoretical lens of
"identity and value negotiation," and providing design implications for future
human-AI collaborative systems.

</details>


### [9] [Ceci N'est Pas un Drone: Investigating the Impact of Design Representation on Design Decision Making When Using GenAI](https://arxiv.org/abs/2511.03131)
*Zeda Xu,Nikolas Martelaro,Christopher McComb*

Main category: cs.HC

TL;DR: 本研究探讨不同设计表现形式对设计师选择AI生成设计方案的影响，发现数值性能数据能最佳引导选择最佳设计。


<details>
  <summary>Details</summary>
Motivation: 随着生成性AI设计工具的发展，设计师需要有效选择较少的设计方案以进行进一步开发。

Method: 研究不同设计表现形式如何影响设计师从AI生成的设计概念中进行选择。

Result: 研究发现不同的设计表现形式影响设计师的选择，提供单一的数值设计性能数据时能更好地选出最佳设计，同时参与者更倾向于视觉上传统且对称的设计。

Conclusion: 不同的设计表现形式会影响设计师的选择，而提供仅有的数值设计性能数据能有效帮助选择最佳设计。

Abstract: With generative AI-powered design tools, designers and engineers can
efficiently generate large numbers of design ideas. However, efficient
exploration of these ideas requires designers to select a smaller group of
potential solutions for further development. Therefore, the ability to judge
and evaluate designs is critical for the successful use of generative design
tools. Different design representation modalities can potentially affect
designers' judgments. This work investigates how different design modalities,
including visual rendering, numerical performance data, and a combination of
both, affect designers' design selections from AI-generated design concepts for
Uncrewed Aerial Vehicles. We found that different design modalities do affect
designers' choices. Unexpectedly, we found that providing only numerical design
performance data can lead to the best ability to select optimal designs. We
also found that participants prefer visually conventional designs with
axis-symmetry. The findings of this work provide insights into the interaction
between human users and generative design systems.

</details>


### [10] [From Measurement to Expertise: Empathetic Expert Adapters for Context-Based Empathy in Conversational AI Agents](https://arxiv.org/abs/2511.03143)
*Erfan Shayegani,Jina Suh,Andy Wilson,Nagu Rangan,Javier Hernandez*

Main category: cs.HC

TL;DR: 本研究提出一种新的框架，通过分析对话数据集和开发上下文特定适配器，提高了对话AI中的同理心表现，减少了用户期望与实际体验的差距。


<details>
  <summary>Details</summary>
Motivation: 提高对话AI中同理心的水平，使其更符合用户在不同任务和情境下的期望。

Method: 分析真实世界中的对话数据集，开发合成多轮对话生成管道，并训练上下文特定的同理心专家适配器。

Result: 在用户期望的同理心与实际体验之间，减少了72.66%的差距，平均得分提高了2.43倍，此外，专家适配器在长对话中维持同理心模式的效果优于系统提示。

Conclusion: 通过引入上下文特定的同理心大型语言模型，该研究成功减少了用户期望和体验之间的差距，并在多轮对话中保持了同理心模式。

Abstract: Empathy is a critical factor in fostering positive user experiences in
conversational AI. While models can display empathy, it is often generic rather
than tailored to specific tasks and contexts. In this work, we introduce a
novel framework for developing and evaluating context-specific empathetic large
language models (LLMs). We first analyze a real-world conversational dataset
consisting of 672 multi-turn conversations across 8 tasks, revealing
significant differences in terms of expected and experienced empathy before and
after the conversations, respectively. To help minimize this gap, we develop a
synthetic multi-turn conversational generation pipeline and steer responses
toward our defined empathy patterns based on the context that more closely
matches users' expectations. We then train empathetic expert adapters for
context-specific empathy that specialize in varying empathy levels based on the
recognized task. Our empirical results demonstrate a significant gap reduction
of 72.66% between perceived and desired empathy with scores increasing by an
average factor of 2.43 as measured by our metrics and reward models.
Additionally, our trained empathetic expert adapters demonstrate superior
effectiveness in preserving empathy patterns throughout conversation turns,
outperforming system prompts, which tend to dramatically diminish in impact as
conversations lengthen.

</details>


### [11] [AI as We Describe It: How Large Language Models and Their Applications in Health are Represented Across Channels of Public Discourse](https://arxiv.org/abs/2511.03174)
*Jiawei Zhou,Lei Zhang,Mei Li,Benjamin D Horne,Munmun De Choudhury*

Main category: cs.HC

TL;DR: 该研究分析了五个话语渠道对大语言模型的描述，发现公众讨论总体较积极，但对风险的关注不足，强调需要改进沟通策略以促进知情参与。


<details>
  <summary>Details</summary>
Motivation: 分析当前叙述是否呈现出对大语言模型（LLM）在高风险领域（如健康）中的作用的平衡视角，以应对其快速 adoption。

Method: 分析了五个主要话语渠道（新闻、研究新闻、YouTube、TikTok和Reddit）在两年期间的词汇风格、信息内容和象征性表现。

Result: 讨论整体积极且偶发，积极性随时间增加，但风险交流不彻底，且对LLM生成特性的解释较少。TikTok和Reddit相比专业渠道更多关注幸福应用，但对风险关注较少。

Conclusion: 公众话语在识别素养和治理差距方面具有诊断功能，并为支持更知情的LLM参与提供了交流与设计策略。

Abstract: Representation shapes public attitudes and behaviors. With the arrival and
rapid adoption of LLMs, the way these systems are introduced will negotiate
societal expectations for their role in high-stakes domains like health. Yet it
remains unclear whether current narratives present a balanced view. We analyzed
five prominent discourse channels (news, research press, YouTube, TikTok, and
Reddit) over a two-year period on lexical style, informational content, and
symbolic representation. Discussions were generally positive and episodic, with
positivity increasing over time. Risk communication was unthorough and often
reduced to information quality incidents, while explanations of LLMs'
generative nature were rare. Compared with professional outlets, TikTok and
Reddit highlighted wellbeing applications and showed greater variations in tone
and anthropomorphism but little attention to risks. We discuss implications for
public discourse as a diagnostic tool in identifying literacy and governance
gaps, and for communication and design strategies to support more informed LLM
engagement.

</details>


### [12] [Large Language Models as Information Sources: Distinctive Characteristics and Types of Low-Quality Information](https://arxiv.org/abs/2511.03198)
*Jiawei Zhou,Amy Z. Chen,Darshi Shah,Laura M. Schwab-Reese,Munmun De Choudhury*

Main category: cs.HC

TL;DR: 本研究探讨了大语言模型生成的低质量信息种类及其特征，提出了研究未来信息质量的概念和方法论框架。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型(LLM)的发展，其生成低质量信息的潜力备受关注，但低质量信息的具体表现及其与传统信息源的区别尚不清楚。

Method: 通过与公共卫生专业人员和具有相关经历的个体进行焦点小组讨论，研究在疫苗、阿片类药物使用障碍和伴侣暴力等关键健康背景下LLM生成的信息。

Result: 研究识别了LLM生成的低质量信息类型，包括错误优先级和夸大等，并揭示了LLM与传统信息源的明显区别。

Conclusion: 该研究提供了LLM生成低质量信息的类型学及其独特特征，为未来理解和减轻信息危害奠定基础。

Abstract: Recent advances in large language models (LLMs) have brought public and
scholarly attention to their potential in generating low-quality information.
While widely acknowledged as a risk, low-quality information remains a vaguely
defined concept, and little is known about how it manifests in LLM outputs or
how these outputs differ from those of traditional information sources. In this
study, we focus on two key questions: What types of low-quality information are
produced by LLMs, and what makes them distinct than human-generated
counterparts? We conducted focus groups with public health professionals and
individuals with lived experience in three critical health contexts (vaccines,
opioid use disorder, and intimate partner violence) where high-quality
information is essential and misinformation, bias, and insensitivity are
prevalent concerns. We identified a typology of LLM-generated low-quality
information and a set of distinctive LLM characteristics compared to
traditional information sources. Our findings show that low-quality information
extends beyond factual inaccuracies into types such as misprioritization and
exaggeration, and that LLM affordances fundamentally differs from previous
technologies. This work offers typologies on LLM distinctive characteristics
and low-quality information types as a starting point for future efforts to
understand LLM-generated low-quality information and mitigate related
informational harms. We call for conceptual and methodological discussions of
information quality to move beyond truthfulness, in order to address the
affordances of emerging technologies and the evolving dynamics of information
behaviors.

</details>


### [13] [Node-Based Editing for Multimodal Generation of Text, Audio, Image, and Vide](https://arxiv.org/abs/2511.03227)
*Alexander Htet Kyaw,Lenin Ravindranath Sivalingam*

Main category: cs.HC

TL;DR: 提出了一种节点基础的故事生成系统，支持多模态内容的编辑与生成，但存在扩展性和一致性问题，未来计划探讨人机协作的创意AI工具。


<details>
  <summary>Details</summary>
Motivation: 设计一个能够支持创作者通过多模态方式讲述故事的系统，以提升故事创作的灵活性和控制能力。

Method: 通过节点图形化表示故事，用户可以直接编辑和使用自然语言提示进行交互，系统内置任务选择代理，处理各种生成任务。

Result: 展示了节点编辑能有效控制叙事结构，并在量化和质性方面给出故事大纲生成和编辑工作流的结果。

Conclusion: 该节点基础的故事讲述系统为多模态内容生成提供了控制权，并展现了文本、图像、音频和视频的迭代生成能力。

Abstract: We present a node-based storytelling system for multimodal content
generation. The system represents stories as graphs of nodes that can be
expanded, edited, and iteratively refined through direct user edits and
natural-language prompts. Each node can integrate text, images, audio, and
video, allowing creators to compose multimodal narratives. A task selection
agent routes between specialized generative tasks that handle story generation,
node structure reasoning, node diagram formatting, and context generation. The
interface supports targeted editing of individual nodes, automatic branching
for parallel storylines, and node-based iterative refinement. Our results
demonstrate that node-based editing supports control over narrative structure
and iterative generation of text, images, audio, and video. We report
quantitative outcomes on automatic story outline generation and qualitative
observations of editing workflows. Finally, we discuss current limitations such
as scalability to longer narratives and consistency across multiple nodes, and
outline future work toward human-in-the-loop and user-centered creative AI
tools.

</details>


### [14] [When Generative Artificial Intelligence meets Extended Reality: A Systematic Review](https://arxiv.org/abs/2511.03282)
*Xinyu Ning,Yan Zhuo,Xian Wang,Chan-In Devin Sio,Lik-Hang Lee*

Main category: cs.HC

TL;DR: 本调研文章系统性回顾了生成性人工智能在扩展现实中的应用，突出关键技术和未来研究机会。


<details>
  <summary>Details</summary>
Motivation: 随着技术的不断进步，生成性人工智能与扩展现实结合，创造了前所未有的可能性。

Method: 通过PRISMA筛选和分析最后26篇文章，总结了生成性AI在XR中的关键技术实现和应用领域。

Result: 调研总结了2023至2025年生成性AI在XR中的应用领域及其技术实现，指出了当前趋势和研究空白。

Conclusion: 研究指出生成性人工智能在扩展现实中的应用潜力巨大，并为未来研究提供了指导和信息。

Abstract: With the continuous advancement of technology, the application of generative
artificial intelligence (AI) in various fields is gradually demonstrating great
potential, particularly when combined with Extended Reality (XR), creating
unprecedented possibilities. This survey article systematically reviews the
applications of generative AI in XR, covering as much relevant literature as
possible from 2023 to 2025. The application areas of generative AI in XR and
its key technology implementations are summarised through PRISMA screening and
analysis of the final 26 articles. The survey highlights existing articles from
the last three years related to how XR utilises generative AI, providing
insights into current trends and research gaps. We also explore potential
opportunities for future research to further empower XR through generative AI,
providing guidance and information for future generative XR research.

</details>


### [15] [I Prompt, it Generates, we Negotiate. Exploring Text-Image Intertextuality in Human-AI Co-Creation of Visual Narratives with VLMs](https://arxiv.org/abs/2511.03375)
*Mengyao Guo,Kexin Nie,Ze Gao,Black Sun,Xueyang Wang,Jinda Han,Xingting Wu*

Main category: cs.HC

TL;DR: 本研究探讨了人机合作中文本-图像互文性的形成过程，揭示用户如何利用AI产生有意义的视觉叙事，并总结出成功合作的路径及面临的挑战。


<details>
  <summary>Details</summary>
Motivation: 探索文本-图像互文性如何在文本意图和AI生成视觉内容交互中出现，以促进富有意义的视觉叙事的创造。

Method: 通过对15名参与者进行三阶段的定性研究，使用GPT-4o探讨新手如何在顺序视觉叙事中导航。

Result: 用户通过识别超越字面描述的有意义视觉内容、反复完善提示以及通过互补的文本-图像关系构建叙事意义，发展了利用AI语义盈余的策略。研究识别出四种不同的协作模式，并发现成功的互文协作有三个路径：教育合作者、技术专家和视觉思维者。

Conclusion: 该研究为人机协作中文本-图像互文性的经验性理解提供了新颖视角，并提出了改进AI助手设计的建议，以更好地支持人类主导的创作过程。

Abstract: Creating meaningful visual narratives through human-AI collaboration requires
understanding how text-image intertextuality emerges when textual intentions
meet AI-generated visuals. We conducted a three-phase qualitative study with 15
participants using GPT-4o to investigate how novices navigate sequential visual
narratives. Our findings show that users develop strategies to harness AI's
semantic surplus by recognizing meaningful visual content beyond literal
descriptions, iteratively refining prompts, and constructing narrative
significance through complementary text-image relationships. We identified four
distinct collaboration patterns and, through fsQCA's analysis, discovered three
pathways to successful intertextual collaboration: Educational Collaborator,
Technical Expert, and Visual Thinker. However, participants faced challenges,
including cultural representation gaps, visual consistency issues, and
difficulties translating narrative concepts into visual prompts. These findings
contribute to HCI research by providing an empirical account of
\textit{text-image intertextuality} in human-AI co-creation and proposing
design implications for role-based AI assistants that better support iterative,
human-led creative processes in visual storytelling.

</details>


### [16] [Inter-Agent Trust Models: A Comparative Study of Brief, Claim, Proof, Stake, Reputation and Constraint in Agentic Web Protocol Design-A2A, AP2, ERC-8004, and Beyond](https://arxiv.org/abs/2511.03434)
*Botao 'Amber' Hu,Helena Rong*

Main category: cs.HC

TL;DR: 本文研究了多种代理协议的信任模型，分析了它们的假设和脆弱性，提出了混合信任模型以改善代理经济的安全性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 随着AI代理的崛起，信任从人类监督转向协议设计，而现有的信任机制尚未得到充分研究，特别是LLM特有的脆弱性和风险。

Method: 本文通过比较研究不同的信任模型，分析了它们在代理协议设计中的假设、攻击面和设计权衡。

Result: 研究发现没有单一的机制可以满足需求，建议以Proof和Stake为基础的无信任架构，并结合Brief和Reputation以增强灵活性和社交信号。

Conclusion: 本研究提出了混合信任模型的建议，以减轻信誉游戏和误导性LLM行为，并为安全、可互操作且可扩展的代理经济制定了可行的设计指南。

Abstract: As the "agentic web" takes shape-billions of AI agents (often LLM-powered)
autonomously transacting and collaborating-trust shifts from human oversight to
protocol design. In 2025, several inter-agent protocols crystallized this
shift, including Google's Agent-to-Agent (A2A), Agent Payments Protocol (AP2),
and Ethereum's ERC-8004 "Trustless Agents," yet their underlying trust
assumptions remain under-examined. This paper presents a comparative study of
trust models in inter-agent protocol design: Brief (self- or third-party
verifiable claims), Claim (self-proclaimed capabilities and identity, e.g.
AgentCard), Proof (cryptographic verification, including zero-knowledge proofs
and trusted execution environment attestations), Stake (bonded collateral with
slashing and insurance), Reputation (crowd feedback and graph-based trust
signals), and Constraint (sandboxing and capability bounding). For each, we
analyze assumptions, attack surfaces, and design trade-offs, with particular
emphasis on LLM-specific fragilities-prompt injection,
sycophancy/nudge-susceptibility, hallucination, deception, and
misalignment-that render purely reputational or claim-only approaches brittle.
Our findings indicate no single mechanism suffices. We argue for
trustless-by-default architectures anchored in Proof and Stake to gate
high-impact actions, augmented by Brief for identity and discovery and
Reputation overlays for flexibility and social signals. We comparatively
evaluate A2A, AP2, ERC-8004 and related historical variations in academic
research under metrics spanning security, privacy, latency/cost, and social
robustness (Sybil/collusion/whitewashing resistance). We conclude with hybrid
trust model recommendations that mitigate reputation gaming and misinformed LLM
behavior, and we distill actionable design guidelines for safer, interoperable,
and scalable agent economies.

</details>


### [17] [SVG Decomposition for Enhancing Large Multimodal Models Visualization Comprehension: A Study with Floor Plans](https://arxiv.org/abs/2511.03478)
*Jeongah Lee,Ali Sarvghad*

Main category: cs.HC

TL;DR: 本研究探讨了使用可扩展矢量图形（SVG）作为分解策略来改善大型多模态模型在理解楼层平面中的表现，显示了SVG的潜力与局限性。


<details>
  <summary>Details</summary>
Motivation: 大型多模态模型在解释可视化方面的能力越来越强，但在空间推理方面仍然存在困难，因此需要探索新的策略以提升其理解能力。

Method: 通过对75个平面图进行探索性研究，评估三种大型多模态模型（GPT-4o、Claude 3.7 Sonnet和Llama 3.2 11B Vision Instruct）在理解楼层平面方面的性能。

Result: 研究结果表明，SVG与光栅输入的结合有助于提高空间理解任务的表现，但在某些情况下却会妨碍空间推理能力。

Conclusion: 结合SVG与光栅输入(SVG+PNG)可以提高空间理解任务的表现，但在路径寻找等空间推理任务中却可能受到 hinder。

Abstract: Large multimodal models (LMMs) are increasingly capable of interpreting
visualizations, yet they continue to struggle with spatial reasoning. One
proposed strategy is decomposition, which breaks down complex visualizations
into structured components. In this work, we examine the efficacy of scalable
vector graphics (SVGs) as a decomposition strategy for improving LMMs'
performance on floor plans comprehension. Floor plans serve as a valuable
testbed because they combine geometry, topology, and semantics, and their
reliable comprehension has real-world applications, such as accessibility for
blind and low-vision individuals. We conducted an exploratory study with three
LMMs (GPT-4o, Claude 3.7 Sonnet, and Llama 3.2 11B Vision Instruct) across 75
floor plans. Results show that combining SVG with raster input (SVG+PNG)
improves performance on spatial understanding tasks but often hinders spatial
reasoning, particularly in pathfinding. These findings highlight both the
promise and limitations of decomposition as a strategy for advancing spatial
visualization comprehension.

</details>


### [18] [PnPSelect: Plug-and-play IoT Device Selection Using Ultra-wideband Signals](https://arxiv.org/abs/2511.03534)
*Zhaoxin Chang,Fusang Zhang,Jie Xiong,Ziyu Li,Badii Jouaber,Daqing Zhang*

Main category: cs.HC

TL;DR: PnPSelect是一种基于超宽带技术的即插即用物联网设备选择解决方案，提升了用户选取设备的效率和直观性，且具有高精度和适应性。


<details>
  <summary>Details</summary>
Motivation: 随着智能家居中物联网设备数量的快速增长，用户选择控制设备的效率和直观性面临挑战。

Method: 利用超宽带技术开发了一种轻量级设备定位方法，并引入指向方向估计方法。

Result: PnPSelect在商业智能手机和智能手表上实现，并在受控实验室和真实环境中进行了广泛评估，展现出高准确性和适应性。

Conclusion: PnPSelect为下一代智能家居交互提供了一个实际可行且可扩展的解决方案，具备高精度、鲁棒性和适应性。

Abstract: In recent years, the number of Internet of Things (IoT) devices in smart
homes has rapidly increased. A key challenge affecting user experience is how
to enable users to efficiently and intuitively select the devices they wish to
control. This paper proposes PnPSelect, a plug-and-play IoT device selection
solution utilizing Ultra-wideband (UWB) technology on commercial devices.
Unlike previous works, PnPSelect does not require the installation of dedicated
hardware on each IoT device, thereby reducing deployment costs and
complexities, and achieving true plug-and-play functionality. To enable
intuitive device selection, we introduce a pointing direction estimation method
that utilizes UWB readings from a single anchor to infer the user pointing
direction. Additionally, we propose a lightweight device localization method
that allows users to register new IoT devices by simply pointing at them from
two distinct positions, eliminating the need for manual measurements. We
implement PnPSelect on commercial smartphones and smartwatches and conduct
extensive evaluations in both controlled laboratory settings and real-world
environments. Our results demonstrate high accuracy, robustness, and
adaptability, making PnPSelect a practical and scalable solution for
next-generation smart home interactions.

</details>


### [19] [Knowledge Graph for Intelligent Generation of Artistic Image Creation: Constructing a New Annotation Hierarchy](https://arxiv.org/abs/2511.03585)
*Jia Kaixin,Zhu Kewen,Deng Huanghuang,Qiu Yiwu,Ding Shiying,Ding Chenyang,Li Zejian*

Main category: cs.HC

TL;DR: 本研究建立了一个系统化的艺术图像知识图谱，以解决标注中的模糊性和不一致性问题，并为AI艺术生成提供了基础。


<details>
  <summary>Details</summary>
Motivation: 旨在解决艺术图像数据集标注中存在的模糊定义和不一致结果问题，缺乏统一标准导致的挑战。

Method: 构建了一个层次化、系统化的艺术图像知识图谱，基于艺术图像的构成原理，结合了中国文化视角和东西方艺术理论的深入复习与比较。

Result: 成功构建了一个艺术图像的知识图谱，清晰地将定性艺术概念转化为有结构的框架，并保证了标注数据的高质量和一致性。

Conclusion: 该知识图谱为艺术图像数据集的标注提供了系统化的参考框架，提升了数据标注的一致性和质量，同时为人工智能艺术生成和跨文化艺术分析提供了可解释的视觉知识基础。

Abstract: Our study aims to establish a unified, systematic, and referable knowledge
framework for the annotation of art image datasets, addressing issues of
ambiguous definitions and inconsistent results caused by the lack of common
standards during the annotation process. To achieve this goal, a hierarchical
and systematic art image knowledge graph was constructed. It was developed
based on the composition principles of art images, incorporating the Structured
Theory of Visual Knowledge proposed by Academician Yunhe Pan in On Visual
Knowledge-which states that visual knowledge must achieve precise expression of
spatial forms and dynamic relationships through "prototype-category" and
"hierarchical structure". Through in-depth review of Chinese and Western art
theories and pioneering integration of the Chinese cultural perspective, this
graph took shape. The core visual language of art images was deconstructed by
this knowledge graph. Meanwhile, the unique spatial theory and symbolic system
of Chinese painting were compared with and supplemented by Western art
theories. This graph converts qualitative artistic concepts into a clear
structured framework. It not only conforms to the cognitive law that "visual
knowledge takes precedence over verbal knowledge" in humans but also provides
an interpretable and inferential visual knowledge foundation for AI art
generation and cross-cultural art analysis. It ensures the high quality and
consistency of annotated data, thus offering key support for art intelligence
research in the AI 2.0 era.

</details>


### [20] [OriFeel: Origami-Inspired Actuation for Force-Based Tactile Feedback on Ambient Surfaces](https://arxiv.org/abs/2511.03673)
*Shubham Rohal,Shijia Pan*

Main category: cs.HC

TL;DR: 该论文提出了一种基于Miura-Ori折叠结构的触觉反馈机制，具有紧凑的设计和良好的用户识别能力。


<details>
  <summary>Details</summary>
Motivation: 当前形变表面技术难以应用于日常环境，因其体积庞大或功耗高，迫切需要更灵活且易于集成的解决方案。

Method: 通过Miura-Ori折叠结构实现的触觉反馈机制，使用伺服电机和电缆驱动。

Result: 开发了一个可折叠的触觉反馈机制，并通过原型和用户研究验证其有效性。

Conclusion: 用户能够有效区分多种强度水平，表明该触觉反馈机制具有实用性。

Abstract: People are constantly in touch with surfaces in their lives, such as a sofa,
armrest, and table, making them natural tactile interfaces. Despite the recent
advancements in shape-changing surfaces, current available solutions are often
challenging to retrofit into ambient surfaces due to their bulky form factor or
high power requirements. We present \name, a foldable structure-enabled tactile
feedback mechanism that leverages the structural properties of Miura-Ori fold
to enable on-surface force actuation. The foldable structure allows the
surfaces to provide perpendicular force via lateral actuation, resulting in a
slim form factor that can be actuated via cable-based design using a servo
motor. We evaluate the system with a real-world prototype and a user study. The
user study shows that users can effectively distinguish multiple intensity
levels.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [21] [Toward an Agricultural Operational Design Domain: A Framework](https://arxiv.org/abs/2511.02937)
*Mirco Felske,Jannik Redenius,Georg Happich,Julius Schöning*

Main category: cs.RO

TL;DR: 本文提出农业ODD框架（Ag-ODD），用于描述和验证自主农业系统的操作边界，提升环境描述的标准化和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 当前的操作设计域（ODD）概念未能满足农业应用的独特挑战，需要一个有结构的、透明的环境描述。

Method: Ag-ODD框架由Ag-ODD描述概念、7层模型和迭代验证过程三部分组成。

Result: 通过Ag-ODD框架的演示用例，展示了该框架如何支持自主农业系统环境描述的标准化与可扩展性。

Conclusion: Ag-ODD框架为自主农业系统的操作边界描述与验证提供了一种一致的方法，支持环境描述的标准化与可扩展性。

Abstract: The agricultural sector increasingly relies on autonomous systems that
operate in complex and variable environments. Unlike on-road applications,
agricultural automation integrates driving and working processes, each of which
imposes distinct operational constraints. Handling this complexity and ensuring
consistency throughout the development and validation processes requires a
structured, transparent, and verified description of the environment. However,
existing Operational Design Domain (ODD) concepts do not yet address the unique
challenges of agricultural applications.
  Therefore, this work introduces the Agricultural ODD (Ag-ODD) Framework,
which can be used to describe and verify the operational boundaries of
autonomous agricultural systems. The Ag-ODD Framework consists of three core
elements. First, the Ag-ODD description concept, which provides a structured
method for unambiguously defining environmental and operational parameters
using concepts from ASAM Open ODD and CityGML. Second, the 7-Layer Model
derived from the PEGASUS 6-Layer Model, has been extended to include a process
layer to capture dynamic agricultural operations. Third, the iterative
verification process verifies the Ag-ODD against its corresponding logical
scenarios, derived from the 7-Layer Model, to ensure the Ag-ODD's completeness
and consistency.
  Together, these elements provide a consistent approach for creating
unambiguous and verifiable Ag-ODD. Demonstrative use cases show how the Ag-ODD
Framework can support the standardization and scalability of environmental
descriptions for autonomous agricultural systems.

</details>


### [22] [Comprehensive Assessment of LiDAR Evaluation Metrics: A Comparative Study Using Simulated and Real Data](https://arxiv.org/abs/2511.02994)
*Syed Mostaquim Ali,Taufiq Rahman,Ghazal Farhani,Mohamed H. Zaki,Benoit Anctil,Dominique Charlebois*

Main category: cs.RO

TL;DR: 本研究探索了比较真实和模拟LiDAR扫描的评估指标，发现密度感知的Chamfer距离表现最好，并指出模拟和真实LiDAR扫描在模型输出上存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 由于全面的传统物理测试在成本和安全方面的限制，开发安全的自主驾驶系统需要寻找有效的虚拟测试方法。

Method: 通过对真实LiDAR扫描数据进行虚拟测试环境的搭建，比较了真实与模拟LiDAR扫描的多个评估指标，评估其灵敏度和准确性。

Result: 在模拟和真实LiDAR扫描的比较中，发现密度感知的Chamfer距离（DCD）在所有测试案例中表现最好；实际和模拟LiDAR扫描在模型感知和几何相似性上有相似的语义分割输出。

Conclusion: 不同的测量指标在真实和模拟LiDAR扫描的比较中表现不同，其中密度感知的Chamfer距离是最为相关的指标，表明在具体的语义分割输出和几何相似性上，模拟和真实LiDAR扫描具有一定一致性。

Abstract: For developing safe Autonomous Driving Systems (ADS), rigorous testing is
required before they are deemed safe for road deployments. Since comprehensive
conventional physical testing is impractical due to cost and safety concerns,
Virtual Testing Environments (VTE) can be adopted as an alternative. Comparing
VTE-generated sensor outputs against their real-world analogues can be a strong
indication that the VTE accurately represents reality. Correspondingly, this
work explores a comprehensive experimental approach to finding evaluation
metrics suitable for comparing real-world and simulated LiDAR scans. The
metrics were tested in terms of sensitivity and accuracy with different noise,
density, distortion, sensor orientation, and channel settings. From comparing
the metrics, we found that Density Aware Chamfer Distance (DCD) works best
across all cases. In the second step of the research, a Virtual Testing
Environment was generated using real LiDAR scan data. The data was collected in
a controlled environment with only static objects using an instrumented vehicle
equipped with LiDAR, IMU and cameras. Simulated LiDAR scans were generated from
the VTEs using the same pose as real LiDAR scans. The simulated and LiDAR scans
were compared in terms of model perception and geometric similarity. Actual and
simulated LiDAR scans have a similar semantic segmentation output with a mIoU
of 21\% with corrected intensity and an average density aware chamfer distance
(DCD) of 0.63. This indicates a slight difference in the geometric properties
of simulated and real LiDAR scans and a significant difference between model
outputs. During the comparison, density-aware chamfer distance was found to be
the most correlated among the metrics with perception methods.

</details>


### [23] [A Collaborative Reasoning Framework for Anomaly Diagnostics in Underwater Robotics](https://arxiv.org/abs/2511.03075)
*Markus Buchholz,Ignacio Carlucho,Yvan R. Petillot*

Main category: cs.RO

TL;DR: AURA框架结合了AI与人类专家，提升机器人系统在异常情况下的响应能力，建立了一个动态反馈机制以优化AI的表现。


<details>
  <summary>Details</summary>
Motivation: 在安全关键环境中，自动系统的安全部署需要将人类专业知识与AI分析相结合，特别是在面对未预见异常的情况下。

Method: 引入AURA框架，该框架结合了大语言模型、数字双胞胎和人机交互，用于机器人领域的异常检测和故障诊断。

Result: AURA框架使用低级状态异常表征代理和高级诊断推理代理，实现实时监控和故障根本原因识别，从而建立了可信赖且不断改进的人机团队。

Conclusion: 该框架通过将人类验证的诊断转化为训练数据，逐渐优化了低级感知模型，使得AI在实际应用中变得更加适应和可靠。

Abstract: The safe deployment of autonomous systems in safety-critical settings
requires a paradigm that combines human expertise with AI-driven analysis,
especially when anomalies are unforeseen. We introduce AURA (Autonomous
Resilience Agent), a collaborative framework for anomaly and fault diagnostics
in robotics. AURA integrates large language models (LLMs), a high-fidelity
digital twin (DT), and human-in-the-loop interaction to detect and respond to
anomalous behavior in real time. The architecture uses two agents with clear
roles: (i) a low-level State Anomaly Characterization Agent that monitors
telemetry and converts signals into a structured natural-language problem
description, and (ii) a high-level Diagnostic Reasoning Agent that conducts a
knowledge-grounded dialogue with an operator to identify root causes, drawing
on external sources. Human-validated diagnoses are then converted into new
training examples that refine the low-level perceptual model. This feedback
loop progressively distills expert knowledge into the AI, transforming it from
a static tool into an adaptive partner. We describe the framework's operating
principles and provide a concrete implementation, establishing a pattern for
trustworthy, continually improving human-robot teams.

</details>


### [24] [WorldPlanner: Monte Carlo Tree Search and MPC with Action-Conditioned Visual World Models](https://arxiv.org/abs/2511.03077)
*R. Khorrambakht,Joaquim Ortiz-Haro,Joseph Amigo,Omar Mostafa,Daniel Dugas,Franziska Meier,Ludovic Righetti*

Main category: cs.RO

TL;DR: 本研究提出了一种基于模型的方法，通过采集游戏数据和规划，提高了机器人在复杂任务中的表现，优于传统的行为克隆。


<details>
  <summary>Details</summary>
Motivation: 为了克服行为克隆方法在新任务转移和数据生成方面的挑战，提出了一种基于模型的方法，利用简单易收集的游戏数据。

Method: 我们通过收集少量未结构化的游戏数据，学习了一个基于动作的视觉世界模型、扩散动作采样器和可选的奖励模型。然后，结合这些组件，通过蒙特卡洛树搜索规划器优化长序列动作。

Result: 在三个不同复杂度的真实机器人任务中验证了我们的方法，发现我们的行动采样器能够减轻世界模型在规划过程中的错误推断。

Conclusion: 我们的方法通过规划显著提高了机器人的任务表现，优于行为克隆的基线。

Abstract: Robots must understand their environment from raw sensory inputs and reason
about the consequences of their actions in it to solve complex tasks. Behavior
Cloning (BC) leverages task-specific human demonstrations to learn this
knowledge as end-to-end policies. However, these policies are difficult to
transfer to new tasks, and generating training data is challenging because it
requires careful demonstrations and frequent environment resets. In contrast to
such policy-based view, in this paper we take a model-based approach where we
collect a few hours of unstructured easy-to-collect play data to learn an
action-conditioned visual world model, a diffusion-based action sampler, and
optionally a reward model. The world model -- in combination with the action
sampler and a reward model -- is then used to optimize long sequences of
actions with a Monte Carlo Tree Search (MCTS) planner. The resulting plans are
executed on the robot via a zeroth-order Model Predictive Controller (MPC). We
show that the action sampler mitigates hallucinations of the world model during
planning and validate our approach on 3 real-world robotic tasks with varying
levels of planning and modeling complexity. Our experiments support the
hypothesis that planning leads to a significant improvement over BC baselines
on a standard manipulation test environment.

</details>


### [25] [3D Cal: An Open-Source Software Library for Calibrating Tactile Sensors](https://arxiv.org/abs/2511.03078)
*Rohan Kota,Kaival Shah,J. Edward Colgate,Gregory Reardon*

Main category: cs.RO

TL;DR: 
本文提出	extbackslash libname{}，一个开源库，利用自动探测设备生成大量数据，以简化和加速触觉传感器的校准过程，增强机器人的触觉感知能力。


<details>
  <summary>Details</summary>
Motivation: 
触觉感知在实现灵巧和可靠的机器人操作中至关重要，但现有的校准过程仍然是临时和劳动密集型的，因此需要一种更高效的方法来简化校准过程。

Method: 
我们利用开源库	extbackslash libname{}将低成本3D打印机转化为自动探测设备，生成大量标记的训练数据用于触觉传感器校准，并使用自定义的卷积神经网络重建高质量深度图。

Result: 
成功校准了两种商业化的基于视觉的触觉传感器DIGIT和GelSight Mini，并通过数据消融研究提供了关于准确校准所需数据量的实用指导，同时评估了模型在之前未见物体上的校准准确性和泛化性能。

Conclusion: 
本研究提出的开源库	extbackslash libname{}能够自动化触觉传感器的校准，推动触觉感知研究，简化传感器部署，并促进触觉感知在机器人平台中的实际应用。

Abstract: Tactile sensing plays a key role in enabling dexterous and reliable robotic
manipulation, but realizing this capability requires substantial calibration to
convert raw sensor readings into physically meaningful quantities. Despite its
near-universal necessity, the calibration process remains ad hoc and
labor-intensive. Here, we introduce \libname{}, an open-source library that
transforms a low-cost 3D printer into an automated probing device capable of
generating large volumes of labeled training data for tactile sensor
calibration. We demonstrate the utility of \libname{} by calibrating two
commercially available vision-based tactile sensors, DIGIT and GelSight Mini,
to reconstruct high-quality depth maps using the collected data and a custom
convolutional neural network. In addition, we perform a data ablation study to
determine how much data is needed for accurate calibration, providing practical
guidelines for researchers working with these specific sensors, and we
benchmark the trained models on previously unseen objects to evaluate
calibration accuracy and generalization performance. By automating tactile
sensor calibration, \libname{} can accelerate tactile sensing research,
simplify sensor deployment, and promote the practical integration of tactile
sensing in robotic platforms.

</details>


### [26] [SENT Map -- Semantically Enhanced Topological Maps with Foundation Models](https://arxiv.org/abs/2511.03165)
*Raj Surya Rajendran Kathirvel,Zach A Chavis,Stephen J. Guy,Karthik Desingh*

Main category: cs.RO

TL;DR: 引入SENT-Map，支持自主导航的室内环境语义增强拓扑地图，利用基础模型的进展，实验表明其能成功规划室内环境。


<details>
  <summary>Details</summary>
Motivation: 旨在通过利用基础模型的进展，支持自主导航和操作，创建室内环境的语义增强拓扑地图。

Method: 该框架采用两阶段方法，首先利用视觉基础模型与操作员一起映射环境，然后结合自然语言查询使用SENT-Map进行规划。

Result: 实验结果表明，语义增强使得小型本地可部署的基础模型能够有效进行室内环境规划。

Conclusion: 语义增强使得即使是小型本地可部署的基础模型也能够成功地在室内环境中进行规划。

Abstract: We introduce SENT-Map, a semantically enhanced topological map for
representing indoor environments, designed to support autonomous navigation and
manipulation by leveraging advancements in foundational models (FMs). Through
representing the environment in a JSON text format, we enable semantic
information to be added and edited in a format that both humans and FMs
understand, while grounding the robot to existing nodes during planning to
avoid infeasible states during deployment. Our proposed framework employs a two
stage approach, first mapping the environment alongside an operator with a
Vision-FM, then using the SENT-Map representation alongside a natural-language
query within an FM for planning. Our experimental results show that
semantic-enhancement enables even small locally-deployable FMs to successfully
plan over indoor environments.

</details>


### [27] [Learning Natural and Robust Hexapod Locomotion over Complex Terrains via Motion Priors based on Deep Reinforcement Learning](https://arxiv.org/abs/2511.03167)
*Xin Liu,Jinze Wu,Yinghui Li,Chenkun Qi,Yufei Xue,Feng Gao*

Main category: cs.RO

TL;DR: 本论文提出了一种基于运动先验的深度强化学习方法，实现了六足机器人在复杂地形上的自然行走。


<details>
  <summary>Details</summary>
Motivation: 多足机器人在复杂地形导航中具备更强的稳定性，如何有效协调多条腿进行自然且稳健的移动是一个关键问题。

Method: 采用基于运动先验的方法，利用深度强化学习算法训练六足机器人。

Result: 通过优化运动先验生成的数据集和对抗鉴别器的训练，成功实现了六足机器人在复杂地形上的自然步态和出色的稳健性。

Conclusion: 本研究首次将强化学习控制器应用于真实六足机器人，实现了在复杂地形上行走的能力。

Abstract: Multi-legged robots offer enhanced stability to navigate complex terrains
with their multiple legs interacting with the environment. However, how to
effectively coordinate the multiple legs in a larger action exploration space
to generate natural and robust movements is a key issue. In this paper, we
introduce a motion prior-based approach, successfully applying deep
reinforcement learning algorithms to a real hexapod robot. We generate a
dataset of optimized motion priors, and train an adversarial discriminator
based on the priors to guide the hexapod robot to learn natural gaits. The
learned policy is then successfully transferred to a real hexapod robot, and
demonstrate natural gait patterns and remarkable robustness without visual
information in complex terrains. This is the first time that a reinforcement
learning controller has been used to achieve complex terrain walking on a real
hexapod robot.

</details>


### [28] [Learning-based Cooperative Robotic Paper Wrapping: A Unified Control Policy with Residual Force Control](https://arxiv.org/abs/2511.03181)
*Rewida Ali,Cristian C. Beltran-Hernandez,Weiwei Wan,Kensuke Harada*

Main category: cs.RO

TL;DR: 本研究提出了一种新的学习框架，通过结合高层规划和低层控制，成功实现了高效的机器人包裹任务，展示了对可变形物体的精细操控能力。


<details>
  <summary>Details</summary>
Motivation: 人机合作在处理例如纸张、袋子和织物等可变形物体的环境中至关重要，但由于可变形材料的不可预测动态以及自适应力控制的需求，使得协调机器人行动与人类协助变得困难。

Method: 提出了一种基于学习的框架，集成了大语言模型驱动的高层任务规划器与低层混合模仿学习和强化学习策略，核心是一种能够捕捉长范围时间依赖的统一策略模型。

Result: 该框架实现了97%的成功率，且能够通过学习子目标来支持灵活的执行，而不仅仅是复现运动序列。

Conclusion: 本研究的框架在现实世界的包裹任务上达到了97%的成功率，有效地桥接了高层意图与对可变形物体操作所需的精细力控制。

Abstract: Human-robot cooperation is essential in environments such as warehouses and
retail stores, where workers frequently handle deformable objects like paper,
bags, and fabrics. Coordinating robotic actions with human assistance remains
difficult due to the unpredictable dynamics of deformable materials and the
need for adaptive force control. To explore this challenge, we focus on the
task of gift wrapping, which exemplifies a long-horizon manipulation problem
involving precise folding, controlled creasing, and secure fixation of paper.
Success is achieved when the robot completes the sequence to produce a neatly
wrapped package with clean folds and no tears.
  We propose a learning-based framework that integrates a high-level task
planner powered by a large language model (LLM) with a low-level hybrid
imitation learning (IL) and reinforcement learning (RL) policy. At its core is
a Sub-task Aware Robotic Transformer (START) that learns a unified policy from
human demonstrations. The key novelty lies in capturing long-range temporal
dependencies across the full wrapping sequence within a single model. Unlike
vanilla Action Chunking with Transformer (ACT), typically applied to short
tasks, our method introduces sub-task IDs that provide explicit temporal
grounding. This enables robust performance across the entire wrapping process
and supports flexible execution, as the policy learns sub-goals rather than
merely replicating motion sequences.
  Our framework achieves a 97% success rate on real-world wrapping tasks. We
show that the unified transformer-based policy reduces the need for specialized
models, allows controlled human supervision, and effectively bridges high-level
intent with the fine-grained force control required for deformable object
manipulation.

</details>


### [29] [Collaborative Assembly Policy Learning of a Sightless Robot](https://arxiv.org/abs/2511.03189)
*Zeqing Zhang,Weifeng Lu,Lei Yang,Wei Jing,Bowei Tang,Jia Pan*

Main category: cs.RO

TL;DR: 本文介绍了一种新型RL方法，旨在改善机器人在人类-机器人协作任务中的表现，尤其是在安全约束和稀疏奖励场景下。


<details>
  <summary>Details</summary>
Motivation: 目前的适应控制方法在测量人类施加的力/扭矩方面存在挑战，限制了机器人在协作任务中的能力。

Method: 采用人类设计的适应控制器的RL方法进行实验。

Result: 通过模拟和实际实验，证明了新方法在效果上的显著提升。

Conclusion: 提出的RL方法在成功率和任务完成时间上优于传统的适应控制，同时降低了测量到的力/扭矩。

Abstract: This paper explores a physical human-robot collaboration (pHRC) task
involving the joint insertion of a board into a frame by a sightless robot and
a human operator. While admittance control is commonly used in pHRC tasks, it
can be challenging to measure the force/torque applied by the human for
accurate human intent estimation, limiting the robot's ability to assist in the
collaborative task. Other methods that attempt to solve pHRC tasks using
reinforcement learning (RL) are also unsuitable for the board-insertion task
due to its safety constraints and sparse rewards. Therefore, we propose a novel
RL approach that utilizes a human-designed admittance controller to facilitate
more active robot behavior and reduce human effort. Through simulation and
real-world experiments, we demonstrate that our approach outperforms admittance
control in terms of success rate and task completion time. Additionally, we
observed a significant reduction in measured force/torque when using our
proposed approach compared to admittance control. The video of the experiments
is available at https://youtu.be/va07Gw6YIog.

</details>


### [30] [GUIDES: Guidance Using Instructor-Distilled Embeddings for Pre-trained Robot Policy Enhancement](https://arxiv.org/abs/2511.03400)
*Minquan Gao,Xinyi Li,Qing Yan,Xiaojian Sun,Xiaopan Zhang,Chien-Ming Huang,Jiachen Li*

Main category: cs.RO

TL;DR: 本论文提出GUIDES，一个轻量级框架，通过基础模型的语义指导增强预训练机器人策略，而无需改建架构，提升任务成功率和运动精度。


<details>
  <summary>Details</summary>
Motivation: 在许多情况中，完全替换预训练机器人策略是不现实的，因为这可能导致高成本和知识的丢失，因此需要一种方法来提升这些策略的语义意识。

Method: 通过将预训练策略与基础模型的语义指导相结合，使用微调的视觉-语言模型生成上下文指令，并通过辅助模块编码为指导嵌入，注入到策略的潜在空间中。

Result: 在RoboCasa仿真环境中进行的广泛验证显示，TASK成功率持续且显著提高，UR5机器人上的实际部署进一步证明了GUIDES在重要子任务（如抓取）中的运动精度增强。

Conclusion: GUIDES为升级现有机器人策略提供了一种切实可行和资源高效的方法，而非完全替代它们。

Abstract: Pre-trained robot policies serve as the foundation of many validated robotic
systems, which encapsulate extensive embodied knowledge. However, they often
lack the semantic awareness characteristic of foundation models, and replacing
them entirely is impractical in many situations due to high costs and the loss
of accumulated knowledge. To address this gap, we introduce GUIDES, a
lightweight framework that augments pre-trained policies with semantic guidance
from foundation models without requiring architectural redesign. GUIDES employs
a fine-tuned vision-language model (Instructor) to generate contextual
instructions, which are encoded by an auxiliary module into guidance
embeddings. These embeddings are injected into the policy's latent space,
allowing the legacy model to adapt to this new semantic input through brief,
targeted fine-tuning. For inference-time robustness, a large language
model-based Reflector monitors the Instructor's confidence and, when confidence
is low, initiates a reasoning loop that analyzes execution history, retrieves
relevant examples, and augments the VLM's context to refine subsequent actions.
Extensive validation in the RoboCasa simulation environment across diverse
policy architectures shows consistent and substantial improvements in task
success rates. Real-world deployment on a UR5 robot further demonstrates that
GUIDES enhances motion precision for critical sub-tasks such as grasping.
Overall, GUIDES offers a practical and resource-efficient pathway to upgrade,
rather than replace, validated robot policies.

</details>


### [31] [Value Elicitation for a Socially Assistive Robot Addressing Social Anxiety: A Participatory Design Approach](https://arxiv.org/abs/2511.03444)
*Vesna Poprcova,Iulia Lefter,Martijn Warnier,Frances Brazier*

Main category: cs.RO

TL;DR: 本研究探讨了社交焦虑支持的社交辅助机器人的设计价值，通过参与式设计研讨会获得用户中心的见解，强调在设计中考虑适应性、接受度和有效性。


<details>
  <summary>Details</summary>
Motivation: 社交焦虑是一种广泛存在的心理健康问题，影响着整体福祉和生活质量，而现有的支持和治疗往往无法满足需求。

Method: 通过与心理健康学术研究者进行参与式设计研讨会，探索与社交焦虑支持的机器人干预相关的价值、期望、需求和偏好。

Result: 研究结果揭示了与社交焦虑支持相关的设计相关价值，包括适应性、接受度和有效性，并提供了深入的设计洞察。

Conclusion: 研究强调以研究为导向的价值获取方法的重要性，强调用户中心和情境意识的设计考虑在社交辅助机器人开发中的作用。

Abstract: Social anxiety is a prevalent mental health condition that can significantly
impact overall well-being and quality of life. Despite its widespread effects,
adequate support or treatment for social anxiety is often insufficient.
Advances in technology, particularly in social robotics, offer promising
opportunities to complement traditional mental health. As an initial step
toward developing effective solutions, it is essential to understand the values
that shape what is considered meaningful, acceptable, and helpful. In this
study, a participatory design workshop was conducted with mental health
academic researchers to elicit the underlying values that should inform the
design of socially assistive robots for social anxiety support. Through
creative, reflective, and envisioning activities, participants explored
scenarios and design possibilities, allowing for systematic elicitation of
values, expectations, needs, and preferences related to robot-supported
interventions. The findings reveal rich insights into design-relevant
values-including adaptivity, acceptance, and efficacy-that are core to support
for individuals with social anxiety. This study highlights the significance of
a research-led approach to value elicitation, emphasising user-centred and
context-aware design considerations in the development of socially assistive
robots.

</details>


### [32] [Development of the Bioinspired Tendon-Driven DexHand 021 with Proprioceptive Compliance Control](https://arxiv.org/abs/2511.03481)
*Jianbo Yuan,Haohua Zhu,Jing Dai,Sheng Yi*

Main category: cs.RO

TL;DR: 本研究介绍了Dex-Hand 021，通过创新的力传感控制方法，显著提升了机器人手的性能和灵活性，推动了灵巧机械手的工业应用。


<details>
  <summary>Details</summary>
Motivation: 复制人手的多功能能力，以应对日常生活和工业应用中的挑战。

Method: 提出了一种基于本体感知的力传感控制方法来增强操控能力。

Result: Dex-Hand 021是一款高性能的纤维驱动五指机器人手，具备19个自由度，轻量化设计，表现出优越的负载能力和高重复性。与PID控制相比，多物体抓握中的关节扭矩减少了31.19%。

Conclusion: 该研究为轻量级工业级灵巧手的设计和本体感知控制的发展做出了贡献，提升了机器人操控能力和智能制造水平。

Abstract: The human hand plays a vital role in daily life and industrial applications,
yet replicating its multifunctional capabilities-including motion, sensing, and
coordinated manipulation-with robotic systems remains a formidable challenge.
Developing a dexterous robotic hand requires balancing human-like agility with
engineering constraints such as complexity, size-to-weight ratio, durability,
and force-sensing performance. This letter presents Dex-Hand 021, a
high-performance, cable-driven five-finger robotic hand with 12 active and 7
passive degrees of freedom (DoFs), achieving 19 DoFs dexterity in a lightweight
1 kg design. We propose a proprioceptive force-sensing-based admittance control
method to enhance manipulation. Experimental results demonstrate its superior
performance: a single-finger load capacity exceeding 10 N, fingertip
repeatability under 0.001 m, and force estimation errors below 0.2 N. Compared
to PID control, joint torques in multi-object grasping are reduced by 31.19%,
significantly improves force-sensing capability while preventing overload
during collisions. The hand excels in both power and precision grasps,
successfully executing 33 GRASP taxonomy motions and complex manipulation
tasks. This work advances the design of lightweight, industrial-grade dexterous
hands and enhances proprioceptive control, contributing to robotic manipulation
and intelligent manufacturing.

</details>


### [33] [ROSBag MCP Server: Analyzing Robot Data with LLMs for Agentic Embodied AI Applications](https://arxiv.org/abs/2511.03497)
*Lei Fu,Sahar Salimpour,Leonardo Militano,Harry Edelman,Jorge Peña Queralta,Giovanni Toffetti*

Main category: cs.RO

TL;DR: 该研究开发了MCP服务器以提升移动机器人数据分析能力，并分析了不同LLM/VLM模型的工具调用效果，发现Kimi K2和Claude Sonnet 4表现最佳。


<details>
  <summary>Details</summary>
Motivation: 填补Agentic Embodied AI领域文献的空白，探索MCP在移动机器人数据分析中的应用。

Method: 通过构建MCP服务器分析ROS和ROS 2数据包，开发特定工具并使用多种LLM和VLM进行实验。

Result: 实验结果显示Kimi K2和Claude Sonnet 4在工具调用能力上显著优于其他模型，且成功率受多种因素的影响。

Conclusion: 本研究表明不同LLM/VLM模型在工具调用能力方面存在显著差距，且多个因素影响成功率。

Abstract: Agentic AI systems and Physical or Embodied AI systems have been two key
research verticals at the forefront of Artificial Intelligence and Robotics,
with Model Context Protocol (MCP) increasingly becoming a key component and
enabler of agentic applications. However, the literature at the intersection of
these verticals, i.e., Agentic Embodied AI, remains scarce. This paper
introduces an MCP server for analyzing ROS and ROS 2 bags, allowing for
analyzing, visualizing and processing robot data with natural language through
LLMs and VLMs. We describe specific tooling built with robotics domain
knowledge, with our initial release focused on mobile robotics and supporting
natively the analysis of trajectories, laser scan data, transforms, or time
series data. This is in addition to providing an interface to standard ROS 2
CLI tools ("ros2 bag list" or "ros2 bag info"), as well as the ability to
filter bags with a subset of topics or trimmed in time. Coupled with the MCP
server, we provide a lightweight UI that allows the benchmarking of the tooling
with different LLMs, both proprietary (Anthropic, OpenAI) and open-source
(through Groq). Our experimental results include the analysis of tool calling
capabilities of eight different state-of-the-art LLM/VLM models, both
proprietary and open-source, large and small. Our experiments indicate that
there is a large divide in tool calling capabilities, with Kimi K2 and Claude
Sonnet 4 demonstrating clearly superior performance. We also conclude that
there are multiple factors affecting the success rates, from the tool
description schema to the number of arguments, as well as the number of tools
available to the models. The code is available with a permissive license at
https://github.com/binabik-ai/mcp-rosbags.

</details>


### [34] [Indicating Robot Vision Capabilities with Augmented Reality](https://arxiv.org/abs/2511.03550)
*Hong Wang,Ridhima Phatak,James Ocampo,Zhao Han*

Main category: cs.RO

TL;DR: 本研究探讨了人类对机器人视野的错误理解，并通过AR技术提出了四种视野指示器以改善这一问题。


<details>
  <summary>Details</summary>
Motivation: 人类常常错误地假设机器人和人类有相同的视野，这会影响人机协作的成功。

Method: 通过在人群中进行用户实验（N=41），评估四种AR视野指示器的准确性、信心、任务效率和工作负载。

Result: 结果显示，任务空间的外部视野指标准确性最高，且参与者在所有指标下信心高、认知负担低。

Conclusion: 研究提出的AR视野指示器有效提高了人类对机器人视野能力的理解，并为实践者提供了应用指南。

Abstract: Research indicates that humans can mistakenly assume that robots and humans
have the same field of view (FoV), possessing an inaccurate mental model of
robots. This misperception may lead to failures during human-robot
collaboration tasks where robots might be asked to complete impossible tasks
about out-of-view objects. The issue is more severe when robots do not have a
chance to scan the scene to update their world model while focusing on assigned
tasks. To help align humans' mental models of robots' vision capabilities, we
propose four FoV indicators in augmented reality (AR) and conducted a user
human-subjects experiment (N=41) to evaluate them in terms of accuracy,
confidence, task efficiency, and workload. These indicators span a spectrum
from egocentric (robot's eye and head space) to allocentric (task space).
Results showed that the allocentric blocks at the task space had the highest
accuracy with a delay in interpreting the robot's FoV. The egocentric indicator
of deeper eye sockets, possible for physical alteration, also increased
accuracy. In all indicators, participants' confidence was high while cognitive
load remained low. Finally, we contribute six guidelines for practitioners to
apply our AR indicators or physical alterations to align humans' mental models
with robots' vision capabilities.

</details>


### [35] [OneOcc: Semantic Occupancy Prediction for Legged Robots with a Single Panoramic Camera](https://arxiv.org/abs/2511.03571)
*Hao Shi,Ze Wang,Shangwei Guo,Mengfei Duan,Song Wang,Teng Chen,Kailun Yang,Lin Wang,Kaiwei Wang*

Main category: cs.RO

TL;DR: OneOcc是一个为腿部/类人机器人设计的全视觉360度语义场景完成框架，实现了新的性能突破，并将提供公共数据集和代码。


<details>
  <summary>Details</summary>
Motivation: 针对腿部/类人机器人，提供鲁棒的3D语义占用，克服大多数语义场景完成系统在运动平台与传感器布局上的局限性。

Method: 提出了多个模块，包括双投影融合、双网格体素化、轻量解码器和运动补偿，以实现动态多尺度融合和长距离推理。

Result: OneOcc在QuadOcc上击败了强大的视觉基线和流行的LiDAR方法，在H3O上分别提升了+3.83 mIoU（城市内）和+8.08（跨城市）。

Conclusion: OneOcc在QuadOcc和H3O基准上设置了新的状态-of-the-art，证明了其在全方位感知中的有效性与轻量化优势。

Abstract: Robust 3D semantic occupancy is crucial for legged/humanoid robots, yet most
semantic scene completion (SSC) systems target wheeled platforms with
forward-facing sensors. We present OneOcc, a vision-only panoramic SSC
framework designed for gait-introduced body jitter and 360{\deg} continuity.
OneOcc combines: (i) Dual-Projection fusion (DP-ER) to exploit the annular
panorama and its equirectangular unfolding, preserving 360{\deg} continuity and
grid alignment; (ii) Bi-Grid Voxelization (BGV) to reason in Cartesian and
cylindrical-polar spaces, reducing discretization bias and sharpening
free/occupied boundaries; (iii) a lightweight decoder with Hierarchical AMoE-3D
for dynamic multi-scale fusion and better long-range/occlusion reasoning; and
(iv) plug-and-play Gait Displacement Compensation (GDC) learning feature-level
motion correction without extra sensors. We also release two panoramic
occupancy benchmarks: QuadOcc (real quadruped, first-person 360{\deg}) and
Human360Occ (H3O) (CARLA human-ego 360{\deg} with RGB, Depth, semantic
occupancy; standardized within-/cross-city splits). OneOcc sets new
state-of-the-art (SOTA): on QuadOcc it beats strong vision baselines and
popular LiDAR ones; on H3O it gains +3.83 mIoU (within-city) and +8.08
(cross-city). Modules are lightweight, enabling deployable full-surround
perception for legged/humanoid robots. Datasets and code will be publicly
available at https://github.com/MasterHow/OneOcc.

</details>


### [36] [Multi-User Personalisation in Human-Robot Interaction: Using Quantitative Bipolar Argumentation Frameworks for Preferences Conflict Resolution](https://arxiv.org/abs/2511.03576)
*Aniol Civit,Antonio Andriella,Carles Sierra,Guillem Alenyà*

Main category: cs.RO

TL;DR: 本研究提出了一种新颖的多用户个性化框架MUP-QBAF，能有效解决人机交互中多个用户之间的偏好冲突，适应动态环境。


<details>
  <summary>Details</summary>
Motivation: 大多数现有的方法专注于单用户适应，而忽视了涉及多个利益相关者的场景，可能导致偏好冲突。

Method: 提出了一种基于定量双极论证框架的多用户个性化框架（MUP-QBAF），能够显式建模和解决多用户偏好冲突。

Result: 通过现实案例研究验证框架的属性和能力，展示了助理机器人如何在照顾者和照护对象之间调解冲突的偏好，并进行了论证基础分数的敏感性分析。

Conclusion: 本研究提供了一种透明、结构化且敏感于上下文的方法，以解决多个用户偏好的冲突，推动了多用户人机交互领域的发展。

Abstract: While personalisation in Human-Robot Interaction (HRI) has advanced
significantly, most existing approaches focus on single-user adaptation,
overlooking scenarios involving multiple stakeholders with potentially
conflicting preferences. To address this, we propose the Multi-User Preferences
Quantitative Bipolar Argumentation Framework (MUP-QBAF), a novel multi-user
personalisation framework based on Quantitative Bipolar Argumentation
Frameworks (QBAFs) that explicitly models and resolves multi-user preference
conflicts. Unlike prior work in Argumentation Frameworks, which typically
assumes static inputs, our approach is tailored to robotics: it incorporates
both users' arguments and the robot's dynamic observations of the environment,
allowing the system to adapt over time and respond to changing contexts.
Preferences, both positive and negative, are represented as arguments whose
strength is recalculated iteratively based on new information. The framework's
properties and capabilities are presented and validated through a realistic
case study, where an assistive robot mediates between the conflicting
preferences of a caregiver and a care recipient during a frailty assessment
task. This evaluation further includes a sensitivity analysis of argument base
scores, demonstrating how preference outcomes can be shaped by user input and
contextual observations. By offering a transparent, structured, and
context-sensitive approach to resolving competing user preferences, this work
advances the field of multi-user HRI. It provides a principled alternative to
data-driven methods, enabling robots to navigate conflicts in real-world
environments.

</details>


### [37] [Manifold-constrained Hamilton-Jacobi Reachability Learning for Decentralized Multi-Agent Motion Planning](https://arxiv.org/abs/2511.03591)
*Qingyi Chen,Ruiqi Ni,Jun Kim,Ahmed H. Qureshi*

Main category: cs.RO

TL;DR: 提出了一种新型的高效多智能体运动规划框架，通过哈密顿-雅可比可达性学习来处理流形约束，实现安全和任务可行的路径规划，并在实验中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在动态环境中，多智能体运动规划面临在遵循任务引发的复杂约束的同时安全导航的挑战，现有方法在处理流形约束方面仍然存在困难。

Method: 提出了一种流形约束的哈密顿-雅可比可达性学习框架，结合分散的轨迹优化规划器，解决了流形约束下的哈密顿-雅可比问题，以捕获任务感知的安全条件。

Result: 我们的实验表明，该方法在多任务约束的运动规划中超越了现有的约束规划器，速度适合实际应用。

Conclusion: 该方法在适应多任务约束的情况下提供了更高效的安全路径规划，适用于高维度的多智能体操作问题，并且表现出优于现有的约束运动规划方法。

Abstract: Safe multi-agent motion planning (MAMP) under task-induced constraints is a
critical challenge in robotics. Many real-world scenarios require robots to
navigate dynamic environments while adhering to manifold constraints imposed by
tasks. For example, service robots must carry cups upright while avoiding
collisions with humans or other robots. Despite recent advances in
decentralized MAMP for high-dimensional systems, incorporating manifold
constraints remains difficult. To address this, we propose a
manifold-constrained Hamilton-Jacobi reachability (HJR) learning framework for
decentralized MAMP. Our method solves HJR problems under manifold constraints
to capture task-aware safety conditions, which are then integrated into a
decentralized trajectory optimization planner. This enables robots to generate
motion plans that are both safe and task-feasible without requiring assumptions
about other agents' policies. Our approach generalizes across diverse
manifold-constrained tasks and scales effectively to high-dimensional
multi-agent manipulation problems. Experiments show that our method outperforms
existing constrained motion planners and operates at speeds suitable for
real-world applications. Video demonstrations are available at
https://youtu.be/RYcEHMnPTH8 .

</details>


### [38] [Multi-robot searching with limited sensing range for static and mobile intruders](https://arxiv.org/abs/2511.03622)
*Swadhin Agrawal,Sujoy Bhore,Joseph S. B. Mitchell,P. B. Sujit,Aayush Gohil*

Main category: cs.RO

TL;DR: 本文提出了使用多搜索机器人在几何域中寻找入侵者的问题，并开发了有效的搜索算法以应对NP难度。


<details>
  <summary>Details</summary>
Motivation: 在简单连通的正交多边形中使用多机器人搜索入侵者，解决潜在的NP-难问题。

Method: 开发基于空间填充曲线、随机搜索和合作随机搜索的算法来寻找入侵者。

Result: 找到有效算法的同时，评估了搜索机器人数量与完成搜索过程所需时间之间的权衡。

Conclusion: 通过空间填充曲线、随机搜索和合作随机搜索的方法，提出了有效且稳健的算法来解决在几何域中寻找入侵者的问题。

Abstract: We consider the problem of searching for an intruder in a geometric domain by
utilizing multiple search robots. The domain is a simply connected orthogonal
polygon with edges parallel to the cartesian coordinate axes. Each robot has a
limited sensing capability. We study the problem for both static and mobile
intruders. It turns out that the problem of finding an intruder is NP-hard,
even for a stationary intruder. Given this intractability, we turn our
attention towards developing efficient and robust algorithms, namely methods
based on space-filling curves, random search, and cooperative random search.
Moreover, for each proposed algorithm, we evaluate the trade-off between the
number of search robots and the time required for the robots to complete the
search process while considering the geometric properties of the connected
orthogonal search area.

</details>


### [39] [Flying Robotics Art: ROS-based Drone Draws the Record-Breaking Mural](https://arxiv.org/abs/2511.03651)
*Andrei A. Korigodskii,Oleg D. Kalachev,Artem E. Vasiunik,Matvei V. Urvantsev,Georgii E. Bondar*

Main category: cs.RO

TL;DR: 本文展示了一种创新的自主无人机系统，用于绘制世界上最大的壁画，克服了艺术精度和操作可靠性的挑战。


<details>
  <summary>Details</summary>
Motivation: 解决在户外恶劣条件下维持艺术精度和操作可靠性的挑战，推进无人机艺术创作的能力。

Method: 采用红外运动捕捉摄像头和LiDAR技术相结合的导航系统，独特的控制架构，轨迹规划和路径优化算法，以及定制的喷漆机制。

Result: 实验结果显示系统在不同条件下均表现出色，呈现出卓越的精确性和鲁棒性。

Conclusion: 该系统展示了强大的鲁棒性和精确性，具有自我创造大型艺术的潜力，拓展了机器人在创意领域的功能应用。

Abstract: This paper presents the innovative design and successful deployment of a
pioneering autonomous unmanned aerial system developed for executing the
world's largest mural painted by a drone. Addressing the dual challenges of
maintaining artistic precision and operational reliability under adverse
outdoor conditions such as wind and direct sunlight, our work introduces a
robust system capable of navigating and painting outdoors with unprecedented
accuracy. Key to our approach is a novel navigation system that combines an
infrared (IR) motion capture camera and LiDAR technology, enabling precise
location tracking tailored specifically for largescale artistic applications.
We employ a unique control architecture that uses different regulation in
tangential and normal directions relative to the planned path, enabling precise
trajectory tracking and stable line rendering. We also present algorithms for
trajectory planning and path optimization, allowing for complex curve drawing
and area filling. The system includes a custom-designed paint spraying
mechanism, specifically engineered to function effectively amidst the turbulent
airflow generated by the drone's propellers, which also protects the drone's
critical components from paint-related damage, ensuring longevity and
consistent performance. Experimental results demonstrate the system's
robustness and precision in varied conditions, showcasing its potential for
autonomous large-scale art creation and expanding the functional applications
of robotics in creative fields.

</details>


### [40] [Unconscious and Intentional Human Motion Cues for Expressive Robot-Arm Motion Design](https://arxiv.org/abs/2511.03676)
*Taito Tashiro,Tomoko Yonezawa,Hirotake Yamazoe*

Main category: cs.RO

TL;DR: 本研究探讨了如何通过人类运动线索设计机器人动作，发现后期运动时序和物理呈现对观众印象有显著影响。


<details>
  <summary>Details</summary>
Motivation: 探讨如何利用人类运动线索来设计富有表现力的机器人手臂运动。

Method: 通过分析不完全信息游戏Geister中的两种人类移动棋子的方式，创建了基于运动速度和停顿时长的阶段特定机器人动作，并评估了观察者在物理机器人和录像呈现下的印象。

Result: 后期运动时序在形象形成中起着重要作用，物理体现增强了运动线索的可解释性。

Conclusion: 物理体现增强了运动线索的可解释性，并且后期运动时序在形象形成中扮演了重要角色。

Abstract: This study investigates how human motion cues can be used to design
expressive robot-arm movements. Using the imperfect-information game Geister,
we analyzed two types of human piece-moving motions: natural gameplay
(unconscious tendencies) and instructed expressions (intentional cues). Based
on these findings, we created phase-specific robot motions by varying movement
speed and stop duration, and evaluated observer impressions under two
presentation modalities: a physical robot and a recorded video. Results
indicate that late-phase motion timing, particularly during withdrawal, plays
an important role in impression formation and that physical embodiment enhances
the interpretability of motion cues. These findings provide insights for
designing expressive robot motions based on human timing behavior.

</details>


### [41] [Motion Planning Under Temporal Logic Specifications In Semantically Unknown Environments](https://arxiv.org/abs/2511.03652)
*Azizollah Taheri,Derya Aksaray*

Main category: cs.RO

TL;DR: 本研究提出了一种新颖的运动规划方法，能够在不确定环境中基于语义标签进行有效的任务规划。


<details>
  <summary>Details</summary>
Motivation: 任务是在不确定的环境中实现空间-时间-逻辑任务，而环境中语义标签的确切位置不明确。

Method: 构建了一个特殊的产品自动机来捕捉与语义标签相关的不确定性，并为该自动机的每个边设计了奖励函数，使用价值迭代进行在线重新规划。

Result: 通过理论结果和实验模拟，验证了所提方法的有效性。

Conclusion: 提出的自动机理论方法有效地解决了不确定环境下的运动规划问题。

Abstract: This paper addresses a motion planning problem to achieve
spatio-temporal-logical tasks, expressed by syntactically co-safe linear
temporal logic specifications (scLTL\next), in uncertain environments. Here,
the uncertainty is modeled as some probabilistic knowledge on the semantic
labels of the environment. For example, the task is "first go to region 1, then
go to region 2"; however, the exact locations of regions 1 and 2 are not known
a priori, instead a probabilistic belief is available. We propose a novel
automata-theoretic approach, where a special product automaton is constructed
to capture the uncertainty related to semantic labels, and a reward function is
designed for each edge of this product automaton. The proposed algorithm
utilizes value iteration for online replanning. We show some theoretical
results and present some simulations/experiments to demonstrate the efficacy of
the proposed approach.

</details>


### [42] [Source-Free Bistable Fluidic Gripper for Size-Selective and Stiffness-Adaptive Grasping](https://arxiv.org/abs/2511.03691)
*Zhihang Qin,Yueheng Zhang,Wan Su,Linxin Hou,Shenghao Zhou,Zhijun Chen,Yu Jun Tan,Cecilia Laschi*

Main category: cs.RO

TL;DR: 本文提出了一种新型自供能软抓手，通过内部液体重新分配实现抓取，具有良好的便携性和适应性。


<details>
  <summary>Details</summary>
Motivation: 传统的流体驱动软抓手依赖外部电源，限制了其便携性和长期自主性。

Method: 通过内部液体重新分配在三个互连的双稳态快切腔室中操作，利用内置液压反馈实现自主驱动。

Result: 开发出一种独立的、固定尺寸的软抓手，能够在不需要持续能量输入的情况下实现稳定和尺寸选择性的抓取。

Conclusion: 该设计为柔性机器人在水下和现场环境中的特定尺寸抽样和操作提供了可行的方法。

Abstract: Conventional fluid-driven soft grippers typically depend on external sources,
which limit portability and long-term autonomy. This work introduces a
self-contained soft gripper with fixed size that operates solely through
internal liquid redistribution among three interconnected bistable snap-through
chambers. When the top sensing chamber deforms upon contact, the displaced
liquid triggers snap-through expansion of the grasping chambers, enabling
stable and size-selective grasping without continuous energy input. The
internal hydraulic feedback further allows passive adaptation of gripping
pressure to object stiffness. This source-free and compact design opens new
possibilities for lightweight, stiffness-adaptive fluid-driven manipulation in
soft robotics, providing a feasible approach for targeted size-specific
sampling and operation in underwater and field environments.

</details>
