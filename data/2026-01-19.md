<div id=toc></div>

# Table of Contents

- [cs.HC](#cs.HC) [Total: 17]
- [cs.RO](#cs.RO) [Total: 25]


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [1] [Bridging Psychological Safety and Skill Guidance: An Adaptive Robotic Interview Coach](https://arxiv.org/abs/2601.10824)
*Wanqi Zhang,Jiangen He,Marielle Santos*

Main category: cs.HC

TL;DR: 社会机器人在求职面试中降低焦虑的潜力，但设计平衡心理安全与指导的挑战仍然复杂。研究揭示了安全性和指导性之间的张力，并提出了自适应支架生态系统框架以重塑机器人辅导的动态角色。


<details>
  <summary>Details</summary>
Motivation: 社会机器人有潜力降低求职面试的焦虑，但同时如果提供心理安全和指导的设计仍然面临挑战。

Method: 通过三阶段迭代设计研究(N = 8)来探讨和映射安全性与指导性之间的张力。

Result: 第一阶段发现了'安全-指导差距'，第二阶段发现了'支架悖论'，第三阶段通过发展代理驱动的交互层解决了这些张力。

Conclusion: 本文提出了一个新的自适应支架生态系统概念框架，重塑了机器人辅导的角色，强调用户自主性在提供情感支持和指导挑战之间的动态平衡。

Abstract: Social robots hold promise for reducing job interview anxiety, yet designing agents that provide both psychological safety and instructional guidance remains challenging. Through a three-phase iterative design study (N = 8), we empirically mapped this tension. Phase I revealed a "Safety-Guidance Gap": while a Person-Centered Therapy (PCT) robot established safety (d = 3.27), users felt insufficiently coached. Phase II identified a "Scaffolding Paradox": rigid feedback caused cognitive overload, while delayed feedback lacked specificity. In Phase III, we resolved these tensions by developing an Agency-Driven Interaction Layer. Synthesizing our empirical findings, we propose the Adaptive Scaffolding Ecosystem, a conceptual framework that redefines robotic coaching not as a static script, but as a dynamic balance between affective support and instructional challenge, mediated by user agency.

</details>


### [2] ["My Brother Is a School Principal, Earns About $80,000 Per Year... But When the Kids See Me, 'Wow, Uncle, You Have 1500 Followers on TikTok!'": A Study of Blind TikTokers' Alternative Professional Development Experiences](https://arxiv.org/abs/2601.10956)
*Yao Lyu,Tawanna Dillahunt,Jiaying Liu,John M. Carroll*

Main category: cs.HC

TL;DR: 研究调查了视觉障碍者在TikTok上的职业发展，识别了更包容和多样化的职业发展实践。


<details>
  <summary>Details</summary>
Motivation: 关注视觉障碍者在传统职业发展中面临的挑战，探索社交媒体作为更加平等的职业发展空间。

Method: 通过对60名视觉障碍者的访谈研究，分析他们在TikTok上的职业发展经验。

Result: 本研究探索了视觉障碍者在TikTok上的职业发展经历，强调了其目标、策略和挑战，并提出了更灵活、多样的职业发展模式。

Conclusion: 视觉障碍者在TikTok上的实践展示了更灵活和个性化的职业发展方法，研究为职业发展研究提供了新的视角。

Abstract: One's profession is an essential part of modern life. Traditionally, professional development has been criticized for excluding people with disabilities. People with visual impairments, for example, face disproportionately low employment rates, highlighting persistent gaps in professional opportunities. Recently, there has been growing research on social media platforms as spaces for more equitable career development approaches. In this paper, we present an interview study on the professional development experiences of 60 people with visual impairments on TikTok (also known as "BlindTokers"). We report BlindTokers' goals, strategies, and challenges, supported by detailed examples and in-depth analysis. Based on the findings, we identify that BlindTokers' practices reveal an alternative professional development approach that is more flexible, inclusive, personalized, and diversified than traditional models. Our study also extends professional development research by foregrounding emerging digital skills and proposing design implications to foster more equitable and inclusive professional opportunities.

</details>


### [3] ["I'm Constantly Getting Comments Like, 'Oh, You're Blind. You're Like the Only Woman That I Stand a Chance With.'": A Study of Blind TikTokers' Intersectional Experiences of Gender and Sexuality](https://arxiv.org/abs/2601.10957)
*Yao Lyu,Jessica Shen,Alina Faisal,John M. Carroll*

Main category: cs.HC

TL;DR: 本研究探讨盲人TikTok用户的交叉身份表达，揭示平台特征如何影响其边缘化体验，并提出未来社交媒体设计的建议。


<details>
  <summary>Details</summary>
Motivation: 研究盲人TikTok用户及其在社交媒体上的身份表达，特别关注女性和LGBTQ+群体的交叉经历。

Method: 访谈研究

Result: 发现盲人TikTok用户的交叉边缘化是基础设施性的，TikTok的分类和审核特征与社会规范的互动导致了这一现象。

Conclusion: 建议开发无障碍创作工具、包容性的身份选项和社区合作的上下文感知审核，以改善这些用户的体验。

Abstract: Social media platforms are important venues for identity expression, and the Human-Computer Interaction community has been paying growing attention to how marginalized groups express their identities on these platforms. Joining the emerging literature on intersectional experiences, we study blind TikTokers ("BlindTokers") who are also women and/or LGBTQ+. Using interview data from \rev{41} participants, we identify their intersectional experiences as mediated by TikTok's socio-technical affordances. We argue that BlindTokers' intersectional marginalization is infrastructural: TikTok's classification and moderation features interact with social norms in ways that push them aside and distort how they are treated on the platform. We use this infrastructure perspective to understand what these experiences are, how they were formed, and how they become harmful. We further recognize participants' infrastructuring work to address these problems. This study guides future social media design with accessible creator tools, inclusive identity options, and context-aware moderation developed in partnership with communities.

</details>


### [4] [Haptic Light-Emitting Diodes: Miniature, Luminous Tactile Actuators](https://arxiv.org/abs/2601.11043)
*Max Linnander,Yon Visell*

Main category: cs.HC

TL;DR: HLEDs是将脉冲光转化为机械动力的高效执行器，能提供触觉反馈并适用于多种领域。


<details>
  <summary>Details</summary>
Motivation: 为了解决触觉反馈的需求，设计一种高效且可以与人机交互相结合的新型执行器。

Method: 通过在气体填充的腔体中封装微型LED和低惯性的石墨光吸收体，利用光脉冲加热导致的气体压力变化来驱动膜片产生机械位移。

Result: HLEDs是一种光驱动的机械执行器，通过发光二极管直接将光脉冲转化为机械力量和位移。

Conclusion: HLEDs由于其简单的机械结构和高效的制造工艺，有望广泛应用于触觉显示和人机交互等领域。

Abstract: We present Haptic Light-Emitting Diodes (HLEDs), luminous thermopneumatic actuators that directly convert pulsed light into mechanical forces and displacements. Each device packages a miniature surface-mount LED in a gas-filled cavity that contains a low-inertia graphite photoabsorber. The cavity is sealed by an elastic membrane, which functions as a working diaphragm. Brief optical pulses heat the photoabsorber, which heats the gas. The resulting rapid pressure increases generate forces and displacements at the working diaphragm. Millimeter-scale HLEDs produce forces exceeding 0.4 N and displacements of 1 mm at low voltages, with 5 to 100 ms response times, making them attractive as actuators providing tactile feedback in human-machine interfaces. Perceptual testing revealed that the strength of tactile feedback increased linearly with optical power. HLEDs devices are mechanically simple and efficient to fabricate. Unusually, these actuators are also light-emitting, as a fraction of optical energy is transmitted through the membrane. These opto-mechanical actuators have many potential applications in tactile displays, human interface engineering, wearable computing, and other areas.

</details>


### [5] [Predicting Biased Human Decision-Making with Large Language Models in Conversational Settings](https://arxiv.org/abs/2601.11049)
*Stephen Pilli,Vivek Nallur*

Main category: cs.HC

TL;DR: 研究表明大语言模型可以有效预测人类在对话中的偏见决策，并在认知负荷增加时模拟人类的偏见行为。


<details>
  <summary>Details</summary>
Motivation: 研究大语言模型在对话环境中是否能够预测偏见决策，以及这些预测是否能够反映人类认知偏见在认知负荷下的变化。

Method: 通过预注册研究和聊天机器人进行六项经典决策任务，分析参与者的决策行为及其偏见表现。

Result: 参与者表现出框架效应和现状偏见，增加的对话复杂性提高了心理需求，并显著增强了偏见效应。大语言模型在考虑对话上下文后，在多个关键情境中的预测表现更加准确，并一致重现了人类的偏见模式。

Conclusion: 大语言模型能够预测人类决策中的偏见，并且在认知负荷变化时，其预测表现出与人类一致的偏见模式和负荷-偏见交互效应。

Abstract: We examine whether large language models (LLMs) can predict biased decision-making in conversational settings, and whether their predictions capture not only human cognitive biases but also how those effects change under cognitive load. In a pre-registered study (N = 1,648), participants completed six classic decision-making tasks via a chatbot with dialogues of varying complexity. Participants exhibited two well-documented cognitive biases: the Framing Effect and the Status Quo Bias. Increased dialogue complexity resulted in participants reporting higher mental demand. This increase in cognitive load selectively, but significantly, increased the effect of the biases, demonstrating the load-bias interaction. We then evaluated whether LLMs (GPT-4, GPT-5, and open-source models) could predict individual decisions given demographic information and prior dialogue. While results were mixed across choice problems, LLM predictions that incorporated dialogue context were significantly more accurate in several key scenarios. Importantly, their predictions reproduced the same bias patterns and load-bias interactions observed in humans. Across all models tested, the GPT-4 family consistently aligned with human behavior, outperforming GPT-5 and open-source models in both predictive accuracy and fidelity to human-like bias patterns. These findings advance our understanding of LLMs as tools for simulating human decision-making and inform the design of conversational agents that adapt to user biases.

</details>


### [6] [Children's Expectations, Engagement, and Evaluation of an LLM-enabled Spherical Visualization Platform in the Classroom](https://arxiv.org/abs/2601.11060)
*Emelie Fälton,Isabelle Strömstedt,Mathis Brossier,Andreas Göransson,Konrad Schönborn,Amy Loutfi,Erik Sunden,Mujtaba Fadhil Jawad,Yadgar Suleiman,Johanna Björklund,Mario Romero,Anders Ynnerman,Lonni Besançon*

Main category: cs.HC

TL;DR: 本研究探讨了在课堂环境中使用LLM增强的可视化软件与儿童进行互动的初步结果，为教育技术的未来研究方向提供了实证性见解。


<details>
  <summary>Details</summary>
Motivation: 随着对对话式人工智能在探究式学习中支持的兴趣日益增长，我们探讨儿童对口语LLM接口与共享沉浸式可视化系统的期望和参与。

Method: 通过结构化观察和小组讨论结合课堂研究的方法，收集了儿童在与系统互动前后的期望和体验。

Result: 在瑞典9-10岁儿童的课堂研究中，我们观察到儿童对增强可视化平台的初步接触及其互动模式和评估。

Conclusion: 本研究为课堂使用增强型可视化软件的技术潜力提供了实证见解，强调了未来研究的重要方向。

Abstract: We present our first stage results from deploying an LLM-augmented visualization software in a classroom setting to engage primary school children with earth-related datasets. Motivated by the growing interest in conversational AI as a means to support inquiry-based learning, we investigate children's expectations, engagement, and evaluation of a spoken LLM interface with a shared, immersive visualization system in a formal educational context. Our system integrates a speech-capable large language model with an interactive spherical display. It enables children to ask natural-language questions and receive coordinated verbal explanations and visual responses through the LLM-augmented visualization updating in real time based on spoken queries. We report on a classroom study with Swedish children aged 9-10, combining structured observation and small-group discussions to capture expectations prior to interaction, interaction patterns during facilitated sessions, and children's reflections on their encounter afterward. Our results provide empirical insights into children's initial encounters with an LLM-enabled visualization platform within a classroom setting and their expectations, interactions, and evaluations of the system. These findings inform the technology's potential for educational use and highlight important directions for future research.

</details>


### [7] [More Human or More AI? Visualizing Human-AI Collaboration Disclosures in Journalistic News Production](https://arxiv.org/abs/2601.11072)
*Amber Kusters,Pooja Prajod,Pablo Cesar,Abdallah El Ali*

Main category: cs.HC

TL;DR: 当前的新闻中AI使用披露方式过于简单，本文探讨了通过四种视觉化原型提升人类与AI合作的透明度。


<details>
  <summary>Details</summary>
Motivation: 为了提高新闻中对AI合作的透明度，帮助受众理解人类与AI的实际协作程度。

Method: 通过共设计会展开设计并实现原型，并进行实验研究以评估不同视觉化影响。

Result: 本文探讨了新闻报道中AI使用的披露方式，指出目前的简单标签无法充分反映人类与AI的合作细节。通过10次共设计会议，提出了69种披露设计，并实现了四个原型，旨在以视觉方式披露人类与AI在新闻中的合作。研究表明，不同的披露可视化（文本、角色时间线、任务时间线、聊天机器人）和合作比例（主要人类与主要AI）对可视化感知、注视模式和体验反馈有显著影响。结果显示，文本披露最不有效，而聊天机器人提供了最全面的信息。角色时间线强调了人类主导的文章中的AI贡献，而任务时间线则在主要由AI撰写的文章中改变了人类的参与感。

Conclusion: 我们提出了人类与AI合作的可视化披露方法，并警示视觉化如何改变对AI在新闻创作中实际角色的感知。

Abstract: Within journalistic editorial processes, disclosing AI usage is currently limited to simplistic labels, which misses the nuance of how humans and AI collaborated on a news article. Through co-design sessions (N=10), we elicited 69 disclosure designs and implemented four prototypes that visually disclose human-AI collaboration in journalism. We then ran a within-subjects lab study (N=32) to examine how disclosure visualizations (Textual, Role-based Timeline, Task-based Timeline, Chatbot) and collaboration ratios (Primarily Human vs. Primarily AI) influenced visualization perceptions, gaze patterns, and post-experience responses. We found that textual disclosures were least effective in communicating human-AI collaboration, whereas Chatbot offered the most in-depth information. Furthermore, while role-based timelines amplified AI contribution in primarily human articles, task-based timeline shifted perceptions toward human involvement in primarily AI articles. We contribute Human-AI collaboration disclosure visualizations and their evaluation, and cautionary considerations on how visualizations can alter perceptions of AI's actual role during news article creation.

</details>


### [8] [AI Twin: Enhancing ESL Speaking Practice through AI Self-Clones of a Better Me](https://arxiv.org/abs/2601.11103)
*Minju Park,Seunghyun Lee,Juhwan Ma,Dongwook Yoon*

Main category: cs.HC

TL;DR: AI Twin是一种新系统，旨在为ESL学习者提供更流畅的语言实践，采用隐性反馈以维持对话流畅性，提升学习动机。


<details>
  <summary>Details</summary>
Motivation: 现有工具的显性纠错会干扰对话并削弱学习者信心，为此提出AI Twin以隐性反馈形式提升学习者的自信和动机。

Method: 通过在20名成年ESL学习者中进行的对照研究，比较了AI Twin与显性纠错和非个性化重述代理的效果。

Result: AI Twin通过以学习者的声音将其语言表达进行流利化重述，从而提高了学习者的情感投入和动机。

Conclusion: AI Twin在语言学习中表现出更高的情感投入和动机，展现了自我代表性人工智能在个性化支持中的潜力。

Abstract: Advances in AI have enabled ESL learners to practice speaking through conversational systems. However, most tools rely on explicit correction, which can interrupt the conversation and undermine confidence. Grounded in second language acquisition and motivational psychology, we present AI Twin, a system that rephrases learner utterances into more fluent English and delivers them in the learner's voice. Embodying a more confident and proficient version of the learner, AI Twin reinforces motivation through alignment with their aspirational Ideal L2 Self. Also, its use of implicit feedback through rephrasing preserves conversational flow and fosters an emotionally supportive environment. In a within-subject study with 20 adult ESL learners, we compared AI Twin with explicit correction and a non-personalized rephrasing agent. Results show that AI Twin elicited higher emotional engagement, with participants describing the experience as more motivating. These findings highlight the potential of self-representative AI for personalized, psychologically grounded support in ESL learning.

</details>


### [9] [Noisy Graph Patterns via Ordered Matrices](https://arxiv.org/abs/2601.11171)
*Jules Wulms,Wouter Meulemans,Bettina Speckmann*

Main category: cs.HC

TL;DR: 本论文提出了一种基于有序矩阵的方法来定义和检测噪声图案，利用Moran's I优化邻接矩阵，成功实现对噪声图案的高效检测与可视化。


<details>
  <summary>Details</summary>
Motivation: 图的高层次结构对于关系数据的分析和可视化至关重要，但发现重要图案面临计算复杂性和噪声问题的挑战。

Method: 使用有序矩阵定义和检测噪声图案，通过Moran's I优化图的邻接矩阵排序，结合精确算法和启发式方法。

Result: 通过优化排序和噪声级别的定义，成功检测到标准图案的矩阵，以及实现图案的可视化简化。

Conclusion: 我们的方法有效地检测并可视化噪声图案，并在实际数据集上证明了其有效性。

Abstract: The high-level structure of a graph is a crucial ingredient for the analysis and visualization of relational data. However, discovering the salient graph patterns that form this structure is notoriously difficult for two reasons. (1) Finding important patterns, such as cliques and bicliques, is computationally hard. (2) Real-world graphs contain noise, and therefore do not always exhibit patterns in their pure form. Defining meaningful noisy patterns and detecting them efficiently is a currently unsolved challenge. In this paper, we propose to use well-ordered matrices as a tool to both define and effectively detect noisy patterns. Specifically, we represent a graph as its adjacency matrix and optimally order it using Moran's $I$. Standard graph patterns (cliques, bicliques, and stars) now translate to rectangular submatrices. Using Moran's $I$, we define a permitted level of noise for such patterns. A combination of exact algorithms and heuristics allows us to efficiently decompose the matrix into noisy patterns. We also introduce a novel motif simplification that visualizes noisy patterns while explicitly encoding the level of noise. We showcase our techniques on several real-world data sets.

</details>


### [10] [Game Accessibility Through Shared Control for People With Upper-Limb Impairments](https://arxiv.org/abs/2601.11218)
*Sergio Mascetti,Matteo Manzoni,Filippo Corti,Dragan Ahmetovic*

Main category: cs.HC

TL;DR: 本研究比较了上肢受限者在人工合作与软件代理辅助下的游戏体验。


<details>
  <summary>Details</summary>
Motivation: 帮助上肢受限的人更好地访问和参与视频游戏的挑战

Method: 通过实验比较13名参与者在人工合作和部分自动化环境中的表现，使用GamePals框架支持实验。

Result: 比较评估人类合作与部分自动化的效果

Conclusion: 部分自动化可以在没有人类助手的情况下有效辅助玩家，解决助理可用性和共存的问题。

Abstract: Accessing video games is challenging for people with upper-limb impairments, especially when multiple inputs are required in rapid succession. Human cooperation, where a copilot assists the main player, has been proposed as a solution, but relying on a human assistant poses limitations in terms of availability and co-location. An alternative solution is to use partial automation, where the player is assisted by a software agent. In this work, we present a study with 13 participants with upper-limb impairments, comparatively evaluating how participants collaborate with their copilot in human cooperation and partial automation. The experiment is supported by GamePals, a modular framework that enables both human cooperation and partial automation on existing third-party video games.

</details>


### [11] ["Can You Tell Me?": Designing Copilots to Support Human Judgement in Online Information Seeking](https://arxiv.org/abs/2601.11284)
*Markus Bink,Marten Risius,Udo Kruschwitz,David Elsweiler*

Main category: cs.HC

TL;DR: 生成性AI改变了信息获取方式，但其流畅的回应可能导致用户过于依赖，阻碍独立思考。我们设计了一种会话助手，旨在促进信息评估而不是简单回答。试验结果表明，用户与助手互动深入，但未显著提高答案正确率或搜索参与度。


<details>
  <summary>Details</summary>
Motivation: 随着生成性AI工具的普及，用户需要更多支持以进行有效的信息评估，避免过度依赖和降低独立思考能力。

Method: 通过一项预注册的随机对照试验(N=261)，考察了包括基于聊天的助手在内的三种界面条件，采用混合方法分析。

Result: 本文提出了一种基于大型语言模型的会话助手，旨在支持用户的信息评估而非直接提供答案，促进数字素养技能的发展。

Conclusion: 该研究强调了教学助手的潜力与局限，提出在设计上需要平衡数字素养目标与效率需求。

Abstract: Generative AI (GenAI) tools are transforming information seeking, but their fluent, authoritative responses risk overreliance and discourage independent verification and reasoning. Rather than replacing the cognitive work of users, GenAI systems should be designed to support and scaffold it. Therefore, this paper introduces an LLM-based conversational copilot designed to scaffold information evaluation rather than provide answers and foster digital literacy skills. In a pre-registered, randomised controlled trial (N=261) examining three interface conditions including a chat-based copilot, our mixed-methods analysis reveals that users engaged deeply with the copilot, demonstrating metacognitive reflection. However, the copilot did not significantly improve answer correctness or search engagement, largely due to a "time-on-chat vs. exploration" trade-off and users' bias toward positive information. Qualitative findings reveal tension between the copilot's Socratic approach and users' desire for efficiency. These results highlight both the promise and pitfalls of pedagogical copilots, and we outline design pathways to reconcile literacy goals with efficiency demands.

</details>


### [12] [Seek and You Shall Find: Design & Evaluation of a Context-Aware Interactive Search Companion](https://arxiv.org/abs/2601.11287)
*Markus Bink,Marten Risius,Udo Kruschwitz,David Elsweiler*

Main category: cs.HC

TL;DR: 本研究展示了一种交互式搜索助手，通过提供上下文相关的提示，帮助用户优化搜索过程，最终提高搜索素养与用户的查询数量和结果查看数量。


<details>
  <summary>Details</summary>
Motivation: 许多用户在高风险领域（如健康）中有效在线搜索和批判性评估方面存在困难，通常还会高估自己的数字素养。

Method: 通过一个用户研究展示了助手的效果，尽管未来愿景涉及实时LLM自适应，但本研究利用了一个受控实施来测试相关干预策略。

Result: 此演示展示了一种交互式搜索助手，成功地鼓励用户进行更积极和探索性的搜索。

Conclusion: 轻量级的上下文指导可以提升搜索素养，并通过微学习的机会赋能用户。

Abstract: Many users struggle with effective online search and critical evaluation, especially in high-stakes domains like health, while often overestimating their digital literacy. Thus, in this demo, we present an interactive search companion that seamlessly integrates expert search strategies into existing search engine result pages. Providing context-aware tips on clarifying information needs, improving query formulation, encouraging result exploration, and mitigating biases, our companion aims to foster reflective search behaviour while minimising cognitive burden. A user study demonstrates the companion's successful encouragement of more active and exploratory search, leading users to submit 75 % more queries and view roughly twice as many results, as well as performance gains in difficult tasks. This demo illustrates how lightweight, contextual guidance can enhance search literacy and empower users through micro-learning opportunities. While the vision involves real-time LLM adaptivity, this study utilises a controlled implementation to test the underlying intervention strategies.

</details>


### [13] [ProjecTA: A Semi-Humanoid Robotic Teaching Assistant with In-Situ Projection for Guided Tours](https://arxiv.org/abs/2601.11328)
*Hanqing Zhou,Yichuan Zhang,Zihan Zhang,Wei Zhang,Chao Wang,Pengcheng An*

Main category: cs.HC

TL;DR: ProjecTA是一种新的机器人教学助手，通过空间投影减少学习者的认知负担，提高理解能力，优于传统的屏幕显示方式


<details>
  <summary>Details</summary>
Motivation: 探讨机器人教学助手在行走学习场景中如何更有效地传达信息

Method: 混合方法研究，涉及24名参与者，测试ProjecTA的有效性

Result: ProjecTA显著减少了学习者的认知负担，并在可用性、视觉展示的有用性和跨模态互补性方面优于屏幕基础的对手

Conclusion: 未来的机器人教学助手设计应重视空间投影的应用，以支持物理环境中的移动学习

Abstract: Robotic teaching assistants (TAs) often use body-mounted screens to deliver content. In nomadic, walk-and-talk learning, such as tours in makerspaces, these screens can distract learners from real-world objects, increasing extraneous cognitive load. HCI research lacks empirical comparisons of potential alternatives, such as robots with in-situ projection versus screen-based counterparts; little knowledge has been derived for designing such alternatives. We introduce ProjecTA, a semi-humanoid, gesture-capable TA that guides learners while projecting near-object overlays coordinated with speech and gestures. In a mixed-method study (N=24) in a university makerspace, ProjecTA significantly reduced extraneous load and outperformed its screen-based counterpart in perceived usability, usefulness of visual display, and cross-modal complementarity. Qualitative analyses revealed how ProjecTA's coordinated projections, gestures, and speech anchored explanations in place and time, enhancing understanding in ways a screen could not. We derive key design implications for future robotic TAs leveraging spatial projection to support mobile learning in physical environments.

</details>


### [14] [Human Factors in Immersive Analytics](https://arxiv.org/abs/2601.11365)
*Yi Li,Kadek Ananta Satriadi,Jiazhou Liu,Anjali Khurana,Zhiqing Wu,Benjamin Tag,Tim Dwyer*

Main category: cs.HC

TL;DR: 本文探讨了沉浸式分析十年后的发展，以及人因因素在这一领域的应用和标准化的重要性。


<details>
  <summary>Details</summary>
Motivation: 当前沉浸式分析技术缺乏物理和心理上的人机工程设计，阻碍了实际应用的普及。

Method: 通过在多个会议上举办的研讨会，收集研究者和从业者的意见，探讨评估沉浸式分析系统的新方法。

Result: 希望通过聚焦人因因素来改善沉浸式分析技术的设计与应用，从而推动未来的研究和实践。

Conclusion: 建立标准化的以人为本的验证协议对于沉浸式分析系统的广泛应用至关重要。

Abstract: It has been ten years since the term ''Immersive Analytics'' (IA) was coined and research interest in the topic remains strong. Researchers in this field have produced practical and conceptual knowledge concerning the use of emerging immersive spatial display and interaction technologies for sense-making tasks through a number of papers, surveys, and books. However, a lack of truly physically and psychologically ergonomic techniques, as well as standardized human-centric validation protocols for these, remains a significant barrier to wider acceptance of practical IA systems in ubiquitous applications. Building upon a series of workshops on immersive analytics at various conferences, this workshop aims to explore new approaches and establish standard practices for evaluating immersive analytics systems from a human factors perspective. We will gather immersive analytics researchers and practitioners to look closely at these human factors -- including cognitive and physical functions as well as behaviour and performance -- to see how they inform the design and deployment of immersive analytics techniques and applications and to inform future research.

</details>


### [15] [Show me the evidence: Evaluating the role of evidence and natural language explanations in AI-supported fact-checking](https://arxiv.org/abs/2601.11387)
*Greta Warren,Jingyi Sun,Irina Shklovski,Isabelle Augenstein*

Main category: cs.HC

TL;DR: 虽然AI解释在决策支持中重要，但证据的角色仍被低估。本研究揭示了证据在评估AI声明可靠性中的关键作用，以及其与自然语言解释结合时为决策提供的支持。


<details>
  <summary>Details</summary>
Motivation: 研究AI解释在决策支持中的作用，尤其是在证据方面的不足。

Method: 系统性地变化解释类型、AI预测确定性和AI系统建议的正确性，评估非专家参与者对声明的真实性和AI系统预测的反应。

Result: 参与者在所有实验条件下都依赖证据来验证AI的声明，尽管在自然语言解释出现时使用证据的频率较低，但在这些解释不足或有缺陷时，参与者仍然依赖证据。参与者还试图推断证据源的可靠性。

Conclusion: 证据在评估AI系统信息可靠性中的重要性，需要进一步研究如何有效呈现证据以及人们如何实际使用证据。

Abstract: Although much research has focused on AI explanations to support decisions in complex information-seeking tasks such as fact-checking, the role of evidence is surprisingly under-researched. In our study, we systematically varied explanation type, AI prediction certainty, and correctness of AI system advice for non-expert participants, who evaluated the veracity of claims and AI system predictions. Participants were provided the option of easily inspecting the underlying evidence. We found that participants consistently relied on evidence to validate AI claims across all experimental conditions. When participants were presented with natural language explanations, evidence was used less frequently although they relied on it when these explanations seemed insufficient or flawed. Qualitative data suggests that participants attempted to infer evidence source reliability, despite source identities being deliberately omitted. Our results demonstrate that evidence is a key ingredient in how people evaluate the reliability of information presented by an AI system and, in combination with natural language explanations, offers valuable support for decision-making. Further research is urgently needed to understand how evidence ought to be presented and how people engage with it in practice.

</details>


### [16] [Sociotechnical Challenges of Machine Learning in Healthcare and Social Welfare](https://arxiv.org/abs/2601.11417)
*Tyler Reinmund,Lars Kunze,Marina Jirotka*

Main category: cs.HC

TL;DR: 本文通过定性研究和工作坊，提出了一个框架，系统化了机器学习在医疗和社会福利中的十一种社会技术挑战，旨在改善机器学习工具的功能和应用。


<details>
  <summary>Details</summary>
Motivation: 为了解决机器学习工具在实际应用中与护理实践之间的不匹配问题，支持更系统的描述和比较。

Method: 结合定性实地研究、纵向部署研究回顾和与医疗及社会福利从业者的共同设计工作坊。

Result: 本文提出了一个框架，用于概念化机器学习在医疗保健和社会福利中的社会技术挑战，分析了机器学习工具的功能与护理实践结构之间的差异。

Conclusion: 通过清晰的分类和过程导向的描述，本文提供了分析机器学习工具在实际护理交付中如何运作和失效的视角，促进了对社会技术挑战的理解。

Abstract: Sociotechnical challenges of machine learning in healthcare and social welfare are mismatches between how a machine learning tool functions and the structure of care practices. While prior research has documented many such issues, existing accounts often attribute them either to designers' limited social understanding or to inherent technical constraints, offering limited support for systematic description and comparison across settings. In this paper, we present a framework for conceptualizing sociotechnical challenges of machine learning grounded in qualitative fieldwork, a review of longitudinal deployment studies, and co-design workshops with healthcare and social welfare practitioners. The framework comprises (1) a categorization of eleven sociotechnical challenges organized along an ML-enabled care pathway, and (2) a process-oriented account of the conditions through which these challenges emerge across design and use. By providing a parsimonious vocabulary and an explanatory lens focused on practice, this work supports more precise analysis of how machine learning tools function and malfunction within real-world care delivery.

</details>


### [17] [Interactive Narrative Analytics: Bridging Computational Narrative Extraction and Human Sensemaking](https://arxiv.org/abs/2601.11459)
*Brian Keith*

Main category: cs.HC

TL;DR: 本研究定义了互动叙事分析（INA），旨在通过计算和交互式分析帮助人们从大量信息中提取叙事。


<details>
  <summary>Details</summary>
Motivation: 解决信息过载和虚假信息带来的挑战，以从大量新闻中提取有意义的叙事。

Method: 定义互动叙事分析（INA）并结合计算叙事提取与交互式视觉分析以支持理解。

Result: INA方法允许通过计算方法和视觉界面进行叙事结构的交互探索，促进人类的解读。

Conclusion: 尽管面对可扩展性、交互性等挑战，INA在新闻分析、情报、科学文献探索和社交媒体分析等领域展现出广阔的机会。

Abstract: Information overload and misinformation create significant challenges in extracting meaningful narratives from large news collections. This paper defines the nascent field of Interactive Narrative Analytics (INA), which combines computational narrative extraction with interactive visual analytics to support sensemaking. INA approaches enable the interactive exploration of narrative structures through computational methods and visual interfaces that facilitate human interpretation. The field faces challenges in scalability, interactivity, knowledge integration, and evaluation standardization, yet offers promising opportunities across news analysis, intelligence, scientific literature exploration, and social media analysis. Through the combination of computational and human insight, INA addresses complex challenges in narrative sensemaking.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [18] [Verified Design of Robotic Autonomous Systems using Probabilistic Model Checking](https://arxiv.org/abs/2601.10720)
*Atef Azaiez,Alireza David Anisi*

Main category: cs.RO

TL;DR: 本文提出一种方法，利用概率模型检查（PMC）系统地评估和分析机器人自主系统（RAS）的设计概念，以实现经过验证的设计（VD）。


<details>
  <summary>Details</summary>
Motivation: 在机器人自主系统的设计中，及早考虑安全与可靠性等问题对于工程生命周期的后续步骤至关重要。

Method: 采用概率模型检查（PMC）方法，对一组系统设计概念进行系统评估和分析，使用PRISM作为工具。

Result: 通过案例研究，导出了针对农业机器人系统的特定设计评估标准，验证了所提方法的有效性。

Conclusion: 通过应用概率模型检查方法，可以有效地评估农业机器人系统的设计方案，从而提高其安全性和可靠性。

Abstract: Safety and reliability play a crucial role when designing Robotic Autonomous Systems (RAS). Early consideration of hazards, risks and mitigation actions -- already in the concept study phase -- are important steps in building a solid foundations for the subsequent steps in the system engineering life cycle. The complex nature of RAS, as well as the uncertain and dynamic environments the robots operate within, do not merely effect fault management and operation robustness, but also makes the task of system design concept selection, a hard problem to address. Approaches to tackle the mentioned challenges and their implications on system design, range from ad-hoc concept development and design practices, to systematic, statistical and analytical techniques of Model Based Systems Engineering. In this paper, we propose a methodology to apply a formal method, namely Probabilistic Model Checking (PMC), to enable systematic evaluation and analysis of a given set of system design concepts, ultimately leading to a set of Verified Designs (VD). We illustrate the application of the suggested methodology -- using PRISM as probabilistic model checker -- to a practical RAS concept selection use-case from agriculture robotics. Along the way, we also develop and present a domain-specific Design Evaluation Criteria for agri-RAS.

</details>


### [19] [Collaborative Continuum Robots: A Survey](https://arxiv.org/abs/2601.10721)
*Xinyu Li,Qian Tang,Guoxin Yin,Gang Zheng,Jessica Burgner-Kahrs,Cesare Stefanini,Ke Wu*

Main category: cs.RO

TL;DR: 该论文综述了协作连续机器人(CCRs)的最新进展，包括分类、设计、建模、规划和控制等方面，讨论了当前挑战与未来机会。


<details>
  <summary>Details</summary>
Motivation: 随着连续机器人在多个领域的应用增多，对协作连续机器人的研究需求也日益增长。

Method: 对协作连续机器人进行分类与系统总结，涵盖不同协作模式及其相关进展。

Result: 综述了CCR的三种协作模式及最新技术进展，强调未来研究方向。

Conclusion: 协作连续机器人在结构设计、建模、运动规划和控制方面仍面临挑战，但未来发展前景广阔。

Abstract: Continuum robots (CRs), owing to their compact structure, inherent compliance, and flexible deformation, have been widely applied in various fields. By coordinating multiple CRs to form collaborative continuum robots (CCRs), task adaptability, workspace, flexibility, load capacity, and operational stability can be further improved, thus offering significant advantages. In recent years, interest in this emerging field has grown steadily within the continuum-robotics community, accompanied by a consistent rise in related publications. By presenting a comprehensive overview of recent progress from different system-architecture levels, this survey provides a clear framework for research on CCRs. First, CCRs are classified into the three collaboration modes of separated collaboration, assistance collaboration, and parallel collaboration, with definitions provided. Next, advances in structural design, modeling, motion planning, and control for each mode are systematically summarized. Finally, current challenges and future opportunities for CCRs are discussed.

</details>


### [20] [A Survey of Real-Time Support, Analysis, and Advancements in ROS 2](https://arxiv.org/abs/2601.10722)
*Daniel Casini,Jian-Jia Chen,Jing Li,Federico Reghenzani,Harun Teper*

Main category: cs.RO

TL;DR: 本调查概述了对ROS~2的研究，重点分析其实时执行能力的改进，并分类总结相关贡献。


<details>
  <summary>Details</summary>
Motivation: 随着机器人应用的不断发展，ROS~2作为一个中间件框架，需增强对实时系统的支持，因此本调查旨在综述相关研究努力。

Method: 全面回顾相关文献，分析ROS~2的调度机制、通信模式及社区驱动的增强，提出支持分析和实验的技术以及分类标准。

Result: 该调查提供了ROS~2的内部调度机制、架构及其与DDS通信的交互的详细描述，并回顾了文献中对实时执行的主要贡献。

Conclusion: 通过建立分类法，帮助研究人员和从业者理解和提升ROS~2的实时能力。

Abstract: The Robot Operating System 2 (ROS~2) has emerged as a relevant middleware framework for robotic applications, offering modularity, distributed execution, and communication. In the last six years, ROS~2 has drawn increasing attention from the real-time systems community and industry. This survey presents a comprehensive overview of research efforts that analyze, enhance, and extend ROS~2 to support real-time execution. We first provide a detailed description of the internal scheduling mechanisms of ROS~2 and its layered architecture, including the interaction with DDS-based communication and other communication middleware. We then review key contributions from the literature, covering timing analysis for both single- and multi-threaded executors, metrics such as response time, reaction time, and data age, and different communication modes. The survey also discusses community-driven enhancements to the ROS~2 runtime, including new executor algorithm designs, real-time GPU management, and microcontroller support via micro-ROS. Furthermore, we summarize techniques for bounding DDS communication delays, message filters, and profiling tools that have been developed to support analysis and experimentation. To help systematize this growing body of work, we introduce taxonomies that classify the surveyed contributions based on different criteria. This survey aims to guide both researchers and practitioners in understanding and improving the real-time capabilities of ROS~2.

</details>


### [21] [Energy-Efficient Omnidirectional Locomotion for Wheeled Quadrupeds via Predictive Energy-Aware Nominal Gait Selection](https://arxiv.org/abs/2601.10723)
*Xu Yang,Wei Yang,Kaibo He,Bo Yang,Yanan Sui,Yilin Mo*

Main category: cs.RO

TL;DR: 提出了一种新的控制框架，通过预测能量消耗和强化学习优化轮足机器人的运动效率。


<details>
  <summary>Details</summary>
Motivation: 优化轮足机器人在多样环境中的能量效率

Method: 分层控制框架结合预测功率建模与残差强化学习

Result: 能量消耗降低了最高35%，同时保持相应的速度追踪性能

Conclusion: 通过大量模拟和实际实验验证了该框架在面对外部干扰时的强大性能。

Abstract: Wheeled-legged robots combine the efficiency of wheels with the versatility of legs, but face significant energy optimization challenges when navigating diverse environments. In this work, we present a hierarchical control framework that integrates predictive power modeling with residual reinforcement learning to optimize omnidirectional locomotion efficiency for wheeled quadrupedal robots. Our approach employs a novel power prediction network that forecasts energy consumption across different gait patterns over a 1-second horizon, enabling intelligent selection of the most energy-efficient nominal gait. A reinforcement learning policy then generates residual adjustments to this nominal gait, fine-tuning the robot's actions to balance energy efficiency with performance objectives. Comparative analysis shows our method reduces energy consumption by up to 35\% compared to fixed-gait approaches while maintaining comparable velocity tracking performance. We validate our framework through extensive simulations and real-world experiments on a modified Unitree Go1 platform, demonstrating robust performance even under external disturbances. Videos and implementation details are available at \href{https://sites.google.com/view/switching-wpg}{https://sites.google.com/view/switching-wpg}.

</details>


### [22] [Adaptive Sliding Mode Control for Vehicle Platoons with State-Dependent Friction Uncertainty](https://arxiv.org/abs/2601.10724)
*Rishabh Dev Yadav*

Main category: cs.RO

TL;DR: 本文提出了一种自适应滑模控制器，能够有效应对多机器人编队中摩擦力的不确定性，保证机器人间的安全距离和速度。


<details>
  <summary>Details</summary>
Motivation: 为了克服摩擦力建模和识别的挑战，提出一种新策略，以确保在各种扰动和不确定性条件下的安全距离和速度保持。

Method: 该方法包括两个阶段：首先由运动学控制器基于期望轨迹计算期望速度，然后由动力学模型生成执行指令。

Result: 本论文提出了一种新的自适应滑模控制器，旨在处理多机器人编队控制中的未知和复杂摩擦力行为，特别适用于轮式移动机器人车队。

Conclusion: 通过将运动学和动力学分离，本控制器提供了更高效和稳健的控制策略，特别是在存在外部干扰和系统参数不确定时。

Abstract: Multi-robot formation control has various applications in domains such as vehicle troops, platoons, payload transportation, and surveillance. Maintaining formation in a vehicle platoon requires designing a suitable control scheme that can tackle external disturbances and uncertain system parameters while maintaining a predefined safe distance between the robots. A crucial challenge in this context is dealing with the unknown/uncertain friction forces between wheels and the ground, which vary with changes in road surface, wear in tires, and speed of the vehicle. Although state-of-the-art adaptive controllers can handle a priori bounded uncertainties, they struggle with accurately modeling and identifying frictional forces, which are often state-dependent and cannot be a priori bounded.
  This thesis proposes a new adaptive sliding mode controller for wheeled mobile robot-based vehicle platoons that can handle the unknown and complex behavior of frictional forces without prior knowledge of their parameters and structures. The controller uses the adaptive sliding mode control techniques to regulate the platoon's speed and maintain a predefined inter-robot distance, even in the presence of external disturbances and uncertain system parameters. This approach involves a two-stage process: first, the kinematic controller calculates the desired velocities based on the desired trajectory; and second, the dynamics model generates the commands to achieve the desired motion. By separating the kinematics and dynamics of the robot, this approach can simplify the control problem and allow for more efficient and robust control of the wheeled mobile robot.

</details>


### [23] [Multi-Agent Formation Navigation Using Diffusion-Based Trajectory Generation](https://arxiv.org/abs/2601.10725)
*Hieu Do Quang,Chien Truong-Quoc,Quoc Van Tran*

Main category: cs.RO

TL;DR: 本文提出了一种扩散基础的规划者，旨在提升复杂环境中的领导-追随者编队控制表现。


<details>
  <summary>Details</summary>
Motivation: 在复杂环境中实现领导-追随者的编队控制，尤其是在存在障碍物的情况下。

Method: 通过扩散策略，生成两个领导者之间的中点轨迹，以此定义平面编队的运动路径，追随者则通过基于距离限制的控制器来保持所需的编队几何形状。

Result: 提出了一种基于扩散的规划方法，能够有效生成领导者间的轨迹与形状，并促进追随者的编队几何形状。

Conclusion: 扩散模型在多智能体编队规划中表现出了良好的可靠性，尽管在狭窄的无障碍空间或未见过的障碍配置下存在一定的失败。

Abstract: This paper introduces a diffusion-based planner for leader--follower formation control in cluttered environments. The diffusion policy is used to generate the trajectory of the midpoint of two leaders as a rigid bar in the plane, thereby defining their desired motion paths in a planar formation. While the followers track the leaders and form desired foramtion geometry using a distance-constrained formation controller based only on the relative positions in followers' local coordinates. The proposed approach produces smooth motions and low tracking errors, with most failures occurring in narrow obstacle-free space, or obstacle configurations that are not in the training data set. Simulation results demonstrate the potential of diffusion models for reliable multi-agent formation planning.

</details>


### [24] [Bidirectional Human-Robot Communication for Physical Human-Robot Interaction](https://arxiv.org/abs/2601.10796)
*Junxiang Wang,Cindy Wang,Rana Soltani Zarrin,Zackory Erickson*

Main category: cs.RO

TL;DR: 本论文提出BRIDGE系统，利用大型语言模型实现用户通过自然语言实时修改机器人规划轨迹，并提供口头反馈，显著提高用户体验的直观性和系统的透明性。


<details>
  <summary>Details</summary>
Motivation: 现有的物理人机交互系统缺乏适应用户偏好的能力和对其行为的透明性。

Method: 使用一个大型语言模型来解释用户命令暗示的轨迹修改，并通过自然语言实时调整机器人的规划轨迹。

Result: 在包含18名老年人的用户研究中，BRIDGE系统在三项辅助任务中成功让参与者实时修改机器人轨迹，并在互动性和透明性上获得显著更高的评分。

Conclusion: 机器人提供的口头反馈对于提升用户体验的直观性至关重要。

Abstract: Effective physical human-robot interaction requires systems that are not only adaptable to user preferences but also transparent about their actions. This paper introduces BRIDGE, a system for bidirectional human-robot communication in physical assistance. Our method allows users to modify a robot's planned trajectory -- position, velocity, and force -- in real time using natural language. We utilize a large language model (LLM) to interpret any trajectory modifications implied by user commands in the context of the planned motion and conversation history. Importantly, our system provides verbal feedback in response to the user, either assuring any resulting changes or posing a clarifying question. We evaluated our method in a user study with 18 older adults across three assistive tasks, comparing BRIDGE to an ablation without verbal feedback and a baseline. Results show that participants successfully used the system to modify trajectories in real time. Moreover, the bidirectional feedback led to significantly higher ratings of interactivity and transparency, demonstrating that the robot's verbal response is critical for a more intuitive user experience. Videos and code can be found on our project website: https://bidir-comm.github.io/

</details>


### [25] [SurfSLAM: Sim-to-Real Underwater Stereo Reconstruction For Real-Time SLAM](https://arxiv.org/abs/2601.10814)
*Onur Bagoren,Seth Isaacson,Sacchin Sundar,Yung-Ching Sun,Anja Sheppard,Haoyu Ma,Abrar Shariff,Ram Vasudevan,Katherine A. Skinner*

Main category: cs.RO

TL;DR: 本文提出了一种新颖的框架，通过模拟数据和自我监督微调，改进水下立体深度估计，并在真实水下环境中实现了高效的定位和3D重建。


<details>
  <summary>Details</summary>
Motivation: 水下机器人在定位和映射时面临着图像退化、缺乏纹理和训练数据不足等挑战，迫切需要改进水下立体深度估计的方法。

Method: 使用模拟数据进行sim-to-real训练，并结合IMU、气压和多普勒速度计(DVL)测量，开发新的实时水下SLAM框架。

Result: 通过广泛的实验，展示了所提出的训练方法在真实数据上改善水下立体估计的优势，并提升了复杂沉船现场的轨迹估计和3D重建的准确性。

Conclusion: 提出的框架通过模拟数据和自我监督微调，提升了水下立体估计的准确性，并在复杂的沉船场景中实现了精确的轨迹估计和3D重建。

Abstract: Localization and mapping are core perceptual capabilities for underwater robots. Stereo cameras provide a low-cost means of directly estimating metric depth to support these tasks. However, despite recent advances in stereo depth estimation on land, computing depth from image pairs in underwater scenes remains challenging. In underwater environments, images are degraded by light attenuation, visual artifacts, and dynamic lighting conditions. Furthermore, real-world underwater scenes frequently lack rich texture useful for stereo depth estimation and 3D reconstruction. As a result, stereo estimation networks trained on in-air data cannot transfer directly to the underwater domain. In addition, there is a lack of real-world underwater stereo datasets for supervised training of neural networks. Poor underwater depth estimation is compounded in stereo-based Simultaneous Localization and Mapping (SLAM) algorithms, making it a fundamental challenge for underwater robot perception. To address these challenges, we propose a novel framework that enables sim-to-real training of underwater stereo disparity estimation networks using simulated data and self-supervised finetuning. We leverage our learned depth predictions to develop \algname, a novel framework for real-time underwater SLAM that fuses stereo cameras with IMU, barometric, and Doppler Velocity Log (DVL) measurements. Lastly, we collect a challenging real-world dataset of shipwreck surveys using an underwater robot. Our dataset features over 24,000 stereo pairs, along with high-quality, dense photogrammetry models and reference trajectories for evaluation. Through extensive experiments, we demonstrate the advantages of the proposed training approach on real-world data for improving stereo estimation in the underwater domain and for enabling accurate trajectory estimation and 3D reconstruction of complex shipwreck sites.

</details>


### [26] [Approximately Optimal Global Planning for Contact-Rich SE(2) Manipulation on a Graph of Reachable Sets](https://arxiv.org/abs/2601.10827)
*Simin Liu,Tong Zhao,Bernhard Paus Graesdal,Peter Werner,Jiuguang Wang,John Dolan,Changliu Liu,Tao Pang*

Main category: cs.RO

TL;DR: 提出了一种新方法计算近似最优的接触丰富操纵计划，显著提高了效率和成功率。


<details>
  <summary>Details</summary>
Motivation: 现有的基于模型的接触丰富操纵计划主要关注可行性而非最优性，限制了接触丰富操纵的优势

Method: 新范式计算近似最优的操纵者计划

Result: 在一个具有挑战性的接触丰富任务上，该方法比领先的计划者提高了61%的任务成本效率，并在250次查询中达到了91%的成功率，查询时间保持在1分钟内

Conclusion: 全局优化的接触丰富操纵在现实任务中变得可行。

Abstract: If we consider human manipulation, it is clear that contact-rich manipulation (CRM)-the ability to use any surface of the manipulator to make contact with objects-can be far more efficient and natural than relying solely on end-effectors (i.e., fingertips). However, state-of-the-art model-based planners for CRM are still focused on feasibility rather than optimality, limiting their ability to fully exploit CRM's advantages. We introduce a new paradigm that computes approximately optimal manipulator plans. This approach has two phases. Offline, we construct a graph of mutual reachable sets, where each set contains all object orientations reachable from a starting object orientation and grasp. Online, we plan over this graph, effectively computing and sequencing local plans for globally optimized motion. On a challenging, representative contact-rich task, our approach outperforms a leading planner, reducing task cost by 61%. It also achieves a 91% success rate across 250 queries and maintains sub-minute query times, ultimately demonstrating that globally optimized contact-rich manipulation is now practical for real-world tasks.

</details>


### [27] [IMU-based Real-Time Crutch Gait Phase and Step Detections in Lower-Limb Exoskeletons](https://arxiv.org/abs/2601.10832)
*Anis R. Shakkour,David Hexner,Yehuda Bitton,Avishai Sintov*

Main category: cs.RO

TL;DR: 本文提出了一种基于单个低成本IMU的步态阶段检测框架，使用深度学习和有限状态机提高性能，TCN架构表现最佳。


<details>
  <summary>Details</summary>
Motivation: 提高下肢外骨骼和义肢的实时步态相位检测精度，确保用户安全，避免复杂的硬件控制延迟

Method: 低成本IMU集成在助行器手柄中进行步态相位和步伐检测

Result: 在健康参与者上训练的模型能够成功检测到94%的助行器步伐，并且能够泛化到瘫痪用户

Conclusion: 该系统提供一种高性能、成本有效的解决方案，适用于实时外骨骼控制。

Abstract: Lower limb exoskeletons and prostheses require precise, real time gait phase and step detections to ensure synchronized motion and user safety. Conventional methods often rely on complex force sensing hardware that introduces control latency. This paper presents a minimalist framework utilizing a single, low cost Inertial-Measurement Unit (IMU) integrated into the crutch hand grip, eliminating the need for mechanical modifications. We propose a five phase classification system, including standard gait phases and a non locomotor auxiliary state, to prevent undesired motion. Three deep learning architectures were benchmarked on both a PC and an embedded system. To improve performance under data constrained conditions, models were augmented with a Finite State Machine (FSM) to enforce biomechanical consistency. The Temporal Convolutional Network (TCN) emerged as the superior architecture, yielding the highest success rates and lowest latency. Notably, the model generalized to a paralyzed user despite being trained exclusively on healthy participants. Achieving a 94% success rate in detecting crutch steps, this system provides a high performance, cost effective solution for real time exoskeleton control.

</details>


### [28] [Is open robotics innovation a threat to international peace and security?](https://arxiv.org/abs/2601.10877)
*Ludovic Righetti,Vincent Boulanin*

Main category: cs.RO

TL;DR: 开放获取促进了机器人研究和发展的同时，也带来了双重用途风险，作者建议制定行业特定的指导原则和监管措施。


<details>
  <summary>Details</summary>
Motivation: 开放获取在推动机器人发展中至关重要，但同时也需面对其带来的潜在风险，特别是在军事和有害用途方面。

Method: 提出四项实践作为改善方向，包括负责任的机器人教育、风险评估激励、高风险材料传播的调控以及确定红线。

Result: 本文探讨了开放获取对机器人领域的影响，以及开放性如何增加双重用途风险。作者呼吁机器人社区制定特定的指导原则和可能的监管措施，以应对这些风险。

Conclusion: 机器人领域需要特定的指导和监管，以平衡开放性与双重用途风险。

Abstract: Open access to publication, software and hardware is central to robotics: it lowers barriers to entry, supports reproducible science and accelerates reliable system development. However, openness also exacerbates the inherent dual-use risks associated with research and innovation in robotics. It lowers barriers for states and non-state actors to develop and deploy robotics systems for military use and harmful purposes. Compared to other fields of engineering where dual-use risks are present - e.g., those that underlie the development of weapons of mass destruction (chemical, biological, radiological, and nuclear weapons) and even the field of AI, robotics offers no specific regulation and little guidance as to how research and innovation may be conducted and disseminated responsibly. While other fields can be used for guidance, robotics has its own needs and specificities which have to be taken into account. The robotics community should therefore work toward its own set of sector-specific guidance and possibly regulation. To that end, we propose a roadmap focusing on four practices: a) education in responsible robotics; b) incentivizing risk assessment; c) moderating the diffusion of high-risk material; and d) developing red lines.

</details>


### [29] [Where to Touch, How to Contact: Hierarchical RL-MPC Framework for Geometry-Aware Long-Horizon Dexterous Manipulation](https://arxiv.org/abs/2601.10930)
*Zhixian Xie,Yu Xiang,Michael Posa,Wanxin Jin*

Main category: cs.RO

TL;DR: 通过分层强化学习-模型预测控制框架，解决接触丰富的灵巧操作中的数据需求和推广能力问题。


<details>
  <summary>Details</summary>
Motivation: 解决现有端到端策略在数据、模拟到现实转移和任务泛化等方面的局限性，利用灵巧操作的层次特性。

Method: 采用高级强化学习政策预测接触意图，并通过低级模型预测控制优化接触模式，从而生成机器人动作。

Result: 该研究提出了一种分层RL-MPC框架，用于解决接触丰富的灵巧操作中的几何、运动学和接触动态之间的复杂关系。

Conclusion: 该框架在几何泛化推送和物体3D重定位任务中表现出近乎100%的成功率，数据需求减少10倍，并实现零-shot的模拟到现实转移。

Abstract: A key challenge in contact-rich dexterous manipulation is the need to jointly reason over geometry, kinematic constraints, and intricate, nonsmooth contact dynamics. End-to-end visuomotor policies bypass this structure, but often require large amounts of data, transfer poorly from simulation to reality, and generalize weakly across tasks/embodiments. We address those limitations by leveraging a simple insight: dexterous manipulation is inherently hierarchical - at a high level, a robot decides where to touch (geometry) and move the object (kinematics); at a low level it determines how to realize that plan through contact dynamics. Building on this insight, we propose a hierarchical RL--MPC framework in which a high-level reinforcement learning (RL) policy predicts a contact intention, a novel object-centric interface that specifies (i) an object-surface contact location and (ii) a post-contact object-level subgoal pose. Conditioned on this contact intention, a low-level contact-implicit model predictive control (MPC) optimizes local contact modes and replans with contact dynamics to generate robot actions that robustly drive the object toward each subgoal. We evaluate the framework on non-prehensile tasks, including geometry-generalized pushing and object 3D reorientation. It achieves near-100% success with substantially reduced data (10x less than end-to-end baselines), highly robust performance, and zero-shot sim-to-real transfer.

</details>


### [30] [Crane Lowering Guidance Using a Attachable Camera Module for Driver Vision Support](https://arxiv.org/abs/2601.11026)
*HyoJae Kang,SunWoo Ahn,InGyu Choi,GeonYeong Go,KunWoo Son,Min-Sung Kang*

Main category: cs.RO

TL;DR: 本研究提出了一种可附加摄像头模块的系统，旨在改善起重机操作时在下降阶段的安全性，通过实时图像传输为操作员提供隐蔽着陆区的可视参考。


<details>
  <summary>Details</summary>
Motivation: 起重机在降落阶段，负载阻碍操作员视线，传统依赖口头或手势指令影响安全性，故需要改进。

Method: 研究设计了一个可通过吸附杯安装到负载上的摄像头模块，该模块包括单板计算机、电池和紧凑型摄像头，能够实时流式传输和处理负载下方地面的图像。

Result: 初步实验验证了该摄像头模块的实时图像获取和传输的可行性。

Conclusion: 该系统可以显著提升施工现场的安全性，为起重机操作员提供瞬时的可视参考。

Abstract: Cranes have long been essential equipment for lifting and placing heavy loads in construction projects. This study focuses on the lowering phase of crane operation, the stage in which the load is moved to the desired location. During this phase, a constant challenge exists: the load obstructs the operator's view of the landing point. As a result, operators traditionally have to rely on verbal or gestural instructions from ground personnel, which significantly impacts site safety. To alleviate this constraint, the proposed system incorporates a attachable camera module designed to be attached directly to the load via a suction cup. This module houses a single-board computer, battery, and compact camera. After installation, it streams and processes images of the ground directly below the load in real time to generate installation guidance. Simultaneously, this guidance is transmitted to and monitored by a host computer. Preliminary experiments were conducted by attaching this module to a test object, confirming the feasibility of real-time image acquisition and transmission. This approach has the potential to significantly improve safety on construction sites by providing crane operators with an instant visual reference of hidden landing zones.

</details>


### [31] [H-AIM: Orchestrating LLMs, PDDL, and Behavior Trees for Hierarchical Multi-Robot Planning](https://arxiv.org/abs/2601.11063)
*Haishan Zeng,Peng Li*

Main category: cs.RO

TL;DR: H-AIM是一种新的多机器人任务规划框架，通过三级架构提升异构机器人团队的长任务执行能力，实现任务成功率从12%提高到55%。


<details>
  <summary>Details</summary>
Motivation: 在具身人工智能中，异构机器人团队执行长任务的能力是一个关键挑战，尤其在高层指令的执行上存在困难。

Method: H-AIM框架包围三个主要阶段：1）利用大语言模型解析指令，生成PDDL问题描述；2）结合大语言模型的语义推理与传统规划器的搜索能力，生成优化的行动序列；3）将结果计划编译为行为树，进行反应控制。

Result: 提出H-AIM框架，通过三阶段级联架构显著提升了任务成功率和目标条件回忆率。

Conclusion: H-AIM框架有效地结合了大语言模型的语义解析和传统规划器的搜索能力，在动态多机器人协调和长期推理方面表现出色。

Abstract: In embodied artificial intelligence, enabling heterogeneous robot teams to execute long-horizon tasks from high-level instructions remains a critical challenge. While large language models (LLMs) show promise in instruction parsing and preliminary planning, they exhibit limitations in long-term reasoning and dynamic multi-robot coordination. We propose Hierarchical Autonomous Intelligent Multi-Robot Planning(H-AIM), a novel embodied multi-robot task planning framework that addresses these issues through a three-stage cascaded architecture: 1) It leverages an LLM to parse instructions and generate Planning Domain Definition Language (PDDL) problem descriptions, thereby transforming commands into formal planning problems; 2) It combines the semantic reasoning of LLMs with the search capabilities of a classical planner to produce optimized action sequences; 3) It compiles the resulting plan into behavior trees for reactive control. The framework supports dynamically sized heterogeneous robot teams via a shared blackboard mechanism for communication and state synchronization. To validate our approach, we introduce the MACE-THOR benchmark dataset, comprising 42 complex tasks across 8 distinct household layouts. Experimental results demonstrate that H-AIM achieves a remarkable performance improvement, elevating the task success rate from 12% to 55% and boosting the goal condition recall from 32% to 72% against the strongest baseline, LaMMA-P.

</details>


### [32] [A3D: Adaptive Affordance Assembly with Dual-Arm Manipulation](https://arxiv.org/abs/2601.11076)
*Jiaqi Liang,Yue Chen,Qize Yu,Yan Shen,Haipeng Zhang,Hao Dong,Ruihai Wu*

Main category: cs.RO

TL;DR: 提出A3D框架，通过学习自适应能力，优化机器人在家具组装中的支持和稳定策略，有效处理多样的部件几何形状。


<details>
  <summary>Details</summary>
Motivation: 家具组装是机器人面临的一项关键挑战，需实现精准的双臂协调以完成任务。

Method: 利用密集的点级几何表示模型部件交互模式，并引入适应模块根据反馈动态调整支持策略。

Result: 提出一种名为A3D的框架，能够识别家具部件上的最佳支持和稳定位置。

Conclusion: 实验表明，该框架在模拟和真实环境中均能有效推广到不同的部件几何形状和家具分类。

Abstract: Furniture assembly is a crucial yet challenging task for robots, requiring precise dual-arm coordination where one arm manipulates parts while the other provides collaborative support and stabilization. To accomplish this task more effectively, robots need to actively adapt support strategies throughout the long-horizon assembly process, while also generalizing across diverse part geometries. We propose A3D, a framework which learns adaptive affordances to identify optimal support and stabilization locations on furniture parts. The method employs dense point-level geometric representations to model part interaction patterns, enabling generalization across varied geometries. To handle evolving assembly states, we introduce an adaptive module that uses interaction feedback to dynamically adjust support strategies during assembly based on previous interactions. We establish a simulation environment featuring 50 diverse parts across 8 furniture types, designed for dual-arm collaboration evaluation. Experiments demonstrate that our framework generalizes effectively to diverse part geometries and furniture categories in both simulation and real-world settings.

</details>


### [33] [Visual Marker Search for Autonomous Drone Landing in Diverse Urban Environments](https://arxiv.org/abs/2601.11078)
*Jiaohong Yao,Linfeng Liang,Yao Deng,Xi Zheng,Richard Han,Yuankai Qi*

Main category: cs.RO

TL;DR: 本研究评估了无人机在复杂城市环境中基于标记的自主着陆的有效性，使用模拟平台探索不同策略和条件对其性能的影响。


<details>
  <summary>Details</summary>
Motivation: 基于标记的着陆在无人机交付和返回基地系统中被广泛使用，但大多数方法假设理想的着陆场地可见性和传感器性能，限制了在复杂城市环境中的稳健性。

Method: 在AirSim平台上进行基于模拟的评估，系统变化城市布局、光照和天气条件，使用机载相机传感器进行标记检测和障碍物规避。

Result: 基准测试两种启发式覆盖模式和一种基于强化学习的代理，分析探索策略和场景复杂性对成功率、路径效率和稳健性的影响。

Conclusion: 结果强调在多样化、与传感器相关的条件下评估基于标记的自主着陆的必要性，以指导可靠航空导航系统的开发。

Abstract: Marker-based landing is widely used in drone delivery and return-to-base systems for its simplicity and reliability. However, most approaches assume idealized landing site visibility and sensor performance, limiting robustness in complex urban settings. We present a simulation-based evaluation suite on the AirSim platform with systematically varied urban layouts, lighting, and weather to replicate realistic operational diversity. Using onboard camera sensors (RGB for marker detection and depth for obstacle avoidance), we benchmark two heuristic coverage patterns and a reinforcement learning-based agent, analyzing how exploration strategy and scene complexity affect success rate, path efficiency, and robustness. Results underscore the need to evaluate marker-based autonomous landing under diverse, sensor-relevant conditions to guide the development of reliable aerial navigation systems.

</details>


### [34] [Learning Quadrupedal Locomotion for a Heavy Hydraulic Robot Using an Actuator Model](https://arxiv.org/abs/2601.11143)
*Minho Lee,Hyeonseok Kim,Jin Tak Kim,Sangshin Park,Jeong Hyun Lee,Jungsan Cho,Jemin Hwangbo*

Main category: cs.RO

TL;DR: 本文提出了一种新的液压动力学驱动的分析型致动器模型，以解决大型液压机器人的仿真到现实转移问题，展示了其在强化学习环境中的应用潜力和优势。


<details>
  <summary>Details</summary>
Motivation: 针对大型液压机器人的仿真到现实转移问题，因响应速度慢和复杂流体动力学而面临挑战。

Method: 提出了一种基于液压动力学的分析型致动器模型，以代表复杂的致动器，并且能够在不到1微秒内预测12个致动器的关节扭矩，适用于强化学习环境。

Result: 将提议的模型与基于神经网络的致动器模型进行比较，证明了在数据有限的场景中，我们的模型具有优势。所训练的运动策略成功部署在重达300公斤的液压四足机器人上。

Conclusion: 本研究首次成功实现了重型液压四足机器人在强化学习下的稳定和鲁棒的指令跟踪运动，展示了先进的仿真到现实转移能力。

Abstract: The simulation-to-reality (sim-to-real) transfer of large-scale hydraulic robots presents a significant challenge in robotics because of the inherent slow control response and complex fluid dynamics. The complex dynamics result from the multiple interconnected cylinder structure and the difference in fluid rates of the cylinders. These characteristics complicate detailed simulation for all joints, making it unsuitable for reinforcement learning (RL) applications. In this work, we propose an analytical actuator model driven by hydraulic dynamics to represent the complicated actuators. The model predicts joint torques for all 12 actuators in under 1 microsecond, allowing rapid processing in RL environments. We compare our model with neural network-based actuator models and demonstrate the advantages of our model in data-limited scenarios. The locomotion policy trained in RL with our model is deployed on a hydraulic quadruped robot, which is over 300 kg. This work is the first demonstration of a successful transfer of stable and robust command-tracking locomotion with RL on a heavy hydraulic quadruped robot, demonstrating advanced sim-to-real transferability.

</details>


### [35] [Adaptive Monitoring of Stochastic Fire Front Processes via Information-seeking Predictive Control](https://arxiv.org/abs/2601.11231)
*Savvas Papaioannou,Panayiotis Kolios,Christos G. Panayiotou,Marios M. Polycarpou*

Main category: cs.RO

TL;DR: 研究了通过移动代理自适应监测森林火灾的方法，并提出了一种结合传感、估计和控制的随机最优控制问题的解决方案。


<details>
  <summary>Details</summary>
Motivation: 探讨现有方法的局限性，如过于依赖线性-高斯假设及缺乏明确的性能保证，旨在提出新的集成方案。

Method: 将火灾前线监测任务表述为随机最优控制问题，并推导出对于特定模型的最优递归贝叶斯估计器，最终转换为有限时域的马尔可夫决策过程。

Result: 本文解决了使用移动代理（例如无人机）自适应监测森林火灾前线的问题。通过优化其轨迹以提高传感器数据收集的精度，从而影响火灾传播估计的准确性。

Conclusion: 通过将监测任务形式化为随机最优控制问题，并设计基于自适应搜索算法的控制法则，克服了现有方法的局限性，确保了性能保证。

Abstract: We consider the problem of adaptively monitoring a wildfire front using a mobile agent (e.g., a drone), whose trajectory determines where sensor data is collected and thus influences the accuracy of fire propagation estimation. This is a challenging problem, as the stochastic nature of wildfire evolution requires the seamless integration of sensing, estimation, and control, often treated separately in existing methods. State-of-the-art methods either impose linear-Gaussian assumptions to establish optimality or rely on approximations and heuristics, often without providing explicit performance guarantees. To address these limitations, we formulate the fire front monitoring task as a stochastic optimal control problem that integrates sensing, estimation, and control. We derive an optimal recursive Bayesian estimator for a class of stochastic nonlinear elliptical-growth fire front models. Subsequently, we transform the resulting nonlinear stochastic control problem into a finite-horizon Markov decision process and design an information-seeking predictive control law obtained via a lower confidence bound-based adaptive search algorithm with asymptotic convergence to the optimal policy.

</details>


### [36] [VLAgents: A Policy Server for Efficient VLA Inference](https://arxiv.org/abs/2601.11250)
*Tobias Jülg,Khaled Gamal,Nisarga Nilavadi,Pierre Krack,Seongjin Bien,Michael Krawez,Florian Walter,Wolfram Burgard*

Main category: cs.RO

TL;DR: VLAgents是一个模块化策略服务器，简化了Vision-Language-Action模型的部署，改进了通信效率，提升了整体性能。


<details>
  <summary>Details</summary>
Motivation: 针对现有VLA模型部署复杂、接口碎片化及通信延迟问题。

Method: 介绍一种模块化策略服务器VLAgents，用于统一VLA推理。

Result: VLAgents通过支持零拷贝共享内存和压缩流式传输，优化了本地与远程通信，并整合了七种策略，显著提升了性能。

Conclusion: VLAgents在基准测试中表现优于现有的政策服务器，展现了其在机器人控制领域的潜力。

Abstract: The rapid emergence of Vision-Language-Action models (VLAs) has a significant impact on robotics. However, their deployment remains complex due to the fragmented interfaces and the inherent communication latency in distributed setups. To address this, we introduce VLAgents, a modular policy server that abstracts VLA inferencing behind a unified Gymnasium-style protocol. Crucially, its communication layer transparently adapts to the context by supporting both zero-copy shared memory for high-speed simulation and compressed streaming for remote hardware. In this work, we present the architecture of VLAgents and validate it by integrating seven policies -- including OpenVLA and Pi Zero. In a benchmark with both local and remote communication, we further demonstrate how it outperforms the default policy servers provided by OpenVLA, OpenPi, and LeRobot. VLAgents is available at https://github.com/RobotControlStack/vlagents

</details>


### [37] [Skill-Aware Diffusion for Generalizable Robotic Manipulation](https://arxiv.org/abs/2601.11266)
*Aoshen Huang,Jiaming Chen,Jiyu Cheng,Ran Song,Wei Pan,Wei Zhang*

Main category: cs.RO

TL;DR: 提出了一种新的机器人操控方法(SADiff)，通过结合技能水平信息来改善模型的鲁棒通用性。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常单独模型任务，忽略了技能水平信息，而同一技能内的任务具有相似的运动模式。

Method: 通过技能感知编码模块和受约束的扩散模型，学习技能特定的表示，并利用技能回收转换策略优化从2D运动流到3D动作的映射。

Result: 实验验证SADiff在仿真和真实世界环境中都表现出良好的性能和通用性。

Conclusion: SADiff在不同操控任务中的表现和普遍性良好，展示了技能水平信息的重要性。

Abstract: Robust generalization in robotic manipulation is crucial for robots to adapt flexibly to diverse environments. Existing methods usually improve generalization by scaling data and networks, but model tasks independently and overlook skill-level information. Observing that tasks within the same skill share similar motion patterns, we propose Skill-Aware Diffusion (SADiff), which explicitly incorporates skill-level information to improve generalization. SADiff learns skill-specific representations through a skill-aware encoding module with learnable skill tokens, and conditions a skill-constrained diffusion model to generate object-centric motion flow. A skill-retrieval transformation strategy further exploits skill-specific trajectory priors to refine the mapping from 2D motion flow to executable 3D actions. Furthermore, we introduce IsaacSkill, a high-fidelity dataset containing fundamental robotic skills for comprehensive evaluation and sim-to-real transfer. Experiments in simulation and real-world settings show that SADiff achieves good performance and generalization across various manipulation tasks. Code, data, and videos are available at https://sites.google.com/view/sa-diff.

</details>


### [38] [Distributed Control Barrier Functions for Safe Multi-Vehicle Navigation in Heterogeneous USV Fleets](https://arxiv.org/abs/2601.11335)
*Tyler Paine,Brendan Long,Jeremy Wenger,Michael DeFilippo,James Usevitch,Michael Benjamin*

Main category: cs.RO

TL;DR: 提出一种利用控制障碍函数的分布式安全控制过滤器，增强无人船的碰撞避免能力，并验证其在异构舰队中的有效性。


<details>
  <summary>Details</summary>
Motivation: 解决异构无人船队在碰撞避免中面临的决策过程差异和实时共享轨迹及控制值的限制

Method: 在每个无人船上添加控制过滤器，利用控制障碍函数（CBF）理论实现分布式安全控制

Result: 在不同无人船和人类操作船只的实际实验中验证了方法的有效性，并对比了CBF方法与基于碰撞规则的行为方法，发现组合二者可以实现最佳的安全性和效率

Conclusion: 将CBF方法与碰撞规则行为相结合可在保持安全性的同时提高效率，适用于多种平台的异构无人船队。

Abstract: Collision avoidance in heterogeneous fleets of uncrewed vessels is challenging because the decision-making processes and controllers often differ between platforms, and it is further complicated by the limitations on sharing trajectories and control values in real-time. This paper presents a pragmatic approach that addresses these issues by adding a control filter on each autonomous vehicle that assumes worst-case behavior from other contacts, including crewed vessels. This distributed safety control filter is developed using control barrier function (CBF) theory and the application is clearly described to ensure explainability of these safety-critical methods. This work compares the worst-case CBF approach with a Collision Regulations (COLREGS) behavior-based approach in simulated encounters. Real-world experiments with three different uncrewed vessels and a human operated vessel were performed to confirm the approach is effective across a range of platforms and is robust to uncooperative behavior from human operators. Results show that combining both CBF methods and COLREGS behaviors achieves the best safety and efficiency.

</details>


### [39] [The Mini Wheelbot Dataset: High-Fidelity Data for Robot Learning](https://arxiv.org/abs/2601.11394)
*Henrik Hose,Paul Brunzema,Devdutt Subhasish,Sebastian Trimpe*

Main category: cs.RO

TL;DR: 本论文创建了一个Mini Wheelbot的动态数据集，旨在解决获取高质量实时数据的困难，以促进不稳定系统控制算法的研究。


<details>
  <summary>Details</summary>
Motivation: 许多研究人员在开发不稳定系统的学习控制算法时面临缺乏高质量实时数据的问题，尤其是受到专业机器人硬件的限制。

Method: 通过多种控制范式在不同硬件实例和表面上执行实验，收集1 kHz同步数据，包括传感器读数、状态估计和运动捕捉系统的真实位置。

Result: 数据集涵盖了一系列实验数据，支持动态模型学习、状态估计和时间序列分类等常见机器人算法的基准测试。

Conclusion: 本研究为Mini Wheelbot创建了一个高质量的动态数据集，促进了不稳定系统的学习控制算法的研究。

Abstract: The development of robust learning-based control algorithms for unstable systems requires high-quality, real-world data, yet access to specialized robotic hardware remains a significant barrier for many researchers. This paper introduces a comprehensive dynamics dataset for the Mini Wheelbot, an open-source, quasi-symmetric balancing reaction wheel unicycle. The dataset provides 1 kHz synchronized data encompassing all onboard sensor readings, state estimates, ground-truth poses from a motion capture system, and third-person video logs. To ensure data diversity, we include experiments across multiple hardware instances and surfaces using various control paradigms, including pseudo-random binary excitation, nonlinear model predictive control, and reinforcement learning agents. We include several example applications in dynamics model learning, state estimation, and time-series classification to illustrate common robotics algorithms that can be benchmarked on our dataset.

</details>


### [40] [ACoT-VLA: Action Chain-of-Thought for Vision-Language-Action Models](https://arxiv.org/abs/2601.11404)
*Linqing Zhong,Yi Liu,Yifei Wei,Ziyu Xiong,Maoqing Yao,Si Liu,Guanghui Ren*

Main category: cs.RO

TL;DR: 提出了一种新型的视觉-语言-行动模型ACoT-VLA，通过在行动空间中直接推理，提升机器人操作的精准性。


<details>
  <summary>Details</summary>
Motivation: 传统VLA模型依赖于间接推理，难以传达执行操作所需的详细信息，因此需要一种更有效的推理方法。

Method: 提出Action Chain-of-Thought (ACoT)范式，并通过Explicit Action Reasoner (EAR)和Implicit Action Reasoner (IAR)两大组件来实现。

Result: 在LIBERO、LIBERO-Plus和VLABench上，ACoT-VLA分别达到了98.5%、84.1%和47.4%的优异表现。

Conclusion: ACoT-VLA通过显式与隐式动作推理的结合，显著提高了机器人在多种Manipulation任务中的执行效果。

Abstract: Vision-Language-Action (VLA) models have emerged as essential generalist robot policies for diverse manipulation tasks, conventionally relying on directly translating multimodal inputs into actions via Vision-Language Model (VLM) embeddings. Recent advancements have introduced explicit intermediary reasoning, such as sub-task prediction (language) or goal image synthesis (vision), to guide action generation. However, these intermediate reasoning are often indirect and inherently limited in their capacity to convey the full, granular information required for precise action execution. Instead, we posit that the most effective form of reasoning is one that deliberates directly in the action space. We introduce Action Chain-of-Thought (ACoT), a paradigm where the reasoning process itself is formulated as a structured sequence of coarse action intents that guide the final policy. In this paper, we propose ACoT-VLA, a novel architecture that materializes the ACoT paradigm. Specifically, we introduce two complementary components: an Explicit Action Reasoner (EAR) and Implicit Action Reasoner (IAR). The former proposes coarse reference trajectories as explicit action-level reasoning steps, while the latter extracts latent action priors from internal representations of multimodal input, co-forming an ACoT that conditions the downstream action head to enable grounded policy learning. Extensive experiments in real-world and simulation environments demonstrate the superiority of our proposed method, which achieves 98.5%, 84.1%, and 47.4% on LIBERO, LIBERO-Plus and VLABench, respectively.

</details>


### [41] [The Great March 100: 100 Detail-oriented Tasks for Evaluating Embodied AI Agents](https://arxiv.org/abs/2601.11421)
*Ziyu Wang,Chenyuan Liu,Yushun Xiang,Runhao Zhang,Qingbo Hao,Hongliang Lu,Houyu Chen,Zhizhong Feng,Kaiyue Zheng,Dehao Ye,Xianchao Zeng,Xinyu Zhou,Boran Wen,Jiaxin Li,Mingyu Zhang,Kecheng Zheng,Qian Zhu,Ran Cheng,Yong-Lu Li*

Main category: cs.RO

TL;DR: 引入GM-100作为机器人学习的评估基准，旨在提供丰富且具有挑战性的任务，以促进任务设计的多样性和复杂性


<details>
  <summary>Details</summary>
Motivation: 当前数据集和任务设计缺乏系统性，无法准确反映不同方法的表现

Method: 引入GM-100任务集，涵盖100个精心设计的任务，评估机器人能力

Result: GM-100任务在不同机器人平台上执行可行且具有挑战性，能够有效区分现有VLA模型的性能

Conclusion: GM-100为机器人学习提供了首个系统化的评估标准，促进了机器人技术的发展

Abstract: Recently, with the rapid development of robot learning and imitation learning, numerous datasets and methods have emerged. However, these datasets and their task designs often lack systematic consideration and principles. This raises important questions: Do the current datasets and task designs truly advance the capabilities of robotic agents? Do evaluations on a few common tasks accurately reflect the differentiated performance of various methods proposed by different teams and evaluated on different tasks? To address these issues, we introduce the Great March 100 (\textbf{GM-100}) as the first step towards a robot learning Olympics. GM-100 consists of 100 carefully designed tasks that cover a wide range of interactions and long-tail behaviors, aiming to provide a diverse and challenging set of tasks to comprehensively evaluate the capabilities of robotic agents and promote diversity and complexity in robot dataset task designs. These tasks are developed through systematic analysis and expansion of existing task designs, combined with insights from human-object interaction primitives and object affordances. We collect a large amount of trajectory data on different robotic platforms and evaluate several baseline models. Experimental results demonstrate that the GM-100 tasks are 1) feasible to execute and 2) sufficiently challenging to effectively differentiate the performance of current VLA models. Our data and code are available at https://rhos.ai/research/gm-100.

</details>


### [42] [Learning Semantic-Geometric Task Graph-Representations from Human Demonstrations](https://arxiv.org/abs/2601.11460)
*Franziska Herbert,Vignesh Prasad,Han Liu,Dorothea Koert,Georgia Chalvatzaki*

Main category: cs.RO

TL;DR: 提出了一种新的语义几何任务图表示，结合MPNN编码器和变换器解码器，以改善长时间操作行为的理解和机器人任务决策。


<details>
  <summary>Details</summary>
Motivation: 从人类示范中学习结构化任务表示以理解长时间范围的操作行为，特别是在双手设置中，面临任务离散语义结构与对象几何关系的挑战。

Method: 提出了一种结合消息传递神经网络编码器和基于变换器的解码器的学习框架，使用语义几何任务图表示。

Result: 通过广泛评估实现了结构化的语义几何任务图表示，尤其在高动作和对象变异性任务中表现优于简单的基于序列的模型，且成功转移到物理双手机器人，用于在线动作选择。

Conclusion: 语义几何任务图表示可以作为可重用的任务抽象，在操作系统的下游决策中展现出广泛的潜力。

Abstract: Learning structured task representations from human demonstrations is essential for understanding long-horizon manipulation behaviors, particularly in bimanual settings where action ordering, object involvement, and interaction geometry can vary significantly. A key challenge lies in jointly capturing the discrete semantic structure of tasks and the temporal evolution of object-centric geometric relations in a form that supports reasoning over task progression. In this work, we introduce a semantic-geometric task graph-representation that encodes object identities, inter-object relations, and their temporal geometric evolution from human demonstrations. Building on this formulation, we propose a learning framework that combines a Message Passing Neural Network (MPNN) encoder with a Transformer-based decoder, decoupling scene representation learning from action-conditioned reasoning about task progression. The encoder operates solely on temporal scene graphs to learn structured representations, while the decoder conditions on action-context to predict future action sequences, associated objects, and object motions over extended time horizons. Through extensive evaluation on human demonstration datasets, we show that semantic-geometric task graph-representations are particularly beneficial for tasks with high action and object variability, where simpler sequence-based models struggle to capture task progression. Finally, we demonstrate that task graph representations can be transferred to a physical bimanual robot and used for online action selection, highlighting their potential as reusable task abstractions for downstream decision-making in manipulation systems.

</details>
