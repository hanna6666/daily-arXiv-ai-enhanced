<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 50]
- [cs.HC](#cs.HC) [Total: 13]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Untethered thin dielectric elastomer actuated soft robot](https://arxiv.org/abs/2512.17940)
*Xi Wang,Jing Liu,Siqian Li,Hengtai Dai,Jung-Che Chang,Adam Rushworth,Xin Dong*

Main category: cs.RO

TL;DR: 本文介绍了一种新型的无束缚薄软机器人（UTS-Robot），利用薄介电弹性体驱动器，实现低电压驱动和高效运动，适合在复杂环境中导航。


<details>
  <summary>Details</summary>
Motivation: 旨在解决现有DEA驱动软机器人在狭小环境中受限的工作能力，特别是在电压和连接要求方面。

Method: 提出了一种新的设计框架，通过优化薄介电弹性体驱动器（TS-DEA）和集成功能电子设备，实现全自主无束缚运动。

Result: 实验结果表明，无束缚的TS-DEA配置下，该机器人在复杂环境中表现出稳定的运动能力。

Conclusion: UTS-Robot展示了在复杂空间中高效运动的潜力，具备良好的性能和灵活性。

Abstract: Thin dielectric elastomer actuator (DEA) features a unique in-plane configuration, enabling low-profile designs capable of accessing millimetre-scale narrow spaces. However, most existing DEA-powered soft robots require high voltages and wired power connections, limiting their ability to operate in confined environments. This study presents an untethered thin soft robot (UTS-Robot) powered by thin dielectric elastomer actuators (TS-DEA). The robot measures 38 mm in length, 6 mm in height, and weighs just 2.34 grams, integrating flexible onboard electronics to achieve fully untethered actuation. The TS-DEA, operating at resonant frequencies of 86 Hz under a low driving voltage of 220 V, adopts a dual-actuation sandwiched structure, comprising four dielectric elastomer layers bonded to a compressible tensioning mechanism at its core. This design enables high power density actuation and locomotion via three directional friction pads. The low-voltage actuation is achieved by fabricating each elastomer layer via spin coating to an initial thickness of 50 um, followed by biaxial stretching to 8 um. A comprehensive design and modelling framework has been developed to optimise TS-DEA performance. Experimental evaluations demonstrate that the bare TS-DEA achieves a locomotion speed of 12.36 mm/s at resonance, the untethered configuration achieves a locomotion speed of 0.5 mm/s, making it highly suitable for navigating confined and complex environments.

</details>


### [2] [Real-Time Human-Robot Interaction Intent Detection Using RGB-based Pose and Emotion Cues with Cross-Camera Model Generalization](https://arxiv.org/abs/2512.17958)
*Farida Mohsen,Ali Safa*

Main category: cs.RO

TL;DR: 本文提出了一种多模态框架，通过结合摄像机无关的2D姿势和面部情感特征，实现了高效的意图检测，同时在资源受限的环境中表现出良好的跨场景和跨传感器鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 公共场所的服务机器人需要实时理解人类行为意图，以实现自然互动。

Method: 结合单目RGB视频中提取的2D骨骼姿势和面部情感特征，而不是依赖RGB-D传感器或GPU加速。

Result: 在交叉主体和交叉场景协议下的全面离线评估展示出强大的泛化性能，帧和序列级AUROC达到0.95，而在现实城市环境下进行的交互测试中，实现了91%的准确率和100%的召回率。

Conclusion: 提出的多模态系统展示了在各种未经训练的数据集上（不同的相机和环境）的高鲁棒性，以及适合广泛应用于社交机器人中的潜力。

Abstract: Service robots in public spaces require real-time understanding of human behavioral intentions for natural interaction. We present a practical multimodal framework for frame-accurate human-robot interaction intent detection that fuses camera-invariant 2D skeletal pose and facial emotion features extracted from monocular RGB video. Unlike prior methods requiring RGB-D sensors or GPU acceleration, our approach resource-constrained embedded hardware (Raspberry Pi 5, CPU-only). To address the severe class imbalance in natural human-robot interaction datasets, we introduce a novel approach to synthesize temporally coherent pose-emotion-label sequences for data re-balancing called MINT-RVAE (Multimodal Recurrent Variational Autoencoder for Intent Sequence Generation). Comprehensive offline evaluations under cross-subject and cross-scene protocols demonstrate strong generalization performance, achieving frame- and sequence-level AUROC of 0.95. Crucially, we validate real-world generalization through cross-camera evaluation on the MIRA robot head, which employs a different onboard RGB sensor and operates in uncontrolled environments not represented in the training data. Despite this domain shift, the deployed system achieves 91% accuracy and 100% recall across 32 live interaction trials. The close correspondence between offline and deployed performance confirms the cross-sensor and cross-environment robustness of the proposed multimodal approach, highlighting its suitability for ubiquitous multimedia-enabled social robots.

</details>


### [3] [Unifying Deep Predicate Invention with Pre-trained Foundation Models](https://arxiv.org/abs/2512.17992)
*Qianwei Wang,Bowen Li,Zhanpeng Luo,Yifan Xu,Alexander Gray,Tom Silver,Sebastian Scherer,Katia Sycara,Yaqi Xie*

Main category: cs.RO

TL;DR: UniPred是一个双层学习框架，通过结合大型语言模型与低级数据，显著提高机器人长远任务的成功率和学习速度，推动符号世界建模的进展。


<details>
  <summary>Details</summary>
Motivation: 长远的机器人任务由于状态-动作空间连续性和反馈稀疏性而较为困难，符号世界模型通过将任务分解为离散谓词来捕捉对象特性和关系。

Method: 提出了一种双层学习框架UniPred，利用大型语言模型（LLMs）推动谓词效应分布，并监督神经谓词的低级数据学习，同时通过学习反馈迭代优化LLM假设。

Result: 在五个模拟和一个真实机器人领域中，UniPred展示了显著的性能提升。

Conclusion: UniPred在六个领域的成功率提高了2-4倍，并且学习速度比现有的方法快了3-4倍，推动了机器人的符号世界建模的可扩展性和灵活性。

Abstract: Long-horizon robotic tasks are hard due to continuous state-action spaces and sparse feedback. Symbolic world models help by decomposing tasks into discrete predicates that capture object properties and relations. Existing methods learn predicates either top-down, by prompting foundation models without data grounding, or bottom-up, from demonstrations without high-level priors. We introduce UniPred, a bilevel learning framework that unifies both. UniPred uses large language models (LLMs) to propose predicate effect distributions that supervise neural predicate learning from low-level data, while learned feedback iteratively refines the LLM hypotheses. Leveraging strong visual foundation model features, UniPred learns robust predicate classifiers in cluttered scenes. We further propose a predicate evaluation method that supports symbolic models beyond STRIPS assumptions. Across five simulated and one real-robot domains, UniPred achieves 2-4 times higher success rates than top-down methods and 3-4 times faster learning than bottom-up approaches, advancing scalable and flexible symbolic world modeling for robotics.

</details>


### [4] [Robotic VLA Benefits from Joint Learning with Motion Image Diffusion](https://arxiv.org/abs/2512.18007)
*Yu Fang,Kanchana Ranasinghe,Le Xue,Honglu Zhou,Juntao Tan,Ran Xu,Shelby Heinecke,Caiming Xiong,Silvio Savarese,Daniel Szafir,Mingyu Ding,Michael S. Ryoo,Juan Carlos Niebles*

Main category: cs.RO

TL;DR: 本文提出了一种结合运动图像扩散的联合学习方法，显著提升了视觉-语言-动作模型的运动推理能力，且在多个基准上表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前的VLA模型在执行任务时主要依赖模仿专家轨迹，缺乏预测动作的推理能力，这限制了其应用。

Method: 我们提出了一种联合学习的方法，与运动图像扩散结合，扩展了VLA的架构，采用了双头设计，动作头和运动头共同训练。

Result: 在LIBERO基准上，成功率提高至97.5%，在RoboTwin基准上提高至58.0%，实现了23%的真实世界表现提升，验证了方法的有效性。

Conclusion: 联学习与运动图像扩散的方法显著提高了大型视觉-语言-动作模型的运动推理能力，并在真实世界中的性能有所提升。

Abstract: Vision-Language-Action (VLA) models have achieved remarkable progress in robotic manipulation by mapping multimodal observations and instructions directly to actions. However, they typically mimic expert trajectories without predictive motion reasoning, which limits their ability to reason about what actions to take. To address this limitation, we propose joint learning with motion image diffusion, a novel strategy that enhances VLA models with motion reasoning capabilities. Our method extends the VLA architecture with a dual-head design: while the action head predicts action chunks as in vanilla VLAs, an additional motion head, implemented as a Diffusion Transformer (DiT), predicts optical-flow-based motion images that capture future dynamics. The two heads are trained jointly, enabling the shared VLM backbone to learn representations that couple robot control with motion knowledge. This joint learning builds temporally coherent and physically grounded representations without modifying the inference pathway of standard VLAs, thereby maintaining test-time latency. Experiments in both simulation and real-world environments demonstrate that joint learning with motion image diffusion improves the success rate of pi-series VLAs to 97.5% on the LIBERO benchmark and 58.0% on the RoboTwin benchmark, yielding a 23% improvement in real-world performance and validating its effectiveness in enhancing the motion reasoning capability of large-scale VLAs.

</details>


### [5] [Embodied4C: Measuring What Matters for Embodied Vision-Language Navigation](https://arxiv.org/abs/2512.18028)
*Tin Stribor Sohn,Maximilian Dillitzer,Jason J. Corso,Eric Sax*

Main category: cs.RO

TL;DR: 本文介绍了Embodied4C，一个评估视觉-语言模型在不同有体形式下推理能力的基准，展示了跨模态对齐的重要性和推理方面的主要挑战。


<details>
  <summary>Details</summary>
Motivation: 现有基准对有体性的理解有限，因此需要一种新的方法来评估视觉-语言模型在真实环境中踱步、推理与行动时面临的限制。

Method: 通过构建一个闭环基准Embodied4C，评估在三种异构有体形式下的视觉-语言模型（VLM）的核心有体能力，使用约1.1K个一次性推理问题和58个目标导向导航任务。

Result: Embodied4C基准表明，跨模态对齐和指令调整优于单纯增加模型规模，而空间和时间推理仍是实现可靠有体能力的重要挑战。

Conclusion: 跨模态对齐和指令微调比模型规模更为重要，而空间和时间推理是可靠的有体能力的主要瓶颈。

Abstract: Vision-language navigation requires agents to reason and act under constraints of embodiment. While vision-language models (VLMs) demonstrate strong generalization, current benchmarks provide limited understanding of how embodiment -- i.e., the choice of physical platform, sensor configuration, and modality alignment -- influences perception, reasoning, and control. We introduce Embodied4C, a closed-loop benchmark designed as a Turing test for embodied reasoning. The benchmark evaluates the core embodied capabilities of VLMs across three heterogeneous embodiments -- autonomous vehicles, aerial drones, and robotic manipulators -- through approximately 1.1K one-shot reasoning questions and 58 goal-directed navigation tasks. These tasks jointly assess four foundational dimensions: semantic, spatial, temporal, and physical reasoning. Each embodiment presents dynamic sensor configurations and environment variations to probe generalization beyond platform-specific adaptation. To prevent embodiment overfitting, Embodied4C integrates domain-far queries targeting abstract and cross-context reasoning. Comprehensive evaluation across ten state-of-the-art VLMs and four embodied control baselines shows that cross-modal alignment and instruction tuning matter more than scale, while spatial and temporal reasoning remains the primary bottleneck for reliable embodied competence.

</details>


### [6] [Design and Integration of Thermal and Vibrotactile Feedback for Lifelike Touch in Social Robots](https://arxiv.org/abs/2512.18032)
*Jacqueline Borgstedt,Jake Bhattacharyya,Matteo Iovino,Frank E. Pollick,Stephen Brewster*

Main category: cs.RO

TL;DR: 本研究提出了一种多模态触觉原型，通过热和振动反馈改善了社会辅助机器人PARO，使其能更好地与用户产生情感共鸣。


<details>
  <summary>Details</summary>
Motivation: 解决现有社会辅助机器人触觉互动的局限性，提升情感参与感和生命般的物理互动。

Method: 开发了一个多模态触觉原型，结合了热量和振动反馈来模拟生物体信号。

Result: 设计出的原型能模拟人类与动物接触的丰富触觉信号，从而增强与用户的情感交流。

Conclusion: 通过集成热和振动触觉反馈，改进了PARO机器人，使其能够模拟生物体征，增加了与用户的情感连接。

Abstract: Zoomorphic Socially Assistive Robots (SARs) offer an alternative source of social touch for individuals who cannot access animal companionship. However, current SARs provide only limited, passive touch-based interactions and lack the rich haptic cues, such as warmth, heartbeat or purring, that are characteristic of human-animal touch. This limits their ability to evoke emotionally engaging, life-like physical interactions.
  We present a multimodal tactile prototype, which was used to augment the established PARO robot, integrating thermal and vibrotactile feedback to simulate feeling biophysiological signals. A flexible heating interface delivers body-like warmth, while embedded actuators generate heartbeat-like rhythms and continuous purring sensations. These cues were iteratively designed and calibrated with input from users and haptics experts. We outline the design process and offer reproducible guidelines to support the development of emotionally resonant and biologically plausible touch interactions with SARs.

</details>


### [7] [Design of a Polymer-based Steerable Cannula for Neurosurgical Applications](https://arxiv.org/abs/2512.18048)
*Nidhi Malhotra,Amber K. Rothe,Revanth Konda,Jaydev P. Desai*

Main category: cs.RO

TL;DR: 本研究探讨了激光微机械加工聚酰亚胺材料在神经外科工具制造中的应用，成功制作了小型的机器人可操控导管关节，展现出优异的性能与柔性。


<details>
  <summary>Details</summary>
Motivation: 传统刚性外科工具在灵活性和组织损伤方面存在局限性，本研究旨在采用高弹性聚合物材料改善神经外科手术中的这些问题，探索激光微机械加工的潜力。

Method: 本研究采用激光微机械加工法制造聚酰亚胺（PI）机器人可操控导管，制备了不同外径的PI管并对关节的负载行为进行了实验表征。

Result: 成功利用激光微机械加工制备了多种不同外径的聚酰亚胺导管关节，对其加载性能进行了实验研究，结果表明所制备的关节具有良好的灵活性和适应性。

Conclusion: 激光微机械加工的聚酰亚胺（PI）机器人可操控导管在神经外科应用中展现了良好的性能，成功制造了1.5毫米外径的柔性关节并进行了负载行为的实验表征。

Abstract: Robotically steerable compliant surgical tools offer several advantages over rigid tools, including enhanced dexterity, reduced tissue damage, and the ability to generate non-linear trajectories in minimally invasive neurosurgical procedures. Many existing robotic neurosurgical tools are designed using stainless steel or nitinol materials. Using polymer-based materials instead can offer advantages such as reduced interference in magnetic resonance imaging, enhanced safety for guiding electrically powered instruments, and reduced tissue damage due to inherent compliance. Several polymer materials have been used in robotic surgical applications, such as polyimide, polycarbonate, and elastic resin. Various fabrication strategies have also been proposed, including standard microfabrication techniques, thermal drawing, and 3-D printing. In our previous work, a tendon-driven, notched-tube was designed for several neurosurgical robotic tools, utilizing laser micromachining to reduce the stiffness of the tube in certain directions. This fabrication method is desirable because it has a single-step process, has high precision, and does not require a cleanroom or harsh chemicals. Past studies have explored laser-micromachining of polymer material for surgical applications such as stent fabrication. In this work, we explore extending the use of the laser micromachining approach to the fabrication of polyimide (PI) robotically steerable cannulas for neurosurgical applications. Utilizing the method presented in this work, we fabricated joints as small as 1.5 mm outer diameter (OD). Multiple joints were fabricated using PI tubes of different ODs, and the loading behavior of the fabricated joints was experimentally characterized.

</details>


### [8] [SurgiPose: Estimating Surgical Tool Kinematics from Monocular Video for Surgical Robot Learning](https://arxiv.org/abs/2512.18068)
*Juo-Tung Chen,XinHao Chen,Ji Woong Kim,Paul Maria Scheikl,Richard Jaepyeong Cha,Axel Krieger*

Main category: cs.RO

TL;DR: 本文提出SurgiPose，一种从单目外科视频中进行运动学估计的方法，为自主外科政策的大规模学习奠定了基础。实验结果表明，基于估计运动学训练的政策与基于真实数据的政策表现相当。


<details>
  <summary>Details</summary>
Motivation: 为了解锁模仿学习在外科手术中的潜力，需要访问临床数据集，而这些数据集通常缺乏当前IL方法所需的运动学数据。

Method: 提出了一种名为SurgiPose的可微渲染方法，从单目外科视频中估计运动学信息，通过优化工具位姿参数以最小化渲染图像与真实图像之间的差异，推断工具轨迹和关节角度。

Result: 在使用达芬奇研究套件Si（dVRK Si）的两项机器人手术任务（组织提升和针具拾取）上进行的实验表明，基于估计运动学训练的政策与基于真实测量运动学训练的政策在成功率上相当，展示了使用单目视频进行运动学估计的可行性。

Conclusion: 通过从单目外科视频中进行运动学估计，我们的研究为从在线外科数据中进行大规模自主外科策略学习奠定了基础。

Abstract: Imitation learning (IL) has shown immense promise in enabling autonomous dexterous manipulation, including learning surgical tasks. To fully unlock the potential of IL for surgery, access to clinical datasets is needed, which unfortunately lack the kinematic data required for current IL approaches. A promising source of large-scale surgical demonstrations is monocular surgical videos available online, making monocular pose estimation a crucial step toward enabling large-scale robot learning. Toward this end, we propose SurgiPose, a differentiable rendering based approach to estimate kinematic information from monocular surgical videos, eliminating the need for direct access to ground truth kinematics. Our method infers tool trajectories and joint angles by optimizing tool pose parameters to minimize the discrepancy between rendered and real images. To evaluate the effectiveness of our approach, we conduct experiments on two robotic surgical tasks: tissue lifting and needle pickup, using the da Vinci Research Kit Si (dVRK Si). We train imitation learning policies with both ground truth measured kinematics and estimated kinematics from video and compare their performance. Our results show that policies trained on estimated kinematics achieve comparable success rates to those trained on ground truth data, demonstrating the feasibility of using monocular video based kinematic estimation for surgical robot learning. By enabling kinematic estimation from monocular surgical videos, our work lays the foundation for large scale learning of autonomous surgical policies from online surgical data.

</details>


### [9] [Towards Autonomous Navigation in Endovascular Interventions](https://arxiv.org/abs/2512.18081)
*Tudor Jianu,Anh Nguyen,Sebastiano Fichera,Pierre Berthet-Rayne*

Main category: cs.RO

TL;DR: 本文提出了一种基于AI的自主导丝导航框架，通过高保真模拟、传感器融合和几何建模，显著改善微创手术的精确度和安全性。


<details>
  <summary>Details</summary>
Motivation: 针对当前机器人系统在血管内导航中精确性、自适应性不足的问题，提出这一研究以解决数据可用性、模拟保真度和导航准确性等关键挑战。

Method: 提出了一种集成的人工智能驱动框架，使用高保真实时模拟平台CathSim进行强化学习的导管导航，并开发了Expert Navigation Network以融合视觉、运动学和力反馈实现自主工具控制。

Result: 通过引入开放源代码的Guide3D数据集和SplineFormer模型，显著提高了导管导航的准确性和实时性，使得针对复杂血管环境的自主导丝导航成为可能。

Conclusion: 将高保真模拟、多模态传感器融合和几何建模相结合，显着改善了自主血管内导航，并支持更安全、更精确的微创手术。

Abstract: Cardiovascular diseases remain the leading cause of global mortality, with minimally invasive treatment options offered through endovascular interventions. However, the precision and adaptability of current robotic systems for endovascular navigation are limited by heuristic control, low autonomy, and the absence of haptic feedback. This thesis presents an integrated AI-driven framework for autonomous guidewire navigation in complex vascular environments, addressing key challenges in data availability, simulation fidelity, and navigational accuracy.
  A high-fidelity, real-time simulation platform, CathSim, is introduced for reinforcement learning based catheter navigation, featuring anatomically accurate vascular models and contact dynamics. Building on CathSim, the Expert Navigation Network is developed, a policy that fuses visual, kinematic, and force feedback for autonomous tool control. To mitigate data scarcity, the open-source, bi-planar fluoroscopic dataset Guide3D is proposed, comprising more than 8,700 annotated images for 3D guidewire reconstruction. Finally, SplineFormer, a transformer-based model, is introduced to directly predict guidewire geometry as continuous B-spline parameters, enabling interpretable, real-time navigation.
  The findings show that combining high-fidelity simulation, multimodal sensory fusion, and geometric modelling substantially improves autonomous endovascular navigation and supports safer, more precise minimally invasive procedures.

</details>


### [10] [On Swarm Leader Identification using Probing Policies](https://arxiv.org/abs/2512.18146)
*Stergios E. Bachoumas,Panagiotis Artemiadis*

Main category: cs.RO

TL;DR: 该论文提出了一种新颖的交互式群体领导者识别问题（iSLI），使用深度强化学习和新的神经网络架构来识别机器人群体中的领导者。


<details>
  <summary>Details</summary>
Motivation: 在对抗环境中，识别机器人群体中的领导者至关重要，尤其是当领导者需要隐蔽以确保任务成功时。

Method: 将iSLI问题表述为部分可观察的马尔可夫决策过程（POMDP），使用近端策略优化（PPO）训练探测者的策略。引入了一种新的神经网络架构，结合了Timed Graph Relationformer（TGR）层和简化的结构化状态空间序列（S5）模型。

Result: 广泛的模拟表明，TGR基础的模型在识别领导者方面的准确性高于基线图神经网络架构，在不同群体规模和速度下具有显著的零样本泛化能力。

Conclusion: 真实机器人实验进一步验证了该方法的有效性，确认了从模拟到现实的转移以及对动态变化的鲁棒性。

Abstract: Identifying the leader within a robotic swarm is crucial, especially in adversarial contexts where leader concealment is necessary for mission success. This work introduces the interactive Swarm Leader Identification (iSLI) problem, a novel approach where an adversarial probing agent identifies a swarm's leader by physically interacting with its members. We formulate the iSLI problem as a Partially Observable Markov Decision Process (POMDP) and employ Deep Reinforcement Learning, specifically Proximal Policy Optimization (PPO), to train the prober's policy. The proposed approach utilizes a novel neural network architecture featuring a Timed Graph Relationformer (TGR) layer combined with a Simplified Structured State Space Sequence (S5) model. The TGR layer effectively processes graph-based observations of the swarm, capturing temporal dependencies and fusing relational information using a learned gating mechanism to generate informative representations for policy learning. Extensive simulations demonstrate that our TGR-based model outperforms baseline graph neural network architectures and exhibits significant zero-shot generalization capabilities across varying swarm sizes and speeds different from those used during training. The trained prober achieves high accuracy in identifying the leader, maintaining performance even in out-of-training distribution scenarios, and showing appropriate confidence levels in its predictions. Real-world experiments with physical robots further validate the approach, confirming successful sim-to-real transfer and robustness to dynamic changes, such as unexpected agent disconnections.

</details>


### [11] [Alternating Minimization for Time-Shifted Synergy Extraction in Human Hand Coordination](https://arxiv.org/abs/2512.18206)
*Trevor Stepp,Parthan Olikkal,Ramana Vinjamuri,Rajasekhar Anguluri*

Main category: cs.RO

TL;DR: 我们提出了一种新方法，通过优化联合学习运动协同作用和激活系数，简化了数据要求并提高了重构准确性。


<details>
  <summary>Details</summary>
Motivation: 在运动控制和机器人领域，识别运动协同作用（手部关节在任务依赖的时间偏移下的协调模式）是至关重要的。

Method: 我们提出了一种基于优化的框架，联合学习一小组协同作用及其稀疏激活系数。该方法强制实施协同选择的组稀疏性和激活时间的逐元素稀疏性，并开发了一种交替最小化方法，更新系数在任务间解耦，而协同更新简化为正则化最小二乘问题。

Result: 我们的方案只需一个数据集，且模拟结果显示出准确的速度重构，具有紧凑且可解释的协同作用。

Conclusion: 该研究提供了一种简化的方法来识别和利用运动协同作用，有助于改善运动控制和机器人技术的发展。

Abstract: Identifying motor synergies -- coordinated hand joint patterns activated at task-dependent time shifts -- from kinematic data is central to motor control and robotics. Existing two-stage methods first extract candidate waveforms (via SVD) and then select shifted templates using sparse optimization, requiring at least two datasets and complicating data collection. We introduce an optimization-based framework that jointly learns a small set of synergies and their sparse activation coefficients. The formulation enforces group sparsity for synergy selection and element-wise sparsity for activation timing. We develop an alternating minimization method in which coefficient updates decouple across tasks and synergy updates reduce to regularized least-squares problems. Our approach requires only a single data set, and simulations show accurate velocity reconstruction with compact, interpretable synergies.

</details>


### [12] [LLaViDA: A Large Language Vision Driving Assistant for Explicit Reasoning and Enhanced Trajectory Planning](https://arxiv.org/abs/2512.18211)
*Yudong Liu,Spencer Hallyburton,Jiwoo Kim,Yueqian Lin,Yiming Li,Qinsi Wang,Hui Ye,Jingwei Sun,Miroslav Pajic,Yiran Chen,Hai Li*

Main category: cs.RO

TL;DR: 本文提出了一种名为LLaViDA的轨迹规划系统，利用视语言模型(VLM)进行运动预测和语义对应，通过两阶段训练提升自主驾驶场景理解和轨迹规划能力。


<details>
  <summary>Details</summary>
Motivation: 自主驾驶中的轨迹规划面临恶劣天气、不可预测的人类行为和复杂道路布局的挑战，现有的端到端规划器缺乏良好的泛化能力。

Method: 采用监督微调和轨迹偏好优化(TPO)的两阶段训练管道，通过回归监督增强场景理解与轨迹规划。

Result: 在NuScenes基准测试中，LLaViDA在开放循环轨迹规划任务中实现了0.31米的平均L2轨迹误差和0.10%的碰撞率，超越了现有最先进的系统。

Conclusion: LLaViDA显著优于当前最先进的端到端规划器和其他基于VLM/LLM的基准，为自主驾驶的轨迹规划提供了一种创新的方法。

Abstract: Trajectory planning is a fundamental yet challenging component of autonomous driving. End-to-end planners frequently falter under adverse weather, unpredictable human behavior, or complex road layouts, primarily because they lack strong generalization or few-shot capabilities beyond their training data. We propose LLaViDA, a Large Language Vision Driving Assistant that leverages a Vision-Language Model (VLM) for object motion prediction, semantic grounding, and chain-of-thought reasoning for trajectory planning in autonomous driving. A two-stage training pipeline--supervised fine-tuning followed by Trajectory Preference Optimization (TPO)--enhances scene understanding and trajectory planning by injecting regression-based supervision, produces a powerful "VLM Trajectory Planner for Autonomous Driving." On the NuScenes benchmark, LLaViDA surpasses state-of-the-art end-to-end and other recent VLM/LLM-based baselines in open-loop trajectory planning task, achieving an average L2 trajectory error of 0.31 m and a collision rate of 0.10% on the NuScenes test set. The code for this paper is available at GitHub.

</details>


### [13] [Fractional-order Modeling for Nonlinear Soft Actuators via Particle Swarm Optimization](https://arxiv.org/abs/2512.18213)
*Wu-Te Yang,Masayoshi Tomizuka*

Main category: cs.RO

TL;DR: 提出了一种基于分数阶微分方程的高精度建模框架，采用粒子群优化从实验数据中估计参数，成功克服了传统建模技术的局限性。


<details>
  <summary>Details</summary>
Motivation: 软气动驱动器的高度非线性和顺应特性使得高精度建模面临挑战，需要开发新方法以提高建模精度。

Method: 基于分数阶微分方程（FODE）的建模框架，利用粒子群优化（PSO）识别未知参数。

Result: 提出的框架成功捕捉了软材料的动态行为，实验结果验证了模型的准确性和稳健性。

Conclusion: 该框架提供了一种高效、无数据库依赖的软驱动器建模解决方案，提升了软机器人系统设计的精确性和适应性。

Abstract: Modeling soft pneumatic actuators with high precision remains a fundamental challenge due to their highly nonlinear and compliant characteristics. This paper proposes an innovative modeling framework based on fractional-order differential equations (FODEs) to accurately capture the dynamic behavior of soft materials. The unknown parameters within the fractional-order model are identified using particle swarm optimization (PSO), enabling parameter estimation directly from experimental data without reliance on pre-established material databases or empirical constitutive laws. The proposed approach effectively represents the complex deformation phenomena inherent in soft actuators. Experimental results validate the accuracy and robustness of the developed model, demonstrating improvement in predictive performance compared to conventional modeling techniques. The presented framework provides a data-efficient and database-independent solution for soft actuator modeling, advancing the precision and adaptability of soft robotic system design.

</details>


### [14] [On The Computational Complexity for Minimizing Aerial Photographs for Full Coverage of a Planar Region](https://arxiv.org/abs/2512.18268)
*Si Wei Feng*

Main category: cs.RO

TL;DR: 无人机技术的普及导致航空摄影在多个日常场景中的广泛应用，但对目标区域的有效覆盖仍然是一项挑战，本文分析了相关计算复杂性问题。


<details>
  <summary>Details</summary>
Motivation: 随着无人机技术的普及，航空摄影在环境监测、结构检查和执法等多个场景中变得越来越重要。

Method: 将航空摄影问题抽象为计算几何中的覆盖问题，分析了相关问题的计算复杂性。

Result: 大多数相关问题被证明在计算上不可解，表明传统算法无法高效解决这些问题。

Conclusion: 这项工作的直觉不仅适用于航空摄影，还可扩展到更广泛的应用，如农药喷洒和传感器布局。

Abstract: With the popularity of drone technologies, aerial photography have become prevalent in many daily scenarios such as environment monitoring, structure inspection, law enforcement etc. A central challenge in this domain is the efficient coverage of a target area with photographs that can entirely capture the region, while respecting constraints such as the image resolution, and limited number of pictures that can be taken. This work investigates the computational complexity of several fundamental problems arised from this challenge. By abstracting the aerial photography problem into the coverage problems in computational geometry, we demonstrate that most of these problems are in fact computationally intractable, with the implication that traditional algorithms cannot solve them efficiently. The intuitions of this work can extend beyond aerial photography to broader applications such as pesticide spraying, and strategic sensor placement.

</details>


### [15] [Reinforcement Learning Position Control of a Quadrotor Using Soft Actor-Critic (SAC)](https://arxiv.org/abs/2512.18333)
*Youssef Mahran,Zeyad Gamal,Ayman El-Badawy*

Main category: cs.RO

TL;DR: 本论文提出了一种新的基于强化学习的四旋翼控制架构，控制推力矢量而非电机转速，显示出训练时间更短及路径跟踪更平滑的优势。


<details>
  <summary>Details</summary>
Motivation: 在文献中，现有研究主要集中于直接控制四旋翼的电机转速，而该论文旨在通过控制四旋翼的推力矢量来提高控制效果。

Method: 采用基于强化学习的控制架构，采用Soft Actor-Critic算法训练强化学习代理，控制推力沿四旋翼z轴的分布，以及期望的滚转和俯仰角，最终通过PID控制器将控制信号映射到电机转速。

Result: 训练结果表明，所提的推力矢量控制器相比于传统的RPM控制器具有更快的训练时间，仿真结果显示路径跟踪更加平滑和准确。

Conclusion: 该研究提出的推力矢量控制方法在控制四旋翼飞行方面表现出优越性，提供了比传统方法更有效的路径跟踪能力。

Abstract: This paper proposes a new Reinforcement Learning (RL) based control architecture for quadrotors. With the literature focusing on controlling the four rotors' RPMs directly, this paper aims to control the quadrotor's thrust vector. The RL agent computes the percentage of overall thrust along the quadrotor's z-axis along with the desired Roll ($φ$) and Pitch ($θ$) angles. The agent then sends the calculated control signals along with the current quadrotor's Yaw angle ($ψ$) to an attitude PID controller. The PID controller then maps the control signals to motor RPMs. The Soft Actor-Critic algorithm, a model-free off-policy stochastic RL algorithm, was used to train the RL agents. Training results show the faster training time of the proposed thrust vector controller in comparison to the conventional RPM controllers. Simulation results show smoother and more accurate path-following for the proposed thrust vector controller.

</details>


### [16] [Dynamic Entropy Tuning in Reinforcement Learning Low-Level Quadcopter Control: Stochasticity vs Determinism](https://arxiv.org/abs/2512.18336)
*Youssef Mahran,Zeyad Gamal,Ayman El-Badawy*

Main category: cs.RO

TL;DR: 本研究探讨了动态熵调节对随机策略的积极影响，显示其优于确定性策略。


<details>
  <summary>Details</summary>
Motivation: 研究旨在提高四旋翼控制的效率，通过增加策略的随机性以增强探索能力。

Method: 比较动态熵调节的随机策略与静态熵和确定性策略的表现

Result: 通过训练随机和确定性政策，在控制四旋翼飞行器方面实现了显著的改进，动态熵调节提升了探索效率，并防止了灾难性遗忘。

Conclusion: 动态熵调节显著提高了随机策略在强化学习中的表现，尤其是在复杂任务如四旋翼控制中。

Abstract: This paper explores the impact of dynamic entropy tuning in Reinforcement Learning (RL) algorithms that train a stochastic policy. Its performance is compared against algorithms that train a deterministic one. Stochastic policies optimize a probability distribution over actions to maximize rewards, while deterministic policies select a single deterministic action per state. The effect of training a stochastic policy with both static entropy and dynamic entropy and then executing deterministic actions to control the quadcopter is explored. It is then compared against training a deterministic policy and executing deterministic actions. For the purpose of this research, the Soft Actor-Critic (SAC) algorithm was chosen for the stochastic algorithm while the Twin Delayed Deep Deterministic Policy Gradient (TD3) was chosen for the deterministic algorithm. The training and simulation results show the positive effect the dynamic entropy tuning has on controlling the quadcopter by preventing catastrophic forgetting and improving exploration efficiency.

</details>


### [17] [Learning Semantic Atomic Skills for Multi-Task Robotic Manipulation](https://arxiv.org/abs/2512.18368)
*Yihang Zhu,Weiqing Wang,Shijie Wu,Ye Shi,Jingya Wang*

Main category: cs.RO

TL;DR: AtomSkill是一个新的多任务模仿学习框架，通过语义基础原子技能库和行动生成模块解决了多任务操作面临的挑战，实验结果显示其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在单任务机器人操作中，模仿学习已经取得了令人瞩目的结果，但在多任务设置中仍面临挑战，主要是由于演示不佳、轨迹噪声和行为多模态性等问题。

Method: 提出了AtomSkill，一个新的多任务模仿学习框架，学习并利用结构化原子技能空间以实现可组合的机器人操作。关键技术贡献包括：构建一个通过检测抓取器状态关键帧和视觉语言模型注释来划分演示为可变长度技能的语义基础原子技能库；和提出一个联合预测技能长视距终端关键姿态及其立即动作序列的行动生成模块，该模块可以同时考虑整体运动目标和细粒度控制。

Result: 在模拟和现实世界环境中的大量实验表明，AtomSkill在各种操作任务上始终超过了最先进的方法。

Conclusion: AtomSkill提供了一个有效的框架，增强机器人在多任务操作中的能力，尤其是在处理语义一致性和跨任务泛化方面。

Abstract: While imitation learning has shown impressive results in single-task robot manipulation, scaling it to multi-task settings remains a fundamental challenge due to issues such as suboptimal demonstrations, trajectory noise, and behavioral multi-modality. Existing skill-based methods attempt to address this by decomposing actions into reusable abstractions, but they often rely on fixed-length segmentation or environmental priors that limit semantic consistency and cross-task generalization. In this work, we propose AtomSkill, a novel multi-task imitation learning framework that learns and leverages a structured Atomic Skill Space for composable robot manipulation. Our approach is built on two key technical contributions. First, we construct a Semantically Grounded Atomic Skill Library by partitioning demonstrations into variable-length skills using gripper-state keyframe detection and vision-language model annotation. A contrastive learning objective ensures the resulting skill embeddings are both semantically consistent and temporally coherent. Second, we propose an Action Generation module with Keypose Imagination, which jointly predicts a skill's long-horizon terminal keypose and its immediate action sequence. This enables the policy to reason about overarching motion goals and fine-grained control simultaneously, facilitating robust skill chaining. Extensive experiments in simulated and real-world environments show that AtomSkill consistently outperforms state-of-the-art methods across diverse manipulation tasks.

</details>


### [18] [AOMGen: Photoreal, Physics-Consistent Demonstration Generation for Articulated Object Manipulation](https://arxiv.org/abs/2512.18396)
*Yulu Wu,Jiujun Cheng,Haowen Wang,Dengyang Suo,Pei Ren,Qichao Mao,Shangce Gao,Yakun Huang*

Main category: cs.RO

TL;DR: AOMGen是一个可扩展的数据生成框架，通过结合真实和数字资源显著提升了机器人操控任务的成功率。


<details>
  <summary>Details</summary>
Motivation: 解决细粒度操控任务对大量真实演示数据的需求，尤其是在复杂物体操作上。

Method: 提出了一个名为AOMGen的数据生成框架，从单个真实扫描、演示和数字资产库生成合成数据。

Result: 细调VLA策略后，成功率从0%提升到88.7%，并在未见过的物体和布局上测试。

Conclusion: AOMGen框架显著提高了细粒度操控的成功率，达到88.7%。

Abstract: Recent advances in Vision-Language-Action (VLA) and world-model methods have improved generalization in tasks such as robotic manipulation and object interaction. However, Successful execution of such tasks depends on large, costly collections of real demonstrations, especially for fine-grained manipulation of articulated objects. To address this, we present AOMGen, a scalable data generation framework for articulated manipulation which is instantiated from a single real scan, demonstration and a library of readily available digital assets, yielding photoreal training data with verified physical states. The framework synthesizes synchronized multi-view RGB temporally aligned with action commands and state annotations for joints and contacts, and systematically varies camera viewpoints, object styles, and object poses to expand a single execution into a diverse corpus. Experimental results demonstrate that fine-tuning VLA policies on AOMGen data increases the success rate from 0% to 88.7%, and the policies are tested on unseen objects and layouts.

</details>


### [19] [When Robots Say No: The Empathic Ethical Disobedience Benchmark](https://arxiv.org/abs/2512.18474)
*Dmytro Kuzmenko,Nadiya Shvai*

Main category: cs.RO

TL;DR: 本文提出了一个标准化的测试平台——Empathic Ethical Disobedience (EED) Gym，用于评估机器人在拒绝任务时的安全性与社会可接受性。


<details>
  <summary>Details</summary>
Motivation: 由于盲目服从可能导致伤害，而过度拒绝又会损害信任，需在安全与社会期望之间找到平衡。

Method: EED Gym提供多种场景和角色配置，评价机器人在拒绝、澄清或提出更安全替代方案时的风险、情感和信任。

Result: 研究发现，行动屏蔽可消除不安全的服从，而解释性的拒绝有助于维持信任。不同的风格影响信任度与情感度，安全RL方法增强鲁棒性但可能导致过于谨慎的行为。

Conclusion: 我们发布了代码和配置，致力于提高人机交互研究的可重复性和系统性，并承诺在论文接受后开源完整代码库。

Abstract: Robots must balance compliance with safety and social expectations as blind obedience can cause harm, while over-refusal erodes trust. Existing safe reinforcement learning (RL) benchmarks emphasize physical hazards, while human-robot interaction trust studies are small-scale and hard to reproduce. We present the Empathic Ethical Disobedience (EED) Gym, a standardized testbed that jointly evaluates refusal safety and social acceptability. Agents weigh risk, affect, and trust when choosing to comply, refuse (with or without explanation), clarify, or propose safer alternatives. EED Gym provides different scenarios, multiple persona profiles, and metrics for safety, calibration, and refusals, with trust and blame models grounded in a vignette study. Using EED Gym, we find that action masking eliminates unsafe compliance, while explanatory refusals help sustain trust. Constructive styles are rated most trustworthy, empathic styles -- most empathic, and safe RL methods improve robustness but also make agents more prone to overly cautious behavior. We release code, configurations, and reference policies to enable reproducible evaluation and systematic human-robot interaction research on refusal and trust. At submission time, we include an anonymized reproducibility package with code and configs, and we commit to open-sourcing the full repository after the paper is accepted.

</details>


### [20] [STORM: Search-Guided Generative World Models for Robotic Manipulation](https://arxiv.org/abs/2512.18477)
*Wenjun Lin,Jensen Zhang,Kaitong Cai,Keze Wang*

Main category: cs.RO

TL;DR: STORM是一种新的机器人操控框架，通过结合扩散动作生成、视频预测和搜索规划，显著提升了决策的可解释性和成功率。


<details>
  <summary>Details</summary>
Motivation: 提出一种新框架以实现机器人操控中的时空推理，并提高决策的可解释性和前瞻性。

Method: 通过扩散基础的动作生成、条件视频预测和基于搜索的规划相结合，利用明确的视觉展开进行决策。

Result: STORM在SimplerEnv操控基准测试中达到51.0%的平均成功率，显著优于CogACT等强基线，提升了时空保真度和任务相关性，减小了Frechet视频距离超过75%。

Conclusion: STORM在长时间跨度的机器人操控中展现出搜索引导生成世界模型的优势，具备强大的重规划和故障恢复能力。

Abstract: We present STORM (Search-Guided Generative World Models), a novel framework for spatio-temporal reasoning in robotic manipulation that unifies diffusion-based action generation, conditional video prediction, and search-based planning. Unlike prior Vision-Language-Action (VLA) models that rely on abstract latent dynamics or delegate reasoning to language components, STORM grounds planning in explicit visual rollouts, enabling interpretable and foresight-driven decision-making. A diffusion-based VLA policy proposes diverse candidate actions, a generative video world model simulates their visual and reward outcomes, and Monte Carlo Tree Search (MCTS) selectively refines plans through lookahead evaluation. Experiments on the SimplerEnv manipulation benchmark demonstrate that STORM achieves a new state-of-the-art average success rate of 51.0 percent, outperforming strong baselines such as CogACT. Reward-augmented video prediction substantially improves spatio-temporal fidelity and task relevance, reducing Frechet Video Distance by over 75 percent. Moreover, STORM exhibits robust re-planning and failure recovery behavior, highlighting the advantages of search-guided generative world models for long-horizon robotic manipulation.

</details>


### [21] [Systematic Benchmarking of SUMO Against Data-Driven Traffic Simulators](https://arxiv.org/abs/2512.18537)
*Erdao Liang*

Main category: cs.RO

TL;DR: 该论文系统评估了SUMO交通模拟器与数据驱动模拟器的表现，显示出模型驱动和数据驱动方法在自主驾驶模拟中的互补优势。


<details>
  <summary>Details</summary>
Motivation: 为评估模型驱动的微观交通模拟器SUMO与先进的数据驱动交通模拟器的表现，利用真实世界的大规模数据集进行基准测试。

Method: 使用Waymo Open Motion Dataset和Waymo Open Sim Agents Challenge对SUMO进行系统评测，并开发Waymo2SUMO自动化管道将数据场景转换为SUMO模拟。

Result: 在WOSAC基准测试中，SUMO的现实性元指标为0.653，同时需要少于100个可调参数，且在长时间模拟中表现出较强的稳定性。

Conclusion: SUMO在长时间稳定性和低碰撞率方面表现优于数据驱动模拟器，展现了模型驱动与数据驱动方法的互补优势。

Abstract: This paper presents a systematic benchmarking of the model-based microscopic traffic simulator SUMO against state-of-the-art data-driven traffic simulators using large-scale real-world datasets. Using the Waymo Open Motion Dataset (WOMD) and the Waymo Open Sim Agents Challenge (WOSAC), we evaluate SUMO under both short-horizon (8s) and long-horizon (60s) closed-loop simulation settings. To enable scalable evaluation, we develop Waymo2SUMO, an automated pipeline that converts WOMD scenarios into SUMO simulations. On the WOSAC benchmark, SUMO achieves a realism meta metric of 0.653 while requiring fewer than 100 tunable parameters. Extended rollouts show that SUMO maintains low collision and offroad rates and exhibits stronger long-horizon stability than representative data-driven simulators. These results highlight complementary strengths of model-based and data-driven approaches for autonomous driving simulation and benchmarking.

</details>


### [22] [Offline Reinforcement Learning for End-to-End Autonomous Driving](https://arxiv.org/abs/2512.18662)
*Chihiro Noguchi,Takaki Yamamoto*

Main category: cs.RO

TL;DR: 提出了一种仅使用相机的E2E离线强化学习框架，通过伪真实轨迹进行训练，显著提高了自主驾驶性能。


<details>
  <summary>Details</summary>
Motivation: 旨在解决当前以模仿学习为基础的E2E自主驾驶模型中的持续失败模式。

Method: 构建伪真实轨迹并将其用作行为正则化信号，在神经渲染环境中进行训练和闭环评估。

Result: 与模仿学习基线相比，所提出的方法在碰撞率和路径完成方面显著改善。

Conclusion: 提出的方法在碰撞率和路径完成方面相比于模仿学习基线有显著改善。

Abstract: End-to-end (E2E) autonomous driving models that take only camera images as input and directly predict a future trajectory are appealing for their computational efficiency and potential for improved generalization via unified optimization; however, persistent failure modes remain due to reliance on imitation learning (IL). While online reinforcement learning (RL) could mitigate IL-induced issues, the computational burden of neural rendering-based simulation and large E2E networks renders iterative reward and hyperparameter tuning costly. We introduce a camera-only E2E offline RL framework that performs no additional exploration and trains solely on a fixed simulator dataset. Offline RL offers strong data efficiency and rapid experimental iteration, yet is susceptible to instability from overestimation on out-of-distribution (OOD) actions. To address this, we construct pseudo ground-truth trajectories from expert driving logs and use them as a behavior regularization signal, suppressing imitation of unsafe or suboptimal behavior while stabilizing value learning. Training and closed-loop evaluation are conducted in a neural rendering environment learned from the public nuScenes dataset. Empirically, the proposed method achieves substantial improvements in collision rate and route completion compared with IL baselines. Our code will be available at [URL].

</details>


### [23] [CauTraj: A Causal-Knowledge-Guided Framework for Lane-Changing Trajectory Planning of Autonomous Vehicles](https://arxiv.org/abs/2512.18703)
*Cailin Lei,Haiyang Wu,Yuxiong Ji,Xiaoyu Cai,Yuchuan Du*

Main category: cs.RO

TL;DR: 本文提出了一种新型轨迹规划框架，整合因果知识，显著改善了自动驾驶车辆的轨迹规划性能。


<details>
  <summary>Details</summary>
Motivation: 解决目前轨迹规划模型未融入人类驾驶员先验知识的问题，提高自动驾驶的安全性和可靠性。

Method: 提出了一种新颖的轨迹规划框架，将因果先验知识融入控制过程，结合了纵向和横向微观行为建模和因果推断

Result: 通过因果推断量化车辆交互风险，采用预测控制框架进行轨迹规划，实现与人类驾驶行为更高的一致性

Conclusion: 与基线MPC相比，减少了最大轨迹偏差， lateral velocity fluctuation 和 yaw angle variability，有助于提高安全性、稳定性和现实主义

Abstract: Enhancing the performance of trajectory planners for lane - changing vehicles is one of the key challenges in autonomous driving within human - machine mixed traffic. Most existing studies have not incorporated human drivers' prior knowledge when designing trajectory planning models. To address this issue, this study proposes a novel trajectory planning framework that integrates causal prior knowledge into the control process. Both longitudinal and lateral microscopic behaviors of vehicles are modeled to quantify interaction risk, and a staged causal graph is constructed to capture causal dependencies in lane-changing scenarios. Causal effects between the lane-changing vehicle and surrounding vehicles are then estimated using causal inference, including average causal effects (ATE) and conditional average treatment effects (CATE). These causal priors are embedded into a model predictive control (MPC) framework to enhance trajectory planning. The proposed approach is validated on naturalistic vehicle trajectory datasets. Experimental results show that: (1) causal inference provides interpretable and stable quantification of vehicle interactions; (2) individual causal effects reveal driver heterogeneity; and (3) compared with the baseline MPC, the proposed method achieves a closer alignment with human driving behaviors, reducing maximum trajectory deviation from 1.2 m to 0.2 m, lateral velocity fluctuation by 60%, and yaw angle variability by 50%. These findings provide methodological support for human-like trajectory planning and practical value for improving safety, stability, and realism in autonomous vehicle testing and traffic simulation platforms.

</details>


### [24] [DSO-VSA: a Variable Stiffness Actuator with Decoupled Stiffness and Output Characteristics for Rehabilitation Robotics](https://arxiv.org/abs/2512.18712)
*Maozeng Zhang,Ke Shi,Huijun Li,Tongshu Chen,Jiejun Yan,Aiguo Song*

Main category: cs.RO

TL;DR: 提出了一种新型变刚度执行器，通过解耦刚度和输出行为，提升了康复机器人在安全人机交互中的应用效果。


<details>
  <summary>Details</summary>
Motivation: 由于中风引起的运动障碍常导致上肢功能显著丧失，迫切需要能够实现安全和透明人机交互的康复机器人。

Method: 开发了一种将可变刚度机制与行星齿轮差动传动相结合的变刚度执行器，并设计了级联PI控制器以提高系统稳定性和输出性能。

Result: 开发了一种变刚度执行器，特点是刚度和输出行为解耦，适合用于康复机器人。该系统通过可变长度杠杆和假圆形直线机制实现线性扭矩-偏转关系，并实现从近零到理论无限的连续刚度调节。还集成了基于行星齿轮系统的差动传动机制，使得双电机负载分担成为可能。基于差动配置进一步开发了级联PI控制器，用于联动调节刚度和偏转角，有效抑制刚度波动和输出干扰。原型的性能通过实验证实，显示了在康复外骨骼和其他pHRI系统中的潜力。

Conclusion: 所提出的变刚度执行器在康复机器人和人机交互系统中展示了显著的潜力，通过解耦的刚度调节和高效的控制策略，提高了系统性能和可靠性。

Abstract: Stroke-induced motor impairment often results in substantial loss of upper-limb function, creating a strong demand for rehabilitation robots that enable safe and transparent physical human-robot interaction (pHRI). Variable stiffness actuators are well suited for such applications. However, in most existing designs, stiffness is coupled with the deflection angle, complicating both modeling and control. To address this limitation, this paper presents a variable stiffness actuator featuring decoupled stiffness and output behavior for rehabilitation robotics. The system integrates a variable stiffness mechanism that combines a variable-length lever with a hypocycloidal straight-line mechanism to achieve a linear torque-deflection relationship and continuous stiffness modulation from near zero to theoretically infinite. It also incorporates a differential transmission mechanism based on a planetary gear system that enables dual-motor load sharing. A cascade PI controller is further developed on the basis of the differential configuration, in which the position-loop term jointly regulates stiffness and deflection angle, effectively suppressing stiffness fluctuations and output disturbances. The performance of prototype was experimentally validated through stiffness calibration, stiffness regulation, torque control, decoupled characteristics, and dual-motor load sharing, indicating the potential for rehabilitation exoskeletons and other pHRI systems.

</details>


### [25] [Multimodal Classification Network Guided Trajectory Planning for Four-Wheel Independent Steering Autonomous Parking Considering Obstacle Attributes](https://arxiv.org/abs/2512.18836)
*Jingjia Teng,Yang Li,Jianqiang Wang,Yingbai Hu,Songyuan Tang,Manjiang Hu*

Main category: cs.RO

TL;DR: 提出了一种针对4WIS车辆的新轨迹规划框架，通过综合障碍物属性和任务复杂性，提高路径规划的效率和安全性。


<details>
  <summary>Details</summary>
Motivation: 解决现有路径规划方法忽视障碍物属性导致的效率低下或路径寻找失败的问题。

Method: 结合4WIS混合A*和最优控制问题(OCP)的轨迹规划框架，并引入多模态分类网络评估场景复杂性。

Result: 实验结果证明该框架能够生成安全、高效和平滑的轨迹，特别是在受限环境中。

Conclusion: 所提出的轨迹规划框架显著提高了4WIS车辆在受限环境中的路径规划能力和安全性。

Abstract: Four-wheel Independent Steering (4WIS) vehicles have attracted increasing attention for their superior maneuverability. Human drivers typically choose to cross or drive over the low-profile obstacles (e.g., plastic bags) to efficiently navigate through narrow spaces, while existing planners neglect obstacle attributes, causing inefficiency or path-finding failures. To address this, we propose a trajectory planning framework integrating the 4WIS hybrid A* and Optimal Control Problem (OCP), in which the hybrid A* provides an initial path to enhance the OCP solution. Specifically, a multimodal classification network is introduced to assess scene complexity (hard/easy task) by fusing image and vehicle state data. For hard tasks, guided points are set to decompose complex tasks into local subtasks, improving the search efficiency of 4WIS hybrid A*. The multiple steering modes of 4WIS vehicles (Ackermann, diagonal, and zero-turn) are also incorporated into node expansion and heuristic designs. Moreover, a hierarchical obstacle handling strategy is designed to guide the node expansion considering obstacle attributes, i.e., 'non-traversable', 'crossable', and 'drive-over' obstacles. It allows crossing or driving over obstacles instead of the 'avoid-only' strategy, greatly enhancing success rates of pathfinding. We also design a logical constraint for the 'drive-over' obstacle by limiting its velocity to ensure safety. Furthermore, to address dynamic obstacles with motion uncertainty, we introduce a probabilistic risk field model, constructing risk-aware driving corridors that serve as linear collision constraints in OCP. Experimental results demonstrate the proposed framework's effectiveness in generating safe, efficient, and smooth trajectories for 4WIS vehicles, especially in constrained environments.

</details>


### [26] [InDRiVE: Reward-Free World-Model Pretraining for Autonomous Driving via Latent Disagreement](https://arxiv.org/abs/2512.18850)
*Feeza Khan Khanzada,Jaerock Kwon*

Main category: cs.RO

TL;DR: 本文提出InDRiVE，一种在CARLA中进行奖励自由预训练的MBRL代理，利用内在动机和不确定性来支撑更强的零-shot 适应性及碰撞避免能力。


<details>
  <summary>Details</summary>
Motivation: 虽然基于模型的强化学习可以通过学习预测世界模型减少自主驾驶的交互成本，但在任务特定奖励设计上仍存在困难，特别是在分布变化下显得脆弱，因此对奖励自由的预训练方法具有研究价值。

Method: InDRiVE通过潜在集合体的不确定性驱动和无规划的探索策略学习，进行奖励自由的预训练，并在新环境中评估零-shot 转移，最后通过有限的外在反馈训练任务策略实现少量适应。

Result: 本文提出了一种基于模型的强化学习方法InDRiVE，该方法通过利用内在动机驱动代理探索未充分探索的驾驶情况，并在CARLA环境中进行奖励自由的预训练。实验表明，使用不确定性驱动的预训练能够在新的城镇和路线中实现更强的零-shot 适应性，同时在碰撞避免任务中表现出更强的健壮性。

Conclusion: 实验结果证明基于不确定性预训练的智能代理在面对城镇变化和有限反馈条件下，能够有效地适应不同的驾驶任务，展示出内在不确定性作为已有模型的奖励自由预培训信号的可行性。

Abstract: Model-based reinforcement learning (MBRL) can reduce interaction cost for autonomous driving by learning a predictive world model, but it typically still depends on task-specific rewards that are difficult to design and often brittle under distribution shift. This paper presents InDRiVE, a DreamerV3-style MBRL agent that performs reward-free pretraining in CARLA using only intrinsic motivation derived from latent ensemble disagreement. Disagreement acts as a proxy for epistemic uncertainty and drives the agent toward under-explored driving situations, while an imagination-based actor-critic learns a planner-free exploration policy directly from the learned world model. After intrinsic pretraining, we evaluate zero-shot transfer by freezing all parameters and deploying the pretrained exploration policy in unseen towns and routes. We then study few-shot adaptation by training a task policy with limited extrinsic feedback for downstream objectives (lane following and collision avoidance). Experiments in CARLA across towns, routes, and traffic densities show that disagreement-based pretraining yields stronger zero-shot robustness and robust few-shot collision avoidance under town shift and matched interaction budgets, supporting the use of intrinsic disagreement as a practical reward-free pretraining signal for reusable driving world models.

</details>


### [27] [Construction and deformation of P-hedra using control polylines](https://arxiv.org/abs/2512.18869)
*Georg Nawratil*

Main category: cs.RO

TL;DR: 本论文研究了一种新型连续灵活离散表面 P-hedra，探讨了其在变换设计任务中的应用和计算等距变形的高效算法。


<details>
  <summary>Details</summary>
Motivation: 研究者旨在开发有助于形状变换设计的灵活平面四边形表面，以便于交互式工具使用。

Method: 通过研究控制折线，分析 P-hedra 的构造与性能。

Result: P-hedra 的构造及其与控制折线的关系，为其在设计和计算中的应用提供了新的视角。

Conclusion: 本文探讨了 P-hedra 的特性及应用，支持可变设计任务，并提出高效算法计算其等距变形。

Abstract: In the 19th International Symposium on Advances in Robot Kinematics the author introduced a novel class of continuous flexible discrete surfaces and mentioned that these so-called P-hedra (or P-nets) allow direct access to their spatial shapes by three control polylines. In this follow-up paper we study this intuitive method, which makes these flexible planar quad surfaces suitable for transformable design tasks by means of interactive tools. The construction of P-hedra from the control polylines can also be used for an efficient algorithmic computation of their isometric deformations. In addition we discuss flexion limits, bifurcation configurations, developable/flat-foldable pattern and tubular P-hedra.

</details>


### [28] [Optimizing Robotic Placement via Grasp-Dependent Feasibility Prediction](https://arxiv.org/abs/2512.18922)
*Tianyuan Liu,Richard Dazeley,Benjamin Champion,Akan Cosgun*

Main category: cs.RO

TL;DR: 本文研究廉价监督如何有效优先考虑抓取-放置候选，提出了使用双输出MLP的方案，在预算有限条件下提升路径规划效率。


<details>
  <summary>Details</summary>
Motivation: 探索是否可以通过廉价的物理无关监督来可靠地优先考虑预算意识的抓取和放置候选项。

Method: 使用紧凑的双输出多层感知器（MLP）从姿态编码中学习路径感知的几何标签，包括路径逆向运动学（IK）可行性和过境碰撞标志。

Result: 在固定的规划预算下，此政策能更早找到成功路径，减少规划调用，同时保证或提升最终成功率。

Conclusion: 该方法在预算有限的情况下可以更快地找到成功的路径，同时保持最终成功率不变或更好。

Abstract: In this paper, we study whether inexpensive, physics-free supervision can reliably prioritize grasp-place candidates for budget-aware pick-and-place. From an object's initial pose, target pose, and a candidate grasp, we generate two path-aware geometric labels: path-wise inverse kinematics (IK) feasibility across a fixed approach-grasp-lift waypoint template, and a transit collision flag from mesh sweeps along the same template. A compact dual-output MLP learns these signals from pose encodings, and at test time its scores rank precomputed candidates for a rank-then-plan policy under the same IK gate and planner as the baseline. Although learned from cheap labels only, the scores transfer to physics-enabled executed trajectories: at a fixed planning budget the policy finds successful paths sooner with fewer planner calls while keeping final success on par or better. This work targets a single rigid cuboid with side-face grasps and a fixed waypoint template, and we outline extensions to varied objects and richer waypoint schemes.

</details>


### [29] [A Framework for Deploying Learning-based Quadruped Loco-Manipulation](https://arxiv.org/abs/2512.18938)
*Yadong Liu,Jianwei Liu,He Liang,Dimitrios Kanoulas*

Main category: cs.RO

TL;DR: 本文提出了一种开放管道，用于在Unitree B1四足机器人及Z1臂上训练、基准测试和部署基于强化学习的控制器，解决了模拟与现实间的转移问题，并提供了一种可重复的基础以支持未来研究。


<details>
  <summary>Details</summary>
Motivation: 四足移动操纵器在灵活的运动控制上有很强的潜力，但在从模拟到现实的可靠转移方面仍然困难；强化学习在全身控制上表现出前景，但大多数框架是专有的，且难以在真实硬件上重现。

Method: 通过ROS统一了模拟到模拟和模拟到实际的转移，重新实现了在Isaac Gym中训练的策略，并通过硬件抽象层将其扩展到MuJoCo，最后在物理硬件上部署相同的控制器。

Result: 模拟到模拟的实验揭示了Isaac Gym和MuJoCo接触模型之间的差异，这些差异会影响策略行为，而实际的远程操作物体拾取测试表明，协调的全身控制比漂浮基准表现更好，扩展了操作范围并改善了操纵能力。

Conclusion: 该管道为开发和分析基于RL的运动操纵控制器提供了透明和可重复的基础，并将开源以支持未来研究。

Abstract: Quadruped mobile manipulators offer strong potential for agile loco-manipulation but remain difficult to control and transfer reliably from simulation to reality. Reinforcement learning (RL) shows promise for whole-body control, yet most frameworks are proprietary and hard to reproduce on real hardware. We present an open pipeline for training, benchmarking, and deploying RL-based controllers on the Unitree B1 quadruped with a Z1 arm. The framework unifies sim-to-sim and sim-to-real transfer through ROS, re-implementing a policy trained in Isaac Gym, extending it to MuJoCo via a hardware abstraction layer, and deploying the same controller on physical hardware. Sim-to-sim experiments expose discrepancies between Isaac Gym and MuJoCo contact models that influence policy behavior, while real-world teleoperated object-picking trials show that coordinated whole-body control extends reach and improves manipulation over floating-base baselines. The pipeline provides a transparent, reproducible foundation for developing and analyzing RL-based loco-manipulation controllers and will be released open source to support future research.

</details>


### [30] [Affordance RAG: Hierarchical Multimodal Retrieval with Affordance-Aware Embodied Memory for Mobile Manipulation](https://arxiv.org/abs/2512.18987)
*Ryosuke Korekata,Quanting Xie,Yonatan Bisk,Komei Sugiura*

Main category: cs.RO

TL;DR: 本研究通过Affordance RAG框架改进了开放词汇移动操控的效果，实现85%的任务成功率，超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决开放词汇移动操控问题，要求机器人根据自由形式的自然语言指令将各种物体运输到接收处，这一任务涉及理解视觉语义和操控行为的可操作性。

Method: 提出了一种名为Affordance RAG的零-shot层级多模态检索框架，通过预探索的图像构建了适应性记忆，基于区域和视觉语义检索候选目标，并用可操作性评分对其进行重新排序。

Result: 在大型室内环境中的移动操控指令检索性能上，本方法超过了现有技术，真正实验中任务成功率达到85%。

Conclusion: 本研究提出的Affordance RAG框架在执行移动操控任务中表现优越，达到了85%的任务成功率。

Abstract: In this study, we address the problem of open-vocabulary mobile manipulation, where a robot is required to carry a wide range of objects to receptacles based on free-form natural language instructions. This task is challenging, as it involves understanding visual semantics and the affordance of manipulation actions. To tackle these challenges, we propose Affordance RAG, a zero-shot hierarchical multimodal retrieval framework that constructs Affordance-Aware Embodied Memory from pre-explored images. The model retrieves candidate targets based on regional and visual semantics and reranks them with affordance scores, allowing the robot to identify manipulation options that are likely to be executable in real-world environments. Our method outperformed existing approaches in retrieval performance for mobile manipulation instruction in large-scale indoor environments. Furthermore, in real-world experiments where the robot performed mobile manipulation in indoor environments based on free-form instructions, the proposed method achieved a task success rate of 85%, outperforming existing methods in both retrieval performance and overall task success.

</details>


### [31] [DTCCL: Disengagement-Triggered Contrastive Continual Learning for Autonomous Bus Planners](https://arxiv.org/abs/2512.18988)
*Yanding Yang,Weitao Zhou,Jinhai Wang,Xiaomin Guo,Junze Wen,Xiaolong Liu,Lang Ding,Zheng Fu,Jinyu Miao,Kun Jiang,Diange Yang*

Main category: cs.RO

TL;DR: 提出了一种新的框架DTCCL，用于改善自主公交在动态城市环境中的规划策略。


<details>
  <summary>Details</summary>
Motivation: 自主公交在固定路线运行，但在动态城市环境中面临计划失败问题，传统的模仿学习难以处理稀疏的 disengagement 数据。

Method: 提出DTCCL框架，通过现实操作中的disengagement触发云端数据增强，生成正负样本，并应用对比学习优化策略表示，最终在无监督情况下进行持续更新。

Result: 实验结果显示，DTCCL相比直接再训练，整体规划性能提高了48.6%。

Conclusion: DTCCL框架证明了在自主公共交通中实现可扩展的闭环策略改进的有效性。

Abstract: Autonomous buses run on fixed routes but must operate in open, dynamic urban environments. Disengagement events on these routes are often geographically concentrated and typically arise from planner failures in highly interactive regions. Such policy-level failures are difficult to correct using conventional imitation learning, which easily overfits to sparse disengagement data. To address this issue, this paper presents a Disengagement-Triggered Contrastive Continual Learning (DTCCL) framework that enables autonomous buses to improve planning policies through real-world operation. Each disengagement triggers cloud-based data augmentation that generates positive and negative samples by perturbing surrounding agents while preserving route context. Contrastive learning refines policy representations to better distinguish safe and unsafe behaviors, and continual updates are applied in a cloud-edge loop without human supervision. Experiments on urban bus routes demonstrate that DTCCL improves overall planning performance by 48.6 percent compared with direct retraining, validating its effectiveness for scalable, closed-loop policy improvement in autonomous public transport.

</details>


### [32] [IndoorUAV: Benchmarking Vision-Language UAV Navigation in Continuous Indoor Environments](https://arxiv.org/abs/2512.19024)
*Xu Liu,Yu Liu,Hanshuo Qiu,Yang Qirong,Zhouhui Lian*

Main category: cs.RO

TL;DR: IndoorUAV是一个新基准，旨在提高室内无人机的视语言导航能力，包含大量多样化的3D场景和高质量导航数据。


<details>
  <summary>Details</summary>
Motivation: 由于室内无人机导航在现实应用中的重要性，现有的基础研究仍显不足，因此需要一个针对室内环境的专门基准和方法。

Method: 通过收集多样化的3D室内场景和手动导航轨迹，结合自动注释管道生成多样的自然语言指令。

Result: 创建了IndoorUAV基准及IndoorUAV-VLN和IndoorUAV-VLA子集，其中含有超过16,000条高质量导航轨迹及其相应的自然语言指令。

Conclusion: IndoorUAV及其相关子集将为室内无人机导航的视语言融合研究提供重要资源。

Abstract: Vision-Language Navigation (VLN) enables agents to navigate in complex environments by following natural language instructions grounded in visual observations. Although most existing work has focused on ground-based robots or outdoor Unmanned Aerial Vehicles (UAVs), indoor UAV-based VLN remains underexplored, despite its relevance to real-world applications such as inspection, delivery, and search-and-rescue in confined spaces. To bridge this gap, we introduce \textbf{IndoorUAV}, a novel benchmark and method specifically tailored for VLN with indoor UAVs. We begin by curating over 1,000 diverse and structurally rich 3D indoor scenes from the Habitat simulator. Within these environments, we simulate realistic UAV flight dynamics to collect diverse 3D navigation trajectories manually, further enriched through data augmentation techniques. Furthermore, we design an automated annotation pipeline to generate natural language instructions of varying granularity for each trajectory. This process yields over 16,000 high-quality trajectories, comprising the \textbf{IndoorUAV-VLN} subset, which focuses on long-horizon VLN. To support short-horizon planning, we segment long trajectories into sub-trajectories by selecting semantically salient keyframes and regenerating concise instructions, forming the \textbf{IndoorUAV-VLA} subset. Finally, we introduce \textbf{IndoorUAV-Agent}, a novel navigation model designed for our benchmark, leveraging task decomposition and multimodal reasoning. We hope IndoorUAV serves as a valuable resource to advance research on vision-language embodied AI in the indoor aerial navigation domain.

</details>


### [33] [EGM: Efficiently Learning General Motion Tracking Policy for High Dynamic Humanoid Whole-Body Control](https://arxiv.org/abs/2512.19043)
*Chao Yang,Yingkai Sun,Peng Ye,Xin Chen,Chong Yu,Tao Chen*

Main category: cs.RO

TL;DR: EGM框架通过创新的自适应采样和专家系统，实现了高效的动作追踪策略学习，并在极具动态性的任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 传统方法在数据利用效率和训练过程中表现不佳，且在高动态动作跟踪时性能有限，因此需要一个更有效的学习框架。

Method: EGM框架通过四个核心设计，包括基于箱的跨动量课程自适应采样策略和复合解耦专家组合架构，来实现高效的目标动作跟踪策略学习。

Result: EGM通过动态调整采样概率和优化专家组，提高了对不同动作分布的跟踪能力，并在复杂任务中展示了其增强的鲁棒性。

Conclusion: EGM在仅使用4.08小时的数据训练的情况下，对49.25小时的测试动作表现出强大的普适性，超越了基准模型的表现，尤其在常规和极具动态性的任务上。

Abstract: Learning a general motion tracking policy from human motions shows great potential for versatile humanoid whole-body control. Conventional approaches are not only inefficient in data utilization and training processes but also exhibit limited performance when tracking highly dynamic motions. To address these challenges, we propose EGM, a framework that enables efficient learning of a general motion tracking policy. EGM integrates four core designs. Firstly, we introduce a Bin-based Cross-motion Curriculum Adaptive Sampling strategy to dynamically orchestrate the sampling probabilities based on tracking error of each motion bin, eficiently balancing the training process across motions with varying dificulty and durations. The sampled data is then processed by our proposed Composite Decoupled Mixture-of-Experts (CDMoE) architecture, which efficiently enhances the ability to track motions from different distributions by grouping experts separately for upper and lower body and decoupling orthogonal experts from shared experts to separately handle dedicated features and general features. Central to our approach is a key insight we identified: for training a general motion tracking policy, data quality and diversity are paramount. Building on these designs, we develop a three-stage curriculum training flow to progressively enhance the policy's robustness against disturbances. Despite training on only 4.08 hours of data, EGM generalized robustly across 49.25 hours of test motions, outperforming baselines on both routine and highly dynamic tasks.

</details>


### [34] [CoDrone: Autonomous Drone Navigation Assisted by Edge and Cloud Foundation Models](https://arxiv.org/abs/2512.19083)
*Pengyu Chen,Tao Ouyang,Ke Luo,Weijie Hong,Xu Chen*

Main category: cs.RO

TL;DR: 本论文提出了CoDrone框架，通过集成基础模型，实现了复杂环境中资源受限无人机的高效导航。


<details>
  <summary>Details</summary>
Motivation: 自主无人机导航面临有限的计算资源挑战，深度神经网络只能采用较浅的架构，难以处理复杂环境。

Method: 提出了CoDrone框架，集成基础模型和一种新型的一维占用网格导航方法，结合深度强化学习神经调度器。

Result: CoDrone在不同飞行速度和网络条件下，相比基线方法提升40%平均飞行距离，平均导航质量提高5%。

Conclusion: CoDrone有效地增强了资源受限无人机在复杂环境中的导航能力，实现了高效的云边端协作计算。

Abstract: Autonomous navigation for Unmanned Aerial Vehicles faces key challenges from limited onboard computational resources, which restrict deployed deep neural networks to shallow architectures incapable of handling complex environments. Offloading tasks to remote edge servers introduces high latency, creating an inherent trade-off in system design. To address these limitations, we propose CoDrone - the first cloud-edge-end collaborative computing framework integrating foundation models into autonomous UAV cruising scenarios - effectively leveraging foundation models to enhance performance of resource-constrained unmanned aerial vehicle platforms. To reduce onboard computation and data transmission overhead, CoDrone employs grayscale imagery for the navigation model. When enhanced environmental perception is required, CoDrone leverages the edge-assisted foundation model Depth Anything V2 for depth estimation and introduces a novel one-dimensional occupancy grid-based navigation method - enabling fine-grained scene understanding while advancing efficiency and representational simplicity of autonomous navigation. A key component of CoDrone is a Deep Reinforcement Learning-based neural scheduler that seamlessly integrates depth estimation with autonomous navigation decisions, enabling real-time adaptation to dynamic environments. Furthermore, the framework introduces a UAV-specific vision language interaction module incorporating domain-tailored low-level flight primitives to enable effective interaction between the cloud foundation model and the UAV. The introduction of VLM enhances open-set reasoning capabilities in complex unseen scenarios. Experimental results show CoDrone outperforms baseline methods under varying flight speeds and network conditions, achieving a 40% increase in average flight distance and a 5% improvement in average Quality of Navigation.

</details>


### [35] [WorldRFT: Latent World Model Planning with Reinforcement Fine-Tuning for Autonomous Driving](https://arxiv.org/abs/2512.19133)
*Pengxuan Yang,Ben Lu,Zhongpu Xia,Chao Han,Yinfeng Gao,Teng Zhang,Kun Zhan,XianPeng Lang,Yupeng Zheng,Qichao Zhang*

Main category: cs.RO

TL;DR: WorldRFT是一种规划导向的潜在世界模型，通过层次化规划和局部感知精炼机制优化场景表征，降低自主驾驶中的碰撞率，并在基准测试中实现最先进的表现。


<details>
  <summary>Details</summary>
Motivation: 为了解决重建导向的表征学习与规划任务复杂交织的问题，从而实现更优的规划优化，我们提出了一种规划导向的潜在世界模型框架WorldRFT。

Method: WorldRFT采用层次化规划任务分解和局部感知交互细化机制，同时通过强化学习微调提升安全关键政策表现，整合视觉几何基础模型以改善3D空间感知。

Result: WorldRFT显著减少了nuScenes中的碰撞率（从0.30%下降至0.05%），在NavSim中以仅使用相机输入获得了与基于LiDAR的最先进方法DiffusionDrive相媲美的性能（87.8 vs. 88.1 PDMS）。

Conclusion: WorldRFT在开放环路nuScenes和闭环NavSim基准测试中实现了最先进的性能，通过减少碰撞率和在相机输入条件下提供竞争性能，展示了其在自主驾驶中的有效性。

Abstract: Latent World Models enhance scene representation through temporal self-supervised learning, presenting a perception annotation-free paradigm for end-to-end autonomous driving. However, the reconstruction-oriented representation learning tangles perception with planning tasks, leading to suboptimal optimization for planning. To address this challenge, we propose WorldRFT, a planning-oriented latent world model framework that aligns scene representation learning with planning via a hierarchical planning decomposition and local-aware interactive refinement mechanism, augmented by reinforcement learning fine-tuning (RFT) to enhance safety-critical policy performance. Specifically, WorldRFT integrates a vision-geometry foundation model to improve 3D spatial awareness, employs hierarchical planning task decomposition to guide representation optimization, and utilizes local-aware iterative refinement to derive a planning-oriented driving policy. Furthermore, we introduce Group Relative Policy Optimization (GRPO), which applies trajectory Gaussianization and collision-aware rewards to fine-tune the driving policy, yielding systematic improvements in safety. WorldRFT achieves state-of-the-art (SOTA) performance on both open-loop nuScenes and closed-loop NavSim benchmarks. On nuScenes, it reduces collision rates by 83% (0.30% -> 0.05%). On NavSim, using camera-only sensors input, it attains competitive performance with the LiDAR-based SOTA method DiffusionDrive (87.8 vs. 88.1 PDMS).

</details>


### [36] [A Flexible Field-Based Policy Learning Framework for Diverse Robotic Systems and Sensors](https://arxiv.org/abs/2512.19148)
*Jose Gustavo Buenaventura Carreon,Floris Erich,Roman Mykhailyshyn,Tomohiro Motoda,Ryo Hanai,Yukiyasu Domae*

Main category: cs.RO

TL;DR: 该框架利用扩散策略控制与3D场景表示，实现机器人操控技能的类别级泛化，成功率为80%。


<details>
  <summary>Details</summary>
Motivation: 希望实现跨机器人系统的操控技能泛化，提高多种机器人平台的操控灵活性。

Method: 集成扩散策略控制与3D语义场景表示，采用模块化设计、低延迟控制栈和直观的远程操作，支持不同机器人的摄像头配置。

Result: 在抓取和提升块的任务中，经过100次演示，该框架实现了80%的成功率，展示了平台间和传感方式的稳健技能转移。

Conclusion: 该框架实现了跨机器人操控的类别级泛化，成功率达到80%。

Abstract: We present a cross robot visuomotor learning framework that integrates diffusion policy based control with 3D semantic scene representations from D3Fields to enable category level generalization in manipulation. Its modular design supports diverse robot camera configurations including UR5 arms with Microsoft Azure Kinect arrays and bimanual manipulators with Intel RealSense sensors through a low latency control stack and intuitive teleoperation. A unified configuration layer enables seamless switching between setups for flexible data collection training and evaluation. In a grasp and lift block task the framework achieved an 80 percent success rate after only 100 demonstration episodes demonstrating robust skill transfer between platforms and sensing modalities. This design paves the way for scalable real world studies in cross robotic generalization.

</details>


### [37] [Vision-Language-Policy Model for Dynamic Robot Task Planning](https://arxiv.org/abs/2512.19178)
*Jin Wang,Kim Tien Ly,Jacques Cloete,Nikos Tsagarakis,Ioannis Havoutis*

Main category: cs.RO

TL;DR: 本文提出了一种新的基于语言模型的动态任务规划框架，能够有效解释语言指令并灵活适应变化的任务需求。


<details>
  <summary>Details</summary>
Motivation: 解决机器人的自然语言指令与自主执行之间的差距，提升机器人在复杂环境中的任务适应性。

Method: 提出了一种基于语言模型的动态机器人任务规划框架，使用视觉-语言模型，并在真实数据上进行微调。

Result: 实验表明，该模型能够高效适应新场景，动态更新策略，展现出良好的规划能力。

Conclusion: 该模型展示了强大的规划自主性和跨主体泛化能力，能够在新的场景中高效适应并动态更新策略。

Abstract: Bridging the gap between natural language commands and autonomous execution in unstructured environments remains an open challenge for robotics. This requires robots to perceive and reason over the current task scene through multiple modalities, and to plan their behaviors to achieve their intended goals. Traditional robotic task-planning approaches often struggle to bridge low-level execution with high-level task reasoning, and cannot dynamically update task strategies when instructions change during execution, which ultimately limits their versatility and adaptability to new tasks. In this work, we propose a novel language model-based framework for dynamic robot task planning. Our Vision-Language-Policy (VLP) model, based on a vision-language model fine-tuned on real-world data, can interpret semantic instructions and integrate reasoning over the current task scene to generate behavior policies that control the robot to accomplish the task. Moreover, it can dynamically adjust the task strategy in response to changes in the task, enabling flexible adaptation to evolving task requirements. Experiments conducted with different robots and a variety of real-world tasks show that the trained model can efficiently adapt to novel scenarios and dynamically update its policy, demonstrating strong planning autonomy and cross-embodiment generalization. Videos: https://robovlp.github.io/

</details>


### [38] [Translating Flow to Policy via Hindsight Online Imitation](https://arxiv.org/abs/2512.19269)
*Yitian Zheng,Zhangchen Ye,Weijun Dong,Shengjie Wang,Yuyang Liu,Chongjie Zhang,Chuan Wen,Yang Gao*

Main category: cs.RO

TL;DR: 本研究提出HinFlow方法，通过在线交互和回顾性经验标注，显著提高了机器人的操作性能，尤其在数据稀缺的情况下，展示了跨体体现象数据的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 旨在将高层规划有效地转化为可执行的机器人动作，并在低层策略中通过在线交互进行改进，以应对高质量机器人数据稀缺的问题。

Method: Hindsight Flow-conditioned Online Imitation (HinFlow)，通过在线交互获取回顾性标注的经验，更新目标条件的模仿策略。

Result: 在多种模拟和物理世界的操作任务中，HinFlow方法比基础策略表现提高超过2倍，优于现有方法。

Conclusion: 该方法在多种操作任务中显著提升了机器人的表现，并展示了跨体体现象数据中训练的规划者的可扩展性和可转移性。

Abstract: Recent advances in hierarchical robot systems leverage a high-level planner to propose task plans and a low-level policy to generate robot actions. This design allows training the planner on action-free or even non-robot data sources (e.g., videos), providing transferable high-level guidance. Nevertheless, grounding these high-level plans into executable actions remains challenging, especially with the limited availability of high-quality robot data. To this end, we propose to improve the low-level policy through online interactions. Specifically, our approach collects online rollouts, retrospectively annotates the corresponding high-level goals from achieved outcomes, and aggregates these hindsight-relabeled experiences to update a goal-conditioned imitation policy. Our method, Hindsight Flow-conditioned Online Imitation (HinFlow), instantiates this idea with 2D point flows as the high-level planner. Across diverse manipulation tasks in both simulation and physical world, our method achieves more than $2\times$ performance improvement over the base policy, significantly outperforming the existing methods. Moreover, our framework enables policy acquisition from planners trained on cross-embodiment video data, demonstrating its potential for scalable and transferable robot learning.

</details>


### [39] [Are All Data Necessary? Efficient Data Pruning for Large-scale Autonomous Driving Dataset via Trajectory Entropy Maximization](https://arxiv.org/abs/2512.19270)
*Zhaoyang Liu,Weitao Zhou,Junze Wen,Cheng Jing,Qian Cheng,Kun Jiang,Diange Yang*

Main category: cs.RO

TL;DR: 本文提出了一种信息论方法，通过修剪低价值样本，减少数据存储成本并提高政策学习效率，同时保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决现实世界数据集中重复和低价值样本带来的存储成本过高及对政策学习效益有限的问题。

Method: 通过评估驾驶数据的轨迹分布信息熵，迭代选择高价值样本，以保持原始数据集的统计特征。

Result: 在NuPlan基准数据集上进行的实验表明，提出的方法可以将数据集大小减少多达40%，而闭环性能保持不变。

Conclusion: 该研究提出了一种信息论数据修剪方法，成功实现了数据集的有效缩减，同时保持了模型性能。

Abstract: Collecting large-scale naturalistic driving data is essential for training robust autonomous driving planners. However, real-world datasets often contain a substantial amount of repetitive and low-value samples, which lead to excessive storage costs and bring limited benefits to policy learning. To address this issue, we propose an information-theoretic data pruning method that effectively reduces the training data volume without compromising model performance. Our approach evaluates the trajectory distribution information entropy of driving data and iteratively selects high-value samples that preserve the statistical characteristics of the original dataset in a model-agnostic manner. From a theoretical perspective, we show that maximizing trajectory entropy effectively constrains the Kullback-Leibler divergence between the pruned subset and the original data distribution, thereby maintaining generalization ability. Comprehensive experiments on the NuPlan benchmark with a large-scale imitation learning framework demonstrate that the proposed method can reduce the dataset size by up to 40% while maintaining closed-loop performance. This work provides a lightweight and theoretically grounded approach for scalable data management and efficient policy learning in autonomous driving systems.

</details>


### [40] [Comparison and Evaluation of Different Simulation Environments for Rigid Body Systems](https://arxiv.org/abs/2512.19289)
*Longxiang Shao,Ulrich Dahmen,Juergen Rossmann*

Main category: cs.RO

TL;DR: 本研究比较了四种刚体动力学仿真环境，强调不同工具在建模和求解方面的优缺点，以帮助用户选择合适的仿真工具。


<details>
  <summary>Details</summary>
Motivation: 为了支持机械系统的设计、分析和优化，提供不同仿真工具的比较使用户能够选择最适合其应用的工具。

Method: 比较四种不同的仿真环境（Adams, Simscape, OpenModelica, VEROSIM），特别关注建模方法、数值求解器和闭环运动学中的数值问题。

Result: 使用实际林业机械的复杂起重臂作为基准应用示例，展示了不同解决方案在不同仿真工具中的直接比较。

Conclusion: 不同的仿真工具在建模方法、数值求解器以及处理数值问题方面存在显著差异，为用户选择合适的工具提供了依据。

Abstract: Rigid body dynamics simulators are important tools for the design, analysis and optimization of mechanical systems in a variety of technical and scientific applications. This study examines four different simulation environments (Adams, Simscape, OpenModelica, and VEROSIM), focusing in particular on the comparison of the modeling methods, the numerical solvers, and the treatment of numerical problems that arise especially in closed-loop kinematics (esp. redundant boundary conditions and static equilibrium problem). A novel and complex crane boom of a real forestry machine serves as a practical benchmark application example. The direct comparison of the different solution approaches in the examined simulation tools supports the user in selecting the most suitable tool for his application.

</details>


### [41] [OMP: One-step Meanflow Policy with Directional Alignment](https://arxiv.org/abs/2512.19347)
*Han Fang,Yize Huang,Yuheng Zhao,Paul Weng,Xiao Li,Yutong Ban*

Main category: cs.RO

TL;DR: 本研究提出了一种改进的MeanFlow策略，通过余弦损失和DDE优化，提高了机器人操作的实时性能、少量样本泛化及轨迹精度。


<details>
  <summary>Details</summary>
Motivation: 传统的数据驱动生成策略在机器人操作中存在推理延迟高和架构复杂性增加等问题，本研究旨在解决MeanFlow在固定温度超参数导致的少量样本泛化欠缺及预测-真实平均速度不对齐的问题。

Method: 改进的MeanFlow策略引入轻量级的余弦损失来对齐速度方向，并使用微分推导方程（DDE）优化雅可比-向量乘积（JVP）算子。

Result: 在Adroit和Meta-World任务中的实验表明，提出的方法在成功率上优于MP1和FlowPolicy，特别是在具有挑战性的Meta-World任务中，在保持实时性能的同时显著提高了少量样本泛化和轨迹精度。

Conclusion: 提出的改进MeanFlow策略在实时性能、少量样本泛化和轨迹精度方面有效提升了机器人的操作能力，是高精度机器人操作的更强解决方案。

Abstract: Robot manipulation, a key capability of embodied AI, has turned to data-driven generative policy frameworks, but mainstream approaches like Diffusion Models suffer from high inference latency and Flow-based Methods from increased architectural complexity. While simply applying meanFlow on robotic tasks achieves single-step inference and outperforms FlowPolicy, it lacks few-shot generalization due to fixed temperature hyperparameters in its Dispersive Loss and misaligned predicted-true mean velocities. To solve these issues, this study proposes an improved MeanFlow-based Policies: we introduce a lightweight Cosine Loss to align velocity directions and use the Differential Derivation Equation (DDE) to optimize the Jacobian-Vector Product (JVP) operator. Experiments on Adroit and Meta-World tasks show the proposed method outperforms MP1 and FlowPolicy in average success rate, especially in challenging Meta-World tasks, effectively enhancing few-shot generalization and trajectory accuracy of robot manipulation policies while maintaining real-time performance, offering a more robust solution for high-precision robotic manipulation.

</details>


### [42] [TwinAligner: Visual-Dynamic Alignment Empowers Physics-aware Real2Sim2Real for Robotic Manipulation](https://arxiv.org/abs/2512.19390)
*Hongwei Fan,Hang Dai,Jiyao Zhang,Jinzhou Li,Qiyang Yan,Yujie Zhao,Mingju Gao,Jinghang Wu,Hao Tang,Hao Dong*

Main category: cs.RO

TL;DR: 本论文提出的 TwinAligner 系统通过针对视觉和动态一致性进行对齐，提升了机器人学习效率，实现模拟到现实政策的有效转移。


<details>
  <summary>Details</summary>
Motivation: 尽管机器人领域朝着数据驱动的端到端学习发展，但昂贵的现实世界数据限制了进展。因此，模拟器作为成本效益高的替代方案，但模拟与现实之间的差距仍然是有效政策转移的挑战。

Method: 引入了双重对齐模块，分别针对视觉和动态一致性，通过 SDF 重构及可编辑的 3DGS 渲染实现像素级对齐，同时识别机器人与物体交互中的刚性物理以保障动态一致性。

Result: 定量评估显示 TwinAligner 在视觉和动态的真实到模拟对齐方面表现出色，使得在模拟中训练的政策能够在现实世界中实现强大的零样本泛化。

Conclusion: TwinAligner 能够显著提升机器人学习，确保模拟与现实之间的政策表现一致性，从而促进大规模机器人学习的进步。

Abstract: The robotics field is evolving towards data-driven, end-to-end learning, inspired by multimodal large models. However, reliance on expensive real-world data limits progress. Simulators offer cost-effective alternatives, but the gap between simulation and reality challenges effective policy transfer. This paper introduces TwinAligner, a novel Real2Sim2Real system that addresses both visual and dynamic gaps. The visual alignment module achieves pixel-level alignment through SDF reconstruction and editable 3DGS rendering, while the dynamic alignment module ensures dynamic consistency by identifying rigid physics from robot-object interaction. TwinAligner improves robot learning by providing scalable data collection and establishing a trustworthy iterative cycle, accelerating algorithm development. Quantitative evaluations highlight TwinAligner's strong capabilities in visual and dynamic real-to-sim alignment. This system enables policies trained in simulation to achieve strong zero-shot generalization to the real world. The high consistency between real-world and simulated policy performance underscores TwinAligner's potential to advance scalable robot learning. Code and data will be released on https://twin-aligner.github.io

</details>


### [43] [Real2Edit2Real: Generating Robotic Demonstrations via a 3D Control Interface](https://arxiv.org/abs/2512.19402)
*Yujie Zhao,Hongwei Fan,Di Chen,Shengcong Chen,Liliang Chen,Xiaoqi Li,Guanghui Ren,Hao Dong*

Main category: cs.RO

TL;DR: 介绍Real2Edit2Real框架，通过结合3D编辑与2D视觉数据，在机器人操控任务中生成新的演示数据，提高数据效率。


<details>
  <summary>Details</summary>
Motivation: 在机器人学习中，政策的鲁棒性受限于多样化演示的收集成本，特别是在操控任务中的空间泛化。

Method: 通过3D控制接口将3D可编辑性与2D视觉数据结合，从多视角RGB观测中重建场景几何结构，并对点云进行深度可靠的3D编辑，以生成新的操作轨迹。

Result: 实验结果表明，仅用1-5个源演示生成的数据训练的政策可匹敌或超越50个真实演示训练的政策，数据效率提高达到10-50倍。

Conclusion: 该框架显著提高了数据效率，并可用于不同的操作任务生成新的演示数据。

Abstract: Recent progress in robot learning has been driven by large-scale datasets and powerful visuomotor policy architectures, yet policy robustness remains limited by the substantial cost of collecting diverse demonstrations, particularly for spatial generalization in manipulation tasks. To reduce repetitive data collection, we present Real2Edit2Real, a framework that generates new demonstrations by bridging 3D editability with 2D visual data through a 3D control interface. Our approach first reconstructs scene geometry from multi-view RGB observations with a metric-scale 3D reconstruction model. Based on the reconstructed geometry, we perform depth-reliable 3D editing on point clouds to generate new manipulation trajectories while geometrically correcting the robot poses to recover physically consistent depth, which serves as a reliable condition for synthesizing new demonstrations. Finally, we propose a multi-conditional video generation model guided by depth as the primary control signal, together with action, edge, and ray maps, to synthesize spatially augmented multi-view manipulation videos. Experiments on four real-world manipulation tasks demonstrate that policies trained on data generated from only 1-5 source demonstrations can match or outperform those trained on 50 real-world demonstrations, improving data efficiency by up to 10-50x. Moreover, experimental results on height and texture editing demonstrate the framework's flexibility and extensibility, indicating its potential to serve as a unified data generation framework.

</details>


### [44] [MaP-AVR: A Meta-Action Planner for Agents Leveraging Vision Language Models and Retrieval-Augmented Generation](https://arxiv.org/abs/2512.19453)
*Zhenglong Guo,Yiming Zhao,Feng Jiang,Heng Jin,Zongbao Feng,Jianbin Zhou,Siyuan Xu*

Main category: cs.RO

TL;DR: 本文提出了一种新的任务规划方法MaP-AVR，强调技能集的泛化能力，并通过meta-action和RAG技术显著提高了机器人在复杂环境中执行任务的效果。


<details>
  <summary>Details</summary>
Motivation: 强调任务规划中的技能集定义，与现有的提升理解能力的研究相比，技能集的广泛概化能力同样重要。

Method: 通过生成meta-action集合并结合检索增强生成(RAG)技术来构建任务规划器。使用GPT-4o作为预训练的LLM/VLM模型进行实验验证。

Result: 该方法在机器人执行任务的能力上展现出良好的性能，成功处理复杂日常任务。

Conclusion: MaP-AVR展示了与当前最先进的方法相比，优越的性能，验证了其有效性。

Abstract: Embodied robotic AI systems designed to manage complex daily tasks rely on a task planner to understand and decompose high-level tasks. While most research focuses on enhancing the task-understanding abilities of LLMs/VLMs through fine-tuning or chain-of-thought prompting, this paper argues that defining the planned skill set is equally crucial. To handle the complexity of daily environments, the skill set should possess a high degree of generalization ability. Empirically, more abstract expressions tend to be more generalizable. Therefore, we propose to abstract the planned result as a set of meta-actions. Each meta-action comprises three components: {move/rotate, end-effector status change, relationship with the environment}. This abstraction replaces human-centric concepts, such as grasping or pushing, with the robot's intrinsic functionalities. As a result, the planned outcomes align seamlessly with the complete range of actions that the robot is capable of performing. Furthermore, to ensure that the LLM/VLM accurately produces the desired meta-action format, we employ the Retrieval-Augmented Generation (RAG) technique, which leverages a database of human-annotated planning demonstrations to facilitate in-context learning. As the system successfully completes more tasks, the database will self-augment to continue supporting diversity. The meta-action set and its integration with RAG are two novel contributions of our planner, denoted as MaP-AVR, the meta-action planner for agents composed of VLM and RAG. To validate its efficacy, we design experiments using GPT-4o as the pre-trained LLM/VLM model and OmniGibson as our robotic platform. Our approach demonstrates promising performance compared to the current state-of-the-art method. Project page: https://map-avr.github.io/.

</details>


### [45] [REALM: A Real-to-Sim Validated Benchmark for Generalization in Robotic Manipulation](https://arxiv.org/abs/2512.19562)
*Martin Sedlacek,Pavlo Yefanov,Georgy Ponimatkin,Jai Bardhan,Simon Pilc,Mederic Fourmy,Evangelos Kazakos,Cees G. M. Snoek,Josef Sivic,Vladimir Petrik*

Main category: cs.RO

TL;DR: REALM是一个新的模拟环境，旨在评估视觉-语言-动作模型的泛化能力，重点关注其在真实环境中的表现和存在的弱点。


<details>
  <summary>Details</summary>
Motivation: 应对视觉-语言-动作模型在真实世界中泛化能力差、评估成本高的挑战。

Method: 提出REALM，一个新的模拟环境和基准，用于评估视觉-语言-动作模型的泛化能力，包括高保真视觉和对齐的机器人控制。

Result: 通过对π_{0}、π_{0}-FAST和GR00T N1.5模型的评估，展示了在15个扰动因素和7个操作技能下，模型的泛化和鲁棒性仍然存在问题。

Conclusion: 模拟是评估视觉-语言-动作模型在现实世界中的表现的有效工具，但目前这些模型的泛化和鲁棒性仍然是一个开放的挑战。

Abstract: Vision-Language-Action (VLA) models empower robots to understand and execute tasks described by natural language instructions. However, a key challenge lies in their ability to generalize beyond the specific environments and conditions they were trained on, which is presently difficult and expensive to evaluate in the real-world. To address this gap, we present REALM, a new simulation environment and benchmark designed to evaluate the generalization capabilities of VLA models, with a specific emphasis on establishing a strong correlation between simulated and real-world performance through high-fidelity visuals and aligned robot control. Our environment offers a suite of 15 perturbation factors, 7 manipulation skills, and more than 3,500 objects. Finally, we establish two task sets that form our benchmark and evaluate the π_{0}, π_{0}-FAST, and GR00T N1.5 VLA models, showing that generalization and robustness remain an open challenge. More broadly, we also show that simulation gives us a valuable proxy for the real-world and allows us to systematically probe for and quantify the weaknesses and failure modes of VLAs. Project page: https://martin-sedlacek.com/realm

</details>


### [46] [Results of the 2024 CommonRoad Motion Planning Competition for Autonomous Vehicles](https://arxiv.org/abs/2512.19564)
*Yanliang Huang,Xia Yan,Peiran Yin,Zhenduo Zhang,Zeyan Shao,Youran Wang,Haoliang Huang,Matthias Althoff*

Main category: cs.RO

TL;DR: 本报告介绍了2024年第四届CommonRoad运动规划竞赛的设置和结果，旨在通过标准化基准评估运动规划算法的表现，推动自主车辆技术的发展。


<details>
  <summary>Details</summary>
Motivation: 为了填补不同自主车辆运动规划方法在标准化基准上缺乏比较的空白，进而促进算法的发展和优化。

Method: 通过使用CommonRoad基准套件，组织第四届CommonRoad运动规划竞赛，评估不同运动规划算法的性能。

Result: 竞赛涵盖了高速公路和城市环境的多样化交通场景，高性能规划者在2023和2024年间的表现被比较，结果将促使更好的算法设计。

Conclusion: 本次运动规划竞赛为评估自主车辆的运动规划方法提供了标准化的测试平台，各类规划算法的表现得以在效率、安全性、舒适性和遵守交通规则等方面进行比较。

Abstract: Over the past decade, a wide range of motion planning approaches for autonomous vehicles has been developed to handle increasingly complex traffic scenarios. However, these approaches are rarely compared on standardized benchmarks, limiting the assessment of relative strengths and weaknesses. To address this gap, we present the setup and results of the 4th CommonRoad Motion Planning Competition held in 2024, conducted using the CommonRoad benchmark suite. This annual competition provides an open-source and reproducible framework for benchmarking motion planning algorithms. The benchmark scenarios span highway and urban environments with diverse traffic participants, including passenger cars, buses, and bicycles. Planner performance is evaluated along four dimensions: efficiency, safety, comfort, and compliance with selected traffic rules. This report introduces the competition format and provides a comparison of representative high-performing planners from the 2023 and 2024 editions.

</details>


### [47] [LIMOncello: Revisited IKFoM on the SGal(3) Manifold for Fast LiDAR-Inertial Odometry](https://arxiv.org/abs/2512.19567)
*Carlos Pérez-Ruiz,Joan Solà*

Main category: cs.RO

TL;DR: LIMOncello是一种高效的LiDAR-惯性测程系统，利用$	ext{SGal}(3)$流形减少漂移，增量映射后端提高内存效率，表现出竞争力的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 开发一种高效的LiDAR-惯性测程（Odometry）系统，以改善在低可观测性条件下的运动估计，并降低内存使用。

Method: 采用迭代误差状态卡尔曼滤波器后端建模6-DoF运动，使用$	ext{SGal}(3)$流形，并配备轻量级的增量i-Octree映射后端，为数据更新提供支持。

Result: LIMOncello显著提高了在几何稀疏环境中的鲁棒性和准确性，相比传统方法展示了更好的性能。

Conclusion: LIMOncello展示了在几何稀疏环境中具有竞争力的准确性和更好的鲁棒性，且具备实时性能和稳定的内存增长。

Abstract: This work introduces LIMOncello, a tightly coupled LiDAR-Inertial Odometry system that models 6-DoF motion on the $\mathrm{SGal}(3)$ manifold within an iterated error-state Kalman filter backend. Compared to state representations defined on $\mathrm{SO}(3)\times\mathbb{R}^6$, the use of $\mathrm{SGal}(3)$ provides a coherent and numerically stable discrete-time propagation model that helps limit drift in low-observability conditions.
  LIMOncello also includes a lightweight incremental i-Octree mapping backend that enables faster updates and substantially lower memory usage than incremental kd-tree style map structures, without relying on locality-restricted search heuristics. Experiments on multiple real-world datasets show that LIMOncello achieves competitive accuracy while improving robustness in geometrically sparse environments. The system maintains real-time performance with stable memory growth and is released as an extensible open-source implementation at https://github.com/CPerezRuiz335/LIMOncello.

</details>


### [48] [LeLaR: The First In-Orbit Demonstration of an AI-Based Satellite Attitude Controller](https://arxiv.org/abs/2512.19576)
*Kirill Djebko,Tom Baumann,Erik Dilger,Frank Puppe,Sergio Montenegro*

Main category: cs.RO

TL;DR: 本研究首次在轨道上成功展示了基于AI的姿态控制器，利用深度强化学习，显示出卓越的稳健性能，对比传统控制器。


<details>
  <summary>Details</summary>
Motivation: 传统控制器设计耗时，且对模型不确定性和操作边界条件变化敏感，因此需要寻找更有效的控制策略。

Method: 采用深度强化学习(DRL)训练AI控制器，完全基于仿真方法，并在InnoCube 3U纳米卫星上部署。

Result: AI控制器在重复的轨道机动中显示出优越的性能，并与传统的PD控制器进行比较。

Conclusion: 在实际轨道中，AI控制器表现出稳健的性能，成功应用于惯性指向机动操作。

Abstract: Attitude control is essential for many satellite missions. Classical controllers, however, are time-consuming to design and sensitive to model uncertainties and variations in operational boundary conditions. Deep Reinforcement Learning (DRL) offers a promising alternative by learning adaptive control strategies through autonomous interaction with a simulation environment. Overcoming the Sim2Real gap, which involves deploying an agent trained in simulation onto the real physical satellite, remains a significant challenge. In this work, we present the first successful in-orbit demonstration of an AI-based attitude controller for inertial pointing maneuvers. The controller was trained entirely in simulation and deployed to the InnoCube 3U nanosatellite, which was developed by the Julius-Maximilians-Universität Würzburg in cooperation with the Technische Universität Berlin, and launched in January 2025. We present the AI agent design, the methodology of the training procedure, the discrepancies between the simulation and the observed behavior of the real satellite, and a comparison of the AI-based attitude controller with the classical PD controller of InnoCube. Steady-state metrics confirm the robust performance of the AI-based controller during repeated in-orbit maneuvers.

</details>


### [49] [Learning Generalizable Hand-Object Tracking from Synthetic Demonstrations](https://arxiv.org/abs/2512.19583)
*Yinhuai Wang,Runyi Yu,Hok Wai Tsui,Xiaoyi Lin,Hui Zhang,Qihan Zhao,Ke Fan,Miao Li,Jie Song,Jingbo Wang,Qifeng Chen,Ping Tan*

Main category: cs.RO

TL;DR: 我们提出了一种从合成数据中学习可泛化手-物体追踪控制器的系统，包含手-物体规划和追踪组件，能够在多样的物体和手形态下表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前手-物体追踪技术受限于需要大量人类示范数据，限制了其泛化能力和应用范围。

Method: 提出了HOP（手-物体规划器）和HOT（手-物体追踪器），通过强化学习和交互模仿学习实现合成到物理的转移。

Result: 通过广泛评估，显示出该方法能在复杂的长时间序列中有效跟踪，包括物体重新排列和灵活的手内重定向。

Conclusion: 该系统通过使用合成数据实现手-物体追踪控制器的可泛化学习，展现了在复杂操控任务中的应用潜力。

Abstract: We present a system for learning generalizable hand-object tracking controllers purely from synthetic data, without requiring any human demonstrations. Our approach makes two key contributions: (1) HOP, a Hand-Object Planner, which can synthesize diverse hand-object trajectories; and (2) HOT, a Hand-Object Tracker that bridges synthetic-to-physical transfer through reinforcement learning and interaction imitation learning, delivering a generalizable controller conditioned on target hand-object states. Our method extends to diverse object shapes and hand morphologies. Through extensive evaluations, we show that our approach enables dexterous hands to track challenging, long-horizon sequences including object re-arrangement and agile in-hand reorientation. These results represent a significant step toward scalable foundation controllers for manipulation that can learn entirely from synthetic data, breaking the data bottleneck that has long constrained progress in dexterous manipulation.

</details>


### [50] [LoGoPlanner: Localization Grounded Navigation Policy with Metric-aware Visual Geometry](https://arxiv.org/abs/2512.19629)
*Jiaqi Peng,Wenzhe Cai,Yuqiang Yang,Tai Wang,Yuan Shen,Jiangmiao Pang*

Main category: cs.RO

TL;DR: LoGoPlanner是一种新的本地化驱动的端到端导航框架，通过改进视觉几何及场景重构，实现了在非结构化环境中更高效和准确的机器人导航。


<details>
  <summary>Details</summary>
Motivation: 解决传统模块化流程中由于感知、定位、映射和规划模块之间的延迟和级联错误的问题，从而提高移动机器人在非结构化环境中的导航能力。

Method: 提出了一种本地化驱动的端到端导航框架，通过微调视觉几何骨干网，重构场景几何，并根据隐式几何调节策略。

Result: 在模拟和现实环境中验证LoGoPlanner的有效性，发现其设计减少了累计错误，并提高了规划一致性和障碍物规避能力。

Conclusion: LoGoPlanner通过对长时间视觉几何骨干网的微调和场景几何的重构，提高了导航的准确性和高效性，整体上实现了27.3%以上的改进，并在不同环境和实体之间表现出强的泛化能力。

Abstract: Trajectory planning in unstructured environments is a fundamental and challenging capability for mobile robots. Traditional modular pipelines suffer from latency and cascading errors across perception, localization, mapping, and planning modules. Recent end-to-end learning methods map raw visual observations directly to control signals or trajectories, promising greater performance and efficiency in open-world settings. However, most prior end-to-end approaches still rely on separate localization modules that depend on accurate sensor extrinsic calibration for self-state estimation, thereby limiting generalization across embodiments and environments. We introduce LoGoPlanner, a localization-grounded, end-to-end navigation framework that addresses these limitations by: (1) finetuning a long-horizon visual-geometry backbone to ground predictions with absolute metric scale, thereby providing implicit state estimation for accurate localization; (2) reconstructing surrounding scene geometry from historical observations to supply dense, fine-grained environmental awareness for reliable obstacle avoidance; and (3) conditioning the policy on implicit geometry bootstrapped by the aforementioned auxiliary tasks, thereby reducing error propagation.We evaluate LoGoPlanner in both simulation and real-world settings, where its fully end-to-end design reduces cumulative error while metric-aware geometry memory enhances planning consistency and obstacle avoidance, leading to more than a 27.3\% improvement over oracle-localization baselines and strong generalization across embodiments and environments. The code and models have been made publicly available on the \href{https://steinate.github.io/logoplanner.github.io/}{project page}.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [51] [From Prompt to Product: A Human-Centered Benchmark of Agentic App Generation Systems](https://arxiv.org/abs/2512.18080)
*Marcos Ortiz,Justin Hill,Collin Overbay,Ingrida Semenec,Frederic Sauve-Hoover,Jim Schwoebel,Joel Shor*

Main category: cs.HC

TL;DR: 本文提出了一种以人为中心的基准来评估提示至应用系统，展示了Firebase Studio在用户体验方面的优越性，并强调了视觉与功能可靠性之间的差距。


<details>
  <summary>Details</summary>
Motivation: 评估生成完整堆栈网页应用的代理AI系统仍然存在挑战，因此需要建立一个以人为中心的基准来进行评估。

Method: 进行大规模的人类评估研究，比较三种常用的提示至应用平台：Replit、Bolt和Firebase Studio。

Result: 通过大量的提示生成288个应用程序工件，并进行了205名参与者参与的对比研究，发现这些系统在用户体验、视觉吸引力和用户信任方面表现不同。

Conclusion: Firebase Studio在所有人类评估的维度上表现最佳，强调了视觉吸引力和功能可靠性之间的差距。

Abstract: Agentic AI systems capable of generating full-stack web applications from natural language prompts ("prompt- to-app") represent a significant shift in software development. However, evaluating these systems remains challenging, as visual polish, functional correctness, and user trust are often misaligned. As a result, it is unclear how existing prompt-to-app tools compare under realistic, human-centered evaluation criteria. In this paper, we introduce a human-centered benchmark for evaluating prompt-to-app systems and conduct a large-scale comparative study of three widely used platforms: Replit, Bolt, and Firebase Studio. Using a diverse set of 96 prompts spanning common web application tasks, we generate 288 unique application artifacts. We evaluate these systems through a large-scale human-rater study involving 205 participants and 1,071 quality-filtered pairwise comparisons, assessing task-based ease of use, visual appeal, perceived completeness, and user trust. Our results show that these systems are not interchangeable: Firebase Studio consistently outperforms competing platforms across all human-evaluated dimensions, achieving the highest win rates for ease of use, trust, visual appeal, and visual appropriateness. Bolt performs competitively on visual appeal but trails Firebase on usability and trust, while Replit underperforms relative to both across most metrics. These findings highlight a persistent gap between visual polish and functional reliability in prompt-to-app systems and demonstrate the necessity of interactive, task-based evaluation. We release our benchmark framework, prompt set, and generated artifacts to support reproducible evaluation and future research in agentic application generation.

</details>


### [52] [Dimensionality Reduction Considered Harmful (Some of the Time)](https://arxiv.org/abs/2512.18230)
*Hyeon Jeon*

Main category: cs.HC

TL;DR: 本论文聚焦于提升降维技术在视觉分析中的可靠性，提出了新评估指标和优化方法，以解决面临的可靠性挑战。


<details>
  <summary>Details</summary>
Motivation: 视觉分析在决策过程中至关重要，但其可靠性存疑，分析得出的见解可能与实际数据不符。

Method: 通过研究降维技术，分析其在高维数据视觉分析中的应用，同时提出新的评估指标、优化策略和交互技术以提高可靠性。

Result: 改善了降维技术的可靠性，提出了新方法来评估和优化视觉分析过程。

Conclusion: 我们的研究为更加可靠的视觉分析实践奠定了基础。

Abstract: Visual analytics now plays a central role in decision-making across diverse disciplines, but it can be unreliable: the knowledge or insights derived from the analysis may not accurately reflect the underlying data. In this dissertation, we improve the reliability of visual analytics with a focus on dimensionality reduction (DR). DR techniques enable visual analysis of high-dimensional data by reducing it to two or three dimensions, but they inherently introduce errors that can compromise the reliability of visual analytics. To this end, I investigate reliability challenges that practitioners face when using DR for visual analytics. Then, I propose technical solutions to address these challenges, including new evaluation metrics, optimization strategies, and interaction techniques. We conclude the thesis by discussing how our contributions lay the foundation for achieving more reliable visual analytics practices.

</details>


### [53] [The Social Blindspot in Human-AI Collaboration: How Undetected AI Personas Reshape Team Dynamics](https://arxiv.org/abs/2512.18234)
*Lixiang Yan,Xibin Han,Yu Zhang,Samuel Greiff,Inge Molenaar,Roberto Martinez-Maldonado,Yizhou Fan,Linxuan Zhao,Xinyu Li,Yueqiao Jin,Dragan Gašević*

Main category: cs.HC

TL;DR: 生成AI系统在协作工作中逐渐从可见工具演变为人类般的交际参与者，本文探讨了AI队友的沟通角色如何影响团队动态，尤其是在参与者未识别其人工属性时的影响。


<details>
  <summary>Details</summary>
Motivation: 随着人类类AI在教育、组织和公民环境中大规模部署，探讨这些AI如何影响团队动态成为一个日益重要的问题。

Method: 通过一项大规模混合设计实验（N = 905），观察具有不同沟通人格的AI队友对分析、创造和伦理任务的协作影响，参与者在三人小组中工作，且未被告知有AI参与。

Result: 结果显示，参与者对AI队友的识别能力有限，但AI的人格确实对团队的心理安全感和讨论质量产生了显著影响，尤其是相对立的人格降低了讨论质量和心理安全感，而支持性的人格提升了讨论质量。

Conclusion: AI系统可以通过人格层面的线索在混合团队中隐性调节协作规范，这表明人格设计在混合团队中构成了一种社会治理形式，对AI在集体环境中的负责部署具有重要启示。

Abstract: As generative AI systems become increasingly embedded in collaborative work, they are evolving from visible tools into human-like communicative actors that participate socially rather than merely providing information. Yet little is known about how such agents shape team dynamics when their artificial nature is not recognised, a growing concern as human-like AI is deployed at scale in education, organisations, and civic contexts where collaboration underpins collective outcomes. In a large-scale mixed-design experiment (N = 905), we examined how AI teammates with distinct communicative personas, supportive or contrarian, affected collaboration across analytical, creative, and ethical tasks. Participants worked in triads that were fully human or hybrid human-AI teams, without being informed of AI involvement. Results show that participants had limited ability to detect AI teammates, yet AI personas exerted robust social effects. Contrarian personas reduced psychological safety and discussion quality, whereas supportive personas improved discussion quality without affecting safety. These effects persisted after accounting for individual differences in detectability, revealing a dissociation between influence and awareness that we term the social blindspot. Linguistic analyses confirmed that personas were enacted through systematic differences in affective and relational language, with partial mediation for discussion quality but largely direct effects on psychological safety. Together, the findings demonstrate that AI systems can tacitly regulate collaborative norms through persona-level cues, even when users remain unaware of their presence. We argue that persona design constitutes a form of social governance in hybrid teams, with implications for the responsible deployment of AI in collective settings.

</details>


### [54] [Emergent Learner Agency in Implicit Human-AI Collaboration: How AI Personas Reshape Creative-Regulatory Interaction](https://arxiv.org/abs/2512.18239)
*Yueqiao Jin,Roberto Martinez-Maldonado,Dragan Gašević,Lixiang Yan*

Main category: cs.HC

TL;DR: 本研究探讨了支持型与对抗型人工智能在隐性人机合作中的影响，发现对抗型AI促进更具挑战性的讨论，而支持型AI则倾向于增进一致性，二者在团队满意度和心理安全感上存在设计张力。


<details>
  <summary>Details</summary>
Motivation: 随着生成性AI在协作学习中的广泛应用，有必要探讨AI角色如何影响学习者的主体性，特别是在AI身份未被公开的情况下。

Method: 该研究采用随机实验设计，将224名大学生分配到三种条件中，并使用创意调节框架对10分钟的群聊进行编码，结合过渡网络分析、理论驱动的序列模式挖掘和高斯混合聚类等方法来研究学习者主体性及其与认知负荷等因素的关系。

Result: 对抗型AI促进更具挑战性和反思性的讨论结构，而支持型AI则倾向于促进一致性和顺利的达成共识。尽管认知负荷和创造性成果方面没有显著差异，但对抗型AI却显著降低了团队满意度和心理安全感。

Conclusion: 研究揭示了在混合人机团队中，使用不同类型的人工智能（支持型与对抗型）会影响学习者的主体性、团队满意度和心理安全感之间存在设计张力。

Abstract: Generative AI is increasingly embedded in collaborative learning, yet little is known about how AI personas shape learner agency when AI teammates are present but not disclosed. This mechanism study examines how supportive and contrarian AI personas reconfigure emergent learner agency, discourse patterns, and experiences in implicit human-AI creative collaboration. A total of 224 university students were randomly assigned to 97 online triads in one of three conditions: human-only control, hybrid teams with a supportive AI, or hybrid teams with a contrarian AI. Participants completed an individual-group-individual movie-plot writing task; the 10-minute group chat was coded using a creative-regulatory framework. We combined transition network analysis, theory-driven sequential pattern mining, and Gaussian mixture clustering to model structural, temporal, and profile-level manifestations of agency, and linked these to cognitive load, psychological safety, teamwork satisfaction, and embedding-based creative performance. Contrarian AI produced challenge- and reflection-rich discourse structures and motifs indicating productive friction, whereas supportive AI fostered agreement-centred trajectories and smoother convergence. Clustering showed AI agents concentrated in challenger profiles, with reflective regulation uniquely human. While no systematic differences emerged in cognitive load or creative gains, contrarian AI consistently reduced teamwork satisfaction and psychological safety. The findings reveal a design tension between leveraging cognitive conflict and maintaining affective safety and ownership in hybrid human-AI teams.

</details>


### [55] [Leveraging Peer, Self, and Teacher Assessments for Generative AI-Enhanced Feedback](https://arxiv.org/abs/2512.18306)
*Alvaro Becerra,Ruth Cobos*

Main category: cs.HC

TL;DR: 本研究探讨了在AICoFe系统中利用生成人工智能支持反馈过程，提出了一种新的模型以提升反馈的有效性和透明度。


<details>
  <summary>Details</summary>
Motivation: 解决高等教育中在大规模课程中提供及时而有意义的反馈的挑战，尤其是在教师需平衡形成性深度与可扩展性时。

Method: 通过对46个评估集进行分析，探讨评估者之间的协议、相关性及偏差。

Result: 研究发现不同评价来源之间存在一致的总体一致性，但同时也显示出评分行为的系统性变化。

Conclusion: 该研究提出了一种增强的生成人工智能模型，能够有效整合人类评估，以实现更具支持性的反馈过程。

Abstract: Providing timely and meaningful feedback remains a persistent challenge in higher education, especially in large courses where teachers must balance formative depth with scalability. Recent advances in Generative Artificial Intelligence (GenAI) offer new opportunities to support feedback processes while maintaining human oversight. This paper presents an study conducted within the AICoFe (AI-based Collaborative Feedback) system, which integrates teacher, peer, and self-assessments of engineering students' oral presentations. Using a validated rubric, 46 evaluation sets were analyzed to examine agreement, correlation, and bias across evaluators. The analyses revealed consistent overall alignment among sources but also systematic variations in scoring behavior, reflecting distinct evaluative perspectives. These findings informed the proposal of an enhanced GenAI model within AICoFe system, designed to integrate human assessments through weighted input aggregation, bias detection, and context-aware feedback generation. The study contributes empirical evidence and design principles for developing GenAI-based feedback systems that combine data-based efficiency with pedagogical validity and transparency.

</details>


### [56] [Exploration vs. Fixation: Scaffolding Divergent and Convergent Thinking for Human-AI Co-Creation with Generative Models](https://arxiv.org/abs/2512.18388)
*Chao Wen,Tung Phung,Pronita Mehrotra,Sumit Gulwani,Tomohiro Nagashima,Adish Singla*

Main category: cs.HC

TL;DR: 本研究提出一种人机共创范式，改善创意工作的过程，避免设计定势，提升用户的创造潜力。


<details>
  <summary>Details</summary>
Motivation: 现有交互模式未能支持发散探索，用户往往过早收敛于初步结果，限制了创作潜力。

Method: 提出了一种结构化的人机共创范式，包括发散和收敛思维阶段，基于Wallas的创意模型。

Result: 将该范式实例化为HAIExplore，一个图像共创系统，通过专门的头脑风暴阶段来支持发散思维，并通过一个接口来支持收敛的细化过程。

Conclusion: 我们的研究表明，明确地将创作过程分为头脑风暴和细化阶段可以缓解设计定势，提高可控性和与用户意图的一致性，并更好地支持创作工作的非线性特性。

Abstract: Generative AI has begun to democratize creative work, enabling novices to produce complex artifacts such as code, images, and videos. However, in practice, existing interaction paradigms often fail to support divergent exploration: users tend to converge too quickly on early ``good enough'' results and struggle to move beyond them, leading to premature convergence and design fixation that constrains their creative potential. To address this, we propose a structured, process-oriented human-AI co-creation paradigm including divergent and convergent thinking stages, grounded in Wallas's model of creativity. To avoid design fixation, our paradigm scaffolds both high-level exploration of conceptual ideas in the early divergent thinking phase and low-level exploration of variations in the later convergent thinking phrase. We instantiate this paradigm in HAIExplore, an image co-creation system that (i) scaffolds divergent thinking through a dedicated brainstorming stage for exploring high-level ideas in a conceptual space, and (ii) scaffolds convergent refinement through an interface that externalizes users' refinement intentions as interpretable parameters and options, making the refinement process more controllable and easier to explore. We report on a within-subjects study comparing HAIExplore with a widely used linear chat interface (ChatGPT) for creative image generation. Our findings show that explicitly scaffolding the creative process into brainstorming and refinement stages can mitigate design fixation, improve perceived controllability and alignment with users' intentions, and better support the non-linear nature of creative work. We conclude with design implications for future creativity support tools and human-AI co-creation workflows.

</details>


### [57] [Listening to the Mind: Earable Acoustic Sensing of Cognitive Load](https://arxiv.org/abs/2512.18413)
*Xijia Wei,Ting Dang,Khaldoon Al-Naimi,Yang Liu,Fahim Kawsar,Alessandro Montanari*

Main category: cs.HC

TL;DR: 本研究探讨了通过耳可穿戴设备捕获的声学信号推断认知负荷的可能性，发现认知负荷与听觉敏感性之间存在显著相关性。


<details>
  <summary>Details</summary>
Motivation: 随着耳可穿戴设备在日常生活中的逐渐普及，使用这些设备监测实时心理负担和感知负荷的机会显著增加。

Method: 设计基于语音的听觉任务以诱导不同水平的认知负荷，同时嵌入声学刺激以诱发刺激频率耳声发射(SFOAEs)，并对数据进行统计分析。

Result: 耳朵音频感知能够非侵入性地捕捉耳道中的细微听觉和生理信号，从而实现对认知状态的连续和背景感知监控。

Conclusion: 耳朵音频感知可以支持在自然环境中进行可扩展的实时认知负荷监测，为未来增强认知应用奠定基础。

Abstract: Earable acoustic sensing offers a powerful and non-invasive modality for capturing fine-grained auditory and physiological signals directly from the ear canal, enabling continuous and context-aware monitoring of cognitive states. As earable devices become increasingly embedded in daily life, they provide a unique opportunity to sense mental effort and perceptual load in real time through auditory interactions. In this study, we present the first investigation of cognitive load inference through auditory perception using acoustic signals captured by off-the-shelf in-ear devices. We designed speech-based listening tasks to induce varying levels of cognitive load, while concurrently embedding acoustic stimuli to evoke Stimulus Frequency Otoacoustic Emission (SFOAEs) as a proxy for cochlear responsiveness. Statistical analysis revealed a significant association (p < 0.01) between increased cognitive load and changes in auditory sensitivity, with 63.2% of participants showing peak sensitivity at 3 kHz. Notably, sensitivity patterns also varied across demographic subgroups, suggesting opportunities for personalized sensing. Our findings demonstrate that earable acoustic sensing can support scalable, real-time cognitive load monitoring in natural settings, laying a foundation for future applications in augmented cognition, where everyday auditory technologies adapt to and support the users mental health.

</details>


### [58] [DASH: Deception-Augmented Shared Mental Model for a Human-Machine Teaming System](https://arxiv.org/abs/2512.18616)
*Zelin Wan,Han Jun Yoon,Nithin Alluru,Terrence J. Moore,Frederica F. Nelson,Seunghyun Yoon,Hyuk Lim,Dan Dongseong Kim,Jin-Hee Cho*

Main category: cs.HC

TL;DR: DASH是一个新颖的人机合作框架，通过将主动欺骗纳入共享心理模型，以提升任务的韧性和安全性。在高攻击率环境下，该框架显著提高任务成功率。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在解决现有共享心理模型方法中忽视内部威胁的问题，从而提升关键任务应用的安全性和效率。

Method: DASH框架引入了"诱饵任务"以检测内部威胁，并在检测到威胁时激活定制的恢复机制。

Result: DASH的实证评估表明，它在高攻击率下的任务成功率达到约80%，是基线框架的八倍。

Conclusion: DASH是一个有效的框架，通过嵌入主动欺骗来增强人机团队的任务韧性，并在高攻击率下保持约80%的任务成功率。

Abstract: We present DASH (Deception-Augmented Shared mental model for Human-machine teaming), a novel framework that enhances mission resilience by embedding proactive deception into Shared Mental Models (SMM). Designed for mission-critical applications such as surveillance and rescue, DASH introduces "bait tasks" to detect insider threats, e.g., compromised Unmanned Ground Vehicles (UGVs), AI agents, or human analysts, before they degrade team performance. Upon detection, tailored recovery mechanisms are activated, including UGV system reinstallation, AI model retraining, or human analyst replacement. In contrast to existing SMM approaches that neglect insider risks, DASH improves both coordination and security. Empirical evaluations across four schemes (DASH, SMM-only, no-SMM, and baseline) show that DASH sustains approximately 80% mission success under high attack rates, eight times higher than the baseline. This work contributes a practical human-AI teaming framework grounded in shared mental models, a deception-based strategy for insider threat detection, and empirical evidence of enhanced robustness under adversarial conditions. DASH establishes a foundation for secure, adaptive human-machine teaming in contested environments.

</details>


### [59] [Household Plastic Recycling: Empirical Insights and Design Explorations](https://arxiv.org/abs/2512.18889)
*Ashley Colley,Emma Kirjavainen,Sari Tapio,Jonna Häkkilä*

Main category: cs.HC

TL;DR: 本文研究芬兰家庭塑料回收，通过定性研究发现居民在存储和分类时面临的摩擦，提出了设计互动回收概念的机会。


<details>
  <summary>Details</summary>
Motivation: 探索包装、家庭基础设施和数字服务交汇处的设计机会，解决家庭回收中的困难。

Method: 通过两项定性研究和四个设计概念研究芬兰家庭塑料回收。

Result: 研究1通过与居民的短访谈，发现存储、分类和处理塑料包装时存在的主要摩擦点，包括空间有限、临时存储、对正确分类的疑惑，以及处理笨重或脏物品的困难。研究2关注洗涤剂包装，参与者在购买时优先考虑价格和清洁效果，同时对环保影响、材料、冲洗和可回收性表示困惑。

Conclusion: 基于这些见解，四个学生小组设计了结合物理垃圾桶或袋子与移动应用的互动回收概念。

Abstract: This article examines household plastic recycling in Finland through two qualitative studies and four design concepts. Study 1 reports short interviews with residents about how they store, sort, and dispose of plastic packaging in their homes. The findings highlight recurring frictions: limited space, improvised storage, uncertainty about correct sorting, and difficulties with bulky or dirty items. Study 2 focuses on laundry detergent packaging as a common source of large plastic containers. Participants' purchase decisions prioritised price and cleaning performance, while expressing concern for environmental impact and confusion about materials, rinsing, and recyclability.
  Building on these insights, four student groups designed interactive recycling concepts that combine physical bins or bags with mobile applications. The concepts explore modular storage, sensing and compaction, playful feedback, and reward schemes to support domestic recycling routines. Together, the studies and concepts point to design opportunities at the intersection of packaging, home infrastructure, and digital services, while also raising questions about feasibility, privacy, and the cost of new devices.

</details>


### [60] [Narrative Scaffolding: Transforming Data-Driven Sensemaking Through Narrative-First Exploration](https://arxiv.org/abs/2512.18920)
*Oliver Huang,Muhammad Fatir,Steven Luo,Sangho Suh,Hariharan Subramonyam,Carolina Nobre*

Main category: cs.HC

TL;DR: 研究提出了一种叙事驱动的探索框架——叙事支架，通过将叙事构建作为探索和推理的主要接口，改善数据分析工具的局限性，使分析师能够更好地反思和构建连贯的解释。


<details>
  <summary>Details</summary>
Motivation: 现有的数据分析工具将叙事视为附带内容，影响分析师对推理演变的理解和系统反思能力。

Method: 提出了叙事支架框架，并在一个系统中实现，外部化迭代推理，通过叙事优先输入、语义对齐视图生成以及通过洞察来源和查询跟踪的反思支持。

Result: 在一次包含20名参与者的研究中，结果表明叙事支架有效推动了更广泛的探索、深入的反思和更具辩护性的叙事。

Conclusion: 叙事支架能够促进较广泛的探索、深入的反思以及更具辩护性的叙事，且在与可视化素养专家的评估中，系统生成的结果符合叙事意图并促进了有意探索。

Abstract: When exploring data, analysts construct narratives about what the data means by asking questions, generating visualizations, reflecting on patterns, and revising their interpretations as new insights emerge. Yet existing analysis tools treat narrative as an afterthought, breaking the link between reasoning, reflection, and the evolving story from exploration. Consequently, analysts lose the ability to see how their reasoning evolves, making it harder to reflect systematically or build coherent explanations. To address this gap, we propose Narrative Scaffolding, a framework for narrative-driven exploration that positions narrative construction as the primary interface for exploration and reasoning. We implement this framework in a system that externalizes iterative reasoning through narrative-first entry, semantically aligned view generation, and reflection support via insight provenance and inquiry tracking. In a within-subject study N=20, we demonstrate that narrative scaffolding facilitates broader exploration, deeper reflection, and more defensible narratives. An evaluation with visualization literacy experts (N = 6) confirmed that the system produced outputs aligned with narrative intent and facilitated intentional exploration.

</details>


### [61] [Advancing Accessibility: Augmented Reality Solutions for the Blind and Disabled in Bangladesh](https://arxiv.org/abs/2512.19047)
*Md Minhazul Islam Munna,Al Amin,Xin Wang,Hongbin Ma*

Main category: cs.HC

TL;DR: AR技术能够提升盲人和残疾人的生活质量，孟加拉国在该技术的应用仍处于初级阶段，但有潜力通过发展和扩展来改变这一现状。


<details>
  <summary>Details</summary>
Motivation: 寻求通过AR技术改善视觉障碍人士的生活，发现并克服孟加拉国在实现这一潜力时的挑战。

Method: 对全球AR技术在视觉障碍人士中的应用进行回顾和分析，探索其在孟加拉国的潜在应用。

Result: 目前全球正在开发多种针对视觉障碍者的AR应用，功能包括环境音频描述、物体识别和导航辅助，旨在提高独立性和生活质量。

Conclusion: 尽管孟加拉国在盲人和残疾人领域的AR技术 adoption 仍处于早期阶段，但随着智能手机的普及和AR技术的不断进步，存在适应和扩大这些解决方案的机会。

Abstract: Augmented Reality (AR) technology holds immense potential to transform the lives of blind and disabled individuals by offering enhanced interaction with their surroundings and providing real-time, accessible information. Globally, AR applications are being developed with features such as audio descriptions of environments, object recognition, and navigational aids, specifically designed to support the visually impaired. These innovations are paving the way for increased independence, mobility, and overall quality of life for millions of people worldwide. In Bangladesh, the adoption of AR technology for the blind and disabled is still in its early stages, primarily due to limited accessibility resources and infrastructure challenges. However, with the growing penetration of smartphones and continuous advancements in AR technologies, there is a promising opportunity for these solutions to be adapted, localized, and scaled within the country. This paper reviews the current state of AR technologies for the visually impaired on a global scale, explores their potential application in Bangladesh, and delves into the challenges and opportunities for broader implementation in this context.

</details>


### [62] [Towards a collaborative digital platform for railway infrastructure projects](https://arxiv.org/abs/2512.19169)
*Pierre Jehel,Pierre-Étienne Gautier,Judicaël Dehotin,Flavien Viguier*

Main category: cs.HC

TL;DR: 本论文探讨了铁路基础设施项目的协作数字平台，通过访谈识别利益相关者的需求，提出了核心功能和概念模型。


<details>
  <summary>Details</summary>
Motivation: 识别铁路基础设施设计与建设过程中，各利益相关者对协作平台的需求与期望，以便转化为功能规格。

Method: 在2022年10月至12月间进行21次访谈，访谈了35位不同角色的专家，建立一个协作数字平台的概念模型。

Result: 确定了协作平台应提供的五个核心功能，包括访问基础设施数据、加速重复任务、验证项目要求、支持决策及促进利益相关者协调。

Conclusion: 通过分析需求，提出了一个概念模型，有助于改善铁路基础设施项目的设计与建设过程。

Abstract: The management of railway infrastructure projects can be supported by collaborative digital platforms. A survey was carried out to identify the needs and expectations of the various stakeholders involved in the design and construction of railway infrastructure projects regarding collaborative platforms. These needs and expectations can then be translated into functional specifications to be included in the digital platforms. A total of 21 interviews were conducted between October and December 2022, during which 35 individuals were interviewed. Key roles were represented across the different project phases: engineers from design and construction firms, project managers, infrastructure managers. And various engineering fields were represented: civil, electrical, telecommunications, tracks, systems. These interviews were carried out by CentraleSup{é}lec | Universit{é} Paris-Saclay and by SNCF R{é}seau using a structured protocol designed to collect the specific needs of the interviewees for collaboration, as well as the guiding principles that shape both individual work practices and collaboration between professions. The resulting material was analyzed and then synthesized into a conceptual model of a collaborative digital platform for supporting the design and construction phases in a railway infrastructure project. Also, from these interviews emerged five core functionalities that the platform must offer: Providing access to existing infrastructure data; Accelerating repetitive tasks; Verifying essential project requirements; Supporting decision-making; Facilitating coordination among stakeholders.

</details>


### [63] [The Epistemological Consequences of Large Language Models: Rethinking collective intelligence and institutional knowledge](https://arxiv.org/abs/2512.19570)
*Angjelin Hila*

Main category: cs.HC

TL;DR: 文章分析了人类与LLM之间的互动对认知的威胁，阐述了集体认识论的必要性，并提出了三级规范计划以减轻认知风险。


<details>
  <summary>Details</summary>
Motivation: 研究人类与大型语言模型的互动对认知体系的影响，以维持和提升集体理性的标准。

Method: 通过提出内在和外在的正当化概念，构建了反思知识的框架，并提出了相应的规范性建议。

Result: 本文探讨了人类与大型语言模型（LLM）互动所带来的认知威胁，提出了集体认识论作为一种分布于人类集体的认识权威理论。

Conclusion: 为了减轻这些风险，文章提出了一项三级规范计划，包括个人使用的认识互动模型、促进最佳认识结果的机构和组织框架，以及在组织或立法层面上实施话语规范和抑制认知恶习的义务约束。

Abstract: We examine epistemological threats posed by human and LLM interaction. We develop collective epistemology as a theory of epistemic warrant distributed across human collectives, using bounded rationality and dual process theory as background. We distinguish internalist justification, defined as reflective understanding of why a proposition is true, from externalist justification, defined as reliable transmission of truths. Both are necessary for collective rationality, but only internalist justification produces reflective knowledge. We specify reflective knowledge as follows: agents understand the evaluative basis of a claim, when that basis is unavailable agents consistently assess the reliability of truth sources, and agents have a duty to apply these standards within their domains of competence. We argue that LLMs approximate externalist reliabilism because they can reliably transmit information whose justificatory basis is established elsewhere, but they do not themselves possess reflective justification. Widespread outsourcing of reflective work to reliable LLM outputs can weaken reflective standards of justification, disincentivize comprehension, and reduce agents' capacity to meet professional and civic epistemic duties. To mitigate these risks, we propose a three tier norm program that includes an epistemic interaction model for individual use, institutional and organizational frameworks that seed and enforce norms for epistemically optimal outcomes, and deontic constraints at organizational and or legislative levels that instantiate discursive norms and curb epistemic vices.

</details>
