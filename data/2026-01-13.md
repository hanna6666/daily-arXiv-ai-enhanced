<div id=toc></div>

# Table of Contents

- [cs.HC](#cs.HC) [Total: 30]
- [cs.RO](#cs.RO) [Total: 33]


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [1] [AI-Assisted Authoring for Transparent, Data-Driven Documents](https://arxiv.org/abs/2601.06027)
*Alfonso Piscitelli,Cristina David,Mattia De Rosa,Ali Mohammed,Federico Nanni,Jacob Pake,Roly Perera,Jessy Sodimu,Chenyiqiu Zheng*

Main category: cs.HC

TL;DR: 本研究提出了一种透明文档的概念和相应的LLM工具，旨在增强学术文章的交互性和透明度。通过应用gpt4o和Fluid语言，生成可互动的文本与数据之间的关系，评估结果表明其生成效果良好。


<details>
  <summary>Details</summary>
Motivation: 旨在提高学术文章的透明度，使读者能够更直接地探索文本与基础数据之间的关系。

Method: 使用gpt4o工具生成透明文档中的数据驱动元素，并利用Fluid编程语言进行实现和评估。

Result: 在SciGen数据集上评估结果表明，生成的表达式通常与手动生成的黄金解决方案具有扩展兼容性。

Conclusion: gpt4o工具能够生成与黄金标准解决方案兼容的复合表达式，展示了透明文档的交互性和数据驱动特性。

Abstract: We introduce _transparent documents_, interactive web-based scholarly articles which allow readers to explore the relationship to the underlying data by hovering over fragments of text, and present an LLM-based tool for authoring transparent documents, building on recent developments in data provenance for general-purpose programming languages. As a target platform, our implementation uses Fluid, an open source programming language with a provenance-tracking runtime. Our agent-based tool supports a human author during the creation of transparent documents, identifying fragments of text which can be computed from data, such as numerical values selected from records or computed by aggregations like sum and mean, comparatives and superlatives like _better than_ and _largest_, trend-adjectives like _growing_, and similar quantitative or semi-quantitative phrases, and then attempts to synthesise a suitable Fluid query over the data which generates the target string. The resulting expression is inserted into the article's web page, turning the static text fragment into an interactable data-driven element able to reveal the data that underwrites the natural language claim. We evaluate our approach on a subset of SciGen, an open source dataset consisting of tables from scientific articles and their corresponding descriptions, which we extend with hand-generated counterfactual test cases to evaluate how well machine-generated expressions generalise. Our results show that gpt4o is often able to synthesise compound expressions extensionally compatible with our gold solutions.

</details>


### [2] [Leveraging Foundation Models for Calibration-Free c-VEP BCIs](https://arxiv.org/abs/2601.06028)
*Mohammadreza Behboodi,Eli Kinney-Lang,Ali Etemad,Adam Kirton,Hatem Abou-Zeid*

Main category: cs.HC

TL;DR: 本研究提出了一种基于FM的c-VEP BCI方法，成功减少了校准时间，提升了实用性。


<details>
  <summary>Details</summary>
Motivation: 减少BCI系统长时间校准的需求，提高其实用性，支持复杂残疾人士。

Method: 使用基础模型（FM）评估c-VEP BCI系统的校准需求

Result: 在无校准的情况下，第一数据集的平均准确率为68.8%，第二数据集为71.8%；有限校准方法的准确率为92%。

Conclusion: FM方法有效消除了或显著减少了c-VEP BCI系统对长时间校准的需求。

Abstract: Foundation Models (FMs) have surged in popularity over the past five years, with applications spanning fields from computer vision to natural language processing. Brain-Computer Interfaces (BCIs) have also gained momentum due to their potential to support individuals with complex disabilities. Among BCI paradigms, code-modulated Visual Evoked Potentials (c-VEPs) remain relatively understudied, despite offering high information transfer rates and large selection target capacities. However, c-VEP systems require lengthy calibration sessions, limiting their practicality outside of laboratory settings. In this study, we use a FM for the first time to eliminate the need for lengthy calibration in c-VEP BCI systems. We evaluated two approaches: (1) a truly calibration-free approach requiring no subject-specific data, and (2) a limited calibration approach, where we assessed the benefit of incorporating incremental amounts of calibration data. In both cases, a classification head is trained on data from other subjects. For a new subject, no calibration data is required in the calibration-free setup, making the c-VEP system effectively plug-and-play. The proposed method was tested on two c-VEP datasets. For the calibration-free approach, the average accuracy on the first dataset (n = 17) was 68.8% +/- 17.6%, comparable to the full-calibration performance reported in the original study (66.2% +/- 13.8%), which required approximately 11 minutes of calibration. On the second dataset (n = 12), the calibration-free accuracy was 71.8% +/- 20.2%, versus 93.7% +/- 5.5% from the original study, which required around 3.5 minutes. A limited-calibration approach using only 20% of the subject's data (approximately 43 seconds) yielded 92% +/- 5.2% accuracy. These results indicate that our FM-based approach can effectively eliminate or significantly reduce the need for lengthy calibration in c-VEP BCIs.

</details>


### [3] [A Recommendation System-Based Framework for Enhancing Human-Machine Collaboration in Industrial Timetabling Rescheduling: Application in Preventive Maintenance](https://arxiv.org/abs/2601.06029)
*Kévin Ducharlet,Liwen Zhang,Sara Maqrot,Houssem Saidi*

Main category: cs.HC

TL;DR: 本文提出了一种基于推荐系统的框架，用于处理工业调度中的意外事件重调度问题。


<details>
  <summary>Details</summary>
Motivation: 工业调度对于确保系统高效运作至关重要，但在实际情况下，意外事件的发生常常导致执行中的干扰，因此寻求有效的重调度方案至关重要。

Method: 建立在强大的AI驱动规划引擎Timefold基础上的推荐系统框架，并通过对九个实例进行实验评估，以确定最佳启发式方法，从而支持接近最佳的决策制定。

Result: 通过对实际用例的启发式评估，找到在计算时间与解决方案质量之间最佳平衡的启发式。

Conclusion: 通过简单用例展示了推荐系统的完整过程，为处理工业调度中的重调度挑战提供了有力工具。

Abstract: Industrial timetabling is a critical task for decision-makers across various sectors to ensure efficient system operation. In real-world settings, it remains challenging because unexpected events often disrupt execution. When such events arise, effective rescheduling and collaboration between humans and machines becomes essential. This paper presents a recommendation system-based framework for handling rescheduling challenges, built on Timefold, a powerful AI-driven planning engine. Our experimental study evaluates nine instances inspired by a realworld preventive maintenance use case, aiming to identify the heuristic that best balances solution quality and computing time to support near-optimal decisionmaking when rescheduling is required due to unexpected events during operational days. Finally, we illustrate the complete process of our recommendation system through a simple use case.

</details>


### [4] [From Augmentation to Symbiosis: A Review of Human-AI Collaboration Frameworks, Performance, and Perils](https://arxiv.org/abs/2601.06030)
*Richard Jiarui Tong*

Main category: cs.HC

TL;DR: 本文回顾了人类与AI合作的历史，并提出了有效团队合作的因果链模型，分析了人机团队在判断/决策和内容创作中的不同表现，最终提出一个统一框架以实现持续收益。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索人类与AI协作的机制及其影响力，解决人机协作中存在的表现悖论，并为未来的研究与实践提供指导。

Method: 通过构建因果链模型，分析人机协作的协同效应，使用元分析探讨表现悖论，并结合扩展自我与双处理理论来提出统一框架。

Result: 该论文总结了过去60年来人类与人工智能（AI）合作的演变，探讨了从早期的"人机共生"到当代以人为中心的人工智能的不同角色。

Conclusion: 研究提出了一种统一框架，建议将人工智能视为内化的认知组件，从而实现人机协作的持久收益，并解决人机协作的表现悖论。

Abstract: This paper offers a concise, 60-year synthesis of human-AI collaboration, from Licklider's ``man-computer symbiosis" (AI as colleague) and Engelbart's ``augmenting human intellect" (AI as tool) to contemporary poles: Human-Centered AI's ``supertool" and Symbiotic Intelligence's mutual-adaptation model. We formalize the mechanism for effective teaming as a causal chain: Explainable AI (XAI) -> co-adaptation -> shared mental models (SMMs). A meta-analytic ``performance paradox" is then examined: human-AI teams tend to show negative synergy in judgment/decision tasks (underperforming AI alone) but positive synergy in content creation and problem formulation. We trace failures to the algorithm-in-the-loop dynamic, aversion/bias asymmetries, and cumulative cognitive deskilling. We conclude with a unifying framework--combining extended-self and dual-process theories--arguing that durable gains arise when AI functions as an internalized cognitive component, yielding a unitary human-XAI symbiotic agency. This resolves the paradox and delineates a forward agenda for research and practice.

</details>


### [5] [Beyond Clicking:A Step Towards Generalist GUI Grounding via Text Dragging](https://arxiv.org/abs/2601.06031)
*Zeyi Liao,Yadong Lu,Boyu Gou,Huan Sun,Ahmed Awadallah*

Main category: cs.HC

TL;DR: 该研究通过构建GUI-Drag数据集和ScreenDrag基准，显著提升了GUI文本拖拽能力，同时保持点击性能，推动了GUI基础更广泛的研究。


<details>
  <summary>Details</summary>
Motivation: 现有的GUI基础模型主要集中在鼠标点击，而拖拽操作在实际应用中同样重要，因此亟需研究和提升其能力。

Method: 通过引入GUI-Drag数据集和ScreenDrag基准进行系统评估，训练模型以提升文本拖拽能力，同时保持点击性能

Result: 模型在GUI-Drag上经过有效的持续训练策略后，在ScreenDrag上实现了显著提升，而在点击任务上保持了原有性能。

Conclusion: 提出GUI-Drag和ScreenDrag基准支持了更广泛的GUI基础研究，向通用GUI模型的发展迈进。

Abstract: Graphical user interface (GUI) grounding, the process of mapping human instructions to GUI actions, serves as a fundamental basis to autonomous GUI agents. While existing grounding models achieve promising performance to simulate the mouse click action on various click-based benchmarks, another essential mode of mouse interaction, namely dragging, remains largely underexplored. Yet, dragging the mouse to select and manipulate textual content represents a prevalent and important usage in practical GUI scenarios. To narrow this gap, we first introduce GUI-Drag, a diverse dataset of 161K text dragging examples synthesized through a scalable pipeline. To support systematic and robust evaluation, we further construct ScreenDrag, a benchmark with 5,333 examples spanning three levels of interface context, together with three dedicated metrics designed for assessing text dragging capability. Models trained on GUI-Drag with an efficient continual training strategy achieve substantial improvements on ScreenDrag, while preserving the original click-based performance on ScreenSpot, ScreenSpot-v2, and OSWorld-G. Our work encourages further research on broader GUI grounding beyond just clicking and paves way toward a truly generalist GUI grounding model. All benchmark, data, checkpoints, and code are open-sourced and available at https://osu-nlp-group.github.io/GUI-Drag.

</details>


### [6] [Applied Theory of Mind and Large Language Models - how good is ChatGPT at solving social vignettes?](https://arxiv.org/abs/2601.06032)
*Anna Katharina Holl-Etten,Nina Schnaderbeck,Elizaveta Kosareva,Leonhard Aron Prattke,Ralph Krueger,Lisa Marie Warner,Nora C. Vetter*

Main category: cs.HC

TL;DR: 本研究评估了GPT-3.5 Turbo和GPT-4在应用心智理论（ToM）任务中的有效性，发现GPT-4在复杂的ToM任务中表现优越，特别是对自闭症个体的辅助潜力。


<details>
  <summary>Details</summary>
Motivation: 探索基于语言的人工智能在心理治疗和助残系统中的应用，以改善自闭症个体的沟通能力。

Method: 比较GPT-3.5 Turbo和GPT-4在虚假失误测试、社交故事问卷和故事理解测试等三个更高阶的ToM任务中的表现，并由两名独立评分者评定准确性和不确定性标记。

Result: GPT-4在虚假失误测试中接近人类准确度，并且在社交故事问卷和故事理解测试中超越了自闭症特质个体，而GPT-3.5 Turbo表现较差。

Conclusion: 尽管GPT-4在复杂ToM任务中表现良好，但其对不确定性标记的频繁使用表明还需要进一步研究，以确保其在现实世界中的一致性和可靠性支持。

Abstract: The rapid development of language-based artificial intelligence (AI) offers new possibilities for psychotherapy and assistive systems, particularly benefitting autistic individuals who often respond well to technology. Parents of autistic persons emphasize the importance of appropriate and context-specific communication behavior. This study investigated whether GPT-3.5 Turbo and GPT-4, as language-based AI applications, are fundamentally capable of replicating this type of adequate communication behavior in the form of applied Theory of Mind (ToM). GPT-3.5 Turbo and GPT-4 were evaluated on three established higher-order ToM tasks: the Faux Pas Test, the Social Stories Questionnaire, and the Story Comprehension Test in English and German. Two independent raters scored response accuracy based on standardized manuals. In addition, responses were rated for epistemic markers as indicators of uncertainty. GPT's results were compared to human neurotypical and neurodivergent samples from previous own and others' research. GPT-4 achieved near human accuracy on the Faux Pas Test and outperformed GPT-3.5 Turbo and individuals with autistic traits. On the Social Stories Questionnaire, GPT-4 scored comparable to neurotypical adults, while GPT-3.5 Turbo remained well below. In the Story Comprehension Test, GPT-4 reached scores that exceeded neurotypical adult and adolescent benchmarks. However, GPT-4 used epistemic markers in up to 42% of responses. GPT-4 shows encouraging performance in complex higher-order ToM tasks and may offer future potential as an assistive tool for individuals with (and without) social communication difficulties. Its ability to interpret complex social situations is promising; however, the frequent use of uncertainty markers highlights the need for further study for assistive use and possibly further refinement to ensure consistent and reliable support in real-world use.

</details>


### [7] [How Generative AI Empowers Attackers and Defenders Across the Trust & Safety Landscape](https://arxiv.org/abs/2601.06033)
*Patrick Gage Kelley,Steven Rousso-Schindler,Renee Shelby,Kurt Thomas,Allison Woodruff*

Main category: cs.HC

TL;DR: 这篇论文探讨了生成性人工智能在信任与安全领域的影响，强调了其在攻击和防御方面的双重角色。


<details>
  <summary>Details</summary>
Motivation: 查明生成性人工智能在信任与安全领域的潜在影响，特别是其被攻击者滥用和防御者利用的双重能力。

Method: 通过对43位来自五个领域的信任与安全专家的定性研究进行分析。

Result: 研究结果揭示生成性人工智能在攻击和防御方面的双面性，攻击者利用其快速生成有害内容，而防御者也在探索如何利用其检测和缓解这些有害内容。

Conclusion: 提供了一个战略框架，以理解生成性人工智能在信任与安全中的影响，并为其在创建更安全的在线环境中负责任地使用指明了方向。

Abstract: Generative AI (GenAI) is a powerful technology poised to reshape Trust & Safety. While misuse by attackers is a growing concern, its defensive capacity remains underexplored. This paper examines these effects through a qualitative study with 43 Trust & Safety experts across five domains: child safety, election integrity, hate and harassment, scams, and violent extremism. Our findings characterize a landscape in which GenAI empowers both attackers and defenders. GenAI dramatically increases the scale and speed of attacks, lowering the barrier to entry for creating harmful content, including sophisticated propaganda and deepfakes. Conversely, defenders envision leveraging GenAI to detect and mitigate harmful content at scale, conduct investigations, deploy persuasive counternarratives, improve moderator wellbeing, and offer user support. This work provides a strategic framework for understanding GenAI's impact on Trust & Safety and charts a path for its responsible use in creating safer online environments.

</details>


### [8] [Human-in-the-Loop Interactive Report Generation for Chronic Disease Adherence](https://arxiv.org/abs/2601.06364)
*Xiaotian Zhang,Jinhong Yu,Pengwei Yan,Le Jiang,Xingyi Shen,Mumo Cheng,Xiaozhong Liu*

Main category: cs.HC

TL;DR: 本文提出了一种结合AI与临床医生的界面，展现了AI在临床个性化草稿生成中的应用与挑战。


<details>
  <summary>Details</summary>
Motivation: 慢性病管理需要定期的遵从性反馈，以防止可避免的住院，但临床医生缺乏时间来生成个性化的病人沟通。

Method: 提出了一种临床医生参与的界面，AI负责数据组织并通过识别基础的审查保留医生的监督。

Result: 在与三位医生审查的24个案例的试点中，AI成功生成与医生手动撰写实践相匹配的临床个性化草稿，整体均值为4.86/10，较基线5.0/10稍低，仅需进行少量编辑，且无安全关键性问题。

Conclusion: 临床AI的有效性不仅依赖于模型的准确性，还需要选择性的验证机制以维护责任感。

Abstract: Chronic disease management requires regular adherence feedback to prevent avoidable hospitalizations, yet clinicians lack time to produce personalized patient communications. Manual authoring preserves clinical accuracy but does not scale; AI generation scales but can undermine trust in patient-facing contexts. We present a clinician-in-the-loop interface that constrains AI to data organization and preserves physician oversight through recognition-based review. A single-page editor pairs AI-generated section drafts with time-aligned visualizations, enabling inline editing with visual evidence for each claim. This division of labor (AI organizes, clinician decides) targets both efficiency and accountability. In a pilot with three physicians reviewing 24 cases, AI successfully generated clinically personalized drafts matching physicians' manual authoring practice (overall mean 4.86/10 vs. 5.0/10 baseline), requiring minimal physician editing (mean 8.3\% content modification) with zero safety-critical issues, demonstrating effective automation of content generation. However, review time remained comparable to manual practice, revealing an accountability paradox: in high-stakes clinical contexts, professional responsibility requires complete verification regardless of AI accuracy. We contribute three interaction patterns for clinical AI collaboration: bounded generation with recognition-based review via chart-text pairing, automated urgency flagging that analyzes vital trends and adherence patterns with fail-safe escalation for missed critical monitoring tasks, and progressive disclosure controls that reduce cognitive load while maintaining oversight. These patterns indicate that clinical AI efficiency requires not only accurate models, but also mechanisms for selective verification that preserve accountability.

</details>


### [9] [Spatiotemporal Change-Points in Development Discourse: Insights from Social Media in Low-Resource Contexts](https://arxiv.org/abs/2601.06402)
*Woojin Jung,Charles Chear,Andrew H. Kim,Vatsal Shah,Tawfiq Ammari*

Main category: cs.HC

TL;DR: 本研究分析了赞比亚的社交媒体数据，发现发展话语有七个主题，受COVID-19和基础设施项目影响，提出了“持久话语”的概念。


<details>
  <summary>Details</summary>
Motivation: 本研究意在揭示低资源环境中发展话语的动态变化及其对技术与社会经济影响的理解。

Method: 采用混合方法管道，包括主题建模、变化点检测与定性编码，分析超过两年的地理标记社交媒体数据。

Result: 本研究探讨了低资源环境中发展话语的时空演变，识别出与公共健康和政府政策相关的七个主题，及其随时间的变化。

Conclusion: 研究表明，在线讨论反映了政策的关键点，尤其是与COVID-19疫情相关的短期危机与长期基础设施项目的持续性话语之间的区别。

Abstract: This study investigates the spatiotemporal evolution of development discourse in low-resource settings. Analyzing more than two years of geotagged X data from Zambia, we introduce a mixed-methods pipeline utilizing topic modeling, change-point detection, and qualitative coding to identify critical shifts in public debate. We identify seven recurring themes, including public health challenges and frustration with government policy, shaped by regional events and national interventions. Notably, we detect discourse changepoints linked to the COVID19 pandemic and a geothermal project, illustrating how online conversations mirror policy flashpoints. Our analysis distinguishes between the ephemeral nature of acute crises like COVID19 and the persistent, structural reorientations driven by long-term infrastructure projects. We conceptualize "durable discourse" as sustained narrative engagement with development issues. Contributing to HCI and ICTD, we examine technology's socioeconomic impact, providing practical implications and future work for direct local engagement.

</details>


### [10] [Pareto-Optimal Model Selection for Low-Cost, Single-Lead EMG Control in Embedded Systems](https://arxiv.org/abs/2601.06516)
*Carl Vincent Ladres Kho*

Main category: cs.HC

TL;DR: 消费者级生物传感器为医疗级肌电图系统提供了一种低成本替代方案，尽管低成本传感器存在显著的信号不稳定性和运动伪影。


<details>
  <summary>Details</summary>
Motivation: 推动生物传感器在低成本硬件上的应用，以应对医疗级设备的高成本和复杂性。

Method: 评估18种模型架构，包括统计启发式、深度迁移学习（ResNet50）和自定义混合网络（MaxCRNN），使用1,540秒的单一受试者数据集。

Result: 自定义MaxCRNN模型在精准度上（99% 精确率）表现最佳，随机森林（74% 准确率）被确定为嵌入式控制的帕累托最优解。

Conclusion: 在商品硬件上实现可靠的低延迟EMG控制是可行的，并且深度学习为现代边缘AI加速器提供了接近完美可靠性的途径。

Abstract: Consumer-grade biosensors offer a cost-effective alternative to medical-grade electromyography (EMG) systems, reducing hardware costs from thousands of dollars to approximately $13. However, these low-cost sensors introduce significant signal instability and motion artifacts. Deploying machine learning models on resource-constrained edge devices like the ESP32 presents a challenge: balancing classification accuracy with strict latency (<100ms) and memory (<320KB) constraints. Using a single-subject dataset comprising 1,540 seconds of raw data (1.54M data points, segmented into ~1,300 one-second windows), I evaluate 18 model architectures, ranging from statistical heuristics to deep transfer learning (ResNet50) and custom hybrid networks (MaxCRNN). While my custom "MaxCRNN" (Inception + Bi-LSTM + Attention) achieved the highest safety (99% Precision) and robustness, I identify Random Forest (74% accuracy) as the Pareto-optimal solution for embedded control on legacy microcontrollers. I demonstrate that reliable, low-latency EMG control is feasible on commodity hardware, with Deep Learning offering a path to near-perfect reliability on modern Edge AI accelerators.

</details>


### [11] [AI Washing and the Erosion of Digital Legitimacy: A Socio-Technical Perspective on Responsible Artificial Intelligence in Business](https://arxiv.org/abs/2601.06611)
*Nelly Elsayed*

Main category: cs.HC

TL;DR: 人工智能的迅速发展为企业创新开辟了新机会，但也引发了对AI洗涤的担忧，本文建立了有关AI洗涤的概念基础，并提出了相关实践的分类及其影响。


<details>
  <summary>Details</summary>
Motivation: 本文旨在建立一个理解AI洗涤的概念基础，以应对企业在使用AI技术时出现的夸大和误导行为。

Method: 借鉴绿色洗涤的类比，并结合信息系统研究中的伦理、信任、信号和数字创新的洞见，提出AI洗涤实践的分类。

Result: 研究表明，AI洗涤虽然可以带来短期收益，但长期后果严重，且对组织、行业和社会产生负面影响。

Conclusion: AI washing可能在短期内带来利益，但从长远来看会带来声誉损害、信任侵蚀和资源错配等严重后果。

Abstract: The rapid evolution of artificial intelligence (AI) systems, tools, and technologies has opened up novel, unprecedented opportunities for businesses to innovate, differentiate, and compete. However, growing concerns have emerged about the use of AI in businesses, particularly AI washing, in which firms exaggerate, misrepresent, or superficially signal their AI capabilities to gain financial and reputational advantages. This paper aims to establish a conceptual foundation for understanding AI washing. In this paper, we draw on analogies from greenwashing and insights from Information Systems (IS) research on ethics, trust, signaling, and digital innovation. This paper proposes a typology of AI washing practices across four primary domains: marketing and branding, technical capability inflation, strategic signaling, and governance-based washing. In addition, we examine their organizational, industry, and societal impacts. Our investigation and analysis reveal how AI washing can lead to short-term gains; however, it also proposes severe long-term consequences, including reputational damage, erosion of trust, and misallocation of resources. Moreover, this paper examines current research directions and open questions aimed at mitigating AI washing practices and enhancing the trust and reliability of legitimate AI systems and technologies.

</details>


### [12] [LLM-Driven Accessible Interface: A Model-Based Approach](https://arxiv.org/abs/2601.06616)
*Blessing Jerry,Lourdes Moreno,Virginia Francisco,Raquel Hervas*

Main category: cs.HC

TL;DR: 本研究提出了一种模型驱动的架构，利用大型语言模型生成个性化的可及性用户界面，旨在提升交互系统的用户体验，同时确保符合规范和可解释性。


<details>
  <summary>Details</summary>
Motivation: 在交互系统中整合大型语言模型（LLMs）开启了自适应用户体验的新机会，但也带来了可及性、可解释性和规范遵从等挑战。

Method: 提出了一种模型驱动的架构，结合结构化用户档案、声明式适配规则和经过验证的提示模板，生成个性化、多模态且符合可及性要求的用户界面。

Result: 该方法通过动态转化语言复杂度、模态和视觉结构，输出符合ISO 24495-1和W3C COGA指导的可及性模板，例如简单语言文本、图标和高对比度布局。

Conclusion: 通过SysML v2模型提供用户需求、适配规则和规范要求之间的明确可追溯性，确保了可解释和可审计的转化，并在以人为本的AI框架下，结合共同设计过程和结构化反馈机制，指导迭代精细化并支持可信赖的生成行为。

Abstract: The integration of Large Language Models (LLMs) into interactive systems opens new opportunities for adaptive user experiences, yet it also raises challenges regarding accessibility, explainability, and normative compliance. This paper presents an implemented model-driven architecture for generating personalised, multimodal, and accessibility-aligned user interfaces. The approach combines structured user profiles, declarative adaptation rules, and validated prompt templates to refine baseline accessible UI templates that conform to WCAG 2.2 and EN 301 549, tailored to cognitive and sensory support needs. LLMs dynamically transform language complexity, modality, and visual structure, producing outputs such as Plain-Language text, pictograms, and high-contrast layouts aligned with ISO 24495-1 and W3C COGA guidance. A healthcare use case demonstrates how the system generates accessible post-consultation medication instructions tailored to a user profile comprising cognitive disability and hearing impairment. SysML v2 models provide explicit traceability between user needs, adaptation rules, and normative requirements, ensuring explainable and auditable transformations. Grounded in Human-Centered AI (HCAI), the framework incorporates co-design processes and structured feedback mechanisms to guide iterative refinement and support trustworthy generative behaviour.

</details>


### [13] [Learning Password Best Practices Through In-Task Instruction](https://arxiv.org/abs/2601.06650)
*Qian Ma,Yingfan Zhou,Shubhang Kaushik,Aamod Joshi,Aditya Majumdar,Noah Apthorpe,Yan Shvartzshnaider,Sarah Rajtmajer,Brett Frischmann*

Main category: cs.HC

TL;DR: 研究引入教学摩擦的设计方法，通过在密码创建时提供即时指导，能够有效提升用户的规则遵从性和行为认知。


<details>
  <summary>Details</summary>
Motivation: 用户在做出与安全和隐私相关的决策时，常常缺乏对安全行为规则的清晰理解。

Method: 进行了随机重复测量研究，共有128名参与者，测试了四种不同界面条件下的引导深度和互动性。

Result: 参与者在无指导的后续密码任务中纠正了大部分规则违反，规则相关问卷的准确性处于中等水平，并且行为与知识之间高度一致。

Conclusion: 通过引入教学摩擦，用户能够在密码创建任务中更好地遵循规则，展现出一定的知识对行为的影响。

Abstract: Users often make security- and privacy-relevant decisions without a clear understanding of the rules that govern safe behavior. We introduce pedagogical friction, a design approach that introduces brief, instructional interactions at the moment of action. We evaluate this approach in the context of password creation, a task with clear, objective quality criteria and broad familiarity. We conducted a randomized repeated-measures study with 128 participants across four interface conditions that varied the depth and interactivity of guidance. We assessed three outcomes: (1) rule compliance in a subsequent password task without guidance, (2) accuracy on survey questions matched to the rules shown earlier, and (3) behavior-knowledge alignment, which captures whether participants who correctly followed a rule also recognized it on the survey. Across all guided conditions, participants corrected most rule violations in the follow-up task, achieved moderate accuracy on matched rule questions, and showed high behavior-knowledge alignment. These results support pedagogical friction as a lightweight and generalizable intervention for security- and privacy-critical interfaces.

</details>


### [14] [ImmuniFraug: A Metacognitive Intervention Anti-Fraud Approach to Enhance Undergraduate Students' Cyber Fraud Awareness](https://arxiv.org/abs/2601.06774)
*Xiangzhe Yuan,Jiajun Wang,Huanchen Wang,Qian Wan,Siying Hu*

Main category: cs.HC

TL;DR: 本研究提出的ImmuniFraug是基于大语言模型的沉浸式反欺诈干预，较传统方法显著提升了学生的欺诈意识和反欺诈能力。


<details>
  <summary>Details</summary>
Motivation: 针对中国大学生网络欺诈案件上升以及传统反欺诈培训效果有限，亟需一种新的、互动性更强的教育方法。

Method: 通过将ImmuniFraug与传统文本材料进行对比，采用线性混合效应模型分析了846名大学生的干预效果，并利用主题分析评估访谈结果。

Result: ImmuniFraug有效提升了学生对网络欺诈的认识，通过多模态沉浸式体验解决传统反欺诈培训中的不足。

Conclusion: 大语言模型驱动的干预措施显著提高了网络欺诈意识，培养了大学生的反欺诈能力，显示了新的培训范式的可行性。

Abstract: Cyber fraud now constitutes over half of criminal cases in China, with undergraduate students experiencing a disproportionate rise in victimization. Traditional anti-fraud training remains predominantly passive, yielding limited engagement and retention. This paper introduces ImmuniFraug, a Large Language Model (LLM)-based metacognitive intervention that delivers immersive, multimodal fraud simulations integrating text, voice, and visual avatars across ten prevalent fraud types. Each scenario is designed to replicate real-world persuasion tactics and psychological pressure, while post-interaction debriefs provide grounded feedback in protection motivation theory and reflective prompts to reinforce learning. In a controlled study with 846 Chinese undergraduates, ImmuniFraug was compared to official text-based materials. Linear Mixed-Effects Modeling (LMEM) reveals that the interactive intervention significantly improved fraud awareness (p = 0.026), successfully providing incremental learning value even when controlling for participants' extensive prior exposure to anti-fraud education, alongside high narrative immersion (M = 56.95/77). Thematic analysis of interviews revealed key effectiveness factors: perceived realism, adaptive deception, enforced time pressure, emotional manipulation awareness, and enhanced self-efficacy. Findings demonstrate that by shifting the focus from passive knowledge acquisition to active metacognitive engagement, LLM-based simulations offer a scalable and ecologically valid new paradigm for anti-fraud training and fostering fraud resilience.

</details>


### [15] [AutoTour: Automatic Photo Tour Guide with Smartphones and LLMs](https://arxiv.org/abs/2601.06781)
*Huatao Xu,Zihe Liu,Zilin Zeng,Baichuan Li,Mo Li*

Main category: cs.HC

TL;DR: AutoTour系统通过自动生成细致的地标注释和描述性叙述，提升用户探索体验，结合视觉特征和地理空间数据，提供可扩展的照片指导。


<details>
  <summary>Details</summary>
Motivation: 开发一种系统，增强用户探索体验，提供上下文感知的照片导览，而非依赖预定义内容或专有数据集。

Method: 设计一个无训练管道，提取并过滤用户GPS位置周围的地理特征，通过基于视觉语言模型的特征检测识别照片中的主要地标，并使用几何匹配算法将照片特征与地理实体对齐，最终生成注释和描述。

Result: AutoTour能够为标志性和不太知名的地标提供丰富、可解释的注释，支持互动的上下文感知探索。

Conclusion: 该系统连接了视觉感知与地理空间理解，提供了一种新型的探索体验。

Abstract: We present AutoTour, a system that enhances user exploration by automatically generating fine-grained landmark annotations and descriptive narratives for photos captured by users. The key idea of AutoTour is to fuse visual features extracted from photos with nearby geospatial features queried from open matching databases. Unlike existing tour applications that rely on pre-defined content or proprietary datasets, AutoTour leverages open and extensible data sources to provide scalable and context-aware photo-based guidance. To achieve this, we design a training-free pipeline that first extracts and filters relevant geospatial features around the user's GPS location. It then detects major landmarks in user photos through VLM-based feature detection and projects them into the horizontal spatial plane. A geometric matching algorithm aligns photo features with corresponding geospatial entities based on their estimated distance and direction. The matched features are subsequently grounded and annotated directly on the original photo, accompanied by large language model-generated textual and audio descriptions to provide an informative, tour-like experience. We demonstrate that AutoTour can deliver rich, interpretable annotations for both iconic and lesser-known landmarks, enabling a new form of interactive, context-aware exploration that bridges visual perception and geospatial understanding.

</details>


### [16] [Generative Modeling of Human-Computer Interfaces with Diffusion Processes and Conditional Control](https://arxiv.org/abs/2601.06823)
*Rui Liu,Liuqingqing Yang,Runsheng Zhang,Shixiao Wang*

Main category: cs.HC

TL;DR: 本研究提出了一种基于扩散模型的人机界面生成框架，克服了传统模板设计和固定规则方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 研究人机界面生成的关键挑战，包括界面元素多样性、布局逻辑复杂性以及用户需求个性化。

Method: 提出以扩散-反扩散过程为中心的生成框架，在反扩散阶段引入条件控制以整合用户意图、上下文状态和任务约束。结合正则化约束和优化目标，确保生成界面的合理性和稳定性。

Result: 该方法在均方误差、结构相似度、峰值信噪比和均值绝对误差等指标上优于代表性模型，并在不同参数设置和环境条件下保持强健性。

Conclusion: 扩散模型框架有效提高了人机界面生成的多样性、合理性和智能性，为复杂交互场景中的自动化界面生成提供可行解决方案。

Abstract: This study investigates human-computer interface generation based on diffusion models to overcome the limitations of traditional template-based design and fixed rule-driven methods. It first analyzes the key challenges of interface generation, including the diversity of interface elements, the complexity of layout logic, and the personalization of user needs. A generative framework centered on the diffusion-reverse diffusion process is then proposed, with conditional control introduced in the reverse diffusion stage to integrate user intent, contextual states, and task constraints, enabling unified modeling of visual presentation and interaction logic. In addition, regularization constraints and optimization objectives are combined to ensure the rationality and stability of the generated interfaces. Experiments are conducted on a public interface dataset with systematic evaluations, including comparative experiments, hyperparameter sensitivity tests, environmental sensitivity tests, and data sensitivity tests. Results show that the proposed method outperforms representative models in mean squared error, structural similarity, peak signal-to-noise ratio, and mean absolute error, while maintaining strong robustness under different parameter settings and environmental conditions. Overall, the diffusion model framework effectively improves the diversity, rationality, and intelligence of interface generation, providing a feasible solution for automated interface generation in complex interaction scenarios.

</details>


### [17] [Personality-Aware Reinforcement Learning for Persuasive Dialogue with LLM-Driven Simulation](https://arxiv.org/abs/2601.06877)
*Donghuo Zeng,Roberto Legaspi,Kazushi Ikeda*

Main category: cs.HC

TL;DR: 提出了一种个性意识强化学习方法，通过策略框架、个性表示学习和D3QN模型改善说服效果，实验证明具有良好的策略适应性和奖励累计。


<details>
  <summary>Details</summary>
Motivation: 为了提高说服对话代理的有效性，适应用户的心理状态和意图。

Method: 个性意识的强化学习方法，包括策略导向互动框架、个性意识用户表示学习和对抗双重DQN模型，结合对话历史和个性估计进行策略训练。

Result: 在PersuasionForGood (P4G) 数据集上进行实验，结果表明转级别个性条件'améliore政策的适应性和累积说服奖励，LLM驱动的模拟增强对未见用户行为的泛化，改变主意的惩罚减少了协议后的撤回，同时略微改善了捐款结果。

Conclusion: 结构化互动、动态个性评估和行为驱动奖励共同提供了更有效的说服策略。

Abstract: Effective persuasive dialogue agents adapt their strategies to individual users, accounting for the evolution of their psychological states and intentions throughout conversations. We present a personality-aware reinforcement learning approach comprising three main modules: (1) a Strategy-Oriented Interaction Framework, which serves as an agenda-based strategy controller that selects strategy-level actions and generate responses via Maximal Marginal Relevance (MMR) retrieval to ensure contextual relevance, diversity, and scalable data generation; (2) Personality-Aware User Representation Learning, which produces an 81-dimensional mixed-type embedding predicted at each turn from recent exchanges and appended to the reinforcement learning state; and (3) a Dueling Double DQN (D3QN) model and Reward Prediction, in which the policy is conditioned on dialogue history and turn-level personality estimates and trained using a composite reward incorporating agreement intent, donation amount, and changeof-mind penalties. We use an agenda-based LLM simulation pipeline to generate diverse interactions, from which personality estimation is inferred from the generated utterances. Experiments on the PersuasionForGood (P4G) dataset augmented with simulated dialogues reveal three main findings: (i) turn-level personality conditioning improves policy adaptability and cumulative persuasion rewards; (ii) LLM-driven simulation enhances generalization to unseen user behaviors; and (iii) incorporating a change-of-mind penalty reduces post-agreement retractions while slightly improving donation outcomes. These results demonstrate that structured interaction, dynamic personality estimation, and behaviorally informed rewards together yield more effective persuasive policies.

</details>


### [18] [Santa Clara 3D: Digital Reconstruction and Storytelling of a Francoist Concentration Camp](https://arxiv.org/abs/2601.06902)
*Stinne Zacho,Chris Hall,Jakob Kusnick,Stefan Jänicke*

Main category: cs.HC

TL;DR: 本文探讨了数字重建和互动叙事在保存历史被压制地点方面的潜力，以西班牙索里亚的弗朗哥圣克拉拉集中营为例，展示了如何结合多种数字技术进行历史记忆的可视化和互动。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于利用数字技术保存历史上被压制的地方的记忆，特别是弗朗哥时期的集中营，以促进公众对历史的参与和反思。

Method: 通过档案研究、3D建模、360度摄影和网页开发，创建了一个原型数字平台，展示该地点在三种历史阶段的变化。

Result: 该平台允许用户导航时空层次，通过可点击的媒体标记鼓励探索和互动，展示了数字工具在支持记忆工作和公众参与方面的应用。

Conclusion: 本研究展示了数字工具在历史记忆保护、公众参与和历史反思中的重要作用，并提出了适用于其他被遗忘或抹去的地点的低成本概念。

Abstract: This paper explores the potential of digital reconstruction and interactive storytelling to preserve historically suppressed sites. The main objective of an interdisciplinary team of data scientists from the MEMORISE project and associates of the memory association Asociacion Recuerdo y Dignidad was to preserve the memory of the Francoist Santa Clara concentration camp in Soria, Spain, through the use of digital technology. Combining archival research, 3D modelling, 360-degree photography, and web development, a prototype digital platform was created to visualise the transformation of the site across three historical phases: its origin as a convent, its use as a Francoist concentration camp, and its present-day condition. The platform allows users to navigate through spatial and temporal layers. Clickable media markers encourage exploration and interaction. Drawing on principles of participatory design, narrative visualisation, and open-ended user engagement, the project demonstrates how digital tools can support memory work, public engagement, and historical reflection. Our low-cost concept is especially adaptable to other physical sites that have been erased or forgotten.

</details>


### [19] [The AI Cognitive Trojan Horse: How Large Language Models May Bypass Human Epistemic Vigilance](https://arxiv.org/abs/2601.07085)
*Andrew D. Maynard*

Main category: cs.HC

TL;DR: 本研究探讨基于大型语言模型的AI系统如何通过'诚实非信号'来绕过人类的认知评估，强调需要重新审视AI安全性问题。


<details>
  <summary>Details</summary>
Motivation: 当前关于误信息和说服的理解框架未能充分应对大型语言模型带来的认知挑战。

Method: 提出认知特洛伊木马假设，探讨基于大型语言模型的对话式AI对人类认知的影响

Result: 识别了四种可能的认知绕过机制，并生成了可测试的预测

Conclusion: AI安全问题不仅是防止欺骗，还涉及人类评估响应与AI生成内容的实际认知状态的校准。

Abstract: Large language model (LLM)-based conversational AI systems present a challenge to human cognition that current frameworks for understanding misinformation and persuasion do not adequately address. This paper proposes that a significant epistemic risk from conversational AI may lie not in inaccuracy or intentional deception, but in something more fundamental: these systems may be configured, through optimization processes that make them useful, to present characteristics that bypass the cognitive mechanisms humans evolved to evaluate incoming information. The Cognitive Trojan Horse hypothesis draws on Sperber and colleagues' theory of epistemic vigilance -- the parallel cognitive process monitoring communicated information for reasons to doubt -- and proposes that LLM-based systems present 'honest non-signals': genuine characteristics (fluency, helpfulness, apparent disinterest) that fail to carry the information equivalent human characteristics would carry, because in humans these are costly to produce while in LLMs they are computationally trivial. Four mechanisms of potential bypass are identified: processing fluency decoupled from understanding, trust-competence presentation without corresponding stakes, cognitive offloading that delegates evaluation itself to the AI, and optimization dynamics that systematically produce sycophancy. The framework generates testable predictions, including a counterintuitive speculation that cognitively sophisticated users may be more vulnerable to AI-mediated epistemic influence. This reframes AI safety as partly a problem of calibration -- aligning human evaluative responses with the actual epistemic status of AI-generated content -- rather than solely a problem of preventing deception.

</details>


### [20] [EZBlender: Efficient 3D Editing with Plan-and-ReAct Agent](https://arxiv.org/abs/2601.07143)
*Hao Wang,Wenhui Zhu,Shao Tang,Zhipeng Wang,Xuanzhao Dong,Xin Li,Xiwen Chen,Ashish Bastola,Xinhao Huang,Yalin Wang,Abolfazl Razi*

Main category: cs.HC

TL;DR: EZBlender是一种结合规划任务分解和反应性本地自主权的Blender代理，旨在提高3D编辑的效率和效果。


<details>
  <summary>Details</summary>
Motivation: 传统的3D编辑方法在场景编辑中需要大量资源和人工努力，尚未解决编辑精度与代理响应性之间的基本权衡。

Method: EZBlender结合规划任务分解和反应性本地自主权的混合框架，实施了一种新的Plan-and-ReAct设计。

Result: 通过建立专门的多任务基准测试，验证了所提出的边缘自主架构的效率和有效性，并分析了语言模型偏好、系统响应性和经济效率。

Conclusion: EZBlender通过其Plan-and-ReAct设计在保持3D编辑质量的同时，显著降低了延迟和计算成本，推动了人工智能与人类的高效合作。

Abstract: As a cornerstone of the modern digital economy, 3D modeling and rendering demand substantial resources and manual effort when scene editing is performed in the traditional manner. Despite recent progress in VLM-based agents for 3D editing, the fundamental trade-off between editing precision and agent responsiveness remains unresolved. To overcome these limitations, we present EZBlender, a Blender agent with a hybrid framework that combines planning-based task decomposition and reactive local autonomy for efficient human AI collaboration and semantically faithful 3D editing. Specifically, this unexplored Plan-and-ReAct design not only preserves editing quality but also significantly reduces latency and computational cost. To further validate the efficiency and effectiveness of the proposed edge-autonomy architecture, we construct a dedicated multi-tasking benchmark that has not been systematically investigated in prior research. In addition, we provide a comprehensive analysis of language model preference, system responsiveness, and economic efficiency.

</details>


### [21] [DiSCo: Making Absence Visible in Intelligent Summarization Interfaces](https://arxiv.org/abs/2601.07229)
*Eran Fainman,Hagit Ben Shoshan,Adir Solomon,Osnat Mokryn*

Main category: cs.HC

TL;DR: 开发DiSCo方法，通过对比领域期望，使缺失的信息在智能摘要中变得可见，改善了决策支持和透明度。


<details>
  <summary>Details</summary>
Motivation: 当前的智能接口摘要存在偏见，忽略了未提及的内容，可能误导用户决策。

Method: DiSCo通过比较实体内容与域主题期望进行缺失内容识别，整合这些缺失信息到生成的摘要中。

Result: DiSCo是一种通过比较实体内容与领域主题期望来识别内容缺失的智能摘要方法。

Conclusion: DiSCo的摘要在决策支持方面优于传统大语言模型的摘要，尽管可读性稍差。

Abstract: Intelligent interfaces increasingly use large language models to summarize user-generated content, yet these summaries emphasize what is mentioned while overlooking what is missing. This presence bias can mislead users who rely on summaries to make decisions. We present Domain Informed Summarization through Contrast (DiSCo), an expectation-based computational approach that makes absences visible by comparing each entity's content with domain topical expectations captured in reference distributions of aspects typically discussed in comparable accommodations. This comparison identifies aspects that are either unusually emphasized or missing relative to domain norms and integrates them into the generated text. In a user study across three accommodation domains, namely ski, beach, and city center, DiSCo summaries were rated as more detailed and useful for decision making than baseline large language model summaries, although slightly harder to read. The findings show that modeling expectations reduces presence bias and improves both transparency and decision support in intelligent summarization interfaces.

</details>


### [22] [Making Absence Visible: The Roles of Reference and Prompting in Recognizing Missing Information](https://arxiv.org/abs/2601.07234)
*Hagit Ben Shoshan,Joel Lanir,Pavel Goldstein,Osnat Mokryn*

Main category: cs.HC

TL;DR: 本研究探讨了如何通过参考框架和提示提高用户发现数据集中缺失信息的能力，发现部分参考和提示能显著提升缺失检测效果。


<details>
  <summary>Details</summary>
Motivation: 探讨交互系统如何帮助用户形成关于数据集的期望，以便更好地检测缺失信息，从而克服存在偏差。

Method: 通过实验研究，参与者在不同参考条件（全球参考和部分参考）下比较了三个领域（能源、财富和政权）中的数据分布。

Result: 结果显示，在部分参考条件下，缺失检测显著高于全球参考条件，当提示用户寻找缺失内容时，缺失检测水平急剧上升。

Conclusion: 研究表明，部分参考框架和提示可以显著提高用户对缺失类别的识别能力，从而改善交互式用户界面和期望基础可视化设计。

Abstract: Interactive systems that explain data, or support decision making often emphasize what is present while overlooking what is expected but missing. This presence bias limits users' ability to form complete mental models of a dataset or situation. Detecting absence depends on expectations about what should be there, yet interfaces rarely help users form such expectations. We present an experimental study examining how reference framing and prompting influence people's ability to recognize expected but missing categories in datasets. Participants compared distributions across three domains (energy, wealth, and regime) under two reference conditions: Global, presenting a unified population baseline, and Partial, showing several concrete exemplars. Results indicate that absence detection was higher with Partial reference than with Global reference, suggesting that partial, samples-based framing can support expectation formation and absence detection. When participants were prompted to look for what was missing, absence detection rose sharply. We discuss implications for interactive user interfaces and expectation-based visualization design, while considering cognitive trade-offs of reference structures and guided attention.

</details>


### [23] [MeepleLM: A Virtual Playtester Simulating Diverse Subjective Experiences](https://arxiv.org/abs/2601.07251)
*Zizhen Li,Chuanhao Li,Yibin Wang,Yukang Feng,Jianwen Sun,Jiaxin Ai,Fanrui Zhang,Mingzhu Sun,Yifei Huang,Kaipeng Zhang*

Main category: cs.HC

TL;DR: 研究了如何通过MeepleLM模型提升大型语言模型在桌游设计中的批评能力，弥补了人工智能在理解用户体验方面的不足。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在桌游中的应用主要限于作为玩耍代理，而缺乏基于用户体验的建设性批评能力。这一能力对优化设计至关重要。

Method: 通过构建包含1727本结构正确的规则书和150K条评论的数据集，并利用MDA推理和玩家角色提升对规则与游戏体验之间因果关系的理解。引入MeepleLM模型以模拟不同玩家的主观反馈。

Result: MeepleLM能够提供基于用户体验的建设性批评，显著提升游戏设计过程中的人机协作效果。

Conclusion: MeepleLM作为一种专门的模型，通过内部化玩家特定的推理模式，改善了对不同玩家群体的反馈模拟，推动了人机协作的进步。

Abstract: Recent advancements have expanded the role of Large Language Models in board games from playing agents to creative co-designers. However, a critical gap remains: current systems lack the capacity to offer constructive critique grounded in the emergent user experience. Bridging this gap is fundamental for harmonizing Human-AI collaboration, as it empowers designers to refine their creations via external perspectives while steering models away from biased or unpredictable outcomes. Automating critique for board games presents two challenges: inferring the latent dynamics connecting rules to gameplay without an explicit engine, and modeling the subjective heterogeneity of diverse player groups. To address these, we curate a dataset of 1,727 structurally corrected rulebooks and 150K reviews selected via quality scoring and facet-aware sampling. We augment this data with Mechanics-Dynamics-Aesthetics (MDA) reasoning to explicitly bridge the causal gap between written rules and player experience. We further distill player personas and introduce MeepleLM, a specialized model that internalizes persona-specific reasoning patterns to accurately simulate the subjective feedback of diverse player archetypes. Experiments demonstrate that MeepleLM significantly outperforms latest commercial models (e.g., GPT-5.1, Gemini3-Pro) in community alignment and critique quality, achieving a 70% preference rate in user studies assessing utility. MeepleLM serves as a reliable virtual playtester for general interactive systems, marking a pivotal step towards audience-aligned, experience-aware Human-AI collaboration.

</details>


### [24] [ColorBrowserAgent: An Intelligent GUI Agent for Complex Long-Horizon Web Automation](https://arxiv.org/abs/2601.07262)
*Jiamu Zhou,Jihong Wang,Weiming Zhang,Weiwen Liu,Zhuosheng Zhang,Xingyu Lou,Weinan Zhang,Huarong Deng,Jun Wang*

Main category: cs.HC

TL;DR: 提出了一种合成的自动化框架ColorBrowserAgent，结合了渐进式进度摘要和人机互动知识适应机制以提高网络任务的自主性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 网络浏览器作为人类日常活动的主要接口，其自动化是人机中心人工智能的重要前沿领域。

Method: ColorBrowserAgent框架采用了渐进式进度摘要和人机互动知识适应机制，以模仿人类短期记忆并适应多样化环境。

Result: 在WebArena基准测试中，ColorBrowserAgent与GPT-5的结合实现了71.2%的成功率，展现了互动人类帮助在稳健网络自动化中的有效性。

Conclusion: 该框架有效整合了人类的适应性和人工智能的可扩展性，为复杂网络任务的协作自主提供了新的解决方案。

Abstract: The web browser serves as a primary interface for daily human activities, making its automation a critical frontier for Human-Centred AI. While Large Language Models (LLMs) have enabled autonomous agents to interact with web GUIs, their reliability in real-world scenarios is hampered by long-horizon instability and the vast heterogeneity of site designs. In this paper, we introduce ColorBrowserAgent, a framework designed for Collaborative Autonomy in complex web tasks. Our approach integrates two human-centred mechanisms: (1) Progressive Progress Summarization, which mimics human short-term memory to maintain coherence over extended interactions; and (2) Human-in-the-Loop Knowledge Adaptation, which bridges the knowledge gap in diverse environments by soliciting expert intervention only when necessary. This symbiotic design allows the agent to learn from human tips without extensive retraining, effectively combining the scalability of AI with the adaptability of human cognition. Evaluated on the WebArena benchmark using GPT-5, ColorBrowserAgent achieves a state-of-the-art success rate of 71.2\%, demonstrating the efficacy of interactive human assistance in robust web automation.

</details>


### [25] [Interactive visualizations for adolescents to understand and challenge algorithmic profiling in online platforms](https://arxiv.org/abs/2601.07381)
*Yui Kondo,Kevin Dunnell,Isobel Voysey,Qing Hu,Victoria Paesano,Phi H Nguyen,Qing Xiao,Jun Zhao,Luc Rocher*

Main category: cs.HC

TL;DR: 研究展示了青少年通过互动工具理解和反思他们的个人数据，呼吁更高的透明度和代理权。


<details>
  <summary>Details</summary>
Motivation: 社交媒体平台对青少年数据的追踪与分析的缺乏透明性和青少年对数字身份的控制力不足。

Method: 引入互动可视化工具Algorithmic Mirror，转变不透明的个人数据分析为可探索的风景。

Result: 通过参与者的数字足迹提供个性化数据洞见，帮助青少年理解数据收集的规模和持续性。

Conclusion: 青少年对个人身份的理解驱动了他们对数字代理权的渴望，强调了平台和政策制定者需要进行结构性改革。

Abstract: Social media platforms regularly track, aggregate, and monetize adolescents' data, yet provide them with little visibility or agency over how algorithms construct their digital identities and make inferences about them. We introduce Algorithmic Mirror, an interactive visualization tool that transforms opaque profiling practices into explorable landscapes of personal data. It uniquely leverages adolescents' real digital footprints across YouTube, TikTok, and Netflix, to provide situated, personalized insights into datafication over time. In our study with 27 participants (ages 12--16), we show how engaging with their own data enabled adolescents to uncover the scale and persistence of data collection, recognize cross-platform profiling, and critically reflect algorithmic categorizations of their interests. These findings highlight how identity is a powerful motivator for adolescents' desire for greater digital agency, underscoring the need for platforms and policymakers to move toward structural reforms that guarantee children better transparency and the agency to influence their online experiences.

</details>


### [26] [Recommendation-as-Experience: A framework for context-sensitive adaptation in conversational recommender systems](https://arxiv.org/abs/2601.07401)
*Raj Mahmud,Shlomo Berkovsky,Mukesh Prasad,A. Baki Kocaballi*

Main category: cs.HC

TL;DR: 本文提出了一种新的Recommendation-as-Experience（RAE）框架，旨在通过综合考虑教育、探索和情感交互目标，改进对话推荐系统的设计和性能。


<details>
  <summary>Details</summary>
Motivation: 研究当前对话推荐系统在交互目标编码方面的不足，并探讨如何同时考虑用户的教育、探索和情感需求，以提升交互质量。

Method: 通过贝叶斯层次序回归分析168个多领域的数据，量化了教育、探索和情感交互目标的优先级，并提出了RAE框架，将上下文和个体信号结构化映射到对话策略。

Result: 发现用户对自主权的稳定偏好在不同的交互目标中普遍存在，并且能够有效地平衡推荐质量与用户体验。

Conclusion: RAE框架作为一种架构无关的设计蓝图，为灵活应对用户需求和提高对话推荐系统的适应性和体验质量提供了新的思路。

Abstract: While Conversational Recommender Systems (CRS) have matured technically, they frequently lack principled methods for encoding latent experiential aims as adaptive state variables. Consequently, contemporary architectures often prioritise ranking accuracy at the expense of nuanced, context-sensitive interaction behaviours. This paper addresses this gap through a comprehensive multi-domain study ($N = 168$) that quantifies the joint prioritisation of three critical interaction aims: educative (to inform and justify), explorative (to diversify and inspire), and affective (to align emotionally and socially). Utilising Bayesian hierarchical ordinal regression, we establish domain profiles and perceived item value as systematic modulators of these priorities. Furthermore, we identify stable user-level preferences for autonomy that persist across distinct interactional goals, suggesting that agency is a fundamental requirement of the conversational experience. Drawing on these empirical foundations, we formalise the Recommendation-as-Experience (RAE) adaptation framework. RAE systematically encodes contextual and individual signals into structured state representations, mapping them to experience-aligned dialogue policies realised through retrieval diversification, heuristic logic, or Large Language Model based controllable generation. As an architecture-agnostic blueprint, RAE facilitates the design of context-sensitive CRS that effectively balance experiential quality with predictive performance.

</details>


### [27] [Backpropagation-Free Test-Time Adaptation for Lightweight EEG-Based Brain-Computer Interfaces](https://arxiv.org/abs/2601.07556)
*Siyang Li,Jiayi Ouyang,Zhenyao Cui,Ziwei Wang,Tianwang Jia,Feng Wan,Dongrui Wu*

Main category: cs.HC

TL;DR: 本文提出了一种无反向传播的EEG解码适应方法（BFT），旨在解决现有方法的局限性，并提高脑-机接口的部署能力。


<details>
  <summary>Details</summary>
Motivation: EEG基础的脑-机接口面临个体差异、信号非平稳性和计算限制等挑战，因此需要一种新方法来减轻这些问题。

Method: 提出了无反向传播的变换（BFT）方法，通过对每个测试样本进行知识导向的多样本变换，生成多个预测分数，并引入学习排序模块加权这些预测。

Result: 在五个EEG数据集上的广泛实验表明，BFT在电动机想象分类和驾驶疲劳回归任务中表现出有效性、灵活性、鲁棒性和高效性。

Conclusion: BFT方法实现了轻量化的脑-机接口，并显著提高了EEG信号解码的实用性和效率。

Abstract: Electroencephalogram (EEG)-based brain-computer interfaces (BCIs) face significant deployment challenges due to inter-subject variability, signal non-stationarity, and computational constraints. While test-time adaptation (TTA) mitigates distribution shifts under online data streams without per-use calibration sessions, existing TTA approaches heavily rely on explicitly defined loss objectives that require backpropagation for updating model parameters, which incurs computational overhead, privacy risks, and sensitivity to noisy data streams. This paper proposes Backpropagation-Free Transformations (BFT), a TTA approach for EEG decoding that eliminates such issues. BFT applies multiple sample-wise transformations of knowledge-guided augmentations or approximate Bayesian inference to each test trial, generating multiple prediction scores for a single test sample. A learning-to-rank module enhances the weighting of these predictions, enabling robust aggregation for uncertainty suppression during inference under theoretical justifications. Extensive experiments on five EEG datasets of motor imagery classification and driver drowsiness regression tasks demonstrate the effectiveness, versatility, robustness, and efficiency of BFT. This research enables lightweight plug-and-play BCIs on resource-constrained devices, broadening the real-world deployment of decoding algorithms for EEG-based BCI.

</details>


### [28] [GPU accelerated surface-based gaze mapping for XR experiences](https://arxiv.org/abs/2601.07571)
*Charles Javerliat,Guillaume Lavoué*

Main category: cs.HC

TL;DR: 该论文提出了一种新的GPU算法，解决了在6自由度环境中构建视觉注意力地图的几大缺陷，能够实现实时渲染，促进该领域的研究。


<details>
  <summary>Details</summary>
Motivation: 随着扩展现实（XR）领域的快速发展，对用户行为分析的需求日益增长，尤其是对沉浸式体验中人类视觉注意力的理解。

Method: 作者提出了一种基于GPU的新算法，能够在6DoFs环境下高效生成视觉注意力地图，克服了现有方法的不足之处。

Result: 本论文提出了一种新的GPU算法，用于在6自由度（6DoFs）环境中高效构建视觉注意力地图，解决了现有方法在处理时间、网格分辨率和纹理映射依赖性等方面的不足。

Conclusion: 该研究的方法能够在交互时间内生成并实时渲染6DoFs的视觉注意力图，并在具有挑战性的场景中验证了其准确性和鲁棒性。

Abstract: Extended reality is a fast-growing domain for which there is an increasing need to analyze and understand user behavior. In particular, understanding human visual attention during immersive experiences is crucial for many applications. The visualization and analysis of visual attention are commonly done by building fixation density maps from eye-tracking data. Such visual attention mapping is well mastered for 3 degrees of freedom (3DoF) experiences (\textit{i.e.}, involving 360 images or videos) but much less so for 6DoFs data, when the user can move freely in the 3D space. In that case, the visual attention information has to be mapped onto the 3D objects themselves. Some solutions exist for constructing such surface-based 6DoFs attention maps, however, they own several drawbacks: processing time, strong dependence on mesh resolution and/or texture mapping, and/or unpractical data representation for further processing. In this context, we propose a novel GPU-based algorithm that resolves the issues above while being generated in interactive time and rendered in real-time. Experiment on a challenging scene demonstrates the accuracy and robustness of our approach. To stimulate research in this area, the source code is publicly released and integrated into PLUME for ease of use in XR experiments.

</details>


### [29] [A Multimodal Dataset of Student Oral Presentations with Sensors and Evaluation Data](https://arxiv.org/abs/2601.07576)
*Alvaro Becerra,Ruth Cobos,Roberto Daza*

Main category: cs.HC

TL;DR: SOPHIAS是一个包含50场口头展示的12小时多模态数据集，记录了学生的表现，结合多种传感器数据，旨在为高等教育的口头展示技能研究提供支持。


<details>
  <summary>Details</summary>
Motivation: 填补高等教育中口头展示技能方面缺乏真实世界学生表现数据的空白。

Method: 通过整合多个高精度传感器的数据，创建涵盖真实课堂环境的多模态数据集，并包括教师、同伴和自我评估的标准化评分。

Result: SOPHIAS数据集为高等教育中的口头展示技能的研究提供了新的数据来源，涵盖了学生的多种表现指标。

Conclusion: 通过SOPHIAS数据集，研究者可以深入探讨多模态行为与生理信号与演示表现之间的关系，并为自动反馈和多模态学习分析工具的开发提供基准。

Abstract: Oral presentation skills are a critical component of higher education, yet comprehensive datasets capturing real-world student performance across multiple modalities remain scarce. To address this gap, we present SOPHIAS (Student Oral Presentation monitoring for Holistic Insights & Analytics using Sensors), a 12-hour multimodal dataset containing recordings of 50 oral presentations (10-15-minute presentation followed by 5-15-minute Q&A) delivered by 65 undergraduate and master's students at the Universidad Autonoma de Madrid. SOPHIAS integrates eight synchronized sensor streams from high-definition webcams, ambient and webcam audio, eye-tracking glasses, smartwatch physiological sensors, and clicker, keyboard, and mouse interactions. In addition, the dataset includes slides and rubric-based evaluations from teachers, peers, and self-assessments, along with timestamped contextual annotations. The dataset captures presentations conducted in real classroom settings, preserving authentic student behaviors, interactions, and physiological responses. SOPHIAS enables the exploration of relationships between multimodal behavioral and physiological signals and presentation performance, supports the study of peer assessment, and provides a benchmark for developing automated feedback and Multimodal Learning Analytics tools. The dataset is publicly available for research through GitHub and Science Data Bank.

</details>


### [30] [Passing the Baton: Shift Handovers within Cybersecurity Incident Response Teams](https://arxiv.org/abs/2601.07788)
*Liberty Kent,Nilufer Tuptuk,Ingolf Becker*

Main category: cs.HC

TL;DR: 本研究制定了网络安全事件响应团队的换班过渡指南，强调了结构、挑战和培训方法的重要性。


<details>
  <summary>Details</summary>
Motivation: 有效的换班过渡对网络安全事件响应团队至关重要，但有关管理这些交接的指导有限。

Method: 通过分析现有文献和与从业人员咨询，制定有效的换班过渡指南

Result: 参与者一致认为草案包含所有相关细节，但建议增加一个事后复审部分和一个用于处理故障或技术困难的服务部分。

Conclusion: 本研究为增强网络安全事件响应团队的过渡实践奠定了基础。

Abstract: Effective shift transitions are crucial for cybersecurity incident response teams, yet there is limited guidance on managing these handovers. This exploratory study aimed to develop guidelines for such transitions through the analysis of existing literature and consultation with practitioners. Two draft guidelines (A and B) were created based on existing literature and online resources. Six participants from the UK and international incident response teams, with experience in shift handovers, were interviewed about handover structure, challenges, training practices, and their views on the draft guidelines. The collected data indicate the importance of signposting, evolving handover procedures, individual differences in handover style and detail, and streamlining the handover procedure. Participants agreed the drafts included all relevant details but suggested adding a post-incident review section and a service section for outages or technical difficulties. This study establishes a foundation for enhancing transition practices in cybersecurity incident response teams.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [31] [Walk the PLANC: Physics-Guided RL for Agile Humanoid Locomotion on Constrained Footholds](https://arxiv.org/abs/2601.06286)
*Min Dai,William D. Compton,Junheng Li,Lizhi Yang,Aaron D. Ames*

Main category: cs.RO

TL;DR: 本研究提出了一种结合步伐规划和强化学习的步态框架，提升了双足机器人在不连续地形中运动的精准性与适应性。


<details>
  <summary>Details</summary>
Motivation: 经典的优化和控制方法依赖于精确的地形几何表示，而强化学习在干扰和建模误差方面具有韧性，但往往难以发现精确的足部放置和步伐序列。

Method: 通过减阶步伐规划器提供动态一致的运动目标，并结合结构化步伐规划和数据驱动的适应，以实现步态学习。

Result: 该方法相比传统的无模型强化学习基线，显著提高了双足机器人在不连续地形上的步伐可靠性。

Conclusion: 提出了一种通过控制Lyapunov函数奖励指导强化学习的步态框架，显著提高了双足机器人在不连续地形上的步伐精准性和灵活性。

Abstract: Bipedal humanoid robots must precisely coordinate balance, timing, and contact decisions when locomoting on constrained footholds such as stepping stones, beams, and planks -- even minor errors can lead to catastrophic failure. Classical optimization and control pipelines handle these constraints well but depend on highly accurate mathematical representations of terrain geometry, making them prone to error when perception is noisy or incomplete. Meanwhile, reinforcement learning has shown strong resilience to disturbances and modeling errors, yet end-to-end policies rarely discover the precise foothold placement and step sequencing required for discontinuous terrain. These contrasting limitations motivate approaches that guide learning with physics-based structure rather than relying purely on reward shaping. In this work, we introduce a locomotion framework in which a reduced-order stepping planner supplies dynamically consistent motion targets that steer the RL training process via Control Lyapunov Function (CLF) rewards. This combination of structured footstep planning and data-driven adaptation produces accurate, agile, and hardware-validated stepping-stone locomotion on a humanoid robot, substantially improving reliability compared to conventional model-free reinforcement-learning baselines.

</details>


### [32] [BlazeAIoT: A Modular Multi-Layer Platform for Real-Time Distributed Robotics Across Edge, Fog, and Cloud Infrastructures](https://arxiv.org/abs/2601.06344)
*Cedric Melancon,Julien Gascon-Samson,Maarouf Saad,Kuljeet Kaur,Simon Savard*

Main category: cs.RO

TL;DR: BlazeAIoT是一个模块化的多层平台，集成了边缘、雾和云计算，旨在在分布式机器人中提供动态数据传输和实时性能，适用于多种IoT应用。


<details>
  <summary>Details</summary>
Motivation: 分布式机器人系统的复杂性日益增加，需要一种能够无缝整合边缘、雾计算和云计算层的平台，同时满足严格的实时约束。

Method: BlazeAIoT是一个模块化的多层平台，旨在统一异构基础设施上的分布式机器人。该平台利用基于Kubernetes的集群、消息代理互操作性 (DDS, Kafka, Redis和ROS2) 和自适应数据分发机制，优化不同环境下的通信和计算。

Result: 该平台在涉及导航和人工智能驱动的大规模消息处理的机器人场景中进行了验证，展现了在实时约束下的强大性能。

Conclusion: BlazeAIoT能够动态分配服务，通过不完整的拓扑维护系统健康并最小化延迟，使其成为一个具有成本意识和可扩展的解决方案，适用于机器人及更广泛的物联网应用，如智能城市和智能工厂。

Abstract: The increasing complexity of distributed robotics has driven the need for platforms that seamlessly integrate edge, fog, and cloud computing layers while meeting strict real-time constraints. This paper introduces BlazeAIoT, a modular multi-layer platform designed to unify distributed robotics across heterogeneous infrastructures. BlazeAIoT provides dynamic data transfer, configurable services, and integrated monitoring, while ensuring resilience, security, and programming language flexibility. The architecture leverages Kubernetes-based clusters, broker interoperability (DDS, Kafka, Redis, and ROS2), and adaptive data distribution mechanisms to optimize communication and computation across diverse environments. The proposed solution includes a multi-layer configuration service, dynamic and adaptive data bridging, and hierarchical rate limiting to handle large messages. The platform is validated through robotics scenarios involving navigation and artificial intelligence-driven large-scale message processing, demonstrating robust performance under real-time constraints. Results highlight BlazeAIoT's ability to dynamically allocate services across incomplete topologies, maintain system health, and minimize latency, making it a cost-aware, scalable solution for robotics and broader IoT applications, such as smart cities and smart factories.

</details>


### [33] [Semantic Enrichment of CAD-Based Industrial Environments via Scene Graphs for Simulation and Reasoning](https://arxiv.org/abs/2601.06415)
*Nathan Pascal Walus,Ranulfo Bezerra,Shotaro Kojima,Tsige Tadesse Alemayoh,Satoshi Tadokoro,Kazunori Ohno*

Main category: cs.RO

TL;DR: 本研究提出一种基于CAD文件生成3D场景图的方法，以增强工业环境中机器人的训练可能性。


<details>
  <summary>Details</summary>
Motivation: 在工业环境中，功能元素为机器人训练提供了有效的可能性，但CAD文件通常缺乏语义和功能信息，限制了仿真和训练的可能性。

Method: 提出一种离线方法，通过CAD环境生成详细的3D场景图，利用大型视觉语言模型（LVLM）增强环境的信息。

Result: 研究的主要结果包括生成的语义标签的定量结果和场景图的定性结果，特别是在管道结构和识别的功能关系方面。

Conclusion: 通过创建详细的3D场景图，能够更好地模拟和推理功能性和可操作性元素之间的关系，为机器人训练提供了基础。

Abstract: Utilizing functional elements in an industrial environment, such as displays and interactive valves, provide effective possibilities for robot training. When preparing simulations for robots or applications that involve high-level scene understanding, the simulation environment must be equally detailed. Although CAD files for such environments deliver an exact description of the geometry and visuals, they usually lack semantic, relational and functional information, thus limiting the simulation and training possibilities. A 3D scene graph can organize semantic, spatial and functional information by enriching the environment through a Large Vision-Language Model (LVLM). In this paper we present an offline approach to creating detailed 3D scene graphs from CAD environments. This will serve as a foundation to include the relations of functional and actionable elements, which then can be used for dynamic simulation and reasoning. Key results of this research include both quantitative results of the generated semantic labels as well as qualitative results of the scene graph, especially in hindsight of pipe structures and identified functional relations. All code, results and the environment will be made available at https://cad-scenegraph.github.io

</details>


### [34] [CulinaryCut-VLAP: A Vision-Language-Action-Physics Framework for Food Cutting via a Force-Aware Material Point Method](https://arxiv.org/abs/2601.06451)
*Hyunseo Koh,Chang-Yong Song,Youngjae Choi,Misa Viveiros,David Hyde,Heewon Kim*

Main category: cs.RO

TL;DR: 本研究提出了一种结合视觉、语言和物理切割模拟的框架，以应对机器人在可变形物体切割中的挑战，并建立了一套数据集和学习评估机制。


<details>
  <summary>Details</summary>
Motivation: 探索在视觉与机器人操作交叉领域中的食品切割应用，同时应对切割过程中的非线性交互和形变挑战。

Method: 使用基于物体点方法（MPM）的物理切割模拟器，并结合多样化的切割轨迹、视觉观察和语言指令创建基准数据集。

Result: 提出的框架实现了一个学习评估循环，从而改善了可变形物体操作中视觉-语言-动作模型的安全性和可重复性。

Conclusion: 该研究提供了一个统一框架，结合视觉-语言-动作数据集与物理切割模拟器，为可变形物体操作中的机器人切割任务奠定了基础。

Abstract: Food cutting is a highly practical yet underexplored application at the intersection of vision and robotic manipulation. The task remains challenging because interactions between the knife and deformable materials are highly nonlinear and often entail large deformations, frequent contact, and topological change, which in turn hinder stable and safe large-scale data collection.
  To address these challenges, we propose a unified framework that couples a vision-language-action (VLA) dataset with a physically realistic cutting simulator built on the material point method (MPM). Our simulator adopts MLS-MPM as its computational core, reducing numerical dissipation and energy drift while preserving rotational and shear responses even under topology-changing cuts. During cutting, forces and stress distributions are estimated from impulse exchanges between particles and the grid, enabling stable tracking of transient contact forces and energy transfer.
  We also provide a benchmark dataset that integrates diverse cutting trajectories, multi-view visual observations, and fine-grained language instructions, together with force--torque and tool--pose labels to provide physically consistent training signals.
  These components realize a learning--evaluation loop that respects the core physics of cutting and establishes a safe, reproducible, and scalable foundation for advancing VLA models in deformable object manipulation.

</details>


### [35] [Precision Meets Art: Autonomous Multi-UAV System for Large Scale Mural Drawing](https://arxiv.org/abs/2601.06508)
*Andrei A. Korigodskii,Artem E. Vasiunik,Georgii A. Varin,Adilia M. Zukhurova,Matvei V. Urvantsev,Semen A. Osipenkov,Igor S. Efremov,Georgii E. Bondar*

Main category: cs.RO

TL;DR: 本研究介绍了一种新的多无人机系统，成功用于户外壁画绘制，显示了机器人群体在艺术创作中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 探索自主无人机在大规模艺术项目中的新应用，提升无人机绘画的效率和精确性。

Method: 设计、部署和测试新型多无人机系统，用于户外自动壁画绘制。

Result: 创建了一幅100平方米的壁画，验证了多无人机系统的有效性，并与单无人机方法相比显著提升了可扩展性和操作速度，稳定性良好。

Conclusion: 自主机器人群体在创意应用中的潜力显著，为大规模机器人艺术的进一步发展铺平了道路。

Abstract: The integration of autonomous unmanned aerial vehicles (UAVs) into large-scale artistic projects has emerged as a new application in robotics. This paper presents the design, deployment, and testing of a novel multi-drone system for automated mural painting in outdoor settings. This technology makes use of new software that coordinates multiple drones simultaneously, utilizing state-machine algorithms for task execution. Key advancements are the complex positioning system that combines 2D localization using a single motion tracking camera with onboard LiDAR for precise positioning, and a novel flight control algorithm, which works differently along the trajectory and normally to it, ensuring smoothness and high precision of the drawings at the same time. A 100 square meters mural was created using the developed multi-drone system, validating the system's efficacy. Compared to single-drone approaches, our multi-UAV solution significantly improves scalability and operational speed while maintaining high stability even in harsh weather conditions. The findings highlight the potential of autonomous robotic swarms in creative applications, paving the way for further advancements in large-scale robotic art.

</details>


### [36] [Model Reconciliation through Explainability and Collaborative Recovery in Assistive Robotics](https://arxiv.org/abs/2601.06552)
*Britt Besch,Tai Mai,Jeremias Thun,Markus Huff,Jörn Vogel,Freek Stulp,Samuel Bustamante*

Main category: cs.RO

TL;DR: 论文通过模型调和框架，利用大型语言模型解释机器人与人类心理模型差异并支持用户修正，从而促进人机协作。


<details>
  <summary>Details</summary>
Motivation: 确保机器人行为的可解释性，提高人机协作效率，特别是在共享控制的场景中，需要实现用户与机器人对世界的一致理解。

Method: 采用大型语言模型进行心理模型预测和解释，允许用户在机器人输出后进行纠正，以解决模型偏差问题。

Result: 本文提出了一个模型调和框架，利用大型语言模型来预测和解释机器人与人类之间的心理模型差异，以促进人机协作时的透明度和理解。

Conclusion: 通过在助理机器人领域的应用，系统支持用户纠正机器人的行为，从而减小模型之间的差异，提升人机交互的有效性。

Abstract: Whenever humans and robots work together, it is essential that unexpected robot behavior can be explained to the user. Especially in applications such as shared control the user and the robot must share the same model of the objects in the world, and the actions that can be performed on these objects.
  In this paper, we achieve this with a so-called model reconciliation framework. We leverage a Large Language Model to predict and explain the difference between the robot's and the human's mental models, without the need of a formal mental model of the user. Furthermore, our framework aims to solve the model divergence after the explanation by allowing the human to correct the robot. We provide an implementation in an assistive robotics domain, where we conduct a set of experiments with a real wheelchair-based mobile manipulator and its digital twin.

</details>


### [37] [UMLoc: Uncertainty-Aware Map-Constrained Inertial Localization with Quantified Bounds](https://arxiv.org/abs/2601.06602)
*Mohammed S. Alharbi,Shinkyu Park*

Main category: cs.RO

TL;DR: 本论文提出了一种新的不确定性感知地图约束惯性定位框架UMLoc，通过联合建模IMU不确定性和地图约束，实现了抗漂移定位。


<details>
  <summary>Details</summary>
Motivation: 在GPS信号缺失的室内环境中，惯性定位技术的漂移问题严重影响了定位精度，因此本研究旨在通过引入不确定性感知机制来提高惯性定位的可靠性和准确性。

Method: 提出的UMLoc框架整合了两个模块：LSTM量子回归器用于估算不确定性预测区间，CGAN结合跨注意力机制生成符合几何约束的轨迹。

Result: UMLoc在三种数据集上进行了评估，包括一个新收集的包含IMU数据和真实位姿的室内基准数据集，结果显示其漂移率为5.9%，绝对轨迹误差为1.36米。

Conclusion: UMLoc在倾斜定位中表现出色，显著减少了漂移，且在实际应用中能够提供准确的轨迹预测和不确定性量化。

Abstract: Inertial localization is particularly valuable in GPS-denied environments such as indoors. However, localization using only Inertial Measurement Units (IMUs) suffers from drift caused by motion-process noise and sensor biases. This paper introduces Uncertainty-aware Map-constrained Inertial Localization (UMLoc), an end-to-end framework that jointly models IMU uncertainty and map constraints to achieve drift-resilient positioning. UMLoc integrates two coupled modules: (1) a Long Short-Term Memory (LSTM) quantile regressor, which estimates the specific quantiles needed to define 68%, 90%, and 95% prediction intervals serving as a measure of localization uncertainty and (2) a Conditioned Generative Adversarial Network (CGAN) with cross-attention that fuses IMU dynamic data with distance-based floor-plan maps to generate geometrically feasible trajectories. The modules are trained jointly, allowing uncertainty estimates to propagate through the CGAN during trajectory generation. UMLoc was evaluated on three datasets, including a newly collected 2-hour indoor benchmark with time-aligned IMU data, ground-truth poses and floor-plan maps. Results show that the method achieves a mean drift ratio of 5.9% over a 70 m travel distance and an average Absolute Trajectory Error (ATE) of 1.36 m, while maintaining calibrated prediction bounds.

</details>


### [38] [Robotic Tele-Operation for Upper Aerodigestive Tract Microsurgery: System Design and Validation](https://arxiv.org/abs/2601.06617)
*Giovani Braglia,José Jair Alves Mendes Junior,Augusto Tetsuo Prado Inafuco,Federico Mariano,Leonardo S. Mattos*

Main category: cs.RO

TL;DR: 本文提出了一种新型机器人系统，用于UADT手术中的组织操作，旨在改善手动操作的局限性，并进行了验证。


<details>
  <summary>Details</summary>
Motivation: 为了克服传统TLM系统中手动操作夹持器带来的在人体工学、精确度和可控性的限制。

Method: 提出了一种基于新型末端执行器的机器人系统，结合了远程操作框架，使用机器人操纵器和编程的动作中心，允许精确和受限的工具运动。

Result: 通过两个实验研究和一项专门的可用性评估，验证了所提出系统在UADT手术应用中的有效性。

Conclusion: 该系统通过两个实验研究和专门的可用性评估进行了验证，证明了其在UADT外科应用中的有效性和适宜性。

Abstract: Upper aerodigestive tract (UADT) treatments frequently employ transoral laser microsurgery (TLM) for procedures such as the removal of tumors or polyps. In TLM, a laser beam is used to cut target tissue, while forceps are employed to grasp, manipulate, and stabilize tissue within the UADT. Although TLM systems may rely on different technologies and interfaces, forceps manipulation is still predominantly performed manually, introducing limitations in ergonomics, precision, and controllability. This paper proposes a novel robotic system for tissue manipulation in UADT procedures, based on a novel end-effector designed for forceps control. The system is integrated within a teleoperation framework that employs a robotic manipulator with a programmed remote center of motion (RCM), enabling precise and constrained instrument motion while improving surgeon ergonomics. The proposed approach is validated through two experimental studies and a dedicated usability evaluation, demonstrating its effectiveness and suitability for UADT surgical applications.

</details>


### [39] [Follow the Signs: Using Textual Cues and LLMs to Guide Efficient Robot Navigation](https://arxiv.org/abs/2601.06652)
*Jing Cao,Nishanth Kumar,Aidan Curtis*

Main category: cs.RO

TL;DR: 提出了一种新颖的语义导航框架，利用大语言模型提升部分观察情况下的导航效率，并成功在多个环境中超越基线算法。


<details>
  <summary>Details</summary>
Motivation: 现有的自主导航方法忽视了环境中的丰富语义线索，如标志和房间编号。

Method: 结合局部感知输入、基于边界的探索和定期的LLM查询，提取符号模式并更新信心网格。

Result: 在根据真实平面图建模的环境中，该方法的导航效率提高了25%以上，达到近最优路径。

Conclusion: 该方法在稀疏、部分可观察网格环境中展示出高效的导航能力，使用符号模式有效引导探索。

Abstract: Autonomous navigation in unfamiliar environments often relies on geometric mapping and planning strategies that overlook rich semantic cues such as signs, room numbers, and textual labels. We propose a novel semantic navigation framework that leverages large language models (LLMs) to infer patterns from partial observations and predict regions where the goal is most likely located. Our method combines local perceptual inputs with frontier-based exploration and periodic LLM queries, which extract symbolic patterns (e.g., room numbering schemes and building layout structures) and update a confidence grid used to guide exploration. This enables robots to move efficiently toward goal locations labeled with textual identifiers (e.g., "room 8") even before direct observation. We demonstrate that this approach enables more efficient navigation in sparse, partially observable grid environments by exploiting symbolic patterns. Experiments across environments modeled after real floor plans show that our approach consistently achieves near-optimal paths and outperforms baselines by over 25% in Success weighted by Path Length.

</details>


### [40] [Robust Evacuation for Multi-Drone Failure in Drone Light Shows](https://arxiv.org/abs/2601.06728)
*Minhyuk Park,Aloysius K. Mok,Tsz-Chiu Au*

Main category: cs.RO

TL;DR: 本文提出了一种无人机停车算法，旨在提高无人机灯光秀的安全性，减少发生群体坠落事故的风险，并通过深度学习预测坠毁无人机的轨迹。


<details>
  <summary>Details</summary>
Motivation: 随着无人机灯光秀的流行，相关的安全和可靠性问题日益突出，特别是多无人机同时坠落的事件引发了关注。

Method: 结合社会LSTM模型与注意力机制，预测失效无人机的轨迹并计算近似最优的疏散路径。

Result: 通过实验验证，所提算法在预测坠毁无人机轨迹方面表现优异，显著增强了多无人机系统的鲁棒性。

Conclusion: 本研究提出的无人机停车算法能够大幅提高多无人机系统的鲁棒性，确保无人机灯光秀的安全性和可靠性。

Abstract: Drone light shows have emerged as a popular form of entertainment in recent years. However, several high-profile incidents involving large-scale drone failures -- where multiple drones simultaneously fall from the sky -- have raised safety and reliability concerns. To ensure robustness, we propose a drone parking algorithm designed specifically for multiple drone failures in drone light shows, aimed at mitigating the risk of cascading collisions by drone evacuation and enabling rapid recovery from failures by leveraging strategically placed hidden drones. Our algorithm integrates a Social LSTM model with attention mechanisms to predict the trajectories of failing drones and compute near-optimal evacuation paths that minimize the likelihood of surviving drones being hit by fallen drones. In the recovery node, our system deploys hidden drones (operating with their LED lights turned off) to replace failed drones so that the drone light show can continue. Our experiments showed that our approach can greatly increase the robustness of a multi-drone system by leveraging deep learning to predict the trajectories of fallen drones.

</details>


### [41] [On-the-Fly VLA Adaptation via Test-Time Reinforcement Learning](https://arxiv.org/abs/2601.06748)
*Changyu Liu,Yiyang Liu,Taowen Wang,Qiao Zhuang,James Chenhao Liang,Wenhao Yang,Renjing Xu,Qifan Wang,Dongfang Liu,Cheng Han*

Main category: cs.RO

TL;DR: TT-VLA为视觉语言动作模型提供了一种在推理时进行策略适应的新方法，显著提升了模型在复杂环境中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言动作模型在应对动态环境时缺乏灵活性，往往需要人工干预和数据收集，而TT-VLA旨在解决这一问题。

Method: 引入测试时强化学习（TT-VLA）框架，允许在推理过程中进行策略适应。

Result: 通过密集奖励机制，利用逐步任务进展信号在测试时细化动作策略，同时保持SFT/RL训练的先验知识。

Conclusion: TT-VLA有效增强了当前视觉语言动作模型在动态和未见场景中的适应性、稳定性和任务成功率。

Abstract: Vision-Language-Action models have recently emerged as a powerful paradigm for general-purpose robot learning, enabling agents to map visual observations and natural-language instructions into executable robotic actions. Though popular, they are primarily trained via supervised fine-tuning or training-time reinforcement learning, requiring explicit fine-tuning phases, human interventions, or controlled data collection. Consequently, existing methods remain unsuitable for challenging simulated- or physical-world deployments, where robots must respond autonomously and flexibly to evolving environments. To address this limitation, we introduce a Test-Time Reinforcement Learning for VLAs (TT-VLA), a framework that enables on-the-fly policy adaptation during inference. TT-VLA formulates a dense reward mechanism that leverages step-by-step task-progress signals to refine action policies during test time while preserving the SFT/RL-trained priors, making it an effective supplement to current VLA models. Empirical results show that our approach enhances overall adaptability, stability, and task success in dynamic, previously unseen scenarios under simulated and real-world settings. We believe TT-VLA offers a principled step toward self-improving, deployment-ready VLAs.

</details>


### [42] [SPINE Gripper: A Twisted Underactuated Mechanism-based Passive Mode-Transition Gripper](https://arxiv.org/abs/2601.06833)
*JaeHyung Jang,JunHyeong Park,Joong-Ku Lee,Jee-Hwan Ryu*

Main category: cs.RO

TL;DR: 本论文提出了一种新型单致动器被动抓手，能够通过施加扭矩的大小，在抓握和旋转之间平稳切换，具备了非共面的多功能操作能力。


<details>
  <summary>Details</summary>
Motivation: 传统的多功能抓手通常依赖多个驱动器和复杂的控制系统，本文旨在通过简化设计实现更高效的抓取和旋转功能。

Method: 采用扭转欠驱动机制（TUM）实现单一旋转输入下的轴向收缩和旋转运动，从而简化抓手的构造和控制。

Result: 实验验证了该抓手在抓握成功率、摩擦控制下的抓握力度和双向旋转性能方面的优越性，且能在没有传感器或主动控制的情况下，实现高效、稳定的抓握与旋转转换。

Conclusion: 本研究展示了一种基于机械编码功率传输逻辑的单致动器被动抓手，能够实现稳定抓握和连续双向手内旋转。

Abstract: This paper presents a single-actuator passive gripper that achieves both stable grasping and continuous bidirectional in-hand rotation through mechanically encoded power transmission logic. Unlike conventional multifunctional grippers that require multiple actuators, sensors, or control-based switching, the proposed gripper transitions between grasping and rotation solely according to the magnitude of the applied input torque. The key enabler of this behavior is a Twisted Underactuated Mechanism (TUM), which generates non-coplanar motions, namely axial contraction and rotation, from a single rotational input while producing identical contraction regardless of rotation direction. A friction generator mechanically defines torque thresholds that govern passive mode switching, enabling stable grasp establishment before autonomously transitioning to in-hand rotation without sensing or active control. Analytical models describing the kinematics, elastic force generation, and torque transmission of the TUM are derived and experimentally validated. The fabricated gripper is evaluated through quantitative experiments on grasp success, friction-based grasp force regulation, and bidirectional rotation performance. System-level demonstrations, including bolt manipulation, object reorientation, and manipulator-integrated tasks driven solely by wrist torque, confirm reliable grasp to rotate transitions in both rotational directions. These results demonstrate that non-coplanar multifunctional manipulation can be realized through mechanical design alone, establishing mechanically encoded power transmission logic as a robust alternative to actuator and control intensive gripper architectures.

</details>


### [43] [Semilinear single-track vehicle models with distributed tyre friction dynamics](https://arxiv.org/abs/2601.06854)
*Luigi Romano,Ole Morten Aamo,Jan Åslund,Erik Frisk*

Main category: cs.RO

TL;DR: 本文提出了一种新型单车道车辆模型，通过分布式摩擦与刷子动力学模型，系统地整合轮胎动态及摩擦非线性，提升了车辆动力学建模的准确性和实用性。


<details>
  <summary>Details</summary>
Motivation: 提出一种新颖的单车道车辆模型，以便更好地理解和模拟轮胎动态及摩擦引起的非线性效应。

Method: 使用分布式摩擦与刷子动力学（FrBD）模型，结合经典模型如Dahl和LuGre，并通过半线性偏微分方程（PDE）描述滚动接触过程。将这种模型系统地整合进单车道车辆框架中，以捕捉车辆横向运动与轮胎变形的相互作用。

Result: 建立了耦合系统的局部和全局良解性，展示了分布式FrBD模型的耗散性和物理一致性；进行线性化程序以实现谱分析和传递函数推导，支持控制器和观测器的合成；数值仿真验证模型的有效性。

Conclusion: 该研究为车辆动力学建模提供了一种基于物理的、数学上严格且计算上可行的方法，显著推进了轮胎在有限摩擦情况下的瞬态行为的理解与模拟。

Abstract: This paper introduces a novel family of single-track vehicle models that incorporate a distributed representation of transient tyre dynamics, whilst simultaneously accounting for nonlinear effects induced by friction. The core of the proposed framework is represented by the distributed Friction with Bristle Dynamics (FrBD) model, which unifies and extends classical formulations such as Dahl and LuGre by describing the rolling contact process as a spatially distributed system governed by semilinear partial differential equations (PDEs). This model is systematically integrated into a single-track vehicle framework, where the resulting semilinear ODE-PDE interconnection captures the interaction between lateral vehicle motion and tyre deformation. Two main variants are considered: one with rigid tyre carcass and another with flexible carcass, each admitting a compact state-space representation. Local and global well-posedness properties for the coupled system are established rigorously, highlighting the dissipative and physically consistent properties of the distributed FrBD model. A linearisation procedure is also presented, enabling spectral analysis and transfer function derivation, and potentially facilitating the synthesis of controllers and observers. Numerical simulations demonstrate the model's capability to capture micro-shimmy oscillations and transient lateral responses to advanced steering manoeuvres. The proposed formulation advances the state-of-the-art in vehicle dynamics modelling by providing a physically grounded, mathematically rigorous, and computationally tractable approach to incorporating transient tyre behaviour in lateral vehicle dynamics, when accounting for the effect of limited friction.

</details>


### [44] [Observability-Enhanced Target Motion Estimation via Bearing-Box: Theory and MAV Applications](https://arxiv.org/abs/2601.06887)
*Yin Zhang,Zian Ning,Shiyu Zhao*

Main category: cs.RO

TL;DR: 本文提出了一种新颖的bearing-box方法，用于单目视觉下目标运动估计，克服了传统方法的限制，展示出在多旋翼微型飞行器中的优越性。


<details>
  <summary>Details</summary>
Motivation: 单目视觉目标运动估计在多个应用中是一个基本挑战，现有方法多依赖于限制性假设。

Method: 引入bearing-box方法，利用3D边界框中的信息进行目标运动和物理大小的估计，且无须假设目标形状和运动方向。

Result: 通过严格的可观测性分析和广泛的实验验证，展示了估计器在真实场景中的优越性能。

Conclusion: 该算法通过利用3D检测测量中的信息，相较于现有方法具有更灵活的目标运动估计能力，表现出优越的性能。

Abstract: Monocular vision-based target motion estimation is a fundamental challenge in numerous applications. This work introduces a novel bearing-box approach that fully leverages modern 3D detection measurements that are widely available nowadays but have not been well explored for motion estimation so far. Unlike existing methods that rely on restrictive assumptions such as isotropic target shape and lateral motion, our bearing-box estimator can estimate both the target's motion and its physical size without these assumptions by exploiting the information buried in a 3D bounding box. When applied to multi-rotor micro aerial vehicles (MAVs), the estimator yields an interesting advantage: it further removes the need for higher-order motion assumptions by exploiting the unique coupling between MAV's acceleration and thrust. This is particularly significant, as higher-order motion assumptions are widely believed to be necessary in state-of-the-art bearing-based estimators. We support our claims with rigorous observability analyses and extensive experimental validation, demonstrating the estimator's superior performance in real-world scenarios.

</details>


### [45] [ObjSplat: Geometry-Aware Gaussian Surfels for Active Object Reconstruction](https://arxiv.org/abs/2601.06997)
*Yuetao Li,Zhizhou Jia,Yu Zhang,Qun Hao,Shaohui Zhang*

Main category: cs.RO

TL;DR: ObjSplat是一个基于高斯表面点的主动重建框架，能快速高保真重建物体，显著提高扫描效率与重建质量。


<details>
  <summary>Details</summary>
Motivation: 自主高保真物体重建对于创造数字资产和弥合机器人技术中的仿真与现实的差距至关重要。

Method: 提出了ObjSplat，一个利用高斯表面点的主动重建框架，逐步重建未知物体的光照逼真外观和准确几何形状。引入几何感知的视点评估管道，模型化背面可见性和遮挡感知的多视角共可见性。使用下一最佳路径规划器执行多步前瞻性规划，在动态构建的空间图上生成高效的轨迹。

Result: 在仿真和真实文化遗物上的广泛实验表明，ObjSplat能够在数分钟内生成物理一致的模型，具有优越的重建保真度和表面完整性，同时显著减少扫描时间和路径长度。

Conclusion: ObjSplat在重建效率和质量上超越了现有的最先进方法。

Abstract: Autonomous high-fidelity object reconstruction is fundamental for creating digital assets and bridging the simulation-to-reality gap in robotics. We present ObjSplat, an active reconstruction framework that leverages Gaussian surfels as a unified representation to progressively reconstruct unknown objects with both photorealistic appearance and accurate geometry. Addressing the limitations of conventional opacity or depth-based cues, we introduce a geometry-aware viewpoint evaluation pipeline that explicitly models back-face visibility and occlusion-aware multi-view covisibility, reliably identifying under-reconstructed regions even on geometrically complex objects. Furthermore, to overcome the limitations of greedy planning strategies, ObjSplat employs a next-best-path (NBP) planner that performs multi-step lookahead on a dynamically constructed spatial graph. By jointly optimizing information gain and movement cost, this planner generates globally efficient trajectories. Extensive experiments in simulation and on real-world cultural artifacts demonstrate that ObjSplat produces physically consistent models within minutes, achieving superior reconstruction fidelity and surface completeness while significantly reducing scan time and path length compared to state-of-the-art approaches. Project page: https://li-yuetao.github.io/ObjSplat-page/ .

</details>


### [46] [A Sliding Mode Controller Based on Timoshenko Beam Theory Developed for a Tendon-Driven Robotic Wrist](https://arxiv.org/abs/2601.07009)
*Shifa Sulaiman,Mohammad Gohari,Francesco Schetter,Fanny Ficuciello*

Main category: cs.RO

TL;DR: 本研究设计并实现了一种腱驱动的机器人腕关节及高效的滑模控制器，展示了在多变操作条件下的精确运动控制和优越性能。


<details>
  <summary>Details</summary>
Motivation: 发展灵巧的机器人关节是提高机器人系统操控能力的关键。

Method: 采用基于Timoshenko的方法建模腕关节机制，并设计滑模控制器以实现精准的运动控制。

Result: 滑模控制器在模拟和实验中的表现优越，RMSE分别为1.67e-2弧度和0.2弧度，达到小于3秒的稳态时间及小于1e-1弧度的稳态误差。

Conclusion: 提出的滑模控制器在运动准确性和快速收敛方面优于其他控制策略，为未来的机器人应用中腱驱动腕机制及控制策略的探索奠定了基础。

Abstract: Development of dexterous robotic joints is essential for advancing manipulation capabilities in robotic systems. This paper presents the design and implementation of a tendon-driven robotic wrist joint together with an efficient Sliding Mode Controller (SMC) for precise motion control. The wrist mechanism is modeled using a Timoshenko-based approach to accurately capture its kinematic and dynamic properties, which serve as the foundation for tendon force calculations within the controller. The proposed SMC is designed to deliver fast dynamic response and computational efficiency, enabling accurate trajectory tracking under varying operating conditions. The effectiveness of the controller is validated through comparative analyses with existing controllers for similar wrist mechanisms. The proposed SMC demonstrates superior performance in both simulation and experimental studies. The Root Mean Square Error (RMSE) in simulation is approximately 1.67e-2 radians, while experimental validation yields an error of 0.2 radians. Additionally, the controller achieves a settling time of less than 3 seconds and a steady-state error below 1e-1 radians, consistently observed across both simulation and experimental evaluations. Comparative analyses confirm that the developed SMC surpasses alternative control strategies in motion accuracy, rapid convergence, and steady-state precision. This work establishes a foundation for future exploration of tendon-driven wrist mechanisms and control strategies in robotic applications.

</details>


### [47] [RSLCPP - Deterministic Simulations Using ROS 2](https://arxiv.org/abs/2601.07052)
*Simon Sagmeister,Marcel Weinmann,Phillip Pitschi,Markus Lienkamp*

Main category: cs.RO

TL;DR: 提出了一种基于ROS 2的确定性模拟方法，解决了ROS在不同硬件平台上重现性差的问题。


<details>
  <summary>Details</summary>
Motivation: 解决ROS在不同硬件平台上由于异步多进程设计造成的重复性问题，以提高科学基准测试和持续集成的有效性。

Method: 通过ROS 2节点创建确定性模拟的方法，利用C++的ROS Simulation Library (RSLCPP)来实现，不需要对现有节点进行代码修改。

Result: 在测试合成基准和实际机器人系统时，证明该方法在不同CPU和架构上能够提供相同的结果。

Conclusion: RSLCPP通过开放源码形式提供，显著提高了机器人应用中的模拟重现性。

Abstract: Simulation is crucial in real-world robotics, offering safe, scalable, and efficient environments for developing applications, ranging from humanoid robots to autonomous vehicles and drones. While the Robot Operating System (ROS) has been widely adopted as the backbone of these robotic applications in both academia and industry, its asynchronous, multiprocess design complicates reproducibility, especially across varying hardware platforms. Deterministic callback execution cannot be guaranteed when computation times and communication delays vary. This lack of reproducibility complicates scientific benchmarking and continuous integration, where consistent results are essential. To address this, we present a methodology to create deterministic simulations using ROS 2 nodes. Our ROS Simulation Library for C++ (RSLCPP) implements this approach, enabling existing nodes to be combined into a simulation routine that yields reproducible results without requiring any code changes. We demonstrate that our approach yields identical results across various CPUs and architectures when testing both a synthetic benchmark and a real-world robotics system. RSLCPP is open-sourced at https://github.com/TUMFTM/rslcpp.

</details>


### [48] [PALM: Progress-Aware Policy Learning via Affordance Reasoning for Long-Horizon Robotic Manipulation](https://arxiv.org/abs/2601.07060)
*Yuanzhe Liu,Jingyuan Zhu,Yuchen Mo,Gen Li,Xu Cao,Jin Jin,Yifan Shen,Zhengyuan Li,Tianjiao Yu,Wenzhen Yuan,Fangqiang Ding,Ismini Lourentzou*

Main category: cs.RO

TL;DR: PALM是一个新的VLA框架，通过有利性推理和进展线索提升机器人长时间多步骤操作的成功率，展现出显著优势。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有VLA模型在长时间、多步骤任务中的执行错误，PALM框架被提出，以增强机器人对交互相关信息的识别和利用。

Method: PALM框架通过与交互相关的有利性推理和子任务进展线索进行政策学习，并在此基础上进行持续的进展预测。

Result: PALM框架通过与交互相关的有利性推理和子任务进展线索的政策学习，有效推动了机器人操作领域的发展。

Conclusion: PALM在长时间、 multi-step任务上表现优越，能够显著减少执行错误并提高成功率。

Abstract: Recent advancements in vision-language-action (VLA) models have shown promise in robotic manipulation, yet they continue to struggle with long-horizon, multi-step tasks. Existing methods lack internal reasoning mechanisms that can identify task-relevant interaction cues or track progress within a subtask, leading to critical execution errors such as repeated actions, missed steps, and premature termination. To address these challenges, we introduce PALM, a VLA framework that structures policy learning around interaction-centric affordance reasoning and subtask progress cues. PALM distills complementary affordance representations that capture object relevance, contact geometry, spatial placements, and motion dynamics, and serve as task-relevant anchors for visuomotor control. To further stabilize long-horizon execution, PALM predicts continuous within-subtask progress, enabling seamless subtask transitions. Across extensive simulation and real-world experiments, PALM consistently outperforms baselines, achieving a 91.8% success rate on LIBERO-LONG, a 12.5% improvement in average length on CALVIN ABC->D, and a 2x improvement over real-world baselines across three long-horizon generalization settings.

</details>


### [49] [PROTEA: Securing Robot Task Planning and Execution](https://arxiv.org/abs/2601.07186)
*Zainab Altaweel,Mohaiminul Al Nahian,Jake Juettner,Adnan Siraj Rakin,Shiqi Zhang*

Main category: cs.RO

TL;DR: 本研究提出PROTEA，一个基于LLM的防御机制，以提升机器人任务规划的安全性，评估恶性行为并提供系统性评估结果。


<details>
  <summary>Details</summary>
Motivation: 应对现有机器人任务规划中的安全挑战，尤其是在基础模型上的脆弱性。

Method: 引入PROTEA，利用LLM作为判别机制，评估任务规划的安全性，并创建了包含良性和恶性任务计划的数据集进行系统性评估。

Result: 通过评估不同版本的PROTEA，提供了增强机器人任务规划系统鲁棒性和安全性的可操作性见解。

Conclusion: PROTEA为机器人任务规划提供了一种安全性评估机制，能够提高系统的鲁棒性和安全性。

Abstract: Robots need task planning methods to generate action sequences for complex tasks. Recent work on adversarial attacks has revealed significant vulnerabilities in existing robot task planners, especially those built on foundation models. In this paper, we aim to address these security challenges by introducing PROTEA, an LLM-as-a-Judge defense mechanism, to evaluate the security of task plans. PROTEA is developed to address the dimensionality and history challenges in plan safety assessment. We used different LLMs to implement multiple versions of PROTEA for comparison purposes. For systemic evaluations, we created a dataset containing both benign and malicious task plans, where the harmful behaviors were injected at varying levels of stealthiness. Our results provide actionable insights for robotic system practitioners seeking to enhance robustness and security of their task planning systems. Details, dataset and demos are provided: https://protea-secure.github.io/PROTEA/

</details>


### [50] [HERE: Hierarchical Active Exploration of Radiance Field with Epistemic Uncertainty Minimization](https://arxiv.org/abs/2601.07242)
*Taekbeom Lee,Dabin Kim,Youngseok Jang,H. Jin Kim*

Main category: cs.RO

TL;DR: 提出了一种基于神经辐射场的主动3D场景重建框架，通过量化不确定性和层次化探索策略，实现了高效而精确的场景重建。


<details>
  <summary>Details</summary>
Motivation: 开发一种高保真隐式映射的3D场景重建框架，优化数据采集效率并提高重建精度。

Method: 基于神经辐射场的主动3D场景重建框架，利用对未见区域的准确识别生成相机轨迹，通过层次化探索策略进行数据采集和场景重建。

Result: 在不同尺度的光照真实模拟场景中，比较以往方法，所提方法在重建完整性上表现更佳，并通过硬件演示验证其现实应用性。

Conclusion: 所提出的框架在活跃的3D重建方面表现出更高的重建完整性，并在真实世界应用中得到了验证。

Abstract: We present HERE, an active 3D scene reconstruction framework based on neural radiance fields, enabling high-fidelity implicit mapping. Our approach centers around an active learning strategy for camera trajectory generation, driven by accurate identification of unseen regions, which supports efficient data acquisition and precise scene reconstruction. The key to our approach is epistemic uncertainty quantification based on evidential deep learning, which directly captures data insufficiency and exhibits a strong correlation with reconstruction errors. This allows our framework to more reliably identify unexplored or poorly reconstructed regions compared to existing methods, leading to more informed and targeted exploration. Additionally, we design a hierarchical exploration strategy that leverages learned epistemic uncertainty, where local planning extracts target viewpoints from high-uncertainty voxels based on visibility for trajectory generation, and global planning uses uncertainty to guide large-scale coverage for efficient and comprehensive reconstruction. The effectiveness of the proposed method in active 3D reconstruction is demonstrated by achieving higher reconstruction completeness compared to previous approaches on photorealistic simulated scenes across varying scales, while a hardware demonstration further validates its real-world applicability.

</details>


### [51] [AdaMorph: Unified Motion Retargeting via Embodiment-Aware Adaptive Transformers](https://arxiv.org/abs/2601.07284)
*Haoyu Zhang,Shibo Jin,Lvsong Li,Jun Li,Liang Lin,Xiaodong He,Zecui Zeng*

Main category: cs.RO

TL;DR: 本论文提出了AdaMorph，一个统一的神经重定向框架，可以适应各种机器人形态的人的运动，实现了运动的条件生成。


<details>
  <summary>Details</summary>
Motivation: 人类运动的重定向至异构机器人面临着严重的运动学和动力学差异，现有解决方案无法有效利用共享运动语义。

Method: 将重定向视为条件生成任务，采用Morphology-agnostic的潜在意图空间和双重提示机制，运用自适应图层归一化（AdaLN）来动态调节解码器的特征空间。

Result: 针对12种不同的人形机器人进行的实验结果表明，AdaMorph能有效统一不同拓扑的控制，并在保持源行为动态本质的同时对未见过的复杂动作体现出强大的零-shot泛化能力。

Conclusion: AdaMorph提供了一种有效的方法，将人类运动统一地适应于多种机器人形态，展示了其在处理复杂动作时的强大零-shot泛化能力。

Abstract: Retargeting human motion to heterogeneous robots is a fundamental challenge in robotics, primarily due to the severe kinematic and dynamic discrepancies between varying embodiments. Existing solutions typically resort to training embodiment-specific models, which scales poorly and fails to exploit shared motion semantics. To address this, we present AdaMorph, a unified neural retargeting framework that enables a single model to adapt human motion to diverse robot morphologies. Our approach treats retargeting as a conditional generation task. We map human motion into a morphology-agnostic latent intent space and utilize a dual-purpose prompting mechanism to condition the generation. Instead of simple input concatenation, we leverage Adaptive Layer Normalization (AdaLN) to dynamically modulate the decoder's feature space based on embodiment constraints. Furthermore, we enforce physical plausibility through a curriculum-based training objective that ensures orientation and trajectory consistency via integration. Experimental results on 12 distinct humanoid robots demonstrate that AdaMorph effectively unifies control across heterogeneous topologies, exhibiting strong zero-shot generalization to unseen complex motions while preserving the dynamic essence of the source behaviors.

</details>


### [52] [Heterogeneous Multi-Expert Reinforcement Learning for Long-Horizon Multi-Goal Tasks in Autonomous Forklifts](https://arxiv.org/abs/2601.07304)
*Yun Chen,Bowei Huang,Fan Guo,Kang Song*

Main category: cs.RO

TL;DR: HMER框架通过分解长期任务并引入混合模仿-强化训练策略，显著提高了自主叉车在非结构化仓库中的导航与物体交互性能。


<details>
  <summary>Details</summary>
Motivation: 在非结构化仓库中，自主移动操作需要高效的大规模导航与高精度的物体交互之间的平衡。

Method: 提出了一个异构多专家强化学习（HMER）框架，该框架将长期任务分解为由语义任务规划器控制的专门子策略。

Result: HMER在Gazebo模拟实验中显著优于顺序和端到端基线，实现任务成功率94.2%（基线为62.5%），操作时间减少21.4%，放置误差保持在1.5厘米以内。

Conclusion: HMER框架有效解决了自主叉车的精确物料处理问题，证明了它在处理复杂任务中的有效性。

Abstract: Autonomous mobile manipulation in unstructured warehouses requires a balance between efficient large-scale navigation and high-precision object interaction. Traditional end-to-end learning approaches often struggle to handle the conflicting demands of these distinct phases. Navigation relies on robust decision-making over large spaces, while manipulation needs high sensitivity to fine local details. Forcing a single network to learn these different objectives simultaneously often causes optimization interference, where improving one task degrades the other. To address these limitations, we propose a Heterogeneous Multi-Expert Reinforcement Learning (HMER) framework tailored for autonomous forklifts. HMER decomposes long-horizon tasks into specialized sub-policies controlled by a Semantic Task Planner. This structure separates macro-level navigation from micro-level manipulation, allowing each expert to focus on its specific action space without interference. The planner coordinates the sequential execution of these experts, bridging the gap between task planning and continuous control. Furthermore, to solve the problem of sparse exploration, we introduce a Hybrid Imitation-Reinforcement Training Strategy. This method uses expert demonstrations to initialize the policy and Reinforcement Learning for fine-tuning. Experiments in Gazebo simulations show that HMER significantly outperforms sequential and end-to-end baselines. Our method achieves a task success rate of 94.2\% (compared to 62.5\% for baselines), reduces operation time by 21.4\%, and maintains placement error within 1.5 cm, validating its efficacy for precise material handling.

</details>


### [53] [Large-Scale Autonomous Gas Monitoring for Volcanic Environments: A Legged Robot on Mount Etna](https://arxiv.org/abs/2601.07362)
*Julia Richter,Turcan Tuna,Manthan Patel,Takahiro Miki,Devon Higgins,James Fox,Cesar Cadena,Andres Diaz,Marco Hutter*

Main category: cs.RO

TL;DR: 本研究展示了一种腿式机器人系统在火山气体分析中的自主能力，成功率高达100%，并提出了改进自主导航和传感策略的建议。


<details>
  <summary>Details</summary>
Motivation: 火山气体排放是喷发活动的关键前兆，但由于近地面测量的危险性和后勤挑战，迫切需要自主解决方案。

Method: 提出了一种腿式机器人系统ANYmal，配备四极质谱仪，整合了任务规划界面、全局规划器、定位框架和地形意识导航。

Result: 在埃特纳山进行的三次自主任务中实现了93-100%的成功气体源检测，另外还进行了遥控任务，测量了自然喷气孔中的二氧化硫和二氧化碳。

Conclusion: 讨论了从气体分析和自治的角度获得的经验教训，强调适应性传感策略的必要性、全局与局部规划的紧密集成以及改进硬件设计。

Abstract: Volcanic gas emissions are key precursors of eruptive activity. Yet, obtaining accurate near-surface measurements remains hazardous and logistically challenging, motivating the need for autonomous solutions. Limited mobility in rough volcanic terrain has prevented wheeled systems from performing reliable in situ gas measurements, reducing their usefulness as sensing platforms. We present a legged robotic system for autonomous volcanic gas analysis, utilizing the quadruped ANYmal, equipped with a quadrupole mass spectrometer system. Our modular autonomy stack integrates a mission planning interface, global planner, localization framework, and terrain-aware local navigation. We evaluated the system on Mount Etna across three autonomous missions in varied terrain, achieving successful gas-source detections with autonomy rates of 93-100%. In addition, we conducted a teleoperated mission in which the robot measured natural fumaroles, detecting sulfur dioxide and carbon dioxide. We discuss lessons learned from the gas-analysis and autonomy perspectives, emphasizing the need for adaptive sensing strategies, tighter integration of global and local planning, and improved hardware design.

</details>


### [54] [LOONG: Online Time-Optimal Autonomous Flight for MAVs in Cluttered Environments](https://arxiv.org/abs/2601.07434)
*Xin Guan,Fangguo Zhao,Qianyi Wang,Chengcheng Zhao,Jiming Chen,Shuo Li*

Main category: cs.RO

TL;DR: 本文提出了一种用于微型无人飞行器在复杂环境中进行高速度、时间最优自主飞行的集成规划与控制框架，验证了其在实地实验中的优越性能。


<details>
  <summary>Details</summary>
Motivation: 微型无人飞行器在未知复杂环境中的自主飞行，特别是在时间关键任务中，由于保守的操控策略面临挑战。

Method: 通过模仿学习加速时间分配过程，在每个 replanning 周期内（100 Hz）生成多项式表示的时间最优轨迹作为参考，并采用时间最优模型预测轮廓控制（MPCC），融入安全飞行走廊约束，实现激进且安全的操控。

Result: 通过定制的 LiDAR 基础 MAV 平台进行广泛验证，仿真结果显示出较现有技术更为激进的性能，实地实验中在复杂环境中达到最高速度 18 m/s，并成功进行 10 次连续试验。

Conclusion: 所提出的框架在提升自主飞行效率与安全性方面展示了显著的优势。

Abstract: Autonomous flight of micro air vehicles (MAVs) in unknown, cluttered environments remains challenging for time-critical missions due to conservative maneuvering strategies. This article presents an integrated planning and control framework for high-speed, time-optimal autonomous flight of MAVs in cluttered environments. In each replanning cycle (100 Hz), a time-optimal trajectory under polynomial presentation is generated as a reference, with the time-allocation process accelerated by imitation learning. Subsequently, a time-optimal model predictive contouring control (MPCC) incorporates safe flight corridor (SFC) constraints at variable horizon steps to enable aggressive yet safe maneuvering, while fully exploiting the MAV's dynamics. We validate the proposed framework extensively on a custom-built LiDAR-based MAV platform. Simulation results demonstrate superior aggressiveness compared to the state of the art, while real-world experiments achieve a peak speed of 18 m/s in a cluttered environment and succeed in 10 consecutive trials from diverse start points. The video is available at the following link: https://youtu.be/vexXXhv99oQ.

</details>


### [55] [WaveMan: mmWave-Based Room-Scale Human Interaction Perception for Humanoid Robots](https://arxiv.org/abs/2601.07454)
*Yuxuan Hu,Kuangji Zuo,Boyu Ma,Shihao Li,Zhaoyang Xia,Feng Xu,Jianfei Yang*

Main category: cs.RO

TL;DR: WaveMan是一种适应性强的毫米波感知系统，能在家庭环境中实现高准确性的隐私保护人机交互，效果明显优于以往系统。


<details>
  <summary>Details</summary>
Motivation: 在人机交互中，特别是在家庭环境中，需要确保用户隐私并对用户位置变化具有鲁棒性，这激发了对毫米波传感技术的研究。

Method: WaveMan集成了视点对齐和声谱增强技术，并采用双通道注意力机制以实现稳健的特征提取。

Result: 在固定位置下，WaveMan与基线的跨位置准确性相同，但训练位置减少到五分之一。在随机自由位置测试中，准确率从33.00%提升至94.33%。

Conclusion: WaveMan系统在不同用户位置下实现了可靠的人机交互，显著提高了自由位置下的准确性，支持隐私保护的家用机器人交互。

Abstract: Reliable humanoid-robot interaction (HRI) in household environments is constrained by two fundamental requirements, namely robustness to unconstrained user positions and preservation of user privacy. Millimeter-wave (mmWave) sensing inherently supports privacy-preserving interaction, making it a promising modality for room-scale HRI. However, existing mmWave-based interaction-sensing systems exhibit poor spatial generalization at unseen distances or viewpoints. To address this challenge, we introduce WaveMan, a spatially adaptive room-scale perception system that restores reliable human interaction sensing across arbitrary user positions. WaveMan integrates viewpoint alignment and spectrogram enhancement for spatial consistency, with dual-channel attention for robust feature extraction. Experiments across five participants show that, under fixed-position evaluation, WaveMan achieves the same cross-position accuracy as the baseline with five times fewer training positions. In random free-position testing, accuracy increases from 33.00% to 94.33%, enabled by the proposed method. These results demonstrate the feasibility of reliable, privacy-preserving interaction for household humanoid robots across unconstrained user positions.

</details>


### [56] [NanoCockpit: Performance-optimized Application Framework for AI-based Autonomous Nanorobotics](https://arxiv.org/abs/2601.07476)
*Elia Cereda,Alessandro Giusti,Daniele Palossi*

Main category: cs.RO

TL;DR: NanoCockpit 框架通过提高吞吐量和减少延迟，优化了纳米无人机的计算资源使用，提升了闭环控制性能。


<details>
  <summary>Details</summary>
Motivation: 在资源有限的嵌入式系统中，纳米无人机的计算资源常被低效使用。缺乏简单高效的软件层使得其控制性能低下。因此，开发 NanoCockpit 框架以优化这些资源成为必要。

Method: 该论文提出了一种名为 NanoCockpit 的软件框架，通过基于协程的多任务处理，实现时间最优的多缓冲图像获取、多核计算、MCUs 间数据交换和 Wi-Fi 流媒体传输，以提高吞吐量和减少延迟。

Result: 通过在三种真实世界的 TinyML 纳米机器人应用中进行现场实验，我们的框架实现了理想的端到端延迟，提供了量化的闭环控制性能改善。

Conclusion: NanoCockpit 框架显著提高了闭环控制性能，减少了平均位置误差，并使任务成功率从 40% 提高到 100%。

Abstract: Autonomous nano-drones, powered by vision-based tiny machine learning (TinyML) models, are a novel technology gaining momentum thanks to their broad applicability and pushing scientific advancement on resource-limited embedded systems. Their small form factor, i.e., a few 10s grams, severely limits their onboard computational resources to sub-\SI{100}{\milli\watt} microcontroller units (MCUs). The Bitcraze Crazyflie nano-drone is the \textit{de facto} standard, offering a rich set of programmable MCUs for low-level control, multi-core processing, and radio transmission. However, roboticists very often underutilize these onboard precious resources due to the absence of a simple yet efficient software layer capable of time-optimal pipelining of multi-buffer image acquisition, multi-core computation, intra-MCUs data exchange, and Wi-Fi streaming, leading to sub-optimal control performances. Our \textit{NanoCockpit} framework aims to fill this gap, increasing the throughput and minimizing the system's latency, while simplifying the developer experience through coroutine-based multi-tasking. In-field experiments on three real-world TinyML nanorobotics applications show our framework achieves ideal end-to-end latency, i.e. zero overhead due to serialized tasks, delivering quantifiable improvements in closed-loop control performance ($-$30\% mean position error, mission success rate increased from 40\% to 100\%).

</details>


### [57] [FlyCo: Foundation Model-Empowered Drones for Autonomous 3D Structure Scanning in Open-World Environments](https://arxiv.org/abs/2601.07558)
*Chen Feng,Guiyong Zheng,Tengkai Zhuang,Yongqian Wu,Fangzhan He,Haojia Li,Juepeng Zheng,Shaojie Shen,Boyu Zhou*

Main category: cs.RO

TL;DR: 本文提出FlyCo，一个基于基础模型的自主3D扫描系统，结合感知、预测和规划，显示出在多样未知环境中有效的场景理解和操作能力。


<details>
  <summary>Details</summary>
Motivation: 尽管无人机在开放世界目标结构的3D扫描中广泛应用，现有方法受限于严格假设和人工先验，效率和适应性不足，迫切需要突破性解决方案。

Method: FlyCo系统架构集成基础模型知识，采用感知、预测、规划三阶段循环实现全自主3D目标扫描

Result: 深度验证了FlyCo在实景与模拟环境中提供精准场景理解、高效率和实时安全性，超越现有方案并减少人工干预。

Conclusion: FlyCo作为一种灵活可扩展的蓝图，展现了在未来基础模型与机器人技术进展中广泛的应用潜力，代码将在公开提供。

Abstract: Autonomous 3D scanning of open-world target structures via drones remains challenging despite broad applications. Existing paradigms rely on restrictive assumptions or effortful human priors, limiting practicality, efficiency, and adaptability. Recent foundation models (FMs) offer great potential to bridge this gap. This paper investigates a critical research problem: What system architecture can effectively integrate FM knowledge for this task? We answer it with FlyCo, a principled FM-empowered perception-prediction-planning loop enabling fully autonomous, prompt-driven 3D target scanning in diverse unknown open-world environments. FlyCo directly translates low-effort human prompts (text, visual annotations) into precise adaptive scanning flights via three coordinated stages: (1) perception fuses streaming sensor data with vision-language FMs for robust target grounding and tracking; (2) prediction distills FM knowledge and combines multi-modal cues to infer the partially observed target's complete geometry; (3) planning leverages predictive foresight to generate efficient and safe paths with comprehensive target coverage. Building on this, we further design key components to boost open-world target grounding efficiency and robustness, enhance prediction quality in terms of shape accuracy, zero-shot generalization, and temporal stability, and balance long-horizon flight efficiency with real-time computability and online collision avoidance. Extensive challenging real-world and simulation experiments show FlyCo delivers precise scene understanding, high efficiency, and real-time safety, outperforming existing paradigms with lower human effort and verifying the proposed architecture's practicality. Comprehensive ablations validate each component's contribution. FlyCo also serves as a flexible, extensible blueprint, readily leveraging future FM and robotics advances. Code will be released.

</details>


### [58] [Stable In-hand Manipulation for a Lightweight Four-motor Prosthetic Hand](https://arxiv.org/abs/2601.07559)
*Yuki Kuroda,Tomoya Takahashi,Cristian C. Beltran-Hernandez,Kazutoshi Tanaka,Masashi Hamaya*

Main category: cs.RO

TL;DR: 本文提出了一种新型电动假手，通过电机电流反馈优化操控，成功处理多种物体，并执行常见日常任务。


<details>
  <summary>Details</summary>
Motivation: 改善假手操作性能，满足用户在日常生活中对重物及各种物体的操控需求。

Method: 采用电机电流反馈与优化的单轴拇指结合，估算物体宽度并调整食指位置，增强手部操控稳定性。

Result: 实验验证显示，在处理5-30毫米宽的轻质物体时成功率达到100%，在重铝棱柱(重达289克)的处理中成功率保持在80%以上。

Conclusion: 改进后的PLEXUS手在日常活动中的表现提升，能够执行关闭瓶盖和调节笔的位置等任务。

Abstract: Electric prosthetic hands should be lightweight to decrease the burden on the user, shaped like human hands for cosmetic purposes, and designed with motors enclosed inside to protect them from damage and dirt. Additionally, in-hand manipulation is necessary to perform daily activities such as transitioning between different postures, particularly through rotational movements, such as reorienting a pen into a writing posture after picking it up from a desk. We previously developed PLEXUS hand (Precision-Lateral dEXteroUS manipulation hand), a lightweight (311 g) prosthetic hand driven by four motors. This prosthetic performed reorientation between precision and lateral grasps with various objects. However, its controller required predefined object widths and was limited to handling lightweight objects (of weight up to 34 g). This study addresses these limitations by employing motor current feedback. Combined with the hand's previously optimized single-axis thumb, this approach achieves more stable manipulation by estimating the object's width and adjusting the index finger position to maintain stable object holding during the reorientation. Experimental validation using primitive objects of various widths (5-30 mm) and shapes (cylinders and prisms) resulted in a 100% success rate with lightweight objects and maintained a high success rate (>=80) even with heavy aluminum prisms (of weight up to 289 g). By contrast, the performance without index finger coordination dropped to just 40% on the heaviest 289 g prism. The hand also successfully executed several daily tasks, including closing bottle caps and orienting a pen for writing.

</details>


### [59] [Deep Whole-body Parkour](https://arxiv.org/abs/2601.07701)
*Ziwen Zhuang,Shaoting Zhu,Mengjie Zhao,Hang Zhao*

Main category: cs.RO

TL;DR: 本研究提出了一种结合感知与一般运动控制的方法，使人形机器人能够在不平坦地形上执行动态非行走任务。


<details>
  <summary>Details</summary>
Motivation: 希望将现有的人形控制方法结合起来，以提升机器人在复杂地形上的运动能力。

Method: 设计一个框架，将外部感知整合到全身运动跟踪中，训练一个政策执行多种不同动作。

Result: 实现了在不规则地形上执行高动态多接触动作，如翻越和翻滚，显著扩展了机器人的可行性。

Conclusion: 整合感知信息能够显著增强机器人在复杂环境下的运动能力。

Abstract: Current approaches to humanoid control generally fall into two paradigms: perceptive locomotion, which handles terrain well but is limited to pedal gaits, and general motion tracking, which reproduces complex skills but ignores environmental capabilities. This work unites these paradigms to achieve perceptive general motion control. We present a framework where exteroceptive sensing is integrated into whole-body motion tracking, permitting a humanoid to perform highly dynamic, non-locomotion tasks on uneven terrain. By training a single policy to perform multiple distinct motions across varied terrestrial features, we demonstrate the non-trivial benefit of integrating perception into the control loop. Our results show that this framework enables robust, highly dynamic multi-contact motions, such as vaulting and dive-rolling, on unstructured terrain, significantly expanding the robot's traversability beyond simple walking or running. https://project-instinct.github.io/deep-whole-body-parkour

</details>


### [60] [Hiking in the Wild: A Scalable Perceptive Parkour Framework for Humanoids](https://arxiv.org/abs/2601.07718)
*Shaoting Zhu,Ziwen Zhuang,Mengjie Zhao,Kun-Ying Lee,Hang Zhao*

Main category: cs.RO

TL;DR: 本文提出了一种名为《Hiking in the Wild》的可扩展端到端框架，用于类人徒步行走，解决了在复杂环境中行走的多项挑战，且在速度和安全性方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 在复杂且非结构化环境中实现鲁棒的类人徒步行走，需要从反应式本体感知转向主动感知，以克服现有方法的局限性。

Method: 利用单阶段强化学习方案，直接将原始深度输入和本体感受映射到关节动作，无需依赖外部状态估计。

Result: 大量实地实验表明，我们的策略可以在复杂地形中快速而稳健地行走，速度高达2.5米/秒。

Conclusion: 我们提出的框架可以有效地在复杂地形中实现鲁棒的类人徒步行走，速度可达2.5米/秒，且代码已开源以促进研究的可重复性。

Abstract: Achieving robust humanoid hiking in complex, unstructured environments requires transitioning from reactive proprioception to proactive perception. However, integrating exteroception remains a significant challenge: mapping-based methods suffer from state estimation drift; for instance, LiDAR-based methods do not handle torso jitter well. Existing end-to-end approaches often struggle with scalability and training complexity; specifically, some previous works using virtual obstacles are implemented case-by-case. In this work, we present \textit{Hiking in the Wild}, a scalable, end-to-end parkour perceptive framework designed for robust humanoid hiking. To ensure safety and training stability, we introduce two key mechanisms: a foothold safety mechanism combining scalable \textit{Terrain Edge Detection} with \textit{Foot Volume Points} to prevent catastrophic slippage on edges, and a \textit{Flat Patch Sampling} strategy that mitigates reward hacking by generating feasible navigation targets. Our approach utilizes a single-stage reinforcement learning scheme, mapping raw depth inputs and proprioception directly to joint actions, without relying on external state estimation. Extensive field experiments on a full-size humanoid demonstrate that our policy enables robust traversal of complex terrains at speeds up to 2.5 m/s. The training and deployment code is open-sourced to facilitate reproducible research and deployment on real robots with minimal hardware modifications.

</details>


### [61] [THETA: Triangulated Hand-State Estimation for Teleoperation and Automation in Robotic Hand Control](https://arxiv.org/abs/2601.07768)
*Alex Huang,Akshay Karthik*

Main category: cs.RO

TL;DR: 该研究提出了一种经济有效的手部遥操作新方法，通过三个网络摄像头进行三角测量跟踪，实时估计手指关节角度，并利用低成本的DexHand机器人手展示其应用。


<details>
  <summary>Details</summary>
Motivation: 传统的深度摄像头和传感手套成本高，限制了机器人手的遥操作，因此需要探索更经济的替代方案。

Method: 使用三台640x480分辨率的网络摄像头进行手部三角测量跟踪，结合DeepLabV3进行手部分割，以及使用优化的MobileNetV2 CNN分类器进行关节角度分类。

Result: 模型在手部姿势分类上取得了97.18%的准确率、98.72%的召回率、F1分数为0.9274和精确度为0.8906。

Conclusion: 该方法为医疗、语言和制造应用提供了成本效益高且用户友好的遥操作解决方案，并计划在未来增强数据集的多样性和整合腕部跟踪功能。

Abstract: The teleoperation of robotic hands is limited by the high costs of depth cameras and sensor gloves, commonly used to estimate hand relative joint positions (XYZ). We present a novel, cost-effective approach using three webcams for triangulation-based tracking to approximate relative joint angles (theta) of human fingers. We also introduce a modified DexHand, a low-cost robotic hand from TheRobotStudio, to demonstrate THETA's real-time application. Data collection involved 40 distinct hand gestures using three 640x480p webcams arranged at 120-degree intervals, generating over 48,000 RGB images. Joint angles were manually determined by measuring midpoints of the MCP, PIP, and DIP finger joints. Captured RGB frames were processed using a DeepLabV3 segmentation model with a ResNet-50 backbone for multi-scale hand segmentation. The segmented images were then HSV-filtered and fed into THETA's architecture, consisting of a MobileNetV2-based CNN classifier optimized for hierarchical spatial feature extraction and a 9-channel input tensor encoding multi-perspective hand representations. The classification model maps segmented hand views into discrete joint angles, achieving 97.18% accuracy, 98.72% recall, F1 Score of 0.9274, and a precision of 0.8906. In real-time inference, THETA captures simultaneous frames, segments hand regions, filters them, and compiles a 9-channel tensor for classification. Joint-angle predictions are relayed via serial to an Arduino, enabling the DexHand to replicate hand movements. Future research will increase dataset diversity, integrate wrist tracking, and apply computer vision techniques such as OpenAI-Vision. THETA potentially ensures cost-effective, user-friendly teleoperation for medical, linguistic, and manufacturing applications.

</details>


### [62] [Data-driven control of hydraulic impact hammers under strict operational and control constraints](https://arxiv.org/abs/2601.07813)
*Francisco Leiva,Claudio Canales,Michelle Valenzuela,Javier Ruiz-del-Solar*

Main category: cs.RO

TL;DR: 本文提出了一种数据驱动的方法来控制液压冲击锤，解决了系统识别与控制策略设计的问题，使用少量的遥操作数据实现了高精度的岩石破碎控制。


<details>
  <summary>Details</summary>
Motivation: 为了在采矿行业中提高静态液压冲击锤的控制精确性，使其能够在正常操作中达到所需的目标姿态。

Method: 通过监督学习从遥操作数据中获得液压臂的动态模型，随后利用强化学习（RL）和模型预测控制（MPC）算法进行控制策略的设计和对比。

Result: 在真实场景中，使用优化的RL策略实现了目标端执行器姿态的有效控制，位置误差小于12厘米，俯仰角误差小于0.08弧度，满足岩石破碎的精度要求。

Conclusion: 基于强化学习的控制策略在实际应用中表现出良好的精确性，能够有效地指引液压冲击锤达到目标姿态，从而实现高效的岩石破碎。

Abstract: This paper presents a data-driven methodology for the control of static hydraulic impact hammers, also known as rock breakers, which are commonly used in the mining industry. The task addressed in this work is that of controlling the rock-breaker so its end-effector reaches arbitrary target poses, which is required in normal operation to place the hammer on top of rocks that need to be fractured. The proposed approach considers several constraints, such as unobserved state variables due to limited sensing and the strict requirement of using a discrete control interface at the joint level. First, the proposed methodology addresses the problem of system identification to obtain an approximate dynamic model of the hydraulic arm. This is done via supervised learning, using only teleoperation data. The learned dynamic model is then exploited to obtain a controller capable of reaching target end-effector poses. For policy synthesis, both reinforcement learning (RL) and model predictive control (MPC) algorithms are utilized and contrasted. As a case study, we consider the automation of a Bobcat E10 mini-excavator arm with a hydraulic impact hammer attached as end-effector. Using this machine, both the system identification and policy synthesis stages are studied in simulation and in the real world. The best RL-based policy consistently reaches target end-effector poses with position errors below 12 cm and pitch angle errors below 0.08 rad in the real world. Considering that the impact hammer has a 4 cm diameter chisel, this level of precision is sufficient for breaking rocks. Notably, this is accomplished by relying only on approximately 68 min of teleoperation data to train and 8 min to evaluate the dynamic model, and without performing any adjustments for a successful policy Sim2Real transfer. A demonstration of policy execution in the real world can be found in https://youtu.be/e-7tDhZ4ZgA.

</details>


### [63] [Failure-Aware RL: Reliable Offline-to-Online Reinforcement Learning with Self-Recovery for Real-World Manipulation](https://arxiv.org/abs/2601.07821)
*Huanyu Li,Kun Lei,Sheng Zang,Kaizhe Hu,Yongyuan Liang,Bo An,Xiaoli Li,Huazhe Xu*

Main category: cs.RO

TL;DR: FARL是一种新兴的强化学习后训练算法，能有效减少机器人在现实世界探索中的失败，同时提高性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决机器人在现实世界探索中不可避免的干预需求失败的问题。

Method: 引入了基于世界模型的安全评论员和离线训练的恢复策略，以防止在线探索中的失败。

Result: FARL在现实世界强化学习后训练中减少了73.1%的干预需求失败，并平均提高了11.3%的性能。

Conclusion: FARL有效减少了干预需求的失败，并在现实世界的强化学习后训练中提高了性能和泛化能力。

Abstract: Post-training algorithms based on deep reinforcement learning can push the limits of robotic models for specific objectives, such as generalizability, accuracy, and robustness. However, Intervention-requiring Failures (IR Failures) (e.g., a robot spilling water or breaking fragile glass) during real-world exploration happen inevitably, hindering the practical deployment of such a paradigm. To tackle this, we introduce Failure-Aware Offline-to-Online Reinforcement Learning (FARL), a new paradigm minimizing failures during real-world reinforcement learning. We create FailureBench, a benchmark that incorporates common failure scenarios requiring human intervention, and propose an algorithm that integrates a world-model-based safety critic and a recovery policy trained offline to prevent failures during online exploration. Extensive simulation and real-world experiments demonstrate the effectiveness of FARL in significantly reducing IR Failures while improving performance and generalization during online reinforcement learning post-training. FARL reduces IR Failures by 73.1% while elevating performance by 11.3% on average during real-world RL post-training. Videos and code are available at https://failure-aware-rl.github.io.

</details>
