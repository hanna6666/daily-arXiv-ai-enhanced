<div id=toc></div>

# Table of Contents

- [cs.HC](#cs.HC) [Total: 19]
- [cs.RO](#cs.RO) [Total: 41]


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [1] [Manim for STEM Education: Visualizing Complex Problems Through Animation](https://arxiv.org/abs/2510.01187)
*Christina Zhang*

Main category: cs.HC

TL;DR: 使用Manim库创造动画课程可以极大提高STEM领域的学习效果，尤其在计算机科学和数学中，同时该库也有更广泛的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 许多STEM概念本身具有复杂性和抽象性，动画能够有效提升学习效果，但制作动画通常费时费力。

Method: 使用Manim库创建动画视频课程，并通过社交媒体分析观众反馈来评估其有效性和可及性。

Result: 展示了Manim如何用于计算机科学和数学的动画视频教学，同时探索了其在其他学科的潜在应用。

Conclusion: Manim库不仅能在计算机科学和数学领域创造有效的动画视频课程，还能扩展应用到其他学科，从而提升学习效果。

Abstract: Many STEM concepts pose significant learning challenges to students due to
their inherent complexity and abstract nature. Visualizing complex problems
through animations can significantly enhance learning outcomes. However, the
creation of animations can be time-consuming and inconvenient. Hence, many
educators illustrate complex concepts by hand on a board or a digital device.
Although static graphics are helpful for understanding, they are less effective
than animations. The free and open-source Python package Manim enables
educators to create visually compelling animations easily. Python's
straightforward syntax, combined with Manim's comprehensive set of built-in
classes and methods, greatly simplifies implementation. This article presents a
series of examples that demonstrate how Manim can be used to create animated
video lessons for a variety of topics in computer science and mathematics. In
addition, it analyzes viewer feedback collected across multiple social media
platforms to evaluate the effectiveness and accessibility of these
visualizations. The article further explores broader potentials of the Manim
Python library by showcasing demonstrations that extend its applications to
subject areas beyond computer science and mathematics.

</details>


### [2] [Beyond Divergence: Characterizing Co-exploration Patterns in Collaborative Design Processes](https://arxiv.org/abs/2510.01188)
*Xinhui Ye,Joep Frens,Jun Hu*

Main category: cs.HC

TL;DR: 本研究通过对设计团队进行的长期观察，探讨了协同探索的重要性及其对设计成功的影响，提出了五种协同探索活动的模式，并为未来的实践者提供了可行的策略。


<details>
  <summary>Details</summary>
Motivation: 探讨协作与动态实践在设计团队中的作用，以增进创造力和设计成果。

Method: 进行了为期五个月的纵向观察研究，涵盖61名学生的16个设计团队，采用每周的日记访谈。

Result: 提出了一个四维框架，识别到五种不同的协同探索活动模式，揭示了协同探索如何在设计过程中的各种活动中出现。

Conclusion: 协同探索促进了设计团队之间的互动和集体智能，反映了设计成功的轨迹。

Abstract: Exploration is crucial in the design process and is known for its essential
role in fostering creativity and enhancing design outcomes. Within design
teams, exploration evolves into co-exploration, a collaborative and dynamic
practice that this study aims to unpack. To investigate this experience, we
conducted a longitudinal observational study with 61 students across 16 design
teams. Over five months of weekly diary-interviews, we uncovered the intricate
dynamics of co-exploration. Our main contribution is a four-dimensional
framework that identifies five distinct patterns of co-exploration activities.
Our findings reveal how co-exploration emerges across various activities
throughout the design process, demonstrating its role in different team
interactions. It fosters a sense of togetherness, keeping design teams
open-minded and engaged. This engagement cultivates collective intelligence,
enabling teams to actively share knowledge, build upon each other's ideas, and
achieve outcomes beyond individual contributions. Our study underscores the
value of co-exploration, suggesting that it reflects the trajectory of design
success and warrants further research. We also provide actionable insights,
equipping future practitioners with strategies to enhance co-exploration in
design collaborations.

</details>


### [3] [An Anthropologist LLM to Elicit Users' Moral Preferences through Role-Play](https://arxiv.org/abs/2510.01189)
*Gianluca De Ninno,Paola Inverardi,Francesca Belotti*

Main category: cs.HC

TL;DR: 本研究结合角色扮演游戏和LLM分析，探索用户道德决策，通过数据分析提高对用户行为预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 旨在通过富有背景和叙事驱动的互动捕捉用户的道德决策，特别是软伦理在法律合规决策中的影响。

Method: 结合沉浸式角色扮演游戏和定制的LLM分析能力，收集参与者在数字隐私领域的伦理情境中的数据。

Result: 通过交叉验证过程的评估，数据的丰富性和解释框架显著增强了模型预测用户行为的能力。

Conclusion: 该研究表明，LLM可以有效地自动化并增强用户道德偏好和决策过程的理解，尤其在软件开发的早期阶段。

Abstract: This study investigates a novel approach to eliciting users' moral
decision-making by combining immersive roleplaying games with LLM analysis
capabilities. Building on the distinction introduced by Floridi between hard
ethics inspiring and shaping laws-and soft ethics-moral preferences guiding
individual behavior within the free space of decisions compliant to laws-we
focus on capturing the latter through contextrich, narrative-driven
interactions. Grounded in anthropological methods, the role-playing game
exposes participants to ethically charged scenarios in the domain of digital
privacy. Data collected during the sessions were interpreted by a customized
LLM ("GPT Anthropologist"). Evaluation through a cross-validation process shows
that both the richness of the data and the interpretive framing significantly
enhance the model's ability to predict user behavior. Results show that LLMs
can be effectively employed to automate and enhance the understanding of user
moral preferences and decision-making process in the early stages of software
development.

</details>


### [4] [An Optical Measurement System for Open-Source Tracking of Jaw Motions](https://arxiv.org/abs/2510.01191)
*Paul-Otto Müller,Sven Suppelt,Mario Kupnik,Oskar von Stryk*

Main category: cs.HC

TL;DR: 本研究开发了一种开源的低成本非侵入性颌部跟踪系统，适用于咀嚼相关疾病研究和外骨骼设计，已在GitHub发布。


<details>
  <summary>Details</summary>
Motivation: 精确跟踪颌部运动学对于诊断影响咀嚼系统的各种肌肉骨骼和神经肌肉疾病至关重要，同时推动相关康复设备（如颌部外骨骼）的研究。

Method: 基于光学运动捕捉技术，建立了一个低成本、精确、非侵入性和生物相容的颌部跟踪系统，涵盖了数据采集、处理、运动学分析、过滤、可视化和数据存储的完整流程。

Result: 系统在四名参与者执行不同颌部运动的实验中表现出了可靠的运动学跟踪，估计精度为$(182 	imes  47) {	extmu}m$和$(0.126 	imes 0.034) {	extdeg}$。

Conclusion: 该开源颌部跟踪系统适用于多种研究与开发背景，尤其是在颌骨外骨骼的集成与设计以及定制诊断协议应用中。

Abstract: Precise tracking of the jaw kinematics is crucial for diagnosing various
musculoskeletal and neuromuscular diseases affecting the masticatory system and
for advancing rehabilitative devices such as jaw exoskeletons, a hardly
explored research field, to treat these disorders. We introduce an open-source,
low-cost, precise, non-invasive, and biocompatible jaw tracking system based on
optical motion capture technology to address the need for accessible and
adaptable research tools. The system encompasses a complete pipeline from data
acquisition, processing, and kinematic analysis to filtering, visualization,
and data storage. We evaluated its performance and feasibility in experiments
with four participants executing various jaw movements. The system demonstrated
reliable kinematic tracking with an estimated precision of $(182 \pm 47)
{\mu}m$ and $(0.126 \pm 0.034) {\deg}$. Therefore, the open-source nature of
the system and its utility comparable to commercial systems make it suitable
for many research and development contexts, especially for applications such as
the integration and design of jaw exoskeletons and customized diagnostic
protocols. The complete system is available at GitHub with the aim of promoting
innovation in temporomandibular disorders research and jaw assistive
technology.

</details>


### [5] [Better Than "Better Than Nothing": Design Strategies for Enculturated Empathetic AI Robot Companions for Older Adults](https://arxiv.org/abs/2510.01192)
*Isabel Pedersen,Andrea Slane*

Main category: cs.HC

TL;DR: 本文强调在老年人机器人互动中引入同理心设计路径的重要性，建议应重视其文化价值与社会互动质量的提升。


<details>
  <summary>Details</summary>
Motivation: 探索机器人在老年护理场景中的接受度与社会互动质量之间的差距，强调同理心在设计中的重要性。

Method: 通过修辞理论分析人类伴侣之间同理心互动的社会文化期望，并研究相关公共研究资料。

Result: 发现现有机器人设计忽视了同理心，提出以同理心关怀词汇为设计基础，以更好支持老年人的独立生活目标。

Conclusion: 在老年人机器人互动中，融入同理心的设计路径是提升人机互动质量的有效策略，需重视文化价值观与同理心特征的结合。

Abstract: The paper asserts that emulating empathy in human-robot interaction is a key
component to achieve satisfying social, trustworthy, and ethical robot
interaction with older people. Following comments from older adult study
participants, the paper identifies a gap. Despite the acceptance of robot care
scenarios, participants expressed the poor quality of the social aspect.
Current human-robot designs, to a certain extent, neglect to include empathy as
a theorized design pathway. Using rhetorical theory, this paper defines the
socio-cultural expectations for convincing empathetic relationships. It
analyzes and then summarizes how society understands, values, and negotiates
empathic interaction between human companions in discursive exchanges, wherein
empathy acts as a societal value system. Using two public research collections
on robots, with one geared specifically to gerontechnology for older people, it
substantiates the lack of attention to empathy in public materials produced by
robot companies. This paper contends that using an empathetic care vocabulary
as a design pathway is a productive underlying foundation for designing
humanoid social robots that aim to support older people's goals of
aging-in-place. It argues that the integration of affective AI into the
sociotechnical assemblages of human-socially assistive robot interaction ought
to be scrutinized to ensure it is based on genuine cultural values involving
empathetic qualities.

</details>


### [6] [How can AI agents support journalists' work? An experiment with designing an LLM-driven intelligent reporting system](https://arxiv.org/abs/2510.01193)
*Vasileios Maltezos,Roman Kyrychenko,Aleksi Knuutila*

Main category: cs.HC

TL;DR: 这项研究探讨了代理型大型语言模型如何提升新闻工作流程，并讨论了未来人工智能工具在新闻行业的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 研究旨在理解大型语言模型在提升新闻采集、分析和传播中的作用，同时识别它们在新闻编辑室集成中面临的复杂挑战。

Method: 通过对记者的访谈和开发基于大型语言模型的自动化工具，深入探讨了代理型大型语言模型如何支持新闻工作流程。

Result: 文章提供了记者专用的自动聚合和总结系统的技术概述和评估，并讨论了满足和未满足的记者需求。

Conclusion: 这项研究展示了代理能力大型语言模型在支持新闻工作流程方面的潜力，并展望了未来人工智能工具在新闻报道中的应用方向。

Abstract: The integration of artificial intelligence into journalistic practices
represents a transformative shift in how news is gathered, analyzed, and
disseminated. Large language models (LLMs), particularly those with agentic
capabilities, offer unprecedented opportunities for enhancing journalistic
workflows while simultaneously presenting complex challenges for newsroom
integration. This research explores how agentic LLMs can support journalists'
workflows, based on insights from journalist interviews and from the
development of an LLM-based automation tool performing information filtering,
summarization, and reporting. The paper details automated aggregation and
summarization systems for journalists, presents a technical overview and
evaluation of a user-centric LLM-driven reporting system (TeleFlash), and
discusses both addressed and unmet journalist needs, with an outlook on future
directions for AI-driven tools in journalism.

</details>


### [7] [Development and Evaluation of an AI-Driven Telemedicine System for Prenatal Healthcare](https://arxiv.org/abs/2510.01194)
*Juan Barrientos,Michaelle Pérez,Douglas González,Favio Reyna,Julio Fajardo,Andrea Lara*

Main category: cs.HC

TL;DR: 该研究开发了一种AI系统，通过盲扫协议帮助助产士获取胎儿图像，可提升低资源地区的产前影像获取能力。


<details>
  <summary>Details</summary>
Motivation: 在低收入国家和农村地区，获得产科超声的机会有限，急需一种有效的工具帮助医疗工作者。

Method: 开发了一个人机结合的人工智能系统，辅助手访者使用盲扫协议获取胎儿影像，并结合分类模型和网络平台进行专家的异步审核。

Result: 系统在分析由经过简单培训的助产士使用低成本POCUS设备拍摄的盲扫视频时，表现出良好，能够有效识别标准胎儿平面。

Conclusion: 该AI系统在识别非专家的胎儿平面方面表现出良好的效果，能够扩大缺乏资源地区的产前影像获取。

Abstract: Access to obstetric ultrasound is often limited in low-resource settings,
particularly in rural areas of low- and middle-income countries. This work
proposes a human-in-the-loop artificial intelligence (AI) system designed to
assist midwives in acquiring diagnostically relevant fetal images using blind
sweep protocols. The system incorporates a classification model along with a
web-based platform for asynchronous specialist reviews. By identifying key
frames in blind sweep studies, the AI system allows specialists to concentrate
on interpretation rather than having to review entire videos. To evaluate its
performance, blind sweep videos captured by a small group of soft-trained
midwives using a low-cost Point-of-Care Ultrasound (POCUS) device were
analyzed. The system demonstrated promising results in identifying standard
fetal planes from sweeps made by non-experts. A field evaluation indicated good
usability and a low cognitive workload, suggesting that it has the potential to
expand access to prenatal imaging in underserved regions.

</details>


### [8] [LegiScout: A Visual Tool for Understanding Complex Legislation](https://arxiv.org/abs/2510.01195)
*Aadarsh Rajiv,Klaus Mueller*

Main category: cs.HC

TL;DR: LegiScout 是一种交互式可视化工具，通过动态图形帮助用户理解复杂的立法框架，如 ACA.


<details>
  <summary>Details</summary>
Motivation: 改善对复杂立法框架（如 ACA）的理解，解决现有静态图表难以解析的问题。

Method: 通过数据提取、自然语言处理和计算机视觉技术，将静态政策图转化为动态的力导向图。

Result: LegiScout 使政策制定者、分析师和公众能够更深入地探索法规和政策的复杂性。

Conclusion: LegiScout 提供了一种新的交互式可视化系统，能有效提升对复杂立法框架的理解。

Abstract: Modern legislative frameworks, such as the Affordable Care Act (ACA), often
involve complex webs of agencies, mandates, and interdependencies. Government
issued charts attempt to depict these structures but are typically static,
dense, and difficult to interpret - even for experts. We introduce LegiScout,
an interactive visualization system that transforms static policy diagrams into
dynamic, force-directed graphs, enhancing comprehension while preserving
essential relationships. By integrating data extraction, natural language
processing, and computer vision techniques, LegiScout supports deeper
exploration of not only the ACA but also a wide range of legislative and
regulatory frameworks. Our approach enables stakeholders - policymakers,
analysts, and the public - to navigate and understand the complexity inherent
in modern law.

</details>


### [9] [Theory is Shapes](https://arxiv.org/abs/2510.01382)
*Matthew Varona,Maryam Hedayati,Matthew Kay,Carolina Nobre*

Main category: cs.HC

TL;DR: 本研究探讨了使用更具表现力的形状来可视化理论的重要性，认为理论本质上与形状息息相关。


<details>
  <summary>Details</summary>
Motivation: 探讨现有的方法如何限制了理论可视化的创造性和表现力。

Method: 探索使用更具表现力的形状来可视化理论。

Result: 通过反思图形制作在理论实践中的生成作用，提出更多样化的图形可以带来不同的理解和解释。

Conclusion: 理论实际上就是形状。

Abstract: "Theory figures" are a staple of theoretical visualization research. Common
shapes such as Cartesian planes and flowcharts can be used not only to explain
conceptual contributions, but to think through and refine the contribution
itself. Yet, theory figures tend to be limited to a set of standard shapes,
limiting the creative and expressive potential of visualization theory. In this
work, we explore how the shapes used in theory figures afford different
understandings and explanations of their underlying phenomena. We speculate on
the value of visualizing theories using more expressive configurations, such as
icebergs, horseshoes, M\"obius strips, and BLT sandwiches. By reflecting on
figure-making's generative role in the practice of theorizing, we conclude that
theory is, in fact, shapes.

</details>


### [10] [The Command Line GUIde: Graphical Interfaces from Man Pages via AI](https://arxiv.org/abs/2510.01453)
*Saketh Ram Kasibatla,Kiran Medleri Hiremath,Raven Rothkopf,Sorin Lerner,Haijun Xia,Brian Hempel*

Main category: cs.HC

TL;DR: 本研究通过AI将命令行工具的文档转化为图形界面规范，推出GUIde系统，显著提高了命令行的可用性和用户体验。


<details>
  <summary>Details</summary>
Motivation: 命令行虽然功能强大，但对用户而言难以记忆和使用，因此需要优化其可用性，以适应现代用户的需求。

Method: 利用AI将命令行工具的文档（如手册页）自动转换为图形界面规范。

Result: GUIde能够为用户的真实世界命令行任务提供全面的图形界面，有效提升了用户体验。

Conclusion: GUIde通过将命令行工具的文档转换为界面规范，有效为用户提供了图形化的命令选项，从而提升了命令行的可用性。

Abstract: Although birthed in the era of teletypes, the command line shell survived the
graphical interface revolution of the 1980's and lives on in modern desktop
operating systems. The command line provides access to powerful functionality
not otherwise exposed on the computer, but requires users to recall textual
syntax and carefully scour documentation. In contrast, graphical interfaces let
users organically discover and invoke possible actions through widgets and
menus. To better expose the power of the command line, we demonstrate a
mechanism for automatically creating graphical interfaces for command line
tools by translating their documentation (in the form of man pages) into
interface specifications via AI. Using these specifications, our user-facing
system, called GUIde, presents the command options to the user graphically. We
evaluate the generated interfaces on a corpus of commands to show to what
degree GUIde offers thorough graphical interfaces for users' real-world command
line tasks.

</details>


### [11] [From keywords to semantics: Perceptions of large language models in data discovery](https://arxiv.org/abs/2510.01473)
*Maura E Halstead,Mark A. Green,Caroline Jay,Richard Kingston,David Topping,Alexander Singleton*

Main category: cs.HC

TL;DR: 虽然LLMs在数据发现中潜在有益，但研究人员对其接受度受阻，透明度特征可能有助于提升接受度。


<details>
  <summary>Details</summary>
Motivation: 当前的数据发现方法依赖于关键词匹配，这要求研究人员了解先前使用的确切措辞，因此很难找到相关数据。

Method: 通过对27名研究人员的焦点小组进行研究，探讨其对LLMs在数据发现中的看法。

Result: 研究表明，潜在的好处不足以促使研究人员放弃现有技术，开发者可以利用本模型设计出能够提高研究人员对LLMs接受度的特征。

Conclusion: 研究人员对LLMs在数据发现中的接受度受到障碍制约，但透明度特征可能有助于克服这些障碍。

Abstract: Current approaches to data discovery match keywords between metadata and
queries. This matching requires researchers to know the exact wording that
other researchers previously used, creating a challenging process that could
lead to missing relevant data. Large Language Models (LLMs) could enhance data
discovery by removing this requirement and allowing researchers to ask
questions with natural language. However, we do not currently know if
researchers would accept LLMs for data discovery. Using a human-centered
artificial intelligence (HCAI) focus, we ran focus groups (N = 27) to
understand researchers' perspectives towards LLMs for data discovery. Our
conceptual model shows that the potential benefits are not enough for
researchers to use LLMs instead of current technology. Barriers prevent
researchers from fully accepting LLMs, but features around transparency could
overcome them. Using our model will allow developers to incorporate features
that result in an increased acceptance of LLMs for data discovery.

</details>


### [12] [Dialogues with AI Reduce Beliefs in Misinformation but Build No Lasting Discernment Skills](https://arxiv.org/abs/2510.01537)
*Anku Rani,Valdemar Danry,Paul Pu Liang,Andrew B. Lippman,Pattie Maes*

Main category: cs.HC

TL;DR: 本研究表明，AI可能在短期内提高假信息识别能力，但长时间使用后会削弱这一能力。


<details>
  <summary>Details</summary>
Motivation: 鉴于假信息（包括日益逼真的AI生成新闻）的日益普遍性，迫切需要训练人们更好地评估和检测这些信息。

Method: 进行为期一个月的研究，67名参与者对新闻标题-图片组合进行分类，并与AI系统讨论他们的评估，随后进行不受帮助的评估以测量准确性。

Result: AI的帮助在立即的会话中提高了参与者的表现，但在第4周时，他们对新项目的独立表现显著下降。

Conclusion: 尽管AI可以在短期内帮助提高对假信息的识别，但从长远来看，它会削弱人们的判断能力。

Abstract: Given the growing prevalence of fake information, including increasingly
realistic AI-generated news, there is an urgent need to train people to better
evaluate and detect misinformation. While interactions with AI have been shown
to durably reduce people's beliefs in false information, it is unclear whether
these interactions also teach people the skills to discern false information
themselves. We conducted a month-long study where 67 participants classified
news headline-image pairs as real or fake, discussed their assessments with an
AI system, followed by an unassisted evaluation of unseen news items to measure
accuracy before, during, and after AI assistance. While AI assistance produced
immediate improvements during AI-assisted sessions (+21\% average),
participants' unassisted performance on new items declined significantly by
week 4 (-15.3\%). These results indicate that while AI may help immediately, it
ultimately degrades long-term misinformation detection abilities.

</details>


### [13] [TimeGazer: Temporal Modeling of Predictive Gaze Stabilization for AR Interaction](https://arxiv.org/abs/2510.01561)
*Yaozheng Xia,Zaiping Zhu,Bo Pang,Shaorong Wang,Sheng Li*

Main category: cs.HC

TL;DR: 本文提出了TimeGazer，一种通过时间建模的预测凝视稳定化方法，显著提升了增强现实中的交互性能。


<details>
  <summary>Details</summary>
Motivation: 解决在沉浸式增强现实环境中，尤其是在任务导向的视觉行为中，凝视顺序表现出不规则分散和系统性偏差的问题。

Method: 将凝视稳定性重新构建为序列到序列的时间回归问题，通过历史凝视动态预测目标凝视阶段的理想化凝视轨迹。

Result: 实验结果显示，TimeGazer在提高交互准确性和降低完成时间方面具有显著效果。

Conclusion: TimeGazer显著提高了交互准确性并减少了完成时间，展示了其在增强现实（AR）交互中的应用潜力。

Abstract: Gaze stabilization is critical for enabling fluid, accurate, and efficient
interaction in immersive augmented reality (AR) environments, particularly
during task-oriented visual behaviors. However, fixation sequences captured in
active gaze tasks often exhibit irregular dispersion and systematic deviations
from target locations, a variability primarily caused by the combined effects
of human oculomotor physiology, insufficient AR headset tracking and
calibration accuracy, and environmental disturbances, undermining interaction
performance and visual engagement. To address this issue, we propose TimeGazer,
which reformulates gaze stabilization as a sequence-to-sequence temporal
regression problem, predicting idealized fixation trajectories for the
target-fixation phase from historical gaze dynamics in the search phase. We
present a synthetic data generation and blending strategy that produces
spatially concentrated, target-centered fixation references aligned with task
objectives, substantially enriching the training space and enhancing model
generalization. We train and evaluate TimeGazer on a hybrid dataset of real and
augmented gaze sequences collected via Microsoft HoloLens 2 from 54
participants across multiple prediction horizons. Through the user study,
statistical results demonstrate that TimeGazer significantly improves
interaction accuracy and reduces completion time, confirming that temporal
modeling of predictive gaze stabilization can strengthen attentional
consistency and responsiveness in task-driven AR interaction. These findings
highlight the broader potential of TimeGazer for advancing adaptive gaze-based
interfaces and temporal modeling research in immersive systems.

</details>


### [14] [Towards Human-Centered RegTech: Unpacking Professionals' Strategies and Needs for Using LLMs Safely](https://arxiv.org/abs/2510.01638)
*Siying Hu,Yaxing Yao,Zhicong Lu*

Main category: cs.HC

TL;DR: 本研究探讨了大型语言模型在高风险行业中的合规风险，发现专家们担忧敏感信息和模型输出质量，并提出应对策略，但缺乏有效指导，强调了建设合规驱动的自然语言处理系统的必要性。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的广泛应用，了解其对专业领域的合规风险影响是迫切需要的。

Method: 研究采用半结构化访谈法，对24名来自法律、医疗和金融等行业的高技能知识工作者进行了调查。

Result: 研究发现受访专家普遍担忧敏感信息泄露、知识产权侵权以及对模型输出质量的不确定性，并采取了不同的应对策略，但由于缺乏具体的合规指导和培训，这些努力的有效性有限。

Conclusion: 该研究揭示了大型语言模型在高风险专业领域应用中存在的合规风险，并强调了建立以人为本、合规驱动的自然语言处理系统的必要性。

Abstract: Large Language Models are profoundly changing work patterns in high-risk
professional domains, yet their application also introduces severe and
underexplored compliance risks. To investigate this issue, we conducted
semi-structured interviews with 24 highly-skilled knowledge workers from
industries such as law, healthcare, and finance. The study found that these
experts are commonly concerned about sensitive information leakage,
intellectual property infringement, and uncertainty regarding the quality of
model outputs. In response, they spontaneously adopt various mitigation
strategies, such as actively distorting input data and limiting the details in
their prompts. However, the effectiveness of these spontaneous efforts is
limited due to a lack of specific compliance guidance and training for Large
Language Models. Our research reveals a significant gap between current NLP
tools and the actual compliance needs of experts. This paper positions these
valuable empirical findings as foundational work for building the next
generation of Human-Centered, Compliance-Driven Natural Language Processing for
Regulatory Technology (RegTech), providing a critical human-centered
perspective and design requirements for engineering NLP systems that can
proactively support expert compliance workflows.

</details>


### [15] [Who is responsible? Social Identity, Robot Errors and Blame Attribution](https://arxiv.org/abs/2510.01862)
*Samantha Stedtler,Marianna Leventi*

Main category: cs.HC

TL;DR: 论文探讨机器人如何在社会互动中引发刻板印象和责任归属问题，并呼吁对此进行深入研究。


<details>
  <summary>Details</summary>
Motivation: 传统责备实践无法捕捉道德体验的复杂性，忽视了权力动态和歧视性社会实践。

Method: 理论分析与实证研究结合，探讨人机交互对人际交互的影响。

Result: 机器人可能加剧对特定社会群体的刻板印象，导致不成比例的责任归属，使弱势群体受到更多指责。

Conclusion: 需要更多研究来了解机器人刻板印象和责任归属的后果，并在社交机器人设计阶段考虑伦理方面。

Abstract: This paper argues that conventional blame practices fall short of capturing
the complexity of moral experiences, neglecting power dynamics and
discriminatory social practices. It is evident that robots, embodying roles
linked to specific social groups, pose a risk of reinforcing stereotypes of how
these groups behave or should behave, so they set a normative and descriptive
standard. In addition, we argue that faulty robots might create expectations of
who is supposed to compensate and repair after their errors, where social
groups that are already disadvantaged might be blamed disproportionately if
they do not act according to their ascribed roles. This theoretical and
empirical gap becomes even more urgent to address as there have been
indications of potential carryover effects from Human-Robot Interactions (HRI)
to Human-Human Interactions (HHI). We therefore urge roboticists and designers
to stay in an ongoing conversation about how social traits are conceptualised
and implemented in this technology. We also argue that one solution could be to
'embrace the glitch' and to focus on constructively disrupting practices
instead of prioritizing efficiency and smoothness of interaction above
everything else. Apart from considering ethical aspects in the design phase of
social robots, we see our analysis as a call for more research on the
consequences of robot stereotyping and blame attribution.

</details>


### [16] [Komitee Equal Shares: Choosing Together as Voters and as Groups with a Co-designed Virtual Budget Algorithm](https://arxiv.org/abs/2510.02040)
*Joshua C. Yang,Noemi Scheurer*

Main category: cs.HC

TL;DR: 提出了一种新型虚拟预算分配框架，增强了公民在参与式预算中的角色，提供了公平和可追溯的资金分配方式。


<details>
  <summary>Details</summary>
Motivation: 公共资金过程需要公平、公正，且参与者能够理解的结果。

Method: 提出了一种名为Komitee Equal Shares的虚拟预算分配框架，通过点数投票和小组评估提案，结合两个信号进行预算分配。

Result: 在瑞士温特图尔的2025年Kultur Komitee中部署了该框架，验证其在实际应用中的有效性和可操作性。

Conclusion: 该框架提供了一个可扩展的模型，使公民能够在参与式预算和拨款中同时扮演投票者和评估者，保障了公平和透明性。

Abstract: Public funding processes demand fairness, learning, and outcomes that
participants can understand. We introduce Komitee Equal Shares, a priceable
virtual-budget allocation framework that integrates two signals: in voter mode,
participants cast point votes; in evaluator mode, small groups assess proposals
against collectively defined impact fields. The framework extends the Method of
Equal Shares by translating both signals into virtual spending power and
producing voting receipts. We deployed the framework in the 2025 Kultur Komitee
in Winterthur, Switzerland. Our contributions are: (1) a clear separation of
decision modes, addressing a gap in social choice that typically treats
participatory budgeting as preference aggregation while citizens also see
themselves as evaluators; and (2) the design of voting receipts that
operationalise priceability into participant-facing explanations, making
proportional allocations legible and traceable. The framework generalises to
participatory grant-making and budgeting, offering a model where citizens act
as voters and evaluators within one proportional, explainable allocation.

</details>


### [17] [Human-Robo-advisor collaboration in decision-making: Evidence from a multiphase mixed methods experimental study](https://arxiv.org/abs/2510.02153)
*Hasan Mahmud,Najmul Islam,Satish Krishnan*

Main category: cs.HC

TL;DR: 本研究探讨了用户对机器人顾问的理解及其建议整合，发现不同用户类型和RA角色影响依赖性，并提供设计改进建议。


<details>
  <summary>Details</summary>
Motivation: 尽管机器人顾问作为人类财务顾问的成本效益和抗偏见的替代选项，但其采用率仍然有限，因此研究个体对RA角色的理解和建议整合。

Method: 采用多阶段混合方法设计，结合行为实验、主题分析和后续的定量测试。

Result: 研究发现人们倾向于依赖RA，而这种依赖受到RA绩效信息和建议框架（收益或损失）的影响。同时，揭示了RA在决策中的三种角色和四种用户类型，以及接受的促进因素和抑制因素。

Conclusion: 本研究深入探讨了用户如何理解和整合机器人顾问（RA）的建议，为设计更可信和适应性强的RA系统提供了可行的见解。

Abstract: Robo-advisors (RAs) are cost-effective, bias-resistant alternatives to human
financial advisors, yet adoption remains limited. While prior research has
examined user interactions with RAs, less is known about how individuals
interpret RA roles and integrate their advice into decision-making. To address
this gap, this study employs a multiphase mixed methods design integrating a
behavioral experiment (N = 334), thematic analysis, and follow-up quantitative
testing. Findings suggest that people tend to rely on RAs, with reliance shaped
by information about RA performance and the framing of advice as gains or
losses. Thematic analysis reveals three RA roles in decision-making and four
user types, each reflecting distinct patterns of advice integration. In
addition, a 2 x 2 typology categorizes antecedents of acceptance into enablers
and inhibitors at both the individual and algorithmic levels. By combining
behavioral, interpretive, and confirmatory evidence, this study advances
understanding of human-RA collaboration and provides actionable insights for
designing more trustworthy and adaptive RA systems.

</details>


### [18] [Agentic Reasoning and Refinement through Semantic Interaction](https://arxiv.org/abs/2510.02157)
*Xuxin Tang,Rehema Abulikemu,Eric Krokos,Kirsten Whitley,Xuan Wang,Chris North*

Main category: cs.HC

TL;DR: VIS-ReAct 是一种改进报告编写的框架，通过两个代理提升了大型语言模型在报告精细化过程中的表现。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在精细化过程中难以准确处理顺序语义互动的问题。

Method: 提出 VIS-ReAct 框架，采用两个代理：分析代理理解新的语义互动并规划精细化，精细化代理依据计划更新报告。

Result: VIS-ReAct 显著提高了目标精细化、语义准确性和推理透明度，能够更好地处理不同类型和粒度的互动。

Conclusion: VIS-ReAct 在针对报告的精细化方面优于其他基准方法，并提升了人类与大型语言模型的透明协作能力。

Abstract: Sensemaking report writing often requires multiple refinements in the
iterative process. While Large Language Models (LLMs) have shown promise in
generating initial reports based on human visual workspace representations,
they struggle to precisely incorporate sequential semantic interactions during
the refinement process. We introduce VIS-ReAct, a framework that reasons about
newly-added semantic interactions in visual workspaces to steer the LLM for
report refinement.
  VIS-ReAct is a two-agent framework: a primary LLM analysis agent interprets
new semantic interactions to infer user intentions and generate refinement
planning, followed by an LLM refinement agent that updates reports accordingly.
Through case study, VIS-ReAct outperforms baseline and VIS-ReAct (without LLM
analysis) on targeted refinement, semantic fidelity, and transparent inference.
Results demonstrate that VIS-ReAct better handles various interaction types and
granularities while enhancing the transparency of human-LLM collaboration.

</details>


### [19] [EvolveCaptions: Empowering DHH Users Through Real-Time Collaborative Captioning](https://arxiv.org/abs/2510.02181)
*Liang-Yuan Wu,Dhruv Jain*

Main category: cs.HC

TL;DR: EvolveCaptions是一个实时协作的ASR自适应系统，通过听力参与者的实时纠正和短时间录音，显著提升了聋人和听障人士的语音识别准确性。


<details>
  <summary>Details</summary>
Motivation: 自动语音识别系统在转录聋人和听障人士的语言时常常不准确，现有个性化方法需要大量预录数据，对用户适应性要求高。

Method: 让听力用户在实时对话中纠正ASR错误，基于这些纠正生成短暂的，语音上具有针对性的提示供DHH用户录音，从而微调ASR模型。

Result: 在一项包含12名DHH用户和6名听力用户的研究中，EvolveCaptions在使用仅五分钟录音的情况下，在一小时内降低了所有DHH用户的单词错误率（WER）。

Conclusion: EvolveCaptions展示了实时协作的ASR自适应系统在促进更平等沟通方面的潜力。

Abstract: Automatic Speech Recognition (ASR) systems often fail to accurately
transcribe speech from Deaf and Hard of Hearing (DHH) individuals, especially
during real-time conversations. Existing personalization approaches typically
require extensive pre-recorded data and place the burden of adaptation on the
DHH speaker. We present EvolveCaptions, a real-time, collaborative ASR
adaptation system that supports in-situ personalization with minimal effort.
Hearing participants correct ASR errors during live conversations. Based on
these corrections, the system generates short, phonetically targeted prompts
for the DHH speaker to record, which are then used to fine-tune the ASR model.
In a study with 12 DHH and six hearing participants, EvolveCaptions reduced
Word Error Rate (WER) across all DHH users within one hour of use, using only
five minutes of recording time on average. Participants described the system as
intuitive, low-effort, and well-integrated into communication. These findings
demonstrate the promise of collaborative, real-time ASR adaptation for more
equitable communication.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [20] [Kilometer-Scale GNSS-Denied UAV Navigation via Heightmap Gradients: A Winning System from the SPRIN-D Challenge](https://arxiv.org/abs/2510.01348)
*Michal Werner,David Čapek,Tomáš Musil,Ondřej Franěk,Tomáš Báča,Martin Saska*

Main category: cs.RO

TL;DR: 本研究提出了一种全新的ONBOARD系统，成功减少了GNSS受限环境下无人机长途飞行的漂移，提供了对无人机自主性的实用见解。


<details>
  <summary>Details</summary>
Motivation: 在GNSS受限环境中，无人机的长途飞行具有挑战性，尤其是漂移问题和缺乏回环闭合。

Method: 整合感知、地图构建、规划和控制，使用轻量级漂移校正方法，通过梯度模板匹配将LiDAR生成的局部高度图与之前的地理数据高度图进行匹配，并在聚类粒子滤波器中融合证据与里程计数据。

Result: 系统在竞争中成功执行了公里级的飞行任务，涵盖城市、森林和开阔地带，相较于原始里程计数据显著减少漂移，同时在仅使用CPU的硬件上实时运行。

Conclusion: 该系统在GNSS受限环境中成功执行了长期无人机自主飞行，显著减少了漂移。

Abstract: Reliable long-range flight of unmanned aerial vehicles (UAVs) in GNSS-denied
environments is challenging: integrating odometry leads to drift, loop closures
are unavailable in previously unseen areas and embedded platforms provide
limited computational power. We present a fully onboard UAV system developed
for the SPRIN-D Funke Fully Autonomous Flight Challenge, which required 9 km
long-range waypoint navigation below 25 m AGL (Above Ground Level) without GNSS
or prior dense mapping. The system integrates perception, mapping, planning,
and control with a lightweight drift-correction method that matches
LiDAR-derived local heightmaps to a prior geo-data heightmap via
gradient-template matching and fuses the evidence with odometry in a clustered
particle filter. Deployed during the competition, the system executed
kilometer-scale flights across urban, forest, and open-field terrain and
reduced drift substantially relative to raw odometry, while running in real
time on CPU-only hardware. We describe the system architecture, the
localization pipeline, and the competition evaluation, and we report practical
insights from field deployment that inform the design of GNSS-denied UAV
autonomy.

</details>


### [21] [Safe Motion Planning and Control Using Predictive and Adaptive Barrier Methods for Autonomous Surface Vessels](https://arxiv.org/abs/2510.01357)
*Alejandro Gonzalez-Garcia,Wei Xiao,Wei Wang,Alejandro Astudillo,Wilm Decré,Jan Swevers,Carlo Ratti,Daniela Rus*

Main category: cs.RO

TL;DR: 本文提出了一种结合MPC和CBFs的安全运动规划策略，通过调整障碍物膨胀半径，有效降低了控制器的保守性，增强了自主船舶在狭窄水域中的导航能力。


<details>
  <summary>Details</summary>
Motivation: 自主船舶在狭窄内陆水道等挑战性空间中的安全运动规划至关重要，现有方法通常计算复杂或过于保守。

Method: 结合模型预测控制（MPC）和控制障碍函数（CBFs），使用时变膨胀椭圆障碍物表示，并根据船舶与障碍物的相对位置和姿态调整膨胀半径。

Result: 仿真和实际测试表明，所提出的策略使全驱动自主机器人船舶能够在确保安全的同时，实时通过狭窄空间并解决潜在死锁问题。

Conclusion: 提出的安全运动规划策略有效降低了控制器的保守性，使自主船舶能够在狭窄水域中实时安全导航。

Abstract: Safe motion planning is essential for autonomous vessel operations,
especially in challenging spaces such as narrow inland waterways. However,
conventional motion planning approaches are often computationally intensive or
overly conservative. This paper proposes a safe motion planning strategy
combining Model Predictive Control (MPC) and Control Barrier Functions (CBFs).
We introduce a time-varying inflated ellipse obstacle representation, where the
inflation radius is adjusted depending on the relative position and attitude
between the vessel and the obstacle. The proposed adaptive inflation reduces
the conservativeness of the controller compared to traditional fixed-ellipsoid
obstacle formulations. The MPC solution provides an approximate motion plan,
and high-order CBFs ensure the vessel's safety using the varying inflation
radius. Simulation and real-world experiments demonstrate that the proposed
strategy enables the fully-actuated autonomous robot vessel to navigate through
narrow spaces in real time and resolve potential deadlocks, all while ensuring
safety.

</details>


### [22] [A Stochastic Framework for Continuous-Time State Estimation of Continuum Robots](https://arxiv.org/abs/2510.01381)
*Spencer Teetaert,Sven Lilge,Jessica Burgner-Kahrs,Timothy D. Barfoot*

Main category: cs.RO

TL;DR: 提出了一种新的连续时间随机状态估计框架，能够实时适应未建模扰动，并在真实系统中验证。


<details>
  <summary>Details</summary>
Motivation: 现有的连续机器人状态估计技术面临复杂的动态模型和简化形状逼近的问题，影响了对未建模扰动的适应性。

Method: 基于连续时间动力学和高频传感器，结合潜在的高斯噪声模型进行状态估计。

Result: 通过简单的机器人模型和高频率传感器，实现了对机器人姿态、速度和应变的均值和协方差估计，并且支持时空的连续插值。

Conclusion: 本研究提出了一种针对连续机器人状态估计的框架，能够有效应对未建模的外部扰动和数据丢失。

Abstract: State estimation techniques for continuum robots (CRs) typically involve
using computationally complex dynamic models, simplistic shape approximations,
or are limited to quasi-static methods. These limitations can be sensitive to
unmodelled disturbances acting on the robot. Inspired by a factor-graph
optimization paradigm, this work introduces a continuous-time stochastic state
estimation framework for continuum robots. We introduce factors based on
continuous-time kinematics that are corrupted by a white noise Gaussian process
(GP). By using a simple robot model paired with high-rate sensing, we show
adaptability to unmodelled external forces and data dropout. The result
contains an estimate of the mean and covariance for the robot's pose, velocity,
and strain, each of which can be interpolated continuously in time or space.
This same interpolation scheme can be used during estimation, allowing for
inclusion of measurements on states that are not explicitly estimated. Our
method's inherent sparsity leads to a linear solve complexity with respect to
time and interpolation queries in constant time. We demonstrate our method on a
CR with gyroscope and pose sensors, highlighting its versatility in real-world
systems.

</details>


### [23] [VENTURA: Adapting Image Diffusion Models for Unified Task Conditioned Navigation](https://arxiv.org/abs/2510.01388)
*Arthur Zhang,Xiangyun Meng,Luca Calliari,Dong-Ki Kim,Shayegan Omidshafiei,Joydeep Biswas,Ali Agha,Amirreza Shaban*

Main category: cs.RO

TL;DR: VENTURA是一种视觉-语言导航系统，通过微调图像扩散模型生成路径掩码，显著提升机器人在多样化任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 机器人需适应多样的人类指令并在非结构化环境中安全操作，而现有的视觉-语言模型的行动空间及预训练目标差异限制了其在机器人任务中的可转移性。

Method: 通过微调互联网预训练的图像扩散模型，使用路径掩码生成视觉计划，并结合轻量级行为克隆策略实现可执行轨迹。

Result: VENTURA生成的视觉计划有效增强机器人在多种任务中的执行表现，并在面临不同任务组合时展现出紧凑的组合能力。

Conclusion: VENTURA在真实世界评估中超过了当前最先进的基础模型，在目标到达、避障和地形偏好任务上成功率提高了33%，碰撞减少了54%。

Abstract: Robots must adapt to diverse human instructions and operate safely in
unstructured, open-world environments. Recent Vision-Language models (VLMs)
offer strong priors for grounding language and perception, but remain difficult
to steer for navigation due to differences in action spaces and pretraining
objectives that hamper transferability to robotics tasks. Towards addressing
this, we introduce VENTURA, a vision-language navigation system that finetunes
internet-pretrained image diffusion models for path planning. Instead of
directly predicting low-level actions, VENTURA generates a path mask (i.e. a
visual plan) in image space that captures fine-grained, context-aware
navigation behaviors. A lightweight behavior-cloning policy grounds these
visual plans into executable trajectories, yielding an interface that follows
natural language instructions to generate diverse robot behaviors. To scale
training, we supervise on path masks derived from self-supervised tracking
models paired with VLM-augmented captions, avoiding manual pixel-level
annotation or highly engineered data collection setups. In extensive real-world
evaluations, VENTURA outperforms state-of-the-art foundation model baselines on
object reaching, obstacle avoidance, and terrain preference tasks, improving
success rates by 33% and reducing collisions by 54% across both seen and unseen
scenarios. Notably, we find that VENTURA generalizes to unseen combinations of
distinct tasks, revealing emergent compositional capabilities. Videos, code,
and additional materials: https://venturapath.github.io

</details>


### [24] [INSIGHT: INference-time Sequence Introspection for Generating Help Triggers in Vision-Language-Action Models](https://arxiv.org/abs/2510.01389)
*Ulas Berk Karli,Ziyao Shangguan,Tesca FItzgerald*

Main category: cs.RO

TL;DR: 本文提出 INSIGHT 框架，通过不确定性感知改进 VLA 模型，实现有效的自我监控和错误纠正。


<details>
  <summary>Details</summary>
Motivation: 尽管现有 VLA 模型具有较强的泛化能力，但缺乏预判失败和请求人类监督的内省机制。

Method: 采用 $	ext{pi}_0$-FAST 模型，提取每个 token 的熵、对数概率和 Dirichlet 基于的 aleatoric 及 epistemic 不确定性估计，并训练紧凑的 transformer 分类器进行帮助触发映射。

Result: 强标签辅助模型捕捉细粒度的不确定性动态以实现可靠的帮助检测，而弱标签虽然存在噪声但在训练和评估一致时仍能支持竞争性的内省。

Conclusion: 通过对 VLA 模型的不确定性感知进行系统评估，本文开启了主动学习和实时错误缓解的未来方向。

Abstract: Recent Vision-Language-Action (VLA) models show strong generalization
capabilities, yet they lack introspective mechanisms for anticipating failures
and requesting help from a human supervisor. We present \textbf{INSIGHT}, a
learning framework for leveraging token-level uncertainty signals to predict
when a VLA should request help. Using $\pi_0$-FAST as the underlying model, we
extract per-token \emph{entropy}, \emph{log-probability}, and Dirichlet-based
estimates of \emph{aleatoric and epistemic uncertainty}, and train compact
transformer classifiers to map these sequences to help triggers. We explore
supervision regimes for strong or weak supervision, and extensively compare
them across in-distribution and out-of-distribution tasks. Our results show a
trade-off: strong labels enable models to capture fine-grained uncertainty
dynamics for reliable help detection, while weak labels, though noisier, still
support competitive introspection when training and evaluation are aligned,
offering a scalable path when dense annotation is impractical. Crucially, we
find that modeling the temporal evolution of token-level uncertainty signals
with transformers provides far greater predictive power than static
sequence-level scores. This study provides the first systematic evaluation of
uncertainty-based introspection in VLAs, opening future avenues for active
learning and for real-time error mitigation through selective human
intervention.

</details>


### [25] [Beyond Collision Cones: Dynamic Obstacle Avoidance for Nonholonomic Robots via Dynamic Parabolic Control Barrier Functions](https://arxiv.org/abs/2510.01402)
*Hun Kuk Park,Taekyung Kim,Dimitra Panagou*

Main category: cs.RO

TL;DR: 本研究提出动态抛物线控制屏障函数（DPCBF），有效应对复杂动态环境中的导航挑战，提升安全性与可行性。


<details>
  <summary>Details</summary>
Motivation: 在复杂动态环境中应用控制屏障函数（CBFs）确保自主系统的安全性，克服现有方法的保守性。

Method: 动态抛物线控制屏障函数（DPCBF），通过动态调整抛物线的顶点和曲率来定义安全集。

Result: DPCBF在含有多达100个动态障碍物的场景中，显著提升了导航成功率和QP可行性。

Conclusion: 提出的动态抛物线控制屏障函数显著提高了自主系统在拥挤动态环境中的导航成功率和可行性。

Abstract: Control Barrier Functions (CBFs) are a powerful tool for ensuring the safety
of autonomous systems, yet applying them to nonholonomic robots in cluttered,
dynamic environments remains an open challenge. State-of-the-art methods often
rely on collision-cone or velocity-obstacle constraints which, by only
considering the angle of the relative velocity, are inherently conservative and
can render the CBF-based quadratic program infeasible, particularly in dense
scenarios. To address this issue, we propose a Dynamic Parabolic Control
Barrier Function (DPCBF) that defines the safe set using a parabolic boundary.
The parabola's vertex and curvature dynamically adapt based on both the
distance to an obstacle and the magnitude of the relative velocity, creating a
less restrictive safety constraint. We prove that the proposed DPCBF is valid
for a kinematic bicycle model subject to input constraints. Extensive
comparative simulations demonstrate that our DPCBF-based controller
significantly enhances navigation success rates and QP feasibility compared to
baseline methods. Our approach successfully navigates through dense
environments with up to 100 dynamic obstacles, scenarios where collision
cone-based methods fail due to infeasibility.

</details>


### [26] [How Well do Diffusion Policies Learn Kinematic Constraint Manifolds?](https://arxiv.org/abs/2510.01404)
*Lexi Foland,Thomas Cohn,Adam Wei,Nicholas Pfaff,Boyuan Chen,Russ Tedrake*

Main category: cs.RO

TL;DR: 研究扩散策略在机器人模仿学习中的表现，发现其对约束流形的学习受到数据集大小和质量的负面影响，而流形曲率的影响则不明确。


<details>
  <summary>Details</summary>
Motivation: 探究扩散策略如何精确地学习训练数据中的约束，并评估其在满足运动学约束方面的能力。

Method: 通过对双手抓取任务的案例研究，分析扩散策略在学习约束流形方面的表现。

Result: 实验表明，扩散策略学习到了约束流形的粗略近似，数据集的大小和质量下降会影响学习效果，流形曲率与约束满足度和任务成功之间的关系不明确。

Conclusion: 扩散策略在逼近约束流形方面表现较为粗略，且数据集的大小和质量对学习效果产生负面影响，而流形的曲率与约束满足度和任务成功之间的关联尚不明确。

Abstract: Diffusion policies have shown impressive results in robot imitation learning,
even for tasks that require satisfaction of kinematic equality constraints.
However, task performance alone is not a reliable indicator of the policy's
ability to precisely learn constraints in the training data. To investigate, we
analyze how well diffusion policies discover these manifolds with a case study
on a bimanual pick-and-place task that encourages fulfillment of a kinematic
constraint for success. We study how three factors affect trained policies:
dataset size, dataset quality, and manifold curvature. Our experiments show
diffusion policies learn a coarse approximation of the constraint manifold with
learning affected negatively by decreases in both dataset size and quality. On
the other hand, the curvature of the constraint manifold showed inconclusive
correlations with both constraint satisfaction and task success. A hardware
evaluation verifies the applicability of our results in the real world. Project
website with additional results and visuals:
https://diffusion-learns-kinematic.github.io

</details>


### [27] [AFFORD2ACT: Affordance-Guided Automatic Keypoint Selection for Generalizable and Lightweight Robotic Manipulation](https://arxiv.org/abs/2510.01433)
*Anukriti Singh,Kasra Torshizi,Khuzema Habib,Kelin Yu,Ruohan Gao,Pratap Tokekar*

Main category: cs.RO

TL;DR: AFFORD2ACT是一个有效的框架，通过从文本提示和单一图像中提取关键点，提升机器人在复杂环境下的操作效率。


<details>
  <summary>Details</summary>
Motivation: 现有的基于关键点的方法依赖于手动启发式或任务耦合选择，限制了可扩展性和语义理解，因此提出AFFORD2ACT以解决这些问题。

Method: AFFORD2ACT通过三个阶段的管道实现：能力过滤、类别级关键点构建和基于变换器的策略学习，嵌入门控以推理最相关的关键点。

Result: AFFORD2ACT生成一组最小的语义2D关键点，可以在15分钟内训练出一个紧凑的38维状态策略，并在不依赖本体感知或密集表示的情况下实现快速实时操作。

Conclusion: AFFORD2ACT能在多种真实世界操作任务中提高数据效率，并在未见物体、陌生类别、背景和干扰物上取得良好的表现。

Abstract: Vision-based robot learning often relies on dense image or point-cloud
inputs, which are computationally heavy and entangle irrelevant background
features. Existing keypoint-based approaches can focus on manipulation-centric
features and be lightweight, but either depend on manual heuristics or
task-coupled selection, limiting scalability and semantic understanding. To
address this, we propose AFFORD2ACT, an affordance-guided framework that
distills a minimal set of semantic 2D keypoints from a text prompt and a single
image. AFFORD2ACT follows a three-stage pipeline: affordance filtering,
category-level keypoint construction, and transformer-based policy learning
with embedded gating to reason about the most relevant keypoints, yielding a
compact 38-dimensional state policy that can be trained in 15 minutes, which
performs well in real-time without proprioception or dense representations.
Across diverse real-world manipulation tasks, AFFORD2ACT consistently improves
data efficiency, achieving an 82% success rate on unseen objects, novel
categories, backgrounds, and distractors.

</details>


### [28] [Differentiable Skill Optimisation for Powder Manipulation in Laboratory Automation](https://arxiv.org/abs/2510.01438)
*Minglun Wei,Xintong Yang,Yu-Kun Lai,Ze Ji*

Main category: cs.RO

TL;DR: 提出一种轨迹优化框架，通过可微物理模拟和基于课程的策略，提高粉末运输的精确操控，从而加速科学研究。


<details>
  <summary>Details</summary>
Motivation: 解决实验室环境中粉末运输任务的精确操控挑战，提升科学发现的效率。

Method: 提出一种轨迹优化框架，该框架集成了可微物理模拟、低维技能空间参数化和基于课程的策略。

Result: 实验结果表明，该方法在任务成功率和稳定性方面表现优越。

Conclusion: 该方法在任务成功率和稳定性方面优于基于强化学习的基线方法。

Abstract: Robotic automation is accelerating scientific discovery by reducing manual
effort in laboratory workflows. However, precise manipulation of powders
remains challenging, particularly in tasks such as transport that demand
accuracy and stability. We propose a trajectory optimisation framework for
powder transport in laboratory settings, which integrates differentiable
physics simulation for accurate modelling of granular dynamics, low-dimensional
skill-space parameterisation to reduce optimisation complexity, and a
curriculum-based strategy that progressively refines task competence over long
horizons. This formulation enables end-to-end optimisation of contact-rich
robot trajectories while maintaining stability and convergence efficiency.
Experimental results demonstrate that the proposed method achieves superior
task success rates and stability compared to the reinforcement learning
baseline.

</details>


### [29] [Touching the tumor boundary: A pilot study on ultrasound based virtual fixtures for breast-conserving surgery](https://arxiv.org/abs/2510.01452)
*Laura Connolly,Tamas Ungi,Adnan Munawar,Anton Deguet,Chris Yeung,Russell H. Taylor,Parvin Mousavi,Gabor Fichtinger Keyvan Hashtrudi-Zaad*

Main category: cs.RO

TL;DR: 本研究引入了一种协作机器人系统，用于改善乳房保守手术中肿瘤边界的定位，结果表明该系统有效提升了切除效果。


<details>
  <summary>Details</summary>
Motivation: 在乳房保守手术中，肿瘤边界的划定具有挑战性，因此提出一种协作机器人引导系统，应用触觉反馈来进行肿瘤定位。

Method: 使用带有电切割刀的小型触觉机器人，并结合超声波和电磁导航识别肿瘤边界。

Result: 虚拟界面引导被证明能改善切除边缘，用户在有触觉反馈时任务的心理负担、挫败感和努力程度均较低。

Conclusion: 虚拟界面可以帮助在模拟的乳房保守手术中定位肿瘤边界。

Abstract: Purpose: Delineating tumor boundaries during breast-conserving surgery is
challenging as tumors are often highly mobile, non-palpable, and have
irregularly shaped borders. To address these challenges, we introduce a
cooperative robotic guidance system that applies haptic feedback for tumor
localization. In this pilot study, we aim to assess if and how this system can
be successfully integrated into breast cancer care.
  Methods: A small haptic robot is retrofitted with an electrocautery blade to
operate as a cooperatively controlled surgical tool. Ultrasound and
electromagnetic navigation are used to identify the tumor boundaries and
position. A forbidden region virtual fixture is imposed when the surgical tool
collides with the tumor boundary. We conducted a study where users were asked
to resect tumors from breast simulants both with and without the haptic
guidance. We then assess the results of these simulated resections both
qualitatively and quantitatively.
  Results: Virtual fixture guidance is shown to improve resection margins. On
average, users find the task to be less mentally demanding, frustrating, and
effort intensive when haptic feedback is available. We also discovered some
unanticipated impacts on surgical workflow that will guide design adjustments
and training protocol moving forward.
  Conclusion: Our results suggest that virtual fixtures can help localize tumor
boundaries in simulated breast-conserving surgery. Future work will include an
extensive user study to further validate these results and fine-tune our
guidance system.

</details>


### [30] [VL-KnG: Visual Scene Understanding for Navigation Goal Identification using Spatiotemporal Knowledge Graphs](https://arxiv.org/abs/2510.01483)
*Mohamad Al Mdfaa,Svetlana Lukina,Timur Akhtyamov,Arthur Nigmatzyanov,Dmitrii Nalberskii,Sergey Zagoruyko,Gonzalo Ferrer*

Main category: cs.RO

TL;DR: 本研究提出了VL-KnG，一个视觉场景理解系统，通过时空知识图和高效查询处理解决机器人导航中的关键挑战，实现高成功率和可解释推理。


<details>
  <summary>Details</summary>
Motivation: 针对现有视觉语言模型在机器人导航中缺乏持久场景记忆、有限的空间推理和实时应用中的可扩展性进行改进。

Method: 通过构建时空知识图和高效的查询处理来解决导航目标识别问题。

Result: 在实际案例中，VL-KnG在差分驱动机器人上展示了良好的效果，与Gemini 2.5 Pro性能相当。

Conclusion: VL-KnG在不同任务上表现出色，达到77.27%的成功率和76.92%的回答准确率，同时提供可解释的推理，适合实时部署。

Abstract: Vision-language models (VLMs) have shown potential for robot navigation but
encounter fundamental limitations: they lack persistent scene memory, offer
limited spatial reasoning, and do not scale effectively with video duration for
real-time application. We present VL-KnG, a Visual Scene Understanding system
that tackles these challenges using spatiotemporal knowledge graph construction
and computationally efficient query processing for navigation goal
identification. Our approach processes video sequences in chunks utilizing
modern VLMs, creates persistent knowledge graphs that maintain object identity
over time, and enables explainable spatial reasoning through queryable graph
structures. We also introduce WalkieKnowledge, a new benchmark with about 200
manually annotated questions across 8 diverse trajectories spanning
approximately 100 minutes of video data, enabling fair comparison between
structured approaches and general-purpose VLMs. Real-world deployment on a
differential drive robot demonstrates practical applicability, with our method
achieving 77.27% success rate and 76.92% answer accuracy, matching Gemini 2.5
Pro performance while providing explainable reasoning supported by the
knowledge graph, computational efficiency for real-time deployment across
different tasks, such as localization, navigation and planning. Code and
dataset will be released after acceptance.

</details>


### [31] [Pose Estimation of a Thruster-Driven Bioinspired Multi-Link Robot](https://arxiv.org/abs/2510.01485)
*Nicholas B. Andrews,Yanhao Yang,Sofya Akhetova,Kristi A. Morgansen,Ross L. Hatton*

Main category: cs.RO

TL;DR: 本研究开发了一种有效的姿态估计方法，并通过多样本步态训练提高了机器人的通用性，减少了训练数据需求。


<details>
  <summary>Details</summary>
Motivation: 研究目的在于实现对一种自由漂浮、仿生的多连杆机器人的姿态估计，尤其是在其关节未被动作控制的情况下。

Method: 采用无味卡尔曼滤波器并结合高斯过程残差学习来实现状态估计。

Result: 实验结果表明该机器人姿态可成功且可靠地估算，并且基于多步态数据集训练的滤波器在同一前进步态测试上表现与单步态数据集训练的滤波器相仿。

Conclusion: 所提议的方法能够有效估算多连杆机器人在自由漂浮条件下的姿态，且在多种步态间具有较好的通用能力。

Abstract: This work demonstrates pose (position and shape) estimation for a
free-floating, bioinspired multi-link robot with unactuated joints,
link-mounted thrusters for control, and a single gyroscope per link, resulting
in an underactuated, minimally sensed platform. Through a proof-of-concept
hardware experiment and offline Kalman filter analysis, we show that the
robot's pose can be reliably estimated. State estimation is performed using an
unscented Kalman filter augmented with Gaussian process residual learning to
compensate for non-zero-mean, non-Gaussian noise. We further show that a filter
trained on a multi-gait dataset (forward, backward, left, right, and turning)
performs comparably to one trained on a larger forward-gait-only dataset when
both are evaluated on the same forward-gait test trajectory. These results
reveal overlap in the gait input space, which can be exploited to reduce
training data requirements while enhancing the filter's generalizability across
multiple gaits.

</details>


### [32] [Online Hierarchical Policy Learning using Physics Priors for Robot Navigation in Unknown Environments](https://arxiv.org/abs/2510.01519)
*Wei Han Chen,Yuchen Liu,Alexiy Buynitsky,Ahmed H. Qureshi*

Main category: cs.RO

TL;DR: 本研究提出了一种分层的机器人导航方法，利用稀疏图和神经场计划，解决了复杂环境中的导航问题，表现出优越的适应性和精确度。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在大规模复杂室内环境导航中的局限性，尤其是传统方法的分辨率控制和模仿学习方法对演示数据的依赖。

Method: 采用分层结构对规划问题进行解构，高层使用稀疏图捕捉全球连通性，低层采用基于神经场的规划方法解决局部障碍。

Result: 在大型环境中验证了框架，相较于现有方法显示出更强的适应性和精确度。

Conclusion: 该方法在大规模环境中表现出更强的适应性和精确度，具有在线探索、映射和现实世界导航的潜力。

Abstract: Robot navigation in large, complex, and unknown indoor environments is a
challenging problem. The existing approaches, such as traditional
sampling-based methods, struggle with resolution control and scalability, while
imitation learning-based methods require a large amount of demonstration data.
Active Neural Time Fields (ANTFields) have recently emerged as a promising
solution by using local observations to learn cost-to-go functions without
relying on demonstrations. Despite their potential, these methods are hampered
by challenges such as spectral bias and catastrophic forgetting, which diminish
their effectiveness in complex scenarios. To address these issues, our approach
decomposes the planning problem into a hierarchical structure. At the high
level, a sparse graph captures the environment's global connectivity, while at
the low level, a planner based on neural fields navigates local obstacles by
solving the Eikonal PDE. This physics-informed strategy overcomes common
pitfalls like spectral bias and neural field fitting difficulties, resulting in
a smooth and precise representation of the cost landscape. We validate our
framework in large-scale environments, demonstrating its enhanced adaptability
and precision compared to previous methods, and highlighting its potential for
online exploration, mapping, and real-world navigation.

</details>


### [33] [Real-time Multi-Plane Segmentation Based on GPU Accelerated High-Resolution 3D Voxel Mapping for Legged Robot Locomotion](https://arxiv.org/abs/2510.01592)
*Shun Niijima,Ryoichi Tsuzaki,Noriaki Takasugi,Masaya Kinoshita*

Main category: cs.RO

TL;DR: 本研究提出了一种基于GPU加速的实时多平面分割方法，成功提升了机器人在复杂3D环境中的运动能力。


<details>
  <summary>Details</summary>
Motivation: 现有的在线平面映射方法在准确性与计算效率之间难以平衡，且体素平面分割尚未在实时应用中得到探索。

Method: 采用GPU加速的高分辨率3D体素映射，结合基于随机采样一致性的平面检测，实现快速提取平面区域。

Result: 实验结果显示该方法在0.01m分辨率下达到超过30Hz的实时更新速率，准确实现3D多平面分割。

Conclusion: 提出的方法在复杂3D平面结构中展示了卓越的运动表现，适用于实时任务。

Abstract: This paper proposes a real-time multi-plane segmentation method based on
GPU-accelerated high-resolution 3D voxel mapping for legged robot locomotion.
Existing online planar mapping approaches struggle to balance accuracy and
computational efficiency: direct depth image segmentation from specific sensors
suffers from poor temporal integration, height map-based methods cannot
represent complex 3D structures like overhangs, and voxel-based plane
segmentation remains unexplored for real-time applications. To address these
limitations, we develop a novel framework that integrates vertex-based
connected component labeling with random sample consensus based plane detection
and convex hull, leveraging GPU parallel computing to rapidly extract planar
regions from point clouds accumulated in high-resolution 3D voxel maps.
Experimental results demonstrate that the proposed method achieves fast and
accurate 3D multi-plane segmentation at over 30 Hz update rate even at a
resolution of 0.01 m, enabling the detected planes to be utilized in real time
for locomotion tasks. Furthermore, we validate the effectiveness of our
approach through experiments in both simulated environments and physical legged
robot platforms, confirming robust locomotion performance when considering 3D
planar structures.

</details>


### [34] [MiniBEE: A New Form Factor for Compact Bimanual Dexterity](https://arxiv.org/abs/2510.01603)
*Sharfin Islam,Zewen Chen,Zhanpeng He,Swapneel Bhatt,Andres Permuy,Brock Taylor,James Vickery,Pedro Piacenza,Cheng Zhang,Matei Ciocarlie*

Main category: cs.RO

TL;DR: MiniBEE是一种紧凑的双手系统，通过结合有限自由度的臂并优化其运动学，提高了双手协作的灵活性与应用范围。


<details>
  <summary>Details</summary>
Motivation: 传统的双臂机器人手操纵器依赖全自由度的臂，增加了系统复杂性且未充分利用工作空间。

Method: 通过运动学分析和设计优化方法，制定运动灵活性指标以扩大灵活工作空间，并实现可穿戴演示训练模仿学习策略。

Result: MiniBEE系统通过将两臂耦合进运动链，支持可穿戴数据采集和标准机器人手臂上的灵活操作，展现了优化的运动学分析。

Conclusion: MiniBEE系统通过优化运动学灵活性，在减少系统复杂性的同时增强了双手协作的能力，适用于可穿戴数据收集及标准机器人手臂的延展。

Abstract: Bimanual robot manipulators can achieve impressive dexterity, but typically
rely on two full six- or seven- degree-of-freedom arms so that paired grippers
can coordinate effectively. This traditional framework increases system
complexity while only exploiting a fraction of the overall workspace for
dexterous interaction. We introduce the MiniBEE (Miniature Bimanual
End-effector), a compact system in which two reduced-mobility arms (3+ DOF
each) are coupled into a kinematic chain that preserves full relative
positioning between grippers. To guide our design, we formulate a kinematic
dexterity metric that enlarges the dexterous workspace while keeping the
mechanism lightweight and wearable. The resulting system supports two
complementary modes: (i) wearable kinesthetic data collection with self-tracked
gripper poses, and (ii) deployment on a standard robot arm, extending dexterity
across its entire workspace. We present kinematic analysis and design
optimization methods for maximizing dexterous range, and demonstrate an
end-to-end pipeline in which wearable demonstrations train imitation learning
policies that perform robust, real-world bimanual manipulation.

</details>


### [35] [ActiveUMI: Robotic Manipulation with Active Perception from Robot-Free Human Demonstrations](https://arxiv.org/abs/2510.01607)
*Qiyuan Zeng,Chengmeng Li,Jude St. John,Zhongyi Zhou,Junjie Wen,Guorui Feng,Yichen Zhu,Yi Xu*

Main category: cs.RO

TL;DR: ActiveUMI是一个数据收集系统，通过记录操作者的头部运动来实现人机协作，使机器人能够执行复杂的双手操作，表现出良好的成功率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 本研究的动力在于构建一个能够让机器人执行复杂双手操作的人类示范数据收集系统。

Method: ActiveUMI结合了便携式虚拟现实遥操作设备与传感器控制器，通过精确的位姿对齐实现人机运动学的桥接。

Result: 在六项具有挑战性的双手任务上，ActiveUMI收集的数据训练的策略在原分布任务上的平均成功率为70%，并在新物体和新环境上的测试中保持56%的成功率。

Conclusion: ActiveUMI为构建通用和高效的机器人策略提供了一种有效且可扩展的数据收集方法。

Abstract: We present ActiveUMI, a framework for a data collection system that transfers
in-the-wild human demonstrations to robots capable of complex bimanual
manipulation. ActiveUMI couples a portable VR teleoperation kit with sensorized
controllers that mirror the robot's end-effectors, bridging human-robot
kinematics via precise pose alignment. To ensure mobility and data quality, we
introduce several key techniques, including immersive 3D model rendering, a
self-contained wearable computer, and efficient calibration methods.
ActiveUMI's defining feature is its capture of active, egocentric perception.
By recording an operator's deliberate head movements via a head-mounted
display, our system learns the crucial link between visual attention and
manipulation. We evaluate ActiveUMI on six challenging bimanual tasks. Policies
trained exclusively on ActiveUMI data achieve an average success rate of 70\%
on in-distribution tasks and demonstrate strong generalization, retaining a
56\% success rate when tested on novel objects and in new environments. Our
results demonstrate that portable data collection systems, when coupled with
learned active perception, provide an effective and scalable pathway toward
creating generalizable and highly capable real-world robot policies.

</details>


### [36] [Reducing Discomfort in Driving Simulators: Motion Cueing for Motion Sickness Mitigation](https://arxiv.org/abs/2510.01986)
*Varun Kotian,Vishrut Jain,Andrea Michelle Rios Lazcano,Daan Marinus Pool,Riender Happee,Barys Shyrokau*

Main category: cs.RO

TL;DR: 本研究提出了一种新型运动提示算法，能够在减少驾驶模拟器晕动病的同时提高仿真逼真度，借助人机实验验证算法的有效性。


<details>
  <summary>Details</summary>
Motivation: 驾驶模拟器在研究和开发中被越来越广泛使用，但由于运动缩放和视觉不对称，常导致用户晕动病问题。

Method: 采用模型预测控制（MPC）的方法，提出了一种运动提示算法，旨在减少由主观垂直冲突模型预测的晕动病。通过人机参与实验比较不同的模拟器运动设置。

Result: 实验结果显示，提出的方法有效减少了晕动病，特别是在妥协方案中，晕动病水平降低超过50%。无运动状态下的晕动病水平最低，但仿真逼真度评价最低。妥协方案在不显著降低逼真度的同时，也大幅降低了晕动病。

Conclusion: 所提出的运动提示算法显著降低了模拟器中的晕动病，同时保持了较高的仿真逼真度，支持更广泛的模拟器应用。

Abstract: Driving simulators are increasingly used in research and development.
However, simulators often cause motion sickness due to downscaled motion and
unscaled veridical visuals. In this paper, a motion cueing algorithm is
proposed that reduces motion sickness as predicted by the subjective vertical
conflict (SVC) model using model predictive control (MPC). Both sensory
conflict and specific force errors are penalised in the cost function, allowing
the algorithm to jointly optimise fidelity and comfort.
  Human-in-the-loop experiments were conducted to compare four simulator motion
settings: two variations of our MPC-based algorithm, one focused on pure
specific force tracking and the second compromising specific force tracking and
motion sickness minimisation, as well as reference adaptive washout and no
motion cases. The experiments were performed on a hexapod driving simulator
with participants exposed to passive driving.
  Experimental motion sickness results closely matched the sickness model
predictions. As predicted by the model, the no motion condition yielded the
lowest sickness levels. However, it was rated lowest in terms of fidelity. The
compromise solution reduced sickness by over 50% (average MISC level 3 to 1.5)
compared to adaptive washout and the algorithm focusing on specific force
tracking, without any significant reduction in fidelity rating.
  The proposed approach for developing MCA that takes into account both the
simulator dynamics and time evolution of motion sickness offers a significant
advancement in achieving an optimal control of motion sickness and specific
force recreation in driving simulators, supporting broader simulator use.

</details>


### [37] [FailSafe: Reasoning and Recovery from Failures in Vision-Language-Action Models](https://arxiv.org/abs/2510.01642)
*Zijun Lin,Jiafei Duan,Haoquan Fang,Dieter Fox,Ranjay Krishna,Cheston Tan,Bihan Wen*

Main category: cs.RO

TL;DR: 本文提出了FailSafe系统，以解决机器人在执行任务过程中遇到的失败问题，通过自动生成失败案例及恢复行为来提升VLA模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现实机器人在执行任务时会面临不可预知的失败，现有数据集缺乏相关失败检测与恢复支持，制约了机器人操作的可靠性。

Method: 引入FailSafe系统，通过自动生成多样化失败案例及其可执行恢复动作，进而优化VLA模型的性能。

Result: FailSafe-VLM在多个任务上，平均提升了三种最先进的VLA模型（pi0-FAST、OpenVLA、OpenVLA-OFT）性能达22.6%。

Conclusion: FailSafe系统显著提高了机器人在多任务中的失败检测与恢复能力，并且在不同配置和机器人形态下具有良好的迁移性。

Abstract: Recent advances in robotic manipulation have integrated low-level robotic
control into Vision-Language Models (VLMs), extending them into
Vision-Language-Action (VLA) models. Although state-of-the-art VLAs achieve
strong performance in downstream robotic applications, supported by large-scale
crowd-sourced robot training data, they still inevitably encounter failures
during execution. Enabling robots to reason about and recover from
unpredictable and abrupt failures remains a critical challenge. Existing
robotic manipulation datasets, collected in either simulation or the real
world, primarily provide only ground-truth trajectories, leaving robots unable
to recover once failures occur. Moreover, the few datasets that address failure
detection typically offer only textual explanations, which are difficult to
utilize directly in VLA models. To address this gap, we introduce FailSafe, a
novel failure generation and recovery system that automatically produces
diverse failure cases paired with executable recovery actions. FailSafe can be
seamlessly applied to any manipulation task in any simulator, enabling scalable
creation of failure-action data. To demonstrate its effectiveness, we fine-tune
LLaVa-OneVision-7B (LLaVa-OV-7B) to build FailSafe-VLM. Experimental results
show that FailSafe-VLM successfully helps robotic arm detect and recover from
potential failures, improving the performance of three state-of-the-art VLA
models pi0-FAST, OpenVLA, OpenVLA-OFT) by up to 22.6% on average across several
tasks in Maniskill. Furthermore, FailSafe-VLM could generalize across different
spatial configurations, camera viewpoints, and robotic embodiments. We plan to
release the FailSafe code to the community.

</details>


### [38] [Statistical Uncertainty Learning for Robust Visual-Inertial State Estimation](https://arxiv.org/abs/2510.01648)
*Seungwon Choi,Donggyu Park,Seo-Yeon Hwang,Tae-Wan Kim*

Main category: cs.RO

TL;DR: 提出了一种实时在线学习传感器测量可靠性的统计框架，通过自我监督改善视觉惯性测距的精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 强调动态评估传感器测量的可靠性以更好地权衡每个测量对状态估计的贡献，解决现有方法在实时数据中捕捉动态误差特性的局限性。

Method: 提出了一个在线学习传感器测量可靠性的统计框架，通过多视图几何一致性作为自我监督的形式，来推断地标不确定性并自适应加权视觉测量。

Result: 在EuRoC数据集上的实验结果表明，该方法在平移误差上平均降低了约24%，旋转误差降低了约42%。

Conclusion: 该方法在实时操作中显著提高了跟踪精度和鲁棒性，并在EuRoC数据集上的表现超越了基准方法。

Abstract: A fundamental challenge in robust visual-inertial odometry (VIO) is to
dynamically assess the reliability of sensor measurements. This assessment is
crucial for properly weighting the contribution of each measurement to the
state estimate. Conventional methods often simplify this by assuming a static,
uniform uncertainty for all measurements. This heuristic, however, may be
limited in its ability to capture the dynamic error characteristics inherent in
real-world data. To improve this limitation, we present a statistical framework
that learns measurement reliability assessment online, directly from sensor
data and optimization results. Our approach leverages multi-view geometric
consistency as a form of self-supervision. This enables the system to infer
landmark uncertainty and adaptively weight visual measurements during
optimization. We evaluated our method on the public EuRoC dataset,
demonstrating improvements in tracking accuracy with average reductions of
approximately 24\% in translation error and 42\% in rotation error compared to
baseline methods with fixed uncertainty parameters. The resulting framework
operates in real time while showing enhanced accuracy and robustness. To
facilitate reproducibility and encourage further research, the source code will
be made publicly available.

</details>


### [39] [Symskill: Symbol and Skill Co-Invention for Data-Efficient and Real-Time Long-Horizon Manipulation](https://arxiv.org/abs/2510.01661)
*Yifei Simon Shao,Yuchen Zheng,Sunan Sun,Pratik Chaudhari,Vijay Kumar,Nadia Figueroa*

Main category: cs.RO

TL;DR: SymSkill是一个结合模仿学习和任务运动规划的统一框架，能在动态环境中实现实时的多步骤操作和恢复，表现出色。


<details>
  <summary>Details</summary>
Motivation: 多步骤操作在动态环境中面临挑战，现有方法在应对这一问题时各有局限，迫切需要一个统一的学习框架。

Method: SymSkill通过从未标记和未分段的示范中联合学习谓词、操作者和技能，使用符号规划器在执行时组合和重新排序技能。

Result: 在RoboCasa仿真中，SymSkill以85%的成功率完成12个单步任务，并能将技能组合为最多需6次重组的多步骤计划。在真实Franka机器人上，SymSkill能够从5分钟的无标签数据中学习并根据目标规范执行多个任务。

Conclusion: SymSkill框架能够实现在线组合和恢复多步骤操作，使得机器人能在复杂动态环境中高效执行任务。

Abstract: Multi-step manipulation in dynamic environments remains challenging. Two
major families of methods fail in distinct ways: (i) imitation learning (IL) is
reactive but lacks compositional generalization, as monolithic policies do not
decide which skill to reuse when scenes change; (ii) classical task-and-motion
planning (TAMP) offers compositionality but has prohibitive planning latency,
preventing real-time failure recovery. We introduce SymSkill, a unified
learning framework that combines the benefits of IL and TAMP, allowing
compositional generalization and failure recovery in real-time. Offline,
SymSkill jointly learns predicates, operators, and skills directly from
unlabeled and unsegmented demonstrations. At execution time, upon specifying a
conjunction of one or more learned predicates, SymSkill uses a symbolic planner
to compose and reorder learned skills to achieve the symbolic goals, while
performing recovery at both the motion and symbolic levels in real time.
Coupled with a compliant controller, SymSkill enables safe and uninterrupted
execution under human and environmental disturbances. In RoboCasa simulation,
SymSkill can execute 12 single-step tasks with 85% success rate. Without
additional data, it composes these skills into multi-step plans requiring up to
6 skill recompositions, recovering robustly from execution failures. On a real
Franka robot, we demonstrate SymSkill, learning from 5 minutes of unsegmented
and unlabeled play data, is capable of performing multiple tasks simply by goal
specifications. The source code and additional analysis can be found on
https://sites.google.com/view/symskill.

</details>


### [40] [Geometric Backstepping Control of Omnidirectional Tiltrotors Incorporating Servo-Rotor Dynamics for Robustness against Sudden Disturbances](https://arxiv.org/abs/2510.01675)
*Jaewoo Lee,Dongjae Lee,Jinwoo Lee,Hyungyu Lee,Yeonjoon Kim,H. Jin Kim*

Main category: cs.RO

TL;DR: 本文提出了一种几何反推控制器，考虑伺服和旋翼动态，提高了可变倾斜全向多旋翼的操作稳定性和跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 考虑执行器动态以提高灵活飞行操控的有效性和可靠性，尤其是在激烈飞行运动或应对突发干扰时。

Method: 采用几何反推控制器设计，并考虑了伺服和旋翼动态，以实现全系统的指数稳定性。

Result: 所提控制器在快速平移跟踪、快速旋转跟踪和应对突发干扰的实验中均超过了不考虑执行器动态的基线控制器，并确保了任务的成功完成。

Conclusion: 所提控制器在各种实验场景中表现出更好的跟踪性能，并且在挑战性任务中保持稳定。

Abstract: This work presents a geometric backstepping controller for a variable-tilt
omnidirectional multirotor that explicitly accounts for both servo and rotor
dynamics. Considering actuator dynamics is essential for more effective and
reliable operation, particularly during aggressive flight maneuvers or recovery
from sudden disturbances. While prior studies have investigated actuator-aware
control for conventional and fixed-tilt multirotors, these approaches rely on
linear relationships between actuator input and wrench, which cannot capture
the nonlinearities induced by variable tilt angles. In this work, we exploit
the cascade structure between the rigid-body dynamics of the multirotor and its
nonlinear actuator dynamics to design the proposed backstepping controller and
establish exponential stability of the overall system. Furthermore, we reveal
parametric uncertainty in the actuator model through experiments, and we
demonstrate that the proposed controller remains robust against such
uncertainty. The controller was compared against a baseline that does not
account for actuator dynamics across three experimental scenarios: fast
translational tracking, rapid rotational tracking, and recovery from sudden
disturbance. The proposed method consistently achieved better tracking
performance, and notably, while the baseline diverged and crashed during the
fastest translational trajectory tracking and the recovery experiment, the
proposed controller maintained stability and successfully completed the tasks,
thereby demonstrating its effectiveness.

</details>


### [41] [PolySim: Bridging the Sim-to-Real Gap for Humanoid Control via Multi-Simulator Dynamics Randomization](https://arxiv.org/abs/2510.01708)
*Zixing Lei,Zibo Zhou,Sheng Yin,Yueru Chen,Qingyao Xu,Weixin Li,Yunhong Wang,Bowei Tang,Wei Jing,Siheng Chen*

Main category: cs.RO

TL;DR: PolySim通过跨多个模拟器联合训练WBC政策，显著提高了从仿真到现实的迁移效果，减少了调动误差并改善了成功率。


<details>
  <summary>Details</summary>
Motivation: 解决在仿真中训练的人形全身控制（WBC）策略所面临的仿真与现实之间的差距，尤其是模拟器的归纳偏差带来的问题。

Method: 介绍PolySim，一个集成多个异质模拟器的WBC训练平台，通过同时启动多个不同引擎的并行环境实现动态级域随机化。

Result: PolySim在MuJoCo上提升了52.8%的执行成功率，并大幅减少了运动跟踪误差，实现了有效的迁移。

Conclusion: PolySim显著减少了模拟到模拟的运动跟踪误差，并且能够在没有额外微调的情况下实现从模拟到现实世界的有效迁移。

Abstract: Humanoid whole-body control (WBC) policies trained in simulation often suffer
from the sim-to-real gap, which fundamentally arises from simulator inductive
bias, the inherent assumptions and limitations of any single simulator. These
biases lead to nontrivial discrepancies both across simulators and between
simulation and the real world. To mitigate the effect of simulator inductive
bias, the key idea is to train policies jointly across multiple simulators,
encouraging the learned controller to capture dynamics that generalize beyond
any single simulator's assumptions. We thus introduce PolySim, a WBC training
platform that integrates multiple heterogeneous simulators. PolySim can launch
parallel environments from different engines simultaneously within a single
training run, thereby realizing dynamics-level domain randomization.
Theoretically, we show that PolySim yields a tighter upper bound on simulator
inductive bias than single-simulator training. In experiments, PolySim
substantially reduces motion-tracking error in sim-to-sim evaluations; for
example, on MuJoCo, it improves execution success by 52.8 over an IsaacSim
baseline. PolySim further enables zero-shot deployment on a real Unitree G1
without additional fine-tuning, showing effective transfer from simulation to
the real world. We will release the PolySim code upon acceptance of this work.

</details>


### [42] [Contrastive Representation Regularization for Vision-Language-Action Models](https://arxiv.org/abs/2510.01711)
*Taeyoung Kim,Jimin Lee,Myungkyu Koo,Dongyoung Kim,Kyungmin Lee,Changyeon Kim,Younggyo Seo,Jinwoo Shin*

Main category: cs.RO

TL;DR: 本文提出RS-CL，通过增强VLA模型对机器人状态的感知，显著提升机器人操作任务的表现。


<details>
  <summary>Details</summary>
Motivation: 解决VLA模型在机器人操作中对控制信号和自我感知状态敏感度不足的问题。

Method: 提出了一种新颖的Robot State-aware Contrastive Loss (RS-CL)，用于增强VLA模型对机器人状态的感知，结合软监督方法来优化表示学习。

Result: RS-CL在RoboCasa-Kitchen的抓取和放置任务上将表现从30.8%提升至41.5%，并在实际机器人操作任务中成功率从45.0%提升至58.3%。

Conclusion: RS-CL显著提高了先进VLA模型在机器人操作性能上的表现，特别是在RoboCasa-Kitchen中的抓取和放置任务。

Abstract: Vision-Language-Action (VLA) models have shown its capabilities in robot
manipulation by leveraging rich representations from pre-trained
Vision-Language Models (VLMs). However, their representations arguably remain
suboptimal, lacking sensitivity to robotic signals such as control actions and
proprioceptive states. To address the issue, we introduce Robot State-aware
Contrastive Loss (RS-CL), a simple and effective representation regularization
for VLA models, designed to bridge the gap between VLM representations and
robotic signals. In particular, RS-CL aligns the representations more closely
with the robot's proprioceptive states, by using relative distances between the
states as soft supervision. Complementing the original action prediction
objective, RS-CL effectively enhances control-relevant representation learning,
while being lightweight and fully compatible with standard VLA training
pipeline. Our empirical results demonstrate that RS-CL substantially improves
the manipulation performance of state-of-the-art VLA models; it pushes the
prior art from 30.8% to 41.5% on pick-and-place tasks in RoboCasa-Kitchen,
through more accurate positioning during grasping and placing, and boosts
success rates from 45.0% to 58.3% on challenging real-robot manipulation tasks.

</details>


### [43] [Dual-Mode Magnetic Continuum Robot for Targeted Drug Delivery](https://arxiv.org/abs/2510.01761)
*Wendu Zhang,Heng Wang,Shuangyi Wang,Yuanrui Huang*

Main category: cs.RO

TL;DR: 本文提出了一种新型的磁性连续机器人，通过嵌入式磁铁实现了更复杂的运动控制，并成功演示了药物释放功能，具有良好的应用前景。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有的轴向磁化设计在运动能力上的限制，旨在扩展磁性连续机器人的变形能力。

Method: 通过在导管壁内径向嵌入永久磁铁，利用单个外部引导的永久磁铁独立诱导弯曲或扭转，以实现控制。

Result: 实验验证了在实际场景中的解耦模式控制，并通过实验展示了该系统的整体操作能力，从而实现靶向介入。

Conclusion: 该论文提出的磁性连续机器人系统具有优越的变形能力和精确的药物传递功能，显示出在特定治疗中强大的潜力。

Abstract: Magnetic continuum robots (MCRs) enable minimally invasive navigation through
tortuous anatomical channels, yet axially magnetized designs have largely been
limited to bending-only motion. To expand deformation capabilities, this paper
presents a simple assembly that embeds permanent magnets radially within the
catheter wall, allowing a single externally steered permanent magnet to
independently induce either bending or torsion. A physics-based formulation
together with finite-element analysis establishes the actuation principles, and
benchtop experiments validate decoupled mode control under practical fields.
Building on this, a dual-layer blockage mechanism consisting of outer grooves
and inner plates leverages torsional shear to achieve on-demand drug release.
Finally, an in-phantom intervention experiment demonstrates end-to-end
operation: lumen following by bending for target approach, followed by
twist-activated release at the site. The resulting compact, cable-free platform
combines versatile deformation with precise payload delivery, indicating strong
potential for next-generation, site-specific therapies.

</details>


### [44] [An Anytime, Scalable and Complete Algorithm for Embedding a Manufacturing Procedure in a Smart Factory](https://arxiv.org/abs/2510.01770)
*Christopher Leet,Aidan Sciortino,Sven Koenig*

Main category: cs.RO

TL;DR: 提出一种新的解决方案TS-ACES，有效解决智能工厂中嵌入问题，支持超过一百台机器的扩展性。


<details>
  <summary>Details</summary>
Motivation: 现代智能工厂需要处理大量机器和复杂运输系统，现有解决方案无法满足规模要求。

Method: 提出TS-ACES方法，作为一种基于交通系统的随时循环嵌入求解器，解决智能工厂嵌入问题。

Result: 实验证明TS-ACES能够完成智能工厂嵌入，并具有良好的可扩展性。

Conclusion: TS-ACES是一种在实际工业场景中能够扩展到超过一百台机器的智能工厂嵌入问题的首个高可扩展性解决方案。

Abstract: Modern automated factories increasingly run manufacturing procedures using a
matrix of programmable machines, such as 3D printers, interconnected by a
programmable transport system, such as a fleet of tabletop robots. To embed a
manufacturing procedure into a smart factory, an operator must: (a) assign each
of its processes to a machine and (b) specify how agents should transport parts
between machines. The problem of embedding a manufacturing process into a smart
factory is termed the Smart Factory Embedding (SFE) problem. State-of-the-art
SFE solvers can only scale to factories containing a couple dozen machines.
Modern smart factories, however, may contain hundreds of machines. We fill this
hole by introducing the first highly scalable solution to the SFE, TS-ACES, the
Traffic System based Anytime Cyclic Embedding Solver. We show that TS-ACES is
complete and can scale to SFE instances based on real industrial scenarios with
more than a hundred machines.

</details>


### [45] [Nav-EE: Navigation-Guided Early Exiting for Efficient Vision-Language Models in Autonomous Driving](https://arxiv.org/abs/2510.01795)
*Haibo Hu,Lianming Huang,Xinyu Wang,Yufei Cui,Nan Guan,Chun Jason Xue*

Main category: cs.RO

TL;DR: Nav-EE框架通过导航预见提高了自动驾驶中的推理效率，显著减少推理延迟。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶中视觉-语言模型(VLMs)的应用日益增长，面临的高推理延迟问题限制了实时部署的能力。

Method: 提出了一种导航引导的早期退出框架Nav-EE，该框架离线预计算特定任务的退出层，并根据导航先验在线动态应用。

Result: Nav-EE在CODA、Waymo和BOSCH上的实验表明，其准确性与完整推理相当，同时将推理延迟降低了多达63.9%。在Autoware Universe上的实车集成进一步减少推理延迟（从600毫秒降至300毫秒），支持复杂场景中的快速决策。

Conclusion: 将导航预见与早期退出相结合，为自主系统中大型模型的高效部署提供了一条可行的路径。

Abstract: Vision-Language Models (VLMs) are increasingly applied in autonomous driving
for unified perception and reasoning, but high inference latency hinders
real-time deployment. Early-exit reduces latency by terminating inference at
intermediate layers, yet its task-dependent nature limits generalization across
diverse scenarios. We observe that this limitation aligns with autonomous
driving: navigation systems can anticipate upcoming contexts (e.g.,
intersections, traffic lights), indicating which tasks will be required. We
propose Nav-EE, a navigation-guided early-exit framework that precomputes
task-specific exit layers offline and dynamically applies them online based on
navigation priors. Experiments on CODA, Waymo, and BOSCH show that Nav-EE
achieves accuracy comparable to full inference while reducing latency by up to
63.9%. Real-vehicle integration with Autoware Universe further demonstrates
reduced inference latency (600ms to 300ms), supporting faster decision-making
in complex scenarios. These results suggest that coupling navigation foresight
with early-exit offers a viable path toward efficient deployment of large
models in autonomous systems. Code and data are available at our anonymous
repository: https://anonymous.4open.science/r/Nav-EE-BBC4

</details>


### [46] [What Matters in RL-Based Methods for Object-Goal Navigation? An Empirical Study and A Unified Framework](https://arxiv.org/abs/2510.01830)
*Hongze Wang,Boyang Sun,Jiaxu Xing,Fan Yang,Marco Hutter,Dhruv Shah,Davide Scaramuzza,Marc Pollefeys*

Main category: cs.RO

TL;DR: 本研究深入分析了模块化RL在目标导航中的表现，识别出感知质量和测试策略为主要性能驱动因素，提出了设计指导并展示了新的系统性能提升。


<details>
  <summary>Details</summary>
Motivation: 在复杂和不受控的环境中部署移动机器人，成功需要集成语义理解、空间推理和长期规划，而当前强化学习方法尚未清晰证明哪些组件真正推动性能。

Method: 进行了大规模的实证研究，分解了ObjectNav系统的三个关键组件：感知、策略和测试增强，采用了广泛的控制实验来隔离每个组件的贡献。

Result: 提出了一种增强的模块化系统，在SPL上超越了现有最先进（SotA）方法6.6%和2.7%的成功率，而专家在相同条件下实现了98%的平均成功率，突显了RL代理与人类水平导航之间的差距。

Conclusion: 这项研究通过对模块化强化学习（RL）基于目标导航系统的深入分析，提高了性能并为未来的ObjectNav发展提供了指导。

Abstract: Object-Goal Navigation (ObjectNav) is a critical component toward deploying
mobile robots in everyday, uncontrolled environments such as homes, schools,
and workplaces. In this context, a robot must locate target objects in
previously unseen environments using only its onboard perception. Success
requires the integration of semantic understanding, spatial reasoning, and
long-horizon planning, which is a combination that remains extremely
challenging. While reinforcement learning (RL) has become the dominant
paradigm, progress has spanned a wide range of design choices, yet the field
still lacks a unifying analysis to determine which components truly drive
performance. In this work, we conduct a large-scale empirical study of modular
RL-based ObjectNav systems, decomposing them into three key components:
perception, policy, and test-time enhancement. Through extensive controlled
experiments, we isolate the contribution of each and uncover clear trends:
perception quality and test-time strategies are decisive drivers of
performance, whereas policy improvements with current methods yield only
marginal gains. Building on these insights, we propose practical design
guidelines and demonstrate an enhanced modular system that surpasses
State-of-the-Art (SotA) methods by 6.6% on SPL and by a 2.7% success rate. We
also introduce a human baseline under identical conditions, where experts
achieve an average 98% success, underscoring the gap between RL agents and
human-level navigation. Our study not only sets the SotA performance but also
provides principled guidance for future ObjectNav development and evaluation.

</details>


### [47] [Like Playing a Video Game: Spatial-Temporal Optimization of Foot Trajectories for Controlled Football Kicking in Bipedal Robots](https://arxiv.org/abs/2510.01843)
*Wanyue Li,Ji Ma,Minghao Lu,Peng Lu*

Main category: cs.RO

TL;DR: 本研究通过应用空间-时间轨迹规划方法于双足机器人，实现了高效的踢球轨迹生成，优化了稳定性和精确度，且实验结果显示接近完美的任务完成率。


<details>
  <summary>Details</summary>
Motivation: 现有的传统控制方法和强化学习在解决双足机器人在足球运动中面临的稳定性和精确度问题上存在重大局限性，因此需要探索一种更有效的轨迹规划方法。

Method: 使用空间-时间轨迹规划方法，生成符合目标射门位置、速度和加速度约束的脚部运动轨迹，同时优化摆动阶段的持续时间。

Result: 通过实验验证，优化的运动轨迹与人类踢球行为相近，且在-90度到90度的射门范围内，算法表现出高度的效率和可靠性。

Conclusion: 该研究通过创新性地应用空间-时间轨迹规划方法于双足机器人系统，实现了优化的脚部运动轨迹，能够高效、精准地完成射门任务，且轨迹规划时间小于1毫秒，任务完成率接近100%。

Abstract: Humanoid robot soccer presents several challenges, particularly in
maintaining system stability during aggressive kicking motions while achieving
precise ball trajectory control. Current solutions, whether traditional
position-based control methods or reinforcement learning (RL) approaches,
exhibit significant limitations. Model predictive control (MPC) is a prevalent
approach for ordinary quadruped and biped robots. While MPC has demonstrated
advantages in legged robots, existing studies often oversimplify the leg swing
progress, relying merely on simple trajectory interpolation methods. This
severely constrains the foot's environmental interaction capability, hindering
tasks such as ball kicking. This study innovatively adapts the spatial-temporal
trajectory planning method, which has been successful in drone applications, to
bipedal robotic systems. The proposed approach autonomously generates foot
trajectories that satisfy constraints on target kicking position, velocity, and
acceleration while simultaneously optimizing swing phase duration. Experimental
results demonstrate that the optimized trajectories closely mimic human kicking
behavior, featuring a backswing motion. Simulation and hardware experiments
confirm the algorithm's efficiency, with trajectory planning times under 1 ms,
and its reliability, achieving nearly 100 % task completion accuracy when the
soccer goal is within the range of -90{\deg} to 90{\deg}.

</details>


### [48] [GreenhouseSplat: A Dataset of Photorealistic Greenhouse Simulations for Mobile Robotics](https://arxiv.org/abs/2510.01848)
*Diram Tabaa,Gianni Di Caro*

Main category: cs.RO

TL;DR: 本研究推出了GreenhouseSplat框架，利用RGB图像生成真实感温室资产，推动农业机器人领域的发展。


<details>
  <summary>Details</summary>
Motivation: 模拟温室环境对农业机器人系统的开发和评估至关重要，但现有方法的简化资产限制了仿真与现实的转移。

Method: 本研究提出了GreenhouseSplat框架，使用低成本RGB图像生成真实感温室资产，并与ROS仿真集成，支持相机和LiDAR渲染。

Result: 构建了一个包含82个黄瓜植物的数据集，验证了其在机器人评估中的实用性。

Conclusion: GreenhouseSplat为温室规模的辐射场仿真奠定了基础，提升了农业机器人研究的可能性。

Abstract: Simulating greenhouse environments is critical for developing and evaluating
robotic systems for agriculture, yet existing approaches rely on simplistic or
synthetic assets that limit simulation-to-real transfer. Recent advances in
radiance field methods, such as Gaussian splatting, enable photorealistic
reconstruction but have so far been restricted to individual plants or
controlled laboratory conditions. In this work, we introduce GreenhouseSplat, a
framework and dataset for generating photorealistic greenhouse assets directly
from inexpensive RGB images. The resulting assets are integrated into a
ROS-based simulation with support for camera and LiDAR rendering, enabling
tasks such as localization with fiducial markers. We provide a dataset of 82
cucumber plants across multiple row configurations and demonstrate its utility
for robotics evaluation. GreenhouseSplat represents the first step toward
greenhouse-scale radiance-field simulation and offers a foundation for future
research in agricultural robotics.

</details>


### [49] [TACOS: Task Agnostic COordinator of a multi-drone System](https://arxiv.org/abs/2510.01869)
*Alessandro Nazzari,Roberto Rubinacci,Marco Lovera*

Main category: cs.RO

TL;DR: 本文提出TACOS框架，实现了多无人机系统的高层次自然语言控制，通过集成多种关键能力，减轻了飞行员工作负担。


<details>
  <summary>Details</summary>
Motivation: 随着无人机系统复杂度增加，单一飞行员管理多无人机的任务要求更高的自主性和灵活的交互模式。

Method: 提出了TACOS框架，实现高层次自然语言控制多无人机系统，并集成自然语言接口、智能协调器和自主代理。

Result: 在真实的多无人机系统中演示了TACOS，进行了各模块贡献的消融研究。

Conclusion: TACOS框架通过自然语言接口和智能协调功能有效提升了单一飞行员对多无人机系统的控制能力，支持高层次的任务分配与执行。

Abstract: When a single pilot is responsible for managing a multi-drone system, the
task demands varying levels of autonomy, from direct control of individual
UAVs, to group-level coordination, to fully autonomous swarm behaviors for
accomplishing high-level tasks. Enabling such flexible interaction requires a
framework that supports multiple modes of shared autonomy. As language models
continue to improve in reasoning and planning, they provide a natural
foundation for such systems, reducing pilot workload by enabling high-level
task delegation through intuitive, language-based interfaces. In this paper we
present TACOS (Task-Agnostic COordinator of a multi-drone System), a unified
framework that enables high-level natural language control of multi-UAV systems
through Large Language Models (LLMs). TACOS integrates three key capabilities
into a single architecture: a one-to-many natural language interface for
intuitive user interaction, an intelligent coordinator for translating user
intent into structured task plans, and an autonomous agent that executes plans
interacting with the real-world. TACOS allows a LLM to interact with a library
of executable APIs, bridging semantic reasoning with real-time multi-robot
coordination. We demonstrate the system in real-world multi-drone system and
conduct an ablation study to assess the contribution of each module.

</details>


### [50] [SPARC: Spine with Prismatic and Revolute Compliance for Quadruped Robot](https://arxiv.org/abs/2510.01984)
*Yue Wang*

Main category: cs.RO

TL;DR: SPARC是一个紧凑的脊柱模块，具备优秀的可编程阻抗控制，已通过实验验证其性能，适合四足机器人使用。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一个紧凑的、开放源码的脊柱模块，以便在四足机器人中实现有效的运动控制和适应性。

Method: 使用基于RNEA的计算加速度控制器并实现平滑的Stribeck摩擦补偿，验证了阻尼和刚度调节的效果。

Result: 通过实验验证SPARC的线性刚度和质量-弹簧-阻尼器响应，性能指标良好，能够支持各种实验研究。

Conclusion: SPARC系统为四足机器人提供了一种可编程的任务空间阻抗平台，能够有效研究脊柱顺应性，并具备良好的实验验证。

Abstract: We present SPARC, a compact, open-source 3-DoF sagittal-plane spine module
that combines revolute (pitch) and prismatic (axial) motion with programmable
task-space impedance for quadruped robots. The system integrates three
torque-controlled actuators, a custom 1 kHz control board, and a protected
power unit in a 1.26 kg package, enabling closed-loop stiffness and damping
shaping along x, z, and theta. We develop an RNEA-based computed-acceleration
controller with smooth Stribeck friction compensation to render spring-damper
behavior without explicit inertia shaping. Bench experiments validate the
approach. Quasi-static push-pull tests show linear force-displacement
characteristics with commanded horizontal stiffness spanning 300-700 N/m and <=
1.5% relative error (R^2 >= 0.992, narrow 95% CIs). Dynamic
displace-and-release trials confirm mass-spring-damper responses over multiple
damping settings, with small, interpretable phase deviations due to
configuration-dependent inertia and low-speed friction effects. A task-space PD
controller produces roughly linear stiffness but with greater variability and
coupling sensitivity. SPARC provides a portable platform for systematic studies
of spine compliance in legged locomotion and will be released with complete
hardware and firmware resources.

</details>


### [51] [EC3R-SLAM: Efficient and Consistent Monocular Dense SLAM with Feed-Forward 3D Reconstruction](https://arxiv.org/abs/2510.02080)
*Lingxiang Hu,Naima Ait Oufroukh,Fabien Bonardi,Raymond Ghandour*

Main category: cs.RO

TL;DR: 本研究提出EC3R-SLAM，一个新颖的单目密集SLAM框架，无需相机标定，实现高效的定位与映射，尤其适用于资源受限的平台。


<details>
  <summary>Details</summary>
Motivation: 现有的单目密集SLAM受限于高延迟、大GPU内存占用和相机标定的依赖，迫切需要一种高效的解决方案。

Method: 通过结合稀疏特征点的跟踪模块和前馈3D重建模型的映射模块，EC3R-SLAM实现了高定位和映射精度，同时估计相机内参。

Result: 实验结果表明，EC3R-SLAM在提供竞争性能的同时，比最新方法更快、更节省内存。

Conclusion: EC3R-SLAM在多个基准测试中表现出色，具有效率高、低延迟和低GPU内存消耗的特点，非常适合实际机器人应用。

Abstract: The application of monocular dense Simultaneous Localization and Mapping
(SLAM) is often hindered by high latency, large GPU memory consumption, and
reliance on camera calibration. To relax this constraint, we propose EC3R-SLAM,
a novel calibration-free monocular dense SLAM framework that jointly achieves
high localization and mapping accuracy, low latency, and low GPU memory
consumption. This enables the framework to achieve efficiency through the
coupling of a tracking module, which maintains a sparse map of feature points,
and a mapping module based on a feed-forward 3D reconstruction model that
simultaneously estimates camera intrinsics. In addition, both local and global
loop closures are incorporated to ensure mid-term and long-term data
association, enforcing multi-view consistency and thereby enhancing the overall
accuracy and robustness of the system. Experiments across multiple benchmarks
show that EC3R-SLAM achieves competitive performance compared to
state-of-the-art methods, while being faster and more memory-efficient.
Moreover, it runs effectively even on resource-constrained platforms such as
laptops and Jetson Orin NX, highlighting its potential for real-world robotics
applications.

</details>


### [52] [LangGrasp: Leveraging Fine-Tuned LLMs for Language Interactive Robot Grasping with Ambiguous Instructions](https://arxiv.org/abs/2510.02104)
*Yunhan Lin,Wenqi Wu,Zhijie Zhang,Huasong Min*

Main category: cs.RO

TL;DR: LangGrasp是一个新的语言互动机器人抓取框架，通过使用大型语言模型与点云定位，提升了机器人在处理模糊指令时的抓取精度与任务执行效率。


<details>
  <summary>Details</summary>
Motivation: 现有的语言驱动抓取方法难以处理含有隐性意图的模糊指令，亟需一种新方法来提高机器人抓取能力。

Method: 该框架整合了微调的大型语言模型和点云定位模块，通过2D部件分割实现场景中的局部点云定位。

Result: 实验结果表明，LangGrasp能够准确识别模糊指令中的隐性意图，并动态选择最优抓取姿态。

Conclusion: LangGrasp框架有效解决了含有隐性意图的模糊指令问题，提升了机器人在非结构化环境中的抓取精度和任务执行效率。

Abstract: The existing language-driven grasping methods struggle to fully handle
ambiguous instructions containing implicit intents. To tackle this challenge,
we propose LangGrasp, a novel language-interactive robotic grasping framework.
The framework integrates fine-tuned large language models (LLMs) to leverage
their robust commonsense understanding and environmental perception
capabilities, thereby deducing implicit intents from linguistic instructions
and clarifying task requirements along with target manipulation objects.
Furthermore, our designed point cloud localization module, guided by 2D part
segmentation, enables partial point cloud localization in scenes, thereby
extending grasping operations from coarse-grained object-level to fine-grained
part-level manipulation. Experimental results show that the LangGrasp framework
accurately resolves implicit intents in ambiguous instructions, identifying
critical operations and target information that are unstated yet essential for
task completion. Additionally, it dynamically selects optimal grasping poses by
integrating environmental information. This enables high-precision grasping
from object-level to part-level manipulation, significantly enhancing the
adaptability and task execution efficiency of robots in unstructured
environments. More information and code are available here:
https://github.com/wu467/LangGrasp.

</details>


### [53] [Stand Up, NAO! Increasing the Reliability of Stand-Up Motions Through Error Compensation in Position Control](https://arxiv.org/abs/2510.02129)
*Philip Reichenberg,Tim Laue*

Main category: cs.RO

TL;DR: 本文提出的NAO机器人站立动作通过解决关节位置误差问题，显著提高了站立成功率，并被多个团队采用。


<details>
  <summary>Details</summary>
Motivation: 确保机器人能够独立站立，以提高在足球比赛中的表现，避免因无法站立而被暂停。

Method: 针对机器人关节位置的偏差问题，采用特殊动作释放卡住的肢体，并用其他关节进行补偿。

Result: 通过优化站立动作，成功率显著提升，多个团队在比赛中也达到了类似的成功率。

Conclusion: 我们的站立动作显著提高了NAO机器人在比赛中的成功率，并得到多个团队的应用和验证。

Abstract: Stand-up motions are an indispensable part of humanoid robot soccer. A robot
incapable of standing up by itself is removed from the game for some time. In
this paper, we present our stand-up motions for the NAO robot. Our approach
dates back to 2019 and has been evaluated and slightly expanded over the past
six years. We claim that the main reason for failed stand-up attempts are large
errors in the executed joint positions. By addressing such problems by either
executing special motions to free up stuck limbs such as the arms, or by
compensating large errors with other joints, we significantly increased the
overall success rate of our stand-up routine. The motions presented in this
paper are also used by several other teams in the Standard Platform League,
which thereby achieve similar success rates, as shown in an analysis of videos
from multiple tournaments.

</details>


### [54] [SCANS: A Soft Gripper with Curvature and Spectroscopy Sensors for In-Hand Material Differentiation](https://arxiv.org/abs/2510.02164)
*Nathaniel Hanson,Austin Allison,Charles DiMarzio,Taşkın Padır,Kristen L. Dorsey*

Main category: cs.RO

TL;DR: SCANS系统是一个创新的软操控器，能够在无电子驱动的情况下，为软机器人提供先进的光谱感知能力，帮助区分多种材料。


<details>
  <summary>Details</summary>
Motivation: 现有软机器人在光谱感知方面的能力有限，需要探索更广泛的感知能力以适应多样化的材料分类。

Method: 软操控器通过流体驱动实现，无需电子部件，采用线性判别分析评估物体的光谱特性。

Result: 实验显示SCANS系统能够对金属、木材、塑料、有机物、纸张和泡沫等不同物体进行有效的光谱分析，尤其在近红外波长下表现出优异的敏感性。

Conclusion: SCANS系统提高了软机器人在光学传感方面的多功能性，能够有效区分不同材料的物品。

Abstract: We introduce the soft curvature and spectroscopy (SCANS) system: a versatile,
electronics-free, fluidically actuated soft manipulator capable of assessing
the spectral properties of objects either in hand or through pre-touch caging.
This platform offers a wider spectral sensing capability than previous soft
robotic counterparts. We perform a material analysis to explore optimal soft
substrates for spectral sensing, and evaluate both pre-touch and in-hand
performance. Experiments demonstrate explainable, statistical separation across
diverse object classes and sizes (metal, wood, plastic, organic, paper, foam),
with large spectral angle differences between items. Through linear
discriminant analysis, we show that sensitivity in the near-infrared
wavelengths is critical to distinguishing visually similar objects. These
capabilities advance the potential of optics as a multi-functional sensory
modality for soft robots. The complete parts list, assembly guidelines, and
processing code for the SCANS gripper are accessible at:
https://parses-lab.github.io/scans/.

</details>


### [55] [Product Digital Twin Supporting End-of-life Phase of Electric Vehicle Batteries Utilizing Product-Process-Resource Asset Network](https://arxiv.org/abs/2510.02167)
*Sara Strakosova,Petr Novak,Petr Kadera*

Main category: cs.RO

TL;DR: 本文提出利用数字双胞胎技术和双流产品-过程-资源资产网络（Bi-PAN）模型优化电动车电池的拆解过程，以促进循环经济中的再制造和回收。


<details>
  <summary>Details</summary>
Motivation: 在循环经济背景下，产品生命周期结束时应关注再制造或回收，但生产商对于相关数据的分享不足，影响了这些过程的实施。

Method: 通过产品数字双胞胎技术，结合双流产品-过程-资源资产网络（Bi-PAN）模型，对电动车电池实施拆解案例研究。

Result: 通过应用产品数字双胞胎，能够灵活且高效地解决电动车电池的拆解挑战，并支持更可持续的环境管理。

Conclusion: 提出的双流产品-过程-资源资产网络（Bi-PAN）模型可以优化电动车电池的拆解过程，从而支持循环经济相关的再制造和回收过程。

Abstract: In the context of the circular economy, products in their end-of-life phase
should be either remanufactured or recycled. Both of these processes are
crucial for sustainability and environmental conservation. However,
manufacturers often do not support these processes enough by not sharing
relevant data. This paper proposes use of a digital twin technology, which is
capable to help optimizing the disassembly processes to reduce ecological
impact and enhance sustainability. The proposed approach is demonstrated
through a disassembly use-case of the product digital twin of an electric
vehicle battery. By utilizing product digital twins, challenges associated with
the disassembly of electric vehicle batteries can be solved flexibly and
efficiently for various battery types. As a backbone for the product digital
twin representation, the paper uses the paradigm of product-process-resource
asset networks (PAN). Such networks enable to model relevant relationships
across products, production resources, manufacturing processes, and specific
production operations that have to be done in the manufacturing phase of a
product. This paper introduces a Bi-Flow Product-Process-Resource Asset Network
(Bi-PAN) representation, which extends the PAN paradigm to cover not only the
manufacturing, but also the remanufacturing/recycling phase.

</details>


### [56] [DisCo-Layout: Disentangling and Coordinating Semantic and Physical Refinement in a Multi-Agent Framework for 3D Indoor Layout Synthesis](https://arxiv.org/abs/2510.02178)
*Jialin Gao,Donghao Zhou,Mingjian Liang,Lihao Liu,Chi-Wing Fu,Xiaowei Hu,Pheng-Ann Heng*

Main category: cs.RO

TL;DR: DisCo-Layout是一个新框架，通过语义和物理优化工具，生成高质量的3D室内布局。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法在数据集固定下的泛化问题，以及LLM和VLM方法在布局优化中的不足。

Method: 使用语义和物理两个独立的工具（SRT和PRT），结合多智能体框架进行协同优化。

Result: DisCo-Layout能够有效修正抽象对象关系和具体空间问题，表现出前沿的性能。

Conclusion: DisCo-Layout展示了在生成真实、连贯和可泛化的3D室内布局方面的卓越性能。

Abstract: 3D indoor layout synthesis is crucial for creating virtual environments.
Traditional methods struggle with generalization due to fixed datasets. While
recent LLM and VLM-based approaches offer improved semantic richness, they
often lack robust and flexible refinement, resulting in suboptimal layouts. We
develop DisCo-Layout, a novel framework that disentangles and coordinates
physical and semantic refinement. For independent refinement, our Semantic
Refinement Tool (SRT) corrects abstract object relationships, while the
Physical Refinement Tool (PRT) resolves concrete spatial issues via a
grid-matching algorithm. For collaborative refinement, a multi-agent framework
intelligently orchestrates these tools, featuring a planner for placement
rules, a designer for initial layouts, and an evaluator for assessment.
Experiments demonstrate DisCo-Layout's state-of-the-art performance, generating
realistic, coherent, and generalizable 3D indoor layouts. Our code will be
publicly available.

</details>


### [57] [Performance-Guided Refinement for Visual Aerial Navigation using Editable Gaussian Splatting in FalconGym 2.0](https://arxiv.org/abs/2510.02248)
*Yan Miao,Ege Yuceel,Georgios Fainekos,Bardh Hoxha,Hideki Okamoto,Sayan Mitra*

Main category: cs.RO

TL;DR: 开发了FalconGym 2.0仿真框架并提出PGR算法，有效解决视觉策略过拟合问题，显著提升了模型的泛化能力和在实际应用中的表现。


<details>
  <summary>Details</summary>
Motivation: 解决现有视觉策略对单一轨道的过拟合问题，以及在轨道几何变化时性能下降的困境。

Method: 开发了一个基于高斯点云（GSplat）的仿真框架FalconGym 2.0，并提出了一种性能指导的改进算法（PGR），专注于高挑战性轨道进行视觉策略训练。

Result: 通过固定翼无人机和四旋翼案例研究，PGR训练的单一视觉策略在三个未见轨道上实现100%成功率，并在动态条件下显示出更高的成功率。

Conclusion: 使用PGR训练的视觉策略在FalconGym 2.0中实现了出色的泛化能力和鲁棒性，并能成功迁移到实际硬件。

Abstract: Visual policy design is crucial for aerial navigation. However,
state-of-the-art visual policies often overfit to a single track and their
performance degrades when track geometry changes. We develop FalconGym 2.0, a
photorealistic simulation framework built on Gaussian Splatting (GSplat) with
an Edit API that programmatically generates diverse static and dynamic tracks
in milliseconds. Leveraging FalconGym 2.0's editability, we propose a
Performance-Guided Refinement (PGR) algorithm, which concentrates visual
policy's training on challenging tracks while iteratively improving its
performance. Across two case studies (fixed-wing UAVs and quadrotors) with
distinct dynamics and environments, we show that a single visual policy trained
with PGR in FalconGym 2.0 outperforms state-of-the-art baselines in
generalization and robustness: it generalizes to three unseen tracks with 100%
success without per-track retraining and maintains higher success rates under
gate-pose perturbations. Finally, we demonstrate that the visual policy trained
with PGR in FalconGym 2.0 can be zero-shot sim-to-real transferred to a
quadrotor hardware, achieving a 98.6% success rate (69 / 70 gates) over 30
trials spanning two three-gate tracks and a moving-gate track.

</details>


### [58] [Retargeting Matters: General Motion Retargeting for Humanoid Motion Tracking](https://arxiv.org/abs/2510.02252)
*Joao Pedro Araujo,Yanjie Ze,Pei Xu,Jiajun Wu,C. Karen Liu*

Main category: cs.RO

TL;DR: 本论文研究人类动作重定向对类人机器人强化学习政策性能的影响，提出的一种新方法GMR在跟踪性能和忠实度上显著优于现有的其他方法。


<details>
  <summary>Details</summary>
Motivation: 解决当前人类动作数据重定向到类人机器人时存在的身体体现差距，特别是在重定向过程中引入的伪影问题。

Method: 通过提出新方法General Motion Retargeting (GMR)来改善运动重定向质量，并使用BeyondMimic进行政策训练，从而隔离重定向效果。

Result: 实验显示大多数动作可以被跟踪，但重定向数据中的伪影会显著降低策略的鲁棒性，尤其对于动态或长序列。

Conclusion: 提出的GMR方法在跟踪性能和忠实度方面优于现有的开源方法，达到了与闭源基准相近的感知保真度和策略成功率。

Abstract: Humanoid motion tracking policies are central to building teleoperation
pipelines and hierarchical controllers, yet they face a fundamental challenge:
the embodiment gap between humans and humanoid robots. Current approaches
address this gap by retargeting human motion data to humanoid embodiments and
then training reinforcement learning (RL) policies to imitate these reference
trajectories. However, artifacts introduced during retargeting, such as foot
sliding, self-penetration, and physically infeasible motion are often left in
the reference trajectories for the RL policy to correct. While prior work has
demonstrated motion tracking abilities, they often require extensive reward
engineering and domain randomization to succeed. In this paper, we
systematically evaluate how retargeting quality affects policy performance when
excessive reward tuning is suppressed. To address issues that we identify with
existing retargeting methods, we propose a new retargeting method, General
Motion Retargeting (GMR). We evaluate GMR alongside two open-source
retargeters, PHC and ProtoMotions, as well as with a high-quality closed-source
dataset from Unitree. Using BeyondMimic for policy training, we isolate
retargeting effects without reward tuning. Our experiments on a diverse subset
of the LAFAN1 dataset reveal that while most motions can be tracked, artifacts
in retargeted data significantly reduce policy robustness, particularly for
dynamic or long sequences. GMR consistently outperforms existing open-source
methods in both tracking performance and faithfulness to the source motion,
achieving perceptual fidelity and policy success rates close to the
closed-source baseline. Website:
https://jaraujo98.github.io/retargeting_matters. Code:
https://github.com/YanjieZe/GMR.

</details>


### [59] [Do You Know Where Your Camera Is? View-Invariant Policy Learning with Camera Conditioning](https://arxiv.org/abs/2510.02268)
*Tianchong Jiang,Jingtian Ji,Xiangshan Tan,Jiading Fang,Anand Bhattad,Vitor Guizilini,Matthew R. Walter*

Main category: cs.RO

TL;DR: 本研究通过条件化相机外部参数提高视图不变的模仿学习能力，对现有行为克隆政策的泛化进行了实验证明，提供了新任务和代码用于社区使用。


<details>
  <summary>Details</summary>
Motivation: 为了提高政策在不同视角下的泛化能力，特别是在真实视角变化的情况下。

Method: 使用Plucker嵌入对每个像素的光线进行建模，并在标准行为克隆政策中，包括ACT、Diffusion Policy和SmolVLA，条件化外部参数。

Result: 通过实验，我们发现没有外部参数的政策依赖静态背景的视觉线索，导致在工作区几何形状或相机位置变化时性能下降，而条件化外部参数可以恢复性能。

Conclusion: 通过显式地对政策进行相机外部条件化，增强了视图不变模仿学习的效果。

Abstract: We study view-invariant imitation learning by explicitly conditioning
policies on camera extrinsics. Using Plucker embeddings of per-pixel rays, we
show that conditioning on extrinsics significantly improves generalization
across viewpoints for standard behavior cloning policies, including ACT,
Diffusion Policy, and SmolVLA. To evaluate policy robustness under realistic
viewpoint shifts, we introduce six manipulation tasks in RoboSuite and
ManiSkill that pair "fixed" and "randomized" scene variants, decoupling
background cues from camera pose. Our analysis reveals that policies without
extrinsics often infer camera pose using visual cues from static backgrounds in
fixed scenes; this shortcut collapses when workspace geometry or camera
placement shifts. Conditioning on extrinsics restores performance and yields
robust RGB-only control without depth. We release the tasks, demonstrations,
and code at https://ripl.github.io/know_your_camera/ .

</details>


### [60] [ARMADA: Autonomous Online Failure Detection and Human Shared Control Empower Scalable Real-world Deployment and Adaptation](https://arxiv.org/abs/2510.02298)
*Wenye Yu,Jun Lv,Zixi Ying,Yang Jin,Chuan Wen,Cewu Lu*

Main category: cs.RO

TL;DR: ARMADA系统通过在线故障检测FLOAT，优化了多机器人部署，显著提升了成功率并降低了对人类监控的需求。


<details>
  <summary>Details</summary>
Motivation: 传统方法在缺乏足够领域数据时表现不佳，而人类收集的示范数据通常质量参差不齐，成本高。

Method: 提出了一种名为ARMADA的多机器人部署和适应系统，结合了人机协作共享控制和名为FLOAT的在线故障检测方法。

Result: ARMADA在四个真实世界任务中的表现卓越，FLOAT的故障检测准确率接近95%，政策成功率提高了4倍，人类干预率减少了2倍。

Conclusion: ARMADA系统显著提高了政策成功率，并减少了对人类干预的依赖，展示了在复杂环境中的有效性。

Abstract: Imitation learning has shown promise in learning from large-scale real-world
datasets. However, pretrained policies usually perform poorly without
sufficient in-domain data. Besides, human-collected demonstrations entail
substantial labour and tend to encompass mixed-quality data and redundant
information. As a workaround, human-in-the-loop systems gather domain-specific
data for policy post-training, and exploit closed-loop policy feedback to offer
informative guidance, but usually require full-time human surveillance during
policy rollout. In this work, we devise ARMADA, a multi-robot deployment and
adaptation system with human-in-the-loop shared control, featuring an
autonomous online failure detection method named FLOAT. Thanks to FLOAT, ARMADA
enables paralleled policy rollout and requests human intervention only when
necessary, significantly reducing reliance on human supervision. Hence, ARMADA
enables efficient acquisition of in-domain data, and leads to more scalable
deployment and faster adaptation to new scenarios. We evaluate the performance
of ARMADA on four real-world tasks. FLOAT achieves nearly 95% accuracy on
average, surpassing prior state-of-the-art failure detection approaches by over
20%. Besides, ARMADA manifests more than 4$\times$ increase in success rate and
greater than 2$\times$ reduction in human intervention rate over multiple
rounds of policy rollout and post-training, compared to previous
human-in-the-loop learning methods.

</details>
