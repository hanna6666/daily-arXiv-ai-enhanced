<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 19]
- [cs.HC](#cs.HC) [Total: 8]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Safe Path Planning and Observation Quality Enhancement Strategy for Unmanned Aerial Vehicles in Water Quality Monitoring Tasks](https://arxiv.org/abs/2512.21375)
*Yuanshuang Fu,Qianyao Wang,Qihao Wang,Bonan Zhang,Jiaxin Zhao,Yiming Cao,Zhijun Li*

Main category: cs.RO

TL;DR: 该论文提出了一种针对动态光影干扰的无人机路径规划方法，以提高水质监测的数据质量和飞行安全。


<details>
  <summary>Details</summary>
Motivation: 在变化的环境中，无人机在水质监测中遭遇光影干扰，导致数据可用性降低。本研究旨在解决这一问题。

Method: 构建动态预测模型将光影干扰转化为三维虚拟障碍，应用改进的干扰流体动力系统算法生成初始避障路径，并采用模型预测控制框架进行路径优化，设计动态飞行高度调整机制以提升空间分辨率。

Result: 在复杂照明环境下，所提方法在密集干扰场景中实现了98%的避障成功率，路径平滑度显著提高，有效观测数据量增加约27%。

Conclusion: 本研究为复杂光照环境下的精确无人机水质监测提供了有效的工程解决方案。

Abstract: Unmanned Aerial Vehicle (UAV) spectral remote sensing technology is widely used in water quality monitoring. However, in dynamic environments, varying illumination conditions, such as shadows and specular reflection (sun glint), can cause severe spectral distortion, thereby reducing data availability. To maximize the acquisition of high-quality data while ensuring flight safety, this paper proposes an active path planning method for dynamic light and shadow disturbance avoidance. First, a dynamic prediction model is constructed to transform the time-varying light and shadow disturbance areas into three-dimensional virtual obstacles. Second, an improved Interfered Fluid Dynamical System (IFDS) algorithm is introduced, which generates a smooth initial obstacle avoidance path by building a repulsive force field. Subsequently, a Model Predictive Control (MPC) framework is employed for rolling-horizon path optimization to handle flight dynamics constraints and achieve real-time trajectory tracking. Furthermore, a Dynamic Flight Altitude Adjustment (DFAA) mechanism is designed to actively reduce the flight altitude when the observable area is narrow, thereby enhancing spatial resolution. Simulation results show that, compared with traditional PID and single obstacle avoidance algorithms, the proposed method achieves an obstacle avoidance success rate of 98% in densely disturbed scenarios, significantly improves path smoothness, and increases the volume of effective observation data by approximately 27%. This research provides an effective engineering solution for precise UAV water quality monitoring in complex illumination environments.

</details>


### [2] [Fast Navigation Through Occluded Spaces via Language-Conditioned Map Prediction](https://arxiv.org/abs/2512.21398)
*Rahul Moorthy Mahesh,Oguzhan Goktug Poyrazoglu,Yukang Cao,Volkan Isler*

Main category: cs.RO

TL;DR: 本文提出了一种利用协助指令的运动规划器PaceForecaster，可在复杂环境中更安全、迅速地规划路径。


<details>
  <summary>Details</summary>
Motivation: 在复杂环境中，运动规划面临安全与速度之间的权衡，特别是在存在遮挡和传感器范围限制的情况下。

Method: PaceForecaster结合机器人局部传感器信息和协助指令，预测可见区域地图，并生成目标指向的子目标，以指导规划。

Result: 与仅使用局部地图的基线相比，集成PaceForecaster的导航性能在多边形环境中提升了36%。

Conclusion: 引入语言指令的预测和目标显著改善了机器人的导航能力。

Abstract: In cluttered environments, motion planners often face a trade-off between safety and speed due to uncertainty caused by occlusions and limited sensor range. In this work, we investigate whether co-pilot instructions can help robots plan more decisively while remaining safe. We introduce PaceForecaster, as an approach that incorporates such co-pilot instructions into local planners. PaceForecaster takes the robot's local sensor footprint (Level-1) and the provided co-pilot instructions as input and predicts (i) a forecasted map with all regions visible from Level-1 (Level-2) and (ii) an instruction-conditioned subgoal within Level-2. The subgoal provides the planner with explicit guidance to exploit the forecasted environment in a goal-directed manner. We integrate PaceForecaster with a Log-MPPI controller and demonstrate that using language-conditioned forecasts and goals improves navigation performance by 36% over a local-map-only baseline while in polygonal environments.

</details>


### [3] [Developing a Fundamental Diagram for Urban Air Mobility Based on Physical Experiments](https://arxiv.org/abs/2512.21425)
*Hang Zhou,Yuhui Zhai,Shiyu Shen,Yanfeng Ouyang,Xiaowei Shi,Xiaopeng*

Main category: cs.RO

TL;DR: 本研究提出了构建UAM交通基本图的框架，通过理论与实验结合，确认传统FD结构适用于UAM，并强调实验验证的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着无人机密度的增加，UAM运营可能会经历类似地面交通的拥堵，但目前UAM交通流的基本特征尚未得到充分理解。

Method: 通过整合理论分析与物理实验构建UAM交通的基本图，并设计无人机控制法则与基于仿真的交通生成方法。

Result: 收集的仿真和物理测试轨迹数据被组织成UAMTra2Flow数据集，初步结果表明传统地面交通的FD结构同样适用于UAM系统，并且从物理实验中得到的FD曲线与仿真结果存在偏差。

Conclusion: 涉及实验验证的重要性，最终将缩小规模测试的数据结果扩展至现实操作条件，为未来的UAM交通系统提供实用见解。

Abstract: Urban Air Mobility (UAM) is an emerging application of unmanned aerial vehicles (UAVs) that promises to reduce travel time and alleviate congestion in urban transportation systems. As drone density increases, UAM operations are expected to experience congestion similar to that in ground traffic. However, the fundamental characteristics of UAM traffic flow, particularly under real-world operating conditions, remain poorly understood. This study proposes a general framework for constructing the fundamental diagram (FD) of UAM traffic by integrating theoretical analysis with physical experiments. To the best of our knowledge, this is the first study to derive a UAM FD using real-world physical test data. On the theoretical side, we design two drone control laws for collision avoidance and develop simulation-based traffic generation methods to produce diverse UAM traffic scenarios. Based on Edie's definition, traffic flow theory is then applied to construct the FD and characterize the macroscopic properties of UAM traffic. To account for real-world disturbances and modeling uncertainties, we further conduct physical experiments on a reduced-scale testbed using Bitcraze Crazyflie drones. Both simulation and physical test trajectory data are collected and organized into the UAMTra2Flow dataset, which is analyzed using the proposed framework. Preliminary results indicate that classical FD structures for ground transportation are also applicable to UAM systems. Notably, FD curves obtained from physical experiments exhibit deviations from simulation-based results, highlighting the importance of experimental validation. Finally, results from the reduced-scale testbed are scaled to realistic operating conditions to provide practical insights for future UAM traffic systems. The dataset and code for this paper are publicly available at https://github.com/CATS-Lab/UAM-FD.

</details>


### [4] [EVE: A Generator-Verifier System for Generative Policies](https://arxiv.org/abs/2512.21430)
*Yusuf Ali,Gryphon Patlin,Karthik Kothuri,Muhammad Zubair Irshad,Wuwei Liang,Zsolt Kira*

Main category: cs.RO

TL;DR: EVE是一个模块化的生成-验证交互框架，通过零-shot验证者在测试时增强生成政策的性能，无需额外训练。


<details>
  <summary>Details</summary>
Motivation: 探索如何利用生成-验证框架提升生成政策性能，尤其是在面对分布变化的情况下，降低成本和减少微调需求。

Method: 引入EVE框架，将预训练生成政策与多个零-shot VLM基础的验证者代理相结合，以在测试时提升政策表现。

Result: 在各种操作任务中，EVE显著提高了成功率，并在设计选择上提供了可扩展的生成-验证系统构建指南。

Conclusion: EVE通过无额外训练提升了预训练生成政策在测试时的表现，且在多种操作任务中 consistently提高了任务成功率。

Abstract: Visuomotor policies based on generative architectures such as diffusion and flow-based matching have shown strong performance but degrade under distribution shifts, demonstrating limited recovery capabilities without costly finetuning. In the language modeling domain, test-time compute scaling has revolutionized reasoning capabilities of modern LLMs by leveraging additional inference-time compute for candidate solution refinement. These methods typically leverage foundation models as verification modules in a zero-shot manner to synthesize improved candidate solutions. In this work, we hypothesize that generative policies can similarly benefit from additional inference-time compute that employs zero-shot VLM-based verifiers. A systematic analysis of improving policy performance through the generation-verification framework remains relatively underexplored in the current literature. To this end, we introduce EVE - a modular, generator-verifier interaction framework - that boosts the performance of pretrained generative policies at test time, with no additional training. EVE wraps a frozen base policy with multiple zero-shot, VLM-based verifier agents. Each verifier proposes action refinements to the base policy candidate actions, while an action incorporator fuses the aggregated verifier output into the base policy action prediction to produce the final executed action. We study design choices for generator-verifier information interfacing across a system of verifiers with distinct capabilities. Across a diverse suite of manipulation tasks, EVE consistently improves task success rates without any additional policy training. Through extensive ablations, we isolate the contribution of verifier capabilities and action incorporator strategies, offering practical guidelines to build scalable, modular generator-verifier systems for embodied control.

</details>


### [5] [Planetary Terrain Datasets and Benchmarks for Rover Path Planning](https://arxiv.org/abs/2512.21438)
*Marvin Chancán,Avijit Banerjee,George Nikolakopoulos*

Main category: cs.RO

TL;DR: 本文提出了MarsPlanBench和MoonPlanBench两个大型基准数据集，评估了传统和学习路径规划算法在行星地形上的表现，结果显示传统算法在复杂地形中成功率高。


<details>
  <summary>Details</summary>
Motivation: 当前行星探测任务的数据未被充分利用，缺乏针对路径规划的行星数据集、标准化基准和评估协议。

Method: 通过高分辨率数字地形图构建MarsPlanBench和MoonPlanBench数据集，并在统一框架下评估经典和学习的路径规划算法。

Result: 传统算法在月球北极和南极等复杂地形上的全球路径规划成功率可达100%，而学习模型在复杂环境中的普适性仍需提高。

Conclusion: 传统路径规划算法在月球极地等复杂地形上表现优异，而基于学习的模型在复杂环境中尚需改进。

Abstract: Planetary rover exploration is attracting renewed interest with several upcoming space missions to the Moon and Mars. However, a substantial amount of data from prior missions remain underutilized for path planning and autonomous navigation research. As a result, there is a lack of space mission-based planetary datasets, standardized benchmarks, and evaluation protocols. In this paper, we take a step towards coordinating these three research directions in the context of planetary rover path planning. We propose the first two large planar benchmark datasets, MarsPlanBench and MoonPlanBench, derived from high-resolution digital terrain images of Mars and the Moon. In addition, we set up classical and learned path planning algorithms, in a unified framework, and evaluate them on our proposed datasets and on a popular planning benchmark. Through comprehensive experiments, we report new insights on the performance of representative path planning algorithms on planetary terrains, for the first time to the best of our knowledge. Our results show that classical algorithms can achieve up to 100% global path planning success rates on average across challenging terrains such as Moon's north and south poles. This suggests, for instance, why these algorithms are used in practice by NASA. Conversely, learning-based models, although showing promising results in less complex environments, still struggle to generalize to planetary domains. To serve as a starting point for fundamental path planning research, our code and datasets will be released at: https://github.com/mchancan/PlanetaryPathBench.

</details>


### [6] [Spatiotemporal Tubes for Probabilistic Temporal Reach-Avoid-Stay Task in Uncertain Dynamic Environment](https://arxiv.org/abs/2512.21497)
*Siddhartha Upadhyay,Ratnangshu Das,Pushpak Jagtap*

Main category: cs.RO

TL;DR: 该论文扩展了时间空间管框架，以解决动态环境下的概率时间到达-避开-停留任务，提供了正式的概率安全保证。


<details>
  <summary>Details</summary>
Motivation: 在动态环境中，存在不确定障碍物带来的安全问题，因此需要一种新的方法来保证任务的顺利完成与安全性。

Method: 提出了一种实时管道合成程序，通过时间变化的不确定障碍物和感知信息，形成一个时间变化的状态空间球体，并导出了不需要近似的控制律。

Result: 该方法确保系统轨迹在管道内，保证了概率安全性和任务履行。通过仿真和硬件实验验证了框架的有效性和可扩展性。

Conclusion: 所提出的方法是无模型、无近似和无优化的，能有效地在复杂环境中实时运行并确保收敛到目标。

Abstract: In this work, we extend the Spatiotemporal Tube (STT) framework to address Probabilistic Temporal Reach-Avoid-Stay (PrT-RAS) tasks in dynamic environments with uncertain obstacles. We develop a real-time tube synthesis procedure that explicitly accounts for time-varying uncertain obstacles and provides formal probabilistic safety guarantees. The STT is formulated as a time-varying ball in the state space whose center and radius evolve online based on uncertain sensory information. We derive a closed-form, approximation-free control law that confines the system trajectory within the tube, ensuring both probabilistic safety and task satisfaction. Our method offers a formal guarantee for probabilistic avoidance and finite-time task completion. The resulting controller is model-free, approximation-free, and optimization-free, enabling efficient real-time execution while guaranteeing convergence to the target. The effectiveness and scalability of the framework are demonstrated through simulation studies and hardware experiments on mobile robots, a UAV, and a 7-DOF manipulator navigating in cluttered and uncertain environments.

</details>


### [7] [A Novel Robotic Variable Stiffness Mechanism Based on Helically Wound Structured Electrostatic Layer Jamming](https://arxiv.org/abs/2512.21534)
*Congrui Bai,Zhenting Du,Weibang Bai*

Main category: cs.RO

TL;DR: 本文提出了一种新的可变刚度机制HWS-ELJ，并展示其在机器人手指设计中的应用及其有效性。


<details>
  <summary>Details</summary>
Motivation: 开发一种新型的可变刚度机制以应用于机器人手指设计。

Method: 提出了螺旋缠绕结构电静电层粘弹性机制（HWS-ELJ），利用电静电吸引增强层间摩擦，从而控制刚度调整。

Result: 通过不同初始力条件下的实验测试，验证了HWS-ELJ的刚度调节特性，结果符合理论趋势。

Conclusion: 开发的集成HWS-ELJ的机器人手指原型展示了电压驱动的刚度调节，证明了所提议的可变刚度机制的可行性。

Abstract: This paper introduces a novel variable stiffness mechanism termed Helically Wound Structured Electrostatic Layer Jamming (HWS-ELJ) and systematically investigates its potential applications in variable stiffness robotic finger design. The proposed method utilizes electrostatic attraction to enhance interlayer friction, thereby suppressing relative sliding and enabling tunable stiffness. Compared with conventional planar ELJ, the helical configuration of HWS-ELJ provides exponentially increasing stiffness adjustment with winding angle, achieving significantly greater stiffness enhancement for the same electrode contact area while reducing the required footprint under equivalent stiffness conditions. Considering the practical advantage of voltage-based control, a series of experimental tests under different initial force conditions were conducted to evaluate the stiffness modulation characteristics of HWS-ELJ. The results demonstrated its rational design and efficacy, with outcomes following the deduced theoretical trends. Furthermore, a robotic finger prototype integrating HWS-ELJ was developed, demonstrating voltage-driven stiffness modulation and confirming the feasibility of the proposed robotic variable stiffness mechanism.

</details>


### [8] [World-Coordinate Human Motion Retargeting via SAM 3D Body](https://arxiv.org/abs/2512.21573)
*Zhangzheng Tu,Kailun Su,Shaolong Zhu,Yukun Zheng*

Main category: cs.RO

TL;DR: 提出一种轻量级框架，通过结构化的人体表示和物理约束，从单目视频中恢复稳定的人体运动并实现可靠的机器人重定向。


<details>
  <summary>Details</summary>
Motivation: 从单目视频中恢复世界坐标的人体运动对于具身智能和机器人技术至关重要。

Method: 提出一种轻量级的工程导向框架，利用SAM 3D Body作为感知后端，并使用Momentum HumanRig作为机器人友好的中间表示。

Result: 在真实单目视频上的结果表明，方法具有稳定的世界轨迹和可靠的机器人重定向。

Conclusion: 结构化的人体表示与轻量物理约束相结合，可以从单目输入中生成适合机器人使用的运动。

Abstract: Recovering world-coordinate human motion from monocular videos with humanoid robot retargeting is significant for embodied intelligence and robotics. To avoid complex SLAM pipelines or heavy temporal models, we propose a lightweight, engineering-oriented framework that leverages SAM 3D Body (3DB) as a frozen perception backbone and uses the Momentum HumanRig (MHR) representation as a robot-friendly intermediate. Our method (i) locks the identity and skeleton-scale parameters of per tracked subject to enforce temporally consistent bone lengths, (ii) smooths per-frame predictions via efficient sliding-window optimization in the low-dimensional MHR latent space, and (iii) recovers physically plausible global root trajectories with a differentiable soft foot-ground contact model and contact-aware global optimization. Finally, we retarget the reconstructed motion to the Unitree G1 humanoid using a kinematics-aware two-stage inverse kinematics pipeline. Results on real monocular videos show that our method has stable world trajectories and reliable robot retargeting, indicating that structured human representations with lightweight physical constraints can yield robot-ready motion from monocular input.

</details>


### [9] [AstraNav-Memory: Contexts Compression for Long Memory](https://arxiv.org/abs/2512.21627)
*Botao Ren,Junjun Hu,Xinda Xue,Minghua Luo,Jintao Chen,Haochen Bai,Liangliang You,Mu Xu*

Main category: cs.RO

TL;DR: 本研究提出了一种图像中心的记忆框架，通过高效的视觉上下文压缩模块与导航策略的结合，实现了长期隐式记忆，提高了在陌生环境中的探索能力和在熟悉环境中的路径缩短效果。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决传统对象中心记忆在鲁棒性和可扩展性上的限制，通过引入图像中心记忆框架，提升代理在各种环境中的导航能力。

Method: 提出了一种基于Qwen2.5-VL的导航策略与视觉上下文压缩模块相结合的图像中心记忆框架，建立在ViT主干上，利用冻结的DINOv3特征与轻量级的PixelUnshuffle+Conv模块。

Result: 在GOAT-Bench和HM3D-OVON上的实验结果表明，该方法在导航性能上达到了最先进水平，改善了陌生环境中的探索并缩短了熟悉环境中的路径。

Conclusion: 压缩的图像中心记忆为终身具身代理提供了一种实际和可扩展的接口，使其能够对长时间的视觉历史进行推理并以类人效率进行导航。

Abstract: Lifelong embodied navigation requires agents to accumulate, retain, and exploit spatial-semantic experience across tasks, enabling efficient exploration in novel environments and rapid goal reaching in familiar ones. While object-centric memory is interpretable, it depends on detection and reconstruction pipelines that limit robustness and scalability. We propose an image-centric memory framework that achieves long-term implicit memory via an efficient visual context compression module end-to-end coupled with a Qwen2.5-VL-based navigation policy. Built atop a ViT backbone with frozen DINOv3 features and lightweight PixelUnshuffle+Conv blocks, our visual tokenizer supports configurable compression rates; for example, under a representative 16$\times$ compression setting, each image is encoded with about 30 tokens, expanding the effective context capacity from tens to hundreds of images. Experimental results on GOAT-Bench and HM3D-OVON show that our method achieves state-of-the-art navigation performance, improving exploration in unfamiliar environments and shortening paths in familiar ones. Ablation studies further reveal that moderate compression provides the best balance between efficiency and accuracy. These findings position compressed image-centric memory as a practical and scalable interface for lifelong embodied agents, enabling them to reason over long visual histories and navigate with human-like efficiency.

</details>


### [10] [Structural Induced Exploration for Balanced and Scalable Multi-Robot Path Planning](https://arxiv.org/abs/2512.21654)
*Zikun Guo,Adeyinka P. Adedigba,Rammohan Mallipeddi,Heoncheol Lee*

Main category: cs.RO

TL;DR: 本研究提出了一种新颖的多机器人路径规划框架，利用结构先验提高任务分配的公平性和路径规划的整体效率，并在不同场景中进行了验证。


<details>
  <summary>Details</summary>
Motivation: 多机器人路径规划是一个复杂的组合问题，涉及在高效性与公平性之间的平衡，现有算法在复杂环境中存在收敛过早和规模扩展不足的问题。

Method: 引入结构诱导的探索框架，通过初始化时利用任务的空间分布来约束搜索空间，并在信息素更新规则中强调结构上有意义的连接，同时考虑任务的负载情况。

Result: 通过引入结构先验的多机器人路径规划框架提高了路径的紧凑性、稳定性和任务分配的公平性。

Conclusion: 该框架在多种基准场景中验证了其有效性，相比传统元启发式算法，有显著的性能提升，并具备较好的可扩展性和可解释性。

Abstract: Multi-robot path planning is a fundamental yet challenging problem due to its combinatorial complexity and the need to balance global efficiency with fair task allocation among robots. Traditional swarm intelligence methods, although effective on small instances, often converge prematurely and struggle to scale to complex environments. In this work, we present a structure-induced exploration framework that integrates structural priors into the search process of the ant colony optimization (ACO). The approach leverages the spatial distribution of the task to induce a structural prior at initialization, thereby constraining the search space. The pheromone update rule is then designed to emphasize structurally meaningful connections and incorporates a load-aware objective to reconcile the total travel distance with individual robot workload. An explicit overlap suppression strategy further ensures that tasks remain distinct and balanced across the team. The proposed framework was validated on diverse benchmark scenarios covering a wide range of instance sizes and robot team configurations. The results demonstrate consistent improvements in route compactness, stability, and workload distribution compared to representative metaheuristic baselines. Beyond performance gains, the method also provides a scalable and interpretable framework that can be readily applied to logistics, surveillance, and search-and-rescue applications where reliable large-scale coordination is essential.

</details>


### [11] [MAction-SocialNav: Multi-Action Socially Compliant Navigation via Reasoning-enhanced Prompt Tuning](https://arxiv.org/abs/2512.21722)
*Zishuo Wang,Xinyu Zhang,Zhuonan Liu,Tomohito Kawabata,Daeun Song,Xuesu Xiao,Ling Xiao*

Main category: cs.RO

TL;DR: MAction-SocialNav是一种新型的机器人社交合规导航模型，通过处理行为模糊性和提升推理能力，在决策质量和安全性上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 研究社交合规导航，以确保机器人在以人为中心的环境中安全且合适地移动。

Method: 提出了一种有效的视觉语言模型MAction-SocialNav，解决行为模糊性，通过新的元认知提示方法增强推理能力。

Result: 创建了一个多动作社交合规导航数据集，包含789个样本，设计五个评估指标，并证明MAction-SocialNav在社交推理性能和效率方面表现优异。

Conclusion: 相较于现有模型，MAction-SocialNav在决策质量和安全对齐方面取得了显著提升，同时保持了实时效率。

Abstract: Socially compliant navigation requires robots to move safely and appropriately in human-centered environments by respecting social norms. However, social norms are often ambiguous, and in a single scenario, multiple actions may be equally acceptable. Most existing methods simplify this problem by assuming a single correct action, which limits their ability to handle real-world social uncertainty. In this work, we propose MAction-SocialNav, an efficient vision language model for socially compliant navigation that explicitly addresses action ambiguity, enabling generating multiple plausible actions within one scenario. To enhance the model's reasoning capability, we introduce a novel meta-cognitive prompt (MCP) method. Furthermore, to evaluate the proposed method, we curate a multi-action socially compliant navigation dataset that accounts for diverse conditions, including crowd density, indoor and outdoor environments, and dual human annotations. The dataset contains 789 samples, each with three-turn conversation, split into 710 training samples and 79 test samples through random selection. We also design five evaluation metrics to assess high-level decision precision, safety, and diversity. Extensive experiments demonstrate that the proposed MAction-SocialNav achieves strong social reasoning performance while maintaining high efficiency, highlighting its potential for real-world human robot navigation. Compared with zero-shot GPT-4o and Claude, our model achieves substantially higher decision quality (APG: 0.595 vs. 0.000/0.025) and safety alignment (ER: 0.264 vs. 0.642/0.668), while maintaining real-time efficiency (1.524 FPS, over 3x faster).

</details>


### [12] [HELP: Hierarchical Embodied Language Planner for Household Tasks](https://arxiv.org/abs/2512.21723)
*Alexandr V. Korchemnyi,Anatoly O. Onishchenko,Eva A. Bakaeva,Alexey K. Kovalev,Aleksandr I. Panov*

Main category: cs.RO

TL;DR: 本文提出了一种新的层次化语言规划器HELP，通过多个LLM代理来解决复杂的实际任务，并在家庭场景中进行了有效性评估。


<details>
  <summary>Details</summary>
Motivation: 随着复杂场景的增多，现有的规划能力不足以应对自然语言指令，因此提出一种新的架构以充分利用LLM在语言理解上的优势。

Method: Hierarchical Embodied Language Planner (HELP)

Result: 通过一个集成多种任务的LLM代理来解决复杂场景中的任务

Conclusion: 提出的HELP架构在家庭任务中表现出有效性，并支持小参数的开源LLM进行自主应用

Abstract: Embodied agents tasked with complex scenarios, whether in real or simulated environments, rely heavily on robust planning capabilities. When instructions are formulated in natural language, large language models (LLMs) equipped with extensive linguistic knowledge can play this role. However, to effectively exploit the ability of such models to handle linguistic ambiguity, to retrieve information from the environment, and to be based on the available skills of an agent, an appropriate architecture must be designed. We propose a Hierarchical Embodied Language Planner, called HELP, consisting of a set of LLM-based agents, each dedicated to solving a different subtask. We evaluate the proposed approach on a household task and perform real-world experiments with an embodied agent. We also focus on the use of open source LLMs with a relatively small number of parameters, to enable autonomous deployment.

</details>


### [13] [MoonBot: Modular and On-Demand Reconfigurable Robot Toward Moon Base Construction](https://arxiv.org/abs/2512.21853)
*Kentaro Uno,Elian Neppel,Gustavo H. Diaz,Ashutosh Mishra,Shamistan Karimov,A. Sejal Jain,Ayesha Habib,Pascal Pama,Hazal Gozbasi,Shreya Santra,Kazuya Yoshida*

Main category: cs.RO

TL;DR: 本研究介绍了一种模块化的月球探索机器人MoonBot，并通过初步的现场演示验证了其概念的有效性。


<details>
  <summary>Details</summary>
Motivation: 探索和开发月球表面引起了全球的广泛关注，机器人在探索未知地形和建设人类居住环境中至关重要。

Method: 介绍了MoonBot，这是一种模块化和按需可重构的机器人系统，旨在在严格的质量约束下最大化功能。

Result: MoonBot在模拟建立月球基础设施的试验任务中证明了其概念的有效性，包括土木工程操作、基础设施组件运输和部署以及助力充气模块的操作。

Conclusion: 测试总结了宝贵的经验教训，尤其是在连接器设计方面，为未来的月球任务中的模块化机器人系统的进步提供了有价值的见解。

Abstract: The allure of lunar surface exploration and development has recently captured widespread global attention. Robots have proved to be indispensable for exploring uncharted terrains, uncovering and leveraging local resources, and facilitating the construction of future human habitats. In this article, we introduce the modular and on-demand reconfigurable robot (MoonBot), a modular and reconfigurable robotic system engineered to maximize functionality while operating within the stringent mass constraints of lunar payloads and adapting to varying environmental conditions and task requirements. This article details the design and development of MoonBot and presents a preliminary field demonstration that validates the proof of concept through the execution of milestone tasks simulating the establishment of lunar infrastructure. These tasks include essential civil engineering operations, infrastructural component transportation and deployment, and assistive operations with inflatable modules. Furthermore, we systematically summarize the lessons learned during testing, focusing on the connector design and providing valuable insights for the advancement of modular robotic systems in future lunar missions.

</details>


### [14] [Optimal Trajectory Planning for Orbital Robot Rendezvous and Docking](https://arxiv.org/abs/2512.21882)
*Kenta Iizuka,Akiyoshi Uchida,Kentaro Uno,Kazuya Yoshida*

Main category: cs.RO

TL;DR: 本研究提出了一种基于非线性优化的轨迹规划方法，旨在安全有效地接近并捕获旋转的空间 debris。


<details>
  <summary>Details</summary>
Motivation: 解决太空 debris 移除任务中，安全接近翻滚目标的难题。

Method: 基于非线性优化的轨迹规划方法，结合动态保持球以适应接近条件，和控制策略使用离散 ON/OFF 推进器复现优化轨迹。

Result: 实现了在接近翻滚 debris 目标时的更近和更安全的访问。

Conclusion: 该方法为旋转目标的捕获提供了新的可能性，并考虑了实际实施的约束。

Abstract: Approaching a tumbling target safely is a critical challenge in space debris removal missions utilizing robotic manipulators onboard servicing satellites. In this work, we propose a trajectory planning method based on nonlinear optimization for a close-range rendezvous to bring a free-floating, rotating debris object in a two-dimensional plane into the manipulator's workspace, as a preliminary step for its capture. The proposed method introduces a dynamic keep-out sphere that adapts depending on the approach conditions, allowing for closer and safer access to the target. Furthermore, a control strategy is developed to reproduce the optimized trajectory using discrete ON/OFF thrusters, considering practical implementation constraints.

</details>


### [15] [Online Inertia Parameter Estimation for Unknown Objects Grasped by a Manipulator Towards Space Applications](https://arxiv.org/abs/2512.21886)
*Akiyoshi Uchida,Antonine Richard,Kentaro Uno,Miguel Olivares-Mendez,Kazuya Yoshida*

Main category: cs.RO

TL;DR: 本文提出了一种新的在线估计方法，通过动量守恒来改善惯性参数识别，适用于空间机器人。


<details>
  <summary>Details</summary>
Motivation: 在动态感知的操作中，了解抓取对象的惯性参数至关重要，尤其是在自由浮动基座的空间机器人中。

Method: 该工作扩展了现有的在线识别方法，并结合了动量守恒理论，以适应浮动基座机器人的需求。

Result: 本研究提出了一种新的方法，用于在操控中估计未知目标物体的惯性参数，特别适用于有自由浮动基座的空间机器人。这种方法通过纳入动量守恒来扩展现有的在线识别方法，并通过数值仿真进行验证。

Conclusion: 该方法在模拟场景中的惯性参数识别准确，显示出其在轨道服务及其他太空任务中的适用性。

Abstract: Knowing the inertia parameters of a grasped object is crucial for dynamics-aware manipulation, especially in space robotics with free-floating bases. This work addresses the problem of estimating the inertia parameters of an unknown target object during manipulation. We apply and extend an existing online identification method by incorporating momentum conservation, enabling its use for the floating-base robots. The proposed method is validated through numerical simulations, and the estimated parameters are compared with ground-truth values. Results demonstrate accurate identification in the scenarios, highlighting the method's applicability to on-orbit servicing and other space missions.

</details>


### [16] [Aerial World Model for Long-horizon Visual Generation and Navigation in 3D Space](https://arxiv.org/abs/2512.21887)
*Weichen Zhang,Peizhi Tang,Xin Zeng,Fanhang Man,Shiquan Yu,Zichao Dai,Baining Zhao,Hongjin Chen,Yu Shang,Wei Wu,Chen Gao,Xinlei Chen,Xin Wang,Yong Li,Wenwu Zhu*

Main category: cs.RO

TL;DR: ANWM是一个通过预测未来视觉来增强无人机导航的模型，显著提高了导航成功率。


<details>
  <summary>Details</summary>
Motivation: 当前无人机导航政策通常优化低层目标，缺乏将高层语义融入规划的能力，因此需要一个能够整合语义信息的导航方法。

Method: 提出了一种名为ANWM的空中导航世界模型，该模型通过过去帧和动作预测未来视觉观察，从而使代理能够通过语义可信度和导航效用对候选轨迹进行排名。

Result: ANWM相较于现有世界模型在长距离视觉预测方面表现显著优越，提高了无人机在大规模环境中的导航成功率。

Conclusion: ANWM能够有效地减少长距离视觉生成中的表征不确定性，并捕捉3D轨迹与自我中心观察之间的映射，进而改善无人机的导航能力。

Abstract: Unmanned aerial vehicles (UAVs) have emerged as powerful embodied agents. One of the core abilities is autonomous navigation in large-scale three-dimensional environments. Existing navigation policies, however, are typically optimized for low-level objectives such as obstacle avoidance and trajectory smoothness, lacking the ability to incorporate high-level semantics into planning. To bridge this gap, we propose ANWM, an aerial navigation world model that predicts future visual observations conditioned on past frames and actions, thereby enabling agents to rank candidate trajectories by their semantic plausibility and navigational utility. ANWM is trained on 4-DoF UAV trajectories and introduces a physics-inspired module: Future Frame Projection (FFP), which projects past frames into future viewpoints to provide coarse geometric priors. This module mitigates representational uncertainty in long-distance visual generation and captures the mapping between 3D trajectories and egocentric observations. Empirical results demonstrate that ANWM significantly outperforms existing world models in long-distance visual forecasting and improves UAV navigation success rates in large-scale environments.

</details>


### [17] [Flexible Multitask Learning with Factorized Diffusion Policy](https://arxiv.org/abs/2512.21898)
*Chaoqi Liu,Haonan Chen,Sigmund H. Høeg,Shaoxiong Yao,Yunzhu Li,Kris Hauser,Yilun Du*

Main category: cs.RO

TL;DR: 本研究提出一种模块化扩散策略框架，通过将复杂动作分布分解为多个专业模型，有效应对多任务学习中的挑战，并在多个设置中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 多任务学习在机器人动作分布的多模态和多样性方面面临显著挑战，现有的单体模型难以有效适应这些复杂的任务分布。

Method: 提出了一种新颖的模块化扩散策略框架，将复杂的动作分布分解为多个专业的扩散模型，每个模型捕捉行为空间的一个特定子模式。

Result: 在模拟和现实世界的机器人操作设置中，提出的方法明显优于强大的模块化和单体基线模型。

Conclusion: 模块化结构使得政策能够灵活适应新任务，降低了灾难性遗忘的风险。

Abstract: Multitask learning poses significant challenges due to the highly multimodal and diverse nature of robot action distributions. However, effectively fitting policies to these complex task distributions is often difficult, and existing monolithic models often underfit the action distribution and lack the flexibility required for efficient adaptation. We introduce a novel modular diffusion policy framework that factorizes complex action distributions into a composition of specialized diffusion models, each capturing a distinct sub-mode of the behavior space for a more effective overall policy. In addition, this modular structure enables flexible policy adaptation to new tasks by adding or fine-tuning components, which inherently mitigates catastrophic forgetting. Empirically, across both simulation and real-world robotic manipulation settings, we illustrate how our method consistently outperforms strong modular and monolithic baselines.

</details>


### [18] [StereoVLA: Enhancing Vision-Language-Action Models with Stereo Vision](https://arxiv.org/abs/2512.21970)
*Shengliang Deng,Mi Yan,Yixin Zheng,Jiayi Su,Wenhao Zhang,Xiaoguang Zhao,Heming Cui,Zhizheng Zhang,He Wang*

Main category: cs.RO

TL;DR: StereoVLA模型利用立体视觉的几何和语义特征，提升机器人操作精度，表现优异


<details>
  <summary>Details</summary>
Motivation: 探索立体视觉在视觉-语言-动作模型中的应用及提升机器人操作的空间感知能力

Method: 提出StereoVLA模型，结合立体视觉的几何特征与单目视图的语义特征

Result: StereoVLA在不同任务中表现出色，具有良好的鲁棒性，超越了基线方法

Conclusion: 通过立体视觉增强视觉-语言-动作模型的空间感知能力，支持更精确的机器人操作

Abstract: Stereo cameras closely mimic human binocular vision, providing rich spatial cues critical for precise robotic manipulation. Despite their advantage, the adoption of stereo vision in vision-language-action models (VLAs) remains underexplored. In this work, we present StereoVLA, a VLA model that leverages rich geometric cues from stereo vision. We propose a novel Geometric-Semantic Feature Extraction module that utilizes vision foundation models to extract and fuse two key features: 1) geometric features from subtle stereo-view differences for spatial perception; 2) semantic-rich features from the monocular view for instruction following. Additionally, we propose an auxiliary Interaction-Region Depth Estimation task to further enhance spatial perception and accelerate model convergence. Extensive experiments show that our approach outperforms baselines by a large margin in diverse tasks under the stereo setting and demonstrates strong robustness to camera pose variations.

</details>


### [19] [Bab_Sak Robotic Intubation System (BRIS): A Learning-Enabled Control Framework for Safe Fiberoptic Endotracheal Intubation](https://arxiv.org/abs/2512.21983)
*Saksham Gupta,Sarthak Mishra,Arshad Ayub,Kamran Farooque,Spandan Roy,Babita Gupta*

Main category: cs.RO

TL;DR: 介绍了一种新的机器人插管系统BRIS，解决了气道管理中的关键问题，提供实时深度感知和安全的插管指导。


<details>
  <summary>Details</summary>
Motivation: 解决现有机器人气管插管系统在气道导航和端管推进集成控制及深度验证方面的不足。

Method: 提出一种紧凑型、实时、目标导向的机器人插管系统BRIS，结合了可四向转动的纤维支气管镜、独立的插管推进机制以及兼容标准临床工作流程的增强相机口腔装置，采用闭环控制框架和单目内窥镜深度估计。

Result: 在高保真气道模拟器上验证，在标准和困难气道配置下显示出可靠的导航和受控的插管。

Conclusion: BRIS系统为更安全、一致且临床兼容的机器人气道管理迈出了重要一步。

Abstract: Endotracheal intubation is a critical yet technically demanding procedure, with failure or improper tube placement leading to severe complications. Existing robotic and teleoperated intubation systems primarily focus on airway navigation and do not provide integrated control of endotracheal tube advancement or objective verification of tube depth relative to the carina. This paper presents the Robotic Intubation System (BRIS), a compact, human-in-the-loop platform designed to assist fiberoptic-guided intubation while enabling real-time, objective depth awareness. BRIS integrates a four-way steerable fiberoptic bronchoscope, an independent endotracheal tube advancement mechanism, and a camera-augmented mouthpiece compatible with standard clinical workflows. A learning-enabled closed-loop control framework leverages real-time shape sensing to map joystick inputs to distal bronchoscope tip motion in Cartesian space, providing stable and intuitive teleoperation under tendon nonlinearities and airway contact. Monocular endoscopic depth estimation is used to classify airway regions and provide interpretable, anatomy-aware guidance for safe tube positioning relative to the carina. The system is validated on high-fidelity airway mannequins under standard and difficult airway configurations, demonstrating reliable navigation and controlled tube placement. These results highlight BRIS as a step toward safer, more consistent, and clinically compatible robotic airway management.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [20] [Human-AI Interaction Alignment: Designing, Evaluating, and Evolving Value-Centered AI For Reciprocal Human-AI Futures](https://arxiv.org/abs/2512.21551)
*Hua Shen,Tiffany Knearem,Divy Thakkar,Pat Pataranutaporn,Anoop Sinha,Yike,Shi,Jenny T. Liang,Lama Ahmad,Tanu Mitra,Brad A. Myers,Yang Li*

Main category: cs.HC

TL;DR: 本研讨会关注人类与AI的双向对齐，鼓励跨学科合作以构建负责任的AI与人类合作未来。


<details>
  <summary>Details</summary>
Motivation: 在生成AI迅速融入日常生活的背景下，亟需超越单向对齐模型，重视双向人类与AI的互动。

Method: 通过演讲、跨学科讨论和合作活动，参与者将共同探讨相关方法与策略。

Result: 该研讨会强调了人类与AI之间的双向对齐，旨在促进人类与AI的共同适应。

Conclusion: 通过跨学科讨论与合作活动，参与者将探索互动对齐的方法、社会影响评估框架和动态环境中的对齐策略。

Abstract: The rapid integration of generative AI into everyday life underscores the need to move beyond unidirectional alignment models that only adapt AI to human values. This workshop focuses on bidirectional human-AI alignment, a dynamic, reciprocal process where humans and AI co-adapt through interaction, evaluation, and value-centered design. Building on our past CHI 2025 BiAlign SIG and ICLR 2025 Workshop, this workshop will bring together interdisciplinary researchers from HCI, AI, social sciences and more domains to advance value-centered AI and reciprocal human-AI collaboration. We focus on embedding human and societal values into alignment research, emphasizing not only steering AI toward human values but also enabling humans to critically engage with and evolve alongside AI systems. Through talks, interdisciplinary discussions, and collaborative activities, participants will explore methods for interactive alignment, frameworks for societal impact evaluation, and strategies for alignment in dynamic contexts. This workshop aims to bridge the disciplines' gaps and establish a shared agenda for responsible, reciprocal human-AI futures.

</details>


### [21] [Emotion-Aware Smart Home Automation Based on the eBICA Model](https://arxiv.org/abs/2512.21589)
*Masaaki Yamauchi,Yiyuan Liang,Hiroko Hara,Hideyuki Shimonishi,Masayuki Murata*

Main category: cs.HC

TL;DR: 研究提出了一种情感感知的智能家居自动化框架，并证实其能够有效减少用户的焦虑，提高心理安全感。


<details>
  <summary>Details</summary>
Motivation: 随着智能家居技术的发展，如何使这些系统更加人性化和能够理解用户情感状态变得尤为重要。本研究旨在探索如何通过情感驱动的自动化来提升用户在家庭环境中的心理安全感。

Method: 研究在伪智能家居环境中进行，通过情境设置引发参与者的焦虑，然后引入舒适感自动化进行干预，同时测量状态焦虑以评估自动化的效果。

Result: 该研究验证了情感驱动的智能家居自动化在增强用户心理安全方面的有效性，提供了实证支持，展示了个性化情感适应自动化的可能性。

Conclusion: 研究表明，基于情感的控制可以有效降低焦虑，并为未来的情感化家庭自动化系统奠定了基础。

Abstract: Smart home automation that adapts to a user's emotional state can enhance psychological safety in daily living environments. This study proposes an emotion-aware automation framework guided by the emotional Biologically Inspired Cognitive Architecture (eBICA), which integrates appraisal, somatic responses, and behavior selection. We conducted a proof-of-concept experiment in a pseudo-smart-home environment, where participants were exposed to an anxiety-inducing event followed by a comfort-inducing automation. State anxiety (STAI-S) was measured throughout the task sequence. The results showed a significant reduction in STAI-S immediately after introducing the avoidance automation, demonstrating that emotion-based control can effectively promote psychological safety. Furthermore, an analysis of individual characteristics suggested that personality and anxiety-related traits modulate the degree of relief, indicating the potential for personalized emotion-adaptive automation. Overall, this study provides empirical evidence that eBICA-based emotional control can function effectively in smart home environments and offers a foundation for next-generation affective home automation systems.

</details>


### [22] [Ghostcrafting AI: Under the Rug of Platform Labor](https://arxiv.org/abs/2512.21649)
*ATM Mizanur Rahman,Sharifa Sultana*

Main category: cs.HC

TL;DR: 平台劳动者在构建和维持AI系统中发挥着重要而隐蔽的作用，他们面临着剥削和不平等的挑战，需要通过战术性的方法来应对自身的脆弱状况，揭示了AI对Ghostcrafting劳动的依赖。


<details>
  <summary>Details</summary>
Motivation: 研究旨在揭示平台劳动者在AI系统中的重要作用，尽管他们的劳动常常被忽视和低估。

Method: 通过对孟加拉国平台劳动产业的八个月民族志研究，分析劳动者的工作实践和挑战。

Result: 发现平台劳动者通过资源学习和战术手段在艰难环境中生存，反映了AI对劳动者的依赖和产业中存在的剥削性问题。

Conclusion: AI系统的建设和维持依赖于隐形的平台劳动者，必须进行设计、政策和治理干预，以确保未来平台的公平性、认可和可持续性。

Abstract: Platform laborers play an indispensable yet hidden role in building and sustaining AI systems. Drawing on an eight-month ethnography of Bangladesh's platform labor industry and inspired by Gray and Suri, we conceptualize Ghostcrafting AI to describe how workers materially enable AI while remaining invisible or erased from recognition. Workers pursue platform labor as a path to prestige and mobility but sustain themselves through resourceful, situated learning - renting cyber-cafe computers, copying gig templates, following tutorials in unfamiliar languages, and relying on peer networks. At the same time, they face exploitative wages, unreliable payments, biased algorithms, and governance structures that make their labor precarious and invisible. To cope, they develop tactical repertoires such as identity masking, bypassing platform fees, and pirated tools. These practices reveal both AI's dependency on ghostcrafted labor and the urgent need for design, policy, and governance interventions that ensure fairness, recognition, and sustainability in platform futures.

</details>


### [23] [Modified TSception for Analyzing Driver Drowsiness and Mental Workload from EEG](https://arxiv.org/abs/2512.21747)
*Gourav Siddhad,Anurag Singh,Rajkumar Saini,Partha Pratim Roy*

Main category: cs.HC

TL;DR: 这项研究提出了一种改进的TSception架构，用于通过脑电图（EEG）实时检测驾驶员疲劳，具有比原始模型更好的性能和稳定性。


<details>
  <summary>Details</summary>
Motivation: 驾驶员困倦是交通事故的主要原因，因此需要开发实时、可靠的检测系统以确保道路安全。

Method: 研究提出了一种改进的TSception架构，采用五层时序精炼策略以及自适应平均池化和两阶段融合机制，以捕捉多尺度脑动态。

Result: 在SEED-VIG数据集上评估后，改进的TSception模型实现了83.46%的准确率，信心区间显著缩小，且在STEW心理负荷数据集上也达到了最先进的分类结果。

Conclusion: 这项研究的改进和架构显示出在基于EEG的疲劳和心理负荷监测上的有效性，具有更高的稳定性和跨任务的泛化能力。

Abstract: Driver drowsiness remains a primary cause of traffic accidents, necessitating the development of real-time, reliable detection systems to ensure road safety. This study presents a Modified TSception architecture designed for the robust assessment of driver fatigue using Electroencephalography (EEG). The model introduces a novel hierarchical architecture that surpasses the original TSception by implementing a five-layer temporal refinement strategy to capture multi-scale brain dynamics. A key innovation is the use of Adaptive Average Pooling, which provides the structural flexibility to handle varying EEG input dimensions, and a two - stage fusion mechanism that optimizes the integration of spatiotemporal features for improved stability. When evaluated on the SEED-VIG dataset and compared against established methods - including SVM, Transformer, EEGNet, ConvNeXt, LMDA-Net, and the original TSception - the Modified TSception achieves a comparable accuracy of 83.46% (vs. 83.15% for the original). Critically, the proposed model exhibits a substantially reduced confidence interval (0.24 vs. 0.36), signifying a marked improvement in performance stability. Furthermore, the architecture's generalizability is validated on the STEW mental workload dataset, where it achieves state-of-the-art results with 95.93% and 95.35% accuracy for 2-class and 3-class classification, respectively. These improvements in consistency and cross-task generalizability underscore the effectiveness of the proposed modifications for reliable EEG-based monitoring of drowsiness and mental workload.

</details>


### [24] [Generative Lecture: Making Lecture Videos Interactive with LLMs and AI Clone Instructors](https://arxiv.org/abs/2512.21796)
*Hye-Young Jo,Ada Zhao,Xiaoan Liu,Ryo Suzuki*

Main category: cs.HC

TL;DR: 本研究提出了互动讲座概念，通过生成式人工智能和AI克隆讲师使现有讲座视频变得互动，支持个性化学习。


<details>
  <summary>Details</summary>
Motivation: 死板的教学视频难以满足个体学习需求，因此需要通过AI技术增强视频互动性和个性化。

Method: 使用HeyGen、ElevenLabs和GPT-5技术，将AI讲师嵌入视频中，同时根据学生提问增强视频内容，设计了包括八个系统功能的用户研究。

Result: 用户研究表明，该系统实现了有效的双向沟通，支持个性化学习，并收集了专家反馈。

Conclusion: 本系统推动了个性化学习和互动教学的发展，是未来教育技术的一种重要趋势。

Abstract: We introduce Generative Lecture, a concept that makes existing lecture videos interactive through generative AI and AI clone instructors. By leveraging interactive avatars powered by HeyGen, ElevenLabs, and GPT-5, we embed an AI instructor into the video and augment the video content in response to students' questions. This allows students to personalize the lecture material, directly ask questions in the video, and receive tailored explanations generated and delivered by the AI-cloned instructor. From a design elicitation study (N=8), we identified four goals that guided the development of eight system features: 1) on-demand clarification, 2) enhanced visuals, 3) interactive example, 4) personalized explanation, 5) adaptive quiz, 6) study summary, 7) automatic highlight, and 8) adaptive break. We then conducted a user study (N=12) to evaluate the usability and effectiveness of the system and collected expert feedback (N=5). The results suggest that our system enables effective two-way communication and supports personalized learning.

</details>


### [25] [Positive Narrativity Enhances Sense of Agency toward a VR Avatar](https://arxiv.org/abs/2512.21968)
*Kureha Hamagashira,Miyuki Azuma,Sotaro Shimada*

Main category: cs.HC

TL;DR: 本研究探讨了虚拟现实中，通过叙事背景影响用户对人工生命体头像的印象，从而调节全身幻觉的可能性。正面叙事增强了用户的代理感，并与其对头像的熟悉感相关。


<details>
  <summary>Details</summary>
Motivation: 研究全身幻觉(FBI)在虚拟现实中对用户身体体验和行为的调节作用，特别是如何通过叙事背景影响用户对头像的印象。

Method: 参与者在虚拟现实中体验一个强大的人工生命体头像，听取正面或负面叙事后进行判断。

Result: 正面叙事显著增强了参与者的代理感(SoA)，而SoA与参与者对头像的个人熟悉感呈正相关。

Conclusion: 头像的叙事性可以调节虚拟现实中的身体化体验。

Abstract: The full-body illusion (FBI) refers to the experience of perceiving a virtual avatar as one's own body. In virtual reality (VR) environments, inducing the FBI has been shown to modulate users' bodily experiences and behavior. Previous studies have demonstrated that embodying avatars with specific characteristics can influence users' actions, largely through the activation of implicit stereotypes. However, few studies have explicitly manipulated users' impressions of an avatar by introducing narrative context. The present study investigated how avatar narrativity, induced through contextual narratives, affects the FBI. Healthy participants embodied a powerful artificial lifeform avatar in VR after listening to either a positive narrative, in which the avatar used its abilities to protect others, or a negative narrative, in which it misused its power. Participants' impressions of the avatar and indices of bodily self-consciousness were subsequently assessed. The results showed that positive narratives significantly enhanced the sense of agency (SoA), and that SoA was positively correlated with participants' perceived personal familiarity with the avatar. These findings suggest that the avatar narrativity can modulate embodiment in VR.

</details>


### [26] [SketchPlay: Intuitive Creation of Physically Realistic VR Content with Gesture-Driven Sketching](https://arxiv.org/abs/2512.22016)
*Xiangwen Zhang,Xiaowei Dai,Runnan Chen,Xiaoming Chen,Zeke Zexi Hu*

Main category: cs.HC

TL;DR: SketchPlay是一种独特的虚拟现实交互框架，通过用户的手绘草图和手势来创建动态且物理上真实的场景，降低了非专家用户的创作门槛。


<details>
  <summary>Details</summary>
Motivation: 传统的3D建模和动画工具对非专业用户存在显著障碍。

Method: SketchPlay框架结合手绘草图和手势输入，捕捉对象和场景的结构及空间排列，并通过手势传达物理信息，生成复杂的物理现象。

Result: 实验结果表明，SketchPlay在表现力和用户体验方面优于传统文本驱动的方法。

Conclusion: SketchPlay提供了直观且引人入胜的创作过程，显示出在教育、艺术和沉浸式叙事等领域的应用潜力。

Abstract: Creating physically realistic content in VR often requires complex modeling tools or predefined 3D models, textures, and animations, which present significant barriers for non-expert users. In this paper, we propose SketchPlay, a novel VR interaction framework that transforms humans' air-drawn sketches and gestures into dynamic, physically realistic scenes, making content creation intuitive and playful like drawing. Specifically, sketches capture the structure and spatial arrangement of objects and scenes, while gestures convey physical cues such as velocity, direction, and force that define movement and behavior. By combining these complementary forms of input, SketchPlay captures both the structure and dynamics of user-created content, enabling the generation of a wide range of complex physical phenomena, such as rigid body motion, elastic deformation, and cloth dynamics. Experimental results demonstrate that, compared to traditional text-driven methods, SketchPlay offers significant advantages in expressiveness, and user experience. By providing an intuitive and engaging creation process, SketchPlay lowers the entry barrier for non-expert users and shows strong potential for applications in education, art, and immersive storytelling.

</details>


### [27] [Context-Aware Intelligent Chatbot Framework Leveraging Mobile Sensing](https://arxiv.org/abs/2512.22032)
*Ziyan Zhang,Nan Gao,Zhiqiang Nie,Shantanu Pal,Haining Zhang*

Main category: cs.HC

TL;DR: 本研究提出了一个基于移动传感数据的上下文敏感对话助手框架，以增强对话个性化和相关性。


<details>
  <summary>Details</summary>
Motivation: 为了使智能对话助手能理解用户的真实世界行为，从而提供更个性化的对话体验。

Method: 结合移动传感数据和大型语言模型，通过设计结构化提示系统来提升对话的个性化和相关性。

Result: 建立了一个框架，通过将用户行为和环境数据转化为自然语言提示，显著提升了对话助手对用户状态的理解。

Conclusion: 这项研究展示了通过移动传感数据改进智能对话助手个性化对话的潜力。

Abstract: With the rapid advancement of large language models (LLMs), intelligent conversational assistants have demonstrated remarkable capabilities across various domains. However, they still mainly rely on explicit textual input and do not know the real world behaviors of users. This paper proposes a context-sensitive conversational assistant framework grounded in mobile sensing data. By collecting user behavior and environmental data through smartphones, we abstract these signals into 16 contextual scenarios and translate them into natural language prompts, thus improving the model's understanding of the user's state. We design a structured prompting system to guide the LLM in generating a more personalized and contextually relevant dialogue. This approach integrates mobile sensing with large language models, demonstrating the potential of passive behavioral data in intelligent conversation and offering a viable path toward digital health and personalized interaction.

</details>
