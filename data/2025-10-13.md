<div id=toc></div>

# Table of Contents

- [cs.HC](#cs.HC) [Total: 15]
- [cs.RO](#cs.RO) [Total: 31]


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [1] [Understanding and Predicting Temporal Visual Attention Influenced by Dynamic Highlights in Monitoring Task](https://arxiv.org/abs/2510.08777)
*Zekun Wu,Anna Maria Feit*

Main category: cs.HC

TL;DR: 本研究考察了视觉高亮在无人机监控任务中对用户注意力的影响，并开发了模型来优化高亮设计


<details>
  <summary>Details</summary>
Motivation: 探索视觉高亮如何影响用户在无人机监控任务中的注意力分配

Method: 通过实验研究视觉高亮对用户注视行为的影响

Result: 发现高亮区域在时间特征上与非高亮区域明显不同，并开发了高亮知情显著性模型（HISM）以预测变化

Conclusion: HISM模型能够为未来的监控界面设计提供支持，特别是在时间敏感的任务中.

Abstract: Monitoring interfaces are crucial for dynamic, highstakes tasks where
effective user attention is essential. Visual highlights can guide attention
effectively but may also introduce unintended disruptions. To investigate this,
we examined how visual highlights affect users' gaze behavior in a drone
monitoring task, focusing on when, how long, and how much attention they draw.
We found that highlighted areas exhibit distinct temporal characteristics
compared to non-highlighted ones, quantified using normalized saliency (NS)
metrics. Highlights elicited immediate responses, with NS peaking quickly, but
this shift came at the cost of reduced search efforts elsewhere, potentially
impacting situational awareness. To predict these dynamic changes and support
interface design, we developed the Highlight-Informed Saliency Model (HISM),
which provides granular predictions of NS over time. These predictions enable
evaluations of highlight effectiveness and inform the optimal timing and
deployment of highlights in future monitoring interface designs, particularly
for time-sensitive tasks.

</details>


### [2] [MLLM as a UI Judge: Benchmarking Multimodal LLMs for Predicting Human Perception of User Interfaces](https://arxiv.org/abs/2510.08783)
*Reuben A. Luera,Ryan Rossi,Franck Dernoncourt,Samyadeep Basu,Sungchul Kim,Subhojyoti Mukherjee,Puneet Mathur,Ruiyi Zhang,Jihyung Kil,Nedim Lipka,Seunghyun Yoon,Jiuxiang Gu,Zichao Wang,Cindy Xiong Bearfield,Branislav Kveton*

Main category: cs.HC

TL;DR: 本研究探讨了多模态大型语言模型在评估不同用户界面时的有效性和差异，显示出其在早期用户体验研究中的潜力与局限性。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的早期探索阶段，用户界面设计与用户研究的结合非常重要，但现实中往往缺乏必要的资源。

Method: 通过利用众包平台的数据，对GPT-4o、Claude和Llama在30个用户界面上的表现进行基准测试，评估它们与人类判断在多个UI因素上的一致性。

Result: 多模态大型语言模型（MLLMs）在评估用户界面时能够接近人类的偏好，但在某些维度上存在差异。

Conclusion: MLLMs在补充早期用户体验研究方面具有潜力，但也存在一定的局限性，不能完全替代人类评估。

Abstract: In an ideal design pipeline, user interface (UI) design is intertwined with
user research to validate decisions, yet studies are often resource-constrained
during early exploration. Recent advances in multimodal large language models
(MLLMs) offer a promising opportunity to act as early evaluators, helping
designers narrow options before formal testing. Unlike prior work that
emphasizes user behavior in narrow domains such as e-commerce with metrics like
clicks or conversions, we focus on subjective user evaluations across varied
interfaces. We investigate whether MLLMs can mimic human preferences when
evaluating individual UIs and comparing them. Using data from a crowdsourcing
platform, we benchmark GPT-4o, Claude, and Llama across 30 interfaces and
examine alignment with human judgments on multiple UI factors. Our results show
that MLLMs approximate human preferences on some dimensions but diverge on
others, underscoring both their potential and limitations in supplementing
early UX research.

</details>


### [3] [Green Grid: Smart Tech Meets E-Waste](https://arxiv.org/abs/2510.08888)
*Yashodip Dharmendra Jagtap,Aaditya Ganesh Bagul*

Main category: cs.HC

TL;DR: Green Grid是一个集成的AI驱动电子废物管理平台，通过智能回收、设备分类和公民参与，促进电子废物的循环经济。


<details>
  <summary>Details</summary>
Motivation: 应对全球电子废物危机，尤其是印度的电子废物产生量大且处理不充分的问题。

Method: 该平台结合物联网、人工智能、区块链和游戏化公民参与，提供智能垃圾回收箱、深度学习设备识别和分类、区块链追踪以及基于奖励的参与应用。

Result: 通过Green Grid平台的实施，预计将提升电子废物的正式回收率，支持政策制定者和回收者，并增强公众参与。

Conclusion: Green Grid平台通过整合技术、可持续性和社区参与，提高了透明度，增加了正式回收率，促进了印度向循环经济的转型。

Abstract: Electronic waste (e-waste) is a rapidly growing global problem caused by
shorter device lifecycles and rising consumption. India ranks third globally in
e-waste generation, producing over 1.7 million tonnes in 2023-24, of which less
than half is formally processed. To address this, we propose Green Grid, an
integrated AI-powered e-waste management platform combining IoT-enabled smart
collection, AI-based device classification, blockchain-based traceability, and
gamified citizen engagement. The system features smart recycling bins with
sensors for real-time monitoring, deep learning models for device
identification and sorting, a blockchain ledger for tamper-proof tracking, and
a reward-based mobile or web app to encourage user participation. Additionally,
Green Grid offers analytics dashboards and an eco-marketplace to support
policymakers and recyclers. By bridging technology, sustainability, and
community participation, the platform enhances transparency, increases formal
recycling rates, and advances India's transition toward a circular economy.

</details>


### [4] [Beyond Words: Infusing Conversational Agents with Human-like Typing Behaviors](https://arxiv.org/abs/2510.08912)
*Jijie Zhou,Yuhan Hu*

Main category: cs.HC

TL;DR: 本论文探讨了通过模拟人类打字行为来提升对话AI的自然性和可信度，并展示了用户偏好带有这些行为的代理。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型生成的回复缺乏人类的思考过程，导致对话不够自然和可信。

Method: 设计一种模拟人类打字行为的AI

Result: 用户实验显示，具有人类打字行为（犹豫和自我编辑）的代理更受欢迎，提高了自然性和可信度。

Conclusion: 通过用户反馈，强调了人性化、引人入胜和可信的沟通范式在对话AI中的重要性。

Abstract: Recently, large language models have facilitated the emergence of highly
intelligent conversational AI capable of engaging in human-like dialogues.
However, a notable distinction lies in the fact that these AI models
predominantly generate responses rapidly, often producing extensive content
without emulating the thoughtful process characteristic of human cognition and
typing. This paper presents a design aimed at simulating human-like typing
behaviors, including patterns such as hesitation and self-editing, as well as a
preliminary user experiment to understand whether and to what extent the agent
with human-like typing behaviors could potentially affect conversational
engagement and its trustworthiness. We've constructed an interactive platform
featuring user-adjustable parameters, allowing users to personalize the AI's
communication style and thus cultivate a more enriching and immersive
conversational experience. Our user experiment, involving interactions with
three types of agents - a baseline agent, one simulating hesitation, and
another integrating both hesitation and self-editing behaviors - reveals a
preference for the agent that incorporates both behaviors, suggesting an
improvement in perceived naturalness and trustworthiness. Through the insights
from our design process and both quantitative and qualitative feedback from
user experiments, this paper contributes to the multimodal interaction design
and user experience for conversational AI, advocating for a more human-like,
engaging, and trustworthy communication paradigm.

</details>


### [5] ["I know it's not right, but that's what it said to do": Investigating Trust in AI Chatbots for Cybersecurity Policy](https://arxiv.org/abs/2510.08917)
*Brandon Lit,Edward Crowder,Daniel Vogel,Hassan Khan*

Main category: cs.HC

TL;DR: 研究揭示了AI聊天机器人在安全任务中被操控的风险及用户信任的影响因素。


<details>
  <summary>Details</summary>
Motivation: 研究AI聊天机器人作为潜在的安全攻击渠道，特别是被操控后可能误导用户的风险

Method: 控制性研究，参与者使用被操纵的AI聊天机器人完成安全任务

Result: 结果表明，用户对AI聊天机器人的信任与任务熟悉度和自我判断信心有关

Conclusion: 信任AI聊天机器人的程度受到任务类型和个人判断信心的影响，值得进一步探讨其在不同场景下的信任机制。

Abstract: AI chatbots are an emerging security attack vector, vulnerable to threats
such as prompt injection, and rogue chatbot creation. When deployed in domains
such as corporate security policy, they could be weaponized to deliver guidance
that intentionally undermines system defenses. We investigate whether users can
be tricked by a compromised AI chatbot in this scenario. A controlled study
(N=15) asked participants to use a chatbot to complete security-related tasks.
Without their knowledge, the chatbot was manipulated to give incorrect advice
for some tasks. The results show how trust in AI chatbots is related to task
familiarity, and confidence in their ownn judgment. Additionally, we discuss
possible reasons why people do or do not trust AI chatbots in different
scenarios.

</details>


### [6] [Co-Authoring the Self: A Human-AI Interface for Interest Reflection in Recommenders](https://arxiv.org/abs/2510.08930)
*Ruixuan Sun,Junyuan Wang,Sanjali Roy,Joseph A. Konstan*

Main category: cs.HC

TL;DR: 本文介绍了一种人类与人工智能协作的电影推荐系统，旨在提高用户的参与感和透明度，尽管用户与系统之间存在兴趣差距。


<details>
  <summary>Details</summary>
Motivation: 为了提高推荐系统的可解释性，并帮助用户审查和修正兴趣，以增强推荐质量。

Method: 进行为期八周的在线实地部署，涉及1775名活跃电影推荐用户，以测试和评估协作个人资料的有效性。

Result: 发现用户感知与系统推断之间存在持久差距，同时该个人资料设计能促进用户的参与和反思，并为构建更透明的推荐体验提供设计方向。

Conclusion: 该研究提出的以人类-人工智能协作的电影推荐系统能够促进用户的参与和反思，提高透明度与信任度，尽管存在用户感知与系统推断之间的差距。

Abstract: Natural language-based user profiles in recommender systems have been
explored for their interpretability and potential to help users scrutinize and
refine their interests, thereby improving recommendation quality. Building on
this foundation, we introduce a human-AI collaborative profile for a movie
recommender system that presents editable personalized interest summaries of a
user's movie history. Unlike static profiles, this design invites users to
directly inspect, modify, and reflect on the system's inferences. In an
eight-week online field deployment with 1775 active movie recommender users, we
find persistent gaps between user-perceived and system-inferred interests, show
how the profile encourages engagement and reflection, and identify design
directions for leveraging imperfect AI-powered user profiles to stimulate more
user intervention and build more transparent and trustworthy recommender
experiences.

</details>


### [7] [Creation, Critique, and Consumption: Exploring Generative AI Descriptions for Supporting Blind and Low Vision Professionals with Visual Tasks](https://arxiv.org/abs/2510.08991)
*Lucy Jiang,Lotus Zhang,Leah Findlater*

Main category: cs.HC

TL;DR: 利用生成性AI为BLV人群提供个性化的视觉描述，促进他们的职业参与。


<details>
  <summary>Details</summary>
Motivation: 解决BLV人群在职业中面临的可及性障碍和社会污名问题。

Method: 提出了一些设计建议，以便为多种职业任务提供更好的视觉描述的上下文。

Result: 这篇论文讨论了生成性人工智能如何为盲人和视力低下者（BLV）提供个性化的视觉描述，以便更好地参与与视觉任务相关的职业。

Conclusion: 这些设计可以提高BLV人群的自主性、包容性和技能发展。

Abstract: Many blind and low vision (BLV) people are excluded from professional roles
that may involve visual tasks due to access barriers and persisting stigmas.
Advancing generative AI systems can support BLV people through providing
contextual and personalized visual descriptions for creation, critique, and
consumption. In this workshop paper, we provide design suggestions for how
visual descriptions can be better contextualized for multiple professional
tasks. We conclude by discussing how these designs can improve autonomy,
inclusion, and skill development over time.

</details>


### [8] [Promptimizer: User-Led Prompt Optimization for Personal Content Classification](https://arxiv.org/abs/2510.09009)
*Leijie Wang,Kathryn Yurechko,Amy X. Zhang*

Main category: cs.HC

TL;DR: 本研究介绍了一种新的用户中心提示优化技术Promptimizer，它增强了用户在优化过程中的参与和提示结果的可解释性。


<details>
  <summary>Details</summary>
Motivation: 用户希望在使用过程中不断演化他们的内容过滤器，但现有的自动提示优化技术往往未能考虑这一点。

Method: 使用实验设计评估Promptimizer的性能与用户偏好，并在Puffin工具中实施以支持YouTube内容创作者.

Result: 提出了Promptimizer，是一种以用户为中心的提示优化技术，可以实现高性能和易用性，同时允许用户参与优化过程，并生成可解释的最终提示。

Conclusion: Promptimizer在一项实验中表现出用户偏好的明显优势，通过在内容创作者中应用，证明了其有效性。

Abstract: While LLMs now enable users to create content classifiers easily through
natural language, automatic prompt optimization techniques are often necessary
to create performant classifiers. However, such techniques can fail to consider
how social media users want to evolve their filters over the course of usage,
including desiring to steer them in different ways during initialization and
iteration. We introduce a user-centered prompt optimization technique,
Promptimizer, that maintains high performance and ease-of-use but additionally
(1) allows for user input into the optimization process and (2) produces final
prompts that are interpretable. A lab experiment (n=16) found that users
significantly preferred Promptimizer's human-in-the-loop optimization over a
fully automatic approach. We further implement Promptimizer into Puffin, a tool
to support YouTube content creators in creating and maintaining personal
classifiers to manage their comments. Over a 3-week deployment with 10
creators, participants successfully created diverse filters to better
understand their audiences and protect their communities.

</details>


### [9] [Investigating the Impact of Rational Dilated Wavelet Transform on Motor Imagery EEG Decoding with Deep Learning Models](https://arxiv.org/abs/2510.09242)
*Marco Siino,Giuseppe Bonomo,Rosario Sorbello,Ilenia Tinnirello*

Main category: cs.HC

TL;DR: 本研究探讨了在深度学习分类器中使用RDWT预处理电机意象EEG数据的影响，发现其在多个架构上均能提升分类器的准确性。


<details>
  <summary>Details</summary>
Motivation: 研究通过对电机意象脑电图（EEG）解码过程中的数据预处理方法进行探索，以提高深度学习分类器的性能。

Method: 系统比较四种深度学习架构（EEGNet、ShallowConvNet、MBEEG_SENet和EEGTCNet）在有无RDWT预处理下的性能，使用三个基准数据集进行评估。

Result: 引入了有理离散小波变换（RDWT），作为预处理步骤，在不同的深度学习架构中实现了性能提升。

Conclusion: RDWT是一种低开销且具有架构适应性的预处理技术，对于复杂的EEG数据具有显著的准确性提高。

Abstract: The present study investigates the impact of the Rational Discrete Wavelet
Transform (RDWT), used as a plug-in preprocessing step for motor imagery
electroencephalographic (EEG) decoding prior to applying deep learning
classifiers. A systematic paired evaluation (with/without RDWT) is conducted on
four state-of-the-art deep learning architectures: EEGNet, ShallowConvNet,
MBEEG\_SENet, and EEGTCNet. This evaluation was carried out across three
benchmark datasets: High Gamma, BCI-IV-2a, and BCI-IV-2b. The performance of
the RDWT is reported with subject-wise averages using accuracy and Cohen's
kappa, complemented by subject-level analyses to identify when RDWT is
beneficial. On BCI-IV-2a, RDWT yields clear average gains for EEGTCNet (+4.44
percentage points, pp; kappa +0.059) and MBEEG\_SENet (+2.23 pp; +0.030), with
smaller improvements for EEGNet (+2.08 pp; +0.027) and ShallowConvNet (+0.58
pp; +0.008). On BCI-IV-2b, the enhancements observed are modest yet consistent
for EEGNet (+0.21 pp; +0.044) and EEGTCNet (+0.28 pp; +0.077). On HGD, average
effects are modest to positive, with the most significant gain observed for
MBEEG\_SENet (+1.65 pp; +0.022), followed by EEGNet (+0.76 pp; +0.010) and
EEGTCNet (+0.54 pp; +0.008). Inspection of the subject material reveals
significant enhancements in challenging recordings (e.g., non-stationary
sessions), indicating that RDWT can mitigate localized noise and enhance
rhythm-specific information. In conclusion, RDWT is shown to be a low-overhead,
architecture-aware preprocessing technique that can yield tangible gains in
accuracy and agreement for deep model families and challenging subjects.

</details>


### [10] [Barriers that Programming Instructors Face While Performing Emergency Pedagogical Design to Shape Student-AI Interactions with Generative AI Tools](https://arxiv.org/abs/2510.09492)
*Sam Lau,Kianoosh Boroojeni,Harry Keeling,Jenn Marroquin*

Main category: cs.HC

TL;DR: 生成性AI工具日益普及，教师需重新设计学生在课程中的使用方式，本研究探讨了教师如何在缺乏控制的情况下进行紧急教学设计，并识别了他们面临的五大障碍。


<details>
  <summary>Details</summary>
Motivation: 随着生成性AI工具的广泛应用，教师需要重新思考学生与AI互动的方式，以更好地融入课程。

Method: 通过对计算机教师进行13次访谈和169份调查，了解教师在应对GenAI所遇到的挑战。

Result: 发现教师在实施紧急教学设计时面临五个主要障碍，包括课程修订的支持不足、政策指导的不确定性、实施中的挑战、评估不匹配和资源匮乏。

Conclusion: 本研究强调了紧急教学设计作为HCI的独特设计情境，并为相关研究人员和机构提供了支持教师适应GenAI的建议。

Abstract: Generative AI (GenAI) tools are increasingly pervasive, pushing instructors
to redesign how students use GenAI tools in coursework. We conceptualize this
work as emergency pedagogical design: reactive, indirect efforts by instructors
to shape student-AI interactions without control over commercial interfaces. To
understand practices of lead users conducting emergency pedagogical design, we
conducted interviews (n=13) and a survey (n=169) of computing instructors.
These instructors repeatedly encountered five barriers: fragmented buy-in for
revising courses; policy crosswinds from non-prescriptive institutional
guidance; implementation challenges as instructors attempt interventions;
assessment misfit as student-AI interactions are only partially visible to
instructors; and lack of resources, including time, staffing, and paid tool
access. We use these findings to present emergency pedagogical design as a
distinct design setting for HCI and outline recommendations for HCI
researchers, academic institutions, and organizations to effectively support
instructors in adapting courses to GenAI.

</details>


### [11] [LibraryLens: An Interactive Tool for Exploring and Arranging Digital Bookshelves](https://arxiv.org/abs/2510.09502)
*Trevor DePodesta,Johanna Beyer*

Main category: cs.HC

TL;DR: LibraryLens 是一种新的可视化工具，可以提升用户对个人藏书的管理和分享，克服现有数字平台的不足。


<details>
  <summary>Details</summary>
Motivation: 现有数字图书管理平台无法充分捕捉物理书架的空间和视觉信息，影响用户参与度。

Method: 设计并开发一个可视化工具，允许用户创建和探索个人图书馆的二维表现，并进行社交分享。

Result: LibraryLens 是一款创新的可视化工具，旨在改善数字图书管理平台在捕捉物理书架的空间和视觉线索方面的不足，提升用户对其藏书的参与度。该工具还支持在线书籍社区间的社交分享，使用户能够创造易于分享的藏书视觉呈现。

Conclusion: LibraryLens 具备降低用户优化书籍组织门槛的潜力，从而促进与个人藏书的更深层次互动。

Abstract: Existing digital book management platforms often fail to capture the rich
spatial and visual cues inherent to physical bookshelves, hindering users'
ability to fully engage with their collections. We present LibraryLens, a novel
visualization tool that addresses these shortcomings by enabling users to
create, explore, and interact with immersive, two-dimensional representations
of their personal libraries. The tool also caters to the growing trend of
social sharing within online book communities, allowing users to create
visually appealing representations of their libraries that can be easily shared
on social platforms. Despite limitations inherent to the metadata being
rendered, formative evaluations suggest that LibraryLens has the potential to
lower the barrier to entry for users seeking to optimize their book
organization without the constraints of physical space or manual labor,
ultimately fostering deeper engagement with their personal libraries.

</details>


### [12] [Convivial Conversational Agents -- shifting toward relationships](https://arxiv.org/abs/2510.09516)
*Rafael A. Calvo,Dorian Peters*

Main category: cs.HC

TL;DR: 本论文探讨了对话式人工智能在服务提供中的应用，特别是在医疗领域的挑战与机遇，并提倡一种新的框架以保障人类福祉。


<details>
  <summary>Details</summary>
Motivation: 旨在利用CAI提升服务效率，同时关注人类基本需求的保护。

Method: 通过分析在痴呆症护理中的实践经验，探讨CAI的应用。

Result: 本研究探讨了对话式人工智能（CAI）在提供服务时的巨大发展潜力，尤其是在医疗领域。通过结合在痴呆症护理中的研究，分析了CAI的应用面临的挑战与机遇，同时强调了一种新的思维方式，以确保在自动化过程中不丧失人类所需的基本元素。

Conclusion: CAI的实施需谨慎，确保在服务自动化过程中不损害人类的基本需求和福祉。

Abstract: Conversational AI (CAI) systems offer opportunities to scale service
provision to unprecedented levels and governments and corporations are already
beginning to deploy them across services. The economic argument is similar
across domains: use CAI to automate the time-consuming conversations required
for customer, client or patient support. Herein we draw on our work in dementia
care to explore some of the challenges and opportunities for CAI, and how a new
way of conceptualising these systems could help ensure essential aspects for
human thriving are not lost in the process of automation.

</details>


### [13] [scellop: A Scalable Redesign of Cell Population Plots for Single-Cell Data](https://arxiv.org/abs/2510.09554)
*Thomas C. Smits,Nikolay Akhmetov,Tiffany S. Liaw,Mark S. Keller,Eric Mörth,Nils Gehlenborg*

Main category: cs.HC

TL;DR: scellop是一个交互式细胞群体可视化工具，优化了细胞群体研究中的常用视觉编码，提高了可扩展性。


<details>
  <summary>Details</summary>
Motivation: 随着单细胞数据的增加，传统的细胞群体可视化方法已经难以满足需求，因此开发新的可视化工具以支持更复杂的数据分析变得至关重要。

Method: 通过设计交互式可视化，scellop使用户能够高效地分析和比较不同细胞群体。

Result: 本文提出了一种新型的细胞群体可视化工具scellop，用于解决传统堆叠条形图在细胞类型和样本数量增加时的可扩展性有限的问题。

Conclusion: scellop提供了一种高效且用户友好的方式来研究细胞群体在不同样本或条件下的分布。

Abstract: Summary: Cell population plots are visualizations showing cell population
distributions in biological samples with single-cell data, traditionally shown
with stacked bar charts. Here, we address issues with this approach,
particularly its limited scalability with increasing number of cell types and
samples, and present scellop, a novel interactive cell population viewer
combining visual encodings optimized for common user tasks in studying
populations of cells across samples or conditions.
  Availability and Implementation: Scellop is available under the MIT licence
at https://github.com/hms-dbmi/scellop, and is available on PyPI
(https://pypi.org/project/cellpop/) and NPM
(https://www.npmjs.com/package/cellpop). A demo is available at
https://scellop.netlify.app/.

</details>


### [14] [Differential Analysis of Pseudo Haptic Feedback: Novel Comparative Study of Visual and Auditory Cue Integration for Psychophysical Evaluation](https://arxiv.org/abs/2510.09570)
*Nishant Gautam,Somya Sharma,Peter Corcoran,Kaspar Althoefer*

Main category: cs.HC

TL;DR: 本文研究了假触觉如何通过视觉和听觉刺激相结合，在无物理接触的情况下诱发触觉压力感受。


<details>
  <summary>Details</summary>
Motivation: 假触觉利用视觉或听觉线索填补传统触觉硬件的缺陷，为低成本解决方案提供新的可能。

Method: 通过Unity基础的Rollball游戏，参与者在不同纹理地形上引导虚拟球，同时实时捕捉手指的施力，分析视觉与听觉刺激的组合效果。

Result: 结果表明，音频频率和视觉纹理的强度与触觉感受之间存在显著关系，支持多重感知整合的理论。

Conclusion: 消费级等向设备可以可靠地诱导和测量细微的假触觉反馈，为实惠的康复工具和训练模拟器提供了可能性。

Abstract: Pseudo-haptics exploit carefully crafted visual or auditory cues to trick the
brain into "feeling" forces that are never physically applied, offering a
low-cost alternative to traditional haptic hardware. Here, we present a
comparative psychophysical study that quantifies how visual and auditory
stimuli combine to evoke pseudo-haptic pressure sensations on a commodity
tablet. Using a Unity-based Rollball game, participants (n = 4) guided a
virtual ball across three textured terrains while their finger forces were
captured in real time with a Robotous RFT40 force-torque sensor. Each terrain
was paired with a distinct rolling-sound profile spanning 440 Hz - 4.7 kHz, 440
Hz - 13.1 kHz, or 440 Hz - 8.9 kHz; crevice collisions triggered additional
"knocking" bursts to heighten realism. Average tactile forces increased
systematically with cue intensity: 0.40 N, 0.79 N and 0.88 N for visual-only
trials and 0.41 N, 0.81 N and 0.90 N for audio-only trials on Terrains 1-3,
respectively. Higher audio frequencies and denser visual textures both elicited
stronger muscle activation, and their combination further reduced the force
needed to perceive surface changes, confirming multisensory integration. These
results demonstrate that consumer-grade isometric devices can reliably induce
and measure graded pseudo-haptic feedback without specialized actuators,
opening a path toward affordable rehabilitation tools, training simulators and
assistive interfaces.

</details>


### [15] [VisPile: A Visual Analytics System for Analyzing Multiple Text Documents With Large Language Models and Knowledge Graphs](https://arxiv.org/abs/2510.09605)
*Adam Coscia,Alex Endert*

Main category: cs.HC

TL;DR: 本论文介绍了一种名为VisPile的可视化分析工具，它集成了大型语言模型和知识图谱，以支持情报分析师提升文本分析的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 随着数据规模的增长，情报分析师需要更有效的工具来进行文本分析和洞察挖掘。

Method: 开发了一种名为VisPile的可视化分析系统，结合了大型语言模型和知识图谱，提供多种用户界面功能以支持文档分组、总结和关系映射等任务。

Result: 通过与六名专业情报分析师的协作和反馈，验证了VisPile在分析文档语料库中的有效性和实用性。

Conclusion: VisPile通过将大型语言模型和知识图谱集成到视觉分析系统中，显著提升了情报分析师在处理文档群体时的洞察能力和效率。

Abstract: Intelligence analysts perform sensemaking over collections of documents using
various visual and analytic techniques to gain insights from large amounts of
text. As data scales grow, our work explores how to leverage two AI
technologies, large language models (LLMs) and knowledge graphs (KGs), in a
visual text analysis tool, enhancing sensemaking and helping analysts keep
pace. Collaborating with intelligence community experts, we developed a visual
analytics system called VisPile. VisPile integrates an LLM and a KG into
various UI functions that assist analysts in grouping documents into piles,
performing sensemaking tasks like summarization and relationship mapping on
piles, and validating LLM- and KG-generated evidence. Our paper describes the
tool, as well as feedback received from six professional intelligence analysts
that used VisPile to analyze a text document corpus.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [16] [ConPoSe: LLM-Guided Contact Point Selection for Scalable Cooperative Object Pushing](https://arxiv.org/abs/2510.08705)
*Noah Steinkrüger,Nisarga Nilavadi,Wolfram Burgard,Tanja Katharina Kaiser*

Main category: cs.RO

TL;DR: 本研究提出了ConPoSe，一种结合大型语言模型与局部搜索的方法，以解决多机器人协作运输中的接触点选择问题，表现出更好的可扩展性和效率。


<details>
  <summary>Details</summary>
Motivation: 在复杂环境中，多机器人协作运输物体是一项基本任务，现有的解析选择方法在机器人数和物体尺寸增加时面临可扩展性问题，因此需要更有效的接触点选择方案。

Method: 提出了一种结合大型语言模型与局部搜索的方法，针对物体运输中的接触点选择进行改进。

Result: ConPoSe在多种物体形状的接触点选择上表现良好，包括立方体、圆柱体和T形物体，且在可扩展性和性能上优于现有的方法。

Conclusion: ConPoSe方法在接触点选择上相较于传统解析方法具有更好的可扩展性，并且性能优于仅基于大型语言模型的选择方法。

Abstract: Object transportation in cluttered environments is a fundamental task in
various domains, including domestic service and warehouse logistics. In
cooperative object transport, multiple robots must coordinate to move objects
that are too large for a single robot. One transport strategy is pushing, which
only requires simple robots. However, careful selection of robot-object contact
points is necessary to push the object along a preplanned path. Although this
selection can be solved analytically, the solution space grows combinatorially
with the number of robots and object size, limiting scalability. Inspired by
how humans rely on common-sense reasoning for cooperative transport, we propose
combining the reasoning capabilities of Large Language Models with local search
to select suitable contact points. Our LLM-guided local search method for
contact point selection, ConPoSe, successfully selects contact points for a
variety of shapes, including cuboids, cylinders, and T-shapes. We demonstrate
that ConPoSe scales better with the number of robots and object size than the
analytical approach, and also outperforms pure LLM-based selection.

</details>


### [17] [Point and Go: Intuitive Reference Frame Reallocation in Mode Switching for Assistive Robotics](https://arxiv.org/abs/2510.08753)
*A. Wang,C. Jiang,M. Przystupa,J. Valentine,M. Jagersand*

Main category: cs.RO

TL;DR: 提出了一种直观的Point and Go模式切换方法，显著提高机器人操控效率。


<details>
  <summary>Details</summary>
Motivation: 改善轮椅装载机器人操作者的控制体验，克服卡式模式切换的局限性。

Method: 提出了一种新的Point and Go模式切换方法，结合平移和旋转模式，简化了操作过程。

Result: 实验结果显示，Point and Go模式切换在完成时间、暂停次数和模式切换次数上均有显著减少，同时用户反馈也非常积极。

Conclusion: Point and Go模式切换显著提高了用户操作效率并获得了积极反馈。

Abstract: Operating high degree of freedom robots can be difficult for users of
wheelchair mounted robotic manipulators. Mode switching in Cartesian space has
several drawbacks such as unintuitive control reference frames, separate
translation and orientation control, and limited movement capabilities that
hinder performance. We propose Point and Go mode switching, which reallocates
the Cartesian mode switching reference frames into a more intuitive action
space comprised of new translation and rotation modes. We use a novel sweeping
motion to point the gripper, which defines the new translation axis along the
robot base frame's horizontal plane. This creates an intuitive `point and go'
translation mode that allows the user to easily perform complex, human-like
movements without switching control modes. The system's rotation mode combines
position control with a refined end-effector oriented frame that provides
precise and consistent robot actions in various end-effector poses. We verified
its effectiveness through initial experiments, followed by a three-task user
study that compared our method to Cartesian mode switching and a state of the
art learning method. Results show that Point and Go mode switching reduced
completion times by 31\%, pauses by 41\%, and mode switches by 33\%, while
receiving significantly favorable responses in user surveys.

</details>


### [18] [Whole Body Model Predictive Control for Spin-Aware Quadrupedal Table Tennis](https://arxiv.org/abs/2510.08754)
*David Nguyen,Zulfiqar Zaidi,Kevin Karol,Jessica Hodgins,Zhaoming Xie*

Main category: cs.RO

TL;DR: 开发能够模拟人类速度和准确性的乒乓球机器人是一项重大挑战。此论文展示了一个用于四足机器人动态乒乓球的系统，集成了高速度感知、轨迹预测和灵活控制能力。


<details>
  <summary>Details</summary>
Motivation: 当前乒乓球机器人在反应速度、准确性及对各种旋转的预测与反应能力上仍面临重大挑战，此研究旨在克服这些挑战。

Method: 系统结合外部摄像头进行高速球体定位，使用物理模型和学习残差推断旋转并预测轨迹，采用新型模型预测控制(MPC)实现灵活控制。

Result: 该系统在Spot四足机器人上进行验证，能够准确返回不同旋转类型的球，展现了协调性和灵活性。

Conclusion: 该系统能够通过不同的回球目标自动生成一系列连续的击球策略，并成功与人类玩家进行对打，展示了其在复杂动态环境中的应用潜力。

Abstract: Developing table tennis robots that mirror human speed, accuracy, and ability
to predict and respond to the full range of ball spins remains a significant
challenge for legged robots. To demonstrate these capabilities we present a
system to play dynamic table tennis for quadrupedal robots that integrates high
speed perception, trajectory prediction, and agile control. Our system uses
external cameras for high-speed ball localization, physical models with learned
residuals to infer spin and predict trajectories, and a novel model predictive
control (MPC) formulation for agile full-body control. Notably, a continuous
set of stroke strategies emerge automatically from different ball return
objectives using this control paradigm. We demonstrate our system in the real
world on a Spot quadruped, evaluate accuracy of each system component, and
exhibit coordination through the system's ability to aim and return balls with
varying spin types. As a further demonstration, the system is able to rally
with human players.

</details>


### [19] [Geometry-aware Policy Imitation](https://arxiv.org/abs/2510.08787)
*Yiming Li,Nael Darwiche,Amirreza Razmjoo,Sichao Liu,Yilun Du,Auke Ijspeert,Sylvain Calinon*

Main category: cs.RO

TL;DR: 提出了一种几何感知的模仿策略（GPI），通过将示范视为几何曲线，提高机器人模仿学习的效率和适应性。


<details>
  <summary>Details</summary>
Motivation: 重新思考模仿学习，通过将示范视为几何曲线，而不是简单的状态-动作样本集合，旨在提高机器人行为的控制能力。

Method: GPI通过从几何曲线中推导距离场，生成两个互补的控制原语，进而定义一个可控的非参数向量场来直接引导机器人行为。

Result: GPI方法在多种任务中表现出比扩散基础策略更高的成功率，同时运行速度快20倍，内存需求更少，并且对干扰保持稳健。

Conclusion: GPI被确立为机器人模仿学习中一种高效、可解释和可扩展的替代生成方法。

Abstract: We propose a Geometry-aware Policy Imitation (GPI) approach that rethinks
imitation learning by treating demonstrations as geometric curves rather than
collections of state-action samples. From these curves, GPI derives distance
fields that give rise to two complementary control primitives: a progression
flow that advances along expert trajectories and an attraction flow that
corrects deviations. Their combination defines a controllable, non-parametric
vector field that directly guides robot behavior. This formulation decouples
metric learning from policy synthesis, enabling modular adaptation across
low-dimensional robot states and high-dimensional perceptual inputs. GPI
naturally supports multimodality by preserving distinct demonstrations as
separate models and allows efficient composition of new demonstrations through
simple additions to the distance field. We evaluate GPI in simulation and on
real robots across diverse tasks. Experiments show that GPI achieves higher
success rates than diffusion-based policies while running 20 times faster,
requiring less memory, and remaining robust to perturbations. These results
establish GPI as an efficient, interpretable, and scalable alternative to
generative approaches for robotic imitation learning. Project website:
https://yimingli1998.github.io/projects/GPI/

</details>


### [20] [Humanoid Everyday: A Comprehensive Robotic Dataset for Open-World Humanoid Manipulation](https://arxiv.org/abs/2510.08807)
*Zhenyu Zhao,Hongyi Jing,Xiawei Liu,Jiageng Mao,Abha Jha,Hanwen Yang,Rong Xue,Sergey Zakharor,Vitor Guizilini,Yue Wang*

Main category: cs.RO

TL;DR: Humanoid Everyday是一个涵盖多样化人形机器人操作的庞大数据集，推动了这一领域的研究和评价标准化。


<details>
  <summary>Details</summary>
Motivation: 目前的机器人学习数据集和基准主要集中在静态机器人臂，缺乏多样化的人形机器人数据集，尤其是在与人类互动和下肢运动方面。

Method: 利用人类监督的远程操作流程，收集高质量的多模态感应数据，并引入了云评估平台以进行标准化评估。

Result: 提出了一个名为Humanoid Everyday的大规模多样化人形机器人操作数据集，包含超过3百万帧的高质量多模态传感器数据，以及10.3k个轨迹和260项任务。

Conclusion: 通过发布Humanoid Everyday和评估平台，旨在促进人形机器人操作的研究，推动实用机器人技术的发展。

Abstract: From loco-motion to dextrous manipulation, humanoid robots have made
remarkable strides in demonstrating complex full-body capabilities. However,
the majority of current robot learning datasets and benchmarks mainly focus on
stationary robot arms, and the few existing humanoid datasets are either
confined to fixed environments or limited in task diversity, often lacking
human-humanoid interaction and lower-body locomotion. Moreover, there are a few
standardized evaluation platforms for benchmarking learning-based policies on
humanoid data. In this work, we present Humanoid Everyday, a large-scale and
diverse humanoid manipulation dataset characterized by extensive task variety
involving dextrous object manipulation, human-humanoid interaction,
locomotion-integrated actions, and more. Leveraging a highly efficient
human-supervised teleoperation pipeline, Humanoid Everyday aggregates
high-quality multimodal sensory data, including RGB, depth, LiDAR, and tactile
inputs, together with natural language annotations, comprising 10.3k
trajectories and over 3 million frames of data across 260 tasks across 7 broad
categories. In addition, we conduct an analysis of representative policy
learning methods on our dataset, providing insights into their strengths and
limitations across different task categories. For standardized evaluation, we
introduce a cloud-based evaluation platform that allows researchers to
seamlessly deploy their policies in our controlled setting and receive
performance feedback. By releasing Humanoid Everyday along with our policy
learning analysis and a standardized cloud-based evaluation platform, we intend
to advance research in general-purpose humanoid manipulation and lay the
groundwork for more capable and embodied robotic agents in real-world
scenarios. Our dataset, data collection code, and cloud evaluation website are
made publicly available on our project website.

</details>


### [21] [Adaptive Motion Planning via Contact-Based Intent Inference for Human-Robot Collaboration](https://arxiv.org/abs/2510.08811)
*Jiurun Song,Xiao Liang,Minghui Zheng*

Main category: cs.RO

TL;DR: 本研究提出了一种基于接触的信息自适应运动规划框架，以直接从物理接触中推断人类意图，从而实现人机协作中的在线运动校正。


<details>
  <summary>Details</summary>
Motivation: 为了解决人机协作中机器人运动规划的复杂性和不可靠性，提出了一种新的框架，以提高安全性和效率。

Method: 采用基于优化的力估计方法推断人类意图，结合扭矩基础的接触检测机制和自适应运动规划器，实现实时运动规划与校正。

Result: 基于7自由度的机械手成功验证了所提方法在接触推断和运动规划中的准确性和有效性。

Conclusion: 实验验证了所提出的力估计方法的准确性和基于接触的自适应运动规划器在不确定环境下的有效性。

Abstract: Human-robot collaboration (HRC) requires robots to adapt their motions to
human intent to ensure safe and efficient cooperation in shared spaces.
Although large language models (LLMs) provide high-level reasoning for
inferring human intent, their application to reliable motion planning in HRC
remains challenging. Physical human-robot interaction (pHRI) is intuitive but
often relies on continuous kinesthetic guidance, which imposes burdens on
operators. To address these challenges, a contact-informed adaptive
motion-planning framework is introduced to infer human intent directly from
physical contact and employ the inferred intent for online motion correction in
HRC. First, an optimization-based force estimation method is proposed to infer
human-intended contact forces and locations from joint torque measurements and
a robot dynamics model, thereby reducing cost and installation complexity while
enabling whole-body sensitivity. Then, a torque-based contact detection
mechanism with link-level localization is introduced to reduce the optimization
search space and to enable real-time estimation. Subsequently, a
contact-informed adaptive motion planner is developed to infer human intent
from contacts and to replan robot motion online, while maintaining smoothness
and adapting to human corrections. Finally, experiments on a 7-DOF manipulator
are conducted to demonstrate the accuracy of the proposed force estimation
method and the effectiveness of the contact-informed adaptive motion planner
under perception uncertainty in HRC.

</details>


### [22] [Adaptive Science Operations in Deep Space Missions Using Offline Belief State Planning](https://arxiv.org/abs/2510.08812)
*Grace Ra Kim,Hailey Warner,Duncan Eddy,Evan Astle,Zachary Booth,Edward Balaban,Mykel J. Kochenderfer*

Main category: cs.RO

TL;DR: 为深空任务提出了一种POMDP框架，通过贝叶斯网络整合来有效管理高维不确定性数据，从而提高科学操作的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 深空任务面临极端的通信延迟和环境不确定性，无法进行实时地面操作，因此需要自主科学操作的支持。

Method: 采用部分可观察的马尔可夫决策过程(POMDP)框架来调整航天器科学仪器的顺序。

Result: 通过与任务的基准操作概念(ConOps)进行比较，我们的方法使样本识别错误减少了近40%。

Conclusion: 通过案例研究和比较实验，验证了该方法在样本识别方面的显著优势，提高了深空科学操作的可靠性。

Abstract: Deep space missions face extreme communication delays and environmental
uncertainty that prevent real-time ground operations. To support autonomous
science operations in communication-constrained environments, we present a
partially observable Markov decision process (POMDP) framework that adaptively
sequences spacecraft science instruments. We integrate a Bayesian network into
the POMDP observation space to manage the high-dimensional and uncertain
measurements typical of astrobiology missions. This network compactly encodes
dependencies among measurements and improves the interpretability and
computational tractability of science data. Instrument operation policies are
computed offline, allowing resource-aware plans to be generated and thoroughly
validated prior to launch. We use the Enceladus Orbilander's proposed Life
Detection Suite (LDS) as a case study, demonstrating how Bayesian network
structure and reward shaping influence system performance. We compare our
method against the mission's baseline Concept of Operations (ConOps),
evaluating both misclassification rates and performance in off-nominal sample
accumulation scenarios. Our approach reduces sample identification errors by
nearly 40%

</details>


### [23] [CDE: Concept-Driven Exploration for Reinforcement Learning](https://arxiv.org/abs/2510.08851)
*Le Mao,Andrew H. Liu,Renos Zabounidis,Zachary Kingston,Joseph Campbell*

Main category: cs.RO

TL;DR: 提出了一种名为CDE的概念驱动探索方法，用于视觉控制任务，通过生成视觉概念指导政策训练，从而实现高效的探索。


<details>
  <summary>Details</summary>
Motivation: 解决视觉控制任务中的智能探索挑战，尤其是在利用原始像素时的低效探索问题。

Method: 使用预训练的视觉语言模型生成物体中心的视觉概念，并通过重建这些概念进行策略训练

Result: 在五个复杂的模拟视觉操作任务中，CDE展现出出色的探索能力，并在现实世界的操作中取得80%的成功率。

Conclusion: CDE实现了高效、定向的探索，能够在实际操作中成功应用。

Abstract: Intelligent exploration remains a critical challenge in reinforcement
learning (RL), especially in visual control tasks. Unlike low-dimensional
state-based RL, visual RL must extract task-relevant structure from raw pixels,
making exploration inefficient. We propose Concept-Driven Exploration (CDE),
which leverages a pre-trained vision-language model (VLM) to generate
object-centric visual concepts from textual task descriptions as weak,
potentially noisy supervisory signals. Rather than directly conditioning on
these noisy signals, CDE trains a policy to reconstruct the concepts via an
auxiliary objective, using reconstruction accuracy as an intrinsic reward to
guide exploration toward task-relevant objects. Because the policy internalizes
these concepts, VLM queries are only needed during training, reducing
dependence on external models during deployment. Across five challenging
simulated visual manipulation tasks, CDE achieves efficient, targeted
exploration and remains robust to noisy VLM predictions. Finally, we
demonstrate real-world transfer by deploying CDE on a Franka Research 3 arm,
attaining an 80\% success rate in a real-world manipulation task.

</details>


### [24] [Online IMU-odometer Calibration using GNSS Measurements for Autonomous Ground Vehicle Localization](https://arxiv.org/abs/2510.08880)
*Baoshan Song,Xiao Xia,Penggao Yan,Yihan Zhong,Weisong Wen,Li-Ta Hsu*

Main category: cs.RO

TL;DR: 本论文提出了一种新的在线校准方法，通过融合IMU、里程计和GNSS测量，改进了自动驾驶车辆的定位准确性，并提供了开源数据集以支持后续研究。


<details>
  <summary>Details</summary>
Motivation: 准确的内部和外部参数校准对于自动驾驶地面车辆的定位至关重要，但现有的方法在可观测性特性上仍未深入研究。

Method: 采用扩展因子图优化框架，结合IMU、里程计和原始GNSS测量，实施异常值抑制和模糊解析。

Result: 提出了一种紧密耦合的在线校准方法，融合了IMU、里程计和原始GNSS测量，显著提高了校准和定位性能。

Conclusion: 仿真实验和实际应用表明，所提方法在车辆定位上表现优越，具有更好的校准和定位性能。

Abstract: Accurate calibration of intrinsic (odometer scaling factors) and extrinsic
parameters (IMU-odometer translation and rotation) is essential for autonomous
ground vehicle localization. Existing GNSS-aided approaches often rely on
positioning results or raw measurements without ambiguity resolution, and their
observability properties remain underexplored. This paper proposes a tightly
coupled online calibration method that fuses IMU, odometer, and raw GNSS
measurements (pseudo-range, carrier-phase, and Doppler) within an extendable
factor graph optimization (FGO) framework, incorporating outlier mitigation and
ambiguity resolution. Observability analysis reveals that two horizontal
translation and three rotation parameters are observable under general motion,
while vertical translation remains unobservable. Simulation and real-world
experiments demonstrate superior calibration and localization performance over
state-of-the-art loosely coupled methods. Specifically, the IMU-odometer
positioning using our calibrated parameters achieves the absolute maximum error
of 17.75 m while the one of LC method is 61.51 m, achieving up to 71.14 percent
improvement. To foster further research, we also release the first open-source
dataset that combines IMU, 2D odometer, and raw GNSS measurements from both
rover and base stations.

</details>


### [25] [Model-Based Lookahead Reinforcement Learning for in-hand manipulation](https://arxiv.org/abs/2510.08884)
*Alexandre Lopes,Catarina Barata,Plinio Moreno*

Main category: cs.RO

TL;DR: 本文利用混合强化学习框架改善机器人手中操控性能，但计算成本增加。


<details>
  <summary>Details</summary>
Motivation: 解决手中操控在机器人技术中的复杂动态系统问题，提升任务表现。

Method: 应用混合强化学习框架进行手中操控的任务

Result: 通过对照实验发现，混合框架在大多数测试案例中提高了手中操控的性能，尤其在对象属性变化时。

Conclusion: 尽管增加计算成本，混合框架在高奖励策略和准确动态模型的支持下，能显著提升手中操控的性能。

Abstract: In-Hand Manipulation, as many other dexterous tasks, remains a difficult
challenge in robotics by combining complex dynamic systems with the capability
to control and manoeuvre various objects using its actuators. This work
presents the application of a previously developed hybrid Reinforcement
Learning (RL) Framework to In-Hand Manipulation task, verifying that it is
capable of improving the performance of the task. The model combines concepts
of both Model-Free and Model-Based Reinforcement Learning, by guiding a trained
policy with the help of a dynamic model and value-function through trajectory
evaluation, as done in Model Predictive Control. This work evaluates the
performance of the model by comparing it with the policy that will be guided.
To fully explore this, various tests are performed using both fully-actuated
and under-actuated simulated robotic hands to manipulate different objects for
a given task. The performance of the model will also be tested for
generalization tests, by changing the properties of the objects in which both
the policy and dynamic model were trained, such as density and size, and
additionally by guiding a trained policy in a certain object to perform the
same task in a different one. The results of this work show that, given a
policy with high average reward and an accurate dynamic model, the hybrid
framework improves the performance of in-hand manipulation tasks for most test
cases, even when the object properties are changed. However, this improvement
comes at the expense of increasing the computational cost, due to the
complexity of trajectory evaluation.

</details>


### [26] [Direct Data-Driven Predictive Control for a Three-dimensional Cable-Driven Soft Robotic Arm](https://arxiv.org/abs/2510.08953)
*Cheng Ouyang,Moeen Ul Islam,Dong Chen,Kaixiang Zhang,Zhaojian Li,Xiaobo Tan*

Main category: cs.RO

TL;DR: 本文提出了一个基于数据的预测控制框架，用于三维软机器人，显示出优于传统模型控制的方法。


<details>
  <summary>Details</summary>
Motivation: 尽管软机器人在安全性和适应性上有显著优势，但实现精确和动态控制仍然是一个重大挑战。

Method: 开发并实验验证了一个数据驱动的预测控制框架，通过奇异值分解(SVD)降维，执行固定点调节和轨迹跟踪任务。

Result: 对比实验表明，DeePC在精度、鲁棒性和适应性方面优于基准模型控制器。

Conclusion: 这项研究表明，数据驱动的预测控制可以有效提升三维软机器人的动态控制性能，具有广泛的应用潜力。

Abstract: Soft robots offer significant advantages in safety and adaptability, yet
achieving precise and dynamic control remains a major challenge due to their
inherently complex and nonlinear dynamics. Recently, Data-enabled Predictive
Control (DeePC) has emerged as a promising model-free approach that bypasses
explicit system identification by directly leveraging input-output data. While
DeePC has shown success in other domains, its application to soft robots
remains underexplored, particularly for three-dimensional (3D) soft robotic
systems. This paper addresses this gap by developing and experimentally
validating an effective DeePC framework on a 3D, cable-driven soft arm.
Specifically, we design and fabricate a soft robotic arm with a thick tubing
backbone for stability, a dense silicone body with large cavities for strength
and flexibility, and rigid endcaps for secure termination. Using this platform,
we implement DeePC with singular value decomposition (SVD)-based dimension
reduction for two key control tasks: fixed-point regulation and trajectory
tracking in 3D space. Comparative experiments with a baseline model-based
controller demonstrate DeePC's superior accuracy, robustness, and adaptability,
highlighting its potential as a practical solution for dynamic control of soft
robots.

</details>


### [27] [A geometrical approach to solve the proximity of a point to an axisymmetric quadric in space](https://arxiv.org/abs/2510.08973)
*Bibekananda Patra,Aditya Mahesh Kolte,Sandipan Bandyopadhyay*

Main category: cs.RO

TL;DR: 该论文介绍了轴对称二次曲面的分类和接近问题的解决方法，提出了一种新颖且有效的在R^2中处理二次曲面接近问题的方法。


<details>
  <summary>Details</summary>
Motivation: 研究如何将三维空间中的接近问题简化为二维空间，以提高计算效率并填补文献中相关研究的空白。

Method: 通过二次曲面的几何特性（如副法线、半长轴长度、离心率、斜率和半径）在R^2中解决接近问题，并将问题分类为不同的子情况。

Result: 本论文提出了对一般二次曲面的分类及将给定点与轴对称二次曲面（AQ）之间的接近问题的解决方案。

Conclusion: 提出的方法在常用编程语言中适用，执行速度优于商业库Bullet。

Abstract: This paper presents the classification of a general quadric into an
axisymmetric quadric (AQ) and the solution to the problem of the proximity of a
given point to an AQ. The problem of proximity in $R^3$ is reduced to the same
in $R^2$, which is not found in the literature. A new method to solve the
problem in $R^2$ is used based on the geometrical properties of the conics,
such as sub-normal, length of the semi-major axis, eccentricity, slope and
radius. Furthermore, the problem in $R^2$ is categorised into two and three
more sub-cases for parabola and ellipse/hyperbola, respectively, depending on
the location of the point, which is a novel approach as per the authors'
knowledge. The proposed method is suitable for implementation in a common
programming language, such as C and proved to be faster than a commercial
library, namely, Bullet.

</details>


### [28] [Training Models to Detect Successive Robot Errors from Human Reactions](https://arxiv.org/abs/2510.09080)
*Shannon Liu,Maria Teresa Parreira,Wendy Ju*

Main category: cs.RO

TL;DR: 本研究通过机器学习探讨如何利用人类反应识别机器人连续失败，以改善人机交互中的错误检测。


<details>
  <summary>Details</summary>
Motivation: 随着机器人逐渐融入社会，发现机器人错误对有效的人机交互至关重要。

Method: 使用机器学习识别机器人失败阶段

Result: 研究展示了通过人类反应来识别机器人错误阶段的有效性，最好的模型在错误检测上准确率为93.5%，在分类连续失败上为84.1%。

Conclusion: 建模人类反应的演变有助于提高错误检测能力，并加深对人机交互中反复互动失败的理解。

Abstract: As robots become more integrated into society, detecting robot errors is
essential for effective human-robot interaction (HRI). When a robot fails
repeatedly, how can it know when to change its behavior? Humans naturally
respond to robot errors through verbal and nonverbal cues that intensify over
successive failures-from confusion and subtle speech changes to visible
frustration and impatience. While prior work shows that human reactions can
indicate robot failures, few studies examine how these evolving responses
reveal successive failures. This research uses machine learning to recognize
stages of robot failure from human reactions. In a study with 26 participants
interacting with a robot that made repeated conversational errors, behavioral
features were extracted from video data to train models for individual users.
The best model achieved 93.5% accuracy for detecting errors and 84.1% for
classifying successive failures. Modeling the progression of human reactions
enhances error detection and understanding of repeated interaction breakdowns
in HRI.

</details>


### [29] [Trust Modeling and Estimation in Human-Autonomy Interactions](https://arxiv.org/abs/2510.09013)
*Daniel A. Williams,Airlie Chapman,Daniel R. Little,Chris Manzie*

Main category: cs.RO

TL;DR: 本文提出了一种新的模型来估计监督者对自主系统的信任动态，考虑了不对称反应和间歇性沟通的特点。


<details>
  <summary>Details</summary>
Motivation: 随着自主系统应用的增加，监督者与系统间的信任关系显得尤其重要，现有文献缺乏相应的模型来描述这种信任的动态变化。

Method: 通过使用带有事件触发采样的切换线性系统结构，构建了监督者信任的估计模型。

Result: 用户研究中收集的信任反应数据被用来识别切换线性模型观察器的参数。

Conclusion: 该研究为理解和量化监督者信任动态提供了新的理论基础，并为自主系统设计者提供了有价值的参考。

Abstract: Advances in the control of autonomous systems have accompanied an expansion
in the potential applications for autonomous robotic systems. The success of
applications involving humans depends on the quality of interaction between the
autonomous system and the human supervisor, which is particularly affected by
the degree of trust that the supervisor places in the autonomous system. Absent
from the literature are models of supervisor trust dynamics that can
accommodate asymmetric responses to autonomous system performance and the
intermittent nature of supervisor-autonomous system communication. This paper
focuses on formulating an estimated model of supervisor trust that incorporates
both of these features by employing a switched linear system structure with
event-triggered sampling of the model input and output. Trust response data
collected in a user study with 51 participants were then used identify
parameters for a switched linear model-based observer of supervisor trust.

</details>


### [30] [iMoWM: Taming Interactive Multi-Modal World Model for Robotic Manipulation](https://arxiv.org/abs/2510.09036)
*Chuanrui Zhang,Zhengxian Wu,Guanxing Lu,Yansong Tang,Ziwei Wang*

Main category: cs.RO

TL;DR: iMoWM是一种新型的交互式世界模型，旨在通过多模态输入改进机器人的操作模拟。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有2D视频世界模型在几何和空间推理方面的局限性，尤其是对于3D世界的物理结构的捕捉

Method: 提出了一个新的交互式世界模型iMoWM，采用自回归方式生成颜色图像、深度图和机器人手臂掩模

Result: iMoWM能够通过多模态表示来提升未来预测的视觉质量，同时有效作为基于模型的强化学习和现实模仿学习的模拟器

Conclusion: 广泛的实验结果表明iMoWM在各种任务中的优势，展示了多模态世界建模在机器人操作中的潜力。

Abstract: Learned world models hold significant potential for robotic manipulation, as
they can serve as simulator for real-world interactions. While extensive
progress has been made in 2D video-based world models, these approaches often
lack geometric and spatial reasoning, which is essential for capturing the
physical structure of the 3D world. To address this limitation, we introduce
iMoWM, a novel interactive world model designed to generate color images, depth
maps, and robot arm masks in an autoregressive manner conditioned on actions.
To overcome the high computational cost associated with three-dimensional
information, we propose MMTokenizer, which unifies multi-modal inputs into a
compact token representation. This design enables iMoWM to leverage large-scale
pretrained VideoGPT models while maintaining high efficiency and incorporating
richer physical information. With its multi-modal representation, iMoWM not
only improves the visual quality of future predictions but also serves as an
effective simulator for model-based reinforcement learning (MBRL) and
facilitates real-world imitation learning. Extensive experiments demonstrate
the superiority of iMoWM across these tasks, showcasing the advantages of
multi-modal world modeling for robotic manipulation. Homepage:
https://xingyoujun.github.io/imowm/

</details>


### [31] [Robust Visual Teach-and-Repeat Navigation with Flexible Topo-metric Graph Map Representation](https://arxiv.org/abs/2510.09089)
*Jikai Wang,Yunqi Cheng,Kezhi Wang,Zonghai Chen*

Main category: cs.RO

TL;DR: 本论文提出了一种新型视觉教学与重复导航系统，通过灵活的地图表示和改进的匹配方法，增强了移动机器人的导航能力。


<details>
  <summary>Details</summary>
Motivation: 解决移动机器人在未知环境中进行鲁棒轨迹重复导航的挑战，尤其是环境变化和动态障碍物带来的影响。

Method: 提出了一种新颖的视觉教学与重复导航系统，包含灵活的地图表示、鲁棒的地图匹配和无图局部导航模块。

Result: 在多次实验中，该系统显示出在鲁棒性和有效性方面较基线方法有显著优势。

Conclusion: 该系统在鲁棒性和有效性方面优于基线方法。

Abstract: Visual Teach-and-Repeat Navigation is a direct solution for mobile robot to
be deployed in unknown environments. However, robust trajectory repeat
navigation still remains challenged due to environmental changing and dynamic
objects. In this paper, we propose a novel visual teach-and-repeat navigation
system, which consists of a flexible map representation, robust map matching
and a map-less local navigation module. During the teaching process, the
recorded keyframes are formulated as a topo-metric graph and each node can be
further extended to save new observations. Such representation also alleviates
the requirement of globally consistent mapping. To enhance the place
recognition performance during repeating process, instead of using
frame-to-frame matching, we firstly implement keyframe clustering to aggregate
similar connected keyframes into local map and perform place recognition based
on visual frame-tolocal map matching strategy. To promote the local goal
persistent tracking performance, a long-term goal management algorithm is
constructed, which can avoid the robot getting lost due to environmental
changes or obstacle occlusion. To achieve the goal without map, a local
trajectory-control candidate optimization algorithm is proposed. Extensively
experiments are conducted on our mobile platform. The results demonstrate that
our system is superior to the baselines in terms of robustness and
effectiveness.

</details>


### [32] [When a Robot is More Capable than a Human: Learning from Constrained Demonstrators](https://arxiv.org/abs/2510.09096)
*Xinhu Li,Ayush Jain,Zhaojing Yang,Yigit Korkmaz,Erdem Bıyık*

Main category: cs.RO

TL;DR: 本研究提出一种新方法，通过推断奖励信号，让机器人在学习中超越受限专家的演示，从而提高样本效率和任务完成速度。


<details>
  <summary>Details</summary>
Motivation: 解决受限专家演示导致的次优政策问题，提升机器人的学习效果。

Method: 通过推断状态惩罚信号，自我标记未知状态的奖励，提供超越直接模仿的探索策略。

Result: 在真实的WidowX机械臂上，该方法以12秒完成任务，比行为克隆快10倍。

Conclusion: 该方法在样本效率和任务完成时间方面优于常见的模仿学习。

Abstract: Learning from demonstrations enables experts to teach robots complex tasks
using interfaces such as kinesthetic teaching, joystick control, and
sim-to-real transfer. However, these interfaces often constrain the expert's
ability to demonstrate optimal behavior due to indirect control, setup
restrictions, and hardware safety. For example, a joystick can move a robotic
arm only in a 2D plane, even though the robot operates in a higher-dimensional
space. As a result, the demonstrations collected by constrained experts lead to
suboptimal performance of the learned policies. This raises a key question: Can
a robot learn a better policy than the one demonstrated by a constrained
expert? We address this by allowing the agent to go beyond direct imitation of
expert actions and explore shorter and more efficient trajectories. We use the
demonstrations to infer a state-only reward signal that measures task progress,
and self-label reward for unknown states using temporal interpolation. Our
approach outperforms common imitation learning in both sample efficiency and
task completion time. On a real WidowX robotic arm, it completes the task in 12
seconds, 10x faster than behavioral cloning, as shown in real-robot videos on
https://sites.google.com/view/constrainedexpert .

</details>


### [33] [Decentralized Multi-Robot Relative Navigation in Unknown, Structurally Constrained Environments under Limited Communication](https://arxiv.org/abs/2510.09188)
*Zihao Mao,Yunheng Wang,Yunting Ji,Yi Yang,Wenjie Song*

Main category: cs.RO

TL;DR: 本论文提出了一种分层的多机器人导航框架，结合全局规划与局部操作，显著提高了在复杂环境中的导航效率与成功率。


<details>
  <summary>Details</summary>
Motivation: 解决在未知、结构性约束和无GPS环境中的多机器人导航问题，平衡全局战略前瞻性与局部战术灵活性，尤其是在通信有限的情况下。

Method: 提出一种完全分散的分层相对导航框架，结合了策略层和战术层，前者基于轻量级拓扑地图进行全局规划，后者基于局部信息进行实时动态轨迹生成。

Result: 通过广泛的仿真和实际实验验证了系统的优越性，显示出在复杂拓扑结构中响应快速且高效。

Conclusion: 该系统在成功率和效率方面显著优于其他方法，特别是在通信受限且结构复杂的环境中。

Abstract: Multi-robot navigation in unknown, structurally constrained, and GPS-denied
environments presents a fundamental trade-off between global strategic
foresight and local tactical agility, particularly under limited communication.
Centralized methods achieve global optimality but suffer from high
communication overhead, while distributed methods are efficient but lack the
broader awareness to avoid deadlocks and topological traps. To address this, we
propose a fully decentralized, hierarchical relative navigation framework that
achieves both strategic foresight and tactical agility without a unified
coordinate system. At the strategic layer, robots build and exchange
lightweight topological maps upon opportunistic encounters. This process
fosters an emergent global awareness, enabling the planning of efficient,
trap-avoiding routes at an abstract level. This high-level plan then inspires
the tactical layer, which operates on local metric information. Here, a
sampling-based escape point strategy resolves dense spatio-temporal conflicts
by generating dynamically feasible trajectories in real time, concurrently
satisfying tight environmental and kinodynamic constraints. Extensive
simulations and real-world experiments demonstrate that our system
significantly outperforms in success rate and efficiency, especially in
communication-limited environments with complex topological structures.

</details>


### [34] [Flow-Opt: Scalable Centralized Multi-Robot Trajectory Optimization with Flow Matching and Differentiable Optimization](https://arxiv.org/abs/2510.09204)
*Simon Idoko,Arun Kumar Singh*

Main category: cs.RO

TL;DR: Flow-Opt是一种基于学习的集中化多机器人轨迹优化方法，显著提高了计算效率和轨迹平滑性，能在短时间内生成多条轨迹并捕捉不同的避碰行为。


<details>
  <summary>Details</summary>
Motivation: 集中化的多机器人轨迹优化在紧凑空间中能够获得更大的可行空间并生成更平滑的轨迹，但计算开销使其在较大规模的机器人群中不可行。

Method: 首先学习生成模型以抽样不同候选轨迹，然后使用学习的安全过滤器(SF)确保约束条件的满足，结合扩散变换器(DiT)和神经网络进行上下文初始化预测。

Result: 提出了一种名为Flow-Opt的学习方法，提高了集中式多机器人轨迹优化的计算可行性，能在数十毫秒内生成多个机器人在复杂环境中的轨迹。

Conclusion: 通过Flow-Opt，能够在复杂环境中快速生成多机器人轨迹，并捕捉多样的避碰行为，超越了现有的集中优化方法。

Abstract: Centralized trajectory optimization in the joint space of multiple robots
allows access to a larger feasible space that can result in smoother
trajectories, especially while planning in tight spaces. Unfortunately, it is
often computationally intractable beyond a very small swarm size. In this
paper, we propose Flow-Opt, a learning-based approach towards improving the
computational tractability of centralized multi-robot trajectory optimization.
Specifically, we reduce the problem to first learning a generative model to
sample different candidate trajectories and then using a learned
Safety-Filter(SF) to ensure fast inference-time constraint satisfaction. We
propose a flow-matching model with a diffusion transformer (DiT) augmented with
permutation invariant robot position and map encoders as the generative model.
We develop a custom solver for our SF and equip it with a neural network that
predicts context-specific initialization. The initialization network is trained
in a self-supervised manner, taking advantage of the differentiability of the
SF solver. We advance the state-of-the-art in the following respects. First, we
show that we can generate trajectories of tens of robots in cluttered
environments in a few tens of milliseconds. This is several times faster than
existing centralized optimization approaches. Moreover, our approach also
generates smoother trajectories orders of magnitude faster than competing
baselines based on diffusion models. Second, each component of our approach can
be batched, allowing us to solve a few tens of problem instances in a fraction
of a second. We believe this is a first such result; no existing approach
provides such capabilities. Finally, our approach can generate a diverse set of
trajectories between a given set of start and goal locations, which can capture
different collision-avoidance behaviors.

</details>


### [35] [PLEXUS Hand: Lightweight Four-Motor Prosthetic Hand Enabling Precision-Lateral Dexterous Manipulation](https://arxiv.org/abs/2510.09209)
*Yuki Kuroda,Tomoya Takahashi,Cristian C Beltran-Hernandez,Masashi Hamaya,Kazutoshi Tanaka*

Main category: cs.RO

TL;DR: 本研究提出一种轻量化电动假手，能够实现基本姿态与手内操作，仅使用四个电机，成功率高。


<details>
  <summary>Details</summary>
Motivation: 电动假手需要既轻便又具可操作性，以适应日常生活中的活动，特别是手内操作和各种姿态转换。

Method: 结合单轴拇指和优化的拇指定位，实现基本姿态与手内操作，使用仅四个电机的轻量化假手。

Result: 实验验证显示，该假手在宽度为5-30mm的各种原始物体上，完成重定向任务的成功率高达90-100%。

Conclusion: 新型假手证明了可以在保证轻量化的同时，实现在日常使用中的基本操作和手内操作，展示了其应用潜力。

Abstract: Electric prosthetic hands should be lightweight to decrease the burden on the
user, shaped like human hands for cosmetic purposes, and have motors inside to
protect them from damage and dirt. In addition to the ability to perform daily
activities, these features are essential for everyday use of the hand. In-hand
manipulation is necessary to perform daily activities such as transitioning
between different postures, particularly through rotational movements, such as
reorienting cards before slot insertion and operating tools such as
screwdrivers. However, currently used electric prosthetic hands only achieve
static grasp postures, and existing manipulation approaches require either many
motors, which makes the prosthesis heavy for daily use in the hand, or complex
mechanisms that demand a large internal space and force external motor
placement, complicating attachment and exposing the components to damage.
Alternatively, we combine a single-axis thumb and optimized thumb positioning
to achieve basic posture and in-hand manipulation, that is, the reorientation
between precision and lateral grasps, using only four motors in a lightweight
(311 g) prosthetic hand. Experimental validation using primitive objects of
various widths (5-30 mm) and shapes (cylinders and prisms) resulted in success
rates of 90-100% for reorientation tasks. The hand performed seal stamping and
USB device insertion, as well as rotation to operate a screwdriver.

</details>


### [36] [HANDO: Hierarchical Autonomous Navigation and Dexterous Omni-loco-manipulation](https://arxiv.org/abs/2510.09221)
*Jingyuan Sun,Chaoran Wang,Mingyu Zhang,Cui Miao,Hongyu Ji,Zihan Qu,Han Sun,Bing Wang,Qingyi Si*

Main category: cs.RO

TL;DR: 本文提出HANDO框架，促进了四足机器人的自主探索与全身操控，应用于人性化移动操控任务。


<details>
  <summary>Details</summary>
Motivation: 无缝的机器人在非结构化环境中的操控能力，结合自主探索和全身控制。

Method: 框架分为两层，第一层为目标导向的自主探索策略，第二层为统一的全身操控策略。

Result: 提出了一个名为HANDO的两层框架，使得具有操控器的四足机器人能够执行以人为中心的移动操控任务。

Conclusion: 已进行了导航模块的初步部署，并将继续进行更细粒度的全身操控部署。

Abstract: Seamless loco-manipulation in unstructured environments requires robots to
leverage autonomous exploration alongside whole-body control for physical
interaction. In this work, we introduce HANDO (Hierarchical Autonomous
Navigation and Dexterous Omni-loco-manipulation), a two-layer framework
designed for legged robots equipped with manipulators to perform human-centered
mobile manipulation tasks. The first layer utilizes a goal-conditioned
autonomous exploration policy to guide the robot to semantically specified
targets, such as a black office chair in a dynamic environment. The second
layer employs a unified whole-body loco-manipulation policy to coordinate the
arm and legs for precise interaction tasks-for example, handing a drink to a
person seated on the chair. We have conducted an initial deployment of the
navigation module, and will continue to pursue finer-grained deployment of
whole-body loco-manipulation.

</details>


### [37] [Glovity: Learning Dexterous Contact-Rich Manipulation via Spatial Wrench Feedback Teleoperation System](https://arxiv.org/abs/2510.09229)
*Yuyang Gao,Haofei Ma,Pai Zheng*

Main category: cs.RO

TL;DR: Glovity 是一种新型低成本可穿戴遥操作系统，提供直观的扭矩和触觉反馈，大幅提高了接触丰富任务的成功率和效率，相关硬件和软件将开源。


<details>
  <summary>Details</summary>
Motivation: 解决接触丰富任务中的反馈不足问题，通过精准的重定向来减少身体现象的差距。

Method: 结合空间扭矩反馈设备和触觉手套，使用 Hall 传感器进行指尖校准。

Result: 在用户研究中，书籍翻页任务的成功率从 48% 提升到 78%，完成时间减少了 25%。

Conclusion: Glovity 系统显著提升了接触丰富任务的成功率和效率，并为模仿学习提供了良好的基础。

Abstract: We present Glovity, a novel, low-cost wearable teleoperation system that
integrates a spatial wrench (force-torque) feedback device with a haptic glove
featuring fingertip Hall sensor calibration, enabling feedback-rich dexterous
manipulation. Glovity addresses key challenges in contact-rich tasks by
providing intuitive wrench and tactile feedback, while overcoming embodiment
gaps through precise retargeting. User studies demonstrate significant
improvements: wrench feedback boosts success rates in book-flipping tasks from
48% to 78% and reduces completion time by 25%, while fingertip calibration
enhances thin-object grasping success significantly compared to commercial
glove. Furthermore, incorporating wrench signals into imitation learning (via
DP-R3M) achieves high success rate in novel contact-rich scenarios, such as
adaptive page flipping and force-aware handovers. All hardware designs,
software will be open-sourced. Project website: https://glovity.github.io/

</details>


### [38] [Obstacle Avoidance using Dynamic Movement Primitives and Reinforcement Learning](https://arxiv.org/abs/2510.09254)
*Dominik Urbaniak,Alejandro Agostini,Pol Ramon,Jan Rosell,Raúl Suárez,Michael Suppa*

Main category: cs.RO

TL;DR: 此研究提出了一种基于单个人工示范生成近似最优3D轨迹的学习方法，验证结果表明其在性能上优于传统的RRT-Connect方法。


<details>
  <summary>Details</summary>
Motivation: 学习型运动规划通常需要大量训练数据或昂贵的人类演示。本研究旨在通过单一的人工演示快速生成平滑、近似最优的无碰撞3D轨迹。

Method: 通过DMP对人工演示进行编码，并采用基于策略的强化学习进行迭代重塑，以创建多样化的轨迹数据集。使用神经网络处理任务参数并生成轨迹。

Result: 能够高效产生适应不同障碍配置的平滑轨迹，改善了传统方法在人类示范需求和数据集规模上的不足。

Conclusion: 所提方法在模拟和实际机器人实验中表现优于RRT-Connect基线, 在计算和执行时间以及轨迹长度方面具有优势, 支持针对不同障碍几何和末端执行器尺寸的多模式轨迹生成。

Abstract: Learning-based motion planning can quickly generate near-optimal
trajectories. However, it often requires either large training datasets or
costly collection of human demonstrations. This work proposes an alternative
approach that quickly generates smooth, near-optimal collision-free 3D
Cartesian trajectories from a single artificial demonstration. The
demonstration is encoded as a Dynamic Movement Primitive (DMP) and iteratively
reshaped using policy-based reinforcement learning to create a diverse
trajectory dataset for varying obstacle configurations. This dataset is used to
train a neural network that takes as inputs the task parameters describing the
obstacle dimensions and location, derived automatically from a point cloud, and
outputs the DMP parameters that generate the trajectory. The approach is
validated in simulation and real-robot experiments, outperforming a RRT-Connect
baseline in terms of computation and execution time, as well as trajectory
length, while supporting multi-modal trajectory generation for different
obstacle geometries and end-effector dimensions. Videos and the implementation
code are available at https://github.com/DominikUrbaniak/obst-avoid-dmp-pi2.

</details>


### [39] [Placeit! A Framework for Learning Robot Object Placement Skills](https://arxiv.org/abs/2510.09267)
*Amina Ferrad,Johann Huber,François Hélénon,Julien Gleyze,Mahdi Khoramshahi,Stéphane Doncieux*

Main category: cs.RO

TL;DR: 引入Placeit!作为一个新的进化计算框架，旨在解决物体放置的挑战，并生成高质量的训练数据。


<details>
  <summary>Details</summary>
Motivation: 应对机器人研究中学习基本技能（如物体放置）的挑战，以及获取大规模高质量数据的瓶颈.

Method: Placeit!是一个进化计算框架，用于生成刚性物体的有效放置位置。

Result: Placeit!在生成多样有效姿态方面显著优于最先进的方法，并且在120个真实世界的部署中实现了90%的成功率。

Conclusion: Placeit!不仅是开放环境下捡放任务的强大工具，还为训练仿真基础模型生成所需的数据提供了宝贵引擎。

Abstract: Robotics research has made significant strides in learning, yet mastering
basic skills like object placement remains a fundamental challenge. A key
bottleneck is the acquisition of large-scale, high-quality data, which is often
a manual and laborious process. Inspired by Graspit!, a foundational work that
used simulation to automatically generate dexterous grasp poses, we introduce
Placeit!, an evolutionary-computation framework for generating valid placement
positions for rigid objects. Placeit! is highly versatile, supporting tasks
from placing objects on tables to stacking and inserting them. Our experiments
show that by leveraging quality-diversity optimization, Placeit! significantly
outperforms state-of-the-art methods across all scenarios for generating
diverse valid poses. A pick&place pipeline built on our framework achieved a
90% success rate over 120 real-world deployments. This work positions Placeit!
as a powerful tool for open-environment pick-and-place tasks and as a valuable
engine for generating the data needed to train simulation-based foundation
models in robotics.

</details>


### [40] [Bridging Research and Practice in Simulation-based Testing of Industrial Robot Navigation Systems](https://arxiv.org/abs/2510.09396)
*Sajad Khatiri,Francisco Eli Vina Barrientos,Maximilian Wulf,Paolo Tonella,Sebastiano Panichella*

Main category: cs.RO

TL;DR: 本文提出了Surrealist框架在ANYmal四足机器人中的应用，通过自动生成测试场景，提高了工业检测过程中的算法稳健性，并发现了关键失败。


<details>
  <summary>Details</summary>
Motivation: 在动态环境中确保机器人导航的稳健性是一个关键挑战，传统测试方法难以覆盖全面的操作需求。

Method: 运用基于搜索的算法自动生成具有挑战性的障碍物规避场景，进行模拟测试。

Result: 生成的测试套件揭示了一个实验算法的关键弱点（成功率40.3%），并有效证明了另一个算法的更高稳健性（成功率71.2%）。并且在为期六个月的工业评估中，集成到了ANYbotics工作流程中，用以测试五个专有算法。

Conclusion: 本研究表明，Surrealist框架在工业环境中有效提升了ANYmal机器人的导航可靠性，关键算法的成功率得到了显著改善。

Abstract: Ensuring robust robotic navigation in dynamic environments is a key
challenge, as traditional testing methods often struggle to cover the full
spectrum of operational requirements. This paper presents the industrial
adoption of Surrealist, a simulation-based test generation framework originally
for UAVs, now applied to the ANYmal quadrupedal robot for industrial
inspection. Our method uses a search-based algorithm to automatically generate
challenging obstacle avoidance scenarios, uncovering failures often missed by
manual testing. In a pilot phase, generated test suites revealed critical
weaknesses in one experimental algorithm (40.3% success rate) and served as an
effective benchmark to prove the superior robustness of another (71.2% success
rate). The framework was then integrated into the ANYbotics workflow for a
six-month industrial evaluation, where it was used to test five proprietary
algorithms. A formal survey confirmed its value, showing it enhances the
development process, uncovers critical failures, provides objective benchmarks,
and strengthens the overall verification pipeline.

</details>


### [41] [Failure Prediction at Runtime for Generative Robot Policies](https://arxiv.org/abs/2510.09459)
*Ralf Römer,Adrian Kobras,Luca Worbis,Angela P. Schoellig*

Main category: cs.RO

TL;DR: FIPER是一种通用框架，用于生成IL策略在运行时的失败预测，通过识别关键指标和无需失败数据的方式实现更安全的机器人应用。


<details>
  <summary>Details</summary>
Motivation: 在复杂和长时间的任务中，模仿学习（IL）与生成模型结合，允许机器人执行更高效。但未见环境的分布转移或累积的动作错误可能导致不可预测和不安全的行为，造成任务失败，因此在运行时提前预测失败至关重要。

Method: FIPER通过识别即将失败的两个关键指标（OOD观察和动作不确定性）来进行预测，并利用小规模成功回合的数据进行标定。

Result: 本研究提出了一种名为FIPER的框架，用于运行时预测生成IL政策的失败，该框架不需要失败数据，并在多种环境中进行了评估，展示了其有效性。

Conclusion: 我们认为此工作是朝着更可解释和安全的生成机器人策略迈出的重要一步，能更准确和提前地预测失败。

Abstract: Imitation learning (IL) with generative models, such as diffusion and flow
matching, has enabled robots to perform complex, long-horizon tasks. However,
distribution shifts from unseen environments or compounding action errors can
still cause unpredictable and unsafe behavior, leading to task failure. Early
failure prediction during runtime is therefore essential for deploying robots
in human-centered and safety-critical environments. We propose FIPER, a general
framework for Failure Prediction at Runtime for generative IL policies that
does not require failure data. FIPER identifies two key indicators of impending
failure: (i) out-of-distribution (OOD) observations detected via random network
distillation in the policy's embedding space, and (ii) high uncertainty in
generated actions measured by a novel action-chunk entropy score. Both failure
prediction scores are calibrated using a small set of successful rollouts via
conformal prediction. A failure alarm is triggered when both indicators,
aggregated over short time windows, exceed their thresholds. We evaluate FIPER
across five simulation and real-world environments involving diverse failure
modes. Our results demonstrate that FIPER better distinguishes actual failures
from benign OOD situations and predicts failures more accurately and earlier
than existing methods. We thus consider this work an important step towards
more interpretable and safer generative robot policies. Code, data and videos
are available at https://tum-lsy.github.io/fiper_website.

</details>


### [42] [FOGMACHINE -- Leveraging Discrete-Event Simulation and Scene Graphs for Modeling Hierarchical, Interconnected Environments under Partial Observations from Mobile Agents](https://arxiv.org/abs/2510.09483)
*Lars Ohnemus,Nils Hantke,Max Weißer,Kai Furmans*

Main category: cs.RO

TL;DR: FOGMACHINE框架结合了动态场景图和离散事件仿真，为具身AI提供了一种有效的工具，以处理复杂的不确定环境中的不确定性传播和规划问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以捕捉随机动态、部分可观测性和多Agent活动，这在不确定性和延迟感知下的具身AI中至关重要。

Method: 引入FOGMACHINE框架，将动态场景图（DSGs）与离散事件仿真相融合，模拟物体动态、代理观察和多Agent交互。

Result: 通过在城市场景中的实验，FOGMACHINE揭示了稀疏观察下的信念估计挑战，以及现实的时间和空间模式。

Conclusion: FOGMACHINE为在复杂不确定环境中推进具身AI研究提供了有效的基准测试和模型训练工具。

Abstract: Dynamic Scene Graphs (DSGs) provide a structured representation of
hierarchical, interconnected environments, but current approaches struggle to
capture stochastic dynamics, partial observability, and multi-agent activity.
These aspects are critical for embodied AI, where agents must act under
uncertainty and delayed perception. We introduce FOGMACHINE , an open-source
framework that fuses DSGs with discrete-event simulation to model object
dynamics, agent observations, and interactions at scale. This setup enables the
study of uncertainty propagation, planning under limited perception, and
emergent multi-agent behavior. Experiments in urban scenarios illustrate
realistic temporal and spatial patterns while revealing the challenges of
belief estimation under sparse observations. By combining structured
representations with efficient simulation, FOGMACHINE establishes an effective
tool for benchmarking, model training, and advancing embodied AI in complex,
uncertain environments.

</details>


### [43] [Autonomous Soft Robotic Guidewire Navigation via Imitation Learning](https://arxiv.org/abs/2510.09497)
*Noah Barnes,Ji Woong Kim,Lingyun Di,Hannah Qu,Anuruddha Bhattacharjee,Miroslaw Janowski,Dheeraj Gandhi,Bailey Felix,Shaopeng Jiang,Olivia Young,Mark Fuge,Ryan D. Sochol,Jeremy D. Brown,Axel Krieger*

Main category: cs.RO

TL;DR: 本研究开发了一种基于变压器的模仿学习框架，旨在改善软机器人导线在动脉瘤靶向任务中的导航能力。


<details>
  <summary>Details</summary>
Motivation: 提高血管内手术中导线的操控精度与安全性，克服现有的建模与控制挑战。

Method: 通过模仿学习并结合目标条件和相对动作输出，训练模型以实现软机器人导管的导航。

Result: 在36种不同血管几何形状的模拟荧光影像下训练，并在三个未见过的几何形状上评估，取得了83%的成功率。

Conclusion: 该模型能够在未知血管几何条件下以83%的成功率自主完成动脉瘤导航，展示了其有效性。

Abstract: In endovascular surgery, endovascular interventionists push a thin tube
called a catheter, guided by a thin wire to a treatment site inside the
patient's blood vessels to treat various conditions such as blood clots,
aneurysms, and malformations. Guidewires with robotic tips can enhance
maneuverability, but they present challenges in modeling and control.
Automation of soft robotic guidewire navigation has the potential to overcome
these challenges, increasing the precision and safety of endovascular
navigation. In other surgical domains, end-to-end imitation learning has shown
promising results. Thus, we develop a transformer-based imitation learning
framework with goal conditioning, relative action outputs, and automatic
contrast dye injections to enable generalizable soft robotic guidewire
navigation in an aneurysm targeting task. We train the model on 36 different
modular bifurcated geometries, generating 647 total demonstrations under
simulated fluoroscopy, and evaluate it on three previously unseen vascular
geometries. The model can autonomously drive the tip of the robot to the
aneurysm location with a success rate of 83% on the unseen geometries,
outperforming several baselines. In addition, we present ablation and baseline
studies to evaluate the effectiveness of each design and data collection
choice. Project website: https://softrobotnavigation.github.io/

</details>


### [44] [Dynamic Quadrupedal Legged and Aerial Locomotion via Structure Repurposing](https://arxiv.org/abs/2510.09526)
*Chenghao Wang,Kaushik Venkatesh Krishnamurthy,Shreyansh Pitroda,Adarsh Salagame,Ioannis Mandralis,Eric Sihite,Alireza Ramezani,Morteza Gharib*

Main category: cs.RO

TL;DR: 多模态地面-空中机器人面临操作模式之间的需求冲突，该研究介绍了Husky v.2机器人的设计及其在动态四足行走和悬停中的初步结果。


<details>
  <summary>Details</summary>
Motivation: 解决多模态机器人在不同操作模式下的需求冲突。

Method: 通过结构重利用，实现姿态操控和推力矢量，设计了四足机器人。

Result: 报告了Husky v.2在动态四足行走和悬停方面的初步实验结果。

Conclusion: Husky v.2展示了其在多模态运动中的潜力，尤其是在动态行走和悬停方面。

Abstract: Multi-modal ground-aerial robots have been extensively studied, with a
significant challenge lying in the integration of conflicting requirements
across different modes of operation. The Husky robot family, developed at
Northeastern University, and specifically the Husky v.2 discussed in this
study, addresses this challenge by incorporating posture manipulation and
thrust vectoring into multi-modal locomotion through structure repurposing.
This quadrupedal robot features leg structures that can be repurposed for
dynamic legged locomotion and flight. In this paper, we present the hardware
design of the robot and report primary results on dynamic quadrupedal legged
locomotion and hovering.

</details>


### [45] [Guiding Energy-Efficient Locomotion through Impact Mitigation Rewards](https://arxiv.org/abs/2510.09543)
*Chenghao Wang,Arjun Viswanathan,Eric Sihite,Alireza Ramezani*

Main category: cs.RO

TL;DR: 本研究通过将冲击减轻因子（IMF）与对抗运动先验（AMP）结合，提出了一种改进的强化学习方法，实现了能量效率提高最多32%。


<details>
  <summary>Details</summary>
Motivation: 旨在弥补现有模仿学习方法只捕捉显式运动模式而忽视隐式被动态的不足。

Method: 结合对抗运动先验（AMP）和强化学习（RL），并引入物理驱动的冲击减轻因子（IMF）作为奖励项。

Result: 在AMP和手工奖励结构下，能量效率提高了最多32%，通过运输成本（CoT）进行测量。

Conclusion: 通过将冲击减轻因子（IMF）与对抗运动先验（AMP）相结合，提出的方法能够同时学习动物参考运动的显式运动轨迹和隐式被动态，显示出能量效率提高可达32%。

Abstract: Animals achieve energy-efficient locomotion by their implicit passive
dynamics, a marvel that has captivated roboticists for decades.Recently,
methods incorporated Adversarial Motion Prior (AMP) and Reinforcement learning
(RL) shows promising progress to replicate Animals' naturalistic motion.
However, such imitation learning approaches predominantly capture explicit
kinematic patterns, so-called gaits, while overlooking the implicit passive
dynamics. This work bridges this gap by incorporating a reward term guided by
Impact Mitigation Factor (IMF), a physics-informed metric that quantifies a
robot's ability to passively mitigate impacts. By integrating IMF with AMP, our
approach enables RL policies to learn both explicit motion trajectories from
animal reference motion and the implicit passive dynamic. We demonstrate energy
efficiency improvements of up to 32%, as measured by the Cost of Transport
(CoT), across both AMP and handcrafted reward structure.

</details>


### [46] [Zero-shot Structure Learning and Planning for Autonomous Robot Navigation using Active Inference](https://arxiv.org/abs/2510.09574)
*Daria de tinguy,Tim Verbelen,Emilio Gamba,Bart Dhoedt*

Main category: cs.RO

TL;DR: AIMAPP是一个生物启发的导航框架，能在不预先训练的情况下实现自主的探索和导航，提供对环境变化和传感器噪声的适应性。


<details>
  <summary>Details</summary>
Motivation: 自主导航在复杂环境中要求机器人能够在不依赖预先定义地图或大量训练的情况下，同时进行探索、定位和规划。

Method: 该模型使用拓扑推理、地方细胞编码和情节记忆，同时在线构建和更新稀疏拓扑地图，通过最小化期望自由能来规划动作。

Result: 提出了一种生物启发的主动推理框架AIMAPP，整合了建图、定位和决策。

Conclusion: AIMAPP提供了一种模块化解决方案，能够在非结构化环境中进行可扩展的自我监督导航。

Abstract: Autonomous navigation in unfamiliar environments requires robots to
simultaneously explore, localise, and plan under uncertainty, without relying
on predefined maps or extensive training. We present a biologically inspired,
Active Inference-based framework, Active Inference MAPping and Planning
(AIMAPP). This model unifies mapping, localisation, and decision-making within
a single generative model. Inspired by hippocampal navigation, it uses
topological reasoning, place-cell encoding, and episodic memory to guide
behaviour. The agent builds and updates a sparse topological map online, learns
state transitions dynamically, and plans actions by minimising Expected Free
Energy. This allows it to balance goal-directed and exploratory behaviours. We
implemented a ROS-compatible navigation system that is sensor and
robot-agnostic, capable of integrating with diverse hardware configurations. It
operates in a fully self-supervised manner, is resilient to drift, and supports
both exploration and goal-directed navigation without any pre-training. We
demonstrate robust performance in large-scale real and simulated environments
against state-of-the-art planning models, highlighting the system's
adaptability to ambiguous observations, environmental changes, and sensor
noise. The model offers a biologically inspired, modular solution to scalable,
self-supervised navigation in unstructured settings. AIMAPP is available at
https://github.com/decide-ugent/AIMAPP.

</details>
