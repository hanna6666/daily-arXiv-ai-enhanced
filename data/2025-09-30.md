<div id=toc></div>

# Table of Contents

- [cs.HC](#cs.HC) [Total: 29]
- [cs.RO](#cs.RO) [Total: 108]


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [1] ["I Don't Think RAI Applies to My Model'' -- Engaging Non-champions with Sticky Stories for Responsible AI Work](https://arxiv.org/abs/2509.22858)
*Nadia Nahar,Chenyang Yang,Yanxin Chen,Wesley Hanwen Deng,Ken Holstein,Motahhare Eslami,Christian Kästner*

Main category: cs.HC

TL;DR: 本研究探讨了如何通过粘性故事来有效 吸引非倡导者参与责任人工智能的风险识别。


<details>
  <summary>Details</summary>
Motivation: 责任人工智能工具未能有效地吸引非倡导者，使其认为这些工具仅仅是官僚任务，因此需要找到有效的方法来engage这一群体。

Method: 通过观察会议和访谈数据科学家，结合理论基础，提出了设计原则并产生了粘性故事，随后对这些故事进行了人类与语言模型的评估。

Result: 研究表明，与一般故事相比，粘性故事在增强识别风险的时间、拓宽认识的风险范围和促进更深层次的反思方面具有显著效果。

Conclusion: 使用粘性故事能够显著提高非倡导者在识别机器学习风险方面的参与度和深度反思。

Abstract: Responsible AI (RAI) tools -- checklists, templates, and governance processes
-- often engage RAI champions, individuals intrinsically motivated to advocate
ethical practices, but fail to reach non-champions, who frequently dismiss them
as bureaucratic tasks. To explore this gap, we shadowed meetings and
interviewed data scientists at an organization, finding that practitioners
perceived RAI as irrelevant to their work. Building on these insights and
theoretical foundations, we derived design principles for engaging
non-champions, and introduced sticky stories -- narratives of unexpected ML
harms designed to be concrete, severe, surprising, diverse, and relevant,
unlike widely circulated media to which practitioners are desensitized. Using a
compound AI system, we generated and evaluated sticky stories through human and
LLM assessments at scale, confirming they embodied the intended qualities. In a
study with 29 practitioners, we found that, compared to regular stories, sticky
stories significantly increased time spent on harm identification, broadened
the range of harms recognized, and fostered deeper reflection.

</details>


### [2] [What If Moderation Didn't Mean Suppression? A Case for Personalized Content Transformation](https://arxiv.org/abs/2509.22861)
*Rayhan Rashed,Farnaz Jahanbakhsh*

Main category: cs.HC

TL;DR: 本研究提出了DIY-MOD浏览器扩展，通过个性化内容转化应对内容审核中的主观性，提高用户的参与感和安全感。


<details>
  <summary>Details</summary>
Motivation: 集中内容审核模式不足以应对伤害的主观性，且对有害内容采取强硬的压制措施。

Method: 通过形式访谈收集用户的生活经验，开发DIY-MOD浏览器扩展，并进行为期两次的用户研究。

Result: 用户研究展示，DIY-MOD有效提高了用户的自主性和安全感。

Conclusion: DIY-MOD通过个性化内容转化，提高用户的自主性和安全感，使他们能够参与之前需要回避的内容和社区。

Abstract: Centralized content moderation paradigm both falls short and over-reaches: 1)
it fails to account for the subjective nature of harm, and 2) it acts with
blunt suppression in response to content deemed harmful, even when such content
can be salvaged. We first investigate this through formative interviews,
documenting how seemingly benign content becomes harmful due to individual life
experiences. Based on these insights, we developed DIY-MOD, a browser extension
that operationalizes a new paradigm: personalized content transformation.
Operating on a user's own definition of harm, DIY-MOD transforms sensitive
elements within content in real-time instead of suppressing the content itself.
The system selects the most appropriate transformation for a piece of content
from a diverse palette--from obfuscation to artistic stylizing--to match the
user's specific needs while preserving the content's informational value. Our
two-session user study demonstrates that this approach increases users' sense
of agency and safety, enabling them to engage with content and communities they
previously needed to avoid.

</details>


### [3] [Explicit modelling of subject dependency in BCI decoding](https://arxiv.org/abs/2509.23247)
*Michele Romani,Francesco Paissan,Andrea Fossà,Elisabetta Farella*

Main category: cs.HC

TL;DR: 提出了一种基于轻量级CNN的BCI方法，通过建模受试者依赖性和优化超参数，减少校准需求，提升性能。


<details>
  <summary>Details</summary>
Motivation: BCI系统面临高度的受试者间差异和有限的标注数据，通常需要较长的校准阶段。

Method: 使用轻量级卷积神经网络（CNNs）并配置针对受试者身份的条件，以显式建模受试者依赖性，并整合超参数优化策略。

Result: 在时变事件相关电位（ERP）分类任务中，对三种轻量级架构进行了基准测试，结果显示其改善了泛化能力和数据有效性。

Conclusion: 该方法提高了BCI的泛化能力和数据校准效率，展示了适应受试者变化的可扩展性和实用性。

Abstract: Brain-Computer Interfaces (BCIs) suffer from high inter-subject variability
and limited labeled data, often requiring lengthy calibration phases. In this
work, we present an end-to-end approach that explicitly models the subject
dependency using lightweight convolutional neural networks (CNNs) conditioned
on the subject's identity. Our method integrates hyperparameter optimization
strategies that prioritize class imbalance and evaluates two conditioning
mechanisms to adapt pre-trained models to unseen subjects with minimal
calibration data. We benchmark three lightweight architectures on a
time-modulated Event-Related Potentials (ERP) classification task, providing
interpretable evaluation metrics and explainable visualizations of the learned
representations. Results demonstrate improved generalization and data-efficient
calibration, highlighting the scalability and practicality of subject-adaptive
BCIs.

</details>


### [4] [Debiasing the Influence of Demographic and Appearance Cues in Social Engineering via Role-Taking: Negative Results](https://arxiv.org/abs/2509.23271)
*Tourjana Islam Supti,Israa Abuelezz,Aya Muhanad,Mahmoud Barhmagi,Ala Yankouskaya,Khaled M. Khan,Aiman Erbad,Raian Ali*

Main category: cs.HC

TL;DR: 本研究未能证实干预措施能有效减弱外貌线索对信任和风险的影响，需重新评估相关方法。


<details>
  <summary>Details</summary>
Motivation: 探讨角色扮演与阅读素养干预对外貌线索在社会工程背景下影响信任及风险承担的减弱效果。

Method: 采用4（组别：控制组、识字组、说服者组、被说服者组）* 2（时间：干预前、干预后）混合因素设计，涉及139名参与者，进行为期两周的实验。

Result: 干预前后测试均未显示组间或组内显著差异，表明干预措施未能有效减弱外貌线索的影响。

Conclusion: 本研究发现，不同干预措施未能显著降低外貌线索对信任和风险承担的影响，提出对文献中采用的干预方法需重新考虑。

Abstract: This study investigates the efficacy of role-taking and literacy-based
interventions in reducing the influence of appearance cues, such as gender,
age, ethnicity, and clothing style, on trust and risk-taking in social
engineering contexts. A-4 (Group: Control, Literacy, Persuader, Persuadee) * 2
(Time: Pre, Post) mixed factorial design was implemented over two weeks with
139 participants. The control group received no material. The literacy group
attended two sessions focused on how behavior can be similar regardless of
appearance cues. The persuader group completed three sessions, learning how to
use such cues to influence others. The persuadee group attended three sessions
involving the selection, justification, and reflection on personas and
scenarios. Scenarios centered on financial and rental advice. A one-week gap
followed before post-intervention testing. In both pre- and post-tests,
participants assessed personas combining appearance cues, offering mobile
hotspots with potential risk. They rated trust and willingness to take the
risk. Validated measures and scenarios were used, including word-of-mouth and
issue involvement scales. It was expected that cue influence would diminish
post-intervention. However, no significant within- or between-group differences
emerged. Findings raise concerns about the effectiveness of debiasing efforts
and call for reconsideration of approaches using literacy, role-taking,
rehearsal, drama, and simulation.

</details>


### [5] [Designing AI-Infused Interactive Systems for Online Communities: A Systematic Literature Review](https://arxiv.org/abs/2509.23309)
*Yuanhao Zhang,Xiaoyu Wang,Jiaxiong Hu,Ziqi Pan,Zhenhui Peng,Xiaojuan Ma*

Main category: cs.HC

TL;DR: 本文对AI融合系统在在线社区的应用进行了系统综述，分析了设计与评估模式，识别了用户需求，提出未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着AI融合系统在在线社区中广泛应用，了解用户需求和系统设计的必要性日益增加，但缺乏全面的综合研究。

Method: 对77项研究进行了系统综述，分析了所提出系统的挑战、设计功能和评估策略。

Result: 整理了社区参与的四个核心方面，识别了设计和评估的共同模式，总结了关键的设计考虑因素，并强调了未来研究的机会。

Conclusion: 本研究系统地分析了AI融合系统在在线社区中的设计与评估，揭示了设计与评估的共同模式以及未来研究的机会。

Abstract: AI-infused systems have demonstrated remarkable capabilities in addressing
diverse human needs within online communities. Their widespread adoption has
shaped user experiences and community dynamics at scale. However, designing
such systems requires a clear understanding of user needs, careful design
decisions, and robust evaluation. While research on AI-infused systems for
online communities has flourished in recent years, a comprehensive synthesis of
this space remains absent. In this work, we present a systematic review of 77
studies, analyzing the systems they propose through three lenses: the
challenges they aim to address, their design functionalities, and the
evaluation strategies employed. The first two dimensions are organized around
four core aspects of community participation: contribution, consumption,
mediation, and moderation. Our analysis identifies common design and evaluation
patterns, distills key design considerations, and highlights opportunities for
future research on AI-infused systems in online communities.

</details>


### [6] ["Shall We Dig Deeper?": Designing and Evaluating Strategies for LLM Agents to Advance Knowledge Co-Construction in Asynchronous Online Discussions](https://arxiv.org/abs/2509.23327)
*Yuanhao Zhang,Wenbo Li,Xiaoyu Wang,Kangyu Yuan,Shuai Ma,Xiaojuan Ma*

Main category: cs.HC

TL;DR: 本研究探讨了AI在异步在线讨论中的干预策略，发现LLM驱动代理能有效促进知识的深入构建，且不同策略对内容和体验有不同效果。


<details>
  <summary>Details</summary>
Motivation: 异步在线讨论中的知识共同构建往往停滞在早期阶段，因此需要探讨不同的AI干预风格如何推动讨论深入。

Method: 通过设计工作坊探索AI干预策略，并在60名参与者的内部研究中应用这些策略，评估其在五个连续的异步讨论中的效果。

Result: 研究表明，所实施的AI代理能够持续促进知识的深入进展，各种干预风格对讨论内容和体验产生了显著的差异。

Conclusion: 研究发现，LLM驱动的代理能有效促进在线讨论的深入，且不同干预风格对内容和体验有不同影响，为设计适应性AI代理提供了切实指导。

Abstract: Asynchronous online discussions enable diverse participants to co-construct
knowledge beyond individual contributions. This process ideally evolves through
sequential phases, from superficial information exchange to deeper synthesis.
However, many discussions stagnate in the early stages. Existing AI
interventions typically target isolated phases, lacking mechanisms to
progressively advance knowledge co-construction, and the impacts of different
intervention styles in this context remain unclear and warrant investigation.
To address these gaps, we conducted a design workshop to explore AI
intervention strategies (task-oriented and/or relationship-oriented) throughout
the knowledge co-construction process, and implemented them in an LLM-powered
agent capable of facilitating progression while consolidating foundations at
each phase. A within-subject study (N=60) involving five consecutive
asynchronous discussions showed that the agent consistently promoted deeper
knowledge progression, with different styles exerting distinct effects on both
content and experience. These findings provide actionable guidance for
designing adaptive AI agents that sustain more constructive online discussions.

</details>


### [7] [New Synthetic Goldmine: Hand Joint Angle-Driven EMG Data Generation Framework for Micro-Gesture Recognition](https://arxiv.org/abs/2509.23359)
*Nana Wang,Gen Li,Suli Wang,Pengfei Ren,Hao Su*

Main category: cs.HC

TL;DR: SeqEMG-GAN通过合成高质量EMG信号，有效增强了手势识别的性能，适合多种人机交互应用。


<details>
  <summary>Details</summary>
Motivation: 为了解决EMG数据稀缺、用户差异性大以及对未见手势泛化能力差的问题。

Method: 提出了一种条件、基于序列的生成框架SeqEMG-GAN，用于合成高保真EMG信号，采用对抗学习进行优化。

Result: 在合成数据训练的情况下，分类器的准确率轻微下降，但结合真实与合成数据的训练显著提升了准确率，展示了该框架的有效性。

Conclusion: SeqEMG-GAN在EMG数据增强和手势识别性能方面达到了最先进的水平，适用于多种应用场景。

Abstract: Electromyography (EMG)-based gesture recognition has emerged as a promising
approach for human-computer interaction. However, its performance is often
limited by the scarcity of labeled EMG data, significant cross-user
variability, and poor generalization to unseen gestures. To address these
challenges, we propose SeqEMG-GAN, a conditional, sequence-driven generative
framework that synthesizes high-fidelity EMG signals from hand joint angle
sequences. Our method introduces a context-aware architecture composed of an
angle encoder, a dual-layer context encoder featuring the novel Ang2Gist unit,
a deep convolutional EMG generator, and a discriminator, all jointly optimized
via adversarial learning. By conditioning on joint kinematic trajectories,
SeqEMG-GAN is capable of generating semantically consistent EMG sequences, even
for previously unseen gestures, thereby enhancing data diversity and
physiological plausibility. Experimental results show that classifiers trained
solely on synthetic data experience only a slight accuracy drop (from 57.77% to
55.71%). In contrast, training with a combination of real and synthetic data
significantly improves accuracy to 60.53%, outperforming real-only training by
2.76%. These findings demonstrate the effectiveness of our framework,also
achieves the state-of-art performance in augmenting EMG datasets and enhancing
gesture recognition performance for applications such as neural robotic hand
control, AI/AR glasses, and gesture-based virtual gaming systems.

</details>


### [8] [Bridging the Trust Gap in Crowdfunding: A Novel Expert-Based Evaluation Mechanism](https://arxiv.org/abs/2509.23378)
*Issam Hosni,Omar Talbi*

Main category: cs.HC

TL;DR: 本文提出了双重评分投票机制，以解决众筹中创作者与支持者之间的信任问题和信息不对称，从而提升项目评估的客观性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 当前众筹面临创作者与支持者之间的信任问题和信息不对称，现有的信任增强机制缺乏客观性和稳健性。

Method: 提出了一种新的信任增强机制，称为双重评分投票，通过两种关键维度进行专家验证：专家对项目潜力的细化评分投票和专家的可信度加权评分。

Result: 研发了一个原型众筹平台CertiFund，以测试和验证双重评分投票机制，并展现了其在提高项目可信度方面的有效性。

Conclusion: Double-Score Voting机制可以显著减少信息不对称，提升项目的可信度，从而为创作者和支持者创造一个更加可信的生态系统。

Abstract: Crowdfunding has emerged as a vital alternative funding source, transforming
how creative projects and startups secure financing by directly connecting
creators to backers. However, persistent trust issues and information asymmetry
between creators and backers significantly hinder its growth and development.
Existing trust-enhancement mechanisms, such as third-party endorsements and
basic expert validation often lack objectivity and robustness, leaving backers
vulnerable to biased signals and project failures. This paper addresses these
limitations by introducing a novel trust-enhancement mechanism, referred to as
Double-Score Voting. This approach refines expert validation systems by
integrating two critical dimensions: firstly, a granular score-based vote from
experts on a project's potential, moving beyond simple binary approval; and
secondly, a weighted score representing the expert's credibility and level of
expertise. This dual-layered evaluation provides a more nuanced, objective, and
reliable assessment of project viability. The mechanism is formalised
mathematically, and its practical implementation is demonstrated through
CertiFund, a prototype crowdfunding platform developed to test and validate the
concept. The findings of this study demonstrate that the Double-Score Voting
mechanism can significantly mitigate information asymmetry, thereby increasing
the credibility of projects and fostering a more trustworthy ecosystem for both
creators and backers.

</details>


### [9] [NeuroBridge: Using Generative AI to Bridge Cross-neurotype Communication Differences through Neurotypical Perspective-taking](https://arxiv.org/abs/2509.23434)
*Rukhshan Haroon,Kyle Wigdor,Katie Yang,Nicole Toumanios,Eileen T. Crehan,Fahad Dogar*

Main category: cs.HC

TL;DR: NeuroBridge是一个在线平台，通过模拟自闭症与神经典型之间的沟通，帮助后者理解自闭症人士的独特交流风格，用户反馈显示该平台有效且具建设性。


<details>
  <summary>Details</summary>
Motivation: 旨在解决自闭症个体与神经典型个体之间沟通不畅的问题，尤其是自闭症人士在适应神经典型规范时所承受的压力。

Method: 构建了NeuroBridge在线平台，利用大型语言模型（LLMs）模拟自闭症和神经典型之间的沟通场景，进行反馈驱动的对话。

Result: 用户研究显示，参与者对自闭症沟通的理解得到了改善，并认为模拟的表现准确且反馈具有建设性。

Conclusion: 本研究强调了围绕残疾代表性和AI中个性化的设计的重要性，并指出了LLM在处理复杂社会场景中的局限性。

Abstract: Communication challenges between autistic and neurotypical individuals stem
from a mutual lack of understanding of each other's distinct, and often
contrasting, communication styles. Yet, autistic individuals are expected to
adapt to neurotypical norms, making interactions inauthentic and mentally
exhausting for them. To help redress this imbalance, we build NeuroBridge, an
online platform that utilizes large language models (LLMs) to simulate: (a) an
AI character that is direct and literal, a style common among many autistic
individuals, and (b) four cross-neurotype communication scenarios in a
feedback-driven conversation between this character and a neurotypical user.
Through NeuroBridge, neurotypical individuals gain a firsthand look at autistic
communication, and reflect on their role in shaping cross-neurotype
interactions. In a user study with 12 neurotypical participants, we find that
NeuroBridge improved their understanding of how autistic people may interpret
language differently, with all describing autism as a social difference that
"needs understanding by others" after completing the simulation. Participants
valued its personalized, interactive format and described AI-generated feedback
as "constructive", "logical" and "non-judgmental". Most perceived the portrayal
of autism in the simulation as accurate, suggesting that users may readily
accept AI-generated (mis)representations of disabilities. To conclude, we
discuss design implications for disability representation in AI, the need for
making NeuroBridge more personalized, and LLMs' limitations in modeling complex
social scenarios.

</details>


### [10] [DraftMarks: Enhancing Transparency in Human-AI Co-Writing Through Interactive Skeuomorphic Process Traces](https://arxiv.org/abs/2509.23505)
*Momin N. Siddiqui,Nikki Nasseri,Adam Coscia,Roy Pea,Hari Subramonyam*

Main category: cs.HC

TL;DR: 本研究介绍了DraftMarks，一个增强阅读工具，旨在通过物理隐喻展示人类与AI的写作互动，从而帮助读者理解AI在创作中的角色。


<details>
  <summary>Details</summary>
Motivation: 随着生成性AI成为日常写作的一部分，理解AI对写作过程的影响变得越来越重要。

Method: 通过使用Writer-AI互动的数据，DraftMarks算法计算各种合作指标和写作痕迹，并进行了形成性研究以评估有效性。

Result: DraftMarks作为一种增强阅读工具，使用拟物化编码展示人类与AI的写作过程，提高了读者对AI协作写作的理解。

Conclusion: DraftMarks有效地评估了AI合作写作，通过展现人类与AI的互动过程，帮助读者理解AI在写作中的作用

Abstract: As generative AI becomes part of everyday writing, questions of transparency
and productive human effort are increasingly important. Educators, reviewers,
and readers want to understand how AI shaped the process. Where was human
effort focused? What role did AI play in the creation of the work? How did the
interaction unfold? Existing approaches often reduce these dynamics to summary
metrics or simplified provenance. We introduce DraftMarks, an augmented reading
tool that surfaces the human-AI writing process through familiar physical
metaphors. DraftMarks employs skeuomorphic encodings such as eraser crumbs to
convey the intensity of revision, and masking tape or smudges to mark
AI-generated content, simulating the process within the final written artifact.
By using data from writer-AI interactions, DraftMarks' algorithm computes
various collaboration metrics and writing traces. Through a formative study, we
identified computational logic for different readership, and evaluated
DraftMarks for its effectiveness in assessing AI co-authored writing.

</details>


### [11] [Exploring Collaboration Breakdowns Between Provider Teams and Patients in Post-Surgery Care](https://arxiv.org/abs/2509.23509)
*Bingsheng Yao,Menglin Zhao,Zhan Zhang,Pengqi Wang,Emma G Chester,Changchang Yin,Tianshi Li,Varun Mishra,Lace Padilla,Odysseas Chatzipanagiotou,Timothy Pawlik,Ping Zhang,Weidan Cao,Dakuo Wang*

Main category: cs.HC

TL;DR: 本研究探讨了术后护理中提供者团队与患者之间的协作，发现沟通和护理路径的中断对患者恢复有负面影响，并提出了改进设计的建议。


<details>
  <summary>Details</summary>
Motivation: 研究术后护理中供应商团队和患者之间的持续协作，以及在出院准备和护理交接中可能出现的沟通和护理路径的中断对患者恢复的影响。

Method: 通过对13名医疗提供者和4名患者进行半结构化访谈，研究围绕消化道手术进行。

Result: 发现院内与院外团队之间的协调界限，以及团队内复杂的组织结构阻碍了患者家庭护理计划的准备和患者信息的分类。

Conclusion: 基于研究发现，提出了设计机会以正式化任务归属和转接，情境化同时发生的信号，并将护理计划与家庭资源对齐。

Abstract: Post-surgery care involves ongoing collaboration between provider teams and
patients, which starts from post-surgery hospitalization through home recovery
after discharge. While prior HCI research has primarily examined patients'
challenges at home, less is known about how provider teams coordinate discharge
preparation and care handoffs, and how breakdowns in communication and care
pathways may affect patient recovery. To investigate this gap, we conducted
semi-structured interviews with 13 healthcare providers and 4 patients in the
context of gastrointestinal (GI) surgery. We found coordination boundaries
between in- and out-patient teams, coupled with complex organizational
structures within teams, impeded the "invisible work" of preparing patients'
home care plans and triaging patient information. For patients, these
breakdowns resulted in inadequate preparation for home transition and
fragmented self-collected data, both of which undermine timely clinical
decision-making. Based on these findings, we outline design opportunities to
formalize task ownership and handoffs, contextualize co-temporal signals, and
align care plans with home resources.

</details>


### [12] [Eye-Tracking and BCI Integration for Assistive Communication in Locked-In Syndrome: Pilot Study with Healthy Participants](https://arxiv.org/abs/2509.23518)
*Ana Patrícia Pinto,Rute Bettencourt,Urbano J. Nunes,Gabriel Pires*

Main category: cs.HC

TL;DR: 本研究提出了一种结合眼动追踪和脑-机接口的混合框架，以支持阿尔茨海默病患者在自主运动控制丧失阶段的沟通。


<details>
  <summary>Details</summary>
Motivation: 随着阿尔茨海默病患者自主运动控制逐渐丧失，传统的眼动追踪系统的有效性下降，因此需要探索替代的沟通方式。

Method: 采用基于P300的BCI框架，实时处理视线和脑电图（EEG）数据，并提出了眼动追踪-脑-机接口融合算法。

Result: 实验结果表明，结合眼动追踪和脑-机接口可以在过渡过程中保持高准确率，有助于改善患者的沟通连续性。

Conclusion: 结合眼动追踪和脑-机接口可以提高用户意图的检测精度，有助于帮助渐进式过渡的患者维持高效沟通。

Abstract: Patients with Amyotrophic Lateral Sclerosis (ALS) progressively lose
voluntary motor control, often leading to a Locked-In State (LIS), or in severe
cases, a Completely Locked-in State (CLIS). Eye-tracking (ET) systems are
common communication tools in early LIS but become ineffective as oculomotor
function declines. EEG-based Brain-Computer Interfaces (BCIs) offer a
non-muscular communication alternative, but delayed adoption may reduce
performance due to diminished goal-directed thinking. This study presents a
preliminary hybrid BCI framework combining ET and BCI to support a gradual
transition between modalities. A group of five healthy participants tested a
modified P300-based BCI. Gaze and EEG data were processed in real time, and an
ET-BCI fusion algorithm was proposed to enhance detection of user intention.
Results indicate that combining both modalities may maintain high accuracy and
offers insights on how to potentially improve communication continuity for
patients transitioning from LIS to CLIS.

</details>


### [13] [Privy: Envisioning and Mitigating Privacy Risks for Consumer-facing AI Product Concepts](https://arxiv.org/abs/2509.23525)
*Hao-Ping Lee,Yu-Ju Yang,Matthew Bilik,Isadora Krsek,Thomas Serban von Davier,Kyzyl Monteiro,Jason Lin,Shivani Agarwal,Jodi Forlizzi,Sauvik Das*

Main category: cs.HC

TL;DR: Privy是一个工具，通过结构化的隐私影响评估帮助从业者识别和缓解AI产品的隐私风险。


<details>
  <summary>Details</summary>
Motivation: 现有从业者缺乏有效资源来识别和缓解AI技术带来的隐私风险。

Method: 通过控制研究评估Privy两种版本的效果，涉及24名从业者和13名独立隐私专家的评审。

Result: Privy帮助从业者识别相关隐私风险并提出适当的缓解策略，评估结果被专家认可为高质量。

Conclusion: Privy有效帮助从业者进行隐私评估，并提高了评估质量，尤其是在LLM驱动的版本中表现更佳。

Abstract: AI creates and exacerbates privacy risks, yet practitioners lack effective
resources to identify and mitigate these risks. We present Privy, a tool that
guides practitioners through structured privacy impact assessments to: (i)
identify relevant risks in novel AI product concepts, and (ii) propose
appropriate mitigations. Privy was shaped by a formative study with 11
practitioners, which informed two versions -- one LLM-powered, the other
template-based. We evaluated these two versions of Privy through a
between-subjects, controlled study with 24 separate practitioners, whose
assessments were reviewed by 13 independent privacy experts. Results show that
Privy helps practitioners produce privacy assessments that experts deemed high
quality: practitioners identified relevant risks and proposed appropriate
mitigation strategies. These effects were augmented in the LLM-powered version.
Practitioners themselves rated Privy as being useful and usable, and their
feedback illustrates how it helps overcome long-standing awareness, motivation,
and ability barriers in privacy work.

</details>


### [14] [Community Analysis of Social Virtual Reality Based on Large-Scale Log Data of a Commercial Metaverse Platform](https://arxiv.org/abs/2509.23654)
*Hiroto Tsutsui,Takefumi Hiraki,Yuichi Hiroi,Shoichi Hasegawa*

Main category: cs.HC

TL;DR: 本研究分析了社交虚拟现实平台的用户社区结构，发现其特点与传统社交网络服务大相径庭，且存在特定的中介用户群体。


<details>
  <summary>Details</summary>
Motivation: 深入理解社交虚拟现实平台中用户社区的结构特征及用户在其中的角色。

Method: 通过对大型日志数据的量化分析，检测和评估用户社区结构。

Result: 发现社交虚拟现实平台上存在许多小型社区，具有较强的内部凝聚力但有限的跨社区连接。

Conclusion: 社交虚拟现实中的用户社区结构通常较小且相对封闭，存在特定的中介用户群体，称为"社区跳跃者"。

Abstract: This study quantitatively analyzes the structural characteristics of user
communities within Social Virtual Reality (Social VR) platforms supporting
head-mounted displays (HMDs), based on large-scale log data. By detecting and
evaluating community structures from data on substantial interactions (defined
as prolonged co-presence in the same virtual space), we found that Social VR
platforms tend to host numerous, relatively small communities characterized by
strong internal cohesion and limited inter-community connections. This finding
contrasts with the large-scale, broadly connected community structures
typically observed in conventional Social Networking Services (SNS).
Furthermore, we identified a user segment capable of mediating between
communities, despite these users not necessarily having numerous direct
connections. We term this user segment `community hoppers' and discuss their
characteristics. These findings contribute to a deeper understanding of the
community structures that emerge within the unique communication environment of
Social VR and the roles users play within them.

</details>


### [15] ["Having Lunch Now": Understanding How Users Engage with a Proactive Agent for Daily Planning and Self-Reflection](https://arxiv.org/abs/2509.24073)
*Adnan Abbas,Caleb Wohn,Arnav Jagtap,Eugenia H Rho,Sang Won Lee*

Main category: cs.HC

TL;DR: 本研究探讨了用户与主动型教练代理的互动，揭示了多样的互动模式及代理行为中的问题，并提供了促进有效行为变化的设计建议。


<details>
  <summary>Details</summary>
Motivation: 虽然已有研究表明会话代理在生产力和幸福感方面有积极结果，但仍缺乏对这些结果驱动因素的清晰理解，以及用户如何与作为教练而非助手的代理进行沟通的认知。

Method: 进行了为期14天的纵向研究，涉及12名参与者，使用了一种主动代理，定期进行检查以支持日常规划和反思。

Result: 研究发现参与者与代理的互动模式多样，包括接受或协商建议、发展共享心理模型、报告进展，有时会抗拒或退缩。还发现代理行为中存在一些问题，如僵化、过早转移话语权和过度承诺。

Conclusion: 这项研究增强了我们对人们如何与主动型教练代理互动的理解，并提供了促进有效行为变化的设计考虑。

Abstract: Conversational agents have been studied as tools to scaffold planning and
self-reflection for productivity and well-being. While prior work has
demonstrated positive outcomes, we still lack a clear understanding of what
drives these results and how users behave and communicate with agents that act
as coaches rather than assistants. Such understanding is critical for designing
interactions in which agents foster meaningful behavioral change. We conducted
a 14-day longitudinal study with 12 participants using a proactive agent that
initiated regular check-ins to support daily planning and reflection. Our
findings reveal diverse interaction patterns: participants accepted or
negotiated suggestions, developed shared mental models, reported progress, and
at times resisted or disengaged. We also identified problematic aspects of the
agent's behavior, including rigidity, premature turn-taking, and overpromising.
Our work contributes to understanding how people interact with a proactive,
coach-like agent and offers design considerations for facilitating effective
behavioral change.

</details>


### [16] [WireBend-kit: A Computational Design and Fabrication Toolkit for Wirebending Custom 3D Wireframe Structures](https://arxiv.org/abs/2509.24083)
*Faraz Faruqi,Josha Paonaskar,Riley Schuler,Aiden Prevey,Carson Taylor,Anika Tak,Anthony Guinto,Eeshani Shilamkar,Natarith Cheenaruenthong,Martin Nisser*

Main category: cs.HC

TL;DR: 本文介绍的WireBend-kit是一种桌面线弯曲机与计算设计工具的结合，能以低成本快速制作3D线框结构，克服误差影响。


<details>
  <summary>Details</summary>
Motivation: 旨在为用户提供一个便宜且高效的解决方案，以创建3D线框结构。

Method: 开发了一个计算设计工具，并结合一个桌面线弯曲机，自动将线框设计转化为生产指令，处理材料弹性和运动学误差。

Result: 系统能够克服传统线弯曲过程中固有的误差，从而准确地生成3D结构，且材料成本低廉。

Conclusion: WireBend-kit通过低成本的机器和设计工具，使用户能够快速、经济地创建定制的3D线框结构。

Abstract: This paper introduces WireBend-kit, a desktop wirebending machine and
computational design tool for creating 3D wireframe structures. Combined, they
allow users to rapidly and inexpensively create custom 3D wireframe structures
from aluminum wire. Our design tool is implemented in freely available software
and allows users to generate virtual wireframe designs and assess their
fabricability. A path-planning procedure automatically converts the wireframe
design into fabrication instructions for our machine while accounting for
material elasticity and kinematic error sources. The custom machine costs $293
in parts and can form aluminum wire into 3D wireframe structures through an
ordered sequence of feed, bend, and rotate instructions. Our technical
evaluation reveals our system's ability to overcome odometrically accumulating
errors inherent to wirebending in order to produce accurate 3D structures from
inexpensive hardware. Finally, we provide application examples demonstrating
the design space enabled by Wirebend-kit.

</details>


### [17] [Exploring Opportunities to Support Novice Visual Artists' Inspiration and Ideation with Generative AI](https://arxiv.org/abs/2509.24167)
*Cindy Peng,Alice Qian,Linghao Jin,Jieneng Chen,Evans Xu Han,Paul Pu Liang,Hong Shen,Haiyi Zhu,Jane Hsieh*

Main category: cs.HC

TL;DR: 本研究探讨了生成性AI在支持新手艺术家创作中的可能性，通过访谈和共同设计，识别了关键需求并开发了原型，展示了面向新手艺术家的工具设计机会。


<details>
  <summary>Details</summary>
Motivation: 随着生成性人工智能的进步，探索这些工具如何在创作早期阶段支持新手艺术家是必要的。

Method: 我们进行了13个艺术家的访谈，揭示了创作早期阶段的关键需求，并基于这些需求开发了一组六个互动原型，随后与13位新手视觉艺术家进行共同设计工作坊。

Result: 本研究通过识别新手艺术家的需求，并进行了原型开发和共同设计 workshop，探讨了生成性AI如何更好地服务于视觉创意的实践。

Conclusion: 本研究揭示了设计面向新手艺术家的工具的机会，强调了艺术家的需求，并为生成性人工智能在视觉创作中的应用提供了替代愿景。

Abstract: Recent generative AI advances present new possibilities for supporting visual
art creation, but how such promise might assist novice artists during
early-stage processes requires investigation. How novices adopt or resist these
tools can shift the relationship between the art community and generative
systems. We interviewed 13 artists to uncover needs in key dimensions during
early stages of creation: (1) quicker and better access to references, (2)
visualizations of reference combinations, (3) external artistic feedback, and
(4) personalized support to learn new techniques and styles. Mapping such needs
to state-of-the-art open-sourced advances, we developed a set of six
interactive prototypes to expose emerging capabilities to novice artists.
Afterward, we conducted co-design workshops with 13 novice visual artists
through which artists articulated requirements and tensions for artist-centered
AI development. Our work reveals opportunities to design novice-targeted tools
that foreground artists' needs, offering alternative visions for generative AI
to serve visual creativity.

</details>


### [18] [Understanding Cognitive States from Head & Hand Motion Data](https://arxiv.org/abs/2509.24255)
*Kaiang Wen,Mark Roman Miller*

Main category: cs.HC

TL;DR: 本研究通过新的数据集及深度时间模型分析VR中的头部和手部运动，发现其能够有效识别用户的复杂认知状态。


<details>
  <summary>Details</summary>
Motivation: 探讨运动动力学如何编码复杂的认知状态，如困惑、犹豫和准备，而这些状态缺乏明显的运动相关性。

Method: 使用深度时间模型分析头部和手部运动数据，推断用户的认知状态。

Result: 深度时间模型能够通过运动数据推断出细微的认知状态，其性能可与人类观察者相媲美。

Conclusion: 标准的虚拟现实（VR）遥测包含与用户内部认知过程相关的强模式，未来可用于自适应虚拟环境的开发。

Abstract: As virtual reality (VR) and augmented reality (AR) continue to gain
popularity, head and hand motion data captured by consumer VR systems have
become ubiquitous. Prior work shows that such telemetry can be highly
identifying and reflect broad user traits, often aligning with intuitive "folk
theories" of body language. However, it remains unclear to what extent motion
kinematics encode more nuanced cognitive states, such as confusion, hesitation,
and readiness, which lack clear correlates with motion. To investigate this, we
introduce a novel dataset of head and hand motion with frame-level annotations
of these states collected during structured decision-making tasks. Our findings
suggest that deep temporal models can infer subtle cognitive states from motion
alone, achieving comparable performance with human observers. This work
demonstrates that standard VR telemetry contains strong patterns related to
users' internal cognitive processes, which opens the door for a new generation
of adaptive virtual environments. To enhance reproducibility and support future
work, we will make our dataset and modeling framework publicly available.

</details>


### [19] [Bridging the behavior-neural gap: A multimodal AI reveals the brain's geometry of emotion more accurately than human self-reports](https://arxiv.org/abs/2509.24298)
*Changde Du,Yizhuo Lu,Zhongyu Huang,Yi Sun,Zisen Zhou,Shaozheng Qin,Huiguang He*

Main category: cs.HC

TL;DR: 该研究探讨情感表示与脑活动之间的关系，发现多模态语言模型能够有效地捕捉情感几何，并成功预测神经活动，提出了一种新方法来理解情感。


<details>
  <summary>Details</summary>
Motivation: 探究情感表示在人的认知和社会互动中的重要性，以及传统评分尺度在预测脑活动时的局限性。

Method: 使用AI模型作为'认知代理'，从2180个情感唤起的视频中收集了数百万个三元组判断，测试传统评分尺度的限制。

Result: 通过对情感的30维嵌入进行分析，发现多模态语言模型的表示在预测人类情感处理网络的神经活动方面效果最佳，超越了仅语言模型及基于人类行为评分的表示。

Conclusion: 大规模多模态语言模型（MLLM）能够自主发展丰富的、与神经相关的情感表示，提供了一种强有力的范式来弥合主观体验与其神经基础之间的差距。

Abstract: The ability to represent emotion plays a significant role in human cognition
and social interaction, yet the high-dimensional geometry of this affective
space and its neural underpinnings remain debated. A key challenge, the
`behavior-neural gap,' is the limited ability of human self-reports to predict
brain activity. Here we test the hypothesis that this gap arises from the
constraints of traditional rating scales and that large-scale similarity
judgments can more faithfully capture the brain's affective geometry. Using AI
models as `cognitive agents,' we collected millions of triplet odd-one-out
judgments from a multimodal large language model (MLLM) and a language-only
model (LLM) in response to 2,180 emotionally evocative videos. We found that
the emergent 30-dimensional embeddings from these models are highly
interpretable and organize emotion primarily along categorical lines, yet in a
blended fashion that incorporates dimensional properties. Most remarkably, the
MLLM's representation predicted neural activity in human emotion-processing
networks with the highest accuracy, outperforming not only the LLM but also,
counterintuitively, representations derived directly from human behavioral
ratings. This result supports our primary hypothesis and suggests that sensory
grounding--learning from rich visual data--is critical for developing a truly
neurally-aligned conceptual framework for emotion. Our findings provide
compelling evidence that MLLMs can autonomously develop rich, neurally-aligned
affective representations, offering a powerful paradigm to bridge the gap
between subjective experience and its neural substrates. Project page:
https://reedonepeck.github.io/ai-emotion.github.io/.

</details>


### [20] [Exploring Similarity between Neural and LLM Trajectories in Language Processing](https://arxiv.org/abs/2509.24307)
*Xin Xiao,Kaiwen Wei,Jiang Zhong,Dongshuo Yin,Yu Tian,Xuekai Wei,Mingliang Zhou*

Main category: cs.HC

TL;DR: 本研究评估了16个大型语言模型与人脑活动的相似性与差异性，显示它们在语义处理上的关键区别，为AI与生物智能的对比研究奠定基础。


<details>
  <summary>Details</summary>
Motivation: 理解大型语言模型与人类大脑活动之间的相似性对推进人工智能与认知神经科学的研究至关重要。

Method: 使用岭回归系统比较16个预训练的多语言LLMs与人类在自然语言处理任务中的脑电图（EEG）反应的代表性相似性，分析“神经轨迹”和“LLM潜在轨迹”的相似性。

Result: 发现LLMs和人脑在处理策略上表现出相似性与重要差异，LLMs中层至高层与EEG中的N400成分相关，而大脑在阅读时表现出连续的迭代处理，与LLMs所展现的离散的活动模式形成鲜明对比。

Conclusion: 本研究提供了对大型语言模型（LLMs）与人类大脑活动之间相似性的深入评估，并揭示了在语义处理策略上的关键差异，为今后AI与生物智能的关系探索提供了框架。

Abstract: Understanding the similarity between large language models (LLMs) and human
brain activity is crucial for advancing both AI and cognitive neuroscience. In
this study, we provide a multilinguistic, large-scale assessment of this
similarity by systematically comparing 16 publicly available pretrained LLMs
with human brain responses during natural language processing tasks in both
English and Chinese. Specifically, we use ridge regression to assess the
representational similarity between LLM embeddings and electroencephalography
(EEG) signals, and analyze the similarity between the "neural trajectory" and
the "LLM latent trajectory." This method captures key dynamic patterns, such as
magnitude, angle, uncertainty, and confidence. Our findings highlight both
similarities and crucial differences in processing strategies: (1) We show that
middle-to-high layers of LLMs are central to semantic integration and
correspond to the N400 component observed in EEG; (2) The brain exhibits
continuous and iterative processing during reading, whereas LLMs often show
discrete, stage-end bursts of activity, which suggests a stark contrast in
their real-time semantic processing dynamics. This study could offer new
insights into LLMs and neural processing, and also establish a critical
framework for future investigations into the alignment between artificial
intelligence and biological intelligence.

</details>


### [21] [TraitSpaces: Towards Interpretable Visual Creativity for Human-AI Co-Creation](https://arxiv.org/abs/2509.24326)
*Prerna Luthra*

Main category: cs.HC

TL;DR: 本研究提出了一种结合心理学和艺术的框架，通过对2万件艺术品的分析，定义了12种创造力特质，旨在为艺术家和人工智能提供可解释的合作工具。


<details>
  <summary>Details</summary>
Motivation: 建立一个以心理学为基础的框架，建模视觉创造力，同时尊重艺术家的经验。

Method: 使用SemArt数据集中2万件艺术品，并通过GPT 4.1进行详细的理论对齐提示图像标注，评估这些特质从CLIP图像嵌入中学习的可能性。

Result: 研究发现，某些创造力特质如环境对话性和救赎弧可以较高可靠性地预测，而其他特质如记忆印记则具有挑战性，显示了纯视觉编码的局限性。研究还可视化了一个“创造力特质空间”，展示如何支撑可解释的、特质意识的共同创作。

Conclusion: 本研究旨在结合文化美学见解与计算建模，为艺术家、研究人员和人工智能系统提供共享语言和可解释工具，以促进有意义的合作。

Abstract: We introduce a psychologically grounded and artist-informed framework for
modeling visual creativity across four domains: Inner, Outer, Imaginative, and
Moral Worlds. Drawing on interviews with practicing artists and theories from
psychology, we define 12 traits that capture affective, symbolic, cultural, and
ethical dimensions of creativity.Using 20k artworks from the SemArt dataset, we
annotate images with GPT 4.1 using detailed, theory-aligned prompts, and
evaluate the learnability of these traits from CLIP image embeddings. Traits
such as Environmental Dialogicity and Redemptive Arc are predicted with high
reliability ($R^2 \approx 0.64 - 0.68$), while others like Memory Imprint
remain challenging, highlighting the limits of purely visual encoding. Beyond
technical metrics, we visualize a "creativity trait-space" and illustrate how
it can support interpretable, trait-aware co-creation - e.g., sliding along a
Redemptive Arc axis to explore works of adversity and renewal. By linking
cultural-aesthetic insights with computational modeling, our work aims not to
reduce creativity to numbers, but to offer shared language and interpretable
tools for artists, researchers, and AI systems to collaborate meaningfully.

</details>


### [22] [Investigating the Task Load of Investigating the Task Load in Visualization Studies](https://arxiv.org/abs/2509.24643)
*Daniel Pahr,Sara Di Bartolomeo*

Main category: cs.HC

TL;DR: 通过在线调查研究NASA-TLX的不同版本引发的任务负载，发现参与者的挫败感对全版本的工作负载影响较大，建议使用紧凑版问卷以提高参与者体验。


<details>
  <summary>Details</summary>
Motivation: NASA任务负载指数（NASA-TLX）是评估用户在可视化研究中工作负载的常用指标，但常常未按原意执行，缺少对工作负载来源的评估。

Method: 通过使用ReVISit框架进行在线调查，探讨不同版本NASA-TLX的任务负载。

Result: 参与者对程序的挫折感比实验时间的微小增加更能影响使用全版本TLX的任务负载，相较短版本，框架提供了更加多元的工作负载视角。

Conclusion: 我们建议使用一种紧凑版的工作负载来源问卷，以减少参与者的时间损失和挫折感，同时仍能提供与原始程序相同的数据。

Abstract: The NASA task load index (short: NASA-TLX) is a common metric to evaluate the
workload of a user in a visualization study. Yet, it is rarely performed as
initially intended, as the sources-of-workload evaluation is often omitted for
various reasons. We conduct an online survey to investigate the task load of
administering different versions of the NASA-TLX in a meta-study using the
ReVISit framework. Our results show that it is not the slight increase in
experiment time, but rather participants' frustration with the procedure, that
contributes to the slight increase in task load when using the full version of
the TLX compared to using a shortened version. However, we also show that the
full version can shine a different and more faceted light on workload by adding
a personal dimension to the data. We propose that a compact version of the
sources-of-workload questionnaire can mitigate both time loss and frustration
for study participants, while still providing the same data as the original
procedure. The online study can be found and interactively explored on
https://dpahr.github.io/tlxtlx/, and the source for the study, as well as the
code for our analysis, can be found on https://github.com/dpahr/tlxtlx/.

</details>


### [23] [A Robust Multi-Scale Framework with Test-Time Adaptation for sEEG-Based Speech Decoding](https://arxiv.org/abs/2509.24700)
*Suli Wang,Yang-yang Li,Siqi Cai,Haizhou Li*

Main category: cs.HC

TL;DR: 本研究提出了一种新的两阶段框架，利用多尺度混合模块和在线适应方法，提高了sEEG信号解码的可靠性，能够有效应对领域转移问题。


<details>
  <summary>Details</summary>
Motivation: 脑机接口（BCI）中使用立体脑电图（sEEG）信号解码语音的临床适用性受到神经信号固有非平稳性的限制。

Method: 提出了一个两阶段框架，包括多尺度可分解混合模块和源无关的在线测试时适应方法。

Result: 在公共DU-IN口语解码基准上的评估表明，该方法表现优于最先进的模型，尤其是在具有挑战性的情况下。

Conclusion: 结合不变特征学习与在线自适应是一种开发可靠脑机接口系统的原则性策略。

Abstract: Decoding speech from stereo-electroencephalography (sEEG) signals has emerged
as a promising direction for brain-computer interfaces (BCIs). Its clinical
applicability, however, is limited by the inherent non-stationarity of neural
signals, which causes domain shifts between training and testing, undermining
decoding reliability. To address this challenge, a two-stage framework is
proposed for enhanced robustness. First, a multi-scale decomposable mixing
(MDM) module is introduced to model the hierarchical temporal dynamics of
speech production, learning stable multi-timescale representations from sEEG
signals. Second, a source-free online test-time adaptation (TTA) method
performs entropy minimization to adapt the model to distribution shifts during
inference. Evaluations on the public DU-IN spoken word decoding benchmark show
that the approach outperforms state-of-the-art models, particularly in
challenging cases. This study demonstrates that combining invariant feature
learning with online adaptation is a principled strategy for developing
reliable BCI systems. Our code is available at
https://github.com/lyyi599/MDM-TENT.

</details>


### [24] [Understanding Collaboration between Professional Designers and Decision-making AI: A Case Study in the Workplace](https://arxiv.org/abs/2509.24718)
*Nami Ogawa,Yuki Okafuji,Yuji Hatada,Jun Baba*

Main category: cs.HC

TL;DR: 本研究探讨设计师如何与决策支持AI协作，分析其对创意设计流程的影响，并提出相应的设计整合建议。


<details>
  <summary>Details</summary>
Motivation: 探索设计师与决策支持AI的协作，以理解其在创意工作流程的收敛过程中的作用，填补现有研究的空白。

Method: 通过案例研究分析了专业图形设计师如何看待决策支持AI对其创作工作的影响，并进行了12位设计师的访谈。

Result: 研究结果揭示了设计师对AI的信任与依赖、其感知的益处与挑战，以及应对这些挑战的策略。

Conclusion: 本研究提出了将决策支持AI有效整合到创意设计工作流程中的设计建议。

Abstract: The rapid development of artificial intelligence (AI) has fundamentally
transformed creative work practices in the design industry. Existing studies
have identified both opportunities and challenges for creative practitioners in
their collaboration with generative AI and explored ways to facilitate
effective human-AI co-creation. However, there is still a limited understanding
of designers' collaboration with AI that supports creative processes distinct
from generative AI. To address these gaps, this study focuses on understanding
designers' collaboration with decision-making AI, which supports the
convergence process in the creative workflow, as opposed to the divergent
process supported by generative AI. Specifically, we conducted a case study at
an online advertising design company to explore how professional graphic
designers at the company perceive the impact of decision-making AI on their
creative work practices. The case company incorporated an AI system that
predicts the effectiveness of advertising design into the design workflow as a
decision-making support tool. Findings from interviews with 12 designers
identified how designers trust and rely on AI, its perceived benefits and
challenges, and their strategies for navigating the challenges. Based on the
findings, we discuss design recommendations for integrating decision-making AI
into the creative design workflow.

</details>


### [25] [Diamonds in the rough: Transforming SPARCs of imagination into a game concept by leveraging medium sized LLMs](https://arxiv.org/abs/2509.24730)
*Julian Geheeb,Farhan Abid Ivan,Daniel Dyrda,Miriam Anschütz,Georg Groh*

Main category: cs.HC

TL;DR: 本研究评估了中型语言模型在游戏设计中的应用，发现它们能提供高质量反馈，但需要优化提示方法以提高一致性。


<details>
  <summary>Details</summary>
Motivation: 探索中型语言模型在游戏设计中的实用性，特别是它们在小工作室或家庭环境中的应用潜力。

Method: 使用ChatGPT生成游戏创意，并对三个中型语言模型（LLaMA 3.1、Qwen 2.5和DeepSeek-R1）进行评估和比较。

Result: DeepSeek-R1在可用性反馈上表现最好，大多数参与者认为输出质量高，并希望在工作流程中使用这类工具。

Conclusion: 中型语言模型在游戏设计早期阶段能提供有价值的反馈，但提示方法的进一步优化可以提高一致性和整体有效性。

Abstract: Recent research has demonstrated that large language models (LLMs) can
support experts across various domains, including game design. In this study,
we examine the utility of medium-sized LLMs, models that operate on
consumer-grade hardware typically available in small studios or home
environments. We began by identifying ten key aspects that contribute to a
strong game concept and used ChatGPT to generate thirty sample game ideas.
Three medium-sized LLMs, LLaMA 3.1, Qwen 2.5, and DeepSeek-R1, were then
prompted to evaluate these ideas according to the previously identified
aspects. A qualitative assessment by two researchers compared the models'
outputs, revealing that DeepSeek-R1 produced the most consistently useful
feedback, despite some variability in quality. To explore real-world
applicability, we ran a pilot study with ten students enrolled in a
storytelling course for game development. At the early stages of their own
projects, students used our prompt and DeepSeek-R1 to refine their game
concepts. The results indicate a positive reception: most participants rated
the output as high quality and expressed interest in using such tools in their
workflows. These findings suggest that current medium-sized LLMs can provide
valuable feedback in early game design, though further refinement of prompting
methods could improve consistency and overall effectiveness.

</details>


### [26] [AIPOM: Agent-aware Interactive Planning for Multi-Agent Systems](https://arxiv.org/abs/2509.24826)
*Hannah Kim,Kushan Mitra,Chen Shen,Dan Zhang,Estevam Hruschka*

Main category: cs.HC

TL;DR: AIPOM是一个增强透明度和可控性的系统，通过对话和图形接口改善人机协作规划。


<details>
  <summary>Details</summary>
Motivation: 现有的基于大语言模型的方法在多智能体系统中无法满足用户期望，缺乏有效的用户行为控制和理解机制。

Method: 通过对话和基于图形的接口支持人机协作规划。

Result: AIPOM能够让用户透明地检查、完善和引导LLM生成的计划。

Conclusion: AIPOM系统增强了用户在多智能体工作流中的控制和信任，提供透明的计划检查和协作指导。

Abstract: Large language models (LLMs) are being increasingly used for planning in
orchestrated multi-agent systems. However, existing LLM-based approaches often
fall short of human expectations and, critically, lack effective mechanisms for
users to inspect, understand, and control their behaviors. These limitations
call for enhanced transparency, controllability, and human oversight. To
address this, we introduce AIPOM, a system supporting human-in-the-loop
planning through conversational and graph-based interfaces. AIPOM enables users
to transparently inspect, refine, and collaboratively guide LLM-generated
plans, significantly enhancing user control and trust in multi-agent workflows.
Our code and demo video are available at https://github.com/megagonlabs/aipom.

</details>


### [27] [Rescue Operators' Perspectives on KIRETT Wearable Technology: A Qualitative Study](https://arxiv.org/abs/2509.24831)
*Mubaris Nadeem,Johannes Zenkert,Lisa Bender,Christian Weber,Madjid Fathi*

Main category: cs.HC

TL;DR: KIRETT项目开发了一种智能手腕设备，旨在通过知识图谱和情境检测模型提高紧急情况下的治疗效果，并在用户体验设计方面进行了为期两天的定性评估。


<details>
  <summary>Details</summary>
Motivation: 在紧急情况下，治疗必须快速、准确且针对患者具体情况，而目前的治疗方法面临各种障碍，因此需要新的技术解决方案来改善患者结果。

Method: 通过对KIRETT项目进行为期两天的测试，着重评估知识图谱、知识融合和用户体验设计。

Result: 初步测试显示KIRETT演示器可以根据患者的健康状况提供更加个性化的治疗建议，提高医疗救援的有效性。

Conclusion: 该项目的结果表明，KIRETT演示器在紧急情况下的治疗推荐有潜在的改善效果，并且在用户体验方面也有积极的反馈。

Abstract: In emergencies, treatment needs to be fast, accu-rate and patient-specific.
For instance, in emergency scenarios, obstacles like treatment environments and
medical difficulties can lead to bad outcomes for patients. Additionally, a
drastic change of health vitals can force paramedics to shift to a different
treatment in the ongoing treatment of the patient in order to save a patient's
life. The KIRETT (engl.: 'Artificial intelligence in rescue operations')
demonstrator is developed to provide a rescue operator with a wrist-worn
device, enabling treatment recommendation (with the help of knowledge graph)
with situation detection models to improve the emergency treatment of a
patient. This paper aims to provide a qualitative evaluation of the 2-days
testing in the KIRETT project with the focus of knowledge graphs, knowledge
fusion, and user-experience-design (UX-design).

</details>


### [28] [Interface Design to Support Legal Reading and Writing: Insights from Interviews with Legal Experts](https://arxiv.org/abs/2509.24854)
*Chelse Swoopes,Ziwei Gu,Elena L. Glassman*

Main category: cs.HC

TL;DR: 该研究探讨了法律专业人士在使用新的阅读和写作支持工具时的实践和看法，并为工具设计和整合提供了可行性指导。


<details>
  <summary>Details</summary>
Motivation: 研究法律专业人士在阅读、写作和解读复杂文件时的任务和期望，以弥补现有研究的不足。

Method: 通过对22名法律专业人士的访谈，分析工作流程、挑战和技术使用情况，并进行上下文适配评估。

Result: 分析了工作流程中的局限性和挑战，提供了针对AI鲁棒界面的领域特定反馈，以及法律科技设计的专家见解。

Conclusion: 本研究为法律科技设计提供了可行的指导，帮助法律专业人士更好地整合工具。

Abstract: Legal professionals spend significant time reading, writing, and interpreting
complex documents, yet research has not fully captured how they approach these
tasks or what they expect from skimming and writing-support tools. To examine
practices and views on emerging tools, we interviewed 22 legal professionals
about workflows, challenges, and technology use. In each session, we leveraged
prior HCI-based skimming and writing prototypes that surface emergent
cross-document relationships and support AI-resilient interaction (noticing,
judging, and recovering from model errors or unexpected behavior); participants
completed a contextual fit evaluation to assess whether and how they would use
the tools, which document types, and at what stages in their work. Our analysis
details limitations and challenges in workflows, domain-specific feedback on
AI-resilient interfaces, and expert insights on legal tech design. These
findings offer actionable guidance for technology designers developing reading
and writing-support for legal professionals, and for legal professionals
seeking peer-informed tool integration strategies.

</details>


### [29] [Color, Gender, and Bias: Examining the Role of Stereotyped Colors in Visualization-Driven Pay Decisions](https://arxiv.org/abs/2509.24999)
*Florent Cabric,Margret Vilborg Bjarnadottir,Petra Isenberg*

Main category: cs.HC

TL;DR: 本研究探讨了性别色彩刻板印象在决策中的影响，发现明确标示会导致偏见，而缺失标示会消除此偏见。


<details>
  <summary>Details</summary>
Motivation: 理解刻板色彩在决策中的影响，有助于设计人员在易受刻板印象影响的背景下更好地选择颜色。

Method: 通过两个众包实验评估性别与颜色的关联如何影响用户的分配决策。

Result: 在有色彩-性别关联标示时出现团体偏好，而在没有标示时这一偏好消失，且非刻板色彩仅有微小影响。

Conclusion: 在薪酬调整的决策中，标示性别色彩的显著表达会导致团体偏爱，而缺乏这样的标示则能消除此偏见，非刻板色彩只产生小的影响。

Abstract: We investigate the impact of stereotyped gender-color associations in a
visualization-driven decision-making task. In the context of gender data
visualization, the well-known "pink for girls and blue for boys" color
assignment is associated with stereotypes that could bias readers and
decision-makers. Understanding the effects of using stereotyped colors in
visualizations for decision-making can help designers better choose colors in
stereotype-prone contexts. We therefore explore the potential impact of
stereotyped colors on compensation decision-making through two crowdsourced
experiments. In these experiments, we evaluate how the association of color
with gender (stereotyped vs non-stereotyped) affects the user's allocation
decisions in the context of salary adjustments. Our results indicate that
explicit expression of the color-gender associations, in the form of a legend
on the data visualization, leads to in-group favoritism. However, in the
absence of a legend, this in-group favoritism disappears, and a small effect of
non-stereotyped colors is observed. A free copy of this paper with all
supplemental materials is available at
https://osf.io/d4q3v/?view_only=22b636d6f7bb4a7991d9576933b3aaad

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [30] [Mobile Robot Localization via Indoor Positioning System and Odometry Fusion](https://arxiv.org/abs/2509.22693)
*Muhammad Hafil Nugraha,Fauzi Abdul,Lastiko Bramantyo,Estiko Rijanto,Roni Permana Saputra,Oka Mahendra*

Main category: cs.RO

TL;DR: 本文提出了一种通过融合超声波室内定位系统和轮子里程计数据的方法显著提高移动机器人在室内环境的定位精度。


<details>
  <summary>Details</summary>
Motivation: 有效操作移动机器人需要在室内环境中实现准确的定位。

Method: 采用扩展卡尔曼滤波（EKF）方法将IPS传感器数据与机器人轮子里程计数据进行融合。

Result: 实验结果表明，融合定位系统在精度和准确性上显著优于单独系统，尤其在轨迹跟踪方面表现显著提高，减少了由于轮子滑移和传感器噪声引起的错误。

Conclusion: 融合基于超声波的室内定位系统和轮子里程计数据的方法显著提升了移动机器人在室内环境中的定位精度和可靠性。

Abstract: Accurate localization is crucial for effectively operating mobile robots in
indoor environments. This paper presents a comprehensive approach to mobile
robot localization by integrating an ultrasound-based indoor positioning system
(IPS) with wheel odometry data via sensor fusion techniques. The fusion
methodology leverages the strengths of both IPS and wheel odometry,
compensating for the individual limitations of each method. The Extended Kalman
Filter (EKF) fusion method combines the data from the IPS sensors and the
robot's wheel odometry, providing a robust and reliable localization solution.
Extensive experiments in a controlled indoor environment reveal that the
fusion-based localization system significantly enhances accuracy and precision
compared to standalone systems. The results demonstrate significant
improvements in trajectory tracking, with the EKF-based approach reducing
errors associated with wheel slippage and sensor noise.

</details>


### [31] [Nonlinear Model Predictive Control with Single-Shooting Method for Autonomous Personal Mobility Vehicle](https://arxiv.org/abs/2509.22694)
*Rakha Rahmadani Pratama,Catur Hilman A. H. B. Baskoro,Joga Dharma Setiawan,Dyah Kusuma Dewi,P Paryanto,Mochammad Ariyanto,Roni Permana Saputra*

Main category: cs.RO

TL;DR: 本文提出了一种用于自主个人移动工具的控制方法，基于非线性模型预测控制（NMPC），显示出良好的效果和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为自主个人移动工具提供一种高效的控制方法，以实现目标引导和障碍物避让。

Method: 使用非线性模型预测控制（NMPC）和单次发射方法解决最佳控制问题，结合非完整运动学模型和里程计数据。

Result: 仿真结果证明了所提NMPC方法在障碍物自由和静态障碍环境中均能成功控制车辆，满足设定约束。

Conclusion: 该研究表明，基于NMPC的控制方法能够有效地引导SEATER到达目标位置，并且具备良好的鲁棒性和实时性能。

Abstract: This paper introduces a proposed control method for autonomous personal
mobility vehicles, specifically the Single-passenger Electric Autonomous
Transporter (SEATER), using Nonlinear Model Predictive Control (NMPC). The
proposed method leverages a single-shooting approach to solve the optimal
control problem (OCP) via non-linear programming (NLP). The proposed NMPC is
implemented to a non-holonomic vehicle with a differential drive system, using
odometry data as localization feedback to guide the vehicle towards its target
pose while achieving objectives and adhering to constraints, such as obstacle
avoidance. To evaluate the performance of the proposed method, a number of
simulations have been conducted in both obstacle-free and static obstacle
environments. The SEATER model and testing environment have been developed in
the Gazebo Simulation and the NMPC are implemented within the Robot Operating
System (ROS) framework. The simulation results demonstrate that the NMPC-based
approach successfully controls the vehicle to reach the desired target location
while satisfying the imposed constraints. Furthermore, this study highlights
the robustness and real-time effectiveness of NMPC with a single-shooting
approach for autonomous vehicle control in the evaluated scenarios.

</details>


### [32] [ReSeFlow: Rectifying SE(3)-Equivariant Policy Learning Flows](https://arxiv.org/abs/2509.22695)
*Zhitao Wang,Yanke Wang,Jiangtao Wen,Roberto Horowitz,Yuxing Han*

Main category: cs.RO

TL;DR: ReSeFlow 是一个高效的机器人政策生成方法，通过整流 SE(3) 扩散模型提高推理效率，在多个任务中显著降低错误率。


<details>
  <summary>Details</summary>
Motivation: 在非结构化环境中进行机器人操作需要生成稳健的长远轨迹政策，而现有的 SE(3) 变换模型在推理时间上存在成本问题。

Method: 通过引入整流结构到 SE(3) 扩散模型，提出了 ReSeFlow，专注于快速、符合测地线的一致的政策生成。

Result: ReSeFlow 只需一步推理便能在模拟基准测试中表现优于基线方法，在较短的测地距离下实现了更好的性能。

Conclusion: ReSeFlow 在 painting 任务中实现了 48.5% 的错误减少，在 rotating triangle 任务中实现了 21.9% 的错误减少，展示了其在政策生成中的优势和高效性。

Abstract: Robotic manipulation in unstructured environments requires the generation of
robust and long-horizon trajectory-level policy with conditions of perceptual
observations and benefits from the advantages of SE(3)-equivariant diffusion
models that are data-efficient. However, these models suffer from the inference
time costs. Inspired by the inference efficiency of rectified flows, we
introduce the rectification to the SE(3)-diffusion models and propose the
ReSeFlow, i.e., Rectifying SE(3)-Equivariant Policy Learning Flows, providing
fast, geodesic-consistent, least-computational policy generation. Crucially,
both components employ SE(3)-equivariant networks to preserve rotational and
translational symmetry, enabling robust generalization under rigid-body
motions. With the verification on the simulated benchmarks, we find that the
proposed ReSeFlow with only one inference step can achieve better performance
with lower geodesic distance than the baseline methods, achieving up to a 48.5%
error reduction on the painting task and a 21.9% reduction on the rotating
triangle task compared to the baseline's 100-step inference. This method takes
advantages of both SE(3) equivariance and rectified flow and puts it forward
for the real-world application of generative policy learning models with the
data and inference efficiency.

</details>


### [33] [Advancing Audio-Visual Navigation Through Multi-Agent Collaboration in 3D Environments](https://arxiv.org/abs/2509.22698)
*Hailong Zhang,Yinfeng Yu,Liejun Wang,Fuchun Sun,Wendong Zheng*

Main category: cs.RO

TL;DR: 本研究提出 MASTAVN，一个多代理音视频导航框架，展示了其在动态 3D 环境中的有效性，尤其在时间敏感任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 针对动态 3D 环境中多代理协调的挑战，尤其是在紧急响应等应用中的需求。

Method: 开发了 MASTAVN 框架，通过跨代理通信协议和音视频融合机制，实现自我定位与导航。

Result: 在 photorealistic 3D 模拟器上，MASTAVN 显著减少了任务完成时间，并改善了导航成功率。

Conclusion: MASTAVN 在多代理协作导航中展示了显著的有效性，尤其在时间敏感的紧急场景中。

Abstract: Intelligent agents often require collaborative strategies to achieve complex
tasks beyond individual capabilities in real-world scenarios. While existing
audio-visual navigation (AVN) research mainly focuses on single-agent systems,
their limitations emerge in dynamic 3D environments where rapid multi-agent
coordination is critical, especially for time-sensitive applications like
emergency response. This paper introduces MASTAVN (Multi-Agent Scalable
Transformer Audio-Visual Navigation), a scalable framework enabling two agents
to collaboratively localize and navigate toward an audio target in shared 3D
environments. By integrating cross-agent communication protocols and joint
audio-visual fusion mechanisms, MASTAVN enhances spatial reasoning and temporal
synchronization. Through rigorous evaluation in photorealistic 3D simulators
(Replica and Matterport3D), MASTAVN achieves significant reductions in task
completion time and notable improvements in navigation success rates compared
to single-agent and non-collaborative baselines. This highlights the essential
role of spatiotemporal coordination in multi-agent systems. Our findings
validate MASTAVN's effectiveness in time-sensitive emergency scenarios and
establish a paradigm for advancing scalable multi-agent embodied intelligence
in complex 3D environments.

</details>


### [34] [Large Language Models for 3D IC Space Planning](https://arxiv.org/abs/2509.22716)
*Hung-Ying Chu,Guan-Wei Chen,Shao-Yu Wei,Yu-Cheng Lin*

Main category: cs.RO

TL;DR: 该研究探讨了利用大型语言模型进行3D集成电路空间规划，通过微调和后序切片树表示法，成功实现了高效且合法的布局设计，有助于提升空间利用率。


<details>
  <summary>Details</summary>
Motivation: 为了解决二维设计的缩放极限，研究3D集成电路（3D ICs）的空间规划，以提高集成密度和性能，减少死空间。

Method: 通过对大型语言模型（LLMs）进行微调，并采用后序切片树表示法，进行3D IC空间规划，以保证合法的空间规划同时最小化死空间。

Result: 实验结果表明，所提出的框架在运行效率、合法性和死空间减少方面取得了良好的平衡，且在实际运行预算下，在相当一部分测试案例中获得了零死空间布局。

Conclusion: LLM基础的空间规划方法能够有效地补充传统电子设计自动化方法，为可扩展的3D布局生成提供新视角和数据驱动的支持。

Abstract: Three-dimensional integrated circuits (3D ICs) have emerged as a promising
solution to the scaling limits of two-dimensional designs, offering higher
integration density, shorter interconnects, and improved performance. As design
complexity increases, effective space planning becomes essential to reduce dead
space and ensure layout quality. This study investigates the use of large
language models (LLMs) for 3D IC space planning through a post-order slicing
tree representation, which guarantees legal space plans while aiming to
minimize dead space. Open-source LLMs were fine-tuned on large-scale synthetic
datasets and further evaluated on MCNC-derived 3D benchmarks. Experimental
results indicate that the proposed framework achieves a favorable balance
between runtime efficiency, legality, and dead-space reduction, with
zero-dead-space layouts obtained in a significant portion of test cases under
practical runtime budgets. Beyond synthetic benchmarks, the method generalizes
to MCNC cases such as ami33 and ami49, though larger and irregular instances
remain challenging. The approach also shows potential for cross-domain
applications, including logistics and 3D object placement, where spatial
efficiency is critical. Overall, the results suggest that LLM-based space
planning can serve as a data-driven complement to traditional electronic design
automation (EDA) methods, providing new insights for scalable 3D layout
generation.

</details>


### [35] [Self-driving cars: Are we there yet?](https://arxiv.org/abs/2509.22754)
*Merve Atasever,Zhuochen Liu,Qingpei Li,Akshay Hitendra Shah,Hans Walker,Jyotirmoy V. Deshmukh,Rahul Jain*

Main category: cs.RO

TL;DR: 本文对三大运动规划基准进行了比较，采用CARLA平台进行统一评估，识别了方法的优缺点及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 旨在推动自动驾驶领域的发展，特别是在运动规划算法的评估和改进方面。

Method: 采用CARLA基准v2.0作为统一评估平台，并对所选模型进行适配，以实现公平的比较分析。

Result: 通过分析，确定了当前运动规划方法的优势和劣势，以及未来研究的可能方向。

Conclusion: 本研究对三大领先基准中的运动规划方法进行了全面比较分析，揭示了现有方法的优缺点，识别了普遍趋势和共同挑战，并提出了未来研究的潜在方向。

Abstract: Autonomous driving remains a highly active research domain that seeks to
enable vehicles to perceive dynamic environments, predict the future
trajectories of traffic agents such as vehicles, pedestrians, and cyclists and
plan safe and efficient future motions. To advance the field, several
competitive platforms and benchmarks have been established to provide
standardized datasets and evaluation protocols. Among these, leaderboards by
the CARLA organization and nuPlan and the Waymo Open Dataset have become
leading benchmarks for assessing motion planning algorithms. Each offers a
unique dataset and challenging planning problems spanning a wide range of
driving scenarios and conditions. In this study, we present a comprehensive
comparative analysis of the motion planning methods featured on these three
leaderboards. To ensure a fair and unified evaluation, we adopt CARLA
leaderboard v2.0 as our common evaluation platform and modify the selected
models for compatibility. By highlighting the strengths and weaknesses of
current approaches, we identify prevailing trends, common challenges, and
suggest potential directions for advancing motion planning research.

</details>


### [36] [Persistent Autoregressive Mapping with Traffic Rules for Autonomous Driving](https://arxiv.org/abs/2509.22756)
*Shiyi Liang,Xinyuan Chang,Changjie Wu,Huiyuan Yan,Yifan Bai,Xinran Liu,Hang Zhang,Yujian Yuan,Shuang Zeng,Mu Xu,Xing Wei*

Main category: cs.RO

TL;DR: PAMR是一个新颖的框架，通过自回归方法共同构建车道向量和交通规则，显著提升了自动驾驶的地图生成与规则一致性。


<details>
  <summary>Details</summary>
Motivation: 安全的自动驾驶需要准确的高清地图构建和对交通规则的持续意识，特别是当交通标志不可见时。

Method: PAMR框架通过自回归共同构建车道向量和交通规则，采用两个关键机制：地图-规则共同构建和地图-规则缓存。

Result: 通过大量实验验证，PAMR在联合向量-规则映射任务中表现卓越，同时保持规则的一致性与有效性。

Conclusion: PAMR在联合向量-规则映射任务中表现优越，同时在延续的驾驶序列中保持规则的持久有效性。

Abstract: Safe autonomous driving requires both accurate HD map construction and
persistent awareness of traffic rules, even when their associated signs are no
longer visible. However, existing methods either focus solely on geometric
elements or treat rules as temporary classifications, failing to capture their
persistent effectiveness across extended driving sequences. In this paper, we
present PAMR (Persistent Autoregressive Mapping with Traffic Rules), a novel
framework that performs autoregressive co-construction of lane vectors and
traffic rules from visual observations. Our approach introduces two key
mechanisms: Map-Rule Co-Construction for processing driving scenes in temporal
segments, and Map-Rule Cache for maintaining rule consistency across these
segments. To properly evaluate continuous and consistent map generation, we
develop MapDRv2, featuring improved lane geometry annotations. Extensive
experiments demonstrate that PAMR achieves superior performance in joint
vector-rule mapping tasks, while maintaining persistent rule effectiveness
throughout extended driving sequences.

</details>


### [37] [Towards Developing Standards and Guidelines for Robot Grasping and Manipulation Pipelines in the COMPARE Ecosystem](https://arxiv.org/abs/2509.22801)
*Huajing Zhao,Brian Flynn,Adam Norton,Holly Yanco*

Main category: cs.RO

TL;DR: COMPARE生态系统致力于提高机器人操作的开源产品兼容性，通过标准化模块化实践和开发新管道来实现。


<details>
  <summary>Details</summary>
Motivation: 旨在提高开源机器人操作产品的兼容性和基准测试，促进模块化实践。

Method: 通过建立开源产品库，研究现有模块化处理流程，开发符合新的标准和指导方针的模块化管道。

Result: 文中回顾了建立开源产品库，调查现有模块化管道和开发新模块化管道的进展。

Conclusion: 该文献总结了COMPARE生态系统的实施状况，并阐述了未来的研究方向。

Abstract: The COMPARE Ecosystem aims to improve the compatibility and benchmarking of
open-source products for robot manipulation through a series of activities. One
such activity is the development of standards and guidelines to specify
modularization practices at the component-level for individual modules (e.g.,
perception, grasp planning, motion planning) and integrations of components
that form robot manipulation capabilities at the pipeline-level. This paper
briefly reviews our work-in-progress to date to (1) build repositories of
open-source products to identify common characteristics of each component in
the pipeline, (2) investigate existing modular pipelines to glean best
practices, and (3) develop new modular pipelines that advance prior work while
abiding by the proposed standards and guidelines.

</details>


### [38] [Teleoperator-Aware and Safety-Critical Adaptive Nonlinear MPC for Shared Autonomy in Obstacle Avoidance of Legged Robots](https://arxiv.org/abs/2509.22815)
*Ruturaj Sambhus,Muneeb Ahmad,Basit Muhammad Imran,Sujith Vijayan,Dylan P. Losey,Kaveh Akbari Hamed*

Main category: cs.RO

TL;DR: 提出了一种适用于远程操作的AD非线性模型预测控制框架，解决了四足机器人在障碍物避免任务中的安全与协作问题。


<details>
  <summary>Details</summary>
Motivation: 确保人类与自主四足机器人在复杂环境中的安全高效协作是共享自主界面的基本挑战。

Method: 提出了一种适应性非线性模型预测控制（ANMPC）框架，通过控制障碍函数（CBF）约束和逐层控制架构，实现人机共享自主。

Result: 通过大量数值和硬件实验，以及用户研究，验证了框架在实时避障和人类意图在线学习中的成功应用。

Conclusion: 研究展示了该框架在Quadrupedal机器人上的有效性，能够实现实时避障、在线学习人类意图参数，以及确保安全的远程操作协作。

Abstract: Ensuring safe and effective collaboration between humans and autonomous
legged robots is a fundamental challenge in shared autonomy, particularly for
teleoperated systems navigating cluttered environments. Conventional
shared-control approaches often rely on fixed blending strategies that fail to
capture the dynamics of legged locomotion and may compromise safety. This paper
presents a teleoperator-aware, safety-critical, adaptive nonlinear model
predictive control (ANMPC) framework for shared autonomy of quadrupedal robots
in obstacle-avoidance tasks. The framework employs a fixed arbitration weight
between human and robot actions but enhances this scheme by modeling the human
input with a noisily rational Boltzmann model, whose parameters are adapted
online using a projected gradient descent (PGD) law from observed joystick
commands. Safety is enforced through control barrier function (CBF) constraints
integrated into a computationally efficient NMPC, ensuring forward invariance
of safe sets despite uncertainty in human behavior. The control architecture is
hierarchical: a high-level CBF-based ANMPC (10 Hz) generates blended
human-robot velocity references, a mid-level dynamics-aware NMPC (60 Hz)
enforces reduced-order single rigid body (SRB) dynamics to track these
references, and a low-level nonlinear whole-body controller (500 Hz) imposes
the full-order dynamics via quadratic programming to track the mid-level
trajectories. Extensive numerical and hardware experiments, together with a
user study, on a Unitree Go2 quadrupedal robot validate the framework,
demonstrating real-time obstacle avoidance, online learning of human intent
parameters, and safe teleoperator collaboration.

</details>


### [39] [Parameter Identification of a Differentiable Human Arm Musculoskeletal Model without Deep Muscle EMG Reconstruction](https://arxiv.org/abs/2509.22825)
*Philip Sanderink,Yingfan Zhou,Shuzhen Luo,Cheng Fang*

Main category: cs.RO

TL;DR: 本研究提出了一种新方法，通过使用深层肌肉力量的最小二乘解，在不重建深层肌肉肌电图的情况下识别人臂肌肉骨骼模型参数，并且估计准确性得到验证。


<details>
  <summary>Details</summary>
Motivation: 为了开发安全可靠的物理协作机器人系统，需要对特定个体的人体肌肉骨骼模型进行准确的参数识别，尤其是在肌电图测量的局限性情况下。

Method: 通过使用深层肌肉力量的最小二乘解来计算相对于模型参数的损失梯度，在可微优化框架下识别参数。

Result: 我们的比较模拟结果显示，提出的方法能够在不重建深层肌肉肌电图的情况下，达到与包含所有肌肉肌电图的类似方法相当的估计准确性。

Conclusion: 我们提出的方法可以在不重建深层肌肉肌电图的情况下，实现对人臂肌肉骨骼模型的参数同时识别，且估计准确性与现有方法相当。

Abstract: Accurate parameter identification of a subject-specific human musculoskeletal
model is crucial to the development of safe and reliable physically
collaborative robotic systems, for instance, assistive exoskeletons.
Electromyography (EMG)-based parameter identification methods have demonstrated
promising performance for personalized musculoskeletal modeling, whereas their
applicability is limited by the difficulty of measuring deep muscle EMGs
invasively. Although several strategies have been proposed to reconstruct deep
muscle EMGs or activations for parameter identification, their reliability and
robustness are limited by assumptions about the deep muscle behavior. In this
work, we proposed an approach to simultaneously identify the bone and
superficial muscle parameters of a human arm musculoskeletal model without
reconstructing the deep muscle EMGs. This is achieved by only using the
least-squares solution of the deep muscle forces to calculate a loss gradient
with respect to the model parameters for identifying them in a framework of
differentiable optimization. The results of extensive comparative simulations
manifested that our proposed method can achieve comparable estimation accuracy
compared to a similar method, but with all the muscle EMGs available.

</details>


### [40] [Dynamic Buffers: Cost-Efficient Planning for Tabletop Rearrangement with Stacking](https://arxiv.org/abs/2509.22828)
*Arman Barghi,Hamed Hosseini,Seraj Ghasemi,Mehdi Tale Masouleh,Ahmad Kalhor*

Main category: cs.RO

TL;DR: 本研究提出了一种动态缓冲的新方法，以提高机器人在复杂环境中的物体重新排列效率，实验结果表明，该方法显著降低了旅行成本。


<details>
  <summary>Details</summary>
Motivation: 传统规划者在复杂环境中效率低下，存在缓冲空间限制和固定堆叠的问题。

Method: 通过引入动态缓冲，允许机器人形成可移动的临时堆叠单位。

Result: 在密集场景中，使用动态缓冲法可以将操控器的旅行成本降低11.89%；在大规模低密度设定中降低5.69%。

Conclusion: 动态缓冲作为一个关键原语，在成本高效且稳健的重新排列规划中具有重要意义。

Abstract: Rearranging objects in cluttered tabletop environments remains a
long-standing challenge in robotics. Classical planners often generate
inefficient, high-cost plans by shuffling objects individually and using fixed
buffers--temporary spaces such as empty table regions or static stacks--to
resolve conflicts. When only free table locations are used as buffers, dense
scenes become inefficient, since placing an object can restrict others from
reaching their goals and complicate planning. Allowing stacking provides extra
buffer capacity, but conventional stacking is static: once an object supports
another, the base cannot be moved, which limits efficiency. To overcome these
issues, a novel planning primitive called the Dynamic Buffer is introduced.
Inspired by human grouping strategies, it enables robots to form temporary,
movable stacks that can be transported as a unit. This improves both
feasibility and efficiency in dense layouts, and it also reduces travel in
large-scale settings where space is abundant. Compared with a state-of-the-art
rearrangement planner, the approach reduces manipulator travel cost by 11.89%
in dense scenarios with a stationary robot and by 5.69% in large, low-density
settings with a mobile manipulator. Practicality is validated through
experiments on a Delta parallel robot with a two-finger gripper. These findings
establish dynamic buffering as a key primitive for cost-efficient and robust
rearrangement planning.

</details>


### [41] [Empart: Interactive Convex Decomposition for Converting Meshes to Parts](https://arxiv.org/abs/2509.22847)
*Brandon Vu,Shameek Ganguly,Pushkar Joshi*

Main category: cs.RO

TL;DR: 提出了Empart工具，允许用户为3D网格的特定区域指定不同的简化容限，显著提高了模拟效率。


<details>
  <summary>Details</summary>
Motivation: 解决现有均匀误差容限导致的准确性与性能之间的次优权衡问题。

Method: 利用现有的凸分解算法，结合并行化框架处理区域特定约束。

Result: Empart生成的碰撞网格在机器人取放任务中，模拟时间减少了69%。

Conclusion: Empart提供了基于区域的交互式简化方法，提高了机器人应用中的模拟性能。

Abstract: Simplifying complex 3D meshes is a crucial step in robotics applications to
enable efficient motion planning and physics simulation. Common methods, such
as approximate convex decomposition, represent a mesh as a collection of simple
parts, which are computationally inexpensive to simulate. However, existing
approaches apply a uniform error tolerance across the entire mesh, which can
result in a sub-optimal trade-off between accuracy and performance. For
instance, a robot grasping an object needs high-fidelity geometry in the
vicinity of the contact surfaces but can tolerate a coarser simplification
elsewhere. A uniform tolerance can lead to excessive detail in non-critical
areas or insufficient detail where it's needed most.
  To address this limitation, we introduce Empart, an interactive tool that
allows users to specify different simplification tolerances for selected
regions of a mesh. Our method leverages existing convex decomposition
algorithms as a sub-routine but uses a novel, parallelized framework to handle
region-specific constraints efficiently. Empart provides a user-friendly
interface with visual feedback on approximation error and simulation
performance, enabling designers to iteratively refine their decomposition. We
demonstrate that our approach significantly reduces the number of convex parts
compared to a state-of-the-art method (V-HACD) at a fixed error threshold,
leading to substantial speedups in simulation performance. For a robotic
pick-and-place task, Empart-generated collision meshes reduced the overall
simulation time by 69% compared to a uniform decomposition, highlighting the
value of interactive, region-specific simplification for performant robotics
applications.

</details>


### [42] [Multi-Robot Allocation for Information Gathering in Non-Uniform Spatiotemporal Environments](https://arxiv.org/abs/2509.22883)
*Kaleb Ben Naveed,Haejoon Lee,Dimitra Panagou*

Main category: cs.RO

TL;DR: 本文提出了一种针对非均匀时空环境的多机器人领域估计的新方法，通过动态调整空间和时间长度尺度，改善了不确定性估计。


<details>
  <summary>Details</summary>
Motivation: 解决现有高斯过程方法中长度尺度设定不当导致的不确定性估计不准确的问题。

Method: 采用变差函数驱动的规划器学习区域特定空间长度尺度，并动态重新分配机器人以根据当前的不确定性更新采样。

Result: 在多种环境中评估了所提出的方法，并提供了空间长度尺度估计的收敛分析和动态遗憾界限。

Conclusion: 提出了一种两阶段框架用于多机器人领域估计，能有效应对非均匀时空环境下的长度尺度变化问题。

Abstract: Autonomous robots are increasingly deployed to estimate spatiotemporal fields
(e.g., wind, temperature, gas concentration) that vary across space and time.
We consider environments divided into non-overlapping regions with distinct
spatial and temporal dynamics, termed non-uniform spatiotemporal environments.
Gaussian Processes (GPs) can be used to estimate these fields. The GP model
depends on a kernel that encodes how the field co-varies in space and time,
with its spatial and temporal lengthscales defining the correlation. Hence,
when these lengthscales are incorrect or do not correspond to the actual field,
the estimates of uncertainty can be highly inaccurate. Existing GP methods
often assume one global lengthscale or update only periodically; some allow
spatial variation but ignore temporal changes. To address these limitations, we
propose a two-phase framework for multi-robot field estimation. Phase 1 uses a
variogram-driven planner to learn region-specific spatial lengthscales. Phase 2
employs an allocation strategy that reassigns robots based on the current
uncertainty, and updates sampling as temporal lengthscales are refined. For
encoding uncertainty, we utilize clarity, an information metric from our
earlier work. We evaluate the proposed method across diverse environments and
provide convergence analysis for spatial lengthscale estimation, along with
dynamic regret bounds quantifying the gap to the oracle's allocation sequence.

</details>


### [43] [Good Weights: Proactive, Adaptive Dead Reckoning Fusion for Continuous and Robust Visual SLAM](https://arxiv.org/abs/2509.22910)
*Yanwei Du,Jing-Chen Peng,Patricio A. Vela*

Main category: cs.RO

TL;DR: Good Weights算法通过自适应结合视觉SLAM与死算 odometry ，显著提高了在视觉条件不佳的情况下的定位精度与稳定性。


<details>
  <summary>Details</summary>
Motivation: 在纹理缺失或低光环境中，传统视觉SLAM的定位与跟踪性能下降，因此需要改进方法来结合DR，提高定位的连续性与准确性。

Method: 采用Good Weights算法，通过调整DR在视觉跟踪不可靠时的影响力，提高框架的整体性能和稳定性。

Result: 实验展示了Good Weights在实际应用和数据集上的有效性，显著改善了视觉SLAM的性能和鲁棒性。

Conclusion: Good Weights算法通过自适应结合死算 odometry (DR) 和被动视觉 SLAM，显著提升了视觉 SLAM 在纹理缺失或光照不足环境中的定位精度与鲁棒性。

Abstract: Given that Visual SLAM relies on appearance cues for localization and scene
understanding, texture-less or visually degraded environments (e.g., plain
walls or low lighting) lead to poor pose estimation and track loss. However,
robots are typically equipped with sensors that provide some form of dead
reckoning odometry with reasonable short-time performance but unreliable
long-time performance. The Good Weights (GW) algorithm described here provides
a framework to adaptively integrate dead reckoning (DR) with passive visual
SLAM for continuous and accurate frame-level pose estimation. Importantly, it
describes how all modules in a comprehensive SLAM system must be modified to
incorporate DR into its design. Adaptive weighting increases DR influence when
visual tracking is unreliable and reduces when visual feature information is
strong, maintaining pose track without overreliance on DR. Good Weights yields
a practical solution for mobile navigation that improves visual SLAM
performance and robustness. Experiments on collected datasets and in real-world
deployment demonstrate the benefits of Good Weights.

</details>


### [44] [ARMimic: Learning Robotic Manipulation from Passive Human Demonstrations in Augmented Reality](https://arxiv.org/abs/2509.22914)
*Rohan Walia,Yusheng Wang,Ralf Römer,Masahiro Nishio,Angela P. Schoellig,Jun Ota*

Main category: cs.RO

TL;DR: ARMimic为无机器人数据收集提供了一种新的轻量级解决方案，结合XR头显和工作摄像头，显著提高了演示效率和任务成功率。


<details>
  <summary>Details</summary>
Motivation: 传统的演示方法笨重且难以扩展、使用，而目前的被动观察方法需要额外硬件和复杂校准。

Method: 提出了一种集成了第一人称手部跟踪、增强现实（AR）机器人叠加和实时深度感知的轻量级框架，称为ARMimic。

Result: 在实验中，ARMimic将演示时间减少了50%，在挑战性的长时间碗堆叠任务中，任务成功率比基线提高了11%。

Conclusion: ARMimic实现了安全、无缝、灵活的数据收集，为多种现实场景中的机器人学习提供了良好的潜力。

Abstract: Imitation learning is a powerful paradigm for robot skill acquisition, yet
conventional demonstration methods--such as kinesthetic teaching and
teleoperation--are cumbersome, hardware-heavy, and disruptive to workflows.
Recently, passive observation using extended reality (XR) headsets has shown
promise for egocentric demonstration collection, yet current approaches require
additional hardware, complex calibration, or constrained recording conditions
that limit scalability and usability. We present ARMimic, a novel framework
that overcomes these limitations with a lightweight and hardware-minimal setup
for scalable, robot-free data collection using only a consumer XR headset and a
stationary workplace camera. ARMimic integrates egocentric hand tracking,
augmented reality (AR) robot overlays, and real-time depth sensing to ensure
collision-aware, kinematically feasible demonstrations. A unified imitation
learning pipeline is at the core of our method, treating both human and virtual
robot trajectories as interchangeable, which enables policies that generalize
across different embodiments and environments. We validate ARMimic on two
manipulation tasks, including challenging long-horizon bowl stacking. In our
experiments, ARMimic reduces demonstration time by 50% compared to
teleoperation and improves task success by 11% over ACT, a state-of-the-art
baseline trained on teleoperated data. Our results demonstrate that ARMimic
enables safe, seamless, and in-the-wild data collection, offering great
potential for scalable robot learning in diverse real-world settings.

</details>


### [45] [DBF-MA: A Differential Bayesian Filtering Planner for Multi-Agent Autonomous Racing Overtakes](https://arxiv.org/abs/2509.22937)
*Trent Weiss,Amar Kulkarni,Madhur Behl*

Main category: cs.RO

TL;DR: 提出基于微分贝叶斯滤波的轨迹合成方法，成功提升自主赛车中超车的效率。


<details>
  <summary>Details</summary>
Motivation: 自主赛车中的超车 maneuver 生成是主要挑战之一，现有的方法过于简化，无法满足复杂赛道的需求。

Method: 基于扩展的微分贝叶斯滤波框架进行轨迹合成，利用复合贝塞尔曲线的贝叶斯推断进行无碰撞轨迹合成。

Result: 通过闭环分析，DBF-MA在87%的测试场景中成功超车，优于其他方法。

Conclusion: 该方法在87%的测试场景中成功超车，优于现有的自主超车方法。

Abstract: A significant challenge in autonomous racing is to generate overtaking
maneuvers. Racing agents must execute these maneuvers on complex racetracks
with little room for error. Optimization techniques and graph-based methods
have been proposed, but these methods often rely on oversimplified assumptions
for collision-avoidance and dynamic constraints. In this work, we present an
approach to trajectory synthesis based on an extension of the Differential
Bayesian Filtering framework. Our approach for collision-free trajectory
synthesis frames the problem as one of Bayesian Inference over the space of
Composite Bezier Curves. Our method is derivative-free, does not require a
spherical approximation of the vehicle footprint, linearization of constraints,
or simplifying upper bounds on collision avoidance. We conduct a closed-loop
analysis of DBF-MA and find it successfully overtakes an opponent in 87% of
tested scenarios, outperforming existing methods in autonomous overtaking.

</details>


### [46] [Hierarchical Control Design for Space Robots with Application to In-Orbit Servicing Missions](https://arxiv.org/abs/2509.22955)
*Pietro Bruschi*

Main category: cs.RO

TL;DR: 该研究提出了一种用于太空中捕获翻滚物体的层次化控制框架，显示出优于现有方案的鲁棒性和适应性。


<details>
  <summary>Details</summary>
Motivation: 由于需要在太空中捕获和去除碎片，开发先进的机器人能力显得至关重要。

Method: 通过层次化控制框架结合Lyapunov鲁棒控制和扩展逆运动学问题来实现自动化捕获。

Result: 仿真结果表明，与现有控制方案相比，提出的控制器在多体动力学方面具有更好的适应性和鲁棒性。

Conclusion: 该控制框架在捕获不合作目标方面表现出更好的鲁棒性和适应性。

Abstract: In-Orbit Servicing and Active Debris Removal require advanced robotic
capabilities for capturing and detumbling uncooperative targets. This work
presents a hierarchical control framework for autonomous robotic capture of
tumbling objects in space. A simulation environment is developed, incorporating
sloshing dynamics of the chaser, a rarely studied effect in space robotics. The
proposed controller combines an inner Lyapunov-based robust control loop for
multi-body dynamics with an outer loop addressing an extended inverse
kinematics problem. Simulation results show improved robustness and
adaptability compared to existing control schemes.

</details>


### [47] [Robot Learning from Any Images](https://arxiv.org/abs/2509.22970)
*Siheng Zhao,Jiageng Mao,Wei Chow,Zeyu Shangguan,Tianheng Shi,Rong Xue,Yuxi Zheng,Yijia Weng,Yang You,Daniel Seita,Leonidas Guibas,Sergey Zakharov,Vitor Guizilini,Yue Wang*

Main category: cs.RO

TL;DR: RoLA是一种新型框架，通过单张图像生成交互式物理机器人环境，快速且高效地进行数据生成和增强。


<details>
  <summary>Details</summary>
Motivation: 我们希望简化机器人的数据生成过程，使其能够从普通的图像来源快速生成大量的视觉-运动机器人演示。

Method: RoLA的方法结合了单视图物理场景恢复的新方法和高效的视觉混合策略，以实现逼真的数据收集。

Result: RoLA能够在几分钟内生成来自各种图像源的巨大机器人数据，并支持多种应用如数据生成、增强和从互联网图像学习等。

Conclusion: RoLA是一个能够将单张图像转变为交互式物理机器人环境的框架，具有广泛的应用潜力。

Abstract: We introduce RoLA, a framework that transforms any in-the-wild image into an
interactive, physics-enabled robotic environment. Unlike previous methods, RoLA
operates directly on a single image without requiring additional hardware or
digital assets. Our framework democratizes robotic data generation by producing
massive visuomotor robotic demonstrations within minutes from a wide range of
image sources, including camera captures, robotic datasets, and Internet
images. At its core, our approach combines a novel method for single-view
physical scene recovery with an efficient visual blending strategy for
photorealistic data collection. We demonstrate RoLA's versatility across
applications like scalable robotic data generation and augmentation, robot
learning from Internet images, and single-image real-to-sim-to-real systems for
manipulators and humanoids. Video results are available at
https://sihengz02.github.io/RoLA .

</details>


### [48] [Safe Task Space Synchronization with Time-Delayed Information](https://arxiv.org/abs/2509.22976)
*Rounak Bhattacharya,Vrithik R. Guthikonda,Ashwin P. Dani*

Main category: cs.RO

TL;DR: 本文设计了一种自适应控制器，以应对人机协作任务中因时间延迟导致的轨迹同步问题，使用障碍李雅普诺夫函数确保安全，仿真结果表明该控制器有效。


<details>
  <summary>Details</summary>
Motivation: 人机协作任务中，由于多种因素导致的信息传递延迟，需要设计一个高效的控制器以同步机器人轨迹与人类轨迹。

Method: 采用了障碍李雅普诺夫函数（BLF）和李雅普诺夫-克拉索夫斯基（LK）函数进行稳定性分析，同时应用了基于ICL的自适应法则和基于梯度的自适应法则。

Result: 仿真结果表明，所设计的控制器在有时间延迟的情况下，能够有效实现轨迹同步并满足安全约束。

Conclusion: 所设计的自适应控制器有效地实现了机器人轨迹与人类轨迹的同步，同时确保了安全性。

Abstract: In this paper, an adaptive controller is designed for the synchronization of
the trajectory of a robot with unknown kinematics and dynamics to that of the
current human trajectory in the task space using the delayed human trajectory
information. The communication time delay may be a result of various factors
that arise in human-robot collaboration tasks, such as sensor processing or
fusion to estimate trajectory/intent, network delays, or computational
limitations. The developed adaptive controller uses Barrier Lyapunov Function
(BLF) to constrain the Cartesian coordinates of the robot to ensure safety, an
ICL-based adaptive law to account for the unknown kinematics, and a
gradient-based adaptive law to estimate unknown dynamics. Barrier
Lyapunov-Krasovskii (LK) functionals are used for the stability analysis to
show that the synchronization and parameter estimation errors remain
semi-globally uniformly ultimately bounded (SGUUB). The simulation results
based on a human-robot synchronization scenario with time delay are provided to
demonstrate the effectiveness of the designed synchronization controller with
safety constraints.

</details>


### [49] [UniPrototype: Humn-Robot Skill Learning with Uniform Prototypes](https://arxiv.org/abs/2509.23021)
*Xiao Hu,Qi Yin,Yangming Shi,Yang Ye*

Main category: cs.RO

TL;DR: 提出UniPrototype框架，解决机器人学习中的数据稀缺问题，通过原型机制实现人类知识的有效转移，实验结果表明其极大提升了机器人学习效率和任务表现。


<details>
  <summary>Details</summary>
Motivation: 解决机器人学习中的数据稀缺问题，提升机器人操控能力。

Method: 通过引入组合原型发现机制和自适应原型选择策略，进行知识转移。

Result: 经过广泛的模拟和实际实验验证，UniPrototype有效提升了机器人对人类操控知识的学习能力。

Conclusion: UniPrototype能够成功将人类的操控知识转移到机器人上，显著提高学习效率和任务执行性能。

Abstract: Data scarcity remains a fundamental challenge in robot learning. While human
demonstrations benefit from abundant motion capture data and vast internet
resources, robotic manipulation suffers from limited training examples. To
bridge this gap between human and robot manipulation capabilities, we propose
UniPrototype, a novel framework that enables effective knowledge transfer from
human to robot domains via shared motion primitives. ur approach makes three
key contributions: (1) We introduce a compositional prototype discovery
mechanism with soft assignments, enabling multiple primitives to co-activate
and thus capture blended and hierarchical skills; (2) We propose an adaptive
prototype selection strategy that automatically adjusts the number of
prototypes to match task complexity, ensuring scalable and efficient
representation; (3) We demonstrate the effectiveness of our method through
extensive experiments in both simulation environments and real-world robotic
systems. Our results show that UniPrototype successfully transfers human
manipulation knowledge to robots, significantly improving learning efficiency
and task performance compared to existing approaches.The code and dataset will
be released upon acceptance at an anonymous repository.

</details>


### [50] [RAISE: A Robot-Assisted Selective Disassembly and Sorting System for End-of-Life Phones](https://arxiv.org/abs/2509.23048)
*Chang Liu,Badrinath Balasubramaniam,Neal Yancey,Michael Severson,Adam Shine,Philip Bove,Beiwen Li,Xiao Liang,Minghui Zheng*

Main category: cs.RO

TL;DR: 提出了一种新型自动化拆解系统，能够提高EoL手机的拆解效率和经济效益，解决当前人工作业带来的时间与劳动密集问题。


<details>
  <summary>Details</summary>
Motivation: 由于EoL手机的高生产量和短生命周期，其拆解过程在回收中至关重要，但目前依赖人工操作，且劳动强度大、耗时长。

Method: 提出了一种低成本、易于部署的自动化和选择性拆解分类系统，包括自适应切割系统、基于视觉的机器人分类系统和电池拆除系统。

Result: 该系统每小时可处理超过120部手机，平均拆解成功率达到98.9%，为后续处理提供高价值组件。

Conclusion: 该自动化系统提供了一种可靠和可扩展的EoL手机拆解解决方案，能够提高经济效益，将原本无利可图的拆解过程转变为每单位重量EoL手机的盈利过程。

Abstract: End-of-Life (EoL) phones significantly exacerbate global e-waste challenges
due to their high production volumes and short lifecycles. Disassembly is among
the most critical processes in EoL phone recycling. However, it relies heavily
on human labor due to product variability. Consequently, the manual process is
both labor-intensive and time-consuming. In this paper, we propose a low-cost,
easily deployable automated and selective disassembly and sorting system for
EoL phones, consisting of three subsystems: an adaptive cutting system, a
vision-based robotic sorting system, and a battery removal system. The system
can process over 120 phones per hour with an average disassembly success rate
of 98.9%, efficiently delivering selected high-value components to downstream
processing. It provides a reliable and scalable automated solution to the
pressing challenge of EoL phone disassembly. Additionally, the automated system
can enhance disassembly economics, converting a previously unprofitable process
into one that yields a net profit per unit weight of EoL phones.

</details>


### [51] [In-Hand Manipulation of Articulated Tools with Dexterous Robot Hands with Sim-to-Real Transfer](https://arxiv.org/abs/2509.23075)
*Soofiyan Atar,Daniel Huang,Florian Richter,Michael Yip*

Main category: cs.RO

TL;DR: 本研究通过机器人手控制器的设计，成功解决了在复杂接触场景下对关节工具的操控挑战，提升了机器人的适应性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 应对机器人操作关节机械装置时，由于接触动力学和关节现象引起的策略脆弱性挑战。

Method: 使用减少关节自由度和运动冗余的机械手，通过结合内部意图的动作与触觉和力反馈，实现了在线适应和精准控制。

Result: 在各种实际场景（如剪刀、钳子、微创外科工具和订书机）中验证了方法的有效性，实现了从模拟到硬件的鲁棒转移，增强了抵抗扰动的能力以及对新型关节工具的泛化能力。

Conclusion: 本研究提出的控制器通过结合感知驱动的细化和模拟训练的基础策略，解决了在接触丰富的动态环境中对关节机制进行精确操控的问题，展现出在机械手与各种物体间高效的转移能力。

Abstract: Reinforcement learning (RL) and sim-to-real transfer have advanced robotic
manipulation of rigid objects. Yet, policies remain brittle when applied to
articulated mechanisms due to contact-rich dynamics and under-modeled joint
phenomena such as friction, stiction, backlash, and clearances. We address this
challenge through dexterous in-hand manipulation of articulated tools using a
robotic hand with reduced articulation and kinematic redundancy relative to the
human hand. Our controller augments a simulation-trained base policy with a
sensor-driven refinement learned from hardware demonstrations, conditioning on
proprioception and target articulation states while fusing whole-hand tactile
and force feedback with the policy's internal action intent via
cross-attention-based integration. This design enables online adaptation to
instance-specific articulation properties, stabilizes contact interactions,
regulates internal forces, and coordinates coupled-link motion under
perturbations. We validate our approach across a diversity of real-world
examples, including scissors, pliers, minimally invasive surgical tools, and
staplers. We achieve robust transfer from simulation to hardware, improved
disturbance resilience, and generalization to previously unseen articulated
tools, thereby reducing reliance on precise physical modeling in contact-rich
settings.

</details>


### [52] [Open-Vocabulary Spatio-Temporal Scene Graph for Robot Perception and Teleoperation Planning](https://arxiv.org/abs/2509.23107)
*Yi Wang,Zeyu Xue,Mujie Liu,Tongqin Zhang,Yan Hu,Zhou Zhao,Chenguang Yang,Zhenyu Lu*

Main category: cs.RO

TL;DR: 本文提出了一种新型的时空开放词汇场景图(ST-OVSG)，有效降低了遥操作中的通信延迟带来的误解，提高了指令执行的准确性和成功率。


<details>
  <summary>Details</summary>
Motivation: 减少在高风险或远程环境中进行自然语言遥操作时，由于通信延迟导致的命令误解和错误执行问题。

Method: 通过构建包含时间动态和延迟注释的开放词汇场景图来增强三维物体表示，并使用匈牙利匹配将其扩展到时间域。

Result: 在Replica基准测试中，方法的节点准确率达到74%，在延迟鲁棒性实验中，规划成功率为70.5%。

Conclusion: ST-OVSG提高了在动态远程场景下的指令执行准确性和规划成功率，表现出显著的延迟鲁棒性。

Abstract: Teleoperation via natural-language reduces operator workload and enhances
safety in high-risk or remote settings. However, in dynamic remote scenes,
transmission latency during bidirectional communication creates gaps between
remote perceived states and operator intent, leading to command
misunderstanding and incorrect execution. To mitigate this, we introduce the
Spatio-Temporal Open-Vocabulary Scene Graph (ST-OVSG), a representation that
enriches open-vocabulary perception with temporal dynamics and lightweight
latency annotations. ST-OVSG leverages LVLMs to construct open-vocabulary 3D
object representations, and extends them into the temporal domain via Hungarian
assignment with our temporal matching cost, yielding a unified spatio-temporal
scene graph. A latency tag is embedded to enable LVLM planners to
retrospectively query past scene states, thereby resolving local-remote state
mismatches caused by transmission delays. To further reduce redundancy and
highlight task-relevant cues, we propose a task-oriented subgraph filtering
strategy that produces compact inputs for the planner. ST-OVSG generalizes to
novel categories and enhances planning robustness against transmission latency
without requiring fine-tuning. Experiments show that our method achieves 74
percent node accuracy on the Replica benchmark, outperforming ConceptGraph.
Notably, in the latency-robustness experiment, the LVLM planner assisted by
ST-OVSG achieved a planning success rate of 70.5 percent.

</details>


### [53] [Liaohe-CobotMagic-PnP: an Imitation Learning Dataset of Intelligent Robot for Industrial Applications](https://arxiv.org/abs/2509.23111)
*Chen Yizhe,Wang Qi,Hu Dongxiao,Jingzhe Fang,Liu Sichao,Zixin An,Hongliang Niu,Haoran Liu,Li Dong,Chuanfen Feng,Lan Dapeng,Liu Yu,Zhibo Pang*

Main category: cs.RO

TL;DR: 为应对工业4.0中的动态环境干扰，本研究提出了一个针对机器人感知和控制的多模态干扰数据集，提高了模型验证的稳健性和操作稳定性。


<details>
  <summary>Details</summary>
Motivation: 动态环境干扰导致机器人行为和环境状态之间存在高度非线性和强耦合的交互，表明需要有效地表示动态环境状态。

Method: 采用微秒级时间同步和抗振动数据采集协议，通过机器人操作系统（ROS）收集多模态干扰数据，整合尺寸、颜色和照明变化等特征。

Result: 实验结果显示，该数据集能够提升模型的验证能力和机器人在复杂条件下的操作稳定性。

Conclusion: 该数据集显著提高了模型验证的稳健性，并增强了机器人在动态干扰环境中的操作稳定性。

Abstract: In Industry 4.0 applications, dynamic environmental interference induces
highly nonlinear and strongly coupled interactions between the environmental
state and robotic behavior. Effectively representing dynamic environmental
states through multimodal sensor data fusion remains a critical challenge in
current robotic datasets. To address this, an industrial-grade multimodal
interference dataset is presented, designed for robotic perception and control
under complex conditions. The dataset integrates multi-dimensional interference
features including size, color, and lighting variations, and employs
high-precision sensors to synchronously collect visual, torque, and joint-state
measurements. Scenarios with geometric similarity exceeding 85\% and
standardized lighting gradients are included to ensure real-world
representativeness. Microsecond-level time-synchronization and
vibration-resistant data acquisition protocols, implemented via the Robot
Operating System (ROS), guarantee temporal and operational fidelity.
Experimental results demonstrate that the dataset enhances model validation
robustness and improves robotic operational stability in dynamic,
interference-rich environments. The dataset is publicly available
at:https://modelscope.cn/datasets/Liaoh_LAB/Liaohe-CobotMagic-PnP.

</details>


### [54] [FTACT: Force Torque aware Action Chunking Transformer for Pick-and-Reorient Bottle Task](https://arxiv.org/abs/2509.23112)
*Ryo Watanabe,Maxime Alvarez,Pablo Ferreiro,Pavel Savkin,Genki Sano*

Main category: cs.RO

TL;DR: 本研究提出了一种结合视觉、力和扭矩感知的多模态模仿学习策略，有效提高了机器人在复杂零售环境中的操控能力。


<details>
  <summary>Details</summary>
Motivation: 在零售环境中，机器人操作时面临丰富接触的边缘案例，特别是对立放的饮料瓶，传统的视觉线索不足以解决精确操控所需的微妙接触事件。

Method: 提出了一种多模态模仿学习策略，增强了动作分块变换器，结合了力和扭矩感知，实现了基于图像、关节状态、力和扭矩的端到端学习。

Result: 相比基线方法，我们的方法在任务成功率上表现更佳，特别是在视觉可观察性有限的按压和放置阶段，表明力和扭矩信号对提升操作能力有积极作用。

Conclusion: 结合现代模仿学习架构和轻量级力与扭矩传感器，为零售操作的规模化提供了一条切实可行的路径。

Abstract: Manipulator robots are increasingly being deployed in retail environments,
yet contact rich edge cases still trigger costly human teleoperation. A
prominent example is upright lying beverage bottles, where purely visual cues
are often insufficient to resolve subtle contact events required for precise
manipulation. We present a multimodal Imitation Learning policy that augments
the Action Chunking Transformer with force and torque sensing, enabling
end-to-end learning over images, joint states, and forces and torques. Deployed
on Ghost, single-arm platform by Telexistence Inc, our approach improves
Pick-and-Reorient bottle task by detecting and exploiting contact transitions
during pressing and placement. Hardware experiments demonstrate greater task
success compared to baseline matching the observation space of ACT as an
ablation and experiments indicate that force and torque signals are beneficial
in the press and place phases where visual observability is limited, supporting
the use of interaction forces as a complementary modality for contact rich
skills. The results suggest a practical path to scaling retail manipulation by
combining modern imitation learning architectures with lightweight force and
torque sensing.

</details>


### [55] [EKF-Based Fusion of Wi-Fi/LiDAR/IMU for Indoor Localization and Navigation](https://arxiv.org/abs/2509.23118)
*Zeyi Li,Zhe Tang,Kyeong Soo Kim,Sihao Li,Jeremy S. Smith*

Main category: cs.RO

TL;DR: 提出一种整合Wi-Fi RSSI、LiDAR SLAM和IMU的室内定位框架，显著提高定位精度。


<details>
  <summary>Details</summary>
Motivation: 现有Wi-Fi RSSI指纹识别精度不足，LiDAR解决方案成本高且复杂，因此需要一种新的室内定位和导航框架。

Method: 结合Wi-Fi RSSI指纹识别、基于LiDAR的SLAM及IMU导航，采用扩展卡尔曼滤波。

Result: 实验表明，提出的方法的平均二维误差为0.2449米到0.3781米，显著优于单一Wi-Fi和LiDAR/IMU定位方法的误差。

Conclusion: 多传感器融合框架有效抑制个体方法造成的不稳定性，提供更稳定的精度。

Abstract: Conventional Wi-Fi received signal strength indicator (RSSI) fingerprinting
cannot meet the growing demand for accurate indoor localization and navigation
due to its lower accuracy, while solutions based on light detection and ranging
(LiDAR) can provide better localization performance but is limited by their
higher deployment cost and complexity. To address these issues, we propose a
novel indoor localization and navigation framework integrating Wi-Fi RSSI
fingerprinting, LiDAR-based simultaneous localization and mapping (SLAM), and
inertial measurement unit (IMU) navigation based on an extended Kalman filter
(EKF). Specifically, coarse localization by deep neural network (DNN)-based
Wi-Fi RSSI fingerprinting is refined by IMU-based dynamic positioning using a
Gmapping-based SLAM to generate an occupancy grid map and output high-frequency
attitude estimates, which is followed by EKF prediction-update integrating
sensor information while effectively suppressing Wi-Fi-induced noise and IMU
drift errors. Multi-group real-world experiments conducted on the IR building
at Xi'an Jiaotong-Liverpool University demonstrates that the proposed
multi-sensor fusion framework suppresses the instability caused by individual
approaches and thereby provides stable accuracy across all path configurations
with mean two-dimensional (2D) errors ranging from 0.2449 m to 0.3781 m. In
contrast, the mean 2D errors of Wi-Fi RSSI fingerprinting reach up to 1.3404 m
in areas with severe signal interference, and those of LiDAR/IMU localization
are between 0.6233 m and 2.8803 m due to cumulative drift.

</details>


### [56] [LAGEA: Language Guided Embodied Agents for Robotic Manipulation](https://arxiv.org/abs/2509.23155)
*Abdul Monaf Chowdhury,Akm Moshiur Rahman Mazumder,Rabeya Akter,Safaeid Hossain Arib*

Main category: cs.RO

TL;DR: 本研究提出LAGEA框架，通过自然语言反馈优化机器人自我反省能力，实现更高的操作成功率。


<details>
  <summary>Details</summary>
Motivation: 研究自然语言是否可以作为反馈信号，帮助机器人判断错误并纠正方向。

Method: 引入了LAGEA框架，将视觉语言模型的反思转化为强化学习的时间基础指导。

Result: 在Meta-World MT10基准测试中，LAGEA在随机目标上提高了9.0%的成功率，在固定目标上提高了5.3%的成功率，并且收敛更快。

Conclusion: 语言能够有效地帮助机器人自我反思错误并做出更好的选择。

Abstract: Robotic manipulation benefits from foundation models that describe goals, but
today's agents still lack a principled way to learn from their own mistakes. We
ask whether natural language can serve as feedback, an error reasoning signal
that helps embodied agents diagnose what went wrong and correct course. We
introduce LAGEA (Language Guided Embodied Agents), a framework that turns
episodic, schema-constrained reflections from a vision language model (VLM)
into temporally grounded guidance for reinforcement learning. LAGEA summarizes
each attempt in concise language, localizes the decisive moments in the
trajectory, aligns feedback with visual state in a shared representation, and
converts goal progress and feedback agreement into bounded, step-wise shaping
rewardswhose influence is modulated by an adaptive, failure-aware coefficient.
This design yields dense signals early when exploration needs direction and
gracefully recedes as competence grows. On the Meta-World MT10 embodied
manipulation benchmark, LAGEA improves average success over the
state-of-the-art (SOTA) methods by 9.0% on random goals and 5.3% on fixed
goals, while converging faster. These results support our hypothesis: language,
when structured and grounded in time, is an effective mechanism for teaching
robots to self-reflect on mistakes and make better choices. Code will be
released soon.

</details>


### [57] [Physically-Feasible Reactive Synthesis for Terrain-Adaptive Locomotion](https://arxiv.org/abs/2509.23185)
*Ziyi Zhou,Qian Meng,Hadas Kress-Gazit,Ye Zhao*

Main category: cs.RO

TL;DR: 提出一种集成规划框架，结合反应合成和混合整数凸编程，用于实现四足动物在动态变化地形中的运动，具备优秀的鲁棒性和适应能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在实时足迹选择中依赖启发式，限制了其鲁棒性和适应性，因此提出一种更高效的集成规划框架。

Method: 结合反应合成生成符号级控制器以及混合整数凸编程进行动态和物理可行的足迹规划。

Result: 通过广泛的仿真和硬件实验验证了该框架的有效性。

Conclusion: 该框架能够有效识别缺失的运动技能，并在安全关键环境中表现出色。

Abstract: We present an integrated planning framework for quadrupedal locomotion over
dynamically changing, unforeseen terrains. Existing methods often depend on
heuristics for real-time foothold selection-limiting robustness and
adaptability-or rely on computationally intensive trajectory optimization
across complex terrains and long horizons. In contrast, our approach combines
reactive synthesis for generating correct-by-construction symbolic-level
controllers with mixed-integer convex programming (MICP) for dynamic and
physically feasible footstep planning during each symbolic transition. To
reduce the reliance on costly MICP solves and accommodate specifications that
may be violated due to physical infeasibility, we adopt a symbolic repair
mechanism that selectively generates only the required symbolic transitions.
During execution, real-time MICP replanning based on actual terrain data,
combined with runtime symbolic repair and delay-aware coordination, enables
seamless bridging between offline synthesis and online operation. Through
extensive simulation and hardware experiments, we validate the framework's
ability to identify missing locomotion skills and respond effectively in
safety-critical environments, including scattered stepping stones and rebar
scenarios.

</details>


### [58] [CE-Nav: Flow-Guided Reinforcement Refinement for Cross-Embodiment Local Navigation](https://arxiv.org/abs/2509.23203)
*Kai Yang,Tianlin Zhang,Zhengbo Wang,Zedong Chu,Xiaolong Wu,Yang Cai,Mu Xu*

Main category: cs.RO

TL;DR: CE-Nav提出了一种两阶段框架，通过模仿学习和在线强化学习，实现了跨机器人形态的导航政策泛化，取得了出色的实验结果。


<details>
  <summary>Details</summary>
Motivation: 解决机器人导航政策在不同形态中的泛化困难，尤其是数据成本高和规划控制紧密耦合的问题。

Method: CE-Nav采用两阶段框架，首先通过模仿学习训练一个通用专家，然后结合在线强化学习进行动态适应。

Result: CE-Nav在四足、双足和四旋翼机器人上的大量实验表明，其实现了最先进的性能，并显著降低了适应成本。

Conclusion: CE-Nav是一个高效且可扩展的解决方案，能够解决多种机器人形态的通用导航系统构建问题，具有先进的性能。

Abstract: Generalizing local navigation policies across diverse robot morphologies is a
critical challenge. Progress is often hindered by the need for costly and
embodiment-specific data, the tight coupling of planning and control, and the
"disastrous averaging" problem where deterministic models fail to capture
multi-modal decisions (e.g., turning left or right). We introduce CE-Nav, a
novel two-stage (IL-then-RL) framework that systematically decouples universal
geometric reasoning from embodiment-specific dynamic adaptation. First, we
train an embodiment-agnostic General Expert offline using imitation learning.
This expert, a conditional normalizing flow model named VelFlow, learns the
full distribution of kinematically-sound actions from a large-scale dataset
generated by a classical planner, completely avoiding real robot data and
resolving the multi-modality issue. Second, for a new robot, we freeze the
expert and use it as a guiding prior to train a lightweight, Dynamics-Aware
Refiner via online reinforcement learning. This refiner rapidly learns to
compensate for the target robot's specific dynamics and controller
imperfections with minimal environmental interaction. Extensive experiments on
quadrupeds, bipeds, and quadrotors show that CE-Nav achieves state-of-the-art
performance while drastically reducing adaptation cost. Successful real-world
deployments further validate our approach as an efficient and scalable solution
for building generalizable navigation systems.

</details>


### [59] [Simulated Annealing for Multi-Robot Ergodic Information Acquisition Using Graph-Based Discretization](https://arxiv.org/abs/2509.23214)
*Benjamin Wong,Aaron Weber,Mohamed M. Safwat,Santosh Devasia,Ashis G. Banerjee*

Main category: cs.RO

TL;DR: 本研究提出一种基于模拟退火的目标采样分布生成方法，能够有效改善多机器人团队的信息获取能力，验证了算法的实际可行性。


<details>
  <summary>Details</summary>
Motivation: 确保多机器人团队在不同区域保持相同的不确定性水平，以实现一致的目标检测质量。

Method: 采用模拟退火法创建采样分布，通过调整玻尔兹曼分布中的冷度参数来优化，利用自估计的采样熵作为能量水平。

Result: 仿真结果显示，该方法在瞬态和渐近熵上较均匀和直接遍历搜索都有明显改善，并通过TurtleBot群体系统进行了算法的实证验证。

Conclusion: 使用模拟退火算法生成目标采样分布可以显著提高信息获取的效果，尤其是在估计不准确的情况下。

Abstract: One of the goals of active information acquisition using multi-robot teams is
to keep the relative uncertainty in each region at the same level to maintain
identical acquisition quality (e.g., consistent target detection) in all the
regions. To achieve this goal, ergodic coverage can be used to assign the
number of samples according to the quality of observation, i.e., sampling noise
levels. However, the noise levels are unknown to the robots. Although this
noise can be estimated from samples, the estimates are unreliable at first and
can generate fluctuating values. The main contribution of this paper is to use
simulated annealing to generate the target sampling distribution, starting from
uniform and gradually shifting to an estimated optimal distribution, by varying
the coldness parameter of a Boltzmann distribution with the estimated sampling
entropy as energy. Simulation results show a substantial improvement of both
transient and asymptotic entropy compared to both uniform and direct-ergodic
searches. Finally, a demonstration is performed with a TurtleBot swarm system
to validate the physical applicability of the algorithm.

</details>


### [60] [DynaMIC: Dynamic Multimodal In-Context Learning Enabled Embodied Robot Counterfactual Resistance Ability](https://arxiv.org/abs/2509.24413)
*Tianqiang Yan,Ziqiao Lin,Sicheng Wang,Tianwei Zhang,Zhenglong Sun*

Main category: cs.RO

TL;DR: 本研究提出DynaMIC框架，旨在提升机器人对误导性指令的敏感性，减少任务执行中的错误，从而提高安全性。


<details>
  <summary>Details</summary>
Motivation: 探索机器人在执行任务时对误导性人类指令的敏感性，以减少潜在的安全风险。

Method: 提出DynaMIC框架，通过生成机器人的任务流程来识别指导性反事实，并向人类反馈。

Result: 通过语义水平的实验和消融研究，验证了DynaMIC框架的有效性。

Conclusion: DynaMIC框架能够识别误导性指令中的指导性反事实，从而提高机器人执行过程的可靠性。

Abstract: The emergence of large pre-trained models based on natural language has
breathed new life into robotics development. Extensive research has integrated
large models with robots, utilizing the powerful semantic understanding and
generation capabilities of large models to facilitate robot control through
natural language instructions gradually. However, we found that robots that
strictly adhere to human instructions, especially those containing misleading
information, may encounter errors during task execution, potentially leading to
safety hazards. This resembles the concept of counterfactuals in natural
language processing (NLP), which has not yet attracted much attention in
robotic research. In an effort to highlight this issue for future studies, this
paper introduced directive counterfactuals (DCFs) arising from misleading human
directives. We present DynaMIC, a framework for generating robot task flows to
identify DCFs and relay feedback to humans proactively. This capability can
help robots be sensitive to potential DCFs within a task, thus enhancing the
reliability of the execution process. We conducted semantic-level experiments
and ablation studies, showcasing the effectiveness of this framework.

</details>


### [61] [GLUE: Global-Local Unified Encoding for Imitation Learning via Key-Patch Tracking](https://arxiv.org/abs/2509.23220)
*Ye Chen,Zichen Zhou,Jianyu Dou,Te Cui,Yi Yang,Yufeng Yue*

Main category: cs.RO

TL;DR: GLUE是一个基于关键补丁跟踪的全局-局部统一编码框架，旨在通过改善局部和全局视觉表示的融合，提高复杂环境中机器人模仿学习的性能。


<details>
  <summary>Details</summary>
Motivation: 在复杂的OOD设置中，全局视觉表示可能会遭到干扰，而局部表示对任务相关对象具有不变性，因此利用局部表示来改善政策表现。

Method: 通过关键补丁跟踪的全局-局部统一编码框架，选择和跟踪关键局部表示，并利用文本引导机制进行信息提炼。

Result: GLUE在仿真和真实世界任务中表现出色，仿真中比最强基线提高17.6%，真实世界环境中提高36.3%，以及真实世界泛化设置中提高58.3%。

Conclusion: GLUE显著提高了仿真和真实世界任务中的模仿学习性能，解决了复杂环境中的局部与全局表示的挑战。

Abstract: In recent years, visual representation learning has gained widespread
attention in robotic imitation learning. However, in complex
Out-of-Distribution(OOD) settings characterized by clutter and occlusion, the
attention of global visual representations can be diluted or interfered,
leading to degraded policy performance. The invariance of local representations
for task-relevant objects offers a solution. By efficiently utilizing these
local representations, training and testing data can be mapped to a more
similar feature space, thereby mitigating the covariate shift problem.
Accordingly, we propose GLUE, a global-local unified encoding framework for
imitation learning based on key-patch tracking. GLUE selects and tracks
key-patches as critical local representations by employing a text-guided
mechanism. It features a novel fusion framework where global patch features
query local patches to distill essential information, yielding fine-grained
local features with low heterogeneity relative to the global context. This
fused representation steers the robot's visual attention toward task-relevant
objects and preserves precise global context, which together align the training
and testing distributions into a similar and task-informative feature space,
ultimately enhancing the robustness of the imitation learning policy.
Experiments demonstrate that GLUE achieves strong performance across diverse
tasks in both simulation and real-world settings, outperforming the strongest
baseline by 17.6% in simulation, 36.3% in real-world environments, and 58.3% on
real-world generalization settings. The project website of GLUE is available at
https://GLUE666.github.io/.

</details>


### [62] [SAC-Loco: Safe and Adjustable Compliant Quadrupedal Locomotion](https://arxiv.org/abs/2509.23223)
*Aoqian Zhang,Zixuan Zhuang,Chunzheng Wang,Shuzhi Sam Ge,Fan Shi,Cheng Xiang*

Main category: cs.RO

TL;DR: 本文提出了一种切换策略框架，增强四足机器人在强扰动下的顺应性和安全性，解决了现有控制方法的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的四足机器人控制方法缺乏动物所观察到的适应性和可调顺应性，尤其在面对大范围扰动时容易失效。

Method: 采用教师-学生强化学习框架训练具有可调顺应级别的力顺应策略，结合基于捕获点概念的安全策略以及预测失败可能性的恢复网络。

Result: 通过引入切换策略框架，实现了四足机器人在适应外部干扰时的顺应能力和安全性。

Conclusion: 该框架使四足机器人在遭受严重外部干扰时能够实现力的顺应性和稳健的安全性。

Abstract: Quadruped robots are designed to achieve agile locomotion by mimicking legged
animals. However, existing control methods for quadrupeds often lack one of the
key capabilities observed in animals: adaptive and adjustable compliance in
response to external disturbances. Most locomotion controllers do not provide
tunable compliance and tend to fail under large perturbations. In this work, we
propose a switched policy framework for compliant and safe quadruped
locomotion. First, we train a force compliant policy with adjustable compliance
levels using a teacher student reinforcement learning framework, eliminating
the need for explicit force sensing. Next, we develop a safe policy based on
the capture point concept to stabilize the robot when the compliant policy
fails. Finally, we introduce a recoverability network that predicts the
likelihood of failure and switches between the compliant and safe policies.
Together, this framework enables quadruped robots to achieve both force
compliance and robust safety when subjected to severe external disturbances.

</details>


### [63] [Leave No Observation Behind: Real-time Correction for VLA Action Chunks](https://arxiv.org/abs/2509.23224)
*Kohei Sendai,Maxime Alvarez,Tatsuya Matsushima,Yutaka Matsuo,Yusuke Iwasawa*

Main category: cs.RO

TL;DR: 提出了一种新的轻量级模块A2C2，用于纠正Vision-Language-Action模型的动作块，显著提升了实时控制中的成功率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为了解决VLA模型在推理延迟和长时间距离下的反应性问题，提高效率和时间一致性。

Method: 采用轻量级的实时块修正头，在每个控制步骤上运行，为传统的VLA动作块添加时间感知修正。

Result: 在动态Kinetix任务套件（12个任务）和LIBERO Spatial上，A2C2方法在延迟和执行时间上均取得了一致的成功率提升 (+23% 和 +7%)，并且在长时效下即使没有延迟也能提高鲁棒性。

Conclusion: A2C2是一种有效的小型插件机制，能够在实时控制中增强高容量的块策略。

Abstract: To improve efficiency and temporal coherence, Vision-Language-Action (VLA)
models often predict action chunks; however, this action chunking harms
reactivity under inference delay and long horizons. We introduce Asynchronous
Action Chunk Correction (A2C2), which is a lightweight real-time chunk
correction head that runs every control step and adds a time-aware correction
to any off-the-shelf VLA's action chunk. The module combines the latest
observation, the predicted action from VLA (base action), a positional feature
that encodes the index of the base action within the chunk, and some features
from the base policy, then outputs a per-step correction. This preserves the
base model's competence while restoring closed-loop responsiveness. The
approach requires no retraining of the base policy and is orthogonal to
asynchronous execution schemes such as Real Time Chunking (RTC). On the dynamic
Kinetix task suite (12 tasks) and LIBERO Spatial, our method yields consistent
success rate improvements across increasing delays and execution horizons (+23%
point and +7% point respectively, compared to RTC), and also improves
robustness for long horizons even with zero injected delay. Since the
correction head is small and fast, there is minimal overhead compared to the
inference of large VLA models. These results indicate that A2C2 is an
effective, plug-in mechanism for deploying high-capacity chunking policies in
real-time control.

</details>


### [64] [Online Dynamic Goal Recognition in Gym Environments](https://arxiv.org/abs/2509.23244)
*Shamir Matan,Elhadad Osher,Nageris Ben,Mirsky Reuth*

Main category: cs.RO

TL;DR: 本文提出了两个开源框架gr-libs和gr-envs，以促进目标识别算法在标准化环境中的开发和比较。


<details>
  <summary>Details</summary>
Motivation: 目标识别领域在基准、领域和评估协议方面存在不一致，导致该领域发展碎片化。

Method: 提出了两个互补的开源框架gr-libs和gr-envs，以支持GR算法的开发、评估和比较。

Result: gr-libs包含MDP基础的GR基线的模块化实现、诊断工具和评估工具，gr-envs提供适用于动态和目标导向行为的环境与包装。

Conclusion: gr-libs和gr-envs为目标识别研究提供了一个标准化、可扩展和可重复的平台，促进了该领域的发展。

Abstract: Goal Recognition (GR) is the task of inferring an agent's intended goal from
partial observations of its behavior, typically in an online and one-shot
setting. Despite recent advances in model-free GR, particularly in applications
such as human-robot interaction, surveillance, and assistive systems, the field
remains fragmented due to inconsistencies in benchmarks, domains, and
evaluation protocols.
  To address this, we introduce gr-libs
(https://github.com/MatanShamir1/gr_libs) and gr-envs
(https://github.com/MatanShamir1/gr_envs), two complementary open-source
frameworks that support the development, evaluation, and comparison of GR
algorithms in Gym-compatible environments. gr-libs includes modular
implementations of MDP-based GR baselines, diagnostic tools, and evaluation
utilities. gr-envs provides a curated suite of environments adapted for dynamic
and goal-directed behavior, along with wrappers that ensure compatibility with
standard reinforcement learning toolkits. Together, these libraries offer a
standardized, extensible, and reproducible platform for advancing GR research.
Both packages are open-source and available on GitHub and PyPI.

</details>


### [65] [Preventing Robotic Jailbreaking via Multimodal Domain Adaptation](https://arxiv.org/abs/2509.23281)
*Francesco Marchiori,Rohan Sinha,Christopher Agia,Alexander Robey,George J. Pappas,Mauro Conti,Marco Pavone*

Main category: cs.RO

TL;DR: J-DAPT 是一种轻量级的多模态监测框架，通过整合文本和视觉嵌入及领域适应，显著提升了视觉语言模型(VLMs)在机器人环境中的监测能力，检测准确率接近 100%。


<details>
  <summary>Details</summary>
Motivation: 在机器人和其他安全关键环境中，现有的数据驱动防御方法如监狱突破分类器难以在缺乏专业数据集的领域中进行有效泛化。

Method: J-DAPT 采用多模态监测框架，通过基于注意力的融合和领域适应整合文本和视觉嵌入，捕捉语义意图和环境基础。

Result: J-DAPT 在自主驾驶、海洋机器人和四足导航等多个领域的评估中，检测准确率提升至接近 100%，且开销极小。

Conclusion: J-DAPT 提供了一种实用的防御机制，可以有效保护机器人应用中的视觉语言模型 (VLMs)，其检测准确率接近 100%。

Abstract: Large Language Models (LLMs) and Vision-Language Models (VLMs) are
increasingly deployed in robotic environments but remain vulnerable to
jailbreaking attacks that bypass safety mechanisms and drive unsafe or
physically harmful behaviors in the real world. Data-driven defenses such as
jailbreak classifiers show promise, yet they struggle to generalize in domains
where specialized datasets are scarce, limiting their effectiveness in robotics
and other safety-critical contexts. To address this gap, we introduce J-DAPT, a
lightweight framework for multimodal jailbreak detection through
attention-based fusion and domain adaptation. J-DAPT integrates textual and
visual embeddings to capture both semantic intent and environmental grounding,
while aligning general-purpose jailbreak datasets with domain-specific
reference data. Evaluations across autonomous driving, maritime robotics, and
quadruped navigation show that J-DAPT boosts detection accuracy to nearly 100%
with minimal overhead. These results demonstrate that J-DAPT provides a
practical defense for securing VLMs in robotic applications. Additional
materials are made available at: https://j-dapt.github.io.

</details>


### [66] [A Novel Narrow Region Detector for Sampling-Based Planners' Efficiency: Match Based Passage Identifier](https://arxiv.org/abs/2509.23288)
*Yafes Enes Şahiner,Esat Yusuf Gündoğdu,Volkan Sezer*

Main category: cs.RO

TL;DR: 本论文提出了一种新的确定性采样算法，通过占用网格地图识别狭窄通道，提高了采样效率，结果显示在多个环境下优于传统采样器。


<details>
  <summary>Details</summary>
Motivation: 随着自主技术的普及，路径规划在各种自主车辆操作中变得至关重要，而现有的概率方法在狭窄通道环境中存在共同的问题。

Method: 使用占用网格地图确定狭窄通道环境的新的采样算法，与基线方法进行对比。

Result: 在具体和随机仿真环境以及真实世界环境中的基准研究显示，该算法在规划时间和里程碑数量上表现更佳。

Conclusion: 本研究提出的算法在规划时间和里程碑数量上优于基线采样器，显示出在狭窄通道环境中的有效性。

Abstract: Autonomous technology, which has become widespread today, appears in many
different configurations such as mobile robots, manipulators, and drones. One
of the most important tasks of these vehicles during autonomous operations is
path planning. In the literature, path planners are generally divided into two
categories: probabilistic and deterministic methods. In the analysis of
probabilistic methods, the common problem of almost all methods is observed in
narrow passage environments. In this paper, a novel sampler is proposed that
deterministically identifies narrow passage environments using occupancy grid
maps and accordingly increases the amount of sampling in these regions. The
codes of the algorithm is provided as open source. To evaluate the performance
of the algorithm, benchmark studies are conducted in three distinct categories:
specific and random simulation environments, and a real-world environment. As a
result, it is observed that our algorithm provides higher performance in
planning time and number of milestones compared to the baseline samplers.

</details>


### [67] [Distributed Multi-Robot Multi-Target Simultaneous Search and Tracking in an Unknown Non-convex Environment](https://arxiv.org/abs/2509.23308)
*Jun Chen,Jiaqing Ma,Philip Dames*

Main category: cs.RO

TL;DR: 本文提出了一种新的运动规划算法框架，旨在提高在复杂环境中的探索和目标跟踪效率。


<details>
  <summary>Details</summary>
Motivation: 在未知非凸环境中，机器人队伍需要同时进行环境探索和目标跟踪，以实现高精度数据收集，解决这一挑战以推动环境监测和救援操作的应用。

Method: 整合前沿探索策略、基于Lloyd算法的覆盖策略以及传感器多目标追踪策略。

Result: 通过MATLAB仿真验证了算法的有效性，并优于标准方法。

Conclusion: 提出的运动规划算法在探索和目标追踪任务中表现出良好的有效性和优越性。

Abstract: In unknown non-convex environments, such as indoor and underground spaces,
deploying a fleet of robots to explore the surroundings while simultaneously
searching for and tracking targets of interest to maintain high-precision data
collection represents a fundamental challenge that urgently requires resolution
in applications such as environmental monitoring and rescue operations. Current
research has made significant progress in addressing environmental exploration,
information search, and target tracking problems, but has yet to establish a
framework for simultaneously optimizing these tasks in complex environments. In
this paper, we propose a novel motion planning algorithm framework that
integrates three control strategies: a frontier-based exploration strategy, a
guaranteed coverage strategy based on Lloyd's algorithm, and a sensor-based
multi-target tracking strategy. By incorporating these three strategies, the
proposed algorithm balances coverage search and high-precision active tracking
during exploration. Our approach is validated through a series of MATLAB
simulations, demonstrating validity and superiority over standard approaches.

</details>


### [68] [GUARD: Toward a Compromise between Traditional Control and Learning for Safe Robot Systems](https://arxiv.org/abs/2509.23312)
*Johannes A. Gaus,Junheon Yoon,Woo-Jeong Baek,Seungwon Choi,Suhan Park,Jaeheung Park*

Main category: cs.RO

TL;DR: 本文提出 GUARD 框架，结合传统控制和不确定性感知技术，通过实时主动学习实现安全的机器人避免碰撞，展示了高性能和广泛的未来应用需求。


<details>
  <summary>Details</summary>
Motivation: 在机器人技术中找到传统方法与学习算法之间的合理妥协，以促进安全、高效和灵活应用的发展。

Method: 将反应式模型预测轮廓控制（RMPCC）与迭代最近点（ICP）算法结合，通过实时能力的主动学习和概率核优化技术在线归因不确定性源。

Result: 实验研究表明，GUARD表现出高性能，突出了其未来应用的相关性和必要性。

Conclusion: GUARD 框架在机器人控制中结合了传统控制与不确定性感知技术，展示了高性能并强调了未来应用的广泛需求。

Abstract: This paper presents the framework \textbf{GUARD} (\textbf{G}uided robot
control via \textbf{U}ncertainty attribution and prob\textbf{A}bilistic kernel
optimization for \textbf{R}isk-aware \textbf{D}ecision making) that combines
traditional control with an uncertainty-aware perception technique using active
learning with real-time capability for safe robot collision avoidance. By doing
so, this manuscript addresses the central challenge in robotics of finding a
reasonable compromise between traditional methods and learning algorithms to
foster the development of safe, yet efficient and flexible applications. By
unifying a reactive model predictive countouring control (RMPCC) with an
Iterative Closest Point (ICP) algorithm that enables the attribution of
uncertainty sources online using active learning with real-time capability via
a probabilistic kernel optimization technique, \emph{GUARD} inherently handles
the existing ambiguity of the term \textit{safety} that exists in robotics
literature. Experimental studies indicate the high performance of \emph{GUARD},
thereby highlighting the relevance and need to broaden its applicability in
future.

</details>


### [69] [Space Robotics Bench: Robot Learning Beyond Earth](https://arxiv.org/abs/2509.23328)
*Andrej Orsula,Matthieu Geist,Miguel Olivares-Mendez,Carol Martinez*

Main category: cs.RO

TL;DR: 为促进太空机器人学习，提出了开源Space Robotics Bench模拟框架，提供多样化训练，建立性能基线，并识别当前方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 太空探索的增长需求对在极端条件下自主系统的开发提出了要求，但现有机器人学习受到技术成本和数据限制的制约。

Method: 采用开放式模拟框架，结合程序生成和并行模拟，支持多样化训练分布的创建。

Result: 通过标准强化学习算法建立性能基线，并展示在通用化、端到端学习、自适应控制和模拟到现实转移中的实验案例研究和见解。

Conclusion: Space Robotics Bench 是开发、基准测试和部署强大自主系统的重要资源。

Abstract: The growing ambition for space exploration demands robust autonomous systems
that can operate in unstructured environments under extreme extraterrestrial
conditions. The adoption of robot learning in this domain is severely hindered
by the prohibitive cost of technology demonstrations and the limited
availability of data. To bridge this gap, we introduce the Space Robotics
Bench, an open-source simulation framework for robot learning in space. It
offers a modular architecture that integrates on-demand procedural generation
with massively parallel simulation environments to support the creation of vast
and diverse training distributions for learning-based agents. To ground
research and enable direct comparison, the framework includes a comprehensive
suite of benchmark tasks that span a wide range of mission-relevant scenarios.
We establish performance baselines using standard reinforcement learning
algorithms and present a series of experimental case studies that investigate
key challenges in generalization, end-to-end learning, adaptive control, and
sim-to-real transfer. Our results reveal insights into the limitations of
current methods and demonstrate the utility of the framework in producing
policies capable of real-world operation. These contributions establish the
Space Robotics Bench as a valuable resource for developing, benchmarking, and
deploying the robust autonomous systems required for the final frontier.

</details>


### [70] [Robust Orientation Estimation with TRIAD-aided Manifold EKF](https://arxiv.org/abs/2509.23456)
*Arjun Sadananda,Ravi Banavar,Kavi Arya*

Main category: cs.RO

TL;DR: 本文将TRIAD算法引入Manifold EKF中，以降低磁力计在俯仰和滚动轴确定中的干扰，通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 针对磁力计在姿态确定中易受外部干扰和校准敏感性影响的问题。

Method: 结合TRIAD算法的子最优特征，通过Manifold EKF算法进行姿态确定。

Result: 实验结果验证了通过融合TRIAD算法来降低磁力计读数对姿态确定的影响。

Conclusion: 通过在大范围内应用Manifold EKF算法并结合TRIAD方法，可以有效改善姿态确定过程中磁力计对俯仰和滚动轴的影响。

Abstract: The manifold extended Kalman filter (Manifold EKF) has found extensive
application for attitude determination. Magnetometers employed as sensors for
such attitude determination are easily prone to disturbances by their
sensitivity to calibration and external magnetic fields. The TRIAD (Tri-Axial
Attitude Determination) algorithm is well known as a sub-optimal attitude
estimator. In this article, we incorporate this sub-optimal feature of the
TRIAD in mitigating the influence of the magnetometer reading in the pitch and
roll axis determination in the Manifold EKF algorithm. We substantiate our
results with experiments.

</details>


### [71] [Multi-Modal Manipulation via Multi-Modal Policy Consensus](https://arxiv.org/abs/2509.23468)
*Haonan Chen,Jiaming Xu,Hongyu Chen,Kaiwen Hong,Binghao Huang,Chaoqi Liu,Jiayuan Mao,Yunzhu Li,Yilun Du,Katherine Driggs-Campbell*

Main category: cs.RO

TL;DR: 本文提出了一种基于扩散模型和自适应路由网络的方法，显著提高了多模态机器人操作的效果和灵活性，尤其在应对接触复杂任务时。


<details>
  <summary>Details</summary>
Motivation: 在机器人操作中有效整合多种感知模态至关重要，但传统特征连接方法往往不够理想，尤其在接触丰富的任务中。

Method: 将策略因子化为多个扩散模型，每个模型专注于单一感知表示，并使用路由网络学习共识权重，以自适应地结合其贡献。

Result: 在模拟和现实任务中，我们的方法在多模态推理场景下显著超越了特征连接基线，并显示出对物理扰动和传感器损坏的鲁棒性。同时，重要性分析揭示了模态之间的自适应转变。

Conclusion: 该方法通过因子化策略和自适应路由网络，在多模态任务中显著优于传统的方法，增强了机器人操作的灵活性和鲁棒性。

Abstract: Effectively integrating diverse sensory modalities is crucial for robotic
manipulation. However, the typical approach of feature concatenation is often
suboptimal: dominant modalities such as vision can overwhelm sparse but
critical signals like touch in contact-rich tasks, and monolithic architectures
cannot flexibly incorporate new or missing modalities without retraining. Our
method factorizes the policy into a set of diffusion models, each specialized
for a single representation (e.g., vision or touch), and employs a router
network that learns consensus weights to adaptively combine their
contributions, enabling incremental of new representations. We evaluate our
approach on simulated manipulation tasks in {RLBench}, as well as real-world
tasks such as occluded object picking, in-hand spoon reorientation, and puzzle
insertion, where it significantly outperforms feature-concatenation baselines
on scenarios requiring multimodal reasoning. Our policy further demonstrates
robustness to physical perturbations and sensor corruption. We further conduct
perturbation-based importance analysis, which reveals adaptive shifts between
modalities.

</details>


### [72] [Ask, Reason, Assist: Decentralized Robot Collaboration via Language and Logic](https://arxiv.org/abs/2509.23506)
*Dan BW Choe,Sundhar Vinodh Sangeetha,Steven Emanuel,Chih-Yuan Chiu,Samuel Coogan,Shreyas Kousik*

Main category: cs.RO

TL;DR: 提出了一种去中心化的框架，使机器人能够有效请求和提供帮助，以处理团队中的冲突，实验结果显示该框架优于传统选择策略。


<details>
  <summary>Details</summary>
Motivation: 随着机器人在仓储等领域的增加部署，亟需解决异构机器人团队的协作问题，以应对意外冲突。

Method: 通过实验评估不同的助手选择策略，使用混合整数线性规划（MILP）解决问题。

Result: 考虑多种助手的报价可以使请求者最小化增加的完成时间，与选择最近可用的候选助手相比，性能显著提升。

Conclusion: 该框架显著优于传统启发式方法，并且在性能上接近于集中式"Oracle"基线，同时避免了重信息需求。

Abstract: Increased robot deployment, such as in warehousing, has revealed a need for
seamless collaboration among heterogeneous robot teams to resolve unforeseen
conflicts. To address this challenge, we propose a novel decentralized
framework that enables robots to request and provide help. The process begins
when a robot detects a conflict and uses a Large Language Model (LLM) to decide
whether external assistance is required. If so, it crafts and broadcasts a
natural language (NL) help request. Potential helper robots reason over the
request and respond with offers of assistance, including information about the
effect on their ongoing tasks. Helper reasoning is implemented via an LLM
grounded in Signal Temporal Logic (STL) using a Backus-Naur Form (BNF) grammar,
ensuring syntactically valid NL-to-STL translations, which are then solved as a
Mixed Integer Linear Program (MILP). Finally, the requester robot selects a
helper by reasoning over the expected increase in system-level total task
completion time. We evaluated our framework through experiments comparing
different helper-selection strategies and found that considering multiple
offers allows the requester to minimize added makespan. Our approach
significantly outperforms heuristics such as selecting the nearest available
candidate helper robot, and achieves performance comparable to a centralized
"Oracle" baseline but without heavy information demands.

</details>


### [73] [Zero-shot Whole-Body Manipulation with a Large-Scale Soft Robotic Torso via Guided Reinforcement Learning](https://arxiv.org/abs/2509.23556)
*Curtis C. Johnson,Carlo Alessi,Egidio Falotico,Marc D. Killpack*

Main category: cs.RO

TL;DR: 本研究探讨了软机器人在全身操作中的应用，提出了一种在MuJoCo中进行的高效仿真方法，成功实现了零-shot策略转移，并展示了该策略的反应能力。


<details>
  <summary>Details</summary>
Motivation: 探索机器人的全身操作能力，使其能够更有效地处理大型、沉重或笨重的物体，特别是软机器人在接触丰富的操作任务中的潜力。

Method: 在MuJoCo中进行的高达350倍真实时间的仿真，并进行了速度与准确性之间权衡的详细分析。

Result: 在Baloo硬件平台上成功实现了88%的成功率，学习到的策略表现出良好的反应能力，如重新抓握和扰动恢复。

Conclusion: 这项研究首次展示了通过零-shot策略转移实现强力的六自由度全身操作，使用两个连续软臂在大型平台（10千克负载）上进行操作。

Abstract: Whole-body manipulation is a powerful yet underexplored approach that enables
robots to interact with large, heavy, or awkward objects using more than just
their end-effectors. Soft robots, with their inherent passive compliance, are
particularly well-suited for such contact-rich manipulation tasks, but their
uncertainties in kinematics and dynamics pose significant challenges for
simulation and control. In this work, we address this challenge with a
simulation that can run up to 350x real time on a single thread in MuJoCo and
provide a detailed analysis of the critical tradeoffs between speed and
accuracy for this simulation. Using this framework, we demonstrate a successful
zero-shot sim-to-real transfer of a learned whole-body manipulation policy,
achieving an 88% success rate on the Baloo hardware platform. We show that
guiding RL with a simple motion primitive is critical to this success where
standard reward shaping methods struggled to produce a stable and successful
policy for whole-body manipulation. Furthermore, our analysis reveals that the
learned policy does not simply mimic the motion primitive. It exhibits
beneficial reactive behavior, such as re-grasping and perturbation recovery. We
analyze and contrast this learned policy against an open-loop baseline to show
that the policy can also exhibit aggressive over-corrections under
perturbation. To our knowledge, this is the first demonstration of forceful,
six-DoF whole-body manipulation using two continuum soft arms on a large-scale
platform (10 kg payloads), with zero-shot policy transfer.

</details>


### [74] [High Torque Density PCB Axial Flux Permanent Magnet Motor for Micro Robots](https://arxiv.org/abs/2509.23561)
*Jianren Wang,Jie Han,Abhinav Gupta,Deepak Pathak,Yang Zhang*

Main category: cs.RO

TL;DR: 本文介绍了一种新型微型轴向流动永磁电机，采用PCB绕组技术，实现高铜填充率，满足小型化和高扭矩需求。


<details>
  <summary>Details</summary>
Motivation: 随着准直接驱动(QDD)驱动技术的发展，迫切需要满足小直径且能够在低速下提供高扭矩的电机。

Method: 使用先进的IC基板高密度互连(HDI)技术制造电路板(PCB)绕组，形成48层定子，通过叠加四个12层HDI模块实现。

Result: 所提出的电机在5mm厚、19mm直径的封装中实现了记录的45%铜填充率，表现出优异的电磁和热性能。

Conclusion: 本文提出了一种微型轴向流动永磁电机，克服了传统绕组定子中铜填充不足的问题，并成功验证了其性能特征。

Abstract: Quasi-direct-drive (QDD) actuation is transforming legged and manipulator
robots by eliminating high-ratio gearboxes, yet it demands motors that deliver
very high torque at low speed within a thin, disc-shaped joint envelope.
Axial-flux permanent-magnet (AFPM) machines meet these geometric and torque
requirements, but scaling them below a 20mm outer diameter is hampered by poor
copper fill in conventional wound stators, inflating resistance and throttling
continuous torque. This paper introduces a micro-scale AFPM motor that
overcomes these limitations through printed-circuit-board (PCB) windings
fabricated with advanced IC-substrate high-density interconnect (HDI)
technology. The resulting 48-layer stator-formed by stacking four 12-layer HDI
modules-achieves a record 45\% copper fill in a package only 5mm thick and 19mm
in diameter. We perform comprehensive electromagnetic and thermal analyses to
inform the motor design, then fabricate a prototype whose performance
characteristics are experimentally verified.

</details>


### [75] [RAVEN: Resilient Aerial Navigation via Open-Set Semantic Memory and Behavior Adaptation](https://arxiv.org/abs/2509.23563)
*Seungchan Kim,Omar Alama,Dmytro Kurdydyk,John Keller,Nikhil Keetha,Wenshan Wang,Yonatan Bisk,Sebastian Scherer*

Main category: cs.RO

TL;DR: RAVEN是一种基于3D记忆的行为树框架，能够在结构复杂的户外环境中进行高效的语义导航，显著提高了目标搜索的成功率。


<details>
  <summary>Details</summary>
Motivation: 克服现有户外语义导航方法的局限性，提供灵活适应性和远程目标搜索能力。

Method: 使用基于3D记忆和行为树框架的RAVEN进行语义导航，通过空间一致的语义体素射线图实现长期规划，并结合短距离和长距离搜索方法。

Result: 在模拟环境中，RAVEN在100个语义任务中表现出85.25%的基线提升，并在真实世界测试中证明了其适用性。

Conclusion: RAVEN在户外环境中表现优异，展示了其实际应用潜力，显著提高了目标对象的导航性能。

Abstract: Aerial outdoor semantic navigation requires robots to explore large,
unstructured environments to locate target objects. Recent advances in semantic
navigation have demonstrated open-set object-goal navigation in indoor
settings, but these methods remain limited by constrained spatial ranges and
structured layouts, making them unsuitable for long-range outdoor search. While
outdoor semantic navigation approaches exist, they either rely on reactive
policies based on current observations, which tend to produce short-sighted
behaviors, or precompute scene graphs offline for navigation, limiting
adaptability to online deployment. We present RAVEN, a 3D memory-based,
behavior tree framework for aerial semantic navigation in unstructured outdoor
environments. It (1) uses a spatially consistent semantic voxel-ray map as
persistent memory, enabling long-horizon planning and avoiding purely reactive
behaviors, (2) combines short-range voxel search and long-range ray search to
scale to large environments, (3) leverages a large vision-language model to
suggest auxiliary cues, mitigating sparsity of outdoor targets. These
components are coordinated by a behavior tree, which adaptively switches
behaviors for robust operation. We evaluate RAVEN in 10 photorealistic outdoor
simulation environments over 100 semantic tasks, encompassing single-object
search, multi-class, multi-instance navigation and sequential task changes.
Results show RAVEN outperforms baselines by 85.25% in simulation and
demonstrate its real-world applicability through deployment on an aerial robot
in outdoor field tests.

</details>


### [76] [GES-UniGrasp: A Two-Stage Dexterous Grasping Strategy With Geometry-Based Expert Selection](https://arxiv.org/abs/2509.23567)
*Fangting Xu,Jilin Zhu,Xiaoming Gu,Jianzhong Tang*

Main category: cs.RO

TL;DR: 本研究提出了ContactGrasp数据集和几何专家选择框架，显著提升了机器人抓取策略的自然性和成功率。


<details>
  <summary>Details</summary>
Motivation: 提高机器人在复杂环境中对各种物体进行自然和灵活抓取的能力，尤其是在人类动作模仿方面。

Method: 通过建立ContactGrasp数据集以及几何基础的专家选择框架，利用形状对物体进行聚类并选择专门的抓取专家。

Result: 在训练和测试集上，本方法实现了99.4%和96.3%的抓取成功率，显示出强大的泛化能力和抓取执行质量。

Conclusion: 本研究的ContactGrasp数据集及其基于几何的专家选择框架显著提高了机器人对多样化物体的自然抓取能力和成功率，展现了优异的泛化能力和高质量的抓取执行。

Abstract: Robust and human-like dexterous grasping of general objects is a critical
capability for advancing intelligent robotic manipulation in real-world
scenarios. However, existing reinforcement learning methods guided by grasp
priors often result in unnatural behaviors. In this work, we present
\textit{ContactGrasp}, a robotic dexterous pre-grasp and grasp dataset that
explicitly accounts for task-relevant wrist orientation and thumb-index
pinching coordination. The dataset covers 773 objects in 82 categories,
providing a rich foundation for training human-like grasp strategies. Building
upon this dataset, we perform geometry-based clustering to group objects by
shape, enabling a two-stage Geometry-based Expert Selection (GES) framework
that selects among specialized experts for grasping diverse object geometries,
thereby enhancing adaptability to diverse shapes and generalization across
categories. Our approach demonstrates natural grasp postures and achieves high
success rates of 99.4\% and 96.3\% on the train and test sets, respectively,
showcasing strong generalization and high-quality grasp execution.

</details>


### [77] [Generalizable Coarse-to-Fine Robot Manipulation via Language-Aligned 3D Keypoints](https://arxiv.org/abs/2509.23575)
*Jianshu Hu,Lidi Wang,Shujia Li,Yunpeng Jiang,Xiao Li,Paul Weng,Yutong Ban*

Main category: cs.RO

TL;DR: 提出一种新的分层政策框架CLAP，通过任务分解和VLM微调，提高了对3D操作的泛化能力，实验显示优于当前方法。


<details>
  <summary>Details</summary>
Motivation: 现有的分层政策在通用性方面仍存在困难，因此需要一种新的方法来提高对新指令和环境变动的泛化能力。

Method: 提出了三组成分的框架：1) 任务分解，2) 针对3D关键点预测的VLM微调，3) 3D感知表示。

Result: 我们的框架在模拟和真实机器人实验中表现优越，在GemBench上比最先进的方法提升了12%的成功率，并仅需1/5的训练轨迹。

Conclusion: 我们的方法在GemBench基准测试中超越了现有的最先进方法，并在真实环境中展示了优越的泛化能力。

Abstract: Hierarchical coarse-to-fine policy, where a coarse branch predicts a region
of interest to guide a fine-grained action predictor, has demonstrated
significant potential in robotic 3D manipulation tasks by especially enhancing
sample efficiency and enabling more precise manipulation. However, even
augmented with pre-trained models, these hierarchical policies still suffer
from generalization issues. To enhance generalization to novel instructions and
environment variations, we propose Coarse-to-fine Language-Aligned manipulation
Policy (CLAP), a framework that integrates three key components: 1) task
decomposition, 2) VLM fine-tuning for 3D keypoint prediction, and 3) 3D-aware
representation. Through comprehensive experiments in simulation and on a real
robot, we demonstrate its superior generalization capability. Specifically, on
GemBench, a benchmark designed for evaluating generalization, our approach
achieves a 12\% higher average success rate than the SOTA method while using
only 1/5 of the training trajectories. In real-world experiments, our policy,
trained on only 10 demonstrations, successfully generalizes to novel
instructions and environments.

</details>


### [78] [Encoding Material Safety using Control Barrier Functions for Soft Actuator Control](https://arxiv.org/abs/2509.23623)
*Nicholas Pagliocca,Behrad Koohbor,Mitja Trkov*

Main category: cs.RO

TL;DR: 本文提出了一种软机器人材料安全的正式定义及控制器，并通过高阶控制障碍函数保障材料安全性，仿真证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 随着软机器人领域向反馈控制和实际应用的发展，明确安全性定义及其潜在风险变得日益重要。

Method: 使用高阶控制障碍函数与基于二次规划的反馈控制，通过对不可压缩超弹性材料的安全和不安全集合进行特征化来设计控制器。

Result: 通过对有惯性效应、一级粘性效应和全状态反馈的加压超弹性管的案例研究，仿真结果验证了所提方法能够执行材料安全规范。

Conclusion: 该研究提出了一种基于应变能函数的材料安全性正式定义，并展示了一种使用高阶控制障碍函数的控制器，从而保证软机器人在操作过程中的安全性。

Abstract: Until recently, the concept of soft robot safety was an informal notion,
often attributed solely to the fact that soft robots are less likely to damage
their operating environment than rigid robots. As the field moves toward
feedback control for practical applications, it becomes increasingly important
to define what safety means and to characterize how soft robots can become
unsafe. The unifying theme of soft robotics is to achieve useful functionality
through deformation. Consequently, limitations in constitutive model accuracy
and risks of material failure are inherent to all soft robots and pose a key
challenge in designing provably safe controllers. This work introduces a formal
definition of material safety based on strain energy functions and provides a
controller that enforces it. We characterize safe and unsafe sets of an
incompressible hyperelastic material and demonstrate that safety can be
enforced using a high-order control barrier function (HOCBF) with quadratic
program-based feedback control. As a case study, we consider a pressurized
hyperelastic tube with inertial effects, first-order viscous effects, and
full-state feedback. Simulation results verify that the proposed methodology
can enforce the material safety specification.

</details>


### [79] [KiVi: Kinesthetic-Visuospatial Integration for Dynamic and Safe Egocentric Legged Locomotion](https://arxiv.org/abs/2509.23650)
*Peizhuo Li,Hongyi Li,Yuxuan Ma,Linnan Chang,Xinrong Yang,Ruiqi Yu,Yifeng Zhang,Yuhong Cao,Qiuguo Zhu,Guillaume Sartoretti*

Main category: cs.RO

TL;DR: 本研究提出的KiVi框架通过结合运动感知与视觉感知，提高了四足机器人的地形适应能力，尤其在不稳定的视觉环境中表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前视觉信息的不稳定性（如遮挡、反射和光照变化）限制了四足机器人的运动能力，因此需要一种可以增强机器人在复杂环境中稳定性的系统。

Method: 提出的KiVi框架结合了运动感知和视觉感知，分别利用本体觉提供稳定性并巧妙地整合视觉信息以增强地形感知和障碍物避让。

Result: 通过大量实验，验证了KiVi框架在多样化地形上稳定行驶的能力，并在未曾训练过的视觉噪声和遮挡下依然表现出良好的可靠性。

Conclusion: KiVi框架使四足机器人能够稳健地在复杂地形上行走，适应现实环境中的视觉噪声和遮挡，展示了其在实际四足运动中的有效性和适用性。

Abstract: Vision-based locomotion has shown great promise in enabling legged robots to
perceive and adapt to complex environments. However, visual information is
inherently fragile, being vulnerable to occlusions, reflections, and lighting
changes, which often cause instability in locomotion. Inspired by animal
sensorimotor integration, we propose KiVi, a Kinesthetic-Visuospatial
integration framework, where kinesthetics encodes proprioceptive sensing of
body motion and visuospatial reasoning captures visual perception of
surrounding terrain. Specifically, KiVi separates these pathways, leveraging
proprioception as a stable backbone while selectively incorporating vision for
terrain awareness and obstacle avoidance. This modality-balanced, yet
integrative design, combined with memory-enhanced attention, allows the robot
to robustly interpret visual cues while maintaining fallback stability through
proprioception. Extensive experiments show that our method enables quadruped
robots to stably traverse diverse terrains and operate reliably in unstructured
outdoor environments, remaining robust to out-of-distribution (OOD) visual
noise and occlusion unseen during training, thereby highlighting its
effectiveness and applicability to real-world legged locomotion.

</details>


### [80] [HeLoM: Hierarchical Learning for Whole-Body Loco-Manipulation in Hexapod Robot](https://arxiv.org/abs/2509.23651)
*Xinrong Yang,Peizhuo Li,Hongyi Li,Junkai Lu,Linnan Chang,Yuhong Cao,Yifeng Zhang,Ge Sun,Guillaume Sartoretti*

Main category: cs.RO

TL;DR: 本研究提出HeLoM框架，通过多肢体协调控制，实现在真实环境中高效、稳定地推动重物，克服了抓取难题。


<details>
  <summary>Details</summary>
Motivation: 在现实环境中，机器人需要处理与自身重量相当的物体，推动是一种更高效的非抓取操控策略，然而，处理重物和不规则物体时需要克服多种挑战，尤其是保持稳定性。

Method: 提出了一种基于学习的层次化全身操控框架，用于六足机器人，利用多肢体协调控制实现推送操作。

Result: 框架在仿真和真实世界实验中验证了其有效性，能够稳定推动不同大小的物体到指定目标位置。

Conclusion: HeLoM框架能够在真实环境中稳定地推动不同大小和未知物理属性的物体。

Abstract: Robots in real-world environments are often required to move/manipulate
objects comparable in weight to their own bodies. Compared to grasping and
carrying, pushing provides a more straightforward and efficient non-prehensile
manipulation strategy, avoiding complex grasp design while leveraging direct
contact to regulate an object's pose. Achieving effective pushing, however,
demands both sufficient manipulation forces and the ability to maintain
stability, which is particularly challenging when dealing with heavy or
irregular objects. To address these challenges, we propose HeLoM, a
learning-based hierarchical whole-body manipulation framework for a hexapod
robot that exploits coordinated multi-limb control. Inspired by the cooperative
strategies of multi-legged insects, our framework leverages redundant contact
points and high degrees of freedom to enable dynamic redistribution of contact
forces. HeLoM's high-level planner plans pushing behaviors and target object
poses, while its low-level controller maintains locomotion stability and
generates dynamically consistent joint actions. Our policies trained in
simulation are directly deployed on real robots without additional fine-tuning.
This design allows the robot to maintain balance while exerting continuous and
controllable pushing forces through coordinated foreleg interaction and
supportive hind-leg propulsion. We validate the effectiveness of HeLoM through
both simulation and real-world experiments. Results show that our framework can
stably push boxes of varying sizes and unknown physical properties to
designated goal poses in the real world.

</details>


### [81] [Focusing on What Matters: Object-Agent-centric Tokenization for Vision Language Action models](https://arxiv.org/abs/2509.23655)
*Rokas Bendikas,Daniel Dijkman,Markus Peschl,Sanjay Haresh,Pietro Mazzaglia*

Main category: cs.RO

TL;DR: 本研究提出Oat-VLA，一种新型token化方案，有效提升机器人操控中的视觉语言模型训练效率，减少计算成本。


<details>
  <summary>Details</summary>
Motivation: 因现有的视觉语言模型在机器人领域的训练效率低下，特别是由于视觉输入的tokenization方案导致的计算成本高。

Method: 提出Oat-VLA，一种面向对象代理的token化方法，以加速视觉语言行动模型的训练。

Result: Oat-VLA在LIBERO测试套件上的收敛速度至少是OpenVLA的两倍，并在不同的实际抓取和放置任务中表现优于OpenVLA。

Conclusion: Oat-VLA方法显著提高了视觉语言行动模型的训练效率，减少了视觉token的数量，同时保持了性能。

Abstract: Vision-Language-Action (VLA) models offer a pivotal approach to learning
robotic manipulation at scale by repurposing large pre-trained
Vision-Language-Models (VLM) to output robotic actions. However, adapting VLMs
for robotic domains comes with an unnecessarily high computational cost, which
we attribute to the tokenization scheme of visual inputs. In this work, we aim
to enable efficient VLA training by proposing Oat-VLA, an Object-Agent-centric
Tokenization for VLAs. Building on the insights of object-centric
representation learning, our method introduces an inductive bias towards scene
objects and the agent's own visual information. As a result, we find that
Oat-VLA can drastically reduce the number of visual tokens to just a few tokens
without sacrificing performance. We reveal that Oat-VLA converges at least
twice as fast as OpenVLA on the LIBERO suite, as well as outperform OpenVLA in
diverse real-world pick and place tasks.

</details>


### [82] [Certifiably Optimal State Estimation and Robot Calibration Using Trace-Constrained SDP](https://arxiv.org/abs/2509.23656)
*Liangting Wu,Roberto Tron*

Main category: cs.RO

TL;DR: 本研究提出一种基于trace-constrained SDP的优化方法，能有效处理机器人非凸问题并在多个任务中获得全局最优解决方案。


<details>
  <summary>Details</summary>
Motivation: 解决机器人领域中的非凸优化问题，提高求解的全局最优性和实用性。

Method: 采用trace-constrained SDP框架，通过引入固定迹的正半定矩阵和梯度优化程序进行求解。

Result: 通过对固定迹SDP的应用，成功完成PnP估计、手眼标定和双机器人系统标定等任务，并证明了方法的有效性和广泛适用性。

Conclusion: 通过引入定制固定迹变量和约束，结合梯度优化程序，在trace-constrained SDP框架中有效处理和优化机器人非凸问题，展现了其在多个机器人任务中的应用潜力。

Abstract: Many nonconvex problems in robotics can be relaxed into convex formulations
via semidefinite programming (SDP), which offers the advantage of global
optimality. The practical quality of these solutions, however, critically
depends on achieving rank-1 matrices, a condition that typically requires
additional tightening. In this work, we focus on trace-constrained SDPs, where
the decision variables are positive semidefinite (PSD) matrices with fixed
trace values. These additional constraints not only capture important
structural properties but also facilitate first-order methods for recovering
rank-1 solutions. We introduce customized fixed-trace variables and constraints
to represent common robotic quantities such as rotations and translations,
which can be exactly recovered when the corresponding variables are rank-1. To
further improve practical performance, we develop a gradient-based refinement
procedure that projects relaxed SDP solutions toward rank-1, low-cost
candidates, which can then be certified for global optimality via the dual
problem. We demonstrate that many robotics tasks can be expressed within this
trace-constrained SDP framework, and showcase its effectiveness through
simulations in perspective-n-point (PnP) estimation, hand-eye calibration, and
dual-robot system calibration. To support broader use, we also introduce a
modular ``virtual robot'' abstraction that simplifies modeling across different
problem settings.

</details>


### [83] [MDCPP: Multi-robot Dynamic Coverage Path Planning for Workload Adaptation](https://arxiv.org/abs/2509.23705)
*Jun Chen,Mingjia Chen,Shinkyu Park*

Main category: cs.RO

TL;DR: 提出了一种新的多机器人动态覆盖路径规划算法（MDCPP），解决了负荷不均和完成时间过长的问题，通过动态工作量评估和Voronoi图优化覆盖区域，取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统的多机器人覆盖路径规划方法假设机器人以固定速度移动，这在实际应用中并不现实，导致工作负荷分配不均和完成时间增加。

Method: 使用高斯混合模型近似目标分布，并利用容量约束Voronoi图进行覆盖区域分配。

Result: MDCPP在仿真中表现出优越性，相较于现有的扫掠算法实现了质量上的改善和性能上的提升。

Conclusion: MDCPP算法在动态估计机器人剩余工作量和区域分配方面具有优越性，且在覆盖效率上受通信范围的显著影响。

Abstract: Multi-robot Coverage Path Planning (MCPP) addresses the problem of computing
paths for multiple robots to effectively cover a large area of interest.
Conventional approaches to MCPP typically assume that robots move at fixed
velocities, which is often unrealistic in real-world applications where robots
must adapt their speeds based on the specific coverage tasks assigned to
them.Consequently, conventional approaches often lead to imbalanced workload
distribution among robots and increased completion time for coverage tasks. To
address this, we introduce a novel Multi-robot Dynamic Coverage Path Planning
(MDCPP) algorithm for complete coverage in two-dimensional environments. MDCPP
dynamically estimates each robot's remaining workload by approximating the
target distribution with Gaussian mixture models, and assigns coverage regions
using a capacity-constrained Voronoi diagram. We further develop a distributed
implementation of MDCPP for range-constrained robotic networks. Simulation
results validate the efficacy of MDCPP, showing qualitative improvements and
superior performance compared to an existing sweeping algorithm, and a
quantifiable impact of communication range on coverage efficiency.

</details>


### [84] [DA-MMP: Learning Coordinated and Accurate Throwing with Dynamics-Aware Motion Manifold Primitives](https://arxiv.org/abs/2509.23721)
*Chi Chu,Huazhe Xu*

Main category: cs.RO

TL;DR: 该论文提出了一个新的动态操控运动生成框架，显著改善了在环形投掷任务中的操控表现，超越了一般人类专家。


<details>
  <summary>Details</summary>
Motivation: 现有方法多依赖手动设计的动作参数化，限制了在复杂任务中产生高度协调动作的能力。

Method: 提出了动态感知运动流形基元（DA-MMP），利用条件流匹配模型在潜在空间中进行训练，从大量规划运动的数据集中学习高质量流形。

Result: 该方法在真实世界的环形投掷任务中展示了高成功率，并且能够普遍适应超出训练范围的新目标。

Conclusion: 该方法有效生成了协调和平滑的投掷轨迹，并在实际测试中表现出高成功率，超越训练有素的人类专家。

Abstract: Dynamic manipulation is a key capability for advancing robot performance,
enabling skills such as tossing. While recent learning-based approaches have
pushed the field forward, most methods still rely on manually designed action
parameterizations, limiting their ability to produce the highly coordinated
motions required in complex tasks. Motion planning can generate feasible
trajectories, but the dynamics gap-stemming from control inaccuracies, contact
uncertainties, and aerodynamic effects-often causes large deviations between
planned and executed trajectories. In this work, we propose Dynamics-Aware
Motion Manifold Primitives (DA-MMP), a motion generation framework for
goal-conditioned dynamic manipulation, and instantiate it on a challenging
real-world ring-tossing task. Our approach extends motion manifold primitives
to variable-length trajectories through a compact parametrization and learns a
high-quality manifold from a large-scale dataset of planned motions. Building
on this manifold, a conditional flow matching model is trained in the latent
space with a small set of real-world trials, enabling the generation of
throwing trajectories that account for execution dynamics. Experiments show
that our method can generate coordinated and smooth motion trajectories for the
ring-tossing task. In real-world evaluations, it achieves high success rates
and even surpasses the performance of trained human experts. Moreover, it
generalizes to novel targets beyond the training range, indicating that it
successfully learns the underlying trajectory-dynamics mapping.

</details>


### [85] [LocoFormer: Generalist Locomotion via Long-context Adaptation](https://arxiv.org/abs/2509.23745)
*Min Liu,Deepak Pathak,Ananye Agarwal*

Main category: cs.RO

TL;DR: LocoFormer是一个通用的运动控制模型，能自动适应不同的机器人类型和结构，表现出在多种情况下的强大控制能力，展示了在未来机器人技能发展的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有的运动控制器需要手动调优，LocoFormer旨在克服这一局限性，成为一种通用的运动模型，以适应不同类型的机器人。

Method: 使用大规模的强化学习，在程序生成的机器人上进行训练，并采用激进的领域随机化，同时扩展上下文长度以跨越整个实验阶段。

Result: LocoFormer实现了对不同机器人稳定的控制，即使在重量变化和电机故障等大扰动情况下，也表现出强大的适应能力，能够从早期的摔倒中学习以改善后续的控制策略。

Conclusion: LocoFormer是一种通用的全身运动模型，能够在不精确了解机器人运动学的情况下控制多种类型的机器人，并能够适应这些机器人在测试时的形态和动力学变化。

Abstract: Modern locomotion controllers are manually tuned for specific embodiments. We
present LocoFormer, a generalist omni-bodied locomotion model that can control
previously unseen legged and wheeled robots, even without precise knowledge of
their kinematics. LocoFormer is able to adapt to changes in morphology and
dynamics at test time. We find that two key choices enable adaptation. First,
we train massive scale RL on procedurally generated robots with aggressive
domain randomization. Second, in contrast to previous policies that are myopic
with short context lengths, we extend context by orders of magnitude to span
episode boundaries. We deploy the same LocoFormer to varied robots and show
robust control even with large disturbances such as weight change and motor
failures. In extreme scenarios, we see emergent adaptation across episodes,
LocoFormer learns from falls in early episodes to improve control strategies in
later ones. We believe that this simple, yet general recipe can be used to
train foundation models for other robotic skills in the future. Videos at
generalist-locomotion.github.io.

</details>


### [86] [Sequence Pathfinder for Multi-Agent Pickup and Delivery in the Warehouse](https://arxiv.org/abs/2509.23778)
*Zeyuan Zhang,Chaoran Li,Shao Zhang,Ying Wen*

Main category: cs.RO

TL;DR: 本研究提出了一个基于Transformer的Sequential Pathfinder (SePar)，在MAPD任务中实现了性能提升与计算复杂性的显著降低。


<details>
  <summary>Details</summary>
Motivation: 学习方法在狭窄通道和长走廊的仓库环境中表现不佳，因此需要一种能够减少计算复杂性的决策方法。

Method: 将MAPF形式化为序列建模问题，并提出用Transformer实现隐式信息交换的Sequential Pathfinder (SePar)。

Result: SePar减少了决策复杂性，从指数降低到线性，且在实验中证明了其优越性能和全球意识的保持。

Conclusion: SePar在多种MAPF任务及其变体中表现优于现有学习方法，并且在复杂环境中具有良好的泛化能力。

Abstract: Multi-Agent Pickup and Delivery (MAPD) is a challenging extension of
Multi-Agent Path Finding (MAPF), where agents are required to sequentially
complete tasks with fixed-location pickup and delivery demands. Although
learning-based methods have made progress in MAPD, they often perform poorly in
warehouse-like environments with narrow pathways and long corridors when
relying only on local observations for distributed decision-making.
Communication learning can alleviate the lack of global information but
introduce high computational complexity due to point-to-point communication. To
address this challenge, we formulate MAPF as a sequence modeling problem and
prove that path-finding policies under sequence modeling possess
order-invariant optimality, ensuring its effectiveness in MAPD. Building on
this, we propose the Sequential Pathfinder (SePar), which leverages the
Transformer paradigm to achieve implicit information exchange, reducing
decision-making complexity from exponential to linear while maintaining
efficiency and global awareness. Experiments demonstrate that SePar
consistently outperforms existing learning-based methods across various MAPF
tasks and their variants, and generalizes well to unseen environments.
Furthermore, we highlight the necessity of integrating imitation learning in
complex maps like warehouses.

</details>


### [87] [High-Precision Climbing Robot Localization Using Planar Array UWB/GPS/IMU/Barometer Integration](https://arxiv.org/abs/2509.23801)
*Shuning Zhang,Renjing Xu,Zhanchen Zhu,Xiangyu Chen,Yunheng Wang,Xu Jiang,Peibo Duan*

Main category: cs.RO

TL;DR: 本研究提出了一种多传感器融合系统，显著提高了攀爬机器人的定位精度和鲁棒性，成功解决了GPS遮挡和UWB非视距问题。


<details>
  <summary>Details</summary>
Motivation: 为了应对复杂高海拔环境中攀爬机器人需要高精度定位的挑战。

Method: 提出了一种基于注意力机制的多传感器融合系统，结合UWB、GPS、IMU和气压计，采用端到端神经网络推理模型和无迹卡尔曼滤波器（UKF）精细化轨迹。

Result: 实验结果表明该方法实现了0.48米的定位精度，最大误差为1.50米，超过了现有基线算法。

Conclusion: 该方法在实际实验中显示出0.48米的定位精度和更低的最大误差，超越了GPS/INS-EKF等基线算法，展现出更强的鲁棒性。

Abstract: To address the need for high-precision localization of climbing robots in
complex high-altitude environments, this paper proposes a multi-sensor fusion
system that overcomes the limitations of single-sensor approaches. Firstly, the
localization scenarios and the problem model are analyzed. An integrated
architecture of Attention Mechanism-based Fusion Algorithm (AMFA) incorporating
planar array Ultra-Wideband (UWB), GPS, Inertial Measurement Unit (IMU), and
barometer is designed to handle challenges such as GPS occlusion and UWB
Non-Line-of-Sight (NLOS) problem. Then, End-to-end neural network inference
models for UWB and barometer are developed, along with a multimodal attention
mechanism for adaptive data fusion. An Unscented Kalman Filter (UKF) is applied
to refine the trajectory, improving accuracy and robustness. Finally,
real-world experiments show that the method achieves 0.48 m localization
accuracy and lower MAX error of 1.50 m, outperforming baseline algorithms such
as GPS/INS-EKF and demonstrating stronger robustness.

</details>


### [88] [Fostering Robots: A Governance-First Conceptual Framework for Domestic, Curriculum-Based Trajectory Collection](https://arxiv.org/abs/2509.23821)
*Federico Pablo-Marti,Carlos Mir Fernandez*

Main category: cs.RO

TL;DR: 提出了一个用于家庭机器人部署的治理优先框架，着重于长期交互轨迹及其质量评估。


<details>
  <summary>Details</summary>
Motivation: 强调以课程驱动和治理优先的方法来促进家庭机器人在家庭中的应用。

Method: 通过量化指标和评估协议来形式化轨迹质量，并与欧盟标准对齐。

Result: 制定了一个低资源的实证路线图，以支持未来试点研究的严格验证。

Conclusion: 提出了一种概念性、可实证测试的框架，以指导家庭机器人部署的长期交互轨迹。

Abstract: We propose a conceptual, empirically testable framework for Robot Fostering,
-a curriculum-driven, governance-first approach to domestic robot deployments,
emphasizing long-term, curated interaction trajectories. We formalize
trajectory quality with quantifiable metrics and evaluation protocols aligned
with EU-grade governance standards, delineating a low-resource empirical
roadmap to enable rigorous validation through future pilot studies.

</details>


### [89] [Control Your Robot: A Unified System for Robot Control and Policy Deployment](https://arxiv.org/abs/2509.23823)
*Tian Nian,Weijie Ke,Yao Mu,Tianxing Chen,Shaolong Zhu,Bingshan Hu*

Main category: cs.RO

TL;DR: 提出了一种统一的模块化框架Control Your Robot，解决了跨平台机器人控制的碎片化问题，支持灵活的控制模式和高效的数据收集，促进了可扩展的机器人学习。


<details>
  <summary>Details</summary>
Motivation: 解决硬件接口、数据格式和控制范式的差异，以减少工具链的碎片化，加快部署速度。

Method: 通过模块化设计、统一API和闭环架构，简化了数据收集和策略实施。

Result: 在单臂和双臂系统上的实验显示高效、低延迟的数据收集和有效的策略学习支持，训练出的策略与专家演示相匹配。

Conclusion: 该框架支持跨平台的机器人学习，并实现了缩放和可重现性。

Abstract: Cross-platform robot control remains difficult because hardware interfaces,
data formats, and control paradigms vary widely, which fragments toolchains and
slows deployment. To address this, we present Control Your Robot, a modular,
general-purpose framework that unifies data collection and policy deployment
across diverse platforms. The system reduces fragmentation through a
standardized workflow with modular design, unified APIs, and a closed-loop
architecture. It supports flexible robot registration, dual-mode control with
teleoperation and trajectory playback, and seamless integration from multimodal
data acquisition to inference. Experiments on single-arm and dual-arm systems
show efficient, low-latency data collection and effective support for policy
learning with imitation learning and vision-language-action models. Policies
trained on data gathered by Control Your Robot match expert demonstrations
closely, indicating that the framework enables scalable and reproducible robot
learning across platforms.

</details>


### [90] [DexFlyWheel: A Scalable and Self-improving Data Generation Framework for Dexterous Manipulation](https://arxiv.org/abs/2509.23829)
*Kefei Zhu,Fengshuo Bai,YuanHao Xiang,Yishuai Cai,Xinglin Chen,Ruochong Li,Xingtao Wang,Hao Dong,Yaodong Yang,Xiaopeng Fan,Yuanpei Chen*

Main category: cs.RO

TL;DR: DexFlyWheel是一个数据生成框架，利用自我改进循环解决了现有数据收集的不足，生成了多样化的数据集并提升了机器人任务的成功率。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有数据收集方法的局限性，DexFlyWheel旨在创建一个高效且多样化的数据生成框架，为机器人的灵活操作提供支撑。

Method: DexFlyWheel采用自我改进循环，通过模仿学习、残差强化学习、轨迹收集和数据增强等方法来生成和增强数据。

Result: DexFlyWheel生成了2,000多个多样化的演示，政策在挑战测试集上的成功率达81.9%，并在真实世界的双臂提举任务中实现了78.3%的成功率。

Conclusion: DexFlyWheel框架有效地生成了多样化的数据集，使机器人在复杂任务中的表现得到了显著提升。

Abstract: Dexterous manipulation is critical for advancing robot capabilities in
real-world applications, yet diverse and high-quality datasets remain scarce.
Existing data collection methods either rely on human teleoperation or require
significant human engineering, or generate data with limited diversity, which
restricts their scalability and generalization. In this paper, we introduce
DexFlyWheel, a scalable data generation framework that employs a self-improving
cycle to continuously enrich data diversity. Starting from efficient seed
demonstrations warmup, DexFlyWheel expands the dataset through iterative
cycles. Each cycle follows a closed-loop pipeline that integrates Imitation
Learning (IL), residual Reinforcement Learning (RL), rollout trajectory
collection, and data augmentation. Specifically, IL extracts human-like
behaviors from demonstrations, and residual RL enhances policy generalization.
The learned policy is then used to generate trajectories in simulation, which
are further augmented across diverse environments and spatial configurations
before being fed back into the next cycle. Over successive iterations, a
self-improving data flywheel effect emerges, producing datasets that cover
diverse scenarios and thereby scaling policy performance. Experimental results
demonstrate that DexFlyWheel generates over 2,000 diverse demonstrations across
four challenging tasks. Policies trained on our dataset achieve an average
success rate of 81.9\% on the challenge test sets and successfully transfer to
the real world through digital twin, achieving a 78.3\% success rate on
dual-arm lift tasks.

</details>


### [91] [MAD-PINN: A Decentralized Physics-Informed Machine Learning Framework for Safe and Optimal Multi-Agent Control](https://arxiv.org/abs/2509.23960)
*Manan Tayal,Aditya Singh,Shishir Kolathaya,Somil Bansal*

Main category: cs.RO

TL;DR: 提出MAD-PINN框架，通过物理知识增强的机器学习方法，在多智能体系统中实现安全性和性能的优化，同时具备可扩展性。


<details>
  <summary>Details</summary>
Motivation: 为了解决当前多智能体系统中安全性与性能之间的优化问题，现有方法面临严格安全保证缺失、保守性或扩展性不足的挑战。

Method: 提出MAD-PINN框架，通过物理知识增强的神经网络解决多智能体状态约束的最优控制问题，并采用再生视野策略执行计划，增强安全性和效率。

Result: MAD-PINN在实验中表现出比现有最先进技术更好的安全性与性能折衷，并在智能体数量增加时有效维护可扩展性。

Conclusion: MAD-PINN在多智能体导航任务中实现了更优的安全性与性能折衷，且在智能体数量增加时保持了可扩展性

Abstract: Co-optimizing safety and performance in large-scale multi-agent systems
remains a fundamental challenge. Existing approaches based on multi-agent
reinforcement learning (MARL), safety filtering, or Model Predictive Control
(MPC) either lack strict safety guarantees, suffer from conservatism, or fail
to scale effectively. We propose MAD-PINN, a decentralized physics-informed
machine learning framework for solving the multi-agent state-constrained
optimal control problem (MASC-OCP). Our method leverages an epigraph-based
reformulation of SC-OCP to simultaneously capture performance and safety, and
approximates its solution via a physics-informed neural network. Scalability is
achieved by training the SC-OCP value function on reduced-agent systems and
deploying them in a decentralized fashion, where each agent relies only on
local observations of its neighbours for decision-making. To further enhance
safety and efficiency, we introduce an Hamilton-Jacobi (HJ) reachability-based
neighbour selection strategy to prioritize safety-critical interactions, and a
receding-horizon policy execution scheme that adapts to dynamic interactions
while reducing computational burden. Experiments on multi-agent navigation
tasks demonstrate that MAD-PINN achieves superior safety-performance
trade-offs, maintains scalability as the number of agents grows, and
consistently outperforms state-of-the-art baselines.

</details>


### [92] [Prepare for Warp Speed: Sub-millisecond Visual Place Recognition Using Event Cameras](https://arxiv.org/abs/2509.24094)
*Vignesh Ramanathan,Michael Milford,Tobias Fischer*

Main category: cs.RO

TL;DR: Flash是一个新型的视觉位置识别系统，利用亚毫秒的事件数据大幅提升识别性能，采用活动像素位置结合高效编码和快速计算。


<details>
  <summary>Details</summary>
Motivation: 传统的视觉位置识别方法依赖密集表示和大量事件数据，而本研究旨在通过使用亚毫秒事件数据来打破这一模式。

Method: Flash系统利用活动像素位置作为判别特征，通过高效的二进制帧编码并使用快速位操作计算相似性，基于查询和参考帧的事件活动进行归一化。

Result: 在室内QCR-Event-Dataset上，Flash提升了Recall@1指标超过11.33倍，在8公里Brisbane-Event-VPR数据集上提升了5.92倍，同时减少了机械臂在无定位意识状态下的操作时间。

Conclusion: Flash是首个展示使用事件相机进行亚毫秒视觉位置识别的系统，显著提高了定位精度和速度。

Abstract: Visual Place Recognition (VPR) enables systems to identify previously visited
locations within a map, a fundamental task for autonomous navigation. Prior
works have developed VPR solutions using event cameras, which asynchronously
measure per-pixel brightness changes with microsecond temporal resolution.
However, these approaches rely on dense representations of the inherently
sparse camera output and require tens to hundreds of milliseconds of event data
to predict a place. Here, we break this paradigm with Flash, a lightweight VPR
system that predicts places using sub-millisecond slices of event data. Our
method is based on the observation that active pixel locations provide strong
discriminative features for VPR. Flash encodes these active pixel locations
using efficient binary frames and computes similarities via fast bitwise
operations, which are then normalized based on the relative event activity in
the query and reference frames. Flash improves Recall@1 for sub-millisecond VPR
over existing baselines by 11.33x on the indoor QCR-Event-Dataset and 5.92x on
the 8 km Brisbane-Event-VPR dataset. Moreover, our approach reduces the
duration for which the robot must operate without awareness of its position, as
evidenced by a localization latency metric we term Time to Correct Match (TCM).
To the best of our knowledge, this is the first work to demonstrate
sub-millisecond VPR using event cameras.

</details>


### [93] [Ancestry Tree Clustering for Particle Filter Diversity Maintenance](https://arxiv.org/abs/2509.24124)
*Ilari Vallivaara,Bingnan Duan,Yinhuan Dong,Tughrul Arslan*

Main category: cs.RO

TL;DR: 本文提出了一种新的粒子过滤中线性时间多样性维护方法，通过聚类粒子的祖先树拓扑，有效防止多模态环境中的早期收敛，并在多个领域表现出良好的效果。


<details>
  <summary>Details</summary>
Motivation: 在多模态环境中维护粒子的多样性，以防止早期收敛问题，同时保持估计的紧凑性。

Method: 一种基于祖先树拓扑对粒子进行聚类的方法，结合了集群内部适应度共享以及保护未被包括在集群中的粒子。

Result: 在多模态机器人仿真和实际的室内环境中验证了方法，与文献中的几种多样性维护算法相比，算法在成功率上表现优异，且对紧凑性基本没有负面影响。

Conclusion: 提出的方法在保持紧凑性的同时，有效防止了多模态环境中的早期收敛，并在不同领域和具有挑战性的初始条件下表现出良好的鲁棒性。

Abstract: We propose a method for linear-time diversity maintenance in particle
filtering. It clusters particles based on ancestry tree topology: closely
related particles in sufficiently large subtrees are grouped together. The main
idea is that the tree structure implicitly encodes similarity without the need
for spatial or other domain-specific metrics. This approach, when combined with
intra-cluster fitness sharing and the protection of particles not included in a
cluster, effectively prevents premature convergence in multimodal environments
while maintaining estimate compactness. We validate our approach in a
multimodal robotics simulation and a real-world multimodal indoor environment.
We compare the performance to several diversity maintenance algorithms from the
literature, including Deterministic Resampling and Particle Gaussian Mixtures.
Our algorithm achieves high success rates with little to no negative effect on
compactness, showing particular robustness to different domains and challenging
initial conditions.

</details>


### [94] [BOSfM: A View Planning Framework for Optimal 3D Reconstruction of Agricultural Scenes](https://arxiv.org/abs/2509.24126)
*Athanasios Bacharis,Konstantinos D. Polyzos,Georgios B. Giannakis,Nikolaos Papanikolopoulos*

Main category: cs.RO

TL;DR: 本文提出了一种新颖的视角规划框架，通过贝叶斯优化有效优化摄像机位置，以准确重建农业环境的三维结构并实现良好的泛化。


<details>
  <summary>Details</summary>
Motivation: 提高在农业任务中，特别是精准作物监测和自主采收等应用中的三维重建效率，减少对大量二维图像的依赖。

Method: 使用贝叶斯优化方法进行视角规划，考虑重建质量为基础的优化，并依赖于‘从运动重构’的概念来进行三维重建。

Result: 数值测试表明该视角规划方法在模拟和真实农业场景中有效，能够在考虑噪声情况下进行有效的摄像机位置优化。

Conclusion: 所提出的视角规划方法在农业环境中有效估计最佳摄像头位置，准确重建三维环境，并在未知相似环境中良好泛化。

Abstract: Active vision (AV) has been in the spotlight of robotics research due to its
emergence in numerous applications including agricultural tasks such as
precision crop monitoring and autonomous harvesting to list a few. A major AV
problem that gained popularity is the 3D reconstruction of targeted
environments using 2D images from diverse viewpoints. While collecting and
processing a large number of arbitrarily captured 2D images can be arduous in
many practical scenarios, a more efficient solution involves optimizing the
placement of available cameras in 3D space to capture fewer, yet more
informative, images that provide sufficient visual information for effective
reconstruction of the environment of interest. This process termed as view
planning (VP), can be markedly challenged (i) by noise emerging in the location
of the cameras and/or in the extracted images, and (ii) by the need to
generalize well in other unknown similar agricultural environments without need
for re-optimizing or re-training. To cope with these challenges, the present
work presents a novel VP framework that considers a reconstruction
quality-based optimization formulation that relies on the notion of
`structure-from-motion' to reconstruct the 3D structure of the sought
environment from the selected 2D images. With no analytic expression of the
optimization function and with costly function evaluations, a Bayesian
optimization approach is proposed to efficiently carry out the VP process using
only a few function evaluations, while accounting for different noise cases.
Numerical tests on both simulated and real agricultural settings signify the
benefits of the advocated VP approach in efficiently estimating the optimal
camera placement to accurately reconstruct 3D environments of interest, and
generalize well on similar unknown environments.

</details>


### [95] [Mash, Spread, Slice! Learning to Manipulate Object States via Visual Spatial Progress](https://arxiv.org/abs/2509.24129)
*Priyanka Mandikal,Jiaheng Hu,Shivin Dass,Sagnik Majumder,Roberto Martín-Martín,Kristen Grauman*

Main category: cs.RO

TL;DR: SPARTA 是一个统一的机器人操作框架，专注于物体状态的逐渐变化，通过空间渐进的变化分割和视觉技能提升操作效率。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人操作大多集中于物体运动，而许多实际操作涉及物体状态的逐渐变化（如压、涂抹或切割）。

Method: SPARTA 集成了空间渐进的物体变化分割图和视觉技能，以生成结构化策略观察和密集奖励，从而实现强化学习和贪婪控制。

Result: 在10种不同的实际物体上验证了SPARTA，显著提高了训练时间和准确性。

Conclusion: SPARTA 框架在实际机器人操作中显著提高了训练时间和准确性，为更广泛的物体状态操作任务奠定了基础。

Abstract: Most robot manipulation focuses on changing the kinematic state of objects:
picking, placing, opening, or rotating them. However, a wide range of
real-world manipulation tasks involve a different class of object state
change--such as mashing, spreading, or slicing--where the object's physical and
visual state evolve progressively without necessarily changing its position. We
present SPARTA, the first unified framework for the family of object state
change manipulation tasks. Our key insight is that these tasks share a common
structural pattern: they involve spatially-progressing, object-centric changes
that can be represented as regions transitioning from an actionable to a
transformed state. Building on this insight, SPARTA integrates spatially
progressing object change segmentation maps, a visual skill to perceive
actionable vs. transformed regions for specific object state change tasks, to
generate a) structured policy observations that strip away appearance
variability, and b) dense rewards that capture incremental progress over time.
These are leveraged in two SPARTA policy variants: reinforcement learning for
fine-grained control without demonstrations or simulation; and greedy control
for fast, lightweight deployment. We validate SPARTA on a real robot for three
challenging tasks across 10 diverse real-world objects, achieving significant
improvements in training time and accuracy over sparse rewards and visual
goal-conditioned baselines. Our results highlight progress-aware visual
representations as a versatile foundation for the broader family of object
state manipulation tasks. Project website:
https://vision.cs.utexas.edu/projects/sparta-robot

</details>


### [96] [A Novel Model for 3D Motion Planning for a Generalized Dubins Vehicle with Pitch and Yaw Rate Constraints](https://arxiv.org/abs/2509.24143)
*Deepak Prakash Kumar,Swaroop Darbha,Satyanarayana Gupta Manyam,David Casbeer*

Main category: cs.RO

TL;DR: 提出了一种针对固定翼无人机的快速3D运动规划新方法，通过考虑完整的姿态和双控制输入，生成更短的路径，并在10秒内计算出可行路径。


<details>
  <summary>Details</summary>
Motivation: 旨在为固定翼无人机构建连接给定初始和最终配置的最短路径，同时考虑运动约束及完整的车辆定向。

Method: 提出了一种新的建模方法和快速算法，通过旋转最小化框架描述无拘束飞行器的配置和演变，并在球面、圆柱面或平面上连接优化的Dubins路径来构建路径。

Result: 该方法考虑了完整的车辆姿态和双控制输入，能够更准确地建模3D空间中的车辆运动，从而生成更短的路径。

Conclusion: 该方法在大多数情况下生成的路径比现有方法更短，并且平均计算时间为10秒内，生成可行路径。

Abstract: In this paper, we propose a new modeling approach and a fast algorithm for 3D
motion planning, applicable for fixed-wing unmanned aerial vehicles. The goal
is to construct the shortest path connecting given initial and final
configurations subject to motion constraints. Our work differs from existing
literature in two ways. First, we consider full vehicle orientation using a
body-attached frame, which includes roll, pitch, and yaw angles. However,
existing work uses only pitch and/or heading angle, which is insufficient to
uniquely determine orientation. Second, we use two control inputs to represent
bounded pitch and yaw rates, reflecting control by two separate actuators. In
contrast, most previous methods rely on a single input, such as path curvature,
which is insufficient for accurately modeling the vehicle's kinematics in 3D.
We use a rotation minimizing frame to describe the vehicle's configuration and
its evolution, and construct paths by concatenating optimal Dubins paths on
spherical, cylindrical, or planar surfaces. Numerical simulations show our
approach generates feasible paths within 10 seconds on average and yields
shorter paths than existing methods in most cases.

</details>


### [97] [Memory Transfer Planning: LLM-driven Context-Aware Code Adaptation for Robot Manipulation](https://arxiv.org/abs/2509.24160)
*Tomoyuki Kagaya,Subramanian Lakshmi,Yuxuan Lou,Thong Jing Yuan,Jayashree Karlekar,Sugiri Pranata,Natsuki Murakami,Akira Kinose,Yang You*

Main category: cs.RO

TL;DR: MTP框架通过利用不同环境的成功示例，改善大语言模型在机器人操控中的环境适应性与成功率。


<details>
  <summary>Details</summary>
Motivation: 解决现有大语言模型在机器人操控中对新环境适应性差的问题。

Method: 通过生成初步计划和代码，检索成功的控制代码示例，适应目标环境进行重新规划。

Result: 在多种设置下，MTP在成功率和适应性方面表现优于固定提示代码生成、简单检索和无记忆重新规划方法。

Conclusion: MTP框架可以有效提高机器人操控的成功率和适应性，桥接模拟与实际部署，是一种实用的方法。

Abstract: Large language models (LLMs) are increasingly explored in robot manipulation,
but many existing methods struggle to adapt to new environments. Many systems
require either environment-specific policy training or depend on fixed prompts
and single-shot code generation, leading to limited transferability and manual
re-tuning. We introduce Memory Transfer Planning (MTP), a framework that
leverages successful control-code examples from different environments as
procedural knowledge, using them as in-context guidance for LLM-driven
planning. Specifically, MTP (i) generates an initial plan and code using LLMs,
(ii) retrieves relevant successful examples from a code memory, and (iii)
contextually adapts the retrieved code to the target setting for re-planning
without updating model parameters. We evaluate MTP on RLBench, CALVIN, and a
physical robot, demonstrating effectiveness beyond simulation. Across these
settings, MTP consistently improved success rate and adaptability compared with
fixed-prompt code generation, naive retrieval, and memory-free re-planning.
Furthermore, in hardware experiments, leveraging a memory constructed in
simulation proved effective. MTP provides a practical approach that exploits
procedural knowledge to realize robust LLM-based planning across diverse
robotic manipulation scenarios, enhancing adaptability to novel environments
and bridging simulation and real-world deployment.

</details>


### [98] [Preference-Based Long-Horizon Robotic Stacking with Multimodal Large Language Models](https://arxiv.org/abs/2509.24163)
*Wanming Yu,Adrian Röfer,Abhinav Valada,Sethu Vijayakumar*

Main category: cs.RO

TL;DR: 本研究提出使用多模态大语言模型微调来提升长远机器人堆叠任务的表现，特别是在物理属性推理方面。


<details>
  <summary>Details</summary>
Motivation: 解决在长远机器人操作任务中，由于缺乏物体物理属性知识，预训练的大语言模型效果不足的问题。

Method: 利用多模态大语言模型作为高级规划者，处理与堆叠相关的任务，并通过自定义数据集进行微调。

Result: 与仅进行提示调优的预训练大语言模型相比，使用自定义数据集微调的模型在堆叠任务的完成率上显著提高。

Conclusion: 通过在自定义数据集上微调的多模态大语言模型在实际人形机器人上展示了较好的长时间堆叠任务的执行效果。

Abstract: Pretrained large language models (LLMs) can work as high-level robotic
planners by reasoning over abstract task descriptions and natural language
instructions, etc. However, they have shown a lack of knowledge and
effectiveness in planning long-horizon robotic manipulation tasks where the
physical properties of the objects are essential. An example is the stacking of
containers with hidden objects inside, which involves reasoning over hidden
physics properties such as weight and stability. To this end, this paper
proposes to use multimodal LLMs as high-level planners for such long-horizon
robotic stacking tasks. The LLM takes multimodal inputs for each object to
stack and infers the current best stacking sequence by reasoning over stacking
preferences. Furthermore, in order to enable the LLM to reason over multiple
preferences at the same time without giving explicit instructions, we propose
to create a custom dataset considering stacking preferences including weight,
stability, size, and footprint, to fine-tune the LLM. Compared to the
pretrained LLM with prompt tuning, we demonstrate the improved stacking
completion of the LLM fine-tuned with our custom dataset via large-scale
simulation evaluation. Furthermore, we showcase the effectiveness of the
proposed framework for the long-horizon stacking task on a real humanoid robot
in an online manner.

</details>


### [99] [Very High Frequency Interpolation for Direct Torque Control](https://arxiv.org/abs/2509.24175)
*Rafael Kourdis,Maciej Stępień,Jérôme Manhes,Nicolas Mansard,Steve Tonneau,Philippe Souères,Thomas Flayols*

Main category: cs.RO

TL;DR: 本研究提出了一种在开源硬件上以最高40 kHz执行全身线性反馈的解决方案，成功稳定了扭矩控制器，从而提升了扭矩控制机器人的性能。


<details>
  <summary>Details</summary>
Motivation: 扭矩控制能实现灵活和稳健的机器人运动，但受到不稳定性和硬件限制的影响。

Method: 实现高达40 kHz的全身线性反馈，通过开源硬件与非线性方案插值。

Result: 稳定扭矩控制器的应用使得高频线性反馈成为强化扭矩控制机器人的有效途径。

Conclusion: 稳定的扭矩控制器使得高频线性反馈能够有效地提升扭矩控制机器人性能。

Abstract: Torque control enables agile and robust robot motion, but deployment is often
hindered by instability and hardware limits. Here, we present a novel solution
to execute whole-body linear feedback at up to 40 kHz on open-source hardware.
We use this to interpolate non-linear schemes during real-world execution, such
as inverse dynamics and learned torque policies. Our results show that by
stabilizing torque controllers, high-frequency linear feedback could be an
effective route towards unlocking the potential of torque-controlled robotics.

</details>


### [100] [ViReSkill: Vision-Grounded Replanning with Skill Memory for LLM-Based Planning in Lifelong Robot Learning](https://arxiv.org/abs/2509.24219)
*Tomoyuki Kagaya,Subramanian Lakshmi,Anbang Ye,Thong Jing Yuan,Jayashree Karlekar,Sugiri Pranata,Natsuki Murakami,Akira Kinose,Yang You*

Main category: cs.RO

TL;DR: ViReSkill 提出了一种结合视觉和技能记忆的自主学习框架，提升了机器人的任务适应能力。


<details>
  <summary>Details</summary>
Motivation: 机器人在适应新任务时通常效率低下，需解决语言/视觉模型在运动规划中与场景几何和物理对象的结合问题。

Method: 通过视觉基础的重新规划和技能记忆相结合，形成一个提升自主学习能力的反馈循环。

Result: ViReSkill 在 LIBERO 和 RLBench 等模拟器及实际机器人上评估，均优于常规基线，证明了该框架的有效性。

Conclusion: ViReSkill 框架在多种环境中表现优越，显著提高了任务成功率，并展现出稳健的仿真到现实的泛化能力。

Abstract: Robots trained via Reinforcement Learning (RL) or Imitation Learning (IL)
often adapt slowly to new tasks, whereas recent Large Language Models (LLMs)
and Vision-Language Models (VLMs) promise knowledge-rich planning from minimal
data. Deploying LLMs/VLMs for motion planning, however, faces two key
obstacles: (i) symbolic plans are rarely grounded in scene geometry and object
physics, and (ii) model outputs can vary for identical prompts, undermining
execution reliability. We propose ViReSkill, a framework that pairs
vision-grounded replanning with a skill memory for accumulation and reuse. When
a failure occurs, the replanner generates a new action sequence conditioned on
the current scene, tailored to the observed state. On success, the executed
plan is stored as a reusable skill and replayed in future encounters without
additional calls to LLMs/VLMs. This feedback loop enables autonomous continual
learning: each attempt immediately expands the skill set and stabilizes
subsequent executions. We evaluate ViReSkill on simulators such as LIBERO and
RLBench as well as on a physical robot. Across all settings, it consistently
outperforms conventional baselines in task success rate, demonstrating robust
sim-to-real generalization.

</details>


### [101] [Towards Tighter Convex Relaxation of Mixed-integer Programs: Leveraging Logic Network Flow for Task and Motion Planning](https://arxiv.org/abs/2509.24235)
*Xuan Lin,Jiming Ren,Yandong Luo,Weijun Xie,Ye Zhao*

Main category: cs.RO

TL;DR: 该论文提出了一种新型的机器人规划框架，通过结合时序逻辑和网络流模型，显著提升了规划的计算效率，并在实际应用中验证了其实时规划能力。


<details>
  <summary>Details</summary>
Motivation: 旨在提升机器人规划效率，并克服传统逻辑树方法的限制。

Method: 引入一种基于网络流的优化任务和运动规划框架，结合时序逻辑规范与混合整数规划。

Result: 通过一系列实验，展示了在车辆调度、多机器人协调等领域达到数个数量级的计算加速，且硬件展示证实了在动态环境条件下的实时重规划能力。

Conclusion: 该论文的优化框架在多种动态系统下有效提高了规划的计算效率，且在实际硬件上验证了其实时重规划能力。

Abstract: This paper proposes an optimization-based task and motion planning framework,
named "Logic Network Flow", that integrates temporal logic specifications into
mixed-integer programs for efficient robot planning. Inspired by the
Graph-of-Convex-Sets formulation, temporal predicates are encoded as polyhedron
constraints on each edge of a network flow model, instead of as constraints
between nodes in traditional Logic Tree formulations. We further propose a
network-flow-based Fourier-Motzkin elimination procedure that removes
continuous flow variables while preserving convex relaxation tightness, leading
to provably tighter convex relaxations and fewer constraints than Logic Tree
formulations. For temporal logic motion planning with piecewise-affine dynamic
systems, comprehensive experiments across vehicle routing, multi-robot
coordination, and temporal logic control on dynamical systems using point mass
and linear inverted pendulum models demonstrate computational speedups of up to
several orders of magnitude. Hardware demonstrations with quadrupedal robots
validate real-time replanning capabilities under dynamically changing
environmental conditions. The project website is at
https://logicnetworkflow.github.io/.

</details>


### [102] [PROFusion: Robust and Accurate Dense Reconstruction via Camera Pose Regression and Optimization](https://arxiv.org/abs/2509.24236)
*Siyan Dong,Zijun Wang,Lulu Cai,Yi Ma,Yanchao Yang*

Main category: cs.RO

TL;DR: 提出了一种结合学习和优化的方法，用于在不稳定相机运动下进行实时稠密场景重建，实验结果显示优异性能。


<details>
  <summary>Details</summary>
Motivation: 在不稳定相机运动下进行实时稠密场景重建对于机器人技术至关重要，现有的RGB-D SLAM系统在相机经历大视角变化、快速运动或突然震动时效果不佳。

Method: 通过结合基于学习的初始化和基于优化的细化，提出了一种新方法。该方法利用相机姿态回归网络从连续的RGB-D帧中预测基于度量的相对姿态，作为随机优化算法的可靠起始点。

Result: 通过广泛的实验，显示出该方法在困难基准测试上表现出色，优于竞争对手，同时在稳定运动序列中保持了相似的精度。

Conclusion: 该方法在复杂基准测试上超越了现有最佳竞争者，同时在稳定运动序列上保持了相当的精度，实时工作证明了简单技术与原则性技术结合的有效性。

Abstract: Real-time dense scene reconstruction during unstable camera motions is
crucial for robotics, yet current RGB-D SLAM systems fail when cameras
experience large viewpoint changes, fast motions, or sudden shaking. Classical
optimization-based methods deliver high accuracy but fail with poor
initialization during large motions, while learning-based approaches provide
robustness but lack sufficient accuracy for dense reconstruction. We address
this challenge through a combination of learning-based initialization with
optimization-based refinement. Our method employs a camera pose regression
network to predict metric-aware relative poses from consecutive RGB-D frames,
which serve as reliable starting points for a randomized optimization algorithm
that further aligns depth images with the scene geometry. Extensive experiments
demonstrate promising results: our approach outperforms the best competitor on
challenging benchmarks, while maintaining comparable accuracy on stable motion
sequences. The system operates in real-time, showcasing that combining simple
and principled techniques can achieve both robustness for unstable motions and
accuracy for dense reconstruction. Project page:
https://github.com/siyandong/PROFusion.

</details>


### [103] [SafeFlowMatcher: Safe and Fast Planning using Flow Matching with Control Barrier Functions](https://arxiv.org/abs/2509.24243)
*Jeongyong Yang,Seunghwan Jang,Soojean Han*

Main category: cs.RO

TL;DR: SafeFlowMatcher是一个计划框架，将流匹配与控制屏障函数结合，实现了实时效率和认证安全性，可在复杂环境中生成更快、更平滑和更安全的路径。


<details>
  <summary>Details</summary>
Motivation: 基于流匹配的生成规划器缺乏正式的安全保障，并且在约束附近可能生成不完整的路径，因此需要一个能在保证安全性的同时又能实时有效的规划框架。

Method: 使用两阶段预测-修正积分器，其中预测阶段一次或几次集成学习到的流匹配，修正阶段通过消失时间缩放向量场和基于控制屏障函数的二次规划对路径进行精炼。

Result: SafeFlowMatcher通过将流匹配与控制屏障函数结合，证明了生成的流系统的屏障证书，建立了健壮安全集的正向不变性和有限时间收敛性。

Conclusion: SafeFlowMatcher在迷宫导航和运动基准测试中提供了比扩散和流匹配基准更快、更平滑和更安全的路径。

Abstract: Generative planners based on flow matching (FM) can produce high-quality
paths in one or a few ODE steps, but their sampling dynamics offer no formal
safety guarantees and can yield incomplete paths near constraints. We present
SafeFlowMatcher, a planning framework that couples FM with control barrier
functions (CBFs) to achieve both real-time efficiency and certified safety.
SafeFlowMatcher uses a two-phase prediction-correction (PC) integrator: (i) a
prediction phase integrates the learned FM once (or a few steps) to obtain a
candidate path without intervention; (ii) a correction phase refines this path
with a vanishing time-scaled vector field and a CBF-based quadratic program
that minimally perturbs the vector field. We prove a barrier certificate for
the resulting flow system, establishing forward invariance of a robust safe set
and finite-time convergence to the safe set. By enforcing safety only on the
executed path (rather than on all intermediate latent paths), SafeFlowMatcher
avoids distributional drift and mitigates local trap problems. Across maze
navigation and locomotion benchmarks, SafeFlowMatcher attains faster, smoother,
and safer paths than diffusion- and FM-based baselines. Extensive ablations
corroborate the contributions of the PC integrator and the barrier certificate.

</details>


### [104] [Contextual Neural Moving Horizon Estimation for Robust Quadrotor Control in Varying Conditions](https://arxiv.org/abs/2509.24281)
*Kasra Torshizi,Chak Lam Shek,Khuzema Habib,Guangyao Shi,Pratap Tokekar,Troi Williams*

Main category: cs.RO

TL;DR: 通过 Contextual NeuroMHE 方法，利用贝叶斯优化选择环境，上述方法在多种环境下提高了控制精度，并展现出卓越的泛化和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的自适应控制器难以处理真实世界中干扰的估计，其灵活性和抗干扰性较差。

Method: 采用贝叶斯优化与高斯过程的序列决策策略，以选择数据收集的环境背景。

Result: 在多个实际环境设置中，方法对最大绝对位置误差的表现提高了20.3%，并能够通过少量精心选择的环境背景捕捉环境的变化。

Conclusion: Contextual NeuroMHE通过动态调整神经网络参数，提高了控制效果的效率和泛化能力，并在多种实际环境中表现出色。

Abstract: Adaptive controllers on quadrotors typically rely on estimation of
disturbances to ensure robust trajectory tracking. Estimating disturbances
across diverse environmental contexts is challenging due to the inherent
variability and uncertainty in the real world. Such estimators require
extensive fine-tuning for a specific scenario, which makes them inflexible and
brittle to changing conditions. Machine-learning approaches, such as training a
neural network to tune the estimator's parameters, are promising. However,
collecting data across all possible environmental contexts is impossible. It is
also inefficient as the same estimator parameters could work for "nearby"
contexts. In this paper, we present a sequential decision making strategy that
decides which environmental contexts, using Bayesian Optimization with a
Gaussian Process, to collect data from in order to ensure robust performance
across a wide range of contexts. Our method, Contextual NeuroMHE, eliminates
the need for exhaustive training across all environments while maintaining
robust performance under different conditions. By enabling the neural network
to adapt its parameters dynamically, our method improves both efficiency and
generalization. Experimental results in various real-world settings demonstrate
that our approach outperforms the prior work by 20.3\% in terms of maximum
absolute position error and can capture the variations in the environment with
a few carefully chosen contexts.

</details>


### [105] [Learning to Sample: Reinforcement Learning-Guided Sampling for Autonomous Vehicle Motion Planning](https://arxiv.org/abs/2509.24313)
*Korbinian Moller,Roland Stroop,Mattia Piccinini,Alexander Langmann,Johannes Betz*

Main category: cs.RO

TL;DR: 提出了一种混合采样框架，通过强化学习引导采样过程，显著提高了城市环境中自主驾驶的决策效率与安全性。


<details>
  <summary>Details</summary>
Motivation: 在复杂城市场景中，传统的均匀或启发式采样导致许多不合适的轨迹，亟需改进采样过程以提升效率和可靠性。

Method: 提出了一种混合框架，结合强化学习（RL）采样器与基于可解码深度集编码器的世界模型，进行样本选择与生成。

Result: 在CommonRoad仿真环境中，所提方法实现了高达99%的样本减少和84%的运行时间缩减，同时成功率和无碰撞率保持在高水平。

Conclusion: 该方法显著减少了所需样本数量和运行时间，同时保持了规划质量，提升了自主车辆在城市环境中的决策速度和可靠性。

Abstract: Sampling-based motion planning is a well-established approach in autonomous
driving, valued for its modularity and analytical tractability. In complex
urban scenarios, however, uniform or heuristic sampling often produces many
infeasible or irrelevant trajectories. We address this limitation with a hybrid
framework that learns where to sample while keeping trajectory generation and
evaluation fully analytical and verifiable. A reinforcement learning (RL) agent
guides the sampling process toward regions of the action space likely to yield
feasible trajectories, while evaluation and final selection remains governed by
deterministic feasibility checks and cost functions. We couple the RL sampler
with a world model (WM) based on a decodable deep set encoder, enabling both
variable numbers of traffic participants and reconstructable latent
representations. The approach is evaluated in the CommonRoad simulation
environment, showing up to 99% fewer required samples and a runtime reduction
of up to 84% while maintaining planning quality in terms of success and
collision-free rates. These improvements lead to faster, more reliable
decision-making for autonomous vehicles in urban environments, achieving safer
and more responsive navigation under real-world constraints. Code and trained
artifacts are publicly available at:
https://github.com/TUM-AVS/Learning-to-Sample

</details>


### [106] [SONAR: Semantic-Object Navigation with Aggregated Reasoning through a Cross-Modal Inference Paradigm](https://arxiv.org/abs/2509.24321)
*Yao Wang,Zhirui Sun,Wenzheng Chi,Baozhi Jia,Wenjun Xu,Jiankun Wang*

Main category: cs.RO

TL;DR: SONAR是一种通过聚合推理和语义地图结合的方法，旨在提升机器人在未知环境中的导航能力。


<details>
  <summary>Details</summary>
Motivation: 当前的模块化方法依赖训练数据质量，不易泛化；视觉-语言模型在语义线索弱时表现不佳，因此需要改进。

Method: 通过跨模态范式的聚合推理方法，结合语义地图和视觉-语言模型，提升导航性能。

Result: 在Gazebo模拟器上评估SONAR，成功率为38.4%，SPL为17.7%。

Conclusion: SONAR方法在未知环境中表现出较强的导航能力，成功率为38.4%。

Abstract: Understanding human instructions and accomplishing Vision-Language Navigation
tasks in unknown environments is essential for robots. However, existing
modular approaches heavily rely on the quality of training data and often
exhibit poor generalization. Vision-Language Model based methods, while
demonstrating strong generalization capabilities, tend to perform
unsatisfactorily when semantic cues are weak. To address these issues, this
paper proposes SONAR, an aggregated reasoning approach through a cross modal
paradigm. The proposed method integrates a semantic map based target prediction
module with a Vision-Language Model based value map module, enabling more
robust navigation in unknown environments with varying levels of semantic cues,
and effectively balancing generalization ability with scene adaptability. In
terms of target localization, we propose a strategy that integrates multi-scale
semantic maps with confidence maps, aiming to mitigate false detections of
target objects. We conducted an evaluation of the SONAR within the Gazebo
simulator, leveraging the most challenging Matterport 3D (MP3D) dataset as the
experimental benchmark. Experimental results demonstrate that SONAR achieves a
success rate of 38.4% and an SPL of 17.7%.

</details>


### [107] [AdaNav: Adaptive Reasoning with Uncertainty for Vision-Language Navigation](https://arxiv.org/abs/2509.24387)
*Xin Ding,Jianyu Wei,Yifan Yang,Shiqi Jiang,Qianxi Zhang,Hao Wu,Fucheng Jia,Liang Mi,Yuxuan Yan,Weijun Wang,Yunxin Liu,Zhibo Chen,Ting Cao*

Main category: cs.RO

TL;DR: AdaNav是一种基于不确定性自适应推理的框架，显著提高了视觉语言导航的成功率，尤其在数据有限的情况下。


<details>
  <summary>Details</summary>
Motivation: 提高视觉语言导航中的时间一致性和感知-行动对齐，同时避免固定步骤推理导致的性能不佳和不必要的计算。

Method: 采用不确定性自适应推理模块（UAR），通过引入动作熵作为策略先验，并通过启发式到强化学习的训练方法进行逐步优化。

Result: AdaNav在仅使用6000个训练样本的情况下，成功率在R2R val-unseen上提高20%，在RxR-CE上提高11.7%，在现实场景中提高11.4%。

Conclusion: AdaNav通过不确定性自适应推理框架显著提升了视觉语言导航任务的成功率。

Abstract: Vision Language Navigation (VLN) requires agents to follow natural language
instructions by grounding them in sequential visual observations over long
horizons. Explicit reasoning could enhance temporal consistency and perception
action alignment, but reasoning at fixed steps often leads to suboptimal
performance and unnecessary computation. To address this, we propose AdaNav, an
uncertainty-based adaptive reasoning framework for VLN. At its core is the
Uncertainty Adaptive Reasoning Block (UAR), a lightweight plugin that
dynamically triggers reasoning. We introduce Action Entropy as a policy prior
for UAR and progressively refine it through a Heuristics to RL training method,
enabling agents to learn difficulty aware reasoning policies under the strict
data limitations of embodied tasks. Results show that with only 6K training
samples, AdaNav achieves substantial gains over closed source models trained on
million scale data, improving success rate by 20% on R2R val-unseen, 11.7% on
RxR-CE, and 11.4% in real world scenes. The code is available at
https://github.com/xinding-sys/AdaNav.

</details>


### [108] [PhysiAgent: An Embodied Agent Framework in Physical World](https://arxiv.org/abs/2509.24524)
*Zhihao Wang,Jianxiong Li,Jinliang Zheng,Wencong Zhang,Dongxiu Liu,Yinan Zheng,Haoyi Niu,Junzhi Yu,Xianyuan Zhan*

Main category: cs.RO

TL;DR: 本文提出了PhysiAgent框架，改进了VLM和VLA的协作，实现了在真实环境中的有效应用，并提升了任务解决性能。


<details>
  <summary>Details</summary>
Motivation: VLA模型在通用性方面存在限制，当前将VLM和VLA组合的方式过于僵化，缺乏有效的协作。

Method: 提出了一种结合监控、记忆、自我反思机制和轻量级工具箱的身体代理框架，以实现VLM和VLA之间的有效协作。

Result: 实验结果表明，PhysiAgent在复杂任务解决中表现出色，展示了对VLM的有效自我调节和工具协作能力。

Conclusion: PhysiAgent在复杂的现实世界机器人任务上显示出显著的任务解决性能提升，成功地整合了VLM和VLA，增强了框架的适应性和有效性。

Abstract: Vision-Language-Action (VLA) models have achieved notable success but often
struggle with limited generalizations. To address this, integrating generalized
Vision-Language Models (VLMs) as assistants to VLAs has emerged as a popular
solution. However, current approaches often combine these models in rigid,
sequential structures: using VLMs primarily for high-level scene understanding
and task planning, and VLAs merely as executors of lower-level actions, leading
to ineffective collaboration and poor grounding challenges. In this paper, we
propose an embodied agent framework, PhysiAgent, tailored to operate
effectively in physical environments. By incorporating monitor, memory,
self-reflection mechanisms, and lightweight off-the-shelf toolboxes, PhysiAgent
offers an autonomous scaffolding framework to prompt VLMs to organize different
components based on real-time proficiency feedback from VLAs to maximally
exploit VLAs' capabilities. Experimental results demonstrate significant
improvements in task-solving performance on complex real-world robotic tasks,
showcasing effective self-regulation of VLMs, coherent tool collaboration, and
adaptive evolution of the framework during execution. PhysiAgent makes
practical and pioneering efforts to integrate VLMs and VLAs, effectively
grounding embodied agent frameworks in real-world settings.

</details>


### [109] [Game Theory to Study Cooperation in Human-Robot Mixed Groups: Exploring the Potential of the Public Good Game](https://arxiv.org/abs/2509.24530)
*Giulia Pusceddu,Sara Mongile,Francesco Rea,Alessandra Sciutti*

Main category: cs.RO

TL;DR: 本研究使用博弈论探索人类与机器人之间的合作与信任，结果表明参与者尽管认为机器人慷慨，仍不愿投入公共资金。


<details>
  <summary>Details</summary>
Motivation: 探索博弈论在研究人类与机器人混合群体中的合作与信任的潜力。

Method: 通过公共物品游戏（PGG）模型，参与者与人形机器人iCub进行互动，以评估不同机器人策略对人类合作意愿的影响。

Result: 参加实验的19名参与者的初步分析显示，他们更倾向于不投入资金，即使他们认为机器人的行为是慷慨的。

Conclusion: 本研究表明，尽管参与者认为机器人是慷慨的，但他们仍然倾向于不将资金投入公共池，从而展示了个体自我利益与集体福祉之间的张力。

Abstract: In this study, we explore the potential of Game Theory as a means to
investigate cooperation and trust in human-robot mixed groups. Particularly, we
introduce the Public Good Game (PGG), a model highlighting the tension between
individual self-interest and collective well-being. In this work, we present a
modified version of the PGG, where three human participants engage in the game
with the humanoid robot iCub to assess whether various robot game strategies
(e.g., always cooperate, always free ride, and tit-for-tat) can influence the
participants' inclination to cooperate. We test our setup during a pilot study
with nineteen participants. A preliminary analysis indicates that participants
prefer not to invest their money in the common pool, despite they perceive the
robot as generous. By conducting this research, we seek to gain valuable
insights into the role that robots can play in promoting trust and cohesion
during human-robot interactions within group contexts. The results of this
study may hold considerable potential for developing social robots capable of
fostering trust and cooperation within mixed human-robot groups.

</details>


### [110] [Unlocking the Potential of Soft Actor-Critic for Imitation Learning](https://arxiv.org/abs/2509.24539)
*Nayari Marie Lessa,Melya Boukheddimi,Frank Kirchner*

Main category: cs.RO

TL;DR: 本文提出了一种新颖的模仿学习框架AMP+SAC，将对抗性运动优先级与离策略学习结合，克服了现有方法的局限性，并在四足运动任务中表现出更高的数据效率和稳定性。


<details>
  <summary>Details</summary>
Motivation: 当前的顶尖框架主要依赖于PPO算法，其重视稳定性而非样本效率与策略泛化，从而限制了机器人运动的自然性和适应性。

Method: 将对抗性运动优先级(AMP)与离策略软演员评论者(SAC)算法结合，使用重放驱动学习和熵正则化探索。

Result: 实验结果表明，所提出的AMP+SAC方法在多参考运动和不同地形的四足运动中，能够提升数据效率和鲁棒性，取得了更好的实验性能。

Conclusion: 提出的AMP+SAC框架在保持稳定任务执行的同时，相较于AMP+PPO方法获得了更高的模仿奖励，展示了离线策略学习在机器人运动生成中的潜力。

Abstract: Learning-based methods have enabled robots to acquire bio-inspired movements
with increasing levels of naturalness and adaptability. Among these, Imitation
Learning (IL) has proven effective in transferring complex motion patterns from
animals to robotic systems. However, current state-of-the-art frameworks
predominantly rely on Proximal Policy Optimization (PPO), an on-policy
algorithm that prioritizes stability over sample efficiency and policy
generalization. This paper proposes a novel IL framework that combines
Adversarial Motion Priors (AMP) with the off-policy Soft Actor-Critic (SAC)
algorithm to overcome these limitations. This integration leverages
replay-driven learning and entropy-regularized exploration, enabling
naturalistic behavior and task execution, improving data efficiency and
robustness. We evaluate the proposed approach (AMP+SAC) on quadruped gaits
involving multiple reference motions and diverse terrains. Experimental results
demonstrate that the proposed framework not only maintains stable task
execution but also achieves higher imitation rewards compared to the widely
used AMP+PPO method. These findings highlight the potential of an off-policy IL
formulation for advancing motion generation in robotics.

</details>


### [111] [Prompting Robot Teams with Natural Language](https://arxiv.org/abs/2509.24575)
*Nicolas Pfitzer,Eduardo Sebastián,Ajay Shankar,Amanda Prorok*

Main category: cs.RO

TL;DR: 本文提出了一种新的框架，通过自然语言表达高效指导多机器人团队执行高层任务，结合DFA和RNN，实现去中心化的协作，经过实验验证表现良好。


<details>
  <summary>Details</summary>
Motivation: 利用语言模型的推理能力，理解和分解人类表达的意图，以促进多机器人决策和协作。

Method: 采用确定性有限自动机（DFA）表示任务，并通过递归神经网络（RNN）编码多个自动机，结合图神经网络（GNN）控制策略。

Result: 在多种模拟和现实世界任务中，验证了该模型能够实现有效的无中心协作行为。

Conclusion: 本研究提出的框架在多机器人协作中展示了良好的有效性，能够利用语言模型的推理能力，使机器人高效执行任务。

Abstract: This paper presents a framework towards prompting multi-robot teams with
high-level tasks using natural language expressions. Our objective is to use
the reasoning capabilities demonstrated by recent language models in
understanding and decomposing human expressions of intent, and repurpose these
for multi-robot collaboration and decision-making. The key challenge is that an
individual's behavior in a collective can be hard to specify and interpret, and
must continuously adapt to actions from others. This necessitates a framework
that possesses the representational capacity required by the logic and
semantics of a task, and yet supports decentralized and interactive real-time
operation. We solve this dilemma by recognizing that a task can be represented
as a deterministic finite automaton (DFA), and that recurrent neural networks
(RNNs) can encode numerous automata. This allows us to distill the logic and
sequential decompositions of sub-tasks obtained from a language model into an
RNN, and align its internal states with the semantics of a given task. By
training a graph neural network (GNN) control policy that is conditioned on the
hidden states of the RNN and the language embeddings, our method enables robots
to execute task-relevant actions in a decentralized manner. We present
evaluations of this single light-weight interpretable model on various
simulated and real-world multi-robot tasks that require sequential and
collaborative behavior by the team -- sites.google.com/view/prompting-teams.

</details>


### [112] [U-DiT Policy: U-shaped Diffusion Transformers for Robotic Manipulation](https://arxiv.org/abs/2509.24579)
*Linzhi Wu,Aoran Mei,Xiyue Wang,Guo-Niu Zhu,Zhongxue Gan*

Main category: cs.RO

TL;DR: U-DiT是结合U-Net和变压器的新型扩散政策，解决了现有方法的局限，表现出卓越的性能和稳健性。


<details>
  <summary>Details</summary>
Motivation: 解决现有DP-U方法在全局上下文建模和过平滑伪影方面的局限性。

Method: 提出了一种新颖的U形扩散变压器框架（U-DiT），结合了U-Net的多尺度特征融合和变压器的全局上下文建模能力。

Result: U-DiT在仿真和现实世界的机器人操控任务中显著提高了性能，仿真中的平均性能提升为10\%，在真实机器人任务中提升了22.5%。

Conclusion: U-DiT Policy展示了在机器人操控中的有效性和实用潜力，是基于扩散的机器人操控的新基础。

Abstract: Diffusion-based methods have been acknowledged as a powerful paradigm for
end-to-end visuomotor control in robotics. Most existing approaches adopt a
Diffusion Policy in U-Net architecture (DP-U), which, while effective, suffers
from limited global context modeling and over-smoothing artifacts. To address
these issues, we propose U-DiT Policy, a novel U-shaped Diffusion Transformer
framework. U-DiT preserves the multi-scale feature fusion advantages of U-Net
while integrating the global context modeling capability of Transformers,
thereby enhancing representational power and policy expressiveness. We evaluate
U-DiT extensively across both simulation and real-world robotic manipulation
tasks. In simulation, U-DiT achieves an average performance gain of 10\% over
baseline methods and surpasses Transformer-based diffusion policies (DP-T) that
use AdaLN blocks by 6\% under comparable parameter budgets. On real-world
robotic tasks, U-DiT demonstrates superior generalization and robustness,
achieving an average improvement of 22.5\% over DP-U. In addition, robustness
and generalization experiments under distractor and lighting variations further
highlight the advantages of U-DiT. These results highlight the effectiveness
and practical potential of U-DiT Policy as a new foundation for diffusion-based
robotic manipulation.

</details>


### [113] [PoseDiff: A Unified Diffusion Model Bridging Robot Pose Estimation and Video-to-Action Control](https://arxiv.org/abs/2509.24591)
*Haozhuo Zhang,Michele Caprio,Jing Shao,Qiang Zhang,Jian Tang,Shanghang Zhang,Wei Pan*

Main category: cs.RO

TL;DR: PoseDiff是一个条件扩散模型，结合机器人状态估计与控制，提供高效且高精度的感知与决策能力。


<details>
  <summary>Details</summary>
Motivation: 为了统一机器人状态估计与控制，提高效率，消除多阶段管道或辅助模态的需求。

Method: 通过条件扩散模型将原始视觉观察映射为结构化的机器人状态，并利用稀疏视频关键帧生成平滑的长时域动作序列。

Result: PoseDiff在DREAM数据集上实现了最先进的精度和实时性能，在Libero-对象操控任务中显著提高了成功率。

Conclusion: PoseDiff为具身AI提供了可扩展、准确和高效的感知、规划与控制之间的桥梁。

Abstract: We present PoseDiff, a conditional diffusion model that unifies robot state
estimation and control within a single framework. At its core, PoseDiff maps
raw visual observations into structured robot states-such as 3D keypoints or
joint angles-from a single RGB image, eliminating the need for multi-stage
pipelines or auxiliary modalities. Building upon this foundation, PoseDiff
extends naturally to video-to-action inverse dynamics: by conditioning on
sparse video keyframes generated by world models, it produces smooth and
continuous long-horizon action sequences through an overlap-averaging strategy.
This unified design enables scalable and efficient integration of perception
and control. On the DREAM dataset, PoseDiff achieves state-of-the-art accuracy
and real-time performance for pose estimation. On Libero-Object manipulation
tasks, it substantially improves success rates over existing inverse dynamics
modules, even under strict offline settings. Together, these results show that
PoseDiff provides a scalable, accurate, and efficient bridge between
perception, planning, and control in embodied AI. The video visualization
results can be found on the project page:
https://haozhuo-zhang.github.io/PoseDiff-project-page/.

</details>


### [114] [CEDex: Cross-Embodiment Dexterous Grasp Generation at Scale from Human-like Contact Representations](https://arxiv.org/abs/2509.24661)
*Zhiyuan Wu,Rolandos Alexandros Potamias,Xuyang Zhang,Zhongqun Zhang,Jiankang Deng,Shan Luo*

Main category: cs.RO

TL;DR: CEDex是一种新型的跨体现灵巧抓握合成方法，通过对齐人类抓握与机器人运动学，构建了包含500K对象和2000万总抓握的巨大数据集，显著提升了抓握合成的性能。


<details>
  <summary>Details</summary>
Motivation: 实现机器人在不同环境中的多样化操作，且针对现有方法在数据收集和物理优化上的局限性。

Method: 通过对人类抓握姿态的生成与机器人运动学模型的对齐，结合条件变分自编码器和拓扑合并方法。

Result: CEDex超过了当前最先进的技术，并为跨体现的抓握学习提供了丰富的数据支持。

Conclusion: CEDex方法在跨体现灵巧抓握合成中表现优异，并构建了一个高质量多样性的抓握数据集。

Abstract: Cross-embodiment dexterous grasp synthesis refers to adaptively generating
and optimizing grasps for various robotic hands with different morphologies.
This capability is crucial for achieving versatile robotic manipulation in
diverse environments and requires substantial amounts of reliable and diverse
grasp data for effective model training and robust generalization. However,
existing approaches either rely on physics-based optimization that lacks
human-like kinematic understanding or require extensive manual data collection
processes that are limited to anthropomorphic structures. In this paper, we
propose CEDex, a novel cross-embodiment dexterous grasp synthesis method at
scale that bridges human grasping kinematics and robot kinematics by aligning
robot kinematic models with generated human-like contact representations. Given
an object's point cloud and an arbitrary robotic hand model, CEDex first
generates human-like contact representations using a Conditional Variational
Auto-encoder pretrained on human contact data. It then performs kinematic human
contact alignment through topological merging to consolidate multiple human
hand parts into unified robot components, followed by a signed distance
field-based grasp optimization with physics-aware constraints. Using CEDex, we
construct the largest cross-embodiment grasp dataset to date, comprising 500K
objects across four gripper types with 20M total grasps. Extensive experiments
show that CEDex outperforms state-of-the-art approaches and our dataset
benefits cross-embodiment grasp learning with high-quality diverse grasps.

</details>


### [115] [Stabilizing Humanoid Robot Trajectory Generation via Physics-Informed Learning and Control-Informed Steering](https://arxiv.org/abs/2509.24697)
*Evelyn D'Elia,Paolo Maria Viceconte,Lorenzo Rapetti,Diego Ferigo,Giulio Romualdi,Giuseppe L'Erario,Raffaello Camoriano,Daniele Pucci*

Main category: cs.RO

TL;DR: 本文提出一种双重学习策略，通过引入物理知识与控制原则，改善类人机器人的运动生成质量，增强了生成轨迹的稳定性与准确性。


<details>
  <summary>Details</summary>
Motivation: 解决现有模仿学习方法在运动数据有限和未考虑物理法则导致不稳定的问题。

Method: 采用双重学习策略，在监督模仿学习中嵌入物理先验，并在推理时应用比例-积分控制器以减少漂移。

Result: 在ergoCub类人机器人上验证了该方法，实验结果表明其能够兼容多种控制器，并有效鼓励零接触足部速度。

Conclusion: 该方法显著提高了生成轨迹的准确性和物理约束符合性，适用于多种控制器，实现了更合理的机器人运动生成。

Abstract: Recent trends in humanoid robot control have successfully employed imitation
learning to enable the learned generation of smooth, human-like trajectories
from human data. While these approaches make more realistic motions possible,
they are limited by the amount of available motion data, and do not incorporate
prior knowledge about the physical laws governing the system and its
interactions with the environment. Thus they may violate such laws, leading to
divergent trajectories and sliding contacts which limit real-world stability.
We address such limitations via a two-pronged learning strategy which leverages
the known physics of the system and fundamental control principles. First, we
encode physics priors during supervised imitation learning to promote
trajectory feasibility. Second, we minimize drift at inference time by applying
a proportional-integral controller directly to the generated output state. We
validate our method on various locomotion behaviors for the ergoCub humanoid
robot, where a physics-informed loss encourages zero contact foot velocity. Our
experiments demonstrate that the proposed approach is compatible with multiple
controllers on a real robot and significantly improves the accuracy and
physical constraint conformity of generated trajectories.

</details>


### [116] [LLM-Handover:Exploiting LLMs for Task-Oriented Robot-Human Handovers](https://arxiv.org/abs/2509.24706)
*Andreea Tulbure,Rene Zurbruegg,Timm Grigat,Marco Hutter*

Main category: cs.RO

TL;DR: 提出了一种新型框架LLM-Handover，以提高人机协作中的物品交接成功率，适应后续任务要求。


<details>
  <summary>Details</summary>
Motivation: 现有方法往往忽略人类在交接后的动作，导致在应用中的局限性。

Method: 整合大语言模型（LLM）推理与部件分割，利用RGB-D图像和任务描述推断相关物体部件并选择最佳抓取方式。

Result: LLM-Handover在60个家庭物品的测试中表现出83%的抓取成功率，并在用户研究中被在86%的情况下优于其他方法。

Conclusion: LLM-Handover 提供了一种上下文感知的抓取选择方法，显著提高了人机协作中的物品交接效率与成功率。

Abstract: Effective human-robot collaboration depends on task-oriented handovers, where
robots present objects in ways that support the partners intended use. However,
many existing approaches neglect the humans post-handover action, relying on
assumptions that limit generalizability. To address this gap, we propose
LLM-Handover, a novel framework that integrates large language model
(LLM)-based reasoning with part segmentation to enable context-aware grasp
selection and execution. Given an RGB-D image and a task description, our
system infers relevant object parts and selects grasps that optimize
post-handover usability. To support evaluation, we introduce a new dataset of
60 household objects spanning 12 categories, each annotated with detailed part
labels. We first demonstrate that our approach improves the performance of the
used state-of-the-art part segmentation method, in the context of robot-human
handovers. Next, we show that LLM-Handover achieves higher grasp success rates
and adapts better to post-handover task constraints. During hardware
experiments, we achieve a success rate of 83% in a zero-shot setting over
conventional and unconventional post-handover tasks. Finally, our user study
underlines that our method enables more intuitive, context-aware handovers,
with participants preferring it in 86% of cases.

</details>


### [117] [APREBot: Active Perception System for Reflexive Evasion Robot](https://arxiv.org/abs/2509.24733)
*Zihao Xu,Kuankuan Sima,Junhao Deng,Zixuan Zhuang,Chunzheng Wang,Ce Hao,Jin Song Dong*

Main category: cs.RO

TL;DR: APREBot是一种新型的集成反射逃避与主动感知的框架，解决了四足机器人在动态环境中感知不足的问题，显著提高了安全性与操作效率。


<details>
  <summary>Details</summary>
Motivation: 在动态环境中，四足机器人的可靠感知对其导航至关重要，传统单传感器系统存在视野或细节信息不足的局限。

Method: 提出了一种新的框架，将基于LiDAR的全向扫描与基于相机的主动聚焦相结合，实现了层次化的主动感知与反射逃避。

Result: 通过广泛的仿真到现实实验，APREBot在安全性指标和操作效率上相较于现有基线有显著提升。

Conclusion: APREBot显著提升了四足机器人在复杂环境中的感知能力和障碍物回避效率，证明其在安全关键场景中的可靠自主性。

Abstract: Reliable onboard perception is critical for quadruped robots navigating
dynamic environments, where obstacles can emerge from any direction under
strict reaction-time constraints. Single-sensor systems face inherent
limitations: LiDAR provides omnidirectional coverage but lacks rich texture
information, while cameras capture high-resolution detail but suffer from
restricted field of view. We introduce APREBot (Active Perception System for
Reflexive Evasion Robot), a novel framework that integrates reflexive evasion
with active hierarchical perception. APREBot strategically combines LiDAR-based
omnidirectional scanning with camera-based active focusing, achieving
comprehensive environmental awareness essential for agile obstacle avoidance in
quadruped robots. We validate APREBot through extensive sim-to-real experiments
on a quadruped platform, evaluating diverse obstacle types, trajectories, and
approach directions. Our results demonstrate substantial improvements over
state-of-the-art baselines in both safety metrics and operational efficiency,
highlighting APREBot's potential for dependable autonomy in safety-critical
scenarios. Videos are available at https://sites.google.com/view/aprebot/

</details>


### [118] [SSR-ZSON: Zero-Shot Object Navigation via Spatial-Semantic Relations within a Hierarchical Exploration Framework](https://arxiv.org/abs/2509.24763)
*Xiangyi Meng,Delun Li,Zihao Mao,Yi Yang,Wenjie Song*

Main category: cs.RO

TL;DR: 本文提出的SSR-ZSON通过优化视点生成和全局指导机制，显著提高了在未知环境中的物体导航性能。


<details>
  <summary>Details</summary>
Motivation: 解决未知环境中零-shot物体导航的效率低下和局部困境问题。

Method: 提出了一种空间-语义相对零-shot对象导航方法SSR-ZSON，基于TARE分层探索框架，采用视点生成策略和LLM全球指导机制。

Result: SSR-ZSON在Matterport3D和Habitat-Matterport3D数据集上，成功率提高18.5%和11.2%，路径长度加权成功率分别提高0.181和0.140。

Conclusion: SSR-ZSON在未知环境中的物体导航任务中，通过整合空间-语义相对方法和LLM全球指导机制，实现了实时操作和显著的性能提升。

Abstract: Zero-shot object navigation in unknown environments presents significant
challenges, mainly due to two key limitations: insufficient semantic guidance
leads to inefficient exploration, while limited spatial memory resulting from
environmental structure causes entrapment in local regions. To address these
issues, we propose SSR-ZSON, a spatial-semantic relative zero-shot object
navigation method based on the TARE hierarchical exploration framework,
integrating a viewpoint generation strategy balancing spatial coverage and
semantic density with an LLM-based global guidance mechanism. The performance
improvement of the proposed method is due to two key innovations. First, the
viewpoint generation strategy prioritizes areas of high semantic density within
traversable sub-regions to maximize spatial coverage and minimize invalid
exploration. Second, coupled with an LLM-based global guidance mechanism, it
assesses semantic associations to direct navigation toward high-value spaces,
preventing local entrapment and ensuring efficient exploration. Deployed on
hybrid Habitat-Gazebo simulations and physical platforms, SSR-ZSON achieves
real-time operation and superior performance. On Matterport3D and
Habitat-Matterport3D datasets, it improves the Success Rate(SR) by 18.5\% and
11.2\%, and the Success weighted by Path Length(SPL) by 0.181 and 0.140,
respectively, over state-of-the-art methods.

</details>


### [119] [IA-VLA: Input Augmentation for Vision-Language-Action models in settings with semantically complex tasks](https://arxiv.org/abs/2509.24768)
*Eric Hannus,Miika Malin,Tran Nguyen Le,Ville Kyrki*

Main category: cs.RO

TL;DR: IA-VLA是一种新框架，通过大规模语言模型的预处理增强VLA，在处理复杂操纵任务时提高了模型性能。


<details>
  <summary>Details</summary>
Motivation: 为了克服传统VLA在快速输出动作时面临的语言理解能力限制，并处理复杂的操纵任务。

Method: 通过引入大规模视觉语言模型进行预处理，增强VLA的输入上下文。

Result: 在对比实验中，增强后的VLA在处理视觉相似对象的复杂任务时表现优于基线VLA。

Conclusion: IA-VLA框架显著提高了视觉语言行动模型在处理复杂任务时的性能，尤其是在面对具有语义重复对象的语言指令时。

Abstract: Vision-language-action models (VLAs) have become an increasingly popular
approach for addressing robot manipulation problems in recent years. However,
such models need to output actions at a rate suitable for robot control, which
limits the size of the language model they can be based on, and consequently,
their language understanding capabilities. Manipulation tasks may require
complex language instructions, such as identifying target objects by their
relative positions, to specify human intention. Therefore, we introduce IA-VLA,
a framework that utilizes the extensive language understanding of a large
vision language model as a pre-processing stage to generate improved context to
augment the input of a VLA. We evaluate the framework on a set of semantically
complex tasks which have been underexplored in VLA literature, namely tasks
involving visual duplicates, i.e., visually indistinguishable objects. A
dataset of three types of scenes with duplicate objects is used to compare a
baseline VLA against two augmented variants. The experiments show that the VLA
benefits from the augmentation scheme, especially when faced with language
instructions that require the VLA to extrapolate from concepts it has seen in
the demonstrations. For the code, dataset, and videos, see
https://sites.google.com/view/ia-vla.

</details>


### [120] [Fidelity-Aware Data Composition for Robust Robot Generalization](https://arxiv.org/abs/2509.24797)
*Zizhao Tong,Di Chen,Sicheng Hu,Hongwei Fan,Liliang Chen,Guanghui Ren,Hao Tang,Hao Dong,Ling Shao*

Main category: cs.RO

TL;DR: CIFT框架通过注重信息保真度的数据组成，显著提高了机器人的OOD泛化能力，是构建稳健通用机器人的关键。


<details>
  <summary>Details</summary>
Motivation: 针对大规模、视觉同质性数据集上训练的通用机器人策略易受捷径学习影响的问题，提出了一种新的数据组成方法以提高其OOD泛化能力。

Method: 提出了CIFT框架，将数据组成视为一个优化问题，并使用基于特征空间几何的保真度代理来识别训练稳定性退化的转折点。

Result: 应用CIFT框架于政策架构如π0和Diffusion Policy，将OOD成功率提高了超过54%。

Conclusion: 通过引入CIFT框架以及有意识的数据组成，可以显著提高机器人的OOD成功率，表明注重信息保真度的数据组成对于构建稳健的通用机器人至关重要。

Abstract: Generalist robot policies trained on large-scale, visually homogeneous
datasets can be susceptible to shortcut learning, which impairs their
out-of-distribution (OOD) generalization. While generative data augmentation is
a common approach to introduce diversity, it presents a subtle challenge: data
composition. Naively mixing real and synthetic data can corrupt the learning
signal, as this process often prioritizes visual diversity at the expense of
information fidelity. This paper suggests that robust generalization depends on
principled, fidelity-aware data composition. We introduce Coherent Information
Fidelity Tuning (CIFT), a framework that treats data composition as an
optimization problem. CIFT uses a practical proxy for Information Fidelity
based on the feature-space geometry of a dataset. This enables the
identification of a phase transition, termed the Decoherence Point, where
training stability degrades. The framework includes a generative engine,
Multi-View Video Augmentation (MVAug), to synthesize a causally disentangled
data spectrum for this tuning process. Applying CIFT to policy architectures
such as $\pi_0$ and Diffusion Policy improves OOD success rates by over 54\%.
These results indicate that fidelity-aware composition, beyond data synthesis
alone, is an important component for developing robust, general-purpose robots.

</details>


### [121] [Towards Modular and Accessible AUV Systems](https://arxiv.org/abs/2509.24864)
*Mingxi Zhou,Farhang Naderi,Yuewei Fu,Tony Jacob,Lin Zhao,Manavi Panjnani,Chengzhi Yuan,William McConnell,Emir Cem Gezer*

Main category: cs.RO

TL;DR: 本研究提出了一种新的开放式模块化框架MVP，旨在提升自主水下车辆的构建自定义性和功能，实现了可扩展的硬件和软件设计，通过实验验证了其性能。


<details>
  <summary>Details</summary>
Motivation: 为了提供一个更灵活、开放且可定制的框架，以满足自主水下车辆的研究需求。

Method: 通过硬件系统设计和模块化软件设计架构实现AUV的构建，强调可定制性与负载能力。

Result: 通过模拟和现场实验结果，验证了MVP的性能与兼容性。

Conclusion: MVP框架展示了其在水下自主车辆应用中的可扩展性和兼容性，适合研究需求。

Abstract: This paper reports the development of a new open-access modular framework,
called Marine Vehicle Packages (MVP), for Autonomous Underwater Vehicles. The
framework consists of both software and hardware designs allowing easy
construction of AUV for research with increased customizability and sufficient
payload capacity. This paper will present the scalable hardware system design
and the modular software design architecture. New features, such as articulated
thruster integration and high-level Graphic User Interface will be discussed.
Both simulation and field experiments results are shown to highlight the
performance and compatibility of the MVP.

</details>


### [122] [Finding an Initial Probe Pose in Teleoperated Robotic Echocardiography via 2D LiDAR-Based 3D Reconstruction](https://arxiv.org/abs/2509.24867)
*Mariadas Capsran Roshan,Edgar M Hidalgo,Mats Isaksson,Michelle Dunn,Jagannatha Charjee Pyaraka*

Main category: cs.RO

TL;DR: 本研究提议一种基于2D LiDAR的自动探头定位方法，通过3D重建胸部表面来提高远程超声检查的效率。


<details>
  <summary>Details</summary>
Motivation: 为了减少远程操作超声检查中的操作负担，自动化非专家任务，如自动调整探头至理想起始位置，是解决方案之一。

Method: 使用机器人搭载的2D LiDAR对人体胸部表面进行3D重建，并通过平面外部标定估计LiDAR与机器人基座之间的变换。

Result: 在平面外部标定后，LiDAR与机器人基座的总均方根残差为1.8毫米，旋转的不确定性低于0.2°。

Conclusion: 提出的基于2D LiDAR的探头定位方法在重建胸部表面和估计初始探头位置方面表现出相对较高的准确性，但在实际应用中尚存在改进空间。

Abstract: Echocardiography is a key imaging modality for cardiac assessment but remains
highly operator-dependent, and access to trained sonographers is limited in
underserved settings. Teleoperated robotic echocardiography has been proposed
as a solution; however, clinical studies report longer examination times than
manual procedures, increasing diagnostic delays and operator workload.
Automating non-expert tasks, such as automatically moving the probe to an ideal
starting pose, offers a pathway to reduce this burden. Prior vision- and
depth-based approaches to estimate an initial probe pose are sensitive to
lighting, texture, and anatomical variability. We propose a robot-mounted 2D
LiDAR-based approach that reconstructs the chest surface in 3D and estimates
the initial probe pose automatically. To the best of our knowledge, this is the
first demonstration of robot-mounted 2D LiDAR used for 3D reconstruction of a
human body surface. Through plane-based extrinsic calibration, the
transformation between the LiDAR and robot base frames was estimated with an
overall root mean square (RMS) residual of 1.8 mm and rotational uncertainty
below 0.2{\deg}. The chest front surface, reconstructed from two linear LiDAR
sweeps, was aligned with non-rigid templates to identify an initial probe pose.
A mannequin-based study assessing reconstruction accuracy showed mean surface
errors of 2.78 +/- 0.21 mm. Human trials (N=5) evaluating the proposed approach
found probe initial points typically 20-30 mm from the clinically defined
initial point, while the variation across repeated trials on the same subject
was less than 4 mm.

</details>


### [123] [JuggleRL: Mastering Ball Juggling with a Quadrotor via Deep Reinforcement Learning](https://arxiv.org/abs/2509.24892)
*Shilong Ji,Yinuo Chen,Chuqi Wang,Jiayu Chen,Ruize Zhang,Feng Gao,Wenhao Tang,Shu'ang Yu,Sirui Xiang,Xinlei Chen,Chao Yu,Yu Wang*

Main category: cs.RO

TL;DR: 本论文提出JuggleRL，一个基于强化学习的空中玩球系统，展示其在现实世界中卓越的表现和对动态任务的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 探讨空中机器人在不确定性下执行精确的接触丰富操作的能力，特别是在空中玩球中的应用。

Method: 提出了JuggleRL，一个基于强化学习的系统，通过系统校准四旋翼和球的动态，学习闭环策略，并在大型模拟环境中进行训练。

Result: JuggleRL在现实世界中的实验中平均实现311次击球，远超模型基础的基线，且在未见条件下成功对较轻的5克球进行空中玩球。

Conclusion: 本研究展示了强化学习能够为空中机器人在动态交互任务中提供稳健和稳定的控制能力，尤其是在空中玩球的情况下，取得了出色的实验证明。

Abstract: Aerial robots interacting with objects must perform precise, contact-rich
maneuvers under uncertainty. In this paper, we study the problem of aerial ball
juggling using a quadrotor equipped with a racket, a task that demands accurate
timing, stable control, and continuous adaptation. We propose JuggleRL, the
first reinforcement learning-based system for aerial juggling. It learns
closed-loop policies in large-scale simulation using systematic calibration of
quadrotor and ball dynamics to reduce the sim-to-real gap. The training
incorporates reward shaping to encourage racket-centered hits and sustained
juggling, as well as domain randomization over ball position and coefficient of
restitution to enhance robustness and transferability. The learned policy
outputs mid-level commands executed by a low-level controller and is deployed
zero-shot on real hardware, where an enhanced perception module with a
lightweight communication protocol reduces delays in high-frequency state
estimation and ensures real-time control. Experiments show that JuggleRL
achieves an average of $311$ hits over $10$ consecutive trials in the real
world, with a maximum of $462$ hits observed, far exceeding a model-based
baseline that reaches at most $14$ hits with an average of $3.1$. Moreover, the
policy generalizes to unseen conditions, successfully juggling a lighter $5$ g
ball with an average of $145.9$ hits. This work demonstrates that reinforcement
learning can empower aerial robots with robust and stable control in dynamic
interaction tasks.

</details>


### [124] [DRCP: Diffusion on Reinforced Cooperative Perception for Perceiving Beyond Limits](https://arxiv.org/abs/2509.24903)
*Lantao Li,Kang Yang,Rui Song,Chen Sun*

Main category: cs.RO

TL;DR: 本研究提出了一种新型的实时合作感知框架，旨在通过改进模块提升智能车辆在复杂环境中的感知能力和可靠性。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在克服现有合作感知方法在复杂环境中存在的局限性，特别是针对部分检测和噪声积累带来的挑战。

Method: 此研究提出了一种集成精确金字塔跨模态跨代理的合作感知模块和基于扩散的掩膜聚合模块的方法。

Result: DRCP系统显著提高了在挑战条件下的检测精度和鲁棒性。

Conclusion: DRCP系统在动态驾驶环境中展示了出色的实时性能和鲁棒性。

Abstract: Cooperative perception enabled by Vehicle-to-Everything communication has
shown great promise in enhancing situational awareness for autonomous vehicles
and other mobile robotic platforms. Despite recent advances in perception
backbones and multi-agent fusion, real-world deployments remain challenged by
hard detection cases, exemplified by partial detections and noise accumulation
which limit downstream detection accuracy. This work presents Diffusion on
Reinforced Cooperative Perception (DRCP), a real-time deployable framework
designed to address aforementioned issues in dynamic driving environments. DRCP
integrates two key components: (1) Precise-Pyramid-Cross-Modality-Cross-Agent,
a cross-modal cooperative perception module that leverages
camera-intrinsic-aware angular partitioning for attention-based fusion and
adaptive convolution to better exploit external features; and (2)
Mask-Diffusion-Mask-Aggregation, a novel lightweight diffusion-based refinement
module that encourages robustness against feature perturbations and aligns
bird's-eye-view features closer to the task-optimal manifold. The proposed
system achieves real-time performance on mobile platforms while significantly
improving robustness under challenging conditions. Code will be released in
late 2025.

</details>


### [125] [Real-time Recognition of Human Interactions from a Single RGB-D Camera for Socially-Aware Robot Navigation](https://arxiv.org/abs/2509.24907)
*Thanh Long Nguyen,Duc Phu Nguyen,Thanh Thao Ton Nu,Quan Le,Thuan Hoang Tran,Manh Duong Phung*

Main category: cs.RO

TL;DR: 本论文提出了一种框架，用于识别群体人际互动，助力社会性导航，具备快速处理能力，可整合至现有机器人系统。


<details>
  <summary>Details</summary>
Motivation: 传统机器人系统通常关注障碍物规避，忽视了流畅的人机交互所需的社交线索，因此提出一个框架来识别群体人际互动以实现社会意识导航。

Method: 利用单目RGB-D相机获取的颜色和深度帧估计3D人类关键点和位置，使用主成分分析（PCA）确定主导互动方向，再应用鞋带公式计算兴趣点和参与区域。

Result: 实验表明，该方法在不同人数的场景中识别群体互动的能力强，且在单板计算机上处理每帧的速度约为4毫秒。

Conclusion: 我们的方法能够在不同场景中有效识别群体互动，并能快速处理数据，适用于现有的导航系统。

Abstract: {Recognizing human interactions is essential for social robots as it enables
them to navigate safely and naturally in shared environments. Conventional
robotic systems however often focus on obstacle avoidance, neglecting social
cues necessary for seamless human-robot interaction. To address this gap, we
propose a framework to recognize human group interactions for socially aware
navigation. Our method utilizes color and depth frames from a monocular RGB-D
camera to estimate 3D human keypoints and positions. Principal component
analysis (PCA) is then used to determine dominant interaction directions. The
shoelace formula is finally applied to compute interest points and engagement
areas. Extensive experiments have been conducted to evaluate the validity of
the proposed method. The results show that our method is capable of recognizing
group interactions across different scenarios with varying numbers of
individuals. It also achieves high-speed performance, processing each frame in
approximately 4 ms on a single-board computer used in robotic systems. The
method is implemented as a ROS 2 package making it simple to integrate into
existing navigation systems. Source code is available at
https://github.com/thanhlong103/social-interaction-detector

</details>


### [126] [From Code to Action: Hierarchical Learning of Diffusion-VLM Policies](https://arxiv.org/abs/2509.24917)
*Markus Peschl,Pietro Mazzaglia,Daniel Dijkman*

Main category: cs.RO

TL;DR: 提出了一种分层框架，利用视觉-语言模型和扩散策略改善机器人模仿学习的泛化能力与可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决模仿学习在复杂且长时间任务中面临的有限泛化和数据稀缺问题。

Method: 训练一个视觉-语言模型，将任务描述分解为可执行的子程序，并通过扩散策略模仿机器人行为。

Result: 该设计提高了可解释性，改善了与平坦策略的比较中的泛化能力，并允许对高层规划和低层控制进行单独评估。

Conclusion: 这种分层框架通过结合代码生成的视觉-语言模型和低级扩散策略，实现了对机器人行为的有效模仿和泛化。

Abstract: Imitation learning for robotic manipulation often suffers from limited
generalization and data scarcity, especially in complex, long-horizon tasks. In
this work, we introduce a hierarchical framework that leverages code-generating
vision-language models (VLMs) in combination with low-level diffusion policies
to effectively imitate and generalize robotic behavior. Our key insight is to
treat open-source robotic APIs not only as execution interfaces but also as
sources of structured supervision: the associated subtask functions - when
exposed - can serve as modular, semantically meaningful labels. We train a VLM
to decompose task descriptions into executable subroutines, which are then
grounded through a diffusion policy trained to imitate the corresponding robot
behavior. To handle the non-Markovian nature of both code execution and certain
real-world tasks, such as object swapping, our architecture incorporates a
memory mechanism that maintains subtask context across time. We find that this
design enables interpretable policy decomposition, improves generalization when
compared to flat policies and enables separate evaluation of high-level
planning and low-level control.

</details>


### [127] [CineWild: Balancing Art and Robotics for Ethical Wildlife Documentary Filmmaking](https://arxiv.org/abs/2509.24921)
*Pablo Pueyo,Fernando Caballero,Ana Cristina Murillo,Eduardo Montijano*

Main category: cs.RO

TL;DR: 本论文提出CineWild，一个结合机器人技术、电影拍摄与伦理的自主无人机框架，旨在提高纪录片拍摄质量，同时保护野生动物。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于利用无人机改变纪录片拍摄方式，但同时需解决对动物的潜在干扰问题。

Method: 在该论文中，使用了模型预测控制的自主无人机框架，能够动态调整飞行路径和摄像机设置。

Result: CineWild具有自适应变焦、避开动物视野的路径规划和低噪声操作等重要特性，成功验证了系统的有效性。

Conclusion: CineWild展示了工程、视觉叙事与环境伦理的跨学科创新，旨在提升野生动物纪录片的拍摄质量，同时保障动物福利。

Abstract: Drones, or unmanned aerial vehicles (UAVs), have become powerful tools across
domains-from industry to the arts. In documentary filmmaking, they offer
dynamic, otherwise unreachable perspectives, transforming how stories are told.
Wildlife documentaries especially benefit, yet drones also raise ethical
concerns: the risk of disturbing the animals they aim to capture. This paper
introduces CineWild, an autonomous UAV framework that combines robotics,
cinematography, and ethics. Built on model predictive control, CineWild
dynamically adjusts flight paths and camera settings to balance cinematic
quality with animal welfare. Key features include adaptive zoom for filming
from acoustic and visual safe distances, path-planning that avoids an animal's
field of view, and smooth, low-noise maneuvers. CineWild exemplifies
interdisciplinary innovation-bridging engineering, visual storytelling, and
environmental ethics. We validate the system through simulation studies and
will release the code upon acceptance.

</details>


### [128] [Trajectory Prediction via Bayesian Intention Inference under Unknown Goals and Kinematics](https://arxiv.org/abs/2509.24928)
*Shunan Yin,Zehui Lu,Shaoshuai Mou*

Main category: cs.RO

TL;DR: 引入一种自适应贝叶斯算法，实时预测目标轨迹，显著优于传统方法，适用于多种机器人系统。


<details>
  <summary>Details</summary>
Motivation: 在目标意图和运动特征未知且可能变化的情况下，实现更准确和鲁棒的轨迹预测。

Method: 引入自适应贝叶斯算法，通过推断目标意图和运动特征进行实时轨迹预测，同时估计目标的当前意图和意图参数。

Result: 通过数值实验和硬件演示验证，提出的方法在预测精度和实时性上表现优越。

Conclusion: 该方法在瞬时轨迹预测中优于非自适应和部分自适应方法，具备高实时性和广泛适用性。

Abstract: This work introduces an adaptive Bayesian algorithm for real-time trajectory
prediction via intention inference, where a target's intentions and motion
characteristics are unknown and subject to change. The method concurrently
estimates two critical variables: the target's current intention, modeled as a
Markovian latent state, and an intention parameter that describes the target's
adherence to a shortest-path policy. By integrating this joint update
technique, the algorithm maintains robustness against abrupt intention shifts
and unknown motion dynamics. A sampling-based trajectory prediction mechanism
then exploits these adaptive estimates to generate probabilistic forecasts with
quantified uncertainty. We validate the framework through numerical
experiments: Ablation studies of two cases, and a 500-trial Monte Carlo
analysis; Hardware demonstrations on quadrotor and quadrupedal platforms.
Experimental results demonstrate that the proposed approach significantly
outperforms non-adaptive and partially adaptive methods. The method operates in
real time around 270 Hz without requiring training or detailed prior knowledge
of target behavior, showcasing its applicability in various robotic systems.

</details>


### [129] [World-Env: Leveraging World Model as a Virtual Environment for VLA Post-Training](https://arxiv.org/abs/2509.24948)
*Junjin Xiao,Yandan Yang,Xinyuan Chang,Ronghan Chen,Feng Xiong,Mu Xu,Wei-Shi Zheng,Qing Zhang*

Main category: cs.RO

TL;DR: 本研究提出World-Env框架，利用虚拟模拟器改善VLA模型在数据稀缺和高风险环境中的性能，显著提升任务成功率。


<details>
  <summary>Details</summary>
Motivation: 解决VLA模型在数据稀缺情况下性能下降的问题，以及现实世界环境带来的不可重置性限制，特别是在工业自动化等高风险领域。

Method: 提出了一个基于RL的后训练框架World-Env，采用低成本的世界模型基础虚拟模拟器，辅助VLA模型学习和探索。

Result: 通过使用World-Env，VLA模型在仅有五个专家演示的情况下，显著提升了在复杂机器人操控任务上的表现。

Conclusion: World-Env在处理数据效率、安全约束和传统VLA模型在真实环境互动中的低效执行方面有效，提供了一种在资源受限环境下可行且可扩展的后训练解决方案。

Abstract: Vision-Language-Action (VLA) models trained via imitation learning suffer
from significant performance degradation in data-scarce scenarios due to their
reliance on large-scale demonstration datasets. Although reinforcement learning
(RL)-based post-training has proven effective in addressing data scarcity, its
application to VLA models is hindered by the non-resettable nature of
real-world environments. This limitation is particularly critical in high-risk
domains such as industrial automation, where interactions often induce state
changes that are costly or infeasible to revert. Furthermore, existing VLA
approaches lack a reliable mechanism for detecting task completion, leading to
redundant actions that reduce overall task success rates. To address these
challenges, we propose World-Env, an RL-based post-training framework that
replaces physical interaction with a low-cost, world model-based virtual
simulator. World-Env consists of two key components: (1) a video-based world
simulator that generates temporally consistent future visual observations, and
(2) a vision-language model (VLM)-guided instant reflector that provides
continuous reward signals and predicts action termination. This simulated
environment enables VLA models to safely explore and generalize beyond their
initial imitation learning distribution. Our method achieves notable
performance gains with as few as five expert demonstrations per task.
Experiments on complex robotic manipulation tasks demonstrate that World-Env
effectively overcomes the data inefficiency, safety constraints, and
inefficient execution of conventional VLA models that rely on real-world
interaction, offering a practical and scalable solution for post-training in
resource-constrained settings.

</details>


### [130] [MSG: Multi-Stream Generative Policies for Sample-Efficient Robotic Manipulation](https://arxiv.org/abs/2509.24956)
*Jan Ole von Hartz,Lukas Schweizer,Joschka Boedecker,Abhinav Valada*

Main category: cs.RO

TL;DR: 提出了一种新的多流生成策略（MSG），通过组合多种对象中心政策提高生成效率与性能。


<details>
  <summary>Details</summary>
Motivation: 解决生成机器人政策在样本效率上的不足，同时提升多模态学习能力。

Method: 通过训练多个面向对象的策略，并在推理时组合它们以提升性能。

Result: 在仅有五次演示的情况下实现95%的演示减少，策略性能提高了89%。

Conclusion: Multi-Stream Generative Policy (MSG)显著提高了生成策略的样本效率和通用性，相较于单流方法，表现更佳。

Abstract: Generative robot policies such as Flow Matching offer flexible, multi-modal
policy learning but are sample-inefficient. Although object-centric policies
improve sample efficiency, it does not resolve this limitation. In this work,
we propose Multi-Stream Generative Policy (MSG), an inference-time composition
framework that trains multiple object-centric policies and combines them at
inference to improve generalization and sample efficiency. MSG is
model-agnostic and inference-only, hence widely applicable to various
generative policies and training paradigms. We perform extensive experiments
both in simulation and on a real robot, demonstrating that our approach learns
high-quality generative policies from as few as five demonstrations, resulting
in a 95% reduction in demonstrations, and improves policy performance by 89
percent compared to single-stream approaches. Furthermore, we present
comprehensive ablation studies on various composition strategies and provide
practical recommendations for deployment. Finally, MSG enables zero-shot object
instance transfer. We make our code publicly available at
https://msg.cs.uni-freiburg.de.

</details>


### [131] [Annotation-Free One-Shot Imitation Learning for Multi-Step Manipulation Tasks](https://arxiv.org/abs/2509.24972)
*Vijja Wichitwechkarn,Emlyn Williams,Charles Fox,Ruchi Choudhary*

Main category: cs.RO

TL;DR: 我们提出了一种新的单次模仿学习方法，能够在无额外训练的情况下有效处理多步骤任务，且在多项实验中表现优异。


<details>
  <summary>Details</summary>
Motivation: 尽管现有方法在单步骤任务上表现良好，但在多步骤任务中存在局限性。

Method: 我们提出了一种新方法，能够在只有单一示范的情况下，不需额外模型训练或手动标注，应用于多步骤任务。

Result: 在多步骤和单步骤操控任务中，我们的方法分别达到了82.5%和90%的平均成功率，超越了基准的表现。

Conclusion: 我们的方法在多步骤和单步骤操控任务中均表现优越，展示了强大的适应能力。

Abstract: Recent advances in one-shot imitation learning have enabled robots to acquire
new manipulation skills from a single human demonstration. While existing
methods achieve strong performance on single-step tasks, they remain limited in
their ability to handle long-horizon, multi-step tasks without additional model
training or manual annotation. We propose a method that can be applied to this
setting provided a single demonstration without additional model training or
manual annotation. We evaluated our method on multi-step and single-step
manipulation tasks where our method achieves an average success rate of 82.5%
and 90%, respectively. Our method matches and exceeds the performance of the
baselines in both these cases. We also compare the performance and
computational efficiency of alternative pre-trained feature extractors within
our framework.

</details>


### [132] [Path Diffuser: Diffusion Model for Data-Driven Traffic Simulator](https://arxiv.org/abs/2509.24995)
*Da Saem Lee,Akash Karthikeyan,Yash Vardhan Pant,Sebastian Fischmeister*

Main category: cs.RO

TL;DR: 本研究提出了Path Diffuser，一种新型扩散模型，用于生成多样化且符合道路规则的交通场景，显著提高了传统方法的性能。


<details>
  <summary>Details</summary>
Motivation: 当前的学习基础模拟器依赖于完全标注的历史数据，限制了其可扩展性和多样性，因此需要一种新的方法来生成现实的交通场景。

Method: 提出了一种两阶段的扩散模型Path Diffuser，用于生成初始位置和相应轨迹，依赖于地图信息，而不需要历史轨迹数据。

Result: Path Diffuser在Argoverse2数据集上的实验结果显示，该方法在分布指标上超过了基线方法1.92倍，在常识指标上超过1.14倍，在道路遵循性上超过1.62倍。

Conclusion: Path Diffuser方法在生成多样化和符合道路规则的交通场景方面优于传统方法，尤其在应对分布外场景时效果显著。

Abstract: Simulating diverse and realistic traffic scenarios is critical for developing
and testing autonomous planning. Traditional rule-based planners lack diversity
and realism, while learning-based simulators often replay, forecast, or edit
scenarios using historical agent trajectories. However, they struggle to
generate new scenarios, limiting scalability and diversity due to their
reliance on fully annotated logs and historical data. Thus, a key challenge for
a learning-based simulator's performance is that it requires agents' past
trajectories and pose information in addition to map data, which might not be
available for all agents on the road.Without which, generated scenarios often
produce unrealistic trajectories that deviate from drivable areas, particularly
under out-of-distribution (OOD) map scenes (e.g., curved roads). To address
this, we propose Path Diffuser (PD): a two-stage, diffusion model for
generating agent pose initializations and their corresponding trajectories
conditioned on the map, free of any historical context of agents' trajectories.
Furthermore, PD incorporates a motion primitive-based prior, leveraging Frenet
frame candidate trajectories to enhance diversity while ensuring road-compliant
trajectory generation. We also explore various design choices for modeling
complex multi-agent interactions. We demonstrate the effectiveness of our
method through extensive experiments on the Argoverse2 Dataset and additionally
evaluate the generalizability of the approach on OOD map variants. Notably,
Path Diffuser outperforms the baseline methods by 1.92x on distribution
metrics, 1.14x on common-sense metrics, and 1.62x on road compliance from
adversarial benchmarks.

</details>


### [133] [AIRoA MoMa Dataset: A Large-Scale Hierarchical Dataset for Mobile Manipulation](https://arxiv.org/abs/2509.25032)
*Ryosuke Takanami,Petr Khrapchenkov,Shu Morikuni,Jumpei Arima,Yuta Takaba,Shunsuke Maeda,Takuya Okubo,Genki Sano,Satoshi Sekioka,Aoi Kadoya,Motonari Kambara,Naoya Nishiura,Haruto Suzuki,Takanori Yoshimoto,Koya Sakamoto,Shinnosuke Ono,Hu Yang,Daichi Yashima,Aoi Horo,Tomohiro Motoda,Kensuke Chiyoma,Hiroshi Ito,Koki Fukuda,Akihito Goto,Kazumi Morinaga,Yuya Ikeda,Riko Kawada,Masaki Yoshikawa,Norio Kosuge,Yuki Noguchi,Kei Ota,Tatsuya Matsushima,Yusuke Iwasawa,Yutaka Matsuo,Tetsuya Ogata*

Main category: cs.RO

TL;DR: AIRoA MoMa数据集是一个大规模多模态数据集，旨在解决移动操纵中的挑战，以推动视觉-语言-动作模型的发展。


<details>
  <summary>Details</summary>
Motivation: 旨在填补现有多模态数据集中缺乏同步力-扭矩感应、高阶注释和显式失败案例的不足，从而促进复杂任务的研究。

Method: 构建了包含RGB图像、关节状态、六轴手腕力-扭矩信号和内部机器人状态的大规模多模态数据集，并采用了新的两层注释结构。

Result: 初步数据集包含25,469个episod（约94小时），标准化为LeRobot v2.1格式，支持移动操纵和长期任务分析。

Conclusion: AIRoA MoMa数据集为移动操纵任务提供了一个关键的基准，助力下一代视觉-语言-动作模型的进步。

Abstract: As robots transition from controlled settings to unstructured human
environments, building generalist agents that can reliably follow natural
language instructions remains a central challenge. Progress in robust mobile
manipulation requires large-scale multimodal datasets that capture contact-rich
and long-horizon tasks, yet existing resources lack synchronized force-torque
sensing, hierarchical annotations, and explicit failure cases. We address this
gap with the AIRoA MoMa Dataset, a large-scale real-world multimodal dataset
for mobile manipulation. It includes synchronized RGB images, joint states,
six-axis wrist force-torque signals, and internal robot states, together with a
novel two-layer annotation schema of sub-goals and primitive actions for
hierarchical learning and error analysis. The initial dataset comprises 25,469
episodes (approx. 94 hours) collected with the Human Support Robot (HSR) and is
fully standardized in the LeRobot v2.1 format. By uniquely integrating mobile
manipulation, contact-rich interaction, and long-horizon structure, AIRoA MoMa
provides a critical benchmark for advancing the next generation of
Vision-Language-Action models. The first version of our dataset is now
available at https://huggingface.co/datasets/airoa-org/airoa-moma .

</details>


### [134] [AgriCruiser: An Open Source Agriculture Robot for Over-the-row Navigation](https://arxiv.org/abs/2509.25056)
*Kenny Truong,Yongkyu Lee,Jason Irie,Shivam Kumar Panda,Shahab Ahmad,Md. Mukhlesur Rahman,M. Khalid Jawed*

Main category: cs.RO

TL;DR: AgriCruiser是一款开放源代码的农业机器人，能够有效管理杂草、减少作物损害并降低劳动需求，具有低成本和灵活性，适合多种农业应用。


<details>
  <summary>Details</summary>
Motivation: 为了实现低成本部署和快速适应不同作物和行布局，开发了一种开放源代码的农业机器人。

Method: 实现了集成精确喷雾系统的开放源代码农业机器人——AgriCruiser，采用可调节履带宽度和紧凑的转弯半径。

Result: 在12个亚麻地块中，使用该机器人的喷雾处理较人工除草减少了24至42倍的杂草数量，同时对作物造成的损害也更小。

Conclusion: 低成本、可配置的农业机器人能够有效管理杂草，并减少农作物损害和劳动力需求。同时，为表型、传感和其他农业应用提供了多功能基础。

Abstract: We present the AgriCruiser, an open-source over-the-row agricultural robot
developed for low-cost deployment and rapid adaptation across diverse crops and
row layouts. The chassis provides an adjustable track width of 1.42 m to 1.57
m, along with a ground clearance of 0.94 m. The AgriCruiser achieves compact
pivot turns with radii of 0.71 m to 0.79 m, enabling efficient headland
maneuvers. The platform is designed for the integration of the other
subsystems, and in this study, a precision spraying system was implemented to
assess its effectiveness in weed management. In twelve flax plots, a single
robotic spray pass reduced total weed populations (pigweed and Venice mallow)
by 24- to 42-fold compared to manual weeding in four flax plots, while also
causing less crop damage. Mobility experiments conducted on concrete, asphalt,
gravel, grass, and both wet and dry soil confirmed reliable traversal
consistent with torque sizing. The complete chassis can be constructed from
commodity T-slot extrusion with minimal machining, resulting in a bill of
materials costing approximately $5,000 - $6,000, which enables replication and
customization. The mentioned results demonstrate that low-cost, reconfigurable
over-the-row robots can achieve effective weed management with reduced crop
damage and labor requirements, while providing a versatile foundation for
phenotyping, sensing, and other agriculture applications. Design files and
implementation details are released to accelerate research and adoption of
modular agricultural robotics.

</details>


### [135] [Crop Spirals: Re-thinking the field layout for future robotic agriculture](https://arxiv.org/abs/2509.25091)
*Lakshan Lavan,Lanojithan Thiyagarasa,Udara Muthugala,Rajitha de Silva*

Main category: cs.RO

TL;DR: 提出了一种以机器人为中心的螺旋布局，显著提高自主农业的导航效率和协调能力。


<details>
  <summary>Details</summary>
Motivation: 传统线性作物布局对拖拉机进行了优化，但限制了机器人导航，导致转向困难、行程长和感知失真。

Method: 结合DH-ResNet18的航点回归、像素到里程计的映射、A*规划和模型预测控制（MPC）形成导航系统。

Result: 与线性布局相比，螺旋布局在500个航点的任务中路径长度可缩短28%，执行速度提升约25%；多机器人研究显示，协调效率提升，完成时间降低33-37%。

Conclusion: 重新设计田野几何形状可以更好地适应自主农业，显著提高效率。

Abstract: Conventional linear crop layouts, optimised for tractors, hinder robotic
navigation with tight turns, long travel distances, and perceptual aliasing. We
propose a robot-centric square spiral layout with a central tramline, enabling
simpler motion and more efficient coverage. To exploit this geometry, we
develop a navigation stack combining DH-ResNet18 waypoint regression,
pixel-to-odometry mapping, A* planning, and model predictive control (MPC). In
simulations, the spiral layout yields up to 28% shorter paths and about 25%
faster execution for waypoint-based tasks across 500 waypoints than linear
layouts, while full-field coverage performance is comparable to an optimised
linear U-turn strategy. Multi-robot studies demonstrate efficient coordination
on the spirals rule-constrained graph, with a greedy allocator achieving 33-37%
lower batch completion times than a Hungarian assignment under our setup. These
results highlight the potential of redesigning field geometry to better suit
autonomous agriculture.

</details>


### [136] [Curriculum Imitation Learning of Distributed Multi-Robot Policies](https://arxiv.org/abs/2509.25097)
*Jesús Roche,Eduardo Sebastián,Eduardo Montijano*

Main category: cs.RO

TL;DR: 本研究通过课程学习和感知估计，提升了多机器人系统在复杂环境中的控制策略学习能力，显著改善了长时间协调的性能和对不确定性的适应性。


<details>
  <summary>Details</summary>
Motivation: 目前多机器人系统在长期协调和真实训练数据获取方面面临挑战，因此我们旨在改进此现状。

Method: 通过引入课程学习和第三人称全球状态演示的感知估计方法，在模仿学习框架下优化多机器人系统的控制策略。

Result: 实验结果显示，我们的课程策略提高了长时间的准确性，而感知估计方法使得策略在现实不确定性下具有鲁棒性。

Conclusion: 本研究的策略结合了课程学习和感知估计方法，有效地提高了多机器人系统在长时间协调下的控制策略学习能力，适应了动态环境中的不确定性。

Abstract: Learning control policies for multi-robot systems (MRS) remains a major
challenge due to long-term coordination and the difficulty of obtaining
realistic training data. In this work, we address both limitations within an
imitation learning framework. First, we shift the typical role of Curriculum
Learning in MRS, from scalability with the number of robots, to focus on
improving long-term coordination. We propose a curriculum strategy that
gradually increases the length of expert trajectories during training,
stabilizing learning and enhancing the accuracy of long-term behaviors. Second,
we introduce a method to approximate the egocentric perception of each robot
using only third-person global state demonstrations. Our approach transforms
idealized trajectories into locally available observations by filtering
neighbors, converting reference frames, and simulating onboard sensor
variability. Both contributions are integrated into a physics-informed
technique to produce scalable, distributed policies from observations. We
conduct experiments across two tasks with varying team sizes and noise levels.
Results show that our curriculum improves long-term accuracy, while our
perceptual estimation method yields policies that are robust to realistic
uncertainty. Together, these strategies enable the learning of robust,
distributed controllers from global demonstrations, even in the absence of
expert actions or onboard measurements.

</details>


### [137] [Safe Planning in Unknown Environments using Conformalized Semantic Maps](https://arxiv.org/abs/2509.25124)
*David Smith Sundarsingh,Yifei Li,Tianji Tang,George J. Pappas,Nikolay Atanasov,Yiannis Kantaros*

Main category: cs.RO

TL;DR: 本文提出了一种新方法，解决了在感知不确定性下的语义规划问题，通过量化语义地图中的不确定性，实现了用户定义的任务完成率。


<details>
  <summary>Details</summary>
Motivation: 针对未知环境中的语义规划问题，考虑感知不确定性并确保完成率。

Method: 通过无模型和无分布的方法，用遵循预测的方法定量化语义地图中的不确定性。

Result: 所提出的规划器在任务成功率方面超越现有方法，无需已知的传感器模型或噪声特性。

Conclusion: 提出的方法在任务成功率方面优于基线，展示了其有效性。

Abstract: This paper addresses semantic planning problems in unknown environments under
perceptual uncertainty. The environment contains multiple unknown semantically
labeled regions or objects, and the robot must reach desired locations while
maintaining class-dependent distances from them. We aim to compute robot paths
that complete such semantic reach-avoid tasks with user-defined probability
despite uncertain perception. Existing planning algorithms either ignore
perceptual uncertainty - thus lacking correctness guarantees - or assume known
sensor models and noise characteristics. In contrast, we present the first
planner for semantic reach-avoid tasks that achieves user-specified mission
completion rates without requiring any knowledge of sensor models or noise.
This is enabled by quantifying uncertainty in semantic maps - constructed
on-the-fly from perceptual measurements - using conformal prediction in a
model- and distribution-free manner. We validate our approach and the
theoretical mission completion rates through extensive experiments, showing
that it consistently outperforms baselines in mission success rates.

</details>
