<div id=toc></div>

# Table of Contents

- [cs.HC](#cs.HC) [Total: 19]
- [cs.RO](#cs.RO) [Total: 37]


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [1] [Choreographing Trash Cans: On Speculative Futures of Weak Robots in Public Spaces](https://arxiv.org/abs/2510.13810)
*Minja Axelsson,Lea Luka Sikau*

Main category: cs.HC

TL;DR: 本论文探讨了弱机器人通过情感和想象启发人类合作的可能性，并通过设计虚构展示未来人机交互的异同。


<details>
  <summary>Details</summary>
Motivation: 探讨机器人如何不仅在实用层面上运作，而是在情感和想象层面上激发行人参与。

Method: 通过对弱机器人的功能和能力进行探讨，引入两种设计虚构的情境来展示未来城市中机器人行为的不同想象。

Result: 通过讨论机器人设计中的价值观，揭示了如何形成共存于公共空间的人机互动未来。

Conclusion: 人类与机器人在公共空间的合作可以通过弱机器人设计促进，设计决策将影响未来社会技术环境。

Abstract: Delivering groceries or cleaning airports, mobile robots exist in public
spaces. While these examples showcase robots that execute tasks, this paper
explores mobile robots that encourage posthuman collaboration rather than
managing environments independently. With feigned fragility, cuteness and
incomplete functionalities, the so-called "weak robots" invite passersby to
engage not only on a utilitarian level, but also through imaginative and
emotional responses. After examining the workings of "weak robots" by queering
notions of function and ability, we introduce two speculative design fiction
vignettes that describe choreographies of such robots in future urban spaces --
one exploring a utopian weak robot and the other a dystopian weak robot. We
introduce these speculations in order to discuss how different values may drive
design decisions, and how such decisions may shape and drive different
socio-technical futures in which robots and humans share public spaces that
incentivise collaboration.

</details>


### [2] [Generative AI in Heritage Practice: Improving the Accessibility of Heritage Guidance](https://arxiv.org/abs/2510.13811)
*Jessica Witte,Edmund Lee,Lisa Brausem,Verity Shillabeer,Chiara Bonacchi*

Main category: cs.HC

TL;DR: HAZEL是一款优化的GenAI聊天机器人，比ChatGPT在指导写作上表现更佳，但在文化敏感性和技术专业知识上仍存在局限性。GenAI可以为资源有限的遗产组织提供写作流程的自动化和加速。


<details>
  <summary>Details</summary>
Motivation: 旨在提高公众指导文件的可及性，优化遗产保护和解释相关的写作过程。

Method: 通过定量评估将HAZEL的表现与ChatGPT (GPT-4) 的表现进行比较，以了解HAZEL在指导写作任务中的有效性。

Result: 本文探讨了将生成性人工智能（GenAI）整合到专业遗产实践中的潜力，以提高公众指导文件的可及性。我们开发了HAZEL，这是一款经过微调的GenAI聊天机器人，旨在帮助修改与遗产保护和解释相关的书面指导。

Conclusion: 尽管GenAI无法替代人类遗产专业人士进行技术文稿编写，但其在指导文档写作方面的自动化潜力可为遗产组织提供显著益处，尤其是在资源受限的情况下。

Abstract: This paper discusses the potential for integrating Generative Artificial
Intelligence (GenAI) into professional heritage practice with the aim of
enhancing the accessibility of public-facing guidance documents. We developed
HAZEL, a GenAI chatbot fine-tuned to assist with revising written guidance
relating to heritage conservation and interpretation. Using quantitative
assessments, we compare HAZEL's performance to that of ChatGPT (GPT-4) in a
series of tasks related to the guidance writing process. The results of this
comparison indicate a slightly better performance of HAZEL over ChatGPT,
suggesting that the GenAI chatbot is more effective once the underlying large
language model (LLM) has been fine-tuned. However, we also note significant
limitations, particularly in areas requiring cultural sensitivity and more
advanced technical expertise. These findings suggest that, while GenAI cannot
replace human heritage professionals in technical authoring tasks, its
potential to automate and expedite certain aspects of guidance writing could
offer valuable benefits to heritage organisations, especially in
resource-constrained contexts.

</details>


### [3] [MindBenchAI: An Actionable Platform to Evaluate the Profile and Performance of Large Language Models in a Mental Healthcare Context](https://arxiv.org/abs/2510.13812)
*Bridget Dwyer,Matthew Flathers,Akane Sano,Allison Dempsey,Andrea Cipriani,Asim H. Gazi,Carla Gorban,Carolyn I. Rodriguez,Charles Stromeyer IV,Darlene King,Eden Rozenblit,Gillian Strudwick,Jake Linardon,Jiaee Cheong,Joseph Firth,Julian Herpertz,Julian Schwarz,Margaret Emerson,Martin P. Paulus,Michelle Patriquin,Yining Hua,Soumya Choudhary,Steven Siddals,Laura Ospina Pinillos,Jason Bantjes,Steven Scheuller,Xuhai Xu,Ken Duckworth,Daniel H. Gillison,Michael Wood,John Torous*

Main category: cs.HC

TL;DR: 本文介绍了MindBenchAI，一个旨在评估心理健康领域中LLM及其工具的在线平台，促进透明和客观的测评。


<details>
  <summary>Details</summary>
Motivation: 随着人们越来越多地使用大型语言模型（LLM）工具进行心理健康指导和危机支持，需要评估和规范这些工具，因为缺乏实证证据表明AI技术可以替代人类专家。

Method: 建立MindBenchAI在线平台

Result: MindBenchAI提供了一个聚合评估方法的全面在线平台，方便不同利益相关者访问和理解相关信息。

Conclusion: MindBenchAI可系统地评估LLM及其工具，提供客观标准，促进心理健康领域的透明度和科学决策。

Abstract: Individuals are increasingly utilizing large language model (LLM)based tools
for mental health guidance and crisis support in place of human experts. While
AI technology has great potential to improve health outcomes, insufficient
empirical evidence exists to suggest that AI technology can be deployed as a
clinical replacement; thus, there is an urgent need to assess and regulate such
tools. Regulatory efforts have been made and multiple evaluation frameworks
have been proposed, however,field-wide assessment metrics have yet to be
formally integrated. In this paper, we introduce a comprehensive online
platform that aggregates evaluation approaches and serves as a dynamic online
resource to simplify LLM and LLM-based tool assessment: MindBenchAI. At its
core, MindBenchAI is designed to provide easily accessible/interpretable
information for diverse stakeholders (patients, clinicians, developers,
regulators, etc.). To create MindBenchAI, we built off our work developing
MINDapps.org to support informed decision-making around smartphone app use for
mental health, and expanded the technical MINDapps.org framework to encompass
novel large language model (LLM) functionalities through benchmarking
approaches. The MindBenchAI platform is designed as a partnership with the
National Alliance on Mental Illness (NAMI) to provide assessment tools that
systematically evaluate LLMs and LLM-based tools with objective and transparent
criteria from a healthcare standpoint, assessing both profile (i.e. technical
features, privacy protections, and conversational style) and performance
characteristics (i.e. clinical reasoning skills).

</details>


### [4] [Puzzlegram: a Serious Game Designed for the Elderly in Group Settings](https://arxiv.org/abs/2510.13813)
*Sunny Choi*

Main category: cs.HC

TL;DR: 本文介绍了为老年人设计的严肃游戏原型'Puzzlegram'，侧重于记忆和互动，利用音乐增强游戏体验。


<details>
  <summary>Details</summary>
Motivation: 旨在为老年人群体创造一种能够促进有意义互动的游戏体验，改善他们的认知与社交能力。

Method: 本研究创建了名为'Puzzlegram'的游戏原型，强调记忆、听觉互动和对视觉信号的触觉反应，结合熟悉的音乐作为设计核心。

Result: 提出了为严肃游戏设计制定全面框架的必要性，并探讨了人工智能在游戏中的潜在应用。

Conclusion: 未来的游戏设计应考虑为老年人提供有意义的互动，并可能结合人工智能来适应玩家的认知状态。

Abstract: An original serious game prototype named 'Puzzlegram' is created for the
elderly demographic in group settings as the target players. Puzzlegram is
precisely designed to accentuate memory, auditory interaction as well as haptic
response to visual signals with the use of music. Music is introduced as a key
component for establishing the game design that provides a source of meaningful
contextualization (familiar music from the past) for setting the game
mechanics, which facilitated the construction of the serious game design
process. The discussion topics raised include the need to design serious games
for fostering meaningful interactions, as well as developing a thorough
framework for constructing purposeful design for serious games. A potential
integral of artificial intelligence to Puzzlegram may involve assigning a novel
dimension to its existing problem solving task by adapting to varying states of
cognitive function for monitoring purposes based on an individual's interaction
with the game.

</details>


### [5] [Reversing the Lens: Using Explainable AI to Understand Human Expertise](https://arxiv.org/abs/2510.13814)
*Roussel Rahman,Aashwin Ananda Mishra,Wan-Lin Hu*

Main category: cs.HC

TL;DR: 本研究利用XAI方法分析人类在复杂任务中的学习过程，揭示有效问题解决策略的形成机制


<details>
  <summary>Details</summary>
Motivation: 结合心理学对人类认知的理解与XAI方法，以提升对人类学习过程的认识

Method: 应用解释性人工智能（XAI）的计算工具来分析人类学习

Result: 通过对粒子加速器调节的复杂任务建模，揭示操作人员如何将问题分解成更简单的组件，以及这些结构如何随着专业知识的发展而演变

Conclusion: 研究揭示了人类在缺乏最佳解决方案时如何发展高效策略，并展示了XAI方法在定量研究人类认知中的应用价值。

Abstract: Both humans and machine learning models learn from experience, particularly
in safety- and reliability-critical domains. While psychology seeks to
understand human cognition, the field of Explainable AI (XAI) develops methods
to interpret machine learning models. This study bridges these domains by
applying computational tools from XAI to analyze human learning. We modeled
human behavior during a complex real-world task -- tuning a particle
accelerator -- by constructing graphs of operator subtasks. Applying techniques
such as community detection and hierarchical clustering to archival operator
data, we reveal how operators decompose the problem into simpler components and
how these problem-solving structures evolve with expertise. Our findings
illuminate how humans develop efficient strategies in the absence of globally
optimal solutions, and demonstrate the utility of XAI-based methods for
quantitatively studying human cognition.

</details>


### [6] [Understanding Data Usage when Making High-Stakes Frontline Decisions in Homelessness Services](https://arxiv.org/abs/2510.14141)
*Teale W. Masrani,Geoffrey Messier,Amy Voida,Gina Dimitropoulos,Helen Ai He*

Main category: cs.HC

TL;DR: 本论文研究了应急避难所一线工作人员在使用技术时的挑战，提议如何设计更人性化的数据驱动工具以支持其决策过程。


<details>
  <summary>Details</summary>
Motivation: 探讨一线工作人员在面对数据驱动技术时的抵触情绪，以改善他们的工作条件和决策质量。

Method: 通过定性实地研究方法，进行数据的共同设计、开发和实施，重点关注一线工作人员和数据系统之间的互动。

Result: 本论文探讨了应急避难所一线工作人员在决策过程中面临的挑战，尤其是与科技兼容的问题。通过一项在加拿大大型紧急避难所进行的定性实地研究，提出了设计更人性化的数据驱动技术的建议，以支持工作人员在对无家可归者进行高风险决策时的工作。

Conclusion: 研究表明，技术需要与人性化的决策过程相结合，以促进对处境脆弱个体的同情和深思熟虑的决策。

Abstract: Frontline staff of emergency shelters face challenges such as vicarious
trauma, compassion fatigue, and burnout. The technology they use is often not
designed for their unique needs, and can feel burdensome on top of their
already cognitively and emotionally taxing work. While existing literature
focuses on data-driven technologies that automate or streamline frontline
decision-making about vulnerable individuals, we discuss scenarios in which
staff may resist such automation. We then suggest how data-driven technologies
can better align with their human-centred decision-making processes. This paper
presents findings from a qualitative fieldwork study conducted from 2022 to
2024 at a large emergency shelter in Canada. The goal of this fieldwork was to
co-design, develop, and deploy an interactive data-navigation interface that
supports frontline staff when making collaborative, high-stakes decisions about
individuals experiencing homelessness. By reflecting on this fieldwork, we
contribute insight into the role that administrative shelter data play during
decision-making, and unpack staff members' apparent reluctance to outsource
decisions about vulnerable individuals to data systems. Our findings suggest a
data-outsourcing continuum, which we discuss in terms of how designers may
create technologies to support compassionate, data-driven decision-making in
nonprofit domains.

</details>


### [7] [VisAider: AI-Assisted Context-Aware Visualization Support for Data Presentations](https://arxiv.org/abs/2510.14247)
*Kentaro Takahira,Yuki Ueno*

Main category: cs.HC

TL;DR: 开发VisAider，一个AI辅助的互动数据呈现原型，旨在实时适应动态展示需求。


<details>
  <summary>Details</summary>
Motivation: 小组互动环境中，实时数据呈现尤为重要，但现有可视化系统未能满足动态需求

Method: 基于AI的交互式数据呈现原型VisAider的开发

Result: 介绍了VisAider原型，具有实时分析展示上下文的能力，并能提供相关可视化辅助建议

Conclusion: 正在解决性能和集成问题，并计划评估该系统的可用性和交流效果。

Abstract: Effective real-time data presentation is essential in small-group interactive
contexts, where discussions evolve dynamically and presenters must adapt
visualizations to shifting audience interests. However, most existing
interactive visualization systems rely on fixed mappings between user actions
and visualization commands, limiting their ability to support richer operations
such as changing visualization types, adjusting data transformations, or
incorporating additional datasets on the fly during live presentations. This
work-in-progress paper presents VisAider, an AI-assisted interactive data
presentation prototype that continuously analyzes the live presentation
context, including the available dataset, active visualization, ongoing
conversation, and audience profile, to generate ranked suggestions for relevant
visualization aids. Grounded in a formative study with experienced data
analysts, we identified key challenges in adapting visual content in real time
and distilled design considerations to guide system development. A prototype
implementation demonstrates the feasibility of this approach in simulated
scenarios, and preliminary testing highlights challenges in inferring
appropriate data transformations, resolving ambiguous visualization tasks, and
achieving low-latency responsiveness. Ongoing work focuses on addressing these
limitations, integrating the system into presentation environments, and
preparing a summative user study to evaluate usability and communicative
impact.

</details>


### [8] [TapNav: Adaptive Spatiotactile Screen Readers for Tactually Guided Touchscreen Interactions for Blind and Low Vision People](https://arxiv.org/abs/2510.14267)
*Ricardo Gonzalez,Fannie Liu,Blair MacIntyre,David Saffo*

Main category: cs.HC

TL;DR: TapNav是一种新型的适应性空间触觉屏幕阅读原型，它通过触觉和听觉的结合，改善了盲人和低视力人士与触摸界面的互动效率，减少认知负担并加快了信息获取。


<details>
  <summary>Details</summary>
Motivation: 为了提高盲人和低视力用户在使用触摸屏设备时的信息获取能力，克服传统音频阅读器的顺序限制。

Method: 通过适应性的听觉反馈与触觉覆盖层结合，TapNav实现了一个空间触觉屏幕阅读原型，并进行实地评估。

Result: 通过与12名BLV用户的互动评估，发现TapNav在数据可视化和银行事务应用中明显提升了用户的预期结果，实现更快的探索并有效降低认知负担。

Conclusion: TapNav有效地帮助BLV用户通过触觉和听觉反馈来增强对触摸界面的互动，降低认知负荷，提升信息处理效率。

Abstract: Screen readers are audio-based software that Blind and Low Vision (BLV)
people use to interact with computing devices, such as tablets and smartphones.
Although this technology has significantly improved the accessibility of
touchscreen devices, the sequential nature of audio limits the bandwidth of
information users can receive and process. We introduce TapNav, an adaptive
spatiotactile screen reader prototype developed to interact with touchscreen
interfaces spatially. TapNav's screen reader provides adaptive auditory
feedback that, in combination with a tactile overlay, conveys spatial
information and location of interface elements on-screen. We evaluated TapNav
with 12 BLV users who interacted with TapNav to explore a data visualization
and interact with a bank transactions application. Our qualitative findings
show that touch points and spatially constrained navigation helped users
anticipate outcomes for faster exploration, and offload cognitive load to
touch. We provide design guidelines for creating tactile overlays for adaptive
spatiotactile screen readers and discuss their generalizability beyond our
exploratory data analysis and everyday application navigation scenarios.

</details>


### [9] [GenLARP: Enabling Immersive Live Action Role-Play through LLM-Generated Worlds and Characters](https://arxiv.org/abs/2510.14277)
*Yichen Yu,Yifan Jiang,Mandy Lui,Qiao Jin*

Main category: cs.HC

TL;DR: GenLARP是一个利用VR技术和生成式AI的系统，使用户能够创建和参与个性化的沉浸式角色扮演体验。


<details>
  <summary>Details</summary>
Motivation: 旨在让用户以创作者和玩家的身份沉浸于自己的故事世界中。

Method: 使用生成式人工智能和大型语言模型（LLMs）为用户创建角色和故事环境。

Result: 用户能够设计基于描述的角色，享受个性化的和互动的LARP体验。

Conclusion: GenLARP结合了个性化故事和虚拟现实，为用户提供了沉浸式的角色扮演体验。

Abstract: We introduce GenLARP, a virtual reality (VR) system that transforms
personalized stories into immersive live action role-playing (LARP)
experiences. GenLARP enables users to act as both creators and players,
allowing them to design characters based on their descriptions and live in the
story world. Generative AI and agents powered by Large Language Models (LLMs)
enrich these experiences.

</details>


### [10] [ReUseIt: Synthesizing Reusable AI Agent Workflows for Web Automation](https://arxiv.org/abs/2510.14308)
*Yimeng Liu,Misha Sra,Jeevana Priya Inala,Chenglong Wang*

Main category: cs.HC

TL;DR: 本研究通过合成可重用工作流，提升AI网络代理在重复任务中的成功率至70.1%。


<details>
  <summary>Details</summary>
Motivation: 提高AI网络代理在执行重复任务时的成功率，减少用户每次操作所需的指导。

Method: 通过分析代理的成功和失败尝试，自动合成包含执行保护的工作流，帮助代理识别和修复错误。

Result: 我们提出了一种自动合成可重用工作流的方法，使AI驱动的网络代理能够更好地执行重复任务，达到70.1%的成功率。

Conclusion: 改进后的代理能够在用户干预较少的情况下成功执行任务，并提高用户对代理行为的监控能力。

Abstract: AI-powered web agents have the potential to automate repetitive tasks, such
as form filling, information retrieval, and scheduling, but they struggle to
reliably execute these tasks without human intervention, requiring users to
provide detailed guidance during every run. We address this limitation by
automatically synthesizing reusable workflows from an agent's successful and
failed attempts. These workflows incorporate execution guards that help agents
detect and fix errors while keeping users informed of progress and issues. Our
approach enables agents to successfully complete repetitive tasks of the same
type with minimal intervention, increasing the success rates from 24.2% to
70.1% across fifteen tasks. To evaluate this approach, we invited nine users
and found that our agent helped them complete web tasks with a higher success
rate and less guidance compared to two baseline methods, as well as allowed
users to easily monitor agent behavior and understand failures.

</details>


### [11] [State Your Intention to Steer Your Attention: An AI Assistant for Intentional Digital Living](https://arxiv.org/abs/2510.14513)
*Juheon Choi,Juyoung Lee,Jian Kim,Chanyoung Kim,Taewon Min,W. Bradley Knox,Min Kyung Lee,Kimin Lee*

Main category: cs.HC

TL;DR: 本研究介绍了一种新型AI助手，旨在帮助用户应对数字设备带来的干扰，保持生产力和专注。


<details>
  <summary>Details</summary>
Motivation: 面对数字设备的干扰，用户的生产力和效率可能下降，且会产生负面心理和情感影响，因此需要一种解决方案来帮助用户保持专注。

Method: 该系统利用大型语言模型分析屏幕截图、应用标题和网址，通过用户意图与实际行为的比较，提供提醒，且通过初步对话和用户反馈不断优化检测准确性。

Result: AI助手能够有效地支持用户维护专注，并使其数字行为与意图保持一致。

Conclusion: 通过与传统的基于规则的意图提醒系统和被动记录活动的基础线比较，AI助手表现优越，能有效帮助用户达成目标。

Abstract: When working on digital devices, people often face distractions that can lead
to a decline in productivity and efficiency, as well as negative psychological
and emotional impacts. To address this challenge, we introduce a novel
Artificial Intelligence (AI) assistant that elicits a user's intention,
assesses whether ongoing activities are in line with that intention, and
provides gentle nudges when deviations occur. The system leverages a large
language model to analyze screenshots, application titles, and URLs, issuing
notifications when behavior diverges from the stated goal. Its detection
accuracy is refined through initial clarification dialogues and continuous user
feedback. In a three-week, within-subjects field deployment with 22
participants, we compared our assistant to both a rule-based intent reminder
system and a passive baseline that only logged activity. Results indicate that
our AI assistant effectively supports users in maintaining focus and aligning
their digital behavior with their intentions. Our source code is publicly
available at this url https://intentassistant.github.io

</details>


### [12] [Just-In-Time Objectives: A General Approach for Specialized AI Interactions](https://arxiv.org/abs/2510.14591)
*Michelle S. Lam,Omar Shaikh,Hallie Xu,Alice Guo,Diyi Yang,Jeffrey Heer,James A. Landay,Michael S. Bernstein*

Main category: cs.HC

TL;DR: 本研究提出了一种通过观察用户行为自动生成即时目标的方法，显著提升了大型语言模型的响应效果。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在缺乏特定目标时表现平平，需要改进其响应能力以满足用户需求。

Method: 通过被动观察用户行为，自动引导人工智能系统以满足用户即时目标。

Result: 引入了Just-In-Time (JIT) 目标的架构，实验结果显示，基于JIT目标的LLM输出在用户任务中获得了66-86%的胜率。

Conclusion: JIT目标的引入使得大型语言模型能够生成针对性的工具与响应，提升了用户体验。

Abstract: Large language models promise a broad set of functions, but when not given a
specific objective, they default to milquetoast results such as drafting emails
littered with cliches. We demonstrate that inferring the user's in-the-moment
objective, then rapidly optimizing for that singular objective, enables LLMs to
produce tools, interfaces, and responses that are more responsive and desired.
We contribute an architecture for automatically inducing just-in-time
objectives by passively observing user behavior, then steering downstream AI
systems through generation and evaluation against this objective. Inducing
just-in-time objectives (e.g., "Clarify the abstract's research contribution")
enables automatic generation of tools, e.g., those that critique a draft based
on relevant HCI methodologies, anticipate related researchers' reactions, or
surface ambiguous terminology. In a series of experiments (N=14, N=205) on
participants' own tasks, JIT objectives enable LLM outputs that achieve 66-86%
win rates over typical LLMs, and in-person use sessions (N=17) confirm that JIT
objectives produce specialized tools unique to each participant.

</details>


### [13] [Two Explorative Studies on Tangible Augmented Reality for Neurodevelopmental Disorders](https://arxiv.org/abs/2510.14598)
*Francesco Vona,Giulia Valcamonica,Franca Garzotto*

Main category: cs.HC

TL;DR: 本文研究了两种增强现实应用在神经发育障碍者中的可用性，发现它们具有治疗潜力，尽管存在一些操作上的困难。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索如何通过增强现实技术为神经发育障碍者提供更好的互动体验和生活技能培训。

Method: 通过两项探索性研究评估Holomarket和Along the Oceanic Flow应用的可用性和喜欢度，收集参与者的反馈和体验。

Result: 本研究探讨了两个以物理交互为基础的增强现实应用程序的可用性和受欢迎度，特别是在神经发育障碍者中。结果表明，虽然存在一些可用性挑战，但这两款应用作为治疗工具的潜力得到了肯定。

Conclusion: 增强现实技术可以作为神经发育障碍者的潜在治疗工具，但需要进一步研究以解决可用性和舒适性问题。

Abstract: Tangible Augmented Reality (TAR) is an interaction paradigm that integrates
physical and digital worlds to create immersive, interactive experiences. This
paper explores two TAR applications, Holomarket and Along the Oceanic Flow
(ATOF), and presents insights from two exploratory studies evaluating their
usability and likeability among individuals with neurodevelopmental disorders
(NDD). Holomarket is designed to simulate a supermarket shopping experience,
helping users develop essential life skills such as item selection, basic
arithmetic, and money handling. Participants interacted with augmented food
items and a smart cash register, navigating a virtual supermarket environment.
While participants enjoyed the realistic setting and tangible interactions,
some usability challenges, such as difficulty manipulating virtual objects and
discomfort with prolonged headset use, were noted. ATOF transforms the user
environment into an oceanic world, where participants use a dolphin-shaped
smart object to complete tasks like collecting items and solving puzzles. This
application aims to improve motor coordination and cognitive skills.
Participants appreciated the immersive experience, the customizable tasks, and
the tangible dolphin interface. However, some faced difficulties interacting
with specific virtual elements. Overall, both applications demonstrated
potential as therapeutic tools for NDD, offering engaging and immersive
experiences. Despite some usability challenges and hardware limitations, the
positive feedback suggests that TAR could play a crucial role in future
therapeutic interventions. Further research is needed to refine these
applications and enhance user interaction and comfort.

</details>


### [14] [Sales Skills Training in Virtual Reality: An evaluation utilizing CAVE and Virtual Avatars](https://arxiv.org/abs/2510.14603)
*Francesco Vona,Michael Stern,Navid Ashrafi,Julia Schorlemmer,Jessica Stemann,Jan-Niklas Voigt-Antons*

Main category: cs.HC

TL;DR: 本研究评估了利用VR技术进行销售技能培训的有效性，发现适度的沉浸式VR系统具有多种优势，但仍需进一步研究优化设计。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探讨VR技术如何模拟真实场景，以提高销售技能的培训效果，并分析参与者在不同沟通风格和环境条件下的表现。

Method: 采用了一个被试内实验设计，20名大学生参与了多种销售场景的模拟训练，使用已验证的评估指标和定制的体验问卷来评估培训效果。

Result: 该研究探讨了虚拟现实（VR）在提升销售技能培训中的潜力，利用了Cave Automatic Virtual Environment（CAVE）技术。

Conclusion: 本研究强调了半沉浸式VR系统在协作学习、同伴反馈和现实培训环境中的优越性，同时建议进一步研究以优化VR设计和提高技能转移效果。

Abstract: This study investigates the potential of virtual reality (VR) for enhancing
sales skills training using a Cave Automatic Virtual Environment (CAVE). VR
technology enables users to practice interpersonal and negotiation skills in
controlled, immersive environments that mimic real-world scenarios. In this
study, participants engaged in sales simulations set in a virtual dealership,
interacting with avatars in different work settings and with various
communication styles. The research employed a within-subjects experimental
design involving 20 university students. Each participant experienced four
distinct sales scenarios randomized for environmental and customer conditions.
Training effectiveness was assessed using validated metrics alongside custom
experience questions. Findings revealed consistent user experience and presence
across all scenarios, with no significant differences detected based on
communication styles or environmental conditions. The study highlights the
advantages of semi-immersive VR systems for collaborative learning, peer
feedback, and realistic training environments. However, further research is
recommended to refine VR designs, improve engagement, and maximize skills
transfer to real-world applications.

</details>


### [15] [Exploring the Effects of Different Asymmetric Game Designs on User Experience in Collaborative Virtual Reality](https://arxiv.org/abs/2510.14607)
*Francesco Vona,Evelyn Romanjuk,Sina Hinzmann,Julia Schorlemmer,Navid Ashrafi,Jan-Niklas Voigt-Antons*

Main category: cs.HC

TL;DR: 研究不同设计对VR游戏玩家体验的影响，发现依赖关系改变了体验质量


<details>
  <summary>Details</summary>
Motivation: 解决虚拟现实孤立风险，促进玩家社交互动

Method: 实验研究四种不同版本的VR体验并测试影响

Result: 游戏设计的变化影响玩家体验的多个方面，如系统可用性、实用UX质量、沉浸控制和内在动机

Conclusion: 玩家之间的依赖程度会改变他们的体验，但角色和共存在虚拟环境中不会同时影响这些方面。

Abstract: The risk of isolation in virtual reality (VR) stems from the immersive nature
of the technology. VR can transport users to entirely virtual environments,
often disconnecting them from the physical world and real-life interactions.
Asymmetric multiplayer options have been explored to address this issue and
encourage social interaction by requiring players to communicate and
collaborate to achieve common objectives. Nevertheless, research on
implementing these designs and their effects is limited, mainly due to the
novelty of multiplayer VR gaming. This article investigates how different game
design approaches affect the player experience during an asymmetric multiplayer
VR game. Four versions of a VR experience were created and tested in a study
involving 74 participants. Each version differs in terms of the sharing of
virtual environments (shared vs separated) and the players' dependency on the
experience (mutual vs unidirectional). The results showed that variations in
game design influenced aspects of the player experience, such as system
usability, pragmatic UX quality, immersion control, and intrinsic motivation.
Notably, the player roles and the co-presence in the virtual environment did
not simultaneously impact these aspects, suggesting that the degree to which
players depend on each other changes the player experience.

</details>


### [16] [An Active Inference Model of Mouse Point-and-Click Behaviour](https://arxiv.org/abs/2510.14611)
*Markus Klar,Sebastian Stein,Fraser Paterson,John H. Williamson,Roderick Murray-Smith*

Main category: cs.HC

TL;DR: 本研究提出一种基于活跃推断的代理模型，用于解决人机交互中的鼠标指向和点击问题，展现出与人类用户相似的指向行为。


<details>
  <summary>Details</summary>
Motivation: 探讨活跃推断（AIF）在空间指向中的应用，解决人机交互中的关键问题。

Method: 采用连续状态、动作和观察空间的AIF代理，利用动态系统建模鼠标光标动态，并基于感知的偏好分布最小化期望自由能。

Result: AIF代理能够生成 plausible 的指向动作，并在光标位于目标上时实现点击，且终点方差与人类用户相似。

Conclusion: 在不同目标难度下，代理表现出明显区别，无需重新调整系统参数，强调了在与连续系统交互时配置AIF代理的挑战。

Abstract: We explore the use of Active Inference (AIF) as a computational user model
for spatial pointing, a key problem in Human-Computer Interaction (HCI). We
present an AIF agent with continuous state, action, and observation spaces,
performing one-dimensional mouse pointing and clicking. We use a simple
underlying dynamic system to model the mouse cursor dynamics with realistic
perceptual delay. In contrast to previous optimal feedback control-based
models, the agent's actions are selected by minimizing Expected Free Energy,
solely based on preference distributions over percepts, such as observing
clicking a button correctly. Our results show that the agent creates plausible
pointing movements and clicks when the cursor is over the target, with similar
end-point variance to human users. In contrast to other models of pointing, we
incorporate fully probabilistic, predictive delay compensation into the agent.
The agent shows distinct behaviour for differing target difficulties without
the need to retune system parameters, as done in other approaches. We discuss
the simulation results and emphasize the challenges in identifying the correct
configuration of an AIF agent interacting with continuous systems.

</details>


### [17] [If You Hold Me Without Hurting Me: Pathways to Designing Game Audio for Healthy Escapism and Player Well-being](https://arxiv.org/abs/2510.14691)
*Caio Nunes,Bosco Borges,Georgia Cruz,Ticianne Darin*

Main category: cs.HC

TL;DR: 游戏中的音频在自我调节和健康逃避行为中起重要作用，但其潜力仍未得到充分探索。


<details>
  <summary>Details</summary>
Motivation: 研究游戏中的逃避行为对恢复和有害逃避的支持作用，并强调自我调节在这一过程中的重要性。

Method: 分析当前在游戏设计中音频应用的不足，并提出改善建议。

Result: 本文识别了影响音频潜力认知的研究方法和可达性缺口，并提出解决方案。

Conclusion: 建议研究人员和开发者更有意识地将音频整合到健康逃避游戏的设计和研究中。

Abstract: Escapism in games can support recovery or lead to harmful avoidance.
Self-regulation, understood as combining autonomy with positive outcomes, is
key to this distinction. We argue that audio, often overlooked, plays a central
role in regulation. It can modulate arousal, mark transitions, and provide
closure, yet its contribution to well-being remains underexplored. This paper
identifies methodological and accessibility gaps that limit recognition of
audio's potential and outlines ways to address them. We aim to encourage
researchers and developers to integrate audio more deliberately into the design
and study of healthier escapist play.

</details>


### [18] [Dude, Where's My (Autonomous) Car? Defining an Accessible Description Logic for Blind and Low Vision Travelers Using Autonomous Vehicles](https://arxiv.org/abs/2510.14911)
*Paul D. S. Fink,Justin R. Brown,Rachel Coombs,Emily A. Hamby,Kyle J. James,Aisha Harris,Jacob Bond,Morgan E. Andrulis,Nicholas A. Giudice*

Main category: cs.HC

TL;DR: 本研究探讨了盲人和低视力用户在自主交通工具中的信息需求，提出了一种结构化的信息传递框架，以提升他们的独立出行能力，强调了用户对车辆信息与安全确认的重要性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探讨盲人和低视力旅行者在整个交通旅程中的信息需求，以提升他们的独立出行能力。

Method: 通过对202名盲人和低视力受访者的调查以及与12名个体的访谈，揭示了BLV最终用户的观点，并确定了成功出行所需的自然语言信息的顺序。

Result: 调查和访谈显示，BLV用户在导航阶段优先了解车辆的品牌和型号，以及如何找到正确的车辆。进入车辆时，他们强调确认目的地和车内安全特征的重要性，而在下车时，他们重视障碍物信息及车的出口方向。BLV旅行者希望在获取信息时使用自己手机，并更倾向于音频交互。

Conclusion: 本研究的发现贡献了一个结构化框架，用于为盲人和低视力用户提供与旅行相关的信息，这对设计者有帮助，使其可以根据每个旅行环节量身定制自然语言描述。

Abstract: Purpose: Autonomous vehicles (AVs) are becoming a promising transportation
solution for blind and low-vision (BLV) travelers, offering the potential for
greater independent mobility. This paper explores the information needs of BLV
users across multiple steps of the transportation journey, including finding
and navigating to, entering, and exiting vehicles independently.
  Methods: A survey with 202 BLV respondents and interviews with 12 BLV
individuals revealed the perspectives of BLV end-users and informed the
sequencing of natural language information required for successful travel.
Whereas the survey identified key information needs across the three trip
segments, the interviews helped prioritize how that information should be
presented in a sequence of accessible descriptions to travelers.
  Results: Taken together, the survey and interviews reveal that BLV users
prioritize knowing the vehicle's make and model and how to find the correct
vehicle during the navigation phase. They also emphasize the importance of
confirmations about the vehicle's destination and onboard safety features upon
entering the vehicle. While exiting, BLV users value information about hazards
and obstacles, as well as knowing which side of the vehicle to exit.
Furthermore, results highlight that BLV travelers desire using their own
smartphone devices when receiving information from AVs and prefer audio-based
interaction.
  Conclusion: The findings from this research contribute a structured framework
for delivering trip-related information to BLV users, useful for designers
incorporating natural language descriptions tailored to each travel segment.
This work offers important contributions for sequencing transportation-related
descriptions throughout the AV journey, ultimately enhancing the mobility and
independence of BLV individuals.

</details>


### [19] [Design of Paper Robot Building Kits](https://arxiv.org/abs/2510.14914)
*Ruhan Yang,Ellen Yi-Luen Do*

Main category: cs.HC

TL;DR: 本论文探讨了使用纸作为建筑材料，设计便宜且多功能的机器人套件，以提高可获取性和灵活性。


<details>
  <summary>Details</summary>
Motivation: 提高传统机器人套件的可获取性和灵活性，克服其高成本和功能有限的问题。

Method: 分析现有机器人套件和纸质交互研究，提出设计空间，并应用于设计的纸质机器人套件。

Result: 提出了一个纸质机器人设计空间，并通过示例展示了纸质材料在机器人建造中的应用潜力。

Conclusion: 纸质机器人套件展示了作为成本效益材料的潜力，并为未来的研究和开发提供了指导。

Abstract: Building robots is an engaging activity that provides opportunities for
hands-on learning. However, traditional robot-building kits are usually costly
with limited functionality due to material and technology constraints. To
improve the accessibility and flexibility of such kits, we take paper as the
building material and extensively explore the versatility of paper-based
interactions. Based on an analysis of current robot-building kits and
paper-based interaction research, we propose a design space for devising paper
robots. We also analyzed our building kit designs using this design space,
where these kits demonstrate the potential of paper as a cost-effective
material for robot building. As a starting point, our design space and building
kit examples provide a guideline that inspires and informs future research and
development of novel paper robot-building kits.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [20] [A Diffusion-Refined Planner with Reinforcement Learning Priors for Confined-Space Parking](https://arxiv.org/abs/2510.14000)
*Mingyang Jiang,Yueyuan Li,Jiaru Zhang,Songan Zhang,Ming Yang*

Main category: cs.RO

TL;DR: 本研究提出的DRIP通过引入强化学习的方法，提升了狭小停车场景下的自动规划能力。


<details>
  <summary>Details</summary>
Motivation: 应对在有限空间内停车需求日益增长的挑战

Method: 提出DRIP，一种基于强化学习的扩散精化规划器

Result: 显著提高了狭小空间停车环境中的规划性能，同时保持了在常见场景中的强泛化能力

Conclusion: DRIP能够在狭小和复杂环境下实现高精度的停车规划，成功率更高，推理步骤更少。

Abstract: The growing demand for parking has increased the need for automated parking
planning methods that can operate reliably in confined spaces. In restricted
and complex environments, high-precision maneuvers are required to achieve a
high success rate in planning, yet existing approaches often rely on explicit
action modeling, which faces challenges when accurately modeling the optimal
action distribution. In this paper, we propose DRIP, a diffusion-refined
planner anchored in reinforcement learning (RL) prior action distribution, in
which an RL-pretrained policy provides prior action distributions to regularize
the diffusion training process. During the inference phase the denoising
process refines these coarse priors into more precise action distributions. By
steering the denoising trajectory through the reinforcement learning prior
distribution during training, the diffusion model inherits a well-informed
initialization, resulting in more accurate action modeling, a higher planning
success rate, and reduced inference steps. We evaluate our approach across
parking scenarios with varying degrees of spatial constraints. Experimental
results demonstrate that our method significantly improves planning performance
in confined-space parking environments while maintaining strong generalization
in common scenarios.

</details>


### [21] [Spatially Intelligent Patrol Routes for Concealed Emitter Localization by Robot Swarms](https://arxiv.org/abs/2510.14018)
*Adam Morris,Timothy Pelham,Edmund R. Hunt*

Main category: cs.RO

TL;DR: 本文提出了一种设计空间智能机器人群体行为的方法，以定位隐蔽的无线电发射源。


<details>
  <summary>Details</summary>
Motivation: 研究电磁监控中的关键挑战，特别是如何在不依赖发射源参数的情况下定位未知信号。

Method: 采用差分进化算法生成几何巡逻路线，模拟机器人群体在不同配置下的信号定位能力。

Result: 模拟结果显示，方向性天线的检测成功率和定位误差均优于全向天线，突出空间智能的重要性。

Conclusion: 结果表明，机器人的空间智能和优化巡逻路线及天线选择对于有效的电子监控至关重要。

Abstract: This paper introduces a method for designing spatially intelligent robot
swarm behaviors to localize concealed radio emitters. We use differential
evolution to generate geometric patrol routes that localize unknown signals
independently of emitter parameters, a key challenge in electromagnetic
surveillance. Patrol shape and antenna type are shown to influence information
gain, which in turn determines the effective triangulation coverage. We
simulate a four-robot swarm across eight configurations, assigning
pre-generated patrol routes based on a specified patrol shape and sensing
capability (antenna type: omnidirectional or directional). An emitter is placed
within the map for each trial, with randomized position, transmission power and
frequency. Results show that omnidirectional localization success rates are
driven primarily by source location rather than signal properties, with
failures occurring most often when sources are placed in peripheral areas of
the map. Directional antennas are able to overcome this limitation due to their
higher gain and directivity, with an average detection success rate of 98.75%
compared to 80.25% for omnidirectional. Average localization errors range from
1.01-1.30 m for directional sensing and 1.67-1.90 m for omnidirectional
sensing; while directional sensing also benefits from shorter patrol edges.
These results demonstrate that a swarm's ability to predict electromagnetic
phenomena is directly dependent on its physical interaction with the
environment. Consequently, spatial intelligence, realized here through
optimized patrol routes and antenna selection, is a critical design
consideration for effective robotic surveillance.

</details>


### [22] [Adaptive Obstacle-Aware Task Assignment and Planning for Heterogeneous Robot Teaming](https://arxiv.org/abs/2510.14063)
*Nan Li,Jiming Ren,Haris Miller,Samuel Coogan,Karen M. Feigh,Ye Zhao*

Main category: cs.RO

TL;DR: OATH提供了一种新的障碍物感知任务分配与规划方法，显著提升了多代理系统在复杂环境中的性能。


<details>
  <summary>Details</summary>
Motivation: 针对多代理任务分配与规划中的可扩展性、空间推理和适应性挑战，尤其在障碍物丰富的环境中，提出新的解决方案。

Method: 使用自适应Halton序列图和集群拍卖选择框架，同时结合LLM来实时解读人类指令，进行任务分配与规划。

Result: OATH通过引入障碍物感知策略，在NVIDIA Isaac Sim中验证，显示出显著提升的任务分配效果。

Conclusion: OATH在任务分配质量、可扩展性、适应动态变化能力以及整体执行性能上相比于现有最先进的MATP基准有显著提升。

Abstract: Multi-Agent Task Assignment and Planning (MATP) has attracted growing
attention but remains challenging in terms of scalability, spatial reasoning,
and adaptability in obstacle-rich environments. To address these challenges, we
propose OATH: Adaptive Obstacle-Aware Task Assignment and Planning for
Heterogeneous Robot Teaming, which advances MATP by introducing a novel
obstacle-aware strategy for task assignment. First, we develop an adaptive
Halton sequence map, the first known application of Halton sampling with
obstacle-aware adaptation in MATP, which adjusts sampling density based on
obstacle distribution. Second, we propose a cluster-auction-selection framework
that integrates obstacle-aware clustering with weighted auctions and
intra-cluster task selection. These mechanisms jointly enable effective
coordination among heterogeneous robots while maintaining scalability and
near-optimal allocation performance. In addition, our framework leverages an
LLM to interpret human instructions and directly guide the planner in real
time. We validate OATH in NVIDIA Isaac Sim, showing substantial improvements in
task assignment quality, scalability, adaptability to dynamic changes, and
overall execution performance compared to state-of-the-art MATP baselines. A
project website is available at https://llm-oath.github.io/.

</details>


### [23] [Optimistic Reinforcement Learning-Based Skill Insertions for Task and Motion Planning](https://arxiv.org/abs/2510.14065)
*Gaoyuan Liu,Joris de Winter,Yuri Durodie,Denis Steckelmacher,Ann Nowe,Bram Vanderborght*

Main category: cs.RO

TL;DR: 结合强化学习技能与任务与动作规划，提高了应对不确定性和规划效率。


<details>
  <summary>Details</summary>
Motivation: 任务与动作规划需要长期推理和处理不确定性，而传统规划方法难以处理概率性动作，因此需要新的集成方法。

Method: 我们设计了一种集成RL技能的方法，使用数据驱动的逻辑组件定义RL技能，结合符号规划与计划优化。

Result: 本研究提出了一种将强化学习（RL）技能集成到任务与动作规划（TAMP）流程中的方法，旨在应对不确定性问题并提高规划效率。

Conclusion: 通过嵌入RL技能，本方法扩展了TAMP在具有概率性技能领域中的能力，并比之前的方法提高了规划效率。

Abstract: Task and motion planning (TAMP) for robotics manipulation necessitates
long-horizon reasoning involving versatile actions and skills. While
deterministic actions can be crafted by sampling or optimizing with certain
constraints, planning actions with uncertainty, i.e., probabilistic actions,
remains a challenge for TAMP. On the contrary, Reinforcement Learning (RL)
excels in acquiring versatile, yet short-horizon, manipulation skills that are
robust with uncertainties. In this letter, we design a method that integrates
RL skills into TAMP pipelines. Besides the policy, a RL skill is defined with
data-driven logical components that enable the skill to be deployed by symbolic
planning. A plan refinement sub-routine is designed to further tackle the
inevitable effect uncertainties. In the experiments, we compare our method with
baseline hierarchical planning from both TAMP and RL fields and illustrate the
strength of the method. The results show that by embedding RL skills, we extend
the capability of TAMP to domains with probabilistic skills, and improve the
planning efficiency compared to the previous methods.

</details>


### [24] [Partial Feedback Linearization Control of a Cable-Suspended Multirotor Platform for Stabilization of an Attached Load](https://arxiv.org/abs/2510.14072)
*Hemjyoti Das,Christian Ott*

Main category: cs.RO

TL;DR: 本研究针对悬挂平台及载荷的稳定性，提出一种新的控制方法，考虑了系统的欠驱动特性和耦合动力学。


<details>
  <summary>Details</summary>
Motivation: 旨在为户外施工场景中的起重机提供一种可靠的控制方案，以便在运输重物时保证稳定性。

Method: 采用部分反馈线性化( PFL)方法，考虑系统的欠驱动性和耦合动态进行稳定性分析与鲁棒性分析。

Result: 提出了一种基于部分反馈线性化的新型控制方法，用于稳定悬挂平台及其附加载荷的系统。

Conclusion: 实验和模拟测试验证了所提出的控制方法的有效性，并显示其在外部干扰下的强健性。

Abstract: In this work, we present a novel control approach based on partial feedback
linearization (PFL) for the stabilization of a suspended aerial platform with
an attached load. Such systems are envisioned for various applications in
construction sites involving cranes, such as the holding and transportation of
heavy objects. Our proposed control approach considers the underactuation of
the whole system while utilizing its coupled dynamics for stabilization. We
demonstrate using numerical stability analysis that these coupled terms are
crucial for the stabilization of the complete system. We also carried out
robustness analysis of the proposed approach in the presence of external wind
disturbances, sensor noise, and uncertainties in system dynamics. As our
envisioned target application involves cranes in outdoor construction sites,
our control approaches rely on only onboard sensors, thus making it suitable
for such applications. We carried out extensive simulation studies and
experimental tests to validate our proposed control approach.

</details>


### [25] [ViTacGen: Robotic Pushing with Vision-to-Touch Generation](https://arxiv.org/abs/2510.14117)
*Zhiyuan Wu,Yijiong Lin,Yongqiang Zhao,Xuyang Zhang,Zhuo Chen,Nathan Lepora,Shan Luo*

Main category: cs.RO

TL;DR: ViTacGen 是一种新颖的视觉机器人推理框架，通过视觉生成触觉信息，成功克服了现实触觉传感器的局限性，实验成功率高达86%。


<details>
  <summary>Details</summary>
Motivation: 解决真实触觉传感器在硬件上的局限性和部署挑战，同时提升视觉仅依赖的机器人推理的性能。

Method: 使用编码器-解码器结构的视觉到触觉生成网络，生成接触深度图像，并结合基于对比学习的强化学习策略来融合视觉与生成的触觉数据。

Result: 在模拟和真实实验中进行验证，显示出ViTacGen的有效性与优越的性能。

Conclusion: ViTacGen 提供了一种高效的视觉推理与触觉生成框架，成功克服了高成本和真实触觉传感器的限制，并在模拟与实际实验中表现优异，成功率高达86%。

Abstract: Robotic pushing is a fundamental manipulation task that requires tactile
feedback to capture subtle contact forces and dynamics between the end-effector
and the object. However, real tactile sensors often face hardware limitations
such as high costs and fragility, and deployment challenges involving
calibration and variations between different sensors, while vision-only
policies struggle with satisfactory performance. Inspired by humans' ability to
infer tactile states from vision, we propose ViTacGen, a novel robot
manipulation framework designed for visual robotic pushing with vision-to-touch
generation in reinforcement learning to eliminate the reliance on
high-resolution real tactile sensors, enabling effective zero-shot deployment
on visual-only robotic systems. Specifically, ViTacGen consists of an
encoder-decoder vision-to-touch generation network that generates contact depth
images, a standardized tactile representation, directly from visual image
sequence, followed by a reinforcement learning policy that fuses visual-tactile
data with contrastive learning based on visual and generated tactile
observations. We validate the effectiveness of our approach in both simulation
and real world experiments, demonstrating its superior performance and
achieving a success rate of up to 86\%.

</details>


### [26] [Prescribed Performance Control of Deformable Object Manipulation in Spatial Latent Space](https://arxiv.org/abs/2510.14234)
*Ning Han,Gu Gong,Bin Zhang,Yuexuan Xu,Bohan Yang,Yunhui Liu,David Navarro-Alarcon*

Main category: cs.RO

TL;DR: 本文提出了一种基于关键点的无模型形状控制方法，通过深度学习提取关键点，简化可变形物体操作，结合BLF增强控制精度，并验证了系统的稳定性。


<details>
  <summary>Details</summary>
Motivation: 在机器人系统中，操纵3D可变形物体面临极大的挑战，现有方法常依赖特征降维，本文旨在以一种新型的方式处理这些复杂的可变形动态和状态空间。

Method: 采用无模型控制方法，通过深度学习提取可变形物体的关键点坐标，使用形变Jacobian矩阵来描述其形状动态，并结合BLF进行约束控制。

Result: 本文提出了一种新颖的无模型控制方法，以控制3D可变形物体的形状，并在关键点上施加约束。通过提取关键点坐标作为特征向量，利用深度学习技术从物体的点云中获取信息，简化了可变形物体的操作问题，进而形成了一个视觉伺服控制问题，使用形变Jacobian矩阵描述形状动态。通过融入障碍Lyapunov函数（BLF），提出了一种规定性能控制方法，以增强控制精度，同时对闭环系统的稳定性进行了严格分析和验证。实验结果证明了该方法的有效性和鲁棒性。

Conclusion: 实验结果验证了该控制方法在可变形物体操作中的有效性和鲁棒性，显示其在实际应用中具有广泛的潜力。

Abstract: Manipulating three-dimensional (3D) deformable objects presents significant
challenges for robotic systems due to their infinite-dimensional state space
and complex deformable dynamics. This paper proposes a novel model-free
approach for shape control with constraints imposed on key points. Unlike
existing methods that rely on feature dimensionality reduction, the proposed
controller leverages the coordinates of key points as the feature vector, which
are extracted from the deformable object's point cloud using deep learning
methods. This approach not only reduces the dimensionality of the feature space
but also retains the spatial information of the object. By extracting key
points, the manipulation of deformable objects is simplified into a visual
servoing problem, where the shape dynamics are described using a deformation
Jacobian matrix. To enhance control accuracy, a prescribed performance control
method is developed by integrating barrier Lyapunov functions (BLF) to enforce
constraints on the key points. The stability of the closed-loop system is
rigorously analyzed and verified using the Lyapunov method. Experimental
results further demonstrate the effectiveness and robustness of the proposed
method.

</details>


### [27] [Learning Human-Humanoid Coordination for Collaborative Object Carrying](https://arxiv.org/abs/2510.14293)
*Yushi Du,Yixuan Li,Baoxiong Jia,Yutang Lin,Pei Zhou,Wei Liang,Yanchao Yang,Siyuan Huang*

Main category: cs.RO

TL;DR: 本研究提出了一种新型的自我感知强化学习方法COLA，实现了有效的人类与类人机器协作，提升了搬运任务的效率和稳定性。


<details>
  <summary>Details</summary>
Motivation: 人类与类人机器人协作在医疗、家务和制造等领域应用前景广阔，但由于类人机器人的复杂全身动力学，其顺应性协作尚未被充分探索。

Method: 提出了一种名为COLA的自我感知强化学习方法，通过在单一策略中结合领导者和跟随者行为，进行闭环环境训练，模拟动态物体交互。

Result: 在合作搬运任务中，模型在模拟实验中将人类的努力减少了24.7%，且在现实世界实验中验证了跨不同物体类型和运动模式的稳健性，与基线模型相比，用户研究显示平均提升27.4%。

Conclusion: 提出的方法能够在没有外部传感器和复杂交互模型的情况下，实现人类和类人机器人间的顺应性协作，提供了实际应用的解决方案。

Abstract: Human-humanoid collaboration shows significant promise for applications in
healthcare, domestic assistance, and manufacturing. While compliant robot-human
collaboration has been extensively developed for robotic arms, enabling
compliant human-humanoid collaboration remains largely unexplored due to
humanoids' complex whole-body dynamics. In this paper, we propose a
proprioception-only reinforcement learning approach, COLA, that combines leader
and follower behaviors within a single policy. The model is trained in a
closed-loop environment with dynamic object interactions to predict object
motion patterns and human intentions implicitly, enabling compliant
collaboration to maintain load balance through coordinated trajectory planning.
We evaluate our approach through comprehensive simulator and real-world
experiments on collaborative carrying tasks, demonstrating the effectiveness,
generalization, and robustness of our model across various terrains and
objects. Simulation experiments demonstrate that our model reduces human effort
by 24.7%. compared to baseline approaches while maintaining object stability.
Real-world experiments validate robust collaborative carrying across different
object types (boxes, desks, stretchers, etc.) and movement patterns
(straight-line, turning, slope climbing). Human user studies with 23
participants confirm an average improvement of 27.4% compared to baseline
models. Our method enables compliant human-humanoid collaborative carrying
without requiring external sensors or complex interaction models, offering a
practical solution for real-world deployment.

</details>


### [28] [Expertise need not monopolize: Action-Specialized Mixture of Experts for Vision-Language-Action Learning](https://arxiv.org/abs/2510.14300)
*Weijie Shen,Yitian Liu,Yuhao Wu,Zhixuan Liang,Sijia Gu,Dehui Wang,Tian Nian,Lei Xu,Yusen Qin,Jiangmiao Pang,Xinping Guan,Xiaokang Yang,Yao Mu*

Main category: cs.RO

TL;DR: AdaMoE通过去耦专家选择与权重控制，实现协作专家利用，从而提高机器人操作任务的性能和计算效率。


<details>
  <summary>Details</summary>
Motivation: 解决训练新VLA模型所需的计算资源和数据稀缺问题，同时在实时控制中平衡模型容量和计算效率。

Method: 提出AdaMoE，一种混合专家架构，通过稀疏激活的MoE层替代前馈层来扩展动作专家，并利用去耦技术。

Result: AdaMoE在关键基准测试中优于基线模型，LIBERO提高1.8%，RoboTwin提高9.3%，在实际实验中提高21.5%。

Conclusion: AdaMoE在机器人操作任务中表现出色，验证了其在实际应用中的有效性。

Abstract: Vision-Language-Action (VLA) models are experiencing rapid development and
demonstrating promising capabilities in robotic manipulation tasks. However,
scaling up VLA models presents several critical challenges: (1) Training new
VLA models from scratch demands substantial computational resources and
extensive datasets. Given the current scarcity of robot data, it becomes
particularly valuable to fully leverage well-pretrained VLA model weights
during the scaling process. (2) Real-time control requires carefully balancing
model capacity with computational efficiency. To address these challenges, We
propose AdaMoE, a Mixture-of-Experts (MoE) architecture that inherits
pretrained weights from dense VLA models, and scales up the action expert by
substituting the feedforward layers into sparsely activated MoE layers. AdaMoE
employs a decoupling technique that decouples expert selection from expert
weighting through an independent scale adapter working alongside the
traditional router. This enables experts to be selected based on task relevance
while contributing with independently controlled weights, allowing
collaborative expert utilization rather than winner-takes-all dynamics. Our
approach demonstrates that expertise need not monopolize. Instead, through
collaborative expert utilization, we can achieve superior performance while
maintaining computational efficiency. AdaMoE consistently outperforms the
baseline model across key benchmarks, delivering performance gains of 1.8% on
LIBERO and 9.3% on RoboTwin. Most importantly, a substantial 21.5% improvement
in real-world experiments validates its practical effectiveness for robotic
manipulation tasks.

</details>


### [29] [Risk-Aware Reinforcement Learning with Bandit-Based Adaptation for Quadrupedal Locomotion](https://arxiv.org/abs/2510.14338)
*Yuanhong Zeng,Anushri Dixit*

Main category: cs.RO

TL;DR: 本研究提出了一种风险感知的强化学习方法，专注于四足 locomotion，通过 CVaR 约束提升稳定性和样本效率，并且采用多臂强盗机制实时选择最佳策略。


<details>
  <summary>Details</summary>
Motivation: 研究四足生物的运动能力，以及提高运动稳定性和样本效率,同时时间适应未知环境条件。

Method: 使用受条件价值风险（CVaR）约束的政策优化技术训练风险条件的政策，并通过多臂强盗框架适应性选择最佳政策。

Result: 在八种未见设置下进行模拟评估，并在之前未见的地形上在Unitree Go2机器人上验证。

Conclusion: 我们的风险感知政策在未知环境中的平均和尾部表现几乎是其他基线的两倍，并且我们的带 bandit 自适应能够在两分钟内选择出最佳的风险感知政策。

Abstract: In this work, we study risk-aware reinforcement learning for quadrupedal
locomotion. Our approach trains a family of risk-conditioned policies using a
Conditional Value-at-Risk (CVaR) constrained policy optimization technique that
provides improved stability and sample efficiency. At deployment, we adaptively
select the best performing policy from the family of policies using a
multi-armed bandit framework that uses only observed episodic returns, without
any privileged environment information, and adapts to unknown conditions on the
fly. Hence, we train quadrupedal locomotion policies at various levels of
robustness using CVaR and adaptively select the desired level of robustness
online to ensure performance in unknown environments. We evaluate our method in
simulation across eight unseen settings (by changing dynamics, contacts,
sensing noise, and terrain) and on a Unitree Go2 robot in previously unseen
terrains. Our risk-aware policy attains nearly twice the mean and tail
performance in unseen environments compared to other baselines and our
bandit-based adaptation selects the best-performing risk-aware policy in
unknown terrain within two minutes of operation.

</details>


### [30] [SUM-AgriVLN: Spatial Understanding Memory for Agricultural Vision-and-Language Navigation](https://arxiv.org/abs/2510.14357)
*Xiaobei Zhao,Xingqi Lyu,Xiang Li*

Main category: cs.RO

TL;DR: 本文提出了一种新的农业视觉和语言导航方法SUM-AgriVLN，通过空间理解记忆提高了导航成功率。


<details>
  <summary>Details</summary>
Motivation: 农业机器人在农业任务中的应用日益增加，但仍然依赖手动操作或固定轨道系统进行移动。

Method: 通过空间理解模块（SUM）进行3D重建和表示，以保存空间记忆，用于后续导航指令。

Result: SUM-AgriVLN方法在A2A基准测试中成功将成功率从0.47提升至0.54，略微增加导航误差。

Conclusion: SUM-AgriVLN在农业领域展示出了先进的性能，能有效利用历史导航经验。

Abstract: Agricultural robots are emerging as powerful assistants across a wide range
of agricultural tasks, nevertheless, still heavily rely on manual operation or
fixed rail systems for movement. The AgriVLN method and the A2A benchmark
pioneeringly extend Vision-and-Language Navigation (VLN) to the agricultural
domain, enabling robots to navigate to the target positions following the
natural language instructions. In practical agricultural scenarios, navigation
instructions often repeatedly occur, yet AgriVLN treat each instruction as an
independent episode, overlooking the potential of past experiences to provide
spatial context for subsequent ones. To bridge this gap, we propose the method
of Spatial Understanding Memory for Agricultural Vision-and-Language Navigation
(SUM-AgriVLN), in which the SUM module employs spatial understanding and save
spatial memory through 3D reconstruction and representation. When evaluated on
the A2A benchmark, our SUM-AgriVLN effectively improves Success Rate from 0.47
to 0.54 with slight sacrifice on Navigation Error from 2.91m to 2.93m,
demonstrating the state-of-the-art performance in the agricultural domain.
Code: https://github.com/AlexTraveling/SUM-AgriVLN.

</details>


### [31] [RoboANKLE: Design, Development, and Functional Evaluation of a Robotic Ankle with a Motorized Compliant Unit](https://arxiv.org/abs/2510.14414)
*Baris Baysal,Omid Arfaie,Ramazan Unal*

Main category: cs.RO

TL;DR: 本研究设计了一种名为 RoboANKLE 的下肢假肢，能够模仿人类踝关节的自然运动，实现95%的准确率，并提升行走所需扭矩57%。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在设计一种能够提供充分推离辅助的下肢假肢，以解决现有主被动假肢不足的挑战，并模拟人类踝关节的自然运动。

Method: 本研究采用运动和动力分析，结合计算机辅助设计（CAD）进行动态和结构分析，优化最小重量和设计性能。

Result: RoboANKLE 的原型质量为 1.92 kg，尺寸为 261x107x420 mm，具有比自然行走更高的功率生成能力，增加了10%。

Conclusion: RoboANKLE 在功能评估中显示出优越的性能，能够以95%的准确率实现自然最大背屈角，同时生成的扭矩比自然行走所需的高出57%。

Abstract: This study presents a powered transtibial prosthesis with complete push-off
assistance, RoboANKLE. The design aims to fulfill specific requirements, such
as a sufficient range of motion (RoM) while providing the necessary torque for
achieving natural ankle motion in daily activities. Addressing the challenges
faced in designing active transtibial prostheses, such as maintaining energetic
autonomy and minimizing weight, is vital for the study. With this aim, we try
to imitate the human ankle by providing extensive push-off assistance to
achieve a natural-like torque profile. Thus, Energy Store and Extended Release
mechanism (ESER) is employed with a novel Extra Energy Storage (EES) mechanism.
Kinematic and kinetic analyses are carried out to determine the design
parameters and assess the design performance. Subsequently, a Computer-Aided
Design (CAD) model is built and used in comprehensive dynamic and structural
analyses. These analyses are used for the design performance evaluation and
determine the forces and torques applied to the prosthesis, which aids in
optimizing the design for minimal weight via structural analysis and topology
optimization. The design of the prototype is then finalized and manufactured
for experimental evaluation to validate the design and functionality. The
prototype is realized with a mass of 1.92 kg and dimensions of 261x107x420 mm.
The Functional evaluations of the RoboANKLE revealed that it is capable of
achieving the natural maximum dorsi-flexion angle with 95% accuracy. Also,
Thanks to the implemented mechanisms, the results show that RoboANKLE can
generate 57% higher than the required torque for natural walking. The result of
the power generation capacity of the RoboANKLE is 10% more than the natural
power during the gait cycle.

</details>


### [32] [Towards Adaptable Humanoid Control via Adaptive Motion Tracking](https://arxiv.org/abs/2510.14454)
*Tao Huang,Huayi Wang,Junli Ren,Kangning Yin,Zirui Wang,Xiao Chen,Feiyu Jia,Wentao Zhang,Junfeng Long,Jingbo Wang,Jiangmiao Pang*

Main category: cs.RO

TL;DR: 提出AdaMimic算法，通过稀疏化和编辑单一参考运动，实现高效的运动模仿与适应性。


<details>
  <summary>Details</summary>
Motivation: 现有的方法在运动适应性与模仿准确性之间存在权衡，AdaMimic旨在结合其优点。

Method: 提出一种新的运动跟踪算法AdaMimic，通过一个单一参考运动实现可适应的人形控制。

Result: 通过稀疏化参考运动并应用轻编辑，生成增强数据集，能够有效降低数据依赖，实现了高效的人形机器人控制。

Conclusion: 在多个任务和多种适应条件下，AdaMimic在模拟和实际Unitree G1机器人中表现出显著的改进。

Abstract: Humanoid robots are envisioned to adapt demonstrated motions to diverse
real-world conditions while accurately preserving motion patterns. Existing
motion prior approaches enable well adaptability with a few motions but often
sacrifice imitation accuracy, whereas motion-tracking methods achieve accurate
imitation yet require many training motions and a test-time target motion to
adapt. To combine their strengths, we introduce AdaMimic, a novel motion
tracking algorithm that enables adaptable humanoid control from a single
reference motion. To reduce data dependence while ensuring adaptability, our
method first creates an augmented dataset by sparsifying the single reference
motion into keyframes and applying light editing with minimal physical
assumptions. A policy is then initialized by tracking these sparse keyframes to
generate dense intermediate motions, and adapters are subsequently trained to
adjust tracking speed and refine low-level actions based on the adjustment,
enabling flexible time warping that further improves imitation accuracy and
adaptability. We validate these significant improvements in our approach in
both simulation and the real-world Unitree G1 humanoid robot in multiple tasks
across a wide range of adaptation conditions. Videos and code are available at
https://taohuang13.github.io/adamimic.github.io/.

</details>


### [33] [Restoring Noisy Demonstration for Imitation Learning With Diffusion Models](https://arxiv.org/abs/2510.14467)
*Shang-Fu Chen,Co Yong,Shao-Hua Sun*

Main category: cs.RO

TL;DR: 本文提出了一种滤波与恢复框架，旨在从带噪声的专家示范中学习政策，实验证实其优于现有模仿学习方法。


<details>
  <summary>Details</summary>
Motivation: 针对现有模仿学习算法假设完美专家示范的问题，处理人类专家错误和传感器/控制系统不准确导致的不完美示范。

Method: 提出一种滤波与恢复框架，通过过滤干净样本并学习条件扩散模型来恢复带噪声的示范。

Result: 实验结果表明，该框架在机器人臂操控、灵巧操控和行走等任务上均优于现有方法，证明了框架的有效性和稳健性。

Conclusion: 该框架在处理含有噪声的离线示范数据方面具有实用性，超越了现有方法。

Abstract: Imitation learning (IL) aims to learn a policy from expert demonstrations and
has been applied to various applications. By learning from the expert policy,
IL methods do not require environmental interactions or reward signals.
However, most existing imitation learning algorithms assume perfect expert
demonstrations, but expert demonstrations often contain imperfections caused by
errors from human experts or sensor/control system inaccuracies. To address the
above problems, this work proposes a filter-and-restore framework to best
leverage expert demonstrations with inherent noise. Our proposed method first
filters clean samples from the demonstrations and then learns conditional
diffusion models to recover the noisy ones. We evaluate our proposed framework
and existing methods in various domains, including robot arm manipulation,
dexterous manipulation, and locomotion. The experiment results show that our
proposed framework consistently outperforms existing methods across all the
tasks. Ablation studies further validate the effectiveness of each component
and demonstrate the framework's robustness to different noise types and levels.
These results confirm the practical applicability of our framework to noisy
offline demonstration data.

</details>


### [34] [Stability Criteria and Motor Performance in Delayed Haptic Dyadic Interactions Mediated by Robots](https://arxiv.org/abs/2510.14511)
*Mingtian Du,Suhas Raghavendra Kulkarni,Simone Kager,Domenico Campolo*

Main category: cs.RO

TL;DR: 本文提出机器人中介人际交互系统的稳定性标准，特别关注网络延迟对触觉通信的影响，发现无延迟和有延迟的稳定标准，并建议了有效的延迟补偿策略。


<details>
  <summary>Details</summary>
Motivation: 研究机器人中介的人际交互系统在网络诱导延迟下的稳定性，特别是触觉通信。

Method: 通过频域分析和数值模拟，识别了与延迟无关和与延迟相关的稳定性标准。

Result: 确定了无论延迟如何，延迟无关标准都能保证稳定，以及存在最大可容忍延迟的延迟相关标准。增加的刚度以非线性方式降低了最大可容忍延迟，提高了系统的脆弱性。实验表明，稳定性与运动性能之间存在相关性。

Conclusion: 本研究提出的稳定性标准可广泛应用于机器人中介的人际交互系统，提供了设计稳定远程互动系统的指导。

Abstract: This paper establishes analytical stability criteria for robot-mediated
human-human (dyadic) interaction systems, focusing on haptic communication
under network-induced time delays. Through frequency-domain analysis supported
by numerical simulations, we identify both delay-independent and
delay-dependent stability criteria. The delay-independent criterion guarantees
stability irrespective of the delay, whereas the delay-dependent criterion is
characterised by a maximum tolerable delay before instability occurs. The
criteria demonstrate dependence on controller and robot dynamic parameters,
where increasing stiffness reduces the maximum tolerable delay in a non-linear
manner, thereby heightening system vulnerability. The proposed criteria can be
generalised to a wide range of robot-mediated interactions and serve as design
guidelines for stable remote dyadic systems. Experiments with robots performing
human-like movements further illustrate the correlation between stability and
motor performance. The findings of this paper suggest the prerequisites for
effective delay-compensation strategies.

</details>


### [35] [QuASH: Using Natural-Language Heuristics to Query Visual-Language Robotic Maps](https://arxiv.org/abs/2510.14546)
*Matti Pekkanen,Francesco Verdoja,Ville Kyrki*

Main category: cs.RO

TL;DR: 本论文提出一种基于视觉语言模型的嵌入技术，用于支持机器人地图的开放词汇场景理解，并通过自然语言同义词和反义词改进环境相关部分的查询能力。


<details>
  <summary>Details</summary>
Motivation: 利用视觉语言模型嵌入技术来克服传统标签的限制，实现更灵活的场景理解和环境查询。

Method: 通过利用查询相关的自然语言同义词和反义词，运用启发式方法估算相关语言空间，并训练分类器将环境划分为匹配和不匹配部分。

Result: 通过大量实验证明，该方法能够有效改进地图和图像的查询能力。

Conclusion: 该方法提高了地图和图像的可查询性，显示出在不同表示和编码器下具有广泛适用性，并且训练要求较低。

Abstract: Embeddings from Visual-Language Models are increasingly utilized to represent
semantics in robotic maps, offering an open-vocabulary scene understanding that
surpasses traditional, limited labels. Embeddings enable on-demand querying by
comparing embedded user text prompts to map embeddings via a similarity metric.
The key challenge in performing the task indicated in a query is that the robot
must determine the parts of the environment relevant to the query.
  This paper proposes a solution to this challenge. We leverage
natural-language synonyms and antonyms associated with the query within the
embedding space, applying heuristics to estimate the language space relevant to
the query, and use that to train a classifier to partition the environment into
matches and non-matches. We evaluate our method through extensive experiments,
querying both maps and standard image benchmarks. The results demonstrate
increased queryability of maps and images. Our querying technique is agnostic
to the representation and encoder used, and requires limited training.

</details>


### [36] [A Generalized Placeability Metric for Model-Free Unified Pick-and-Place Reasoning](https://arxiv.org/abs/2510.14584)
*Benno Wingender,Nils Dengler,Rohit Menon,Sicong Pan,Maren Bennewitz*

Main category: cs.RO

TL;DR: 本研究提出了一种无需形状先验、从噪声点云中直接评估物体放置姿势的通用可放置性度量，改善了抓取和放置的稳定性和合理性。


<details>
  <summary>Details</summary>
Motivation: 在现实世界的感知噪声下，可靠地抓取和放置未知物体仍然是一个挑战，现有方法依赖于强对象先验或平面支撑假设。

Method: 提出了一种通用的可放置性度量，通过噪声点云直接评估放置姿势，而不依赖形状先验。

Result: 该方法在处理未见的真实物体和非平面物体支撑时，能够在预测稳定性损失方面达到与CAD可比的准确性，并且通常能生成比基于学习的预测器更具物理合理性的放置。

Conclusion: 我们的提出的方法促进了无模型的统一抓取和放置推理，并选择出能够实现稳定且无碰撞放置的抓取-放置配对。

Abstract: To reliably pick and place unknown objects under real-world sensing noise
remains a challenging task, as existing methods rely on strong object priors
(e.g., CAD models), or planar-support assumptions, limiting generalization and
unified reasoning between grasping and placing. In this work, we introduce a
generalized placeability metric that evaluates placement poses directly from
noisy point clouds, without any shape priors. The metric jointly scores
stability, graspability, and clearance. From raw geometry, we extract the
support surfaces of the object to generate diverse candidates for
multi-orientation placement and sample contacts that satisfy collision and
stability constraints. By conditioning grasp scores on each candidate
placement, our proposed method enables model-free unified pick-and-place
reasoning and selects grasp-place pairs that lead to stable, collision-free
placements. On unseen real objects and non-planar object supports, our metric
delivers CAD-comparable accuracy in predicting stability loss and generally
produces more physically plausible placements than learning-based predictors.

</details>


### [37] [Proprioceptive Image: An Image Representation of Proprioceptive Data from Quadruped Robots for Contact Estimation Learning](https://arxiv.org/abs/2510.14612)
*Gabriel Fischer Abati,João Carlos Virgolino Soares,Giulio Turrisi,Victor Barasuol,Claudio Semini*

Main category: cs.RO

TL;DR: 本文提出了一种将四足机器人感知数据转化为二维图像的新方法，通过此方法可以提高运动相关任务的学习效果，尤其在接触估计中表现优越。


<details>
  <summary>Details</summary>
Motivation: 旨在提高四足机器人在多样化地形上的稳定性和自适应能力，特别是在接触状态估计方面。

Method: 通过将多种时间序列感知信号编码为结构化的二维图像，捕捉信号间的动态关系和步态模式，以便使用卷积神经网络处理这些数据。

Result: 本文提出了一种新颖的方法，通过将四足机器人感知时间序列数据表示为结构化的二维图像，从而使卷积神经网络能够学习与运动相关的任务。该方法编码了多个感知信号的时间动态，同时保留了机器人在图像空间排列中的形态结构。此转换捕捉到信号间的相关性和基于步态的模式，为特征空间提供了比直接时间序列处理更丰富的信息。我们将这一概念应用于接触估计问题，这是在多样化地形上实现稳定和自适应运动的一项关键能力。在真实数据集和模拟环境中的实验评估表明，我们基于图像的表示在预测准确性和泛化能力方面持续提升，超过传统的基于序列的模型，强调了跨模态编码策略在机器人状态学习中的潜力。我们的方法在接触数据集上表现优越，相较于最近提出的MI-HGNN方法，接触状态准确率从87.7%提高到94.5%，且窗口大小缩短了15倍。

Conclusion: 该研究表明，基于图像的感知数据表示可以显著提升四足机器人在复杂地形上的运动识别能力。

Abstract: This paper presents a novel approach for representing proprioceptive
time-series data from quadruped robots as structured two-dimensional images,
enabling the use of convolutional neural networks for learning
locomotion-related tasks. The proposed method encodes temporal dynamics from
multiple proprioceptive signals, such as joint positions, IMU readings, and
foot velocities, while preserving the robot's morphological structure in the
spatial arrangement of the image. This transformation captures inter-signal
correlations and gait-dependent patterns, providing a richer feature space than
direct time-series processing. We apply this concept in the problem of contact
estimation, a key capability for stable and adaptive locomotion on diverse
terrains. Experimental evaluations on both real-world datasets and simulated
environments show that our image-based representation consistently enhances
prediction accuracy and generalization over conventional sequence-based models,
underscoring the potential of cross-modal encoding strategies for robotic state
learning. Our method achieves superior performance on the contact dataset,
improving contact state accuracy from 87.7% to 94.5% over the recently proposed
MI-HGNN method, using a 15 times shorter window size.

</details>


### [38] [Accelerated Multi-Modal Motion Planning Using Context-Conditioned Diffusion Models](https://arxiv.org/abs/2510.14615)
*Edward Sandra,Lander Vanroye,Dries Dirckx,Ruben Cartuyvels,Jan Swevers,Wilm Decré*

Main category: cs.RO

TL;DR: CAMPD是一种新型的运动规划方法，能够在多样化环境中以较少的时间生成高质量轨迹，无需重新训练.


<details>
  <summary>Details</summary>
Motivation: 传统的机器人运动规划方法在高维状态空间和复杂环境中扩展性不足，难以应对学习多模态数据分布的挑战。

Method: 通过无分类器去噪的概率扩散模型，结合U-Net结构及注意力机制，处理多个上下文参数。

Result: 在7自由度机器人操作器的实测评估中，CAMPD能够在未见过的环境中以较短时间生成高质量多模态轨迹。

Conclusion: CAMPD展现出在各种环境中的良好泛化能力，优于现有的运动规划方法.

Abstract: Classical methods in robot motion planning, such as sampling-based and
optimization-based methods, often struggle with scalability towards
higher-dimensional state spaces and complex environments. Diffusion models,
known for their capability to learn complex, high-dimensional and multi-modal
data distributions, provide a promising alternative when applied to motion
planning problems and have already shown interesting results. However, most of
the current approaches train their model for a single environment, limiting
their generalization to environments not seen during training. The techniques
that do train a model for multiple environments rely on a specific camera to
provide the model with the necessary environmental information and therefore
always require that sensor. To effectively adapt to diverse scenarios without
the need for retraining, this research proposes Context-Aware Motion Planning
Diffusion (CAMPD). CAMPD leverages a classifier-free denoising probabilistic
diffusion model, conditioned on sensor-agnostic contextual information. An
attention mechanism, integrated in the well-known U-Net architecture,
conditions the model on an arbitrary number of contextual parameters. CAMPD is
evaluated on a 7-DoF robot manipulator and benchmarked against state-of-the-art
approaches on real-world tasks, showing its ability to generalize to unseen
environments and generate high-quality, multi-modal trajectories, at a fraction
of the time required by existing methods.

</details>


### [39] [GOPLA: Generalizable Object Placement Learning via Synthetic Augmentation of Human Arrangement](https://arxiv.org/abs/2510.14627)
*Yao Zhong,Hanzhi Chen,Simon Schaefer,Anran Zhang,Stefan Leutenegger*

Main category: cs.RO

TL;DR: 提出了一种新的层次框架GOPLA，通过学习人类演示来优化机器人的物体放置，显著提升了放置成功率。


<details>
  <summary>Details</summary>
Motivation: 针对机器人物体放置任务中涉及的语义和几何难题，提出一种新的学习方法以优化机器人进行日常家务的能力。

Method: GOPLA框架综合运用多模态大语言模型和扩增的人类演示数据，生成结构化计划和空间映射，为物体放置提供支持。

Result: GOPLA框架能够有效提高机器人的物体放置成功率，通过学习人类演示数据，结合语义和几何信息，实现了更佳的物体放置效果。

Conclusion: GOPLA通过多模态学习和数据增强，能够在多种真实场景中有效应用，提高物体放置的准确性和物理合理性。

Abstract: Robots are expected to serve as intelligent assistants, helping humans with
everyday household organization. A central challenge in this setting is the
task of object placement, which requires reasoning about both semantic
preferences (e.g., common-sense object relations) and geometric feasibility
(e.g., collision avoidance). We present GOPLA, a hierarchical framework that
learns generalizable object placement from augmented human demonstrations. A
multi-modal large language model translates human instructions and visual
inputs into structured plans that specify pairwise object relationships. These
plans are then converted into 3D affordance maps with geometric common sense by
a spatial mapper, while a diffusion-based planner generates placement poses
guided by test-time costs, considering multi-plan distributions and collision
avoidance. To overcome data scarcity, we introduce a scalable pipeline that
expands human placement demonstrations into diverse synthetic training data.
Extensive experiments show that our approach improves placement success rates
by 30.04 percentage points over the runner-up, evaluated on positioning
accuracy and physical plausibility, demonstrating strong generalization across
a wide range of real-world robotic placement scenarios.

</details>


### [40] [Generative Models From and For Sampling-Based MPC: A Bootstrapped Approach For Adaptive Contact-Rich Manipulation](https://arxiv.org/abs/2510.14643)
*Lara Brudermüller,Brandon Hung,Xinghao Zhu,Jiuguang Wang,Nick Hawes,Preston Culbertson,Simon Le Cleac'h*

Main category: cs.RO

TL;DR: 提出了一种生成预测控制框架，通过条件流匹配模型来增强采样基础的模型预测控制，提升采样效率和规划效果。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法中依赖迭代优化和梯度求解的局限，通过直接从噪声数据中学习有效的提案分布。

Method: 基于条件流匹配模型对采样基础模型预测控制序列进行训练，从而提升在线规划中的采样效率。

Result: 实验结果表明，方法在样本效率、规划时域要求和任务变异的鲁棒性方面均有显著提升。

Conclusion: 该方法在真实世界的接触丰富的四足机器人运动操作中成功应用，显示了显著的规划效率和鲁棒性。

Abstract: We present a generative predictive control (GPC) framework that amortizes
sampling-based Model Predictive Control (SPC) by bootstrapping it with
conditional flow-matching models trained on SPC control sequences collected in
simulation. Unlike prior work relying on iterative refinement or gradient-based
solvers, we show that meaningful proposal distributions can be learned directly
from noisy SPC data, enabling more efficient and informed sampling during
online planning. We further demonstrate, for the first time, the application of
this approach to real-world contact-rich loco-manipulation with a quadruped
robot. Extensive experiments in simulation and on hardware show that our method
improves sample efficiency, reduces planning horizon requirements, and
generalizes robustly across task variations.

</details>


### [41] [Spatially anchored Tactile Awareness for Robust Dexterous Manipulation](https://arxiv.org/abs/2510.14647)
*Jialei Huang,Yang Ye,Yuanqing Gong,Xuezhou Zhu,Yang Gao,Kaifeng Zhang*

Main category: cs.RO

TL;DR: 本研究提出SaTA框架，通过将触觉特征锚定到手的运动框架，实现对复杂灵巧操作中物体几何的准确推理，显著提升了成功率和任务完成效率。


<details>
  <summary>Details</summary>
Motivation: 当前的学习框架未能有效利用触觉信号的感知丰富性及其与手运动的空间关系，导致对亚毫米精度任务的处理不佳。

Method: SaTA通过前向运动学将触觉特征明确锚定到手的运动框架中，不需要物体模型或显式姿态估计，从而实现准确的几何推理。

Result: SaTA在需要亚毫米对准精度的双手USB-C连接、需要精确线程啮合和旋转控制的灯泡安装，以及要求细腻力量调节和角度精确的卡片滑动等复杂的灵巧操作任务中得到了验证。

Conclusion: SaTA在多个基准测试中显著超越强大的视觉触觉基线，成功率提高了30%，任务完成时间减少了27%。

Abstract: Dexterous manipulation requires precise geometric reasoning, yet existing
visuo-tactile learning methods struggle with sub-millimeter precision tasks
that are routine for traditional model-based approaches. We identify a key
limitation: while tactile sensors provide rich contact information, current
learning frameworks fail to effectively leverage both the perceptual richness
of tactile signals and their spatial relationship with hand kinematics. We
believe an ideal tactile representation should explicitly ground contact
measurements in a stable reference frame while preserving detailed sensory
information, enabling policies to not only detect contact occurrence but also
precisely infer object geometry in the hand's coordinate system. We introduce
SaTA (Spatially-anchored Tactile Awareness for dexterous manipulation), an
end-to-end policy framework that explicitly anchors tactile features to the
hand's kinematic frame through forward kinematics, enabling accurate geometric
reasoning without requiring object models or explicit pose estimation. Our key
insight is that spatially grounded tactile representations allow policies to
not only detect contact occurrence but also precisely infer object geometry in
the hand's coordinate system. We validate SaTA on challenging dexterous
manipulation tasks, including bimanual USB-C mating in free space, a task
demanding sub-millimeter alignment precision, as well as light bulb
installation requiring precise thread engagement and rotational control, and
card sliding that demands delicate force modulation and angular precision.
These tasks represent significant challenges for learning-based methods due to
their stringent precision requirements. Across multiple benchmarks, SaTA
significantly outperforms strong visuo-tactile baselines, improving success
rates by up to 30 percentage while reducing task completion times by 27
percentage.

</details>


### [42] [When Planners Meet Reality: How Learned, Reactive Traffic Agents Shift nuPlan Benchmarks](https://arxiv.org/abs/2510.14677)
*Steffen Hagedorn,Luka Donkov,Aron Distelzweig,Alexandru P. Condurache*

Main category: cs.RO

TL;DR: 研究通过引入SMART代理替代传统IDM代理，表明传统方法高估了规划性能，并提出了新的评估基准。


<details>
  <summary>Details</summary>
Motivation: 目前的规则基础交通代理在评估规划者表现时过于简单，被动，无法真实反映复杂的交通交互能力。

Method: 将最先进的学习交通代理模型SMART整合进nuPlan，以评估规划者在更现实的条件下的表现。

Result: 通过分析14个近期的规划者和已建立的基准，发现基于IDM的模拟高估了规划性能，且大多数分数都出现了恶化，而许多规划者在复杂的多车道场景中的表现优于之前的假设。

Conclusion: 基于SMART的反应模拟是一种新的标准闭环基准，能够更真实地评估规划者的性能。

Abstract: Planner evaluation in closed-loop simulation often uses rule-based traffic
agents, whose simplistic and passive behavior can hide planner deficiencies and
bias rankings. Widely used IDM agents simply follow a lead vehicle and cannot
react to vehicles in adjacent lanes, hindering tests of complex interaction
capabilities. We address this issue by integrating the state-of-the-art learned
traffic agent model SMART into nuPlan. Thus, we are the first to evaluate
planners under more realistic conditions and quantify how conclusions shift
when narrowing the sim-to-real gap. Our analysis covers 14 recent planners and
established baselines and shows that IDM-based simulation overestimates
planning performance: nearly all scores deteriorate. In contrast, many planners
interact better than previously assumed and even improve in multi-lane,
interaction-heavy scenarios like lane changes or turns. Methods trained in
closed-loop demonstrate the best and most stable driving performance. However,
when reaching their limits in augmented edge-case scenarios, all learned
planners degrade abruptly, whereas rule-based planners maintain reasonable
basic behavior. Based on our results, we suggest SMART-reactive simulation as a
new standard closed-loop benchmark in nuPlan and release the SMART agents as a
drop-in alternative to IDM at https://github.com/shgd95/InteractiveClosedLoop.

</details>


### [43] [Leveraging Neural Descriptor Fields for Learning Contact-Aware Dynamic Recovery](https://arxiv.org/abs/2510.14768)
*Fan Yang,Zixuan Huang,Abhinav Kumar,Sergio Aguilera Marinovic,Soshi Iba,Rana Soltani Zarrin,Dmitry Berenson*

Main category: cs.RO

TL;DR: 提出CADRE框架，通过NDF模块改善抓取过程中对接触特征的提取，从而提高恢复效果和训练效率。


<details>
  <summary>Details</summary>
Motivation: 应对在实际操作中出现的意外错误和干扰，防止操纵物体掉落并为主要操作任务恢复有利的配置。

Method: 引入Contact-Aware Dynamic Recovery (CADRE)框架，结合神经描述场（NDF）模块提取隐式接触特征，应用于强化学习。

Result: 将接触特征纳入实验，提升了训练效率和强化学习的收敛性能，最终促成更成功的恢复。尤其在处理不同几何形状的未见物体时，CADRE展示出零样本泛化能力。

Conclusion: CADRE通过引入接触特征，显著提高了强化学习的表现，并能适应不同几何形状的物体。

Abstract: Real-world dexterous manipulation often encounters unexpected errors and
disturbances, which can lead to catastrophic failures, such as dropping the
manipulated object. To address this challenge, we focus on the problem of
catching a falling object while it remains within grasping range and,
importantly, resetting the system to a configuration favorable for resuming the
primary manipulation task. We propose Contact-Aware Dynamic Recovery (CADRE), a
reinforcement learning framework that incorporates a Neural Descriptor Field
(NDF)-inspired module to extract implicit contact features. Compared to methods
that rely solely on object pose or point cloud input, NDFs can directly reason
about finger-object correspondence and adapt to different object geometries.
Our experiments show that incorporating contact features improves training
efficiency, enhances convergence performance for RL training, and ultimately
leads to more successful recoveries. Additionally, we demonstrate that CADRE
can generalize zero-shot to unseen objects with different geometries.

</details>


### [44] [Open TeleDex: A Hardware-Agnostic Teleoperation System for Imitation Learning based Dexterous Manipulation](https://arxiv.org/abs/2510.14771)
*Xu Chi,Chao Zhang,Yang Su,Lingfeng Dou,Fujia Yang,Jiakuo Zhao,Haoyu Zhou,Xiaoyou Jia,Yong Zhou,Shan An*

Main category: cs.RO

TL;DR: 提出了Open TeleDex，一个能够支持多种机器人设备的远程操控框架，并引入新的手势重定向算法，提升了异构设备间的兼容性。


<details>
  <summary>Details</summary>
Motivation: 在机器人模仿学习系统的部署中，高精度的数据采集是一个关键瓶颈，尤其是在处理异构机器人平台时。现有的远程操控系统常常无法保证跨不同远程操控设备的高精度数据收集。

Method: 设计了一个统一的远程操控框架Open TeleDex，并提出了一种创新的手势重定向算法，以增强兼容性和可靠性。

Result: 开发了一个名为Open TeleDex的统一远程操控框架，专门用于演示数据的采集，并支持任何机器臂、灵巧手和外部输入设备。

Conclusion: Open TeleDex为复杂机器人操作和模仿学习的加速研究与发展奠定了基础，提供了一个高质量和开放的公共平台。

Abstract: Accurate and high-fidelity demonstration data acquisition is a critical
bottleneck for deploying robot Imitation Learning (IL) systems, particularly
when dealing with heterogeneous robotic platforms. Existing teleoperation
systems often fail to guarantee high-precision data collection across diverse
types of teleoperation devices. To address this, we developed Open TeleDex, a
unified teleoperation framework engineered for demonstration data collection.
Open TeleDex specifically tackles the TripleAny challenge, seamlessly
supporting any robotic arm, any dexterous hand, and any external input device.
Furthermore, we propose a novel hand pose retargeting algorithm that
significantly boosts the interoperability of Open TeleDex, enabling robust and
accurate compatibility with an even wider spectrum of heterogeneous master and
slave equipment. Open TeleDex establishes a foundational, high-quality, and
publicly available platform for accelerating both academic research and
industry development in complex robotic manipulation and IL.

</details>


### [45] [SkyDreamer: Interpretable End-to-End Vision-Based Drone Racing with Model-Based Reinforcement Learning](https://arxiv.org/abs/2510.14783)
*Aderik Verraest,Stavrow Bahnam,Robin Ferede,Guido de Croon,Christophe De Wagter*

Main category: cs.RO

TL;DR: SkyDreamer是首个实现从像素到电机指令的端到端无人机竞速策略，具备高速度与强适应性。


<details>
  <summary>Details</summary>
Motivation: 提升无人机竞速系统的通用性，实现在多种环境下的快速部署及有效控制。

Method: 研究基于模型的强化学习方法，利用世界模型作为隐含状态和参数的估计器，直接从视觉信息生成控制指令。

Result: SkyDreamer是一种新的自主无人机竞速系统，能够实现从像素级别到电机指令的端到端视觉映射，展现出高水平的性能和适应性。

Conclusion: SkyDreamer证明了在复杂环境下快速、精准无人机飞行的可行性，并成功缩小了模拟与现实之间的差距。

Abstract: Autonomous drone racing (ADR) systems have recently achieved champion-level
performance, yet remain highly specific to drone racing. While end-to-end
vision-based methods promise broader applicability, no system to date
simultaneously achieves full sim-to-real transfer, onboard execution, and
champion-level performance. In this work, we present SkyDreamer, to the best of
our knowledge, the first end-to-end vision-based ADR policy that maps directly
from pixel-level representations to motor commands. SkyDreamer builds on
informed Dreamer, a model-based reinforcement learning approach where the world
model decodes to privileged information only available during training. By
extending this concept to end-to-end vision-based ADR, the world model
effectively functions as an implicit state and parameter estimator, greatly
improving interpretability. SkyDreamer runs fully onboard without external aid,
resolves visual ambiguities by tracking progress using the state decoded from
the world model's hidden state, and requires no extrinsic camera calibration,
enabling rapid deployment across different drones without retraining.
Real-world experiments show that SkyDreamer achieves robust, high-speed flight,
executing tight maneuvers such as an inverted loop, a split-S and a ladder,
reaching speeds of up to 21 m/s and accelerations of up to 6 g. It further
demonstrates a non-trivial visual sim-to-real transfer by operating on
poor-quality segmentation masks, and exhibits robustness to battery depletion
by accurately estimating the maximum attainable motor RPM and adjusting its
flight path in real-time. These results highlight SkyDreamer's adaptability to
important aspects of the reality gap, bringing robustness while still achieving
extremely high-speed, agile flight.

</details>


### [46] [Neural Implicit Flow Fields for Spatio-Temporal Motion Mapping](https://arxiv.org/abs/2510.14827)
*Yufei Zhu,Shih-Min Yang,Andrey Rudenko,Tomasz P. Kucner,Achim J. Lilienthal,Martin Magnusson*

Main category: cs.RO

TL;DR: 本研究提出了一种新颖的连续时空动态地图表示方法，利用隐式神经网络改善运动模式的建模效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 安全高效地在复杂人类环境中操作机器人，需要良好的场地特定运动模式模型。现有模型通常需要离线构建且计算开销大。

Method: 提出了一种基于隐式神经函数的连续时空MoD表示，直接将坐标映射到半包裹高斯混合模型的参数。

Result: 提出了一种基于隐式神经网络函数的连续时空动态地图（MoD）表示，能够高效、准确地建模复杂的人类运动模式。

Conclusion: 所提出的方法在复杂人类运动模式建模中展现出了强大而高效的能力。

Abstract: Safe and efficient robot operation in complex human environments can benefit
from good models of site-specific motion patterns. Maps of Dynamics (MoDs)
provide such models by encoding statistical motion patterns in a map, but
existing representations use discrete spatial sampling and typically require
costly offline construction. We propose a continuous spatio-temporal MoD
representation based on implicit neural functions that directly map coordinates
to the parameters of a Semi-Wrapped Gaussian Mixture Model. This removes the
need for discretization and imputation for unevenly sampled regions, enabling
smooth generalization across both space and time. Evaluated on a large public
dataset with long-term real-world people tracking data, our method achieves
better accuracy of motion representation and smoother velocity distributions in
sparse regions while still being computationally efficient, compared to
available baselines. The proposed approach demonstrates a powerful and
efficient way of modeling complex human motion patterns.

</details>


### [47] [RL-100: Performant Robotic Manipulation with Real-World Reinforcement Learning](https://arxiv.org/abs/2510.14830)
*Kun Lei,Huanyu Li,Dongjie Yu,Zhenyu Wei,Lingxiao Guo,Zhennan Jiang,Ziyu Wang,Shiyu Liang,Huazhe Xu*

Main category: cs.RO

TL;DR: RL-100是一种新型强化学习框架，通过三阶段的训练策略，实现在多种任务中的高效、可靠和鲁棒的机器人操作。


<details>
  <summary>Details</summary>
Motivation: 为了实现机器人在家庭和工厂中的可靠、高效和鲁棒的操作，RL-100旨在提升机器人的操作能力，使其接近或超过熟练的人类操作员。

Method: RL-100是一个三阶段的强化学习框架，采用模仿学习、离线强化学习和在线强化学习的结合。

Result: RL-100在七个真实机器人任务中测试，总共900个实验中取得了100%的成功率，包括在一个任务中连续250次尝试的成功。

Conclusion: RL-100在多个真实机器人任务中表现出色，实现了100%的成功率，时间效率接近或优于人类，且具备长时间持续运行的能力。

Abstract: Real-world robotic manipulation in homes and factories demands reliability,
efficiency, and robustness that approach or surpass skilled human operators. We
present RL-100, a real-world reinforcement learning training framework built on
diffusion visuomotor policies trained bu supervised learning. RL-100 introduces
a three-stage pipeline. First, imitation learning leverages human priors.
Second, iterative offline reinforcement learning uses an Offline Policy
Evaluation procedure, abbreviated OPE, to gate PPO-style updates that are
applied in the denoising process for conservative and reliable improvement.
Third, online reinforcement learning eliminates residual failure modes. An
additional lightweight consistency distillation head compresses the multi-step
sampling process in diffusion into a single-step policy, enabling
high-frequency control with an order-of-magnitude reduction in latency while
preserving task performance. The framework is task-, embodiment-, and
representation-agnostic and supports both 3D point clouds and 2D RGB inputs, a
variety of robot platforms, and both single-step and action-chunk policies. We
evaluate RL-100 on seven real-robot tasks spanning dynamic rigid-body control,
such as Push-T and Agile Bowling, fluids and granular pouring, deformable cloth
folding, precise dexterous unscrewing, and multi-stage orange juicing. RL-100
attains 100\% success across evaluated trials for a total of 900 out of 900
episodes, including up to 250 out of 250 consecutive trials on one task. The
method achieves near-human teleoperation or better time efficiency and
demonstrates multi-hour robustness with uninterrupted operation lasting up to
two hours.

</details>


### [48] [Multi Agent Switching Mode Controller for Sound Source localization](https://arxiv.org/abs/2510.14849)
*Marcello Sorge,Nicola Cigarini,Riccardo Lorigiola,Giulia Michieletto,Andrea Masiero,Angelo Cenedese,Alberto Guarnieri*

Main category: cs.RO

TL;DR: 本研究设计了一种基于声学的多智能体目标定位控制策略，适用于单源和多源两种情境。


<details>
  <summary>Details</summary>
Motivation: 声学传感器在无法建立直接视线的情况下仍然能帮助机器人定位目标，因此其研究具有重要意义。

Method: 设计了一种开关模式控制策略，具体包括单源和多源的目标定位场景。

Result: 在考虑的两种场景中，提出的多智能体控制策略展示了优越的性能。

Conclusion: 基于声学的多智能体控制策略在目标定位中展示了有效性，能够应对复杂环境下的定位挑战。

Abstract: Source seeking is an important topic in robotic research, especially
considering sound-based sensors since they allow the agents to locate a target
even in critical conditions where it is not possible to establish a direct line
of sight. In this work, we design a multi- agent switching mode control
strategy for acoustic-based target localization. Two scenarios are considered:
single source localization, in which the agents are driven maintaining a rigid
formation towards the target, and multi-source scenario, in which each agent
searches for the targets independently from the others.

</details>


### [49] [SADCHER: Scheduling using Attention-based Dynamic Coalitions of Heterogeneous Robots in Real-Time](https://arxiv.org/abs/2510.14851)
*Jakob Bichler,Andreu Matoses Gimenez,Javier Alonso-Mora*

Main category: cs.RO

TL;DR: Sadcher是一个实时的多机器人任务分配框架，采用模仿学习和图注意力技术，能有效生成任务调度并具备可扩展性。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于提高异构多机器人团队在动态环境中的任务分配效率，确保符合动态联盟形成和任务优先级约束。

Method: Sadcher采用模仿学习，结合图注意力和变换器，进行任务调度奖励的预测，并使用松弛的二分匹配生成调度。

Result: Sadcher是一个针对异构多机器人团队的实时任务分配框架，结合动态联盟形成和任务优先级约束。通过模仿学习进行训练，Sadcher结合图注意力和变换器模型来预测机器人和任务之间的分配奖励。基于预测的奖励，采用松弛的二分匹配步骤生成具有可行性保证的高质量调度。我们明确建模了机器人和任务的位置、任务持续时间，以及机器人的剩余处理时间，从而实现了高级时效性和空间推理，并能够推广到与训练不同的时空分布的环境。该方法在经过优化求解的小规模实例上训练，能够扩展到更大的任务集和团队规模。Sadcher在针对小型和中型团队的随机未见问题上表现优于其他学习基础和启发式基准，计算时间适合实时操作。我们也探讨了基于采样的变体，并评估了在机器人和任务数量上的可扩展性。此外，我们发布了包含250,000个最优调度的数据集。

Conclusion: Sadcher展示了在实时多机器人任务分配中的有效性和可扩展性， outperforming其他基准，并且具有理论和实际应用价值。

Abstract: We present Sadcher, a real-time task assignment framework for heterogeneous
multi-robot teams that incorporates dynamic coalition formation and task
precedence constraints. Sadcher is trained through Imitation Learning and
combines graph attention and transformers to predict assignment rewards between
robots and tasks. Based on the predicted rewards, a relaxed bipartite matching
step generates high-quality schedules with feasibility guarantees. We
explicitly model robot and task positions, task durations, and robots'
remaining processing times, enabling advanced temporal and spatial reasoning
and generalization to environments with different spatiotemporal distributions
compared to training. Trained on optimally solved small-scale instances, our
method can scale to larger task sets and team sizes. Sadcher outperforms other
learning-based and heuristic baselines on randomized, unseen problems for small
and medium-sized teams with computation times suitable for real-time operation.
We also explore sampling-based variants and evaluate scalability across robot
and task counts. In addition, we release our dataset of 250,000 optimal
schedules: https://autonomousrobots.nl/paper_websites/sadcher_MRTA/

</details>


### [50] [STITCHER: Constrained Trajectory Planning in Known Environments with Real-Time Motion Primitive Search](https://arxiv.org/abs/2510.14893)
*Helene J. Levy,Brett T. Lopez*

Main category: cs.RO

TL;DR: 提出了一种名为STITCHER的新型优化无关路径规划框架，能实时生成安全的、高质量的轨迹，以应对复杂环境中的导航挑战。


<details>
  <summary>Details</summary>
Motivation: 为应对复杂环境中实时生成可行、无碰撞且满足状态或执行器约束的轨迹的挑战。

Method: 通过将短轨迹段结合在一起并进行图搜索，STITCHER生成长距离、富有表现力的、近优的轨迹。

Result: STITCHER在两种50m x 50m环境的路径测试中，能够在几毫秒内创建安全轨迹，并且在硬件测试中验证了其实时路径生成能力。

Conclusion: STITCHER能够在遵循非凸约束的同时提供实时的可跟踪路径，优于现有的基于优化的规划方法。

Abstract: Autonomous high-speed navigation through large, complex environments requires
real-time generation of agile trajectories that are dynamically feasible,
collision-free, and satisfy state or actuator constraints. Modern trajectory
planning techniques primarily use numerical optimization, as they enable the
systematic computation of high-quality, expressive trajectories that satisfy
various constraints. However, stringent requirements on computation time and
the risk of numerical instability can limit the use of optimization-based
planners in safety-critical scenarios. This work presents an optimization-free
planning framework called STITCHER that stitches short trajectory segments
together with graph search to compute long-range, expressive, and near-optimal
trajectories in real-time. STITCHER outperforms modern optimization-based
planners through our innovative planning architecture and several algorithmic
developments that make real-time planning possible. Extensive simulation
testing is performed to analyze the algorithmic components that make up
STITCHER, along with a thorough comparison with two state-of-the-art
optimization planners. Simulation tests show that safe trajectories can be
created within a few milliseconds for paths that span the entirety of two 50 m
x 50 m environments. Hardware tests with a custom quadrotor verify that
STITCHER can produce trackable paths in real-time while respecting nonconvex
constraints, such as limits on tilt angle and motor forces, which are otherwise
hard to include in optimization-based planners.

</details>


### [51] [VLA^2: Empowering Vision-Language-Action Models with an Agentic Framework for Unseen Concept Manipulation](https://arxiv.org/abs/2510.14902)
*Han Zhao,Jiaxuan Zhang,Wenxuan Song,Pengxiang Ding,Donglin Wang*

Main category: cs.RO

TL;DR: 提出了一种新的VLA框架VLA^2，以改善当前视觉-语言-行动模型在处理培训数据之外的对象概念时的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决现有VLA模型在面对未见对象描述和纹理时成功率显著下降的问题。

Method: VLA^2框架通过结合OpenVLA执行基础，并利用外部模块如网络检索和对象检测，来提供目标对象的视觉和文本知识。

Result: VLA^2相比于OpenVLA基线，在困难级别基准测试中成功率提高了44.2%，在所有定制环境中平均提高了20.2%。

Conclusion: VLA^2在定制的困难水平基准测试中，成功地超越了当前最先进的模型，并在不影响领域内任务的情况下，显著提高了成功率。

Abstract: Current vision-language-action (VLA) models, pre-trained on large-scale
robotic data, exhibit strong multi-task capabilities and generalize well to
variations in visual and language instructions for manipulation. However, their
success rate drops significantly when faced with object concepts outside the
training data, such as unseen object descriptions and textures in the dataset.
To address this, we propose a novel agentic framework, VLA^2, which leverages
OpenVLA as the execution backbone and effectively leverages external modules
such as web retrieval and object detection to provide visual and textual
knowledge about target objects to the VLA. This approach mitigates
generalization failure when handling out-of-distribution objects. Based on the
LIBERO simulation environment, we introduced novel objects and object
descriptions to construct a new evaluation benchmark with three difficulty
levels to test the effectiveness of our method. Our framework successfully
outperformed the current state-of-the-art models on our designed hard-level
generalization benchmark. Compared to the standalone OpenVLA baseline, VLA^2
achieves a 44.2% improvement in the success rate in the hard-level benchmark
and an average improvement of 20.2% in all customized environments without any
performance degradation on in-domain tasks. Project website:
https://vla-2.github.io.

</details>


### [52] [VT-Refine: Learning Bimanual Assembly with Visuo-Tactile Feedback via Simulation Fine-Tunin](https://arxiv.org/abs/2510.14930)
*Binghao Huang,Jie Xu,Iretiayo Akinola,Wei Yang,Balakumar Sundaralingam,Rowland O'Flaherty,Dieter Fox,Xiaolong Wang,Arsalan Mousavian,Yu-Wei Chao,Yunzhu Li*

Main category: cs.RO

TL;DR: VT-Refine是一个结合真实示范和触觉模拟的策略学习框架，显著提升了机器人在双手组装任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 人类在双手组装任务中高效应对丰富的触觉反馈，而单靠行为克隆难以在机器人中复制这种能力。

Method: 结合真实世界示范、高保真触觉模拟和强化学习，采用扩散策略在小规模示范集上训练，并在虚拟双胞胎上进行进一步优化。

Result: VT-Refine改进了组装性能，增强了模型的稳健性和泛化能力，提升了模拟到现实的迁移准确性。

Conclusion: VT-Refine通过提升数据多样性和促进有效策略微调，显著提高了仿真和现实世界中的组装性能。

Abstract: Humans excel at bimanual assembly tasks by adapting to rich tactile feedback
-- a capability that remains difficult to replicate in robots through
behavioral cloning alone, due to the suboptimality and limited diversity of
human demonstrations. In this work, we present VT-Refine, a visuo-tactile
policy learning framework that combines real-world demonstrations,
high-fidelity tactile simulation, and reinforcement learning to tackle precise,
contact-rich bimanual assembly. We begin by training a diffusion policy on a
small set of demonstrations using synchronized visual and tactile inputs. This
policy is then transferred to a simulated digital twin equipped with simulated
tactile sensors and further refined via large-scale reinforcement learning to
enhance robustness and generalization. To enable accurate sim-to-real transfer,
we leverage high-resolution piezoresistive tactile sensors that provide normal
force signals and can be realistically modeled in parallel using
GPU-accelerated simulation. Experimental results show that VT-Refine improves
assembly performance in both simulation and the real world by increasing data
diversity and enabling more effective policy fine-tuning. Our project page is
available at https://binghao-huang.github.io/vt_refine/.

</details>


### [53] [Architecture Is All You Need: Diversity-Enabled Sweet Spots for Robust Humanoid Locomotion](https://arxiv.org/abs/2510.14947)
*Blake Werner,Lizhi Yang,Aaron D. Ames*

Main category: cs.RO

TL;DR: 分层控制架构通过分开高频和低频决策，提升了机器人的稳健性。


<details>
  <summary>Details</summary>
Motivation: 在非结构化环境中，平衡快速的低级稳定与较慢的感知决策是实现鲁棒人形步态的关键。

Method: 通过两阶段的训练课程，首先进行盲稳定器的预训练，然后进行感知的微调，来实现稳健的性能。

Result: 该论文提出了一种简单的分层控制架构（LCA），通过高频率的本体感应稳定器和低频率的紧凑感知策略，实现了在复杂环境中机器人健壮的步态控制。

Conclusion: 分层控制架构的时域分离是实现稳健步态控制的关键，而不是网络的规模或复杂性。

Abstract: Robust humanoid locomotion in unstructured environments requires
architectures that balance fast low-level stabilization with slower perceptual
decision-making. We show that a simple layered control architecture (LCA), a
proprioceptive stabilizer running at high rate, coupled with a compact low-rate
perceptual policy, enables substantially more robust performance than
monolithic end-to-end designs, even when using minimal perception encoders.
Through a two-stage training curriculum (blind stabilizer pretraining followed
by perceptual fine-tuning), we demonstrate that layered policies consistently
outperform one-stage alternatives in both simulation and hardware. On a Unitree
G1 humanoid, our approach succeeds across stair and ledge tasks where one-stage
perceptual policies fail. These results highlight that architectural separation
of timescales, rather than network scale or complexity, is the key enabler for
robust perception-conditioned locomotion.

</details>


### [54] [From Language to Locomotion: Retargeting-free Humanoid Control via Motion Latent Guidance](https://arxiv.org/abs/2510.14952)
*Zhe Li,Cheng Chi,Yangyang Wei,Boan Zhu,Yibo Peng,Tao Huang,Pengwei Wang,Zhongyuan Wang,Shanghang Zhang,Chang Xu*

Main category: cs.RO

TL;DR: RoboGhost是一个无重定向的框架，直接利用语言生成类人机器人动作，显著提升了性能和响应速度。


<details>
  <summary>Details</summary>
Motivation: 现有语言指导的类人运动控制方案繁琐且不可靠，需要寻求一种更直接的从语言到动作的路径。

Method: 提出了一种无重定向的框架，直接基于语言条件来生成可操作的动作，而不是通过冗长的中间步骤。

Result: RoboGhost实现了基于扩散的策略，从噪声中直接去噪出可执行的动作，且在长时间区间保持一致性，同时确保稳定性和多样性。

Conclusion: RoboGhost框架显著降低了部署延迟，提高了成功率和跟踪准确性，并在真实人形机器人上产生平滑而语义一致的运动。

Abstract: Natural language offers a natural interface for humanoid robots, but existing
language-guided humanoid locomotion pipelines remain cumbersome and unreliable.
They typically decode human motion, retarget it to robot morphology, and then
track it with a physics-based controller. However, this multi-stage process is
prone to cumulative errors, introduces high latency, and yields weak coupling
between semantics and control. These limitations call for a more direct pathway
from language to action, one that eliminates fragile intermediate stages.
Therefore, we present RoboGhost, a retargeting-free framework that directly
conditions humanoid policies on language-grounded motion latents. By bypassing
explicit motion decoding and retargeting, RoboGhost enables a diffusion-based
policy to denoise executable actions directly from noise, preserving semantic
intent and supporting fast, reactive control. A hybrid causal
transformer-diffusion motion generator further ensures long-horizon consistency
while maintaining stability and diversity, yielding rich latent representations
for precise humanoid behavior. Extensive experiments demonstrate that RoboGhost
substantially reduces deployment latency, improves success rates and tracking
accuracy, and produces smooth, semantically aligned locomotion on real
humanoids. Beyond text, the framework naturally extends to other modalities
such as images, audio, and music, providing a general foundation for
vision-language-action humanoid systems.

</details>


### [55] [CBF-RL: Safety Filtering Reinforcement Learning in Training with Control Barrier Functions](https://arxiv.org/abs/2510.14959)
*Lizhi Yang,Blake Werner,Massimiliano de Sa Aaron D. Ames*

Main category: cs.RO

TL;DR: 本研究提出了一种CBF-RL框架，通过在训练中结合控制屏障函数，确保强化学习过程中的安全行为，无需额外的在线安全过滤器。


<details>
  <summary>Details</summary>
Motivation: 尽管强化学习在性能上非常强大，但由于安全问题可能导致灾难性后果，因此本研究旨在解决强化学习中安全约束的问题。

Method: 提出CBF-RL框架，通过在训练过程中引入CBF约束，最小化修改常规强化学习策略，同时在训练中进行安全过滤。

Result: CBF-RL框架通过实施CBF，能够内化安全约束，实现安全的行为和奖励偏向，使得在现实世界中安全探索和快速收敛成为可能。

Conclusion: CBF-RL框架成功实现在强化学习中通过控制屏障函数（CBF）来生成安全行为，无需在线安全过滤器，并在实际应用中展现出优越性。

Abstract: Reinforcement learning (RL), while powerful and expressive, can often
prioritize performance at the expense of safety. Yet safety violations can lead
to catastrophic outcomes in real-world deployments. Control Barrier Functions
(CBFs) offer a principled method to enforce dynamic safety -- traditionally
deployed \emph{online} via safety filters. While the result is safe behavior,
the fact that the RL policy does not have knowledge of the CBF can lead to
conservative behaviors. This paper proposes CBF-RL, a framework for generating
safe behaviors with RL by enforcing CBFs \emph{in training}. CBF-RL has two key
attributes: (1) minimally modifying a nominal RL policy to encode safety
constraints via a CBF term, (2) and safety filtering of the policy rollouts in
training. Theoretically, we prove that continuous-time safety filters can be
deployed via closed-form expressions on discrete-time roll-outs. Practically,
we demonstrate that CBF-RL internalizes the safety constraints in the learned
policy -- both enforcing safer actions and biasing towards safer rewards --
enabling safe deployment without the need for an online safety filter. We
validate our framework through ablation studies on navigation tasks and on the
Unitree G1 humanoid robot, where CBF-RL enables safer exploration, faster
convergence, and robust performance under uncertainty, enabling the humanoid
robot to avoid obstacles and climb stairs safely in real-world settings without
a runtime safety filter.

</details>


### [56] [RDD: Retrieval-Based Demonstration Decomposer for Planner Alignment in Long-Horizon Tasks](https://arxiv.org/abs/2510.14968)
*Mingxuan Yan,Yuping Wang,Zechun Liu,Jiachen Li*

Main category: cs.RO

TL;DR: 本研究提出了一种新颖的检索方法，自动将复杂任务分解为适合低级策略处理的子任务，显著提升了任务执行表现。


<details>
  <summary>Details</summary>
Motivation: 现有的 VLM 规划器需要通过人工标注或启发式规则对目标任务进行分解，导致与低级视觉运动策略的训练数据存在显著差异，影响任务性能。

Method: 提出一种基于检索的演示分解器 (RDD)，自动将演示分解为子任务。

Result: 我们的 RDD 方法在模拟和真实任务中超越了当前最先进的子任务分解器，展现了在多种情况下的稳健性。

Conclusion: RDD 方法有效解决了现有方法在演示分解时的局限性，提升了长时间跨度任务的执行能力。

Abstract: To tackle long-horizon tasks, recent hierarchical vision-language-action
(VLAs) frameworks employ vision-language model (VLM)-based planners to
decompose complex manipulation tasks into simpler sub-tasks that low-level
visuomotor policies can easily handle. Typically, the VLM planner is finetuned
to learn to decompose a target task. This finetuning requires target task
demonstrations segmented into sub-tasks by either human annotation or heuristic
rules. However, the heuristic subtasks can deviate significantly from the
training data of the visuomotor policy, which degrades task performance. To
address these issues, we propose a Retrieval-based Demonstration Decomposer
(RDD) that automatically decomposes demonstrations into sub-tasks by aligning
the visual features of the decomposed sub-task intervals with those from the
training data of the low-level visuomotor policies. Our method outperforms the
state-of-the-art sub-task decomposer on both simulation and real-world tasks,
demonstrating robustness across diverse settings. Code and more results are
available at rdd-neurips.github.io.

</details>
