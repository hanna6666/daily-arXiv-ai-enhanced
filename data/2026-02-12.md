<div id=toc></div>

# Table of Contents

- [cs.HC](#cs.HC) [Total: 23]
- [cs.RO](#cs.RO) [Total: 33]


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [1] [Understanding the Effects of AI-Assisted Critical Thinking on Human-AI Decision Making](https://arxiv.org/abs/2602.10222)
*Harry Yizhou Tian,Hasan Amin,Ming Yin*

Main category: cs.HC

TL;DR: 本文提出AACT框架，旨在通过AI分析人类决策推理促进批判性思维，提高决策质量。


<details>
  <summary>Details</summary>
Motivation: 研究人类与AI团队决策的低效表现，尝试设计能够促进人类反思自身推理的AI系统。

Method: 通过案例研究（例如房价预测）进行AI辅助的批判性思维框架分析。

Result: AACT框架通过反事实分析，帮助决策者识别决策中的潜在缺陷，提升决策质量。

Conclusion: AACT在减少对AI的过度依赖方面优于传统基于AI的决策支持，同时引发更高的认知负荷，尤其对熟悉AI技术的决策者尤其有利。

Abstract: Despite the growing prevalence of human-AI decision making, the human-AI team's decision performance often remains suboptimal, partially due to insufficient examination of humans' own reasoning. In this paper, we explore designing AI systems that directly analyze humans' decision rationales and encourage critical reflection of their own decisions. We introduce the AI-Assisted Critical Thinking (AACT) framework, which leverages a domain-specific AI model's counterfactual analysis of human decision to help decision-makers identify potential flaws in their decision argument and support the correction of them. Through a case study on house price prediction, we find that AACT outperforms traditional AI-based decision-support in reducing over-reliance on AI, though also triggering higher cognitive load. Subgroup analysis reveals AACT can be particularly beneficial for some decision-makers such as those very familiar with AI technologies. We conclude by discussing the practical implications of our findings, use cases and design choices of AACT, and considerations for using AI to facilitate critical thinking.

</details>


### [2] [Reimagining Sign Language Technologies: Analyzing Translation Work of Chinese Deaf Online Content Creators](https://arxiv.org/abs/2602.10235)
*Xinru Tang,Anne Marie Piper*

Main category: cs.HC

TL;DR: 本研究探讨了聋人内容创作者的手语翻译实践，强调其在翻译中考虑多语言和文化的复杂性，并呼吁重新设计手语翻译系统以适应这些需求。


<details>
  <summary>Details</summary>
Motivation: 尽管手语翻译系统有助于增强聋人获取信息和交流的能力，但聋人社区对其产生的风险表示强烈怀疑。

Method: 通过对13位积极在视频分享平台上创作和分享手语内容的中国聋人内容创作者进行访谈，收集实证数据。

Result: 研究揭示了聋人创作者在翻译工作中如何考虑多语言和多文化，同时应对与翻译相关的政治因素，展现了手语翻译的复杂性。

Conclusion: 通过重新概念化和重新想象手语翻译系统的设计，本文为手语翻译工作提供了新的视角，强调了多文化和多语言的丰富性。

Abstract: While sign language translation systems promise to enhance deaf people's access to information and communication, they have been met with strong skepticism from deaf communities due to risks of misrepresenting and oversimplifying the richness of signed communication in technologies. This article provides empirical evidence of the complexity of translation work involved in deaf communication through interviews with 13 deaf Chinese content creators who actively produce and share sign language content on video sharing platforms with both deaf and hearing audiences. By studying this unique group of content creators, our findings highlight the nuances of sign language translation, showing how deaf creators create content with multilingualism and multiculturalism in mind, support meaning making across languages and cultures, and navigate politics involved in their translation work. Grounded in these deaf-led translation practices, we draw on the sociolinguistic concept of (trans)languaging to re-conceptualize and reimagine the design of sign language translation systems.

</details>


### [3] [Investigating the Effects of Eco-Friendly Service Options on Rebound Behavior in Ride-Hailing](https://arxiv.org/abs/2602.10237)
*Albin Zeqiri,Michael Rietzler,Enrico Rukzio*

Main category: cs.HC

TL;DR: 研究发现，缺乏明确环保反馈的EFSO会导致打车频率增加，设计EFSO时需要重视反弹效应。


<details>
  <summary>Details</summary>
Motivation: 探索EFSO的环保框架是否可能导致消费的增加，以及如何包装 eco反馈以减少这一反弹效应。

Method: 通过在线实验（N=75），研究不同EFSO变体在打车选择中的影响。

Result: 不同的EFSO变体对打车使用的影响，各自的环保反馈指标，尤其在缺乏明确环保反馈的情况下，导致了打车使用的增加。

Conclusion: EFSOs的设计需要考虑反弹效应，以防止环保选择导致更高的碳排放。

Abstract: Eco-friendly service options (EFSOs) aim to reduce personal carbon emissions, yet their eco-friendly framing may permit increased consumption, weakening their intended impact. Such rebound effects remain underexamined in HCI, including how common eco-feedback approaches shape them. We investigate this in an online within-subjects experiment (N=75) in a ride-hailing context. Participants completed 10 trials for five conditions (No EFSO, EFSO - Minimal, EFSO - CO2 Equivalency, EFSO - Gamified, EFSO - Social), yielding 50 choices between walking and ride-hailing for trips ranging from 0.5mi - 2.0mi (0.80km - 3.22km). We measured how different EFSO variants affected ride-hailing uptake relative to a No EFSO baseline. EFSOs lacking explicit eco-feedback metrics increased ride-hailing uptake, and qualitative responses indicate that EFSOs can make convenience-driven choices more permissible. We conclude with implications for designing EFSOs that begin to take rebound effects into account.

</details>


### [4] [Actions Speak Louder Than Chats: Investigating AI Chatbot Age Gating](https://arxiv.org/abs/2602.10251)
*Olivia Figueira,Pranathi Chamarthi,Tu Le,Athina Markopoulou*

Main category: cs.HC

TL;DR: 本研究调查了流行聊天机器人在识别用户年龄方面的能力，发现它们能够估计年龄但未能在识别儿童时采取保护措施，为在线儿童安全提供了启示。


<details>
  <summary>Details</summary>
Motivation: 理解聊天机器人在用户年龄估计和保护儿童隐私安全方面的能力和现状。

Method: 通过编程与聊天机器人互动，采用1050个实验，通过包括隐式和显式年龄披露在内的全面提示库进行分析。

Result: 发现流行的消费者聊天机器人能够估计用户的年龄，但在识别儿童时不采取行动。

Conclusion: 尽管聊天机器人能够估计用户年龄，但在识别儿童时并未采取任何行动，这与其自身政策相悖。

Abstract: AI chatbots are widely used by children and teens today, but they pose significant risks to youth's privacy and safety due to both increasingly personal conversations and potential exposure to unsafe content. While children under 13 are protected by the Children's Online Privacy Protection Act (COPPA), chatbot providers' own privacy policies may also provide protections, since they typically prohibit children from accessing their platforms. Age gating is often employed to restrict children online, but chatbot age gating in particular has not been studied. In this paper, we investigate whether popular consumer chatbots are (i) able to estimate users' ages based solely on their conversations, and (ii) whether they take action upon identifying children. To that end, we develop an auditing framework in which we programmatically interact with chatbots and conduct 1050 experiments using our comprehensive library of age-indicative prompts, including implicit and explicit age disclosures, to analyze the chatbots' responses and actions. We find that while chatbots are capable of estimating age, they do not take any action when children are identified, contradicting their own policies. Our methodology and findings provide insights for platform design, demonstrated by our proof-of-concept chatbot age gating implementation, and regulation to protect children online.

</details>


### [5] [ECHO: An Open Research Platform for Evaluation of Chat, Human Behavior, and Outcomes](https://arxiv.org/abs/2602.10295)
*Jiqun Liu,Nischal Dinesh,Ran Yu*

Main category: cs.HC

TL;DR: ECHO是一个开放研究平台，设计用以支持人机交互的可重复性研究，降低技术门槛并整合多种实验任务。


<details>
  <summary>Details</summary>
Motivation: 为了支持对人机交互、学习、决策和用户体验的研究，ECHO平台能够帮助研究人员在不同的信息获取范式下进行研究。

Method: ECHO通过集成同意和背景调查、信息搜索会话、写作或判断任务及前后任务评估，支持研究人员构建完整实验工作流程。

Result: ECHO记录细粒度的交互轨迹和参与者反应，导出结构化数据集以便后续分析。

Conclusion: ECHO提供了一个低编码负担的研究平台，支持人机互动的可重复性和混合方法研究，降低了技术门槛，并 empowered 不同学科的研究人员开展大规模且可重复的AI评估。

Abstract: ECHO (Evaluation of Chat, Human behavior, and Outcomes) is an open research platform designed to support reproducible, mixed-method studies of human interaction with both conversational AI systems and Web search engines. It enables researchers from varying disciplines to orchestrate end-to-end experimental workflows that integrate consent and background surveys, chat-based and search-based information-seeking sessions, writing or judgment tasks, and pre- and post-task evaluations within a unified, low-coding-load framework. ECHO logs fine-grained interaction traces and participant responses, and exports structured datasets for downstream analysis. By supporting both chat and search alongside flexible evaluation instruments, ECHO lowers technical barriers for studying learning, decision making, and user experience across different information access paradigms, empowering researchers from information retrieval, HCI, and the social sciences to conduct scalable and reproducible human-centered AI evaluations.

</details>


### [6] [Disability-First AI Dataset Annotation: Co-designing Stuttered Speech Annotation Guidelines with People Who Stutter](https://arxiv.org/abs/2602.10403)
*Xinru Tang,Jingjin Li,Shaomei Wu*

Main category: cs.HC

TL;DR: 本研究探讨了无障碍数据集中存在的标注挑战，并通过与言语障碍者的合作提出改进方案。


<details>
  <summary>Details</summary>
Motivation: 探讨当前无残疾专门知识的众包工人标注的无障碍数据集中存在的标注挑战。

Method: 通过与言语障碍者（PWS）和领域专家的访谈及共同设计工作坊，识别在歧义言语标注中的挑战，并提出整合PWS实际经验的标注实践。

Result: 分析了对言语障碍者的言语数据进行标注的难题，提出改进数据集质量的方法，并揭示了残疾体验的复杂性与静态标签之间的紧张关系。

Conclusion: 强调了残疾优先和多样性意识对AI数据解释的重要性。

Abstract: Despite efforts to increase the representation of disabled people in AI datasets, accessibility datasets are often annotated by crowdworkers without disability-specific expertise, leading to inconsistent or inaccurate labels. This paper examines these annotation challenges through a case study of annotating speech data from people who stutter (PWS). Given the variability of stuttering and differing views on how it manifests, annotating and transcribing stuttered speech remains difficult, even for trained professionals. Through interviews and co-design workshops with PWS and domain experts, we identify challenges in stuttered speech annotation and develop practices that integrate the lived experiences of PWS into the annotation process. Our findings highlight the value of embodied knowledge in improving dataset quality, while revealing tensions between the complexity of disability experiences and the rigidity of static labels. We conclude with implications for disability-first and multiplicity-aware approaches to data interpretation across the AI pipeline.

</details>


### [7] [Towards Affordable, Non-Invasive Real-Time Hypoglycemia Detection Using Wearable Sensor Signals](https://arxiv.org/abs/2602.10407)
*Lawrence Obiuwevwi,Krzysztof J. Rechowicz,Vikas Ashok,Sampath Jayarathna*

Main category: cs.HC

TL;DR: 本研究提出了一种基于可穿戴传感器的非侵入性低血糖检测方法，利用皮肤电反应和心率组合，实现了实时低血糖检测，旨在提高糖尿病管理的可及性。


<details>
  <summary>Details</summary>
Motivation: 在糖尿病管理中，准确检测低血糖尤其在连续血糖监测（CGM）成本昂贵或在临床上无法获得的地区仍是一项重要挑战。

Method: 开发了一种全面的多模态生理框架，通过可穿戴传感器信号进行非侵入性低血糖检测，评估了三种生理模式（皮肤电反应、心率及其组合融合），构建了端到端的处理管道。

Result: 结果表明，生理信号在低血糖前显示出不同的自主模式，结合皮肤电反应与心率相比于单一信号模型，检测灵敏度和稳定性更高，多模态深度学习架构在召回率等指标上表现最佳。

Conclusion: 实时低血糖检测可以通过仅使用经济且非侵入性的可穿戴传感器实现，为缺乏服务的社区和低资源医疗环境的可及性葡萄糖监测提供了路径。

Abstract: Accurately detecting hypoglycemia without invasive glucose sensors remains a critical challenge in diabetes management, particularly in regions where continuous glucose monitoring (CGM) is prohibitively expensive or clinically inaccessible. This extended study introduces a comprehensive, multimodal physiological framework for non-invasive hypoglycemia detection using wearable sensor signals. Unlike prior work limited to single-signal analysis, this chapter evaluates three physiological modalities, galvanic skin response (GSR), heart rate (HR), and their combined fusion, using the OhioT1DM 2018 dataset. We develop an end-to-end pipeline that integrates advanced preprocessing, temporal windowing, handcrafted and sequence-based feature extraction, early and late fusion strategies, and a broad spectrum of machine learning and deep temporal models, including CNNs, LSTMs, GRUs, and TCNs. Our results demonstrate that physiological signals exhibit distinct autonomic patterns preceding hypoglycemia and that combining GSR with HR consistently enhances detection sensitivity and stability compared to single-signal models. Multimodal deep learning architectures achieve the most reliable performance, particularly in recall, the most clinically urgent metric. Ablation studies further highlight the complementary contributions of each modality, strengthening the case for affordable, sensor-based glycemic monitoring. The findings show that real-time hypoglycemia detection is achievable using only inexpensive, non-invasive wearable sensors, offering a pathway toward accessible glucose monitoring in underserved communities and low-resource healthcare environments.

</details>


### [8] [Exploring the Feasibility of Full-Body Muscle Activation Sensing with Insole Pressure Sensors](https://arxiv.org/abs/2602.10442)
*Hao Zhou,Mahanth Gowda*

Main category: cs.HC

TL;DR: 本论文提出了Press2Muscle系统，通过鞋垫压力传感器无干扰地推断肌肉激活，展现出在现实环境中监测肌肉激活的有效性和可行性。


<details>
  <summary>Details</summary>
Motivation: 理解肌肉激活对于预防伤害和康复提供了重要的见解，但传统的肌肉激活感知方法不适合长期使用，因此需要探索新的、无干扰的解决方案。

Method: 利用鞋垫压力传感器分析由全身肌肉激活引起的足部压力变化，采用数据驱动的方法以动态调整对不同足部区域的依赖，并结合易获取的用户生物数据以增强系统对未见用户的泛化能力。

Result: 在30名用户的广泛研究中，Press2Muscle在leave-one-user-out设置下实现了0.025的均方根误差，比视频基础的对应方法改善了19%。同时，系统在不同用户群体、鞋类及行走表面之间展示了良好的泛化能力。

Conclusion: Press2Muscle实现了在现实环境中使用鞋垫压力传感器感知肌肉激活，具有较好的可行性和有效性。

Abstract: Muscle activation initiates contractions that drive human movement, and understanding it provides valuable insights for injury prevention and rehabilitation. Yet, sensing muscle activation is barely explored in the rapidly growing mobile health market. Traditional methods for muscle activation sensing rely on specialized electrodes, such as surface electromyography, making them impractical, especially for long-term usage. In this paper, we introduce Press2Muscle, the first system to unobtrusively infer muscle activation using insole pressure sensors. The key idea is to analyze foot pressure changes resulting from full-body muscle activation that drives movements. To handle variations in pressure signals due to differences in users' gait, weight, and movement styles, we propose a data-driven approach to dynamically adjust reliance on different foot regions and incorporate easily accessible biographical data to enhance Press2Muscle's generalization to unseen users. We conducted an extensive study with 30 users. Under a leave-one-user-out setting, Press2Muscle achieves a root mean square error of 0.025, marking a 19% improvement over a video-based counterpart. A robustness study validates Press2Muscle's ability to generalize across user demographics, footwear types, and walking surfaces. Additionally, we showcase muscle imbalance detection and muscle activation estimation under free-living settings with Press2Muscle, confirming the feasibility of muscle activation sensing using insole pressure sensors in real-world settings.

</details>


### [9] [Why Human Guidance Matters in Collaborative Vibe Coding](https://arxiv.org/abs/2602.10473)
*Haoyu Hu,Raja Marjieh,Katherine M Collins,Chenyi Li,Thomas L. Griffiths,Ilia Sucholutsky,Nori Jacoby*

Main category: cs.HC

TL;DR: 本研究探讨了气氛编码对协作和生产力的影响，发现人类提供的指令效果更佳，混合系统在有方向控制的人类的情况下表现最佳。


<details>
  <summary>Details</summary>
Motivation: 尽管气氛编码越来越普遍，但其对生产力和协作的累积影响尚不明确。

Method: 引入了一种控制实验框架，比较人类主导、AI主导和混合小组的协作气氛编码效果。

Result: 在604名参与者的16项实验中，发现人们为气氛编码提供的高层次指令独具有效性，而AI提供的指令往往导致性能崩溃。

Conclusion: 混合系统在保留人类方向控制（提供指令）的情况下表现最好，而评估则由AI来负责。

Abstract: Writing code has been one of the most transformative ways for human societies to translate abstract ideas into tangible technologies. Modern AI is transforming this process by enabling experts and non-experts alike to generate code without actually writing code, but instead, through natural language instructions, or "vibe coding". While increasingly popular, the cumulative impact of vibe coding on productivity and collaboration, as well as the role of humans in this process, remains unclear. Here, we introduce a controlled experimental framework for studying collaborative vibe coding and use it to compare human-led, AI-led, and hybrid groups. Across 16 experiments involving 604 human participants, we show that people provide uniquely effective high-level instructions for vibe coding across iterations, whereas AI-provided instructions often result in performance collapse. We further demonstrate that hybrid systems perform best when humans retain directional control (providing the instructions), while evaluation is delegated to AI.

</details>


### [10] [Division of Labor and Collaboration Between Parents in Family Education](https://arxiv.org/abs/2602.10501)
*Ziyi Wang,Congrong Zhang,Jingying Deng,Xiaofan Hu,Jie Cai,Nan Gao,Chun Yu,Haining Zhang*

Main category: cs.HC

TL;DR: 本文通过访谈18位父母，研究家庭作业辅导的劳动分配及协调，提出了以关系维护为重点的AI设计，以更好地支持父母应对家庭作业的认知与情感负担。


<details>
  <summary>Details</summary>
Motivation: 解决父母在家庭作业辅导中面临的认知与情感负担，寻求有意义的AI介入方式。

Method: 通过对18位1-3年级孩子的父母进行访谈，分析作业相关的劳动如何在家庭中分配与协调。

Result: 研究发现作业劳动涉及身体、认知和情感三个维度，特别是后两者常常被忽视；父母之间及与孩子的动态反馈影响着劳动分配；提出了一种新的AI设计思路，强调维护家庭关系。

Conclusion: 本文探讨了家庭作业辅导工作中父母之间及与孩子的协作，提出了一种以关系维持为重点的AI设计理念，以应对家庭作业带来的认知和情感负担。

Abstract: Homework tutoring work is a demanding and often conflict-prone practice in family life, and parents often lack targeted support for managing its cognitive and emotional burdens. Through interviews with 18 parents of children in grades 1-3, we examine how homework-related labor is divided and coordinated between parents, and where AI might meaningfully intervene. We found three key insights: (1) Homework labor encompasses distinct dimensions: physical, cognitive, and emotional, with the latter two often remaining invisible. (2) We identified father-mother-child triadic dynamics in labor division, with children's feedback as the primary factor shaping parental labor adjustments. (3) Building on prior HCI research, we propose an AI design that prioritizes relationship maintenance over task automation or broad labor mitigation. By employing labor as a lens that integrates care work, we explore the complexities of labor within family contexts, contributing to feminist and care-oriented HCI and to the development of context-sensitive coparenting practices.

</details>


### [11] [Exploring the Interplay Between Voice, Personality, and Gender in Human-Agent Interactions](https://arxiv.org/abs/2602.10535)
*Kai Alexander Hackney,Lucas Guarenti Zangari,Jhonathan Sora-Cardenas,Emmanuel Munoz,Sterling R. Kalogeras,Betsy DiSalvo,Pedro Guillermo Feijoo-Garcia*

Main category: cs.HC

TL;DR: 本研究探讨了用户与智能体之间的性别和人格同步性对人机交互的影响，发现参与者能够识别女性智能体的人格，而对男性智能体的认知较弱。


<details>
  <summary>Details</summary>
Motivation: 为了促进有效的人机交互，设计师需要识别可能影响智能体被感知和接受的特征，以及这些特征如何影响建立亲密关系的程度。

Method: 评估388名参与者以确定他们是否能够从四种人工声音中感知人格特征，考虑性别（男性或女性）和人格（内向或外向）作为分组因素。

Result: 参与者能够显著区分女性智能体的人格特征，而男性智能体的区分则不够一致。此外，观察到人格同步性，参与者倾向于将第一位智能体视为与自己的人格更相似，此效应主要由男性参与者驱动，尤其是针对男性智能体。

Conclusion: 用户与智能体之间的个性和性别同步性在设计人机交互中起着重要作用。

Abstract: To foster effective human-agent interactions, designers need to identify characteristics that could affect how agents are perceived and accepted, and to what extent they could impact rapport-building. Aiming to explore the role of user-agent synchrony, we assessed 388 participants to determine whether they could perceive personality traits from four artificial voices we selected and adapted from human samples, considering gender (male or female) and personality (introvert or extrovert) as grouping factors. Our findings suggest that participants were able to significantly differentiate female agents by personality, while male agents were not consistently distinguished. We also observed evidence of personality synchrony, where participants tended to perceive the first agent as more similar to their own personality, with this effect driven mainly by male participants, especially toward male agents. This paper contributes findings and insights to consider the interplay of user-agent personality and gender synchrony in the design of human-agent interactions.

</details>


### [12] [Labor, Capital, and Machine: Toward a Labor Process Theory for HCI](https://arxiv.org/abs/2602.10548)
*Yigang Qin,EunJeong Cheon*

Main category: cs.HC

TL;DR: 本文探讨劳动过程理论在HCI中的应用，提出多个研究方向以加深对劳动问题的理解，促进批判性设计。


<details>
  <summary>Details</summary>
Motivation: 文章旨在回应HCI社区对劳动问题和计算政治经济学的关注，并推动对劳动理论的深入理解。

Method: 文章通过文献分析和理论框架的建立，探讨劳动过程理论及其在HCI设计中的应用。

Result: 通过对劳动过程理论的探讨，文章提出了HCI研究和实践的多项方向，以增强这一领域与更广泛的政治经济批判的联系。

Conclusion: 这篇文章强调了劳动过程理论在现代工作与计算机系统设计中的重要性，并指出了HCI领域需要关注劳动问题的多个方向。

Abstract: The HCI community has called for renewed attention to labor issues and the political economy of computing. Yet much work remains in engaging with labor theory to better understand modern work and workers. This article traces the development of Labor Process Theory (LPT) -- from Karl Marx and Harry Braverman to Michael Burawoy and beyond -- and introduces it as an essential yet underutilized resource for structural analysis of work under capitalism and the design of computing systems. We examine HCI literature on labor, investigating focal themes and conceptual, empirical, and design approaches. Drawing from LPT, we offer directions for HCI research and practice: distinguish labor from work, link work practice to value production, study up the management, analyze consent and legitimacy, move beyond the point of production, design alternative institutions, and unnaturalize bourgeois designs. These directions can deepen analyses of tech-mediated workplace regimes, inform critical and normative designs, and strengthen the field's connection to broader political economic critique.

</details>


### [13] [From Interaction to Demonstration Quality in Virtual Reality: Effects of Interaction Modality and Visual Representation on Everyday Tasks](https://arxiv.org/abs/2602.10618)
*Robin Beierling,Manuel Scheibl,Jonas Dech,Abhijit Vyas,Anna-Lisa Vollmer*

Main category: cs.HC

TL;DR: 本研究探讨了不同VR输入配置对用户体验和任务执行的影响，发现了有效性与自然性的权衡，有助于优化VR训练和应用设计。


<details>
  <summary>Details</summary>
Motivation: 探讨不同的虚拟现实输入设备及其可视化对用户工作负荷和表现的影响，以提高训练效果和演示质量。

Method: 参与者在模拟环境中执行各种厨房相关的日常活动，使用系统可用性量表和NASA任务负荷指数评估用户体验，同时使用轨迹分段分析任务特定交互行为。

Result: 尽管整体可用性和工作负荷没有显著差异，但轨迹分析显示不同配置下的执行行为及其运动策略差异。

Conclusion: 不同的虚拟现实输入配置在用户体验和任务执行方面具有特定的执行行为，强调了效率与自然之间的权衡。

Abstract: Virtual Reality (VR) is increasingly used for training and demonstration purposes including a variety of applications ranging from robot learning to rehabilitation. However, the choice of input device and its visualization might influence workload and thus user performance leading to suboptimal demonstrations or reduced training effects. This study investigates how different VR input configurations - motion capture gloves, controllers with hand visualization, and controllers with controller visualization - affect user experience and task execution, with the goal of identifying which configuration is best suited for which type of task. Participants performed various kitchen-related activities of daily living (ADLs), including object placement, cutting, cleaning, and pouring in a simulated environment. To address two research questions, we evaluated user experience using the System Usability Scale and NASA Task Load Index (RQ1), and task-specific interaction behavior (RQ2). The latter was assessed using trajectory segmentation, analyzing movement efficiency, unnecessary actions, and execution precision. While no significant differences in overall usability and workload were found, trajectory analysis revealed configuration-specific execution behaviors with different movement strategies. Controllers enabled significantly faster task completion with less movement variability in pick-and-place style tasks such as table setting. In contrast, motion capture gloves produced more natural movements with fewer unnecessary actions, but also showed greater variance in movement patterns for manner-oriented tasks such as cutting bread. These findings highlight trade-offs between efficiency and naturalism, and have implications for optimizing VR-based training, improving the quality of user-generated demonstrations, and tailoring interaction design to specific application goals.

</details>


### [14] [Privacy Control in Conversational LLM Platforms: A Walkthrough Study](https://arxiv.org/abs/2602.10684)
*Zhuoyang Li,Yanlai Wu,Yao Li,Xinning Gui,Yuhan Luo*

Main category: cs.HC

TL;DR: 本研究探讨了对话式大型语言模型平台中用户数据控制机制，强调了新的数据控制范式及其隐私控制的设计建议。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的普及，人们对隐私控制的关注增加，但对数据控制机制的研究较少。

Method: 分析六个对话式大型语言模型平台，评估其用户数据访问、编辑、删除和分享功能。

Result: 分析显示，对话式大型语言模型平台中的用户数据控制机制正在形成一种新的范式，其中交互生成的数据、自然语言控制的灵活性以及多用户共享数据引发了共同拥有和治理的问题。

Conclusion: 通过对六个对话式大型语言模型平台的分析，揭示了用户数据控制的新范式，并提供了可行的建议以改善隐私控制的设计。

Abstract: Large language models (LLMs) are increasingly integrated into daily life through conversational interfaces, processing user data via natural language inputs and exhibiting advanced reasoning capabilities, which raises new concerns about user control over privacy. While much research has focused on potential privacy risks, less attention has been paid to the data control mechanisms these platforms provide. This study examines six conversational LLM platforms, analyzing how they define and implement features for users to access, edit, delete, and share data. Our analysis reveals an emerging paradigm of data control in conversational LLM platforms, where user data is generated and derived through interaction itself, natural language enables flexible yet often ambiguous control, and multi-user interactions with shared data raise questions of co-ownership and governance. Based on these findings, we offer practical insights for platform developers, policymakers, and researchers to design more effective and usable privacy controls in LLM-powered conversational interactions.

</details>


### [15] [Don't blame me: How Intelligent Support Affects Moral Responsibility in Human Oversight](https://arxiv.org/abs/2602.10701)
*Cedric Faas,Richard Uth,Sarah Sterz,Markus Langer,Anna Maria Feit*

Main category: cs.HC

TL;DR: 本研究探讨了AI辅助决策系统如何通过限制用户干预选项影响其道德责任感。结果表明，当监督者仅能选择一项行动时，事故发生时其道德责任感下降。这对用户界面设计和监督架构有重要启示，需考虑道德责任的合理分配。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统越来越多地承担自主工作任务，确保人类监督以防范风险和承担责任变得尤为重要。本研究旨在探讨决策支持系统限制干预选择对监督者道德责任感的影响，尤其是在支持系统出错时。

Method: 通过模拟实验，274名参与者监督一架自主无人机，面临十种关键情况，选择从六种可能的行动中解决每种情况。AI系统根据实验组别，限制参与者选择的可选行动数量（六、四、二或仅一）。

Result: 结果显示，参与者被限制只能选择单一行动时，若发生事故，他们感到的道德责任降低，而对于其他利益相关者的责任判断则没有变化。

Conclusion: 当监督者被限制只能选择单一行动时，他们在发生事故时感到的道德责任降低，无论这一限制对AI或开发者责任的判断没有影响。这表明，在设计用户界面和监督架构时，应考虑道德责任的分配。

Abstract: AI-based systems can increasingly perform work tasks autonomously. In safety-critical tasks, human oversight of these systems is required to mitigate risks and to ensure responsibility in case something goes wrong. Since people often struggle to stay focused and perform good oversight, intelligent support systems are used to assist them, giving decision recommendations, alerting users, or restricting them from dangerous actions. However, in cases where recommendations are wrong, decision support might undermine the very reason why human oversight was employed -- genuine moral responsibility. The goal of our study was to investigate how a decision support system that restricted available interventions would affect overseer's perceived moral responsibility, in particular in cases where the support errs. In a simulated oversight experiment, participants (\textit{N}=274) monitored an autonomous drone that faced ten critical situations, choosing from six possible actions to resolve each situation. An AI system constrained participants' choices to either six, four, two, or only one option (between-subject study). Results showed that participants, who were restricted to choosing from a single action, felt less morally responsible if a crash occurred. At the same time, participants' judgments about the responsibility of other stakeholders (the AI; the developer of the AI) did not change between conditions. Our findings provide important insights for user interface design and oversight architectures: they should prevent users from attributing moral agency to AI, help them understand how moral responsibility is distributed, and, when oversight aims to prevent ethically undesirable outcomes, be designed to support the epistemic and causal conditions required for moral responsibility.

</details>


### [16] [The Effect of Design Thinking on Creative & Innovation Processes: An Empirical Study Across Different Design Experience Levels](https://arxiv.org/abs/2602.10827)
*Yuxin Zhang,Fan Zhang*

Main category: cs.HC

TL;DR: 本研究揭示了设计思维技能对设计创意与创新的影响路径，并提供了改进教学和专业实践的建议。


<details>
  <summary>Details</summary>
Motivation: 探讨思维技能与设计思维如何影响设计创意与创新，以便为教育和专业实践提供指导。

Method: 采用线性回归和结构方程模型分析思维技能、设计思维、自信心等因素对设计创意与创新的影响，结合路径分析和中介分析进行验证。

Result: 设计思维技能对设计思维有显著正向影响，且设计思维对设计创意与创新的预测作用显著，发现多条中介路径。不同经验水平的群体之间存在显著差异。

Conclusion: 本研究提出了设计创意与创新的多维路径，强调了设计思维技能及其对创意与创新的积极影响，为优化教学模型和专业实践提供了实证依据。

Abstract: This study employs linear regression and structural equation modeling to explore how Thinking Skills, Design Thinking, Creative Self-Efficacy (CSE), and Collective Creative Efficacy (CCE) drive Design Creativity & Innovation, and analyzes the structural stability of the model across different levels of experience. Path analysis results indicate that the four Design Thinking Skills, Problem-driven Design (beta = 0.198, p < 0.01), Information-driven Design (beta = 0.241, p < 0.001), Solution-driven Design (beta = 0.227, p < 0.001), and Knowledge-driven Design (beta = 0.263, p < 0.001) all significantly and positively influence Design Thinking. Furthermore, Design Thinking has a significant positive predictive effect on Design Creativity & Innovation (beta = 0.286, p < 0.001). Mediation analysis confirms three significant mediation paths: the CSE mediation path (beta = 0.128, p < 0.001), the CCE mediation path (beta = 0.073, p < 0.01), and the "CSE to CCE" chain mediation path (beta = 0.025, p < 0.01). Multi-group comparison results reveal significant differences between the student and professional groups under the full equivalence model. After relaxing specific constraints, there were no significant differences between the nested models of the baseline model, partial measurement invariance, structural weight invariance, and structural covariance invariance. These findings elucidate the multi-dimensional pathways of Design Creativity & Innovation, providing a robust empirical basis for optimizing differentiated pedagogical models and professional practice guidelines.

</details>


### [17] [Viewpoint Recommendation for Point Cloud Labeling through Interaction Cost Modeling](https://arxiv.org/abs/2602.10871)
*Yu Zhang,Xinyi Zhao,Chongke Bi,Siming Chen*

Main category: cs.HC

TL;DR: 本文提出了一种视角推荐方法，以减少3D点云标注时间，通过Fitts定律建模选点时间，集成于标注系统中。


<details>
  <summary>Details</summary>
Motivation: 在3D点云语义分割中，标注过程耗时，影响模型训练，寻找减少标注时间的方法十分重要。

Method: 我们利用Fitts定律模拟点云中套索选择的时间成本，并推荐可降低选择时间的视角给标注者。

Result: 通过消融研究，我们证明了所提方法在减少数据标注时间成本方面的有效性，并与之前的方法进行了定性比较。

Conclusion: 通过实施我们的方法，数据标注时间成本显著减少，系统提升了标注的效率。

Abstract: Semantic segmentation of 3D point clouds is important for many applications, such as autonomous driving. To train semantic segmentation models, labeled point cloud segmentation datasets are essential. Meanwhile, point cloud labeling is time-consuming for annotators, which typically involves tuning the camera viewpoint and selecting points by lasso. To reduce the time cost of point cloud labeling, we propose a viewpoint recommendation approach to reduce annotators' labeling time costs. We adapt Fitts' law to model the time cost of lasso selection in point clouds. Using the modeled time cost, the viewpoint that minimizes the lasso selection time cost is recommended to the annotator. We build a data labeling system for semantic segmentation of 3D point clouds that integrates our viewpoint recommendation approach. The system enables users to navigate to recommended viewpoints for efficient annotation. Through an ablation study, we observed that our approach effectively reduced the data labeling time cost. We also qualitatively compare our approach with previous viewpoint selection approaches on different datasets.

</details>


### [18] [What do people want to fact-check?](https://arxiv.org/abs/2602.10935)
*Bijean Ghafouri,Dorsaf Sallami,Luca Luceri,Taylor Lynn Curtis,Jean-Francois Godbout,Emilio Ferrara,Reihaneh Rabbany*

Main category: cs.HC

TL;DR: 本研究通过分析457名用户的近2500个事实检查请求，揭示了公众对事实检查工具的需求与现有工具和评估基准之间的不匹配，强调了需求驱动的重要性。


<details>
  <summary>Details</summary>
Motivation: 探讨公众在可获取事实检查系统时，实际关注的事实检查需求，而非仅仅关注虚假信息的供给侧。

Method: 分析了457名参与者提交的近2500个声明，采用五个语义维度对每个声明进行分类。

Result: 研究发现公众的事实检查需求大多集中在简单的描述性声明上，但许多请求涉及无法实证的陈述，且当前的AI系统未能有效应对这些需求。

Conclusion: 当前的事实检查工具与公众的需求存在显著的不匹配，尤其是在不确定性及需求驱动的方面。

Abstract: Research on misinformation has focused almost exclusively on supply, asking what falsehoods circulate, who produces them, and whether corrections work. A basic demand-side question remains unanswered. When ordinary people can fact-check anything they want, what do they actually ask about? We provide the first large-scale evidence on this question by analyzing close to 2{,}500 statements submitted by 457 participants to an open-ended AI fact-checking system. Each claim is classified along five semantic dimensions (domain, epistemic form, verifiability, target entity, and temporal reference), producing a behavioral map of public verification demand. Three findings stand out. First, users range widely across topics but default to a narrow epistemic repertoire, overwhelmingly submitting simple descriptive claims about present-day observables. Second, roughly one in four requests concerns statements that cannot be empirically resolved, including moral judgments, speculative predictions, and subjective evaluations, revealing a systematic mismatch between what users seek from fact-checking tools and what such tools can deliver. Third, comparison with the FEVER benchmark dataset exposes sharp structural divergences across all five dimensions, indicating that standard evaluation corpora encode a synthetic claim environment that does not resemble real-world verification needs. These results reframe fact-checking as a demand-driven problem and identify where current AI systems and benchmarks are misaligned with the uncertainty people actually experience.

</details>


### [19] [Reality Copilot: Voice-First Human-AI Collaboration in Mixed Reality Using Large Multimodal Models](https://arxiv.org/abs/2602.11025)
*Liuchuan Yu,Yongqi Zhang,Lap-Fai Yu*

Main category: cs.HC

TL;DR: 本论文提出了 Reality Copilot，这是一个基于语音的人机助手，利用 LMM 提升混合现实中的人机合作，通过自然语言交互和上下文感知，实现了更智能的用户体验。


<details>
  <summary>Details</summary>
Motivation: 探索如何将大型多模态模型集成到混合现实中，以增强智能助手的交互性和实用性，超越传统的设备使用。

Method: 本研究提出了一种系统，名为 Reality Copilot，专注于语音优先的人机助手，通过 LMM 提供自然的语音交互。

Result: Reality Copilot 具备对物理环境的上下文理解、逼真的 3D 内容生成和实时信息检索能力，同时支持头戴设备内的交互和跨平台工作流程。

Conclusion: Reality Copilot 展示了 LMM 在混合现实中如何提高人机协作的潜力，尤其是在语音交互和上下文理解方面。

Abstract: Large Multimodal Models (LMMs) have shown strong potential for assisting users in tasks, such as programming, content creation, and information access, yet their interaction remains largely limited to traditional interfaces such as desktops and smartphones. Meanwhile, advances in mixed reality (MR) hardware have enabled applications that extend beyond entertainment and into everyday use. However, most existing MR systems rely primarily on manual input (e.g., hand gestures or controllers) and provide limited intelligent assistance due to the lack of integration with large-scale AI models. We present Reality Copilot, a voice-first human-AI assistant for mixed reality that leverages LMMs to enable natural speech-based interaction. The system supports contextual understanding of physical environments, realistic 3D content generation, and real-time information retrieval. In addition to in-headset interaction, Reality Copilot facilitates cross-platform workflows by generating context-aware textual content and exporting generated assets. This work explores the design space of LMM-powered human-AI collaboration in mixed reality.

</details>


### [20] [Normalized Surveillance in the Datafied Car: How Autonomous Vehicle Users Rationalize Privacy Trade-offs](https://arxiv.org/abs/2602.11026)
*Yehuda Perry,Tawfiq Ammari*

Main category: cs.HC

TL;DR: 本研究通过对自动驾驶汽车司机的访谈，探讨用户如何看待汽车监控及其隐私问题，认为其数据化被视为日常数据化的一部分，并提出治理措施来改善数据透明度和隐私保护。


<details>
  <summary>Details</summary>
Motivation: 研究用户在日常数据化中如何理解汽车监控，特别是在用户对隐私的态度和感知上。

Method: 通过对16个AV司机的半结构化访谈进行分析，应用建构主义扎根理论来理解用户如何认知车辆监控。

Result: 发现司机普遍对AV特有的隐私问题关注较少，往往通过与现有数字平台进行比较来正常化监控。这表明，汽车的数据化是作为“渗漏的家”移动延伸的部分。

Conclusion: 治理干预措施可以促进社会学习的民主化，包括普遍的数据访问权、具有约束力的透明度要求以及数据最小化标准，以防止汽车数据化中的低标准竞争。

Abstract: Autonomous vehicles (AVs) are characterized by pervasive datafication and surveillance through sensors like in-cabin cameras, LIDAR, and GPS. Drawing on 16 semi-structured interviews with AV drivers analyzed using constructivist grounded theory, this study examines how users make sense of vehicular surveillance within everyday datafication. Findings reveal drivers demonstrate few AV-specific privacy concerns, instead normalizing monitoring through comparisons with established digital platforms. We theorize this indifference by situating AV surveillance within the `surveillance ecology' of platform environments, arguing the datafied car functions as a mobile extension of the `leaky home' -- private spaces rendered permeable through connected technologies continuously transmitting behavioral data.
  The study contributes to scholarship on surveillance beliefs, datafication, and platform governance by demonstrating how users who have accepted comprehensive smartphone and smart home monitoring encounter AV datafication as just another node in normalized data extraction. We highlight how geographic restrictions on data access -- currently limiting driver log access to California -- create asymmetries that impede informed privacy deliberation, exemplifying `tertiary digital divides.' Finally, we examine how machine learning's reliance on data-intensive approaches creates structural pressure for surveillance that transcends individual manufacturer choices. We propose governance interventions to democratize social learning, including universal data access rights, binding transparency requirements, and data minimization standards to prevent race-to-the-bottom dynamics in automotive datafication.

</details>


### [21] [GenFaceUI: Meta-Design of Generative Personalized Facial Expression Interfaces for Intelligent Agents](https://arxiv.org/abs/2602.11055)
*Yate Ge,Lin Tian,Yi Dai,Shuhan Pan,Yiwen Zhang,Qi Wang,Weiwei Guo,Xiaohua Sun*

Main category: cs.HC

TL;DR: 本研究提出了GPFEI框架及GenFaceUI工具，旨在提升智能代理的面部表情生成能力，并通过设计师的评估展示其可用性和改进需求。


<details>
  <summary>Details</summary>
Motivation: 从元设计的角度探讨生成式面部表情界面，以改善智能代理的表情生成控制、一致性和对齐问题。

Method: 通过开发GenFaceUI工具并进行定性研究，对设计师的反馈进行评估。

Result: 研究结果显示，设计师在使用工具时感受到可控性和一致性的提高，同时也揭示了对结构化视觉机制和轻量解释的需求。

Conclusion: 该研究提出的GPFEI框架及其工具GenFaceUI，为智能代理的面部表情生成提供了新的机会和挑战，但同时也指出了需要改进的领域。

Abstract: This work investigates generative facial expression interfaces for intelligent agents from a meta-design perspective. We propose the Generative Personalized Facial Expression Interface (GPFEI) framework, which organizes rule-bounded spaces, character identity, and context--expression mapping to address challenges of control, coherence, and alignment in run-time facial expression generation. To operationalize this framework, we developed GenFaceUI, a proof-of-concept tool that enables designers to create templates, apply semantic tags, define rules, and iteratively test outcomes. We evaluated the tool through a qualitative study with twelve designers. The results show perceived gains in controllability and consistency, while revealing needs for structured visual mechanisms and lightweight explanations. These findings provide a conceptual framework, a proof-of-concept tool, and empirical insights that highlight both opportunities and challenges for advancing generative facial expression interfaces within a broader meta-design paradigm.

</details>


### [22] [AI Sensing and Intervention in Higher Education: Student Perceptions of Learning Impacts, Affective Responses, and Ethical Priorities](https://arxiv.org/abs/2602.11074)
*Bingyi Han,Ying Ma,Simon Coghlan,Dana McKay,George Buchanan,Wally Smith*

Main category: cs.HC

TL;DR: 本研究探讨了AI技术在教育中的应用及其对学生的影响，发现学生偏好非侵入式、可定制的干预方式，同时重视隐私与自主性。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探讨AI技术在学习中的应用对学生学习、福祉和伦理的影响，特别是关注学生对AI感知干预的看法。

Method: 进行了一项包含132名澳大利亚大学生的在线混合方法实验，展示了使用不同感知方法（基于视线和基于面部的情绪检测）和干预方式（由数字设备或教师进行）的视频场景。参与者完成了配对排名任务，以确定六个核心伦理关注点的优先级。

Result: 研究发现，学生重视有针对性的干预，但对AI监测的反应普遍消极，不论感知方式如何。学生更倾向于系统生成的提示，而非教师发起的帮助，原因在于学习自主性和社交尴尬的顾虑。学生的伦理考量优先关注自主权和隐私，其次是透明度、准确性、公平性和学习的利益。

Conclusion: 我们倡导设计可定制的、社会敏感的、非侵入式的系统，以保持学生的控制权、代理权和福祉。

Abstract: AI technologies that sense student attention and emotions to enable more personalised teaching interventions are increasingly promoted, but raise pressing questions about student learning, well-being, and ethics. In particular, students' perspectives about AI sensing-intervention in learning are often overlooked. We conducted an online mixed-method experiment with Australian university students (N=132), presenting video scenarios varying by whether sensing was used (in-use vs. not-in-use), sensing modality (gaze-based attention detection vs. facial-based emotion detection), and intervention (by digital device vs. teacher). Participants also completed pairwise ranking tasks to prioritise six core ethical concerns. Findings revealed that students valued targeted intervention but responded negatively to AI monitoring, regardless of sensing methods. Students preferred system-generated hints over teacher-initiated assistance, citing learning agency and social embarrassment concerns. Students' ethical considerations prioritised autonomy and privacy, followed by transparency, accuracy, fairness, and learning beneficence. We advocate designing customisable, social-sensitive, non-intrusive systems that preserve student control, agency, and well-being.

</details>


### [23] [LCIP: Loss-Controlled Inverse Projection of High-Dimensional Image Data](https://arxiv.org/abs/2602.11141)
*Yu Wang,Frederik L. Dennig,Michael Behrisch,Alexandru Telea*

Main category: cs.HC

TL;DR: 提出了一种新方法，通过控制两个用户参数，解决逆投影中的数据空间覆盖不足问题，适用于图像风格转移等应用。


<details>
  <summary>Details</summary>
Motivation: 现有逆投影方法存在固定表面结构的限制，难以全面覆盖数据空间的丰富性。

Method: 通过用户设置的两个直观参数，扫过数据空间以生成更丰富的数据分布。

Result: 该方法适用于任何投影技术和数据集，并且应用于图像风格转移的广泛实例，效果显著。

Conclusion: 该方法能在用户控制下有效地覆盖数据空间，有助于数据生成和增强。

Abstract: Projections (or dimensionality reduction) methods $P$ aim to map high-dimensional data to typically 2D scatterplots for visual exploration. Inverse projection methods $P^{-1}$ aim to map this 2D space to the data space to support tasks such as data augmentation, classifier analysis, and data imputation. Current $P^{-1}$ methods suffer from a fundamental limitation -- they can only generate a fixed surface-like structure in data space, which poorly covers the richness of this space. We address this by a new method that can `sweep' the data space under user control. Our method works generically for any $P$ technique and dataset, is controlled by two intuitive user-set parameters, and is simple to implement. We demonstrate it by an extensive application involving image manipulation for style transfer.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [24] [Adaptive Time Step Flow Matching for Autonomous Driving Motion Planning](https://arxiv.org/abs/2602.10285)
*Ananya Trivedi,Anjian Li,Mohamed Elnoor,Yusuf Umut Ciftci,Avinash Singh,Jovin D'sa,Sangjae Bae,David Isele,Taskin Padir,Faizan M. Tariq*

Main category: cs.RO

TL;DR: 提出了一种新框架，利用条件流匹配，在自主驾驶中实现实时路径生成与决策，无需重新训练，优化了运动平滑性与动态约束遵循性。


<details>
  <summary>Details</summary>
Motivation: 解决现有扩散模型在自主驾驶场景中高延迟和需重新训练的问题，提升推理速度和路径生成的质量。

Method: 基于条件流匹配的框架，通过轻量级方差估计器动态选择推理步骤。同时引入路径后处理步骤，优化计算效率，并保证实时性。

Result: 在Waymo Open Motion Dataset上训练后，该方法在执行路径时优于现有的多种模型，在动态约束遵循和路径平滑度上实现了显著改善。

Conclusion: 该框架在实时生成路径和决策上表现优越，适合在线部署，且无场景特定的调整需求。

Abstract: Autonomous driving requires reasoning about interactions with surrounding traffic. A prevailing approach is large-scale imitation learning on expert driving datasets, aimed at generalizing across diverse real-world scenarios. For online trajectory generation, such methods must operate at real-time rates. Diffusion models require hundreds of denoising steps at inference, resulting in high latency. Consistency models mitigate this issue but rely on carefully tuned noise schedules to capture the multimodal action distributions common in autonomous driving. Adapting the schedule, typically requires expensive retraining. To address these limitations, we propose a framework based on conditional flow matching that jointly predicts future motions of surrounding agents and plans the ego trajectory in real time. We train a lightweight variance estimator that selects the number of inference steps online, removing the need for retraining to balance runtime and imitation learning performance. To further enhance ride quality, we introduce a trajectory post-processing step cast as a convex quadratic program, with negligible computational overhead. Trained on the Waymo Open Motion Dataset, the framework performs maneuvers such as lane changes, cruise control, and navigating unprotected left turns without requiring scenario-specific tuning. Our method maintains a 20 Hz update rate on an NVIDIA RTX 3070 GPU, making it suitable for online deployment. Compared to transformer, diffusion, and consistency model baselines, we achieve improved trajectory smoothness and better adherence to dynamic constraints. Experiment videos and code implementations can be found at https://flow-matching-self-driving.github.io/.

</details>


### [25] [A Human-in-the-Loop Confidence-Aware Failure Recovery Framework for Modular Robot Policies](https://arxiv.org/abs/2602.10289)
*Rohan Banerjee,Krishna Palempalli,Bohan Yang,Jiaying Fang,Alif Abdullah,Tom Silver,Sarah Dean,Tapomayukh Bhattacharjee*

Main category: cs.RO

TL;DR: 提出一种人机协作故障恢复框架，通过模块选择和查询算法优化机器人在照护场景中的恢复效率与人类负担，实验证明有效。


<details>
  <summary>Details</summary>
Motivation: 在非结构化的人类环境中，机器人在照护场景中经常会遇到失败，因此设计有效的故障恢复机制至关重要。

Method: 人机协作故障恢复框架，结合模块级不确定性估计和人类干预成本模型，选定最可能导致故障的模块并决定是否询问人类。

Result: 框架在机器人辅助咬合系统中部署，在有移动限制的个体研究中，成功率提高，用户工作负担下降。

Conclusion: 明确考虑机器人的不确定性和人类努力可以提高协作机器人故障恢复的效率和以用户为中心的设计。

Abstract: Robots operating in unstructured human environments inevitably encounter failures, especially in robot caregiving scenarios. While humans can often help robots recover, excessive or poorly targeted queries impose unnecessary cognitive and physical workload on the human partner. We present a human-in-the-loop failure-recovery framework for modular robotic policies, where a policy is composed of distinct modules such as perception, planning, and control, any of which may fail and often require different forms of human feedback. Our framework integrates calibrated estimates of module-level uncertainty with models of human intervention cost to decide which module to query and when to query the human. It separates these two decisions: a module selector identifies the module most likely responsible for failure, and a querying algorithm determines whether to solicit human input or act autonomously. We evaluate several module-selection strategies and querying algorithms in controlled synthetic experiments, revealing trade-offs between recovery efficiency, robustness to system and user variables, and user workload. Finally, we deploy the framework on a robot-assisted bite acquisition system and demonstrate, in studies involving individuals with both emulated and real mobility limitations, that it improves recovery success while reducing the workload imposed on users. Our results highlight how explicitly reasoning about both robot uncertainty and human effort can enable more efficient and user-centered failure recovery in collaborative robots. Supplementary materials and videos can be found at: http://emprise.cs.cornell.edu/modularhil

</details>


### [26] [Solving Geodesic Equations with Composite Bernstein Polynomials for Trajectory Planning](https://arxiv.org/abs/2602.10365)
*Nick Gorman,Gage MacLin,Maxwell Hammond,Venanzio Cichella*

Main category: cs.RO

TL;DR: 本文提出了一种基于复合Bernstein多项式的轨迹规划方法，能在复杂环境中高效生成连续、动态可行的轨迹，并维持安全距离。


<details>
  <summary>Details</summary>
Motivation: 在复杂环境中，针对自主系统的轨迹规划，提高路径效率和安全性。

Method: 基于复合Bernstein多项式的轨迹规划方法，通过符号优化框架实现连续路径和精确的轨迹形状控制。

Result: 在多障碍场景中，展示了该方法有效生成平滑、无碰撞路径的能力，同时维持安全距离。

Conclusion: 该方法能够有效生成平滑、无碰撞的路径，适用于复杂环境下的自主系统导航。

Abstract: This work presents a trajectory planning method based on composite Bernstein polynomials for autonomous systems navigating complex environments. The method is implemented in a symbolic optimization framework that enables continuous paths and precise control over trajectory shape. Trajectories are planned over a cost surface that encodes obstacles as continuous fields rather than discrete boundaries. Regions near obstacles are assigned higher costs, naturally encouraging the trajectory to maintain a safe distance while still allowing efficient routing through constrained spaces. The use of composite Bernstein polynomials preserves continuity while enabling fine control over local curvature to satisfy geodesic constraints. The symbolic representation supports exact derivatives, improving optimization efficiency. The method applies to both two- and three-dimensional environments and is suitable for ground, aerial, underwater, and space systems. In spacecraft trajectory planning, for example, it enables the generation of continuous, dynamically feasible trajectories with high numerical efficiency, making it well suited for orbital maneuvers, rendezvous and proximity operations, cluttered gravitational environments, and planetary exploration missions with limited onboard computational resources. Demonstrations show that the approach efficiently generates smooth, collision-free paths in scenarios with multiple obstacles, maintaining clearance without extensive sampling or post-processing. The optimization incorporates three constraint types: (1) a Gaussian surface inequality enforcing minimum obstacle clearance; (2) geodesic equations guiding the path along locally efficient directions on the cost surface; and (3) boundary constraints enforcing fixed start and end conditions. The method can serve as a standalone planner or as an initializer for more complex motion planning problems.

</details>


### [27] [LocoVLM: Grounding Vision and Language for Adapting Versatile Legged Locomotion Policies](https://arxiv.org/abs/2602.10399)
*I Made Aswin Nahrendra,Seunghyun Lee,Dongkyu Lee,Hyun Myung*

Main category: cs.RO

TL;DR: 本研究提出一种新方法，结合高层常识推理与腿部运动学习，实现指令遵循率高达87%的实时适应。


<details>
  <summary>Details</summary>
Motivation: 解决腿部运动学习中环境几何表示的局限性，使机器人能响应更高层次的语义，如人类指令。

Method: 集成基础模型的高层次常识推理，使用预训练的大型语言模型合成指令驱动的技能数据库，同时利用预训练的视觉语言模型提取环境语义。

Result: 通过训练一种样式条件策略，成功生成多样化和稳健的运动技能，实现高保真度的样式控制。

Conclusion: 本研究是首次展示在无需在线查询云端基础模型的情况下，利用高层次推理进行腿部运动的实时适应，指令遵循准确率高达87%。

Abstract: Recent advances in legged locomotion learning are still dominated by the utilization of geometric representations of the environment, limiting the robot's capability to respond to higher-level semantics such as human instructions. To address this limitation, we propose a novel approach that integrates high-level commonsense reasoning from foundation models into the process of legged locomotion adaptation. Specifically, our method utilizes a pre-trained large language model to synthesize an instruction-grounded skill database tailored for legged robots. A pre-trained vision-language model is employed to extract high-level environmental semantics and ground them within the skill database, enabling real-time skill advisories for the robot. To facilitate versatile skill control, we train a style-conditioned policy capable of generating diverse and robust locomotion skills with high fidelity to specified styles. To the best of our knowledge, this is the first work to demonstrate real-time adaptation of legged locomotion using high-level reasoning from environmental semantics and instructions with instruction-following accuracy of up to 87% without the need for online query to on-the-cloud foundation models.

</details>


### [28] [Towards Long-Lived Robots: Continual Learning VLA Models via Reinforcement Fine-Tuning](https://arxiv.org/abs/2602.10503)
*Yuan Liu,Haoran Li,Shuai Tian,Yuxing Qin,Yuhui Chen,Yupeng Zheng,Yongzhen Huang,Dongbin Zhao*

Main category: cs.RO

TL;DR: 本文提出了LifeLong-RFT方法，通过增强学习微调VLA模型，克服了监督微调的不足，显著提升了多任务学习和持续学习的表现。


<details>
  <summary>Details</summary>
Motivation: 针对传统监督微调(SFT)的局限性，尤其是对特定任务数据的高要求和灾难性遗忘，提出了一种新的解决方案，旨在提高VLA模型的适应性和利用效率。

Method: 提出了一种新的强化学习微调策略LifeLong-RFT，集成了按块强化学习和多维过程奖励机制，不依赖于在线环境反馈和预训练奖励模型。

Result: 在SimperEnv、LIBERO和真实任务中进行的实验表明，LifeLong-RFT在多任务学习中表现出色，且在LIBERO基准测试中比SFT的平均成功率提高了22%，仅使用20%的训练数据就能有效适应新任务。

Conclusion: 我们的LifeLong-RFT方法为VLA模型提供了一种有前景的后训练范式，显著提升了多任务学习和持续学习的能力。

Abstract: Pretrained on large-scale and diverse datasets, VLA models demonstrate strong generalization and adaptability as general-purpose robotic policies. However, Supervised Fine-Tuning (SFT), which serves as the primary mechanism for adapting VLAs to downstream domains, requires substantial amounts of task-specific data and is prone to catastrophic forgetting. To address these limitations, we propose LifeLong-RFT, a simple yet effective Reinforcement Fine-Tuning (RFT) strategy for VLA models independent of online environmental feedback and pre-trained reward models. By integrating chunking-level on-policy reinforcement learning with the proposed Multi-Dimensional Process Reward (MDPR) mechanism, LifeLong-RFT quantifies the heterogeneous contributions of intermediate action chunks across three dimensions to facilitate policy optimization. Specifically, (1) the Quantized Action Consistency Reward (QACR) ensures accurate action prediction within the discrete action space; (2) the Continuous Trajectory Alignment Reward (CTAR) aligns decoded continuous action chunks with reference trajectories to ensure precise control; (3) the Format Compliance Reward (FCR) guarantees the structural validity of outputs. Comprehensive experiments across SimplerEnv, LIBERO, and real-world tasks demonstrate that LifeLong-RFT exhibits strong performance in multi-task learning. Furthermore, for continual learning on the LIBERO benchmark, our method achieves a 22% gain in average success rate over SFT, while effectively adapting to new tasks using only 20% of the training data. Overall, our method provides a promising post-training paradigm for VLAs.

</details>


### [29] [Co-jump: Cooperative Jumping with Quadrupedal Robots via Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.10514)
*Shihao Dong,Yeke Chen,Zeren Luo,Jiahui Zhang,Bowen Xu,Jinghan Lin,Yimin Han,Ji Ma,Zhiyou Yu,Yudong Zhao,Peng Lu*

Main category: cs.RO

TL;DR: 本研究提出了一种四足机器人协同跳跃的新方法，通过无通信的方式实现跳跃能力的显著提升，展示了在受限环境下的有效协作。


<details>
  <summary>Details</summary>
Motivation: 为了突破单一机器人的物理驱动限制，探讨协作跳跃任务，以期提高四足机器人在跳跃能力方面的表现。

Method: 使用多智能体近端策略优化（MAPPO）结合逐步课程策略，来解决高冲击接触动态问题，实现机器人之间的同步，且无需明确通信或预先设定运动原型。

Result: 实验结果表明，两个机器人能够协同跳跃到达1.5米高的平台，其中一台机器人的足端高度达到1.1米，较单独四足机器人0.45米的跳跃高度提升了144%。

Conclusion: 通过本研究的框架，实现了无协议协同跳跃，显著提高了四足机器人在受限环境下的协作运动能力。

Abstract: While single-agent legged locomotion has witnessed remarkable progress, individual robots remain fundamentally constrained by physical actuation limits. To transcend these boundaries, we introduce Co-jump, a cooperative task where two quadrupedal robots synchronize to execute jumps far beyond their solo capabilities. We tackle the high-impulse contact dynamics of this task under a decentralized setting, achieving synchronization without explicit communication or pre-specified motion primitives. Our framework leverages Multi-Agent Proximal Policy Optimization (MAPPO) enhanced by a progressive curriculum strategy, which effectively overcomes the sparse-reward exploration challenges inherent in mechanically coupled systems. We demonstrate robust performance in simulation and successful transfer to physical hardware, executing multi-directional jumps onto platforms up to 1.5 m in height. Specifically, one of the robots achieves a foot-end elevation of 1.1 m, which represents a 144% improvement over the 0.45 m jump height of a standalone quadrupedal robot, demonstrating superior vertical performance. Notably, this precise coordination is achieved solely through proprioceptive feedback, establishing a foundation for communication-free collaborative locomotion in constrained environments.

</details>


### [30] [ReSPEC: A Framework for Online Multispectral Sensor Reconfiguration in Dynamic Environments](https://arxiv.org/abs/2602.10547)
*Yanchen Liu,Yuang Fan,Minghui Zhao,Xiaofan Jiang*

Main category: cs.RO

TL;DR: 提出了一种新的框架，通过动态调整传感器配置以应对环境变化，从而提高机器人的感知能力，减少资源消耗。


<details>
  <summary>Details</summary>
Motivation: 大多数现有系统在静态传感器配置下操作，浪费带宽、计算和能量，不优先考虑在不利条件下的传感器使用。

Method: 引入一个统一的框架，将感知、学习和执行整合为一个闭环重配置系统，任务特定的检测骨干网络提取多光谱特征，并生成每种模态的定量贡献得分，RL代理根据得分动态调整传感器配置。

Result: 在移动巡逻车上实现和评估该框架，显示自适应控制显著降低GPU负载。

Conclusion: 自适应控制使GPU负载减少29.3%，并且与启发式基线相比，仅下降5.3%的准确率，展示了资源感知自适应感知在嵌入式机器人平台上的潜力。

Abstract: Multi-sensor fusion is central to robust robotic perception, yet most existing systems operate under static sensor configurations, collecting all modalities at fixed rates and fidelity regardless of their situational utility. This rigidity wastes bandwidth, computation, and energy, and prevents systems from prioritizing sensors under challenging conditions such as poor lighting or occlusion. Recent advances in reinforcement learning (RL) and modality-aware fusion suggest the potential for adaptive perception, but prior efforts have largely focused on re-weighting features at inference time, ignoring the physical cost of sensor data collection. We introduce a framework that unifies sensing, learning, and actuation into a closed reconfiguration loop. A task-specific detection backbone extracts multispectral features (e.g. RGB, IR, mmWave, depth) and produces quantitative contribution scores for each modality. These scores are passed to an RL agent, which dynamically adjusts sensor configurations, including sampling frequency, resolution, sensing range, and etc., in real time. Less informative sensors are down-sampled or deactivated, while critical sensors are sampled at higher fidelity as environmental conditions evolve. We implement and evaluate this framework on a mobile rover, showing that adaptive control reduces GPU load by 29.3\% with only a 5.3\% accuracy drop compared to a heuristic baseline. These results highlight the potential of resource-aware adaptive sensing for embedded robotic platforms.

</details>


### [31] [LAP: Language-Action Pre-Training Enables Zero-shot Cross-Embodiment Transfer](https://arxiv.org/abs/2602.10556)
*Lihan Zha,Asher J. Hancock,Mingtong Zhang,Tenny Yin,Yixuan Huang,Dhruv Shah,Allen Z. Ren,Anirudha Majumdar*

Main category: cs.RO

TL;DR: 本研究提出了一种新的语言-动作预训练框架，LAP-3B在未见机器人上实现了显著的零-shot迁移和性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决当前的视觉-语言-动作模型在多个机器人形态上适应性的不足，寻求在不需要特定于形态的微调的情况下实现更广泛的适用性。

Method: 提出了一种新的语言-动作预训练方法（LAP），将低级机器人动作直接用自然语言表示，避免了学习的标记器和昂贵的注释需求。

Result: LAP-3B在多个新机器人和操作任务上平均实现超过50%的零-shot成功率，较最强之前的视觉-语言-动作模型表现双倍提升。

Conclusion: LAP-3B实现了首次在未见的机器人形态上具有显著的零-shot迁移能力，并且通过联合训练进一步提升了性能。

Abstract: A long-standing goal in robotics is a generalist policy that can be deployed zero-shot on new robot embodiments without per-embodiment adaptation. Despite large-scale multi-embodiment pre-training, existing Vision-Language-Action models (VLAs) remain tightly coupled to their training embodiments and typically require costly fine-tuning. We introduce Language-Action Pre-training (LAP), a simple recipe that represents low-level robot actions directly in natural language, aligning action supervision with the pre-trained vision-language model's input-output distribution. LAP requires no learned tokenizer, no costly annotation, and no embodiment-specific architectural design. Based on LAP, we present LAP-3B, which to the best of our knowledge is the first VLA to achieve substantial zero-shot transfer to previously unseen robot embodiments without any embodiment-specific fine-tuning. Across multiple novel robots and manipulation tasks, LAP-3B attains over 50% average zero-shot success, delivering roughly a 2x improvement over the strongest prior VLAs. We further show that LAP enables efficient adaptation and favorable scaling, while unifying action prediction and VQA in a shared language-action format that yields additional gains through co-training.

</details>


### [32] [Morphogenetic Assembly and Adaptive Control for Heterogeneous Modular Robots](https://arxiv.org/abs/2602.10561)
*Chongxi Meng,Da Zhao,Yifei Zhao,Minghao Zeng,Yanmin Zhou,Zhipeng Wang,Bin He*

Main category: cs.RO

TL;DR: 本文提出了一种异构模块机器人的闭环自动化框架，通过层次化规划和GPU加速的MPPI控制器，实现了高效的动态组装与运动控制。


<details>
  <summary>Details</summary>
Motivation: 为了解决大规模异构重配置中的状态空间爆炸问题，提出了一种高效的规划框架，旨在实现多种机器人配置的动态组装与即时运动能力。

Method: 通过高层规划器和低层规划器进行层次化规划，高层使用带类型惩罚的双向启发式搜索生成模块处理序列，低层则应用A*搜索计算最优执行轨迹。

Result: 在大规模仿真中，采用类型惩罚项的规划在异构场景中显示出更好的鲁棒性，而贪婪启发式规划相比匈牙利启发式产生了更低的物理执行成本。无论是速度跟踪精度还是控制频率所取得的结果，采用退火方差MPPI控制器的表现均显著优于标准MPPI，达到了实时控制的50Hz。

Conclusion: 所提出的闭环自动化框架能够有效地处理异构模块机器人，从组装到控制实现了端到端的自适应运动生成，且在大规模仿真中表现优异。

Abstract: This paper presents a closed-loop automation framework for heterogeneous modular robots, covering the full pipeline from morphological construction to adaptive control. In this framework, a mobile manipulator handles heterogeneous functional modules including structural, joint, and wheeled modules to dynamically assemble diverse robot configurations and provide them with immediate locomotion capability. To address the state-space explosion in large-scale heterogeneous reconfiguration, we propose a hierarchical planner: the high-level planner uses a bidirectional heuristic search with type-penalty terms to generate module-handling sequences, while the low level planner employs A* search to compute optimal execution trajectories. This design effectively decouples discrete configuration planning from continuous motion execution. For adaptive motion generation of unknown assembled configurations, we introduce a GPU accelerated Annealing-Variance Model Predictive Path Integral (MPPI) controller. By incorporating a multi stage variance annealing strategy to balance global exploration and local convergence, the controller enables configuration-agnostic, real-time motion control. Large scale simulations show that the type-penalty term is critical for planning robustness in heterogeneous scenarios. Moreover, the greedy heuristic produces plans with lower physical execution costs than the Hungarian heuristic. The proposed annealing-variance MPPI significantly outperforms standard MPPI in both velocity tracking accuracy and control frequency, achieving real time control at 50 Hz. The framework validates the full-cycle process, including module assembly, robot merging and splitting, and dynamic motion generation.

</details>


### [33] [Flow-Enabled Generalization to Human Demonstrations in Few-Shot Imitation Learning](https://arxiv.org/abs/2602.10594)
*Runze Tang,Penny Sweetser*

Main category: cs.RO

TL;DR: 该研究提出SFCrP，通过分析场景流和裁剪点云，提高机器人的模仿学习效率，展现了较强的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在通过使用流作为中介表示来减少所需的机器人演示量，解决传统模仿学习中大量演示导致的收集成本问题。

Method: SFCrP方法包含一个用于跨实体学习的场景流预测模型(SFCr)和一个基于流和裁剪点云的条件策略(FCrP)。

Result: SFCrP通过从机器人和人类视频中学习，预测任意点的轨迹，遵循一般流动运动并根据观察进行精确任务的动作调整。

Conclusion: 我们提出的SFCrP方法在多个真实世界任务设置中超越了最新的基准，同时在仅在视频中观察到的场景中表现出强大的空间和实例泛化能力。

Abstract: Imitation Learning (IL) enables robots to learn complex skills from demonstrations without explicit task modeling, but it typically requires large amounts of demonstrations, creating significant collection costs. Prior work has investigated using flow as an intermediate representation to enable the use of human videos as a substitute, thereby reducing the amount of required robot demonstrations. However, most prior work has focused on the flow, either on the object or on specific points of the robot/hand, which cannot describe the motion of interaction. Meanwhile, relying on flow to achieve generalization to scenarios observed only in human videos remains limited, as flow alone cannot capture precise motion details. Furthermore, conditioning on scene observation to produce precise actions may cause the flow-conditioned policy to overfit to training tasks and weaken the generalization indicated by the flow. To address these gaps, we propose SFCrP, which includes a Scene Flow prediction model for Cross-embodiment learning (SFCr) and a Flow and Cropped point cloud conditioned Policy (FCrP). SFCr learns from both robot and human videos and predicts any point trajectories. FCrP follows the general flow motion and adjusts the action based on observations for precision tasks. Our method outperforms SOTA baselines across various real-world task settings, while also exhibiting strong spatial and instance generalization to scenarios seen only in human videos.

</details>


### [34] [Pitch Angle Control of a Magnetically Actuated Capsule Robot with Nonlinear FEA-based MPC and EKF Multisensory Fusion](https://arxiv.org/abs/2602.10610)
*Chongxun Wang,Zikang Shen,Apoorav Rathore,Akanimoh Udombeh,Harrison Teng,Fangzhou Xia*

Main category: cs.RO

TL;DR: 本研究提出了一种新的基于有限元的MPC控制策略，通过传感器融合实现了对胶囊机器人的倾斜控制，显著提高了其在胃肠道的应用效率。


<details>
  <summary>Details</summary>
Motivation: 现有胶囊机器人系统在胃肠道中的应用中，忽视了对胶囊滚转角度的控制，影响了与胃壁的接触交互，因此开发一种新的控制框架是必要的。

Method: 采用四线圈电磁阵列，通过三维有限元模拟特征化胶囊内部永久磁铁的角度相关的磁力和扭矩，并在控制模型中嵌入查找表，同时设计了一种约束模型预测控制器（MPC）来调节倾斜度。

Result: 实验表明，该方法能够在接近临床真实条件的情况下，实现在胃面模拟表面上的倾斜重新定位，其效率是传统控制方法的三至五倍，减少了振荡运动。

Conclusion: 提出的基于有限元的模型预测控制与传感器融合策略为胶囊机器人的倾斜控制，受限于物理硬件的要求，提供了一种可扩展的解决方案。

Abstract: Magnetically actuated capsule robots promise minimally invasive diagnosis and therapy in the gastrointestinal (GI) tract, but existing systems largely neglect control of capsule pitch, a degree of freedom critical for contact-rich interaction with inclined gastric walls. This paper presents a nonlinear, model-based framework for magnetic pitch control of an ingestible capsule robot actuated by a four-coil electromagnetic array. Angle-dependent magnetic forces and torques acting on embedded permanent magnets are characterized using three-dimensional finite-element simulations and embedded as lookup tables in a control-oriented rigid-body pitching model with rolling contact and actuator dynamics. A constrained model predictive controller (MPC) is designed to regulate pitch while respecting hardware-imposed current and slew-rate limits. Experiments on a compliant stomach-inspired surface demonstrate robust pitch reorientation from both horizontal and upright configurations, achieving about three to five times faster settling and reduced oscillatory motion than on-off control. Furthermore, an extended Kalman filter (EKF) fusing inertial sensing with intermittent visual measurements enables stable closed-loop control when the camera update rate is reduced from 30 Hz to 1 Hz, emulating clinically realistic imaging constraints. These results establish finite-element-informed MPC with sensor fusion as a scalable strategy for pitch regulation, controlled docking, and future multi-degree-of-freedom capsule locomotion.

</details>


### [35] [Free-Flying Crew Cooperative Robots on the ISS: A Joint Review of Astrobee, CIMON, and Int-Ball Operations](https://arxiv.org/abs/2602.10686)
*Seiko Piotr Yamaguchi,Andres Mora Vargas,Till Eisenberg,Christian Rogon,Tatsuya Yamamoto,Shona Inoue,Christoph Kössl,Brian Coltin,Trey Smith,Jose V. Benavides*

Main category: cs.RO

TL;DR: 本文分析了NASA的Astrobee、DLR的CIMON和JAXA的Int-Ball三款机器人在开发和运营过程中的共同经验，并为未来设计提供建议。


<details>
  <summary>Details</summary>
Motivation: 为了支持人类航天飞行中的各种工作，研究这三款机器人在国际空间站上的使用经验和设计哲学的共性。

Method: 通过对NASA的Astrobee、DLR的CIMON和JAXA的Int-Ball这三款机器人进行联合分析，汇集其开发和运营团队的经验。

Result: 本文提供了关于这三款机器人目标、设计和操作的详细概述，并总结了从设计到在轨操作的生命周期中的共同经验和教训。

Conclusion: 本研究为未来的机器人设计和研究提供了建议，基于对三个不同机器人在开发和运营过程中的共同经验进行的分析。

Abstract: Intra-vehicular free-flying robots are anticipated to support various work in human spaceflight while working side-by-side with astronauts. Such example of robots includes NASA's Astrobee, DLR's CIMON, and JAXA's Int-Ball, which are deployed on the International Space Station. This paper presents the first joint analyses of these robot's shared experiences, co-authored by their development and operation team members. Despite the different origins and design philosophies, the development and operations of these platforms encountered various convergences. Hence, this paper presents a detailed overview of these robots, presenting their objectives, design, and onboard operations. Hence, joint lessons learned across the lifecycle are presented, from design to on-orbit operations. These lessons learned are anticipated to serve for future development and research as design recommendations.

</details>


### [36] [3D-Printed Anisotropic Soft Magnetic Coating for Directional Rolling of a Magnetically Actuated Capsule Robot](https://arxiv.org/abs/2602.10688)
*Jin Zhou,Chongxun Wang,Zikang Shen,Fangzhou Xia*

Main category: cs.RO

TL;DR: 本研究提出了一种新型的3D打印软胶囊机器人，采用磁涂层替代内部磁铁，提升胶囊的吞咽性和功能，具备良好的运动能力，适用于微创医疗。


<details>
  <summary>Details</summary>
Motivation: 传统胶囊机器人的内部磁铁体积庞大，限制了功能模块的集成，并占用有效空间。

Method: 采用紧凑的3D打印软胶囊机器人，通过磁涂层替代内部磁铁，提升了运动能力。

Result: 通过磁静力模拟和实验验证，改进的聚合物复合材料可实现稳定的双向滚动和全向转向。

Conclusion: 新型涂层胶囊机器人具有可靠的临床应用潜力，能够扩大在微创诊断和治疗中的应用范围。

Abstract: Capsule robots are promising tools for minimally invasive diagnostics and therapy, with applications from gastrointestinal endoscopy to targeted drug delivery and biopsy sampling. Conventional magnetic capsule robots embed bulky permanent magnets at both ends, reducing the usable cavity by about 10-20 mm and limiting integration of functional modules. We propose a compact, 3D-printed soft capsule robot with a magnetic coating that replaces internal magnets, enabling locomotion via a thin, functional shell while preserving the entire interior cavity as a continuous volume for medical payloads. The compliant silicone-magnetic composite also improves swallowability, even with a slightly larger capsule size. Magnetostatic simulations and experiments confirm that programmed NSSN/SNNS pole distributions provide strong anisotropy and reliable torque generation, enabling stable bidirectional rolling, omnidirectional steering, climbing on 7.5 degree inclines, and traversal of 5 mm protrusions. Rolling motion is sustained when the magnetic field at the capsule reaches at least 0.3 mT, corresponding to an effective actuation depth of 30 mm in our setup. Future work will optimize material composition, coating thickness, and magnetic layouts to enhance force output and durability, while next-generation robotic-arm-based field generators with closed-loop feedback will address nonlinearities and expand maneuverability. Together, these advances aim to transition coating-based capsule robots toward reliable clinical deployment and broaden their applications in minimally invasive diagnostics and therapy.

</details>


### [37] [A Unified Experimental Architecture for Informative Path Planning: from Simulation to Deployment with GuadalPlanner](https://arxiv.org/abs/2602.10702)
*Alejandro Mendoza Barrionuevo,Dame Seck Diop,Alejandro Casado Pérez,Daniel Gutiérrez Reina,Sergio L. Toral Marín,Samuel Yanes Luis*

Main category: cs.RO

TL;DR: 本论文提出了GuadalPlanner，一个统一架构，旨在提高自主车辆路径规划算法的评估一致性，支持从仿真到现实的无缝迁移，实验结果显示其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决自主车辆路径规划算法评估中存在的执行流程碎片化和仿真与现实部署之间的可转移性有限的问题。

Method: 使用GuadalPlanner构建统一架构，通过标准化接口连接规划、感知与车辆执行。

Result: 提出的架构在不同抽象层次上无须修改即可对算法进行一致的评估，并通过一系列实验验证了其有效性，包括在自主水面车辆上进行的现实部署。

Conclusion: 该架构通过实验验证，与真实世界的自主车载系统能够一致有效地运作。

Abstract: The evaluation of informative path planning algorithms for autonomous vehicles is often hindered by fragmented execution pipelines and limited transferability between simulation and real-world deployment. This paper introduces a unified architecture that decouples high-level decision-making from vehicle-specific control, enabling algorithms to be evaluated consistently across different abstraction levels without modification. The proposed architecture is realized through GuadalPlanner, which defines standardized interfaces between planning, sensing, and vehicle execution. It is an open and extensible research tool that supports discrete graph-based environments and interchangeable planning strategies, and is built upon widely adopted robotics technologies, including ROS2, MAVLink, and MQTT. Its design allows the same algorithmic logic to be deployed in fully simulated environments, software-in-the-loop configurations, and physical autonomous vehicles using an identical execution pipeline. The approach is validated through a set of experiments, including real-world deployment on an autonomous surface vehicle performing water quality monitoring with real-time sensor feedback.

</details>


### [38] [Omnidirectional Dual-Arm Aerial Manipulator with Proprioceptive Contact Localization for Landing on Slanted Roofs](https://arxiv.org/abs/2602.10703)
*Martijn B. J. Brummelhuis,Nathan F. Lepora,Salua Hamaza*

Main category: cs.RO

TL;DR: 本研究提出一种新型无人空中操控器，能在复杂城市环境中准确检测并应对屋顶倾斜，验证结果显示其在不同倾斜度表面上的出色表现。


<details>
  <summary>Details</summary>
Motivation: 解决传统感知方法在复杂城市环境中难以准确检测屋顶倾斜的问题，尤其是在天气和表面材料等外部因素影响下。

Method: 采用双臂无人空中操控器，通过物理接触检测屋顶倾斜度，结合动量基的扭矩观测器进行接触定位策略。

Result: 实验验证结果显示，该方法可在倾斜度达30.5度的表面上成功着陆，倾斜度估计误差平均为2.87度，表明该技术的可靠性与有效性。

Conclusion: 提出的无人机操控器在复杂的城市环境中能够实现可靠的着陆，尤其是在屋顶等不规则表面上，具有较高的精确性和适应性。

Abstract: Operating drones in urban environments often means they need to land on rooftops, which can have different geometries and surface irregularities. Accurately detecting roof inclination using conventional sensing methods, such as vision-based or acoustic techniques, can be unreliable, as measurement quality is strongly influenced by external factors including weather conditions and surface materials. To overcome these challenges, we propose a novel unmanned aerial manipulator morphology featuring a dual-arm aerial manipulator with an omnidirectional 3D workspace and extended reach. Building on this design, we develop a proprioceptive contact detection and contact localization strategy based on a momentum-based torque observer. This enables the UAM to infer the inclination of slanted surfaces blindly - through physical interaction - prior to touchdown. We validate the approach in flight experiments, demonstrating robust landings on surfaces with inclinations of up to 30.5 degrees and achieving an average surface inclination estimation error of 2.87 degrees over 9 experiments at different incline angles.

</details>


### [39] [Say, Dream, and Act: Learning Video World Models for Instruction-Driven Robot Manipulation](https://arxiv.org/abs/2602.10717)
*Songen Gu,Yunuo Cai,Tianyu Wang,Simo Wu,Yanwei Fu*

Main category: cs.RO

TL;DR: 提出一种新的框架用于视频条件的机器人行动，通过视频生成模型和对抗蒸馏技术，实现对未来状态的预测与提高任务完成效果。


<details>
  <summary>Details</summary>
Motivation: 现有系统在预测环境反应方面能力不足，导致错误和效率低下，需要解决预测未来状态的能力不足，以及目前世界模型的短期预测和空间不一致性的问题。

Method: 提出了一种快速的、预测性的视频条件下的行动框架，包含视频生成模型的选择与适配、对抗蒸馏用于快速生成视频，以及培训利用生成视频和真实观测来纠正空间错误的行为模型。

Result: 我们的方法生成的时间一致、空间准确的视频预测能够直接支持精确操控，相比于现有的基线方法显示出显著的改进。

Conclusion: 我们的方法显著提高了机器人的实施一致性、空间指代能力和任务完成度。

Abstract: Robotic manipulation requires anticipating how the environment evolves in response to actions, yet most existing systems lack this predictive capability, often resulting in errors and inefficiency. While Vision-Language Models (VLMs) provide high-level guidance, they cannot explicitly forecast future states, and existing world models either predict only short horizons or produce spatially inconsistent frames. To address these challenges, we propose a framework for fast and predictive video-conditioned action. Our approach first selects and adapts a robust video generation model to ensure reliable future predictions, then applies adversarial distillation for fast, few-step video generation, and finally trains an action model that leverages both generated videos and real observations to correct spatial errors. Extensive experiments show that our method produces temporally coherent, spatially accurate video predictions that directly support precise manipulation, achieving significant improvements in embodiment consistency, spatial referring ability, and task completion over existing baselines. Codes & Models will be released.

</details>


### [40] [From Representational Complementarity to Dual Systems: Synergizing VLM and Vision-Only Backbones for End-to-End Driving](https://arxiv.org/abs/2602.10719)
*Sining Ang,Yuguang Yang,Chenxu Dang,Canyu Chen,Cheng Chi,Haiyan Liu,Xuanyao Mao,Jason Bao,Xuliang,Bingchuan Sun,Yan Wang*

Main category: cs.RO

TL;DR: 本研究探讨了语言增强的驾驶策略，提出HybridDriveVLA和DualDriveVLA，以提升驾驶效果和效率，最优的PDMS达93.58。


<details>
  <summary>Details</summary>
Motivation: 探讨增益语言能力之下，Vision-Language-Action驾驶在准确性与成本之间的权衡具体变化。

Method: 本文采用3个研究问题(RQ)分析的方式，通过实例化完整的VLM和仅视觉的骨干网络，并使用相同的扩散Transformer规划器评估其表现。

Result: 实验结果显示，通过引入HybridDriveVLA和DualDriveVLA策略，提升了性能指标(PDMS)至最高93.58，同时在效率上有显著提高。

Conclusion: 本研究提出了DualDriveVLA策略，通过在特定场景下动态选择VLM或ViT来优化驾驶表现，显著提高效率和准确性。

Abstract: Vision-Language-Action (VLA) driving augments end-to-end (E2E) planning with language-enabled backbones, yet it remains unclear what changes beyond the usual accuracy--cost trade-off. We revisit this question with 3--RQ analysis in RecogDrive by instantiating the system with a full VLM and vision-only backbones, all under an identical diffusion Transformer planner. RQ1: At the backbone level, the VLM can introduce additional subspaces upon the vision-only backbones. RQ2: This unique subspace leads to a different behavioral in some long-tail scenario: the VLM tends to be more aggressive whereas ViT is more conservative, and each decisively wins on about 2--3% of test scenarios; With an oracle that selects, per scenario, the better trajectory between the VLM and ViT branches, we obtain an upper bound of 93.58 PDMS. RQ3: To fully harness this observation, we propose HybridDriveVLA, which runs both ViT and VLM branches and selects between their endpoint trajectories using a learned scorer, improving PDMS to 92.10. Finally, DualDriveVLA implements a practical fast--slow policy: it runs ViT by default and invokes the VLM only when the scorer's confidence falls below a threshold; calling the VLM on 15% of scenarios achieves 91.00 PDMS while improving throughput by 3.2x. Code will be released.

</details>


### [41] [Biomimetic Mantaray robot toward the underwater autonomous -- Experimental verification of swimming and diving by flapping motion -](https://arxiv.org/abs/2602.10904)
*Kenta Tabata,Ryosuke Oku,Jun Ito,Renato Miyagusuku,Koichi Ozaki*

Main category: cs.RO

TL;DR: 本研究开发了一种仿生曼塔鳐机器人，展示了其在水下探测中的优越性，证明了其生物启发设计的潜力。


<details>
  <summary>Details</summary>
Motivation: 受曼塔鳐启发，旨在减少海底干扰，提高推进效率。

Method: 开发并实验验证了一种仿生的曼塔鳐机器人，使用拍打运动推进，配备伺服电机驱动的胸鳍和流线型控制箱。

Result: 实验结果显示机器人具有稳定的游泳和潜水动作，适用于水族馆和鱼苗等环境。

Conclusion: 本研究表明，生物启发的机器人设计能够提高生态监测和水下探测的效率。

Abstract: This study presents the development and experimental verification of a biomimetic manta ray robot for underwater autonomous exploration. Inspired by manta rays, the robot uses flapping motion for propulsion to minimize seabed disturbance and enhance efficiency compared to traditional screw propulsion. The robot features pectoral fins driven by servo motors and a streamlined control box to reduce fluid resistance. The control system, powered by a Raspberry Pi 3B, includes an IMU and pressure sensor for real-time monitoring and control. Experiments in a pool assessed the robot's swimming and diving capabilities. Results show stable swimming and diving motions with PD control. The robot is suitable for applications in environments like aquariums and fish nurseries, requiring minimal disturbance and efficient maneuverability. Our findings demonstrate the potential of bio-inspired robotic designs to improve ecological monitoring and underwater exploration.

</details>


### [42] [Safe mobility support system using crowd mapping and avoidance route planning using VLM](https://arxiv.org/abs/2602.10910)
*Sena Saito,Kenta Tabata,Renato Miyagusuku,Koichi Ozaki*

Main category: cs.RO

TL;DR: 本文提出了一种新框架，结合视觉-语言模型与高斯过程回归，显著提高了自主移动机器人在动态环境中的导航能力。


<details>
  <summary>Details</summary>
Motivation: 在动态环境中，特别是拥挤区域内，自主机器人导航的安全性和有效性仍然面临挑战，急需新的解决方案。

Method: 采用视觉-语言模型（VLM）和高斯过程回归（GPR）生成动态人群密度图（抽象图）。

Result: 实际试验结果显示，机器人成功生成了避开静态障碍物和动态人群的路线。

Conclusion: 通过将视觉-语言模型与高斯过程回归相结合，提出的框架有效提升了自主移动机器人的导航安全性和适应性。

Abstract: Autonomous mobile robots offer promising solutions for labor shortages and increased operational efficiency. However, navigating safely and effectively in dynamic environments, particularly crowded areas, remains challenging. This paper proposes a novel framework that integrates Vision-Language Models (VLM) and Gaussian Process Regression (GPR) to generate dynamic crowd-density maps (``Abstraction Maps'') for autonomous robot navigation. Our approach utilizes VLM's capability to recognize abstract environmental concepts, such as crowd densities, and represents them probabilistically via GPR. Experimental results from real-world trials on a university campus demonstrated that robots successfully generated routes avoiding both static obstacles and dynamic crowds, enhancing navigation safety and adaptability.

</details>


### [43] [Design, Development, and Use of Maya Robot as an Assistant for the Therapy/Education of Children with Cancer: a Pilot Study](https://arxiv.org/abs/2602.10942)
*Alireza Taheri,Minoo Alemi,Elham Ranjkar,Raman Rafatnejad,Ali F. Meghdari*

Main category: cs.RO

TL;DR: 本研究设计了Maya机器人，旨在与正在接受癌症治疗的儿童互动，结果显示机器人可以有效减轻儿童的疼痛感，并提高其情感安全感和对机器人的信任。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一个便携的社交机器人（Maya机器人）以帮助正在接受癌症治疗的儿童，并希望通过机器人改善他们的治疗体验。

Method: 通过深度神经网络提高Maya机器人的面部表情识别准确度至98%；进行两项实验，分别评估Maya机器人对儿童注射疼痛感知和儿童及其母亲在游戏互动中的心理感受。

Result: 与Maya机器人在场的注射过程中，儿童感知到的疼痛显著减少；互动后，儿童在情感上表现出对机器人的信任程度显著高于母亲。

Conclusion: Maya机器人在儿童癌症治疗中的应用显著减轻了孩子们的疼痛感，并提升了他们的情感福祉，显示出社交机器人在儿科医疗中的潜在价值。

Abstract: This study centers around the design and implementation of the Maya Robot, a portable elephant-shaped social robot, intended to engage with children undergoing cancer treatment. Initial efforts were devoted to enhancing the robot's facial expression recognition accuracy, achieving a 98% accuracy through deep neural networks. Two subsequent preliminary exploratory experiments were designed to advance the study's objectives. The first experiment aimed to compare pain levels experienced by children during the injection process, with and without the presence of the Maya robot. Twenty-five children, aged 4 to 9, undergoing cancer treatment participated in this counterbalanced study. The paired T-test results revealed a significant reduction in perceived pain when the robot was actively present in the injection room. The second experiment sought to assess perspectives of hospitalized children and their mothers during engagement with Maya through a game. Forty participants, including 20 children aged 4 to 9 and their mothers, were involved. Post Human-Maya Interactions, UTAUT questionnaire results indicated that children experienced significantly less anxiety than their parents during the interaction and game play. Notably, children exhibited higher trust levels in both the robot and the games, presenting a statistically significant difference in trust levels compared to their parents (P-value < 0.05). This preliminary exploratory study highlights the positive impact of utilizing Maya as an assistant for therapy/education in a clinical setting, particularly benefiting children undergoing cancer treatment. The findings underscore the potential of social robots in pediatric healthcare contexts, emphasizing improved pain management and emotional well-being among young patients.

</details>


### [44] [Developing Neural Network-Based Gaze Control Systems for Social Robots](https://arxiv.org/abs/2602.10946)
*Ramtin Tabatabaei,Alireza Taheri*

Main category: cs.RO

TL;DR: 本研究利用深度学习开发了人类注视行为的运动时间模式，以提高社交机器人在多方互动中的表现，模型在不同动画中的准确率达60%-65%。


<details>
  <summary>Details</summary>
Motivation: 社交机器人需要适当地指引注意力以有效参与多方互动，理解社交背景对于预测人类意图至关重要。

Method: 使用深度神经网络（LSTM和Transformers）分析和预测人类在各种社交场景中的注视模式，并将模型应用于Nao机器人进行评估。

Result: 在2D动画中，模型预测注视方向的准确率为60%，在3D动画中为65%。在将最佳模型应用于Nao机器人后，36名参与者的反馈显示出总体满意度，机器人受过经验的参与者给予了更高的评价。

Conclusion: 在社交互动中，准确预测人类的注视方向能提高社交机器人与人类的互动效果，纳入深度学习技术能够有效捕捉人类的注视行为模式。

Abstract: During multi-party interactions, gaze direction is a key indicator of interest and intent, making it essential for social robots to direct their attention appropriately. Understanding the social context is crucial for robots to engage effectively, predict human intentions, and navigate interactions smoothly. This study aims to develop an empirical motion-time pattern for human gaze behavior in various social situations (e.g., entering, leaving, waving, talking, and pointing) using deep neural networks based on participants' data. We created two video clips-one for a computer screen and another for a virtual reality headset-depicting different social scenarios. Data were collected from 30 participants: 15 using an eye-tracker and 15 using an Oculus Quest 1 headset. Deep learning models, specifically Long Short-Term Memory (LSTM) and Transformers, were used to analyze and predict gaze patterns. Our models achieved 60% accuracy in predicting gaze direction in a 2D animation and 65% accuracy in a 3D animation. Then, the best model was implemented onto the Nao robot; and 36 new participants evaluated its performance. The feedback indicated overall satisfaction, with those experienced in robotics rating the models more favorably.

</details>


### [45] [Stability Analysis of Geometric Control for a Canonical Class of Underactuated Aerial Vehicles with Spurious Forces](https://arxiv.org/abs/2602.10961)
*Simone Orelli,Mirko Mizzoni,Antonio Franchi*

Main category: cs.RO

TL;DR: 本文对漂浮刚体在受虚假力的情况下，提供了首次的正式稳定性分析，证明悬停平衡态的局部指数稳定性，并解决了非最小相行为问题。


<details>
  <summary>Details</summary>
Motivation: 传统几何控制依赖于力矩解耦的假设，但在许多空中平台中，由于控制力矩引起的虚假力使这一假设失效。因此，需要对受虚假力影响的系统进行严格的理论稳定性认证。

Method: 通过构建一个标准模型，并采用基于Lyapunov的方法提供稳定性证明。

Result: 提出了一种针对一般漂浮刚体的第一个正式稳定性分析，解决了应用标准级联论证时面临的结构性挑战。

Conclusion: 本文提供了一种正式的稳定性分析，证明了在受到虚假力影响的漂浮刚体的悬停平衡态是局部指数稳定的。

Abstract: Standard geometric control relies on force-moment decoupling, an assumption that breaks down in many aerial platforms due to spurious forces naturally induced by control moments. While strategies for such coupled systems have been validated experimentally, a rigorous theoretical certification of their stability is currently missing. This work fills this gap by providing the first formal stability analysis for a generic class of floating rigid bodies subject to spurious forces. We introduce a canonical model and construct a Lyapunov-based proof establishing local exponential stability of the hovering equilibrium. Crucially, the analysis explicitly addresses the structural challenges - specifically the induced non-minimum-phase behavior - that prevent the application of standard cascade arguments.

</details>


### [46] [RADAR: Benchmarking Vision-Language-Action Generalization via Real-World Dynamics, Spatial-Physical Intelligence, and Autonomous Evaluation](https://arxiv.org/abs/2602.10980)
*Yuhao Chen,Zhihao Zhan,Xiaoxin Lin,Zijian Song,Hao Liu,Qinhan Lyu,Yubo Zu,Xiao Chen,Zhiyuan Liu,Tao Pu,Tianshui Chen,Keze Wang,Liang Lin,Guangrun Wang*

Main category: cs.RO

TL;DR: 开发RADAR基准来评估VLA模型在真实环境中的表现，揭示现有模型面临的评估不足和脆弱性。


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型评估存在现实差距，影响模型的公平比较与可靠性，亟需改进真实世界的评估方法。

Method: 提出RADAR基准，集成物理动态、空间推理任务和基于3D指标的自动评估流程。

Result: 通过RADAR对多种先进VLA模型进行审计，发现模型在真实物理动态下表现显著下降，空间推理能力有限。

Conclusion: RADAR基准为VLA模型提供了可靠的真实世界评估，揭示了当前模型在现实环境中的脆弱性和有限的空间推理能力。

Abstract: VLA models have achieved remarkable progress in embodied intelligence; however, their evaluation remains largely confined to simulations or highly constrained real-world settings. This mismatch creates a substantial reality gap, where strong benchmark performance often masks poor generalization in diverse physical environments. We identify three systemic shortcomings in current benchmarking practices that hinder fair and reliable model comparison. (1) Existing benchmarks fail to model real-world dynamics, overlooking critical factors such as dynamic object configurations, robot initial states, lighting changes, and sensor noise. (2) Current protocols neglect spatial--physical intelligence, reducing evaluation to rote manipulation tasks that do not probe geometric reasoning. (3) The field lacks scalable fully autonomous evaluation, instead relying on simplistic 2D metrics that miss 3D spatial structure or on human-in-the-loop systems that are costly, biased, and unscalable. To address these limitations, we introduce RADAR (Real-world Autonomous Dynamics And Reasoning), a benchmark designed to systematically evaluate VLA generalization under realistic conditions. RADAR integrates three core components: (1) a principled suite of physical dynamics; (2) dedicated tasks that explicitly test spatial reasoning and physical understanding; and (3) a fully autonomous evaluation pipeline based on 3D metrics, eliminating the need for human supervision. We apply RADAR to audit multiple state-of-the-art VLA models and uncover severe fragility beneath their apparent competence. Performance drops precipitously under modest physical dynamics, with the expectation of 3D IoU declining from 0.261 to 0.068 under sensor noise. Moreover, models exhibit limited spatial reasoning capability. These findings position RADAR as a necessary bench toward reliable and generalizable real-world evaluation of VLA models.

</details>


### [47] [Scaling World Model for Hierarchical Manipulation Policies](https://arxiv.org/abs/2602.10983)
*Qian Long,Yueze Wang,Jiaxi Song,Junbo Zhang,Peiyan Li,Wenxuan Wang,Yuqi Wang,Haoyang Li,Shaoxuan Xie,Guocai Yao,Hanbo Zhang,Xinlong Wang,Zhongyuan Wang,Xuguang Lan,Huaping Liu,Xinghang Li*

Main category: cs.RO

TL;DR: 提出了一种新的层次化视觉-语言-动作框架，通过生成视觉目标，显著提升机器人在外部分布场景中的任务执行能力。


<details>
  <summary>Details</summary>
Motivation: 为了克服在外部分布场景下的泛化瓶颈，特别是在现实机器人数据有限的情况下。

Method: 引入了一个层次化的视觉-语言-动作框架，其中高层的世界模型作为规划者，低层的VLA作为执行者，专注于任务的子目标拆分和动作序列生成。

Result: 在未见物体和新场景中，使用世界模型资指导的情况下，结构相同的VLA性能从14%提升至69%。

Conclusion: 我们的方法在特定的外部分布场景下显著优于以前的基准，且效果提升明显，尤其是使用了世界模型生成的指导后。

Abstract: Vision-Language-Action (VLA) models are promising for generalist robot manipulation but remain brittle in out-of-distribution (OOD) settings, especially with limited real-robot data. To resolve the generalization bottleneck, we introduce a hierarchical Vision-Language-Action framework \our{} that leverages the generalization of large-scale pre-trained world model for robust and generalizable VIsual Subgoal TAsk decomposition VISTA. Our hierarchical framework \our{} consists of a world model as the high-level planner and a VLA as the low-level executor. The high-level world model first divides manipulation tasks into subtask sequences with goal images, and the low-level policy follows the textual and visual guidance to generate action sequences. Compared to raw textual goal specification, these synthesized goal images provide visually and physically grounded details for low-level policies, making it feasible to generalize across unseen objects and novel scenarios. We validate both visual goal synthesis and our hierarchical VLA policies in massive out-of-distribution scenarios, and the performance of the same-structured VLA in novel scenarios could boost from 14% to 69% with the guidance generated by the world model. Results demonstrate that our method outperforms previous baselines with a clear margin, particularly in out-of-distribution scenarios. Project page: \href{https://vista-wm.github.io/}{https://vista-wm.github.io}

</details>


### [48] [Multi-Task Reinforcement Learning of Drone Aerobatics by Exploiting Geometric Symmetries](https://arxiv.org/abs/2602.10997)
*Zhanyu Guo,Zikang Yin,Guobin Zhu,Shiliang Guo,Shiyu Zhao*

Main category: cs.RO

TL;DR: 本文提出了GEAR，一个高效的多任务强化学习框架，通过利用MAV动态的旋转对称性，实现了卓越的特技控制性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统强化学习方法在多任务环境中表现出的数据效率低和泛化能力有限的问题，特别是在需要单一策略掌握多种特技的情况下。

Method: 提出了一个名为GEAR的多任务强化学习框架，采用了几何等变性设计，集成了等变执行者网络、基于FiLM的任务调制和多头评论者。

Result: GEAR在多种特技任务中表现出高效率和灵活性，能够稳定执行多种动作并实现复杂特技的组合。

Conclusion: GEAR框架在多种特技任务中获得了98.85%的成功率，显著超越了基线方法。

Abstract: Flight control for autonomous micro aerial vehicles (MAVs) is evolving from steady flight near equilibrium points toward more aggressive aerobatic maneuvers, such as flips, rolls, and Power Loop. Although reinforcement learning (RL) has shown great potential in these tasks, conventional RL methods often suffer from low data efficiency and limited generalization. This challenge becomes more pronounced in multi-task scenarios where a single policy is required to master multiple maneuvers. In this paper, we propose a novel end-to-end multi-task reinforcement learning framework, called GEAR (Geometric Equivariant Aerobatics Reinforcement), which fully exploits the inherent SO(2) rotational symmetry in MAV dynamics and explicitly incorporates this property into the policy network architecture. By integrating an equivariant actor network, FiLM-based task modulation, and a multi-head critic, GEAR achieves both efficiency and flexibility in learning diverse aerobatic maneuvers, enabling a data-efficient, robust, and unified framework for aerobatic control. GEAR attains a 98.85\% success rate across various aerobatic tasks, significantly outperforming baseline methods. In real-world experiments, GEAR demonstrates stable execution of multiple maneuvers and the capability to combine basic motion primitives to complete complex aerobatics.

</details>


### [49] [ContactGaussian-WM: Learning Physics-Grounded World Model from Videos](https://arxiv.org/abs/2602.11021)
*Meizhong Wang,Wanxin Jin,Kun Cao,Lihua Xie,Yiguang Hong*

Main category: cs.RO

TL;DR: 提出ContactGaussian-WM，一个可微的物理基础的刚体世界模型，能从稀疏视频序列中学习复杂的物理规律，展现出优越的学习和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 在数据稀缺和复杂接触动态运动条件下，现有方法往往难以准确建模，因此需要一种新的框架来提高模型的学习能力和泛化性能。

Method: 提出了一种基于可微物理的刚体世界模型，包括统一的高斯表示和端到端的可微学习框架，通过封闭形式的物理引擎推断物理属性。

Result: 通过广泛的模拟和现实世界评估，ContactGaussian-WM在学习复杂场景方面优于最先进的方法，展示了稳定的泛化能力，且在数据合成和实时MPC等下游应用中具有实用价值。

Conclusion: ContactGaussian-WM在学习复杂场景中表现优于现有方法，具有强大的泛化能力，并在下游应用中展示了实用性。

Abstract: Developing world models that understand complex physical interactions is essential for advancing robotic planning and simulation.However, existing methods often struggle to accurately model the environment under conditions of data scarcity and complex contact-rich dynamic motion.To address these challenges, we propose ContactGaussian-WM, a differentiable physics-grounded rigid-body world model capable of learning intricate physical laws directly from sparse and contact-rich video sequences.Our framework consists of two core components: (1) a unified Gaussian representation for both visual appearance and collision geometry, and (2) an end-to-end differentiable learning framework that differentiates through a closed-form physics engine to infer physical properties from sparse visual observations.Extensive simulations and real-world evaluations demonstrate that ContactGaussian-WM outperforms state-of-the-art methods in learning complex scenarios, exhibiting robust generalization capabilities.Furthermore, we showcase the practical utility of our framework in downstream applications, including data synthesis and real-time MPC.

</details>


### [50] [SQ-CBF: Signed Distance Functions for Numerically Stable Superquadric-Based Safety Filtering](https://arxiv.org/abs/2602.11049)
*Haocheng Zhao,Lukas Brunke,Oliver Lagerquist,Siqi Zhou,Angela P. Schoellig*

Main category: cs.RO

TL;DR: 本研究提出了一种基于有符号距离函数的SQ安全过滤框架，解决了隐式SQ函数的梯度问题，在复杂环境中有效实现无碰撞操作，提升了任务效率。


<details>
  <summary>Details</summary>
Motivation: 在拥挤和动态环境中确保机器人安全操作是一个基本挑战；现有的控制障碍函数在几何表示上过于简化，导致保守行为或碰撞覆盖不足。

Method: 使用有符号距离函数(SDF)作为障碍候选，并通过Gilbert-Johnson-Keerthi算法计算距离，通过随机平滑获得梯度，以形成SQ-based安全过滤框架。

Result: 广泛的仿真和实际实验表明，在复杂和非结构化场景中实现了一致的无碰撞操作，并且对几何、传感噪声和动态干扰具有鲁棒性，同时提高了远程操作任务的效率。

Conclusion: 研究表明，基于SQ的安全过滤框架在复杂环境中保持精确和可靠，提升了任务效率，同时实现了无碰撞操作。

Abstract: Ensuring safe robot operation in cluttered and dynamic environments remains a fundamental challenge. While control barrier functions provide an effective framework for real-time safety filtering, their performance critically depends on the underlying geometric representation, which is often simplified, leading to either overly conservative behavior or insufficient collision coverage. Superquadrics offer an expressive way to model complex shapes using a few primitives and are increasingly used for robot safety. To integrate this representation into collision avoidance, most existing approaches directly use their implicit functions as barrier candidates. However, we identify a critical but overlooked issue in this practice: the gradients of the implicit SQ function can become severely ill-conditioned, potentially rendering the optimization infeasible and undermining reliable real-time safety filtering. To address this issue, we formulate an SQ-based safety filtering framework that uses signed distance functions as barrier candidates. Since analytical SDFs are unavailable for general SQs, we compute distances using the efficient Gilbert-Johnson-Keerthi algorithm and obtain gradients via randomized smoothing. Extensive simulation and real-world experiments demonstrate consistent collision-free manipulation in cluttered and unstructured scenes, showing robustness to challenging geometries, sensing noise, and dynamic disturbances, while improving task efficiency in teleoperation tasks. These results highlight a pathway toward safety filters that remain precise and reliable under the geometric complexity of real-world environments.

</details>


### [51] [RISE: Self-Improving Robot Policy with Compositional World Model](https://arxiv.org/abs/2602.11075)
*Jiazhi Yang,Kunyang Lin,Jinwei Li,Wencong Zhang,Tianwei Lin,Longyan Wu,Zhizhong Su,Hao Zhao,Ya-Qin Zhang,Li Chen,Ping Luo,Xiangyu Yue,Hongyang Li*

Main category: cs.RO

TL;DR: RISE是一个基于想象的机器人强化学习框架，通过复合世界模型提高在动态任务中的鲁棒性，显著提升了不同任务的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管模型容量和数据获取持续提升，但现有的视觉-语言-动作模型在动态操控任务中表现脆弱，需要寻求提高鲁棒性的方法。

Method: 提出了一种可扩展的机器人强化学习框架RISE，核心为复合世界模型，能够预测多视角未来并评估想象的结果。

Result: 在三个具有挑战性的现实任务中，RISE展示了显著的改进，在动态砖块排序中提升超过35%的绝对性能，在背包整理中提升45%，在盒子关闭中提升35%。

Conclusion: RISE框架在处理复杂的动态操作任务中表现出显著的性能提升，能够在虚拟空间中高效地进行自我改进。

Abstract: Despite the sustained scaling on model capacity and data acquisition, Vision-Language-Action (VLA) models remain brittle in contact-rich and dynamic manipulation tasks, where minor execution deviations can compound into failures. While reinforcement learning (RL) offers a principled path to robustness, on-policy RL in the physical world is constrained by safety risk, hardware cost, and environment reset. To bridge this gap, we present RISE, a scalable framework of robotic reinforcement learning via imagination. At its core is a Compositional World Model that (i) predicts multi-view future via a controllable dynamics model, and (ii) evaluates imagined outcomes with a progress value model, producing informative advantages for the policy improvement. Such compositional design allows state and value to be tailored by best-suited yet distinct architectures and objectives. These components are integrated into a closed-loop self-improving pipeline that continuously generates imaginary rollouts, estimates advantages, and updates the policy in imaginary space without costly physical interaction. Across three challenging real-world tasks, RISE yields significant improvement over prior art, with more than +35% absolute performance increase in dynamic brick sorting, +45% for backpack packing, and +35% for box closing, respectively.

</details>


### [52] [Digging for Data: Experiments in Rock Pile Characterization Using Only Proprioceptive Sensing in Excavation](https://arxiv.org/abs/2602.11082)
*Unal Artan,Martin Magnusson,Joshua A. Marshall*

Main category: cs.RO

TL;DR: 本研究提出了一种基于自感知数据的岩石碎片尺寸估计新方法，结果显示其准确性可与传统视觉分析和筛分方法相媲美。


<details>
  <summary>Details</summary>
Motivation: 在采矿和采石行业中，精确估计岩石碎片的大小对于后续处理非常重要。

Method: 使用波形分析从挖掘过程中收集的自感知数据中构建独特特征，进而推测岩石碎片的相对尺寸。

Result: 通过大规模的现场实验，利用波形特征比率有效地估计了不同粒径分布的岩石堆的平均粒径。

Conclusion: 通过基于自感知数据的新的岩石碎片尺寸估计方法，能够有效推测不同岩石堆的相对粒径，并且与传统的视觉分析工具和筛分方法结果一致。

Abstract: Characterization of fragmented rock piles is a fundamental task in the mining and quarrying industries, where rock is fragmented by blasting, transported using wheel loaders, and then sent for further processing. This field report studies a novel method for estimating the relative particle size of fragmented rock piles from only proprioceptive data collected while digging with a wheel loader. Rather than employ exteroceptive sensors (e.g., cameras or LiDAR sensors) to estimate rock particle sizes, the studied method infers rock fragmentation from an excavator's inertial response during excavation. This paper expands on research that postulated the use of wavelet analysis to construct a unique feature that is proportional to the level of rock fragmentation. We demonstrate through extensive field experiments that the ratio of wavelet features, constructed from data obtained by excavating in different rock piles with different size distributions, approximates the ratio of the mean particle size of the two rock piles. Full-scale excavation experiments were performed with a battery electric, 18-tonne capacity, load-haul-dump (LHD) machine in representative conditions in an operating quarry. The relative particle size estimates generated with the proposed sensing methodology are compared with those obtained from both a vision-based fragmentation analysis tool and from sieving of sampled materials.

</details>


### [53] [A receding-horizon multi-contact motion planner for legged robots in challenging environments](https://arxiv.org/abs/2602.11113)
*Daniel S. J. Derwent,Simon Watson,Bruno V. Adorno*

Main category: cs.RO

TL;DR: 本研究提出了一种新颖的腿部机器人运动规划方法，能有效处理复杂场景，再规划能力强，性能在多方面优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 为了解决腿部机器人在复杂场景中运动规划的挑战，提高运动规划的效率和质量。

Method: 使用一种新颖的递归地平线多接触运动规划方法，同时规划接触位置和全身轨迹，并进行反应式再规划。

Result: 提出的方法在短规划地平线下比现有方法更快，且在某些情况下能规划出质量更高的运动方案，但较长的规划地平线在速度上可能会降低。

Conclusion: 本研究提出的运动规划方法在多接触运动和再规划中展现出显著的优势，尤其在高效性和运动质量方面具有更好的表现。

Abstract: We present a novel receding-horizon multi-contact motion planner for legged robots in challenging scenarios, able to plan motions such as chimney climbing, navigating very narrow passages or crossing large gaps. Our approach adds new capabilities to the state of the art, including the ability to reactively re-plan in response to new information, and planning contact locations and whole-body trajectories simultaneously, simplifying the implementation and removing the need for post-processing or complex multi-stage approaches. Our method is more resistant to local minima problems than other potential field based approaches, and our quadratic-program-based posture generator returns nodes more quickly than those of existing algorithms. Rigorous statistical analysis shows that, with short planning horizons (e.g., one step ahead), our planner is faster than the state-of-the-art across all scenarios tested (between 45% and 98% faster on average, depending on the scenario), while planning less efficient motions (requiring 5% fewer to 700% more stance changes on average). In all but one scenario (Chimney Walking), longer planning horizons (e.g., four steps ahead) extended the average planning times (between 73% faster and 400% slower than the state-of-the-art) but resulted in higher quality motion plans (between 8% more and 47% fewer stance changes than the state-of-the-art).

</details>


### [54] [Data-Efficient Hierarchical Goal-Conditioned Reinforcement Learning via Normalizing Flows](https://arxiv.org/abs/2602.11142)
*Shaswat Garg,Matin Moezzi,Brandon Da Silva*

Main category: cs.RO

TL;DR: NF-HIQL通过归一化流政策提高了层次目标条件强化学习的效果，展示了在数据有限的情况下的优越性能。


<details>
  <summary>Details</summary>
Motivation: 针对层次目标条件强化学习在数据效率和政策表达力方面的缺陷，提出了一种更有效的框架。

Method: 提出了一种基于归一化流的层次隐式Q学习框架，使用流动政策代替传统的高斯政策，增强了策略的表达能力。

Result: NF-HIQL在多种长期任务中表现优异， consistently outperformed previous baselines in robustness and efficiency under data-scarce conditions。

Conclusion: NF-HIQL展示了在复杂任务中优越的鲁棒性和数据效率，超越了以往的基线，表明归纳流架构在层次强化学习中的潜力。

Abstract: Hierarchical goal-conditioned reinforcement learning (H-GCRL) provides a powerful framework for tackling complex, long-horizon tasks by decomposing them into structured subgoals. However, its practical adoption is hindered by poor data efficiency and limited policy expressivity, especially in offline or data-scarce regimes. In this work, Normalizing flow-based hierarchical implicit Q-learning (NF-HIQL), a novel framework that replaces unimodal gaussian policies with expressive normalizing flow policies at both the high- and low-levels of the hierarchy is introduced. This design enables tractable log-likelihood computation, efficient sampling, and the ability to model rich multimodal behaviors. New theoretical guarantees are derived, including explicit KL-divergence bounds for Real-valued non-volume preserving (RealNVP) policies and PAC-style sample efficiency results, showing that NF-HIQL preserves stability while improving generalization. Empirically, NF-HIQL is evaluted across diverse long-horizon tasks in locomotion, ball-dribbling, and multi-step manipulation from OGBench. NF-HIQL consistently outperforms prior goal-conditioned and hierarchical baselines, demonstrating superior robustness under limited data and highlighting the potential of flow-based architectures for scalable, data-efficient hierarchical reinforcement learning.

</details>


### [55] [APEX: Learning Adaptive High-Platform Traversal for Humanoid Robots](https://arxiv.org/abs/2602.11143)
*Yikai Wang,Tingxuan Leng,Changyi Lin,Shiqi Liu,Shir Simon,Bingqing Chen,Jonathan Francis,Ding Zhao*

Main category: cs.RO

TL;DR: 提出APEX系统，通过攀爬行为训练人形机器人，实现对高平台的安全、自主遍历。


<details>
  <summary>Details</summary>
Motivation: 由于现有的RL训练方法往往收敛到高冲击的跳跃解决方案，安全性不足，我们希望提供一种能够适应更高平台并提高安全性的解决方案。

Method: 我们提出了一种基于地形条件的行为组合训练方法，包括攀爬、走动和姿态重配置，通过通用的进度奖励机制来学习接触丰富的动作。

Result: 通过双重策略减少了模拟与真实环境之间的感知差距，并在 29 自由度的人形机器人上实现了对 0.8 米高度平台的零-shot遍历。

Conclusion: 我们的系统APEX能够实现零-shot的真实环境中人形步态的操作，适应不同平台高度和起始姿态，并顺利地实现多技能的过渡。

Abstract: Humanoid locomotion has advanced rapidly with deep reinforcement learning (DRL), enabling robust feet-based traversal over uneven terrain. Yet platforms beyond leg length remain largely out of reach because current RL training paradigms often converge to jumping-like solutions that are high-impact, torque-limited, and unsafe for real-world deployment. To address this gap, we propose APEX, a system for perceptive, climbing-based high-platform traversal that composes terrain-conditioned behaviors: climb-up and climb-down at vertical edges, walking or crawling on the platform, and stand-up and lie-down for posture reconfiguration. Central to our approach is a generalized ratchet progress reward for learning contact-rich, goal-reaching maneuvers. It tracks the best-so-far task progress and penalizes non-improving steps, providing dense yet velocity-free supervision that enables efficient exploration under strong safety regularization. Based on this formulation, we train LiDAR-based full-body maneuver policies and reduce the sim-to-real perception gap through a dual strategy: modeling mapping artifacts during training and applying filtering and inpainting to elevation maps during deployment. Finally, we distill all six skills into a single policy that autonomously selects behaviors and transitions based on local geometry and commands. Experiments on a 29-DoF Unitree G1 humanoid demonstrate zero-shot sim-to-real traversal of 0.8 meter platforms (approximately 114% of leg length), with robust adaptation to platform height and initial pose, as well as smooth and stable multi-skill transitions.

</details>


### [56] [YOR: Your Own Mobile Manipulator for Generalizable Robotics](https://arxiv.org/abs/2602.11150)
*Manan H Anjaria,Mehmet Enes Erciyes,Vedant Ghatnekar,Neha Navarkar,Haritheja Etukuru,Xiaole Jiang,Kanad Patel,Dhawal Kabra,Nicholas Wojno,Radhika Ajay Prayage,Soumith Chintala,Lerrel Pinto,Nur Muhammad Mahi Shafiullah,Zichen Jeff Cui*

Main category: cs.RO

TL;DR: YOR是一款成本低、易组装的开源移动操控机器人，具备竞争性能，适合研究。


<details>
  <summary>Details</summary>
Motivation: 由于机器人学习的进展和驱动器的商品化推动了低成本机器人平台的发展，但移动操控的最佳形式仍然不确定。

Method: 设计一种集成全方向底盘、 telescopic vertical lift 和双手夹持器的模块化机器人，利用现成组件构建，确保易于组装和维护。

Result: YOR能够完成需要协调全身控制、双手操作和自主导航的任务，展示了其在机器人操控研究中的竞争能力。

Conclusion: YOR是一款低成本、开源的移动操控机器人，能够以较低的成本实现多种功能，适合移动操控研究。

Abstract: Recent advances in robot learning have generated significant interest in capable platforms that may eventually approach human-level competence. This interest, combined with the commoditization of actuators, has propelled growth in low-cost robotic platforms. However, the optimal form factor for mobile manipulation, especially on a budget, remains an open question. We introduce YOR, an open-source, low-cost mobile manipulator that integrates an omnidirectional base, a telescopic vertical lift, and two arms with grippers to achieve whole-body mobility and manipulation. Our design emphasizes modularity, ease of assembly using off-the-shelf components, and affordability, with a bill-of-materials cost under 10,000 USD. We demonstrate YOR's capability by completing tasks that require coordinated whole-body control, bimanual manipulation, and autonomous navigation. Overall, YOR offers competitive functionality for mobile manipulation research at a fraction of the cost of existing platforms. Project website: https://www.yourownrobot.ai/

</details>
