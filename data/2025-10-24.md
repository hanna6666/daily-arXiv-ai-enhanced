<div id=toc></div>

# Table of Contents

- [cs.HC](#cs.HC) [Total: 5]
- [cs.RO](#cs.RO) [Total: 28]


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [1] [Beyond One-Way Influence: Bidirectional Opinion Dynamics in Multi-Turn Human-LLM Interactions](https://arxiv.org/abs/2510.20039)
*Yuyang Jiang,Longjie Guo,Yuchen Wu,Aylin Caliskan,Tanu Mitra,Hua Shen*

Main category: cs.HC

TL;DR: 研究表明，用户意见变化微乎其微，而LLM输出则变化显著；个性化设计可以增强双向影响，需谨慎设计以避免过度对齐。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型（LLM）聊天机器人的双向影响，尤其是用户输入如何影响LLM的响应，至今研究较少。

Method: 通过对266名参与者进行50场有争议话题的多轮讨论，比较静态陈述、标准聊天机器人和个性化聊天机器人的效果。

Result: 在人类观点变化不大的情况下，LLM的输出发生了更大程度的变化，个性化设置放大了这种变化。

Conclusion: 在与LLM交互时，过度的对齐存在风险，个性化聊天机器人需更谨慎设计以稳定与用户的对齐。

Abstract: Large language model (LLM)-powered chatbots are increasingly used for opinion
exploration. Prior research examined how LLMs alter user views, yet little work
extended beyond one-way influence to address how user input can affect LLM
responses and how such bi-directional influence manifests throughout the
multi-turn conversations. This study investigates this dynamic through 50
controversial-topic discussions with participants (N=266) across three
conditions: static statements, standard chatbot, and personalized chatbot.
Results show that human opinions barely shifted, while LLM outputs changed more
substantially, narrowing the gap between human and LLM stance. Personalization
amplified these shifts in both directions compared to the standard setting.
Analysis of multi-turn conversations further revealed that exchanges involving
participants' personal stories were most likely to trigger stance changes for
both humans and LLMs. Our work highlights the risk of over-alignment in
human-LLM interaction and the need for careful design of personalized chatbots
to more thoughtfully and stably align with users.

</details>


### [2] ["Learning Together": AI-Mediated Support for Parental Involvement in Everyday Learning](https://arxiv.org/abs/2510.20123)
*Yao Li,Jingyi Xie,Ya-Fang Ling,He Zhang,Ge Wang,Gaojian Huang,Rui Yu,Si Chen*

Main category: cs.HC

TL;DR: 本研究展示了AI如何通过FamLearn原型促进家庭学习，减轻照护负担并增强共享学习体验。


<details>
  <summary>Details</summary>
Motivation: 探讨人工智能如何在家庭教育中促进合作，解决协调、工作不均和家长调解等问题

Method: 通过形成性研究和原型设计

Result: 设计并测试FamLearn原型，展示其在任务分配、贡献可视化与个性化支持方面的有效性

Conclusion: LLMs可以超越家庭教育中的导师角色，作为家庭协作的中介，平衡责任、促进代际参与，并增强家庭学习的关系结构。

Abstract: Family learning takes place in everyday routines where children and
caregivers read, practice, and develop new skills together. Although AI is
increasingly present in learning environments, most systems remain
child-centered and overlook the collaborative, distributed nature of family
education. This paper investigates how AI can mediate family collaboration by
addressing tensions of coordination, uneven workloads, and parental mediation.
From a formative study with families using AI in daily learning, we identified
challenges in responsibility sharing and recognition of contributions. Building
on these insights, we designed FamLearn, an LLM-powered prototype that
distributes tasks, visualizes contributions, and provides individualized
support. A one-week field study with 11 families shows how this prototype can
ease caregiving burdens, foster recognition, and enrich shared learning
experiences. Our findings suggest that LLMs can move beyond the role of tutor
to act as family mediators - balancing responsibilities, scaffolding
intergenerational participation, and strengthening the relational fabric of
family learning.

</details>


### [3] [Designing Intent Communication for Agent-Human Collaboration](https://arxiv.org/abs/2510.20409)
*Yi Li,Francesco Chiossi,Helena Anna Frijns,Jan Leusmann,Julian Rasch,Robin Welsch,Philipp Wintersberger,Florian Michahelles,Albrecht Schmidt*

Main category: cs.HC

TL;DR: 提出了一种多维设计空间，用于自主代理的意图沟通，旨在提升人机互动的安全性与适应性。


<details>
  <summary>Details</summary>
Motivation: 由于现有意图沟通方法的局限性，急需一种适应性更强的沟通策略，以增强人类对自主代理意图的理解。

Method: 介绍了一个包括透明度、抽象度和表现形式三个维度的意图沟通设计空间，并应用于三种人机协作场景。

Result: 通过应用设计空间于多种协作场景，展示了其生成适应性强、可扩展和跨领域沟通策略的能力。

Conclusion: 该设计空间为自主代理与人类的互动设计提供了基础，以实现更安全和直观的沟通策略。

Abstract: As autonomous agents, from self-driving cars to virtual assistants, become
increasingly present in everyday life, safe and effective collaboration depends
on human understanding of agents' intentions. Current intent communication
approaches are often rigid, agent-specific, and narrowly scoped, limiting their
adaptability across tasks, environments, and user preferences. A key gap
remains: existing models of what to communicate are rarely linked to systematic
choices of how and when to communicate, preventing the development of
generalizable, multi-modal strategies. In this paper, we introduce a
multidimensional design space for intent communication structured along three
dimensions: Transparency (what is communicated), Abstraction (when), and
Modality (how). We apply this design space to three distinct human-agent
collaboration scenarios: (a) bystander interaction, (b) cooperative tasks, and
(c) shared control, demonstrating its capacity to generate adaptable, scalable,
and cross-domain communication strategies. By bridging the gap between intent
content and communication implementation, our design space provides a
foundation for designing safer, more intuitive, and more transferable
agent-human interactions.

</details>


### [4] [Optimizing Feature Ordering in Radar Charts for Multi-Profile Comparison](https://arxiv.org/abs/2510.20738)
*Albert Dorador*

Main category: cs.HC

TL;DR: 本文提出了一种置换优化策略，以提高雷达图在多变量数据可视化中的清晰度，重点解决特征值幅度差异导致的图形扭曲问题。


<details>
  <summary>Details</summary>
Motivation: 雷达图在可视化多变量数据时常因特征幅度差异导致清晰度下降，本研究旨在改善这一问题。

Method: 采用组合优化策略，通过全面搜索和字典最小化准则对特征进行重新排序，以减小多轮廓的多边形“尖锐度”。

Result: 通过优化特征顺序，成功实现了视觉平衡，并展示了雷达图在特定示例中的显著改善。

Conclusion: 通过改进特征排序，可以显著提高雷达图的视觉平衡性，从而更准确地表示多种特征的相对差异。

Abstract: Radar charts are widely used to visualize multivariate data and compare
multiple profiles across features. However, the visual clarity of radar charts
can be severely compromised when feature values alternate drastically in
magnitude around the circle, causing areas to collapse, which misrepresents
relative differences. In the present work we introduce a permutation
optimization strategy that reorders features to minimize polygon ``spikiness''
across multiple profiles simultaneously. The method is combinatorial
(exhaustive search) for moderate numbers of features and uses a lexicographic
minimax criterion that first considers overall smoothness (mean jump) and then
the largest single jump as a tie-breaker. This preserves more global
information and produces visually balanced arrangements. We discuss complexity,
practical bounds, and relations to existing approaches that either change the
visualization (e.g., OrigamiPlot) or learn orderings (e.g., Versatile Ordering
Network). An example with two profiles and $p=6$ features (before/after
ordering) illustrates the qualitative improvement.
  Keywords: data visualization, radar charts, combinatorial optimization,
minimax optimization, feature ordering

</details>


### [5] [Empathic Prompting: Non-Verbal Context Integration for Multimodal LLM Conversations](https://arxiv.org/abs/2510.20743)
*Lorenzo Stacchio,Andrea Ubaldi,Alessandro Galdelli,Maurizio Mauri,Emanuele Frontoni,Andrea Gaggioli*

Main category: cs.HC

TL;DR: 同理心提示是一个新框架，利用非 verbal 情绪线索增强 LLM 对话，适用于医疗和教育等领域。


<details>
  <summary>Details</summary>
Motivation: 提高大型语言模型对话的丰富性和连贯性，特别是对于情感内容的处理能力。

Method: 通过集成面部表情识别服务来捕捉和利用用户的情感线索，构建流畅的对话系统。

Result: 本研究提出了一种新颖的多模态人机交互框架——同理心提示，它通过隐含的非语言上下文丰富大型语言模型（LLM）对话。系统集成了一种商业面部表情识别服务，以捕捉用户的情感线索，并将这些线索嵌入提示的上下文中。与传统的多模态接口不同，同理心提示不需要用户明确控制，而是自然而然地将情感信息融入文本输入中，以实现对话的流畅性和一致性。架构是模块化和可扩展的，允许集成其他非语言模块。我们描述了通过本地部署DeepSeek实例实现的系统设计，并报告了一项初步的服务和可用性评估（N=5）。结果显示，在一致的非语言输入与连贯的LLM输出之间实现了一致集成，而参与者强调了对话的流畅性。除了作为概念验证外，同理心提示还指向了在机器人媒介沟通中的应用，特别是在医疗或教育等领域，在这些领域中，用户的情感信号至关重要，但在口头交流中往往是隐蔽的。

Conclusion: 同理心提示为多模态人机交互提供了新的思路，尤其在需要关注用户情感的领域。

Abstract: We present Empathic Prompting, a novel framework for multimodal human-AI
interaction that enriches Large Language Model (LLM) conversations with
implicit non-verbal context. The system integrates a commercial facial
expression recognition service to capture users' emotional cues and embeds them
as contextual signals during prompting. Unlike traditional multimodal
interfaces, empathic prompting requires no explicit user control; instead, it
unobtrusively augments textual input with affective information for
conversational and smoothness alignment. The architecture is modular and
scalable, allowing integration of additional non-verbal modules. We describe
the system design, implemented through a locally deployed DeepSeek instance,
and report a preliminary service and usability evaluation (N=5). Results show
consistent integration of non-verbal input into coherent LLM outputs, with
participants highlighting conversational fluidity. Beyond this proof of
concept, empathic prompting points to applications in chatbot-mediated
communication, particularly in domains like healthcare or education, where
users' emotional signals are critical yet often opaque in verbal exchanges.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [6] [Configuration-Dependent Robot Kinematics Model and Calibration](https://arxiv.org/abs/2510.19962)
*Chen-Lung Lu,Honglu He,Agung Julius,John T. Wen*

Main category: cs.RO

TL;DR: 本文提出一种配置依赖的运动学标定框架，利用FOurier基函数插值，提高了机器人在整个工作空间的精度。


<details>
  <summary>Details</summary>
Motivation: 提高手爪机器人在各种配置下的运动学精度，以降低配置依赖性引起的模型误差。

Method: 采用局部指数积模型，通过傅里叶基函数插值，实现对肩部和肘部角度的参数化，训练效率高。

Result: 提出了一种基于配置的运动学标定框架，通过局部的指数积模型在多个配置中进行识别和插值，提升了整个工作空间的精度。

Conclusion: 该框架能有效减少机器人最大定位误差，尤其对配置依赖性较大的机器人效果显著，符合工业应用精度要求。

Abstract: Accurate robot kinematics is essential for precise tool placement in
articulated robots, but non-geometric factors can introduce
configuration-dependent model discrepancies. This paper presents a
configuration-dependent kinematic calibration framework for improving accuracy
across the entire workspace. Local Product-of-Exponential (POE) models,
selected for their parameterization continuity, are identified at multiple
configurations and interpolated into a global model. Inspired by joint gravity
load expressions, we employ Fourier basis function interpolation parameterized
by the shoulder and elbow joint angles, achieving accuracy comparable to neural
network and autoencoder methods but with substantially higher training
efficiency. Validation on two 6-DoF industrial robots shows that the proposed
approach reduces the maximum positioning error by over 50%, meeting the
sub-millimeter accuracy required for cold spray manufacturing. Robots with
larger configuration-dependent discrepancies benefit even more. A dual-robot
collaborative task demonstrates the framework's practical applicability and
repeatability.

</details>


### [7] [Push Anything: Single- and Multi-Object Pushing From First Sight with Contact-Implicit MPC](https://arxiv.org/abs/2510.19974)
*Hien Bui,Yufeiyang Gao,Haoran Yang,Eric Cui,Siddhant Mody,Brian Acosta,Thomas Stephen Felix,Bibit Bianchini,Michael Posa*

Main category: cs.RO

TL;DR: C3+算法显示了在多样化物体操控中的高效能，成功率达到98%，并且在实时推送任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 面对众多未知物体物理特性和复杂的接触交互，传统的非抓取操作方法面临重大挑战，因此需要开发更为先进的控制算法。

Method: 引入了一种增强的CI-MPC算法C3+，集成了对象扫描、网格重建和硬件执行的完整流程。

Result: C3+在33个物体上实现了98%的成功率，任务完成时间依次为0.5、1.6、3.2和5.3分钟，取决于对象的数量。

Conclusion: C3+算法在多对象推送任务中展示了高效的实时性能和98%的成功率，表明其在非抓取操作中的有效性和广泛适用性。

Abstract: Non-prehensile manipulation of diverse objects remains a core challenge in
robotics, driven by unknown physical properties and the complexity of
contact-rich interactions. Recent advances in contact-implicit model predictive
control (CI-MPC), with contact reasoning embedded directly in the trajectory
optimization, have shown promise in tackling the task efficiently and robustly,
yet demonstrations have been limited to narrowly curated examples. In this
work, we showcase the broader capabilities of CI-MPC through precise planar
pushing tasks over a wide range of object geometries, including multi-object
domains. These scenarios demand reasoning over numerous inter-object and
object-environment contacts to strategically manipulate and de-clutter the
environment, challenges that were intractable for prior CI-MPC methods. To
achieve this, we introduce Consensus Complementarity Control Plus (C3+), an
enhanced CI-MPC algorithm integrated into a complete pipeline spanning object
scanning, mesh reconstruction, and hardware execution. Compared to its
predecessor C3, C3+ achieves substantially faster solve times, enabling
real-time performance even in multi-object pushing tasks. On hardware, our
system achieves overall 98% success rate across 33 objects, reaching pose goals
within tight tolerances. The average time-to-goal is approximately 0.5, 1.6,
3.2, and 5.3 minutes for 1-, 2-, 3-, and 4-object tasks, respectively. Project
page: https://dairlab.github.io/push-anything.

</details>


### [8] [FieldGen: From Teleoperated Pre-Manipulation Trajectories to Field-Guided Data Generation](https://arxiv.org/abs/2510.20774)
*Wenhao Wang,Kehe Ye,Xinyu Zhou,Tianxing Chen,Cao Min,Qiaoming Zhu,Xiaokang Yang,Yongjian Shen,Yang Yang,Maoqing Yao,Yao Mu*

Main category: cs.RO

TL;DR: FieldGen是一个井指导的数据生成框架，通过将操作分为预操作和细操作两个阶段，实现在数据收集方面的规模化、多样化和高质量。


<details>
  <summary>Details</summary>
Motivation: 在训练强大的机器人操作政策时，大规模和多样化的数据集至关重要，但现有的数据收集方法难以平衡规模、多样性和质量。

Method: FieldGen将操作分解为预操作阶段和细操作阶段，通过人类示范捕获关键信息，然后利用吸引场自动生成多样化的轨迹。

Result: FieldGen框架能够在最小人力监督下实现规模化、多样化和高质量的现实数据收集。

Conclusion: FieldGen训练出的政策在成功率和稳定性方面优于基于远程操作的基准，同时显著减少了长期实际数据收集中的人力投入。

Abstract: Large-scale and diverse datasets are vital for training robust robotic
manipulation policies, yet existing data collection methods struggle to balance
scale, diversity, and quality. Simulation offers scalability but suffers from
sim-to-real gaps, while teleoperation yields high-quality demonstrations with
limited diversity and high labor cost. We introduce FieldGen, a field-guided
data generation framework that enables scalable, diverse, and high-quality
real-world data collection with minimal human supervision. FieldGen decomposes
manipulation into two stages: a pre-manipulation phase, allowing trajectory
diversity, and a fine manipulation phase requiring expert precision. Human
demonstrations capture key contact and pose information, after which an
attraction field automatically generates diverse trajectories converging to
successful configurations. This decoupled design combines scalable trajectory
diversity with precise supervision. Moreover, FieldGen-Reward augments
generated data with reward annotations to further enhance policy learning.
Experiments demonstrate that policies trained with FieldGen achieve higher
success rates and improved stability compared to teleoperation-based baselines,
while significantly reducing human effort in long-term real-world data
collection. Webpage is available at https://fieldgen.github.io/.

</details>


### [9] [Simultaneous learning of state-to-state minimum-time planning and control](https://arxiv.org/abs/2510.20008)
*Swati Dantu,Robert Pěnička,Martin Saska*

Main category: cs.RO

TL;DR: 研究一种通用的无人机最短时间飞行策略，利用强化学习提升飞行灵活性与稳定性，实验证明了该策略在真实环境中的有效性。


<details>
  <summary>Details</summary>
Motivation: 传统无人机自主飞行方法受限于预设赛道，缺乏在实际环境中广泛适用的能力，因此需要一种新的通用飞行策略。

Method: 采用基于强化学习的框架，结合点质量模型（PMM）轨迹作为代理奖励，通过课程学习提升训练效率，针对状态到状态的最小时间规划与控制进行学习。

Result: 通过模拟实验和实地测试，验证了所提方法在复杂环境中的稳健性及其在小型单板计算机上的可操作性。

Conclusion: 该研究提出的策略在复杂环境中表现出色，展示了良好的适应性和可推广性。

Abstract: This paper tackles the challenge of learning a generalizable minimum-time
flight policy for UAVs, capable of navigating between arbitrary start and goal
states while balancing agile flight and stable hovering. Traditional
approaches, particularly in autonomous drone racing, achieve impressive speeds
and agility but are constrained to predefined track layouts, limiting
real-world applicability. To address this, we propose a reinforcement
learning-based framework that simultaneously learns state-to-state minimum-time
planning and control and generalizes to arbitrary state-to-state flights. Our
approach leverages Point Mass Model (PMM) trajectories as proxy rewards to
approximate the true optimal flight objective and employs curriculum learning
to scale the training process efficiently and to achieve generalization. We
validate our method through simulation experiments, comparing it against
Nonlinear Model Predictive Control (NMPC) tracking PMM-generated trajectories
and conducting ablation studies to assess the impact of curriculum learning.
Finally, real-world experiments confirm the robustness of our learned policy in
outdoor environments, demonstrating its ability to generalize and operate on a
small ARM-based single-board computer.

</details>


### [10] [Calibration of Parallel Kinematic Machine Based on Stewart Platform-A Literature Review](https://arxiv.org/abs/2510.20070)
*Sourabh Karmakar,Apurva Patel,Cameron J. Turner*

Main category: cs.RO

TL;DR: 本研究回顾了并行运动机的逆向运动学校准方法及其准确性的提升，特别关注误差来源。


<details>
  <summary>Details</summary>
Motivation: 由于并行运动机在医药、工程及航空等领域的潜在应用，提升其在三维空间的微米和纳米尺度运动控制的准确性成为必要。

Method: 通过回顾现有的外部仪器基、约束基与自我校准的方法，分析不同的校准技术及其结果。

Result: 研究发现，提升平台位置和方向精度的校准主要集中在单一或多重误差源上，尽管环境因素有时也被考虑，但校准通常在无负载条件下进行。

Conclusion: 本研究旨在梳理并理解并行运动机的校准方法，特别是逆向运动学方法的应用，以提升平台位置和姿态的精度。

Abstract: Stewart platform-based Parallel Kinematic (PKM) Machines have been
extensively studied by researchers due to their inherent finer control
characteristics. This has opened its potential deployment opportunities in
versatile critical applications like the medical field, engineering machines,
space research, electronic chip manufacturing, automobile manufacturing, etc.
All these precise, complicated, and repeatable motion applications require
micro and nano-scale movement control in 3D space; a 6-DOF PKM can take this
challenge smartly. For this, the PKM must be more accurate than the desired
application accuracy level and thus proper calibration for a PKM robot is
essential. Forward kinematics-based calibration for such hexapod machines
becomes unnecessarily complex and inverse kinematics complete this task with
much ease. To analyze different techniques, an external instrument-based,
constraint-based, and auto or self-calibration-based approaches have been used
for calibration. This survey has been done by reviewing these key
methodologies, their outcome, and important points related to inverse
kinematic-based PKM calibrations in general. It is observed in this study that
the researchers focused on improving the accuracy of the platform position and
orientation considering the errors contributed by a single source or multiple
sources. The error sources considered are mainly structural, in some cases,
environmental factors are also considered, however, these calibrations are done
under no-load conditions. This study aims to understand the current state of
the art in this field and to expand the scope for other researchers in further
exploration in a specific area.

</details>


### [11] [Design of a Bed Rotation Mechanism to Facilitate In-Situ Photogrammetric Reconstruction of Printed Parts](https://arxiv.org/abs/2510.20079)
*Travis A. Roberts,Sourabh Karmakar,Cameron J. Turner*

Main category: cs.RO

TL;DR: 该论文提出了一种新型的聚合物FDM测试平台，旨在通过改进的加热床旋转机制，实现低成本的光测量重建，增强实验的精确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 针对商用和消费级3D打印机在灵活性和可修改性方面的不足，旨在提供一个可重复实验的高精度FDM平台。

Method: 设计并制造了一种测试平台，采用闭环位置反馈、热端和床温度控制，以及对环境温度和湿度的监测。

Result: 构建了一个能够监测FDM构建参数并与几何缺陷关联的系统，提升了实验的可重复性和准确性。

Conclusion: 该论文设计了一种用于研究聚合物FDM过程的测试平台，重点在于通过新颖的加热床旋转机制以较少的相机实现光测量重建。

Abstract: Additive manufacturing, or 3D printing, is a complex process that creates
free-form geometric objects by sequentially placing material to construct an
object, usually in a layer-by-layer process. One of the most widely used
methods is Fused Deposition Modeling (FDM). FDM is used in many of the
consumer-grade polymer 3D printers available today. While consumer grade
machines are cheap and plentiful, they lack many of the features desired in a
machine used for research purposes and are often closed-source platforms.
Commercial-grade models are more expensive and are also usually closed-source
platforms that do not offer flexibility for modifications often needed for
research. The authors designed and fabricated a machine to be used as a test
bed for research in the field of polymer FDM processes. The goal was to create
a platform that tightly controls and/or monitors the FDM build parameters so
that experiments can be repeated with a known accuracy. The platform offers
closed loop position feedback, control of the hot end and bed temperature, and
monitoring of environment temperature and humidity. Additionally, the platform
is equipped with cameras and a mechanism for in-situ photogrammetry, creating a
geometric record of the printing throughout the printing process. Through
photogrammetry, backtracking and linking process parameters to observable
geometric defects can be achieved. This paper focuses on the design of a novel
mechanism for spinning the heated bed to allow for photogrammetric
reconstruction of the printed part using a minimal number of cameras, as
implemented on this platform.

</details>


### [12] [PathFormer: A Transformer with 3D Grid Constraints for Digital Twin Robot-Arm Trajectory Generation](https://arxiv.org/abs/2510.20161)
*Ahmed Alanazi,Duy Ho,Yugyung Lee*

Main category: cs.RO

TL;DR: 我们提出了一种新的Path-based Transformer模型，能够高效解码机器人轨迹，并在多个测试中展现出极高的准确性和成功率。


<details>
  <summary>Details</summary>
Motivation: 机器人手臂需要精确且具有任务意识的轨迹规划，然而忽略运动结构的序列模型往往会导致无效或低效的执行。

Method: 通过约束掩码解码，确保相邻移动和工作空间限制，同时考虑任务图和动作顺序，模型在53,755条轨迹上进行训练.

Result: 提出了一种基于路径的Transformer模型，能够通过3-grid（位置/任务/时间）表示法编码机器人运动。

Conclusion: 路径结构化表示使得Transformer能够生成准确、可靠且可解释的机器人轨迹，促进图基规划与序列学习的结合。

Abstract: Robotic arms require precise, task-aware trajectory planning, yet sequence
models that ignore motion structure often yield invalid or inefficient
executions. We present a Path-based Transformer that encodes robot motion with
a 3-grid (where/what/when) representation and constraint-masked decoding,
enforcing lattice-adjacent moves and workspace bounds while reasoning over task
graphs and action order. Trained on 53,755 trajectories (80% train / 20%
validation), the model aligns closely with ground truth -- 89.44% stepwise
accuracy, 93.32% precision, 89.44% recall, and 90.40% F1 -- with 99.99% of
paths legal by construction. Compiled to motor primitives on an xArm Lite 6
with a depth-camera digital twin, it attains up to 97.5% reach and 92.5% pick
success in controlled tests, and 86.7% end-to-end success across 60
language-specified tasks in cluttered scenes, absorbing slips and occlusions
via local re-grounding without global re-planning. These results show that
path-structured representations enable Transformers to generate accurate,
reliable, and interpretable robot trajectories, bridging graph-based planning
and sequence-based learning and providing a practical foundation for
general-purpose manipulation and sim-to-real transfer.

</details>


### [13] [Reinforcement Learning-based Robust Wall Climbing Locomotion Controller in Ferromagnetic Environment](https://arxiv.org/abs/2510.20174)
*Yong Um,Young-Ha Shin,Joon-Ha Kim,Soonpyo Kwon,Hae-Won Park*

Main category: cs.RO

TL;DR: 本文开发了一种增强学习框架，帮助四足机器人在不确定的磁性附着下完成爬行任务，表现出良好的稳定性和恢复能力。


<details>
  <summary>Details</summary>
Motivation: 解决四足机器人在磁性附着下的运动不确定性问题，提升其在复杂环境中的爬行能力。

Method: 采用三阶段课程学习，首先训练在平坦地面上爬行，接着在垂直面上激活附着模型，最后注入随机的附着失败以增强恢复能力。

Result: 提出了一种增强学习框架，结合物理基础的附着模型，通过逐步学习和注入随机性，提高了机器人在垂直面上的稳定性和恢复能力。

Conclusion: 结合课程学习和现实附着建模的方法，为复杂环境中的磁性爬行机器人提供了一种稳健的仿真到现实的框架。

Abstract: We present a reinforcement learning framework for quadrupedal wall-climbing
locomotion that explicitly addresses uncertainty in magnetic foot adhesion. A
physics-based adhesion model of a quadrupedal magnetic climbing robot is
incorporated into simulation to capture partial contact, air-gap sensitivity,
and probabilistic attachment failures. To stabilize learning and enable
reliable transfer, we design a three-phase curriculum: (1) acquire a crawl gait
on flat ground without adhesion, (2) gradually rotate the gravity vector to
vertical while activating the adhesion model, and (3) inject stochastic
adhesion failures to encourage slip recovery. The learned policy achieves a
high success rate, strong adhesion retention, and rapid recovery from
detachment in simulation under degraded adhesion. Compared with a model
predictive control (MPC) baseline that assumes perfect adhesion, our controller
maintains locomotion when attachment is intermittently lost. Hardware
experiments with the untethered robot further confirm robust vertical crawling
on steel surfaces, maintaining stability despite transient misalignment and
incomplete attachment. These results show that combining curriculum learning
with realistic adhesion modeling provides a resilient sim-to-real framework for
magnetic climbing robots in complex environments.

</details>


### [14] [A Contact-Driven Framework for Manipulating in the Blind](https://arxiv.org/abs/2510.20177)
*Muhammad Suhail Saleem,Lai Yuan,Maxim Likhachev*

Main category: cs.RO

TL;DR: 本研究提出了一个新型框架，将接触反馈与环境结构先验结合，显著提高了机器人在视觉不足场景下的操控效率。


<details>
  <summary>Details</summary>
Motivation: 在视觉不足的环境中，机器人需依赖接触反馈来区分空闲和被占用的空间，同时利用环境中的结构先验来避免碰撞。

Method: 本研究提出了一个综合接触反馈与结构先验的理论框架，包括接触检测与定位模块、占用估计模块和规划模块。

Result: 该系统在仿真和实际环境中测试，能够高效执行两个家庭任务，并验证了各个模块的贡献。

Conclusion: 该框架能够可靠地解决各种操控任务，任务完成时间相比于基线减少了多达2倍。

Abstract: Robots often face manipulation tasks in environments where vision is
inadequate due to clutter, occlusions, or poor lighting--for example, reaching
a shutoff valve at the back of a sink cabinet or locating a light switch above
a crowded shelf. In such settings, robots, much like humans, must rely on
contact feedback to distinguish free from occupied space and navigate around
obstacles. Many of these environments often exhibit strong structural
priors--for instance, pipes often span across sink cabinets--that can be
exploited to anticipate unseen structure and avoid unnecessary collisions. We
present a theoretically complete and empirically efficient framework for
manipulation in the blind that integrates contact feedback with structural
priors to enable robust operation in unknown environments. The framework
comprises three tightly coupled components: (i) a contact detection and
localization module that utilizes joint torque sensing with a contact particle
filter to detect and localize contacts, (ii) an occupancy estimation module
that uses the history of contact observations to build a partial occupancy map
of the workspace and extrapolate it into unexplored regions with learned
predictors, and (iii) a planning module that accounts for the fact that contact
localization estimates and occupancy predictions can be noisy, computing paths
that avoid collisions and complete tasks efficiently without eliminating
feasible solutions. We evaluate the system in simulation and in the real world
on a UR10e manipulator across two domestic tasks--(i) manipulating a valve
under a kitchen sink surrounded by pipes and (ii) retrieving a target object
from a cluttered shelf. Results show that the framework reliably solves these
tasks, achieving up to a 2x reduction in task completion time compared to
baselines, with ablations confirming the contribution of each module.

</details>


### [15] [NODA-MMH: Certified Learning-Aided Nonlinear Control for Magnetically-Actuated Swarm Experiment Toward On-Orbit Proof](https://arxiv.org/abs/2510.20231)
*Yuta Takahashi,Atsuki Ochi,Yoichi Tomioka,Shin-Ichiro Sakai*

Main category: cs.RO

TL;DR: 本研究实验验证了学习辅助的磁场控制卫星群的可行性，解决了多颗卫星控制中的基本挑战，并引入了一种新的功率最优控制方法。


<details>
  <summary>Details</summary>
Motivation: 随着卫星数量超过三颗，传统的控制方法面临非完整约束、欠驱动性、可扩展性和计算成本等挑战，此研究旨在解决这些问题。

Method: 通过实验验证学习辅助的时间积分电流控制的关键方面，设计了两个轴向线圈和基于空气轴承的平台实验设置，模拟轨道动力学。

Result: 验证了学习辅助的时间积分电流控制在系统动力学可控性和去中心化电流管理上的增强表现，并引入了NODA-MMH进行控制。

Conclusion: 本研究验证了通过学习辅助的磁场相互作用进行大规模卫星群控制的原理，并提出了一种基于模型的功率最优控制方法NODA-MMH。

Abstract: This study experimentally validates the principle of large-scale satellite
swarm control through learning-aided magnetic field interactions generated by
satellite-mounted magnetorquers. This actuation presents a promising solution
for the long-term formation maintenance of multiple satellites and has
primarily been demonstrated in ground-based testbeds for two-satellite position
control. However, as the number of satellites increases beyond three,
fundamental challenges coupled with the high nonlinearity arise: 1)
nonholonomic constraints, 2) underactuation, 3) scalability, and 4)
computational cost. Previous studies have shown that time-integrated current
control theoretically solves these problems, where the average actuator outputs
align with the desired command, and a learning-based technique further enhances
their performance. Through multiple experiments, we validate critical aspects
of learning-aided time-integrated current control: (1) enhanced controllability
of the averaged system dynamics, with a theoretically guaranteed error bound,
and (2) decentralized current management. We design two-axis coils and a
ground-based experimental setup utilizing an air-bearing platform, enabling a
mathematical replication of orbital dynamics. Based on the effectiveness of the
learned interaction model, we introduce NODA-MMH (Neural power-Optimal Dipole
Allocation for certified learned Model-based Magnetically swarm control
Harness) for model-based power-optimal swarm control. This study complements
our tutorial paper on magnetically actuated swarms for the long-term formation
maintenance problem.

</details>


### [16] [Kinaema: a recurrent sequence model for memory and pose in motion](https://arxiv.org/abs/2510.20261)
*Mert Bulent Sariyildiz,Philippe Weinzaepfel,Guillaume Bono,Gianluca Monaci,Christian Wolf*

Main category: cs.RO

TL;DR: 本论文介绍了Kinaema模型，该模型帮助机器人在先前观察到的空间中找到位置，能够高效处理视觉信息并进行导航。


<details>
  <summary>Details</summary>
Motivation: 研究空间感知机器人在连续操作中如何利用之前的视觉信息来优化效率，特别是定位自身在已见空间中的能力。

Method: 采用隐式潜在记忆，通过变换器以递归方式更新，以压缩传感器读取的历史信息，增强视觉数据的处理能力。

Result: 提出一种新模型Kinaema和一个代理，能够在大场景中整合视觉观察，并在请求时预测查询图像相对于当前位置的相对位置。

Conclusion: Kinaema模型在保持场景表示方面表现出色，能够有效地实现导航任务，尤其在与经典变换器相比具备更高的计算效率。

Abstract: One key aspect of spatially aware robots is the ability to "find their
bearings", ie. to correctly situate themselves in previously seen spaces. In
this work, we focus on this particular scenario of continuous robotics
operations, where information observed before an actual episode start is
exploited to optimize efficiency. We introduce a new model, Kinaema, and agent,
capable of integrating a stream of visual observations while moving in a
potentially large scene, and upon request, processing a query image and
predicting the relative position of the shown space with respect to its current
position. Our model does not explicitly store an observation history, therefore
does not have hard constraints on context length. It maintains an implicit
latent memory, which is updated by a transformer in a recurrent way,
compressing the history of sensor readings into a compact representation. We
evaluate the impact of this model in a new downstream task we call "Mem-Nav".
We show that our large-capacity recurrent model maintains a useful
representation of the scene, navigates to goals observed before the actual
episode start, and is computationally efficient, in particular compared to
classical transformers with attention over an observation history.

</details>


### [17] [MemER: Scaling Up Memory for Robot Control via Experience Retrieval](https://arxiv.org/abs/2510.20328)
*Ajay Sridhar,Jennifer Pan,Satvik Sharma,Chelsea Finn*

Main category: cs.RO

TL;DR: 本文提出了一种针对机器人策略的分层记忆框架，以改善其在长时间任务中的执行效果。


<details>
  <summary>Details</summary>
Motivation: 希望通过增强机器人的记忆能力，使其能够执行需要长时间记忆的任务。

Method: 通过分层策略框架，使用高层策略选择和跟踪关键帧，并生成低层策略的执行指令。

Result: MemER在三项长时间操作任务的实验中优于现有方法。

Conclusion: 该方法在三项真实世界的长期机器人操作任务中表现超过了之前的方法。

Abstract: Humans routinely rely on memory to perform tasks, yet most robot policies
lack this capability; our goal is to endow robot policies with the same
ability. Naively conditioning on long observation histories is computationally
expensive and brittle under covariate shift, while indiscriminate subsampling
of history leads to irrelevant or redundant information. We propose a
hierarchical policy framework, where the high-level policy is trained to select
and track previous relevant keyframes from its experience. The high-level
policy uses selected keyframes and the most recent frames when generating text
instructions for a low-level policy to execute. This design is compatible with
existing vision-language-action (VLA) models and enables the system to
efficiently reason over long-horizon dependencies. In our experiments, we
finetune Qwen2.5-VL-7B-Instruct and $\pi_{0.5}$ as the high-level and low-level
policies respectively, using demonstrations supplemented with minimal language
annotations. Our approach, MemER, outperforms prior methods on three real-world
long-horizon robotic manipulation tasks that require minutes of memory. Videos
and code can be found at https://jen-pan.github.io/memer/.

</details>


### [18] [Dino-Diffusion Modular Designs Bridge the Cross-Domain Gap in Autonomous Parking](https://arxiv.org/abs/2510.20335)
*Zixuan Wu,Hengyuan Zhang,Ting-Hsuan Chen,Yuliang Guo,David Paz,Xinyu Huang,Liu Ren*

Main category: cs.RO

TL;DR: Dino-Diffusion Parking (DDP)是一种新型的域无关自主停车管道，能够在不同的环境下实现高鲁棒性与成功率，表现优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 现有的端到端(Auto-Domain)停车方法在固定条件下表现良好，但在环境变化（如天气和光照变化）下的鲁棒性仍然是一个关键挑战。

Method: 我们提出的Dino-Diffusion Parking (DDP)是一种集成视觉基础模型和基于扩散的规划的域无关自主停车管道。

Result: 在CARLA模拟环境下训练后，我们的模型能够无缝转移到更具挑战性的环境中，并在多种出分布场景中保持高停车成功率。

Conclusion: Dino-Diffusion Parking (DDP)模型在多种不分布场景下均能保持超过90%的停车成功率，并且在真实世界环境中展示了良好的模拟到现实的转移能力。

Abstract: Parking is a critical pillar of driving safety. While recent end-to-end (E2E)
approaches have achieved promising in-domain results, robustness under domain
shifts (e.g., weather and lighting changes) remains a key challenge. Rather
than relying on additional data, in this paper, we propose Dino-Diffusion
Parking (DDP), a domain-agnostic autonomous parking pipeline that integrates
visual foundation models with diffusion-based planning to enable generalized
perception and robust motion planning under distribution shifts. We train our
pipeline in CARLA at regular setting and transfer it to more adversarial
settings in a zero-shot fashion. Our model consistently achieves a parking
success rate above 90% across all tested out-of-distribution (OOD) scenarios,
with ablation studies confirming that both the network architecture and
algorithmic design significantly enhance cross-domain performance over existing
baselines. Furthermore, testing in a 3D Gaussian splatting (3DGS) environment
reconstructed from a real-world parking lot demonstrates promising sim-to-real
transfer.

</details>


### [19] [Multi-Modal Decentralized Reinforcement Learning for Modular Reconfigurable Lunar Robots](https://arxiv.org/abs/2510.20347)
*Ashutosh Mishra,Shreya Santra,Elian Neppel,Edoardo M. Rossi Lombardi,Shamistan Karimov,Kentaro Uno,Kazuya Yoshida*

Main category: cs.RO

TL;DR: 研究提出了一种去中心化强化学习方案，用于模块化可重构机器人，以实现对新配置的零-shot适应，测试结果显示优秀的控制效果和无缝切换能力。


<details>
  <summary>Details</summary>
Motivation: 模块化可重构机器人适合特定任务的空间操作，但形态的组合增长使得统一控制变得困难。

Method: 每个模块采用不同的强化学习算法进行自主学习，轮式模块使用软演员-评论家算法进行运动，七自由度的肢体模块则使用近端策略优化，用于转向和操作。

Result: 提出了一种去中心化强化学习机制，使每个模块能够独立学习控制策略，能够实现对未见配置的零-shot泛化。

Conclusion: 该系统展示了模块化月球机器人在自主运动、转向和初步对齐等方面的可扩展性、可重用性和鲁棒性。

Abstract: Modular reconfigurable robots suit task-specific space operations, but the
combinatorial growth of morphologies hinders unified control. We propose a
decentralized reinforcement learning (Dec-RL) scheme where each module learns
its own policy: wheel modules use Soft Actor-Critic (SAC) for locomotion and
7-DoF limbs use Proximal Policy Optimization (PPO) for steering and
manipulation, enabling zero-shot generalization to unseen configurations. In
simulation, the steering policy achieved a mean absolute error of 3.63{\deg}
between desired and induced angles; the manipulation policy plateaued at 84.6 %
success on a target-offset criterion; and the wheel policy cut average motor
torque by 95.4 % relative to baseline while maintaining 99.6 % success.
Lunar-analogue field tests validated zero-shot integration for autonomous
locomotion, steering, and preliminary alignment for reconfiguration. The system
transitioned smoothly among synchronous, parallel, and sequential modes for
Policy Execution, without idle states or control conflicts, indicating a
scalable, reusable, and robust approach for modular lunar robots.

</details>


### [20] [NeuralTouch: Neural Descriptors for Precise Sim-to-Real Tactile Robot Control](https://arxiv.org/abs/2510.20390)
*Yijiong Lin,Bowen Deng,Chenghua Lu,Max Yang,Efi Psomopoulou,Nathan F. Lepora*

Main category: cs.RO

TL;DR: NeuralTouch是一个结合视觉和触觉的多模态框架，通过强化学习和NDF，实现了更精准的抓取


<details>
  <summary>Details</summary>
Motivation: 通过融合不同感知方式提高抓取准确性，解决NDF在复杂对象操作时存在的不足

Method: 通过整合神经描述字段（NDF）和触觉传感来实现精确的抓取

Result: NeuralTouch在各类操作任务中显著提高了抓取的准确性和鲁棒性，能够实现未经过调优的直接迁移到现实世界的操作

Conclusion: NeuralTouch提供了一种新的框架，使机器人在物体操作中实现更精细、可靠的触感交互。

Abstract: Grasping accuracy is a critical prerequisite for precise object manipulation,
often requiring careful alignment between the robot hand and object. Neural
Descriptor Fields (NDF) offer a promising vision-based method to generate
grasping poses that generalize across object categories. However, NDF alone can
produce inaccurate poses due to imperfect camera calibration, incomplete point
clouds, and object variability. Meanwhile, tactile sensing enables more precise
contact, but existing approaches typically learn policies limited to simple,
predefined contact geometries. In this work, we introduce NeuralTouch, a
multimodal framework that integrates NDF and tactile sensing to enable
accurate, generalizable grasping through gentle physical interaction. Our
approach leverages NDF to implicitly represent the target contact geometry,
from which a deep reinforcement learning (RL) policy is trained to refine the
grasp using tactile feedback. This policy is conditioned on the neural
descriptors and does not require explicit specification of contact types. We
validate NeuralTouch through ablation studies in simulation and zero-shot
transfer to real-world manipulation tasks--such as peg-out-in-hole and bottle
lid opening--without additional fine-tuning. Results show that NeuralTouch
significantly improves grasping accuracy and robustness over baseline methods,
offering a general framework for precise, contact-rich robotic manipulation.

</details>


### [21] [PointMapPolicy: Structured Point Cloud Processing for Multi-Modal Imitation Learning](https://arxiv.org/abs/2510.20406)
*Xiaogang Jia,Qian Wang,Anrui Wang,Han A. Wang,Balázs Gyenes,Emiliyan Gospodinov,Xinkai Jiang,Ge Li,Hongyi Zhou,Weiran Liao,Xi Huang,Maximilian Beck,Moritz Reuss,Rudolf Lioutikov,Gerhard Neumann*

Main category: cs.RO

TL;DR: PointMapPolicy通过在没有下采样的情况下对点的结构化网格进行条件化，提升了机器人操作系统中的多模态感知。


<details>
  <summary>Details</summary>
Motivation: 当前的点云方法难以捕捉细粒度细节，而RGB方法缺乏几何意识，限制了它们的精度和泛化能力。

Method: 引入PointMapPolicy方法，使用结构化点网格条件化扩散策略，并通过xLSTM进行高效融合。

Result: 我们的模型在多种操作任务上达到了最先进的性能。

Conclusion: PointMapPolicy模型有效融合了点图和RGB数据，利用xLSTM作为骨干，在复杂任务中表现优异。

Abstract: Robotic manipulation systems benefit from complementary sensing modalities,
where each provides unique environmental information. Point clouds capture
detailed geometric structure, while RGB images provide rich semantic context.
Current point cloud methods struggle to capture fine-grained detail, especially
for complex tasks, which RGB methods lack geometric awareness, which hinders
their precision and generalization. We introduce PointMapPolicy, a novel
approach that conditions diffusion policies on structured grids of points
without downsampling. The resulting data type makes it easier to extract shape
and spatial relationships from observations, and can be transformed between
reference frames. Yet due to their structure in a regular grid, we enable the
use of established computer vision techniques directly to 3D data. Using xLSTM
as a backbone, our model efficiently fuses the point maps with RGB data for
enhanced multi-modal perception. Through extensive experiments on the RoboCasa
and CALVIN benchmarks and real robot evaluations, we demonstrate that our
method achieves state-of-the-art performance across diverse manipulation tasks.
The overview and demos are available on our project page:
https://point-map.github.io/Point-Map/

</details>


### [22] [MR-UBi: Mixed Reality-Based Underwater Robot Arm Teleoperation System with Reaction Torque Indicator via Bilateral Control](https://arxiv.org/abs/2510.20407)
*Kohei Nishi,Masato Kobayashi,Yuki Uranishi*

Main category: cs.RO

TL;DR: 本研究提出了一种基于混合现实的水下机器人臂遥操作系统MR-UBi，结合视觉和触觉反馈，显著提高了操控精准性和用户体验。


<details>
  <summary>Details</summary>
Motivation: 开发一种更精准、用户友好的水下机器人臂遥操作系统，以提升抓取扭矩控制的准确性和操作体验。

Method: 通过与传统双向控制基准进行对比，进行用户研究与主观评估。

Result: MR-UBi系统显著改善了抓取扭矩控制的准确性，提升了在最佳扭矩范围内的时间，并减少了低/high扭矩范围。

Conclusion: MR-UBi通过整合视觉和触觉反馈，使水下机器人臂遥操作更加稳定、准确且用户友好。

Abstract: We present a mixed reality-based underwater robot arm teleoperation system
with a reaction torque indicator via bilateral control (MR-UBi). The reaction
torque indicator (RTI) overlays a color and length-coded torque bar in the
MR-HMD, enabling seamless integration of visual and haptic feedback during
underwater robot arm teleoperation. User studies with sixteen participants
compared MR-UBi against a bilateral-control baseline. MR-UBi significantly
improved grasping-torque control accuracy, increasing the time within the
optimal torque range and reducing both low and high grasping torque range
during lift and pick-and-place tasks with objects of different stiffness.
Subjective evaluations further showed higher usability (SUS) and lower workload
(NASA--TLX). Overall, the results confirm that \textit{MR-UBi} enables more
stable, accurate, and user-friendly underwater robot-arm teleoperation through
the integration of visual and haptic feedback. For additional material, please
check: https://mertcookimg.github.io/mr-ubi

</details>


### [23] [Robot Path and Trajectory Planning Considering a Spatially Fixed TCP](https://arxiv.org/abs/2510.20473)
*Bernhard Rameder,Hubert Gattringer,Andreas Mueller,Ronald Naderer*

Main category: cs.RO

TL;DR: 提出了一种在工作空间中规划机器人轨迹的方法，使用B样条实现光滑的加工路径。


<details>
  <summary>Details</summary>
Motivation: 在移动部件比移动工具更简单的情况下，规划加工路径

Method: 在工作空间坐标中计划轨迹，使用空间固定的工具中心点 (TCP)

Result: 机器人路径通过使用B样条表示，从而实现了一条平滑的机器人轨迹

Conclusion: 通过在实际系统中验证，所提出的方法有效地实现了所需的机器人轨迹生成。

Abstract: This paper presents a method for planning a trajectory in workspace
coordinates using a spatially fixed tool center point (TCP), while taking into
account the processing path on a part. This approach is beneficial if it is
easier to move the part rather than moving the tool. Whether a mathematical
description that defines the shape to be processed or single points from a
design program are used, the robot path is finally represented using B-splines.
The use of splines enables the path to be continuous with a desired degree,
which finally leads to a smooth robot trajectory. While calculating the robot
trajectory through prescribed orientation, additionally a given velocity at the
TCP has to be considered. The procedure was validated on a real system using an
industrial robot moving an arbitrary defined part.

</details>


### [24] [Degradation-Aware Cooperative Multi-Modal GNSS-Denied Localization Leveraging LiDAR-Based Robot Detections](https://arxiv.org/abs/2510.20480)
*Václav Pritzl,Xianjia Yu,Tomi Westerlund,Petr Štěpán,Martin Saska*

Main category: cs.RO

TL;DR: 提出了一种新的自适应多机器人协作定位方法，有效融合多种传感器数据以提高定位精度并应对传感器退化。


<details>
  <summary>Details</summary>
Motivation: 在无GNSS的环境中，准确的长期定位对机器人至关重要，而单一机器人携带所有传感器会导致尺寸、重量和能耗的增加。

Method: 一种基于因子图的自适应多模态多机器人协作定位方法

Result: 该方法在多种传感器退化条件下显示出显著提高的定位精度，尤其在异构的无人地面车辆和无人机团队中进行了有效评估。

Conclusion: 该研究表明，在多机器人系统中，通过因子图的松耦合方式，将异步的VIO、LIO和机器人间检测融合，能够显著改善定位精度。

Abstract: Accurate long-term localization using onboard sensors is crucial for robots
operating in Global Navigation Satellite System (GNSS)-denied environments.
While complementary sensors mitigate individual degradations, carrying all the
available sensor types on a single robot significantly increases the size,
weight, and power demands. Distributing sensors across multiple robots enhances
the deployability but introduces challenges in fusing asynchronous, multi-modal
data from independently moving platforms. We propose a novel adaptive
multi-modal multi-robot cooperative localization approach using a factor-graph
formulation to fuse asynchronous Visual-Inertial Odometry (VIO), LiDAR-Inertial
Odometry (LIO), and 3D inter-robot detections from distinct robots in a
loosely-coupled fashion. The approach adapts to changing conditions, leveraging
reliable data to assist robots affected by sensory degradations. A novel
interpolation-based factor enables fusion of the unsynchronized measurements.
LIO degradations are evaluated based on the approximate scan-matching Hessian.
A novel approach of weighting odometry data proportionally to the Wasserstein
distance between the consecutive VIO outputs is proposed. A theoretical
analysis is provided, investigating the cooperative localization problem under
various conditions, mainly in the presence of sensory degradations. The
proposed method has been extensively evaluated on real-world data gathered with
heterogeneous teams of an Unmanned Ground Vehicle (UGV) and Unmanned Aerial
Vehicles (UAVs), showing that the approach provides significant improvements in
localization accuracy in the presence of various sensory degradations.

</details>


### [25] [Dual Control Reference Generation for Optimal Pick-and-Place Execution under Payload Uncertainty](https://arxiv.org/abs/2510.20483)
*Victor Vantilborgh,Hrishikesh Sathyanarayan,Guillaume Crevecoeur,Ian Abraham,Tom Lefebvre*

Main category: cs.RO

TL;DR: 本文提出了一种方法来优化具有未知动态和参数不确定性的机器人操作任务的控制，通过设计参考轨迹来提高任务执行的速度和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决在未知动态下的机器人操作任务，例如在负载不确定性的情况下进行的拣选和放置任务，需要在任务执行过程中进行主动探索和在线参数调整，以实现准确的基于模型的控制。

Method: 将双重控制框架简化为反馈策略的结构预定义，并提出两种参考轨迹生成方法，分别基于鲁棒最优控制和最小化最优性损失。

Result: 提出了两个参考轨迹生成方法，均考虑了在任务执行中参数不确定性对性能的影响。

Conclusion: 通过考虑控制机制设计参考轨迹，可以实现更快速、更准确的任务执行和系统识别，同时确保稳定和高效的控制。

Abstract: This work addresses the problem of robot manipulation tasks under unknown
dynamics, such as pick-and-place tasks under payload uncertainty, where active
exploration and(/for) online parameter adaptation during task execution are
essential to enable accurate model-based control. The problem is framed as dual
control seeking a closed-loop optimal control problem that accounts for
parameter uncertainty. We simplify the dual control problem by pre-defining the
structure of the feedback policy to include an explicit adaptation mechanism.
Then we propose two methods for reference trajectory generation. The first
directly embeds parameter uncertainty in robust optimal control methods that
minimize the expected task cost. The second method considers minimizing the
so-called optimality loss, which measures the sensitivity of parameter-relevant
information with respect to task performance. We observe that both approaches
reason over the Fisher information as a natural side effect of their
formulations, simultaneously pursuing optimal task execution. We demonstrate
the effectiveness of our approaches for a pick-and-place manipulation task. We
show that designing the reference trajectories whilst taking into account the
control enables faster and more accurate task performance and system
identification while ensuring stable and efficient control.

</details>


### [26] [Simultaneous Stiffness and Trajectory Optimization for Energy Minimization of Pick-and-Place Tasks of SEA-Actuated Parallel Kinematic Manipulators](https://arxiv.org/abs/2510.20490)
*Thomas Kordik,Hubert Gattringer,Andreas Mueller*

Main category: cs.RO

TL;DR: 本文探讨了如何通过优化SEA驱动的PKM在拾取和放置操作中的能量消耗。


<details>
  <summary>Details</summary>
Motivation: 关键在于优化并减少PKM在重复任务中的能量消耗，尤其是使用SEA驱动时的能耗问题

Method: 开发动态模型并-formulate energy minimizing optimal control problem

Result: 通过对两个冗余驱动的并联机器人应用的实验验证了能量减少的有效性

Conclusion: 优化SEA的刚度和操作轨迹能够显著降低能耗，验证了该方法的有效性。

Abstract: A major field of industrial robot applications deals with repetitive tasks
that alternate between operating points. For these so-called pick-and-place
operations, parallel kinematic manipulators (PKM) are frequently employed.
These tasks tend to automatically run for a long period of time and therefore
minimizing energy consumption is always of interest. Recent research addresses
this topic by the use of elastic elements and particularly series elastic
actuators (SEA). This paper explores the possibilities of minimizing energy
consumption of SEA actuated PKM performing pick-and-place tasks. The basic idea
is to excite eigenmotions that result from the actuator springs and exploit
their oscillating characteristics. To this end, a prescribed cyclic
pick-and-place operation is analyzed and a dynamic model of SEA driven PKM is
derived. Subsequently, an energy minimizing optimal control problem is
formulated where operating trajectories as well as SEA stiffnesses are
optimized simultaneously. Here, optimizing the actuator stiffness does not
account for variable stiffness actuators. It serves as a tool for the design
and dimensioning process. The hypothesis on energy reduction is tested on two
(parallel) robot applications where redundant actuation is also addressed. The
results confirm the validity of this approach.

</details>


### [27] [A Parameter-Linear Formulation of the Optimal Path Following Problem for Robotic Manipulator](https://arxiv.org/abs/2510.20496)
*Tobias Marauli,Hubert Gattringer,Andreas Mueller*

Main category: cs.RO

TL;DR: 本文提出了一种新方法，通过最大化路径速度来克服时间最优路径跟随中的计算挑战，确保轨迹生成的平滑性和数值效率。


<details>
  <summary>Details</summary>
Motivation: 解决时间最优路径跟随中的计算挑战，尤其是避免在零路径速度时出现的奇点。

Method: 通过最大化路径速度，并进行数值高效的规划。

Result: 该方法能有效规划平滑轨迹，并且优化变量的离散重构是线性的。

Conclusion: 提出了一种通过最大化既定路径上的速度来实现平滑轨迹生成的方法。

Abstract: In this paper the computational challenges of time-optimal path following are
addressed. The standard approach is to minimize the travel time, which
inevitably leads to singularities at zero path speed, when reformulating the
optimization problem in terms of a path parameter. Thus, smooth trajectory
generation while maintaining a low computational effort is quite challenging,
since the singularities have to be taken into account. To this end, a different
approach is presented in this paper. This approach is based on maximizing the
path speed along a prescribed path. Furthermore, the approach is capable of
planning smooth trajectories numerically efficient. Moreover, the discrete
reformulation of the underlying problem is linear in optimization variables.

</details>


### [28] [RubbleSim: A Photorealistic Structural Collapse Simulator for Confined Space Mapping](https://arxiv.org/abs/2510.20529)
*Constantine Frost,Chad Council,Margaret McGuinness,Nathaniel Hanson*

Main category: cs.RO

TL;DR: RubbleSim是一个开源可重配置的模拟器，用于探索结构倒塌事件中的虚空空间，解决了数据获取困难的问题。


<details>
  <summary>Details</summary>
Motivation: 由于法律限制和训练场地信息不公开，获取构造崩塌事件中的虚空空间数据非常困难。

Method: 模拟器使用物理为基础的方法构建随机碎石堆，结合状态最先进的运动重建算法分析感知性能。

Result: 通过RubbleSim，我们展示了在模拟的虚空空间中，视觉条件的挑战如何影响感知性能。

Conclusion: RubbleSim提供了一种有效方法来研究灾后响应中视觉感知的下降，尤其是在复杂的虚空环境中。

Abstract: Despite well-reported instances of robots being used in disaster response,
there is scant published data on the internal composition of the void spaces
within structural collapse incidents. Data collected during these incidents is
mired in legal constraints, as ownership is often tied to the responding
agencies, with little hope of public release for research. While engineered
rubble piles are used for training, these sites are also reluctant to release
information about their proprietary training grounds. To overcome this access
challenge, we present RubbleSim -- an open-source, reconfigurable simulator for
photorealistic void space exploration. The design of the simulation assets is
directly informed by visits to numerous training rubble sites at differing
levels of complexity. The simulator is implemented in Unity with
multi-operating system support. The simulation uses a physics-based approach to
build stochastic rubble piles, allowing for rapid iteration between simulation
worlds while retaining absolute knowledge of the ground truth. Using RubbleSim,
we apply a state-of-the-art structure-from-motion algorithm to illustrate how
perception performance degrades under challenging visual conditions inside the
emulated void spaces. Pre-built binaries and source code to implement are
available online: https://github.com/mit-ll/rubble_pile_simulator.

</details>


### [29] [C-NAV: Towards Self-Evolving Continual Object Navigation in Open World](https://arxiv.org/abs/2510.20685)
*Ming-Ming Yu,Fei Zhu,Wenzhuo Liu,Yirong Yang,Qunbo Wang,Wenjun Wu,Jing Liu*

Main category: cs.RO

TL;DR: 本论文提出了C-Nav框架，旨在应对动态环境中物体导航的持续适应性挑战，并通过实验证明了其优越性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在动态开放世界环境中，物体导航技能无法持续适应新物体类别的问题。

Method: 提出C-Nav，一个连续视觉导航框架，结合双路径反遗忘机制和适应性采样策略。

Result: C-Nav在多个模型架构下的实验表明，其性能优于现有方法，特别是在内存需求显著降低的情况下。

Conclusion: C-Nav有效结合了反遗忘机制与适应性采样策略，实现了对新物体类别的学习，同时保留了先前知识，具有更低的内存需求。

Abstract: Embodied agents are expected to perform object navigation in dynamic,
open-world environments. However, existing approaches typically rely on static
trajectories and a fixed set of object categories during training, overlooking
the real-world requirement for continual adaptation to evolving scenarios. To
facilitate related studies, we introduce the continual object navigation
benchmark, which requires agents to acquire navigation skills for new object
categories while avoiding catastrophic forgetting of previously learned
knowledge. To tackle this challenge, we propose C-Nav, a continual visual
navigation framework that integrates two key innovations: (1) A dual-path
anti-forgetting mechanism, which comprises feature distillation that aligns
multi-modal inputs into a consistent representation space to ensure
representation consistency, and feature replay that retains temporal features
within the action decoder to ensure policy consistency. (2) An adaptive
sampling strategy that selects diverse and informative experiences, thereby
reducing redundancy and minimizing memory overhead. Extensive experiments
across multiple model architectures demonstrate that C-Nav consistently
outperforms existing approaches, achieving superior performance even compared
to baselines with full trajectory retention, while significantly lowering
memory requirements. The code will be publicly available at
https://bigtree765.github.io/C-Nav-project.

</details>


### [30] [Real-Time Gait Adaptation for Quadrupeds using Model Predictive Control and Reinforcement Learning](https://arxiv.org/abs/2510.20706)
*Ganga Nair B,Prakrut Kotecha,Shishir Kolathaya*

Main category: cs.RO

TL;DR: 提出了一种新颖的优化框架，结合MPPI和Dreamer模块，实现四足机器人实时步态适应，显著降低能耗并提高性能


<details>
  <summary>Details</summary>
Motivation: 解决模型自由强化学习中步态收敛至单一形式的问题，并提高在多变环境中的适应能力

Method: 结合Model Predictive Path Integral (MPPI)算法和Dreamer模块进行实时步态适应的优化框架

Result: 在Unitree Go1上进行的仿真实验显示，能量消耗平均减少至多36.48%，同时保持准确跟踪和适应性步态

Conclusion: 该框架有效提高了四足机器人在动态环境中的灵活性和性能。

Abstract: Model-free reinforcement learning (RL) has enabled adaptable and agile
quadruped locomotion; however, policies often converge to a single gait,
leading to suboptimal performance. Traditionally, Model Predictive Control
(MPC) has been extensively used to obtain task-specific optimal policies but
lacks the ability to adapt to varying environments. To address these
limitations, we propose an optimization framework for real-time gait adaptation
in a continuous gait space, combining the Model Predictive Path Integral (MPPI)
algorithm with a Dreamer module to produce adaptive and optimal policies for
quadruped locomotion. At each time step, MPPI jointly optimizes the actions and
gait variables using a learned Dreamer reward that promotes velocity tracking,
energy efficiency, stability, and smooth transitions, while penalizing abrupt
gait changes. A learned value function is incorporated as terminal reward,
extending the formulation to an infinite-horizon planner. We evaluate our
framework in simulation on the Unitree Go1, demonstrating an average reduction
of up to 36.48\% in energy consumption across varying target speeds, while
maintaining accurate tracking and adaptive, task-appropriate gaits.

</details>


### [31] [The Reality Gap in Robotics: Challenges, Solutions, and Best Practices](https://arxiv.org/abs/2510.20808)
*Elie Aljalbout,Jiaxu Xing,Angel Romero,Iretiayo Akinola,Caelan Reed Garrett,Eric Heiden,Abhishek Gupta,Tucker Hermans,Yashraj Narang,Dieter Fox,Davide Scaramuzza,Fabio Ramos*

Main category: cs.RO

TL;DR: 机器学习推动了机器人领域的发展，但模拟与现实之间的差距影响系统转移，本文综述了解决方案与评估指标。


<details>
  <summary>Details</summary>
Motivation: 随着机器人技术的进步，如何有效地将机器人系统从模拟环境转移到真实世界中成为一项重要挑战。

Method: 通过对模拟到现实转移的研究进行全面的文献综述，分析现实差距及其解决方案。

Result: 综述了多种方法（如领域随机化和实到模转移），展示了在解决现实差距方面取得的进展，同时指出了依然存在的挑战。

Conclusion: 本论文综述了模拟到现实转移的现状，强调了现实差距的成因、解决方案及评估指标。

Abstract: Machine learning has facilitated significant advancements across various
robotics domains, including navigation, locomotion, and manipulation. Many such
achievements have been driven by the extensive use of simulation as a critical
tool for training and testing robotic systems prior to their deployment in
real-world environments. However, simulations consist of abstractions and
approximations that inevitably introduce discrepancies between simulated and
real environments, known as the reality gap. These discrepancies significantly
hinder the successful transfer of systems from simulation to the real world.
Closing this gap remains one of the most pressing challenges in robotics.
Recent advances in sim-to-real transfer have demonstrated promising results
across various platforms, including locomotion, navigation, and manipulation.
By leveraging techniques such as domain randomization, real-to-sim transfer,
state and action abstractions, and sim-real co-training, many works have
overcome the reality gap. However, challenges persist, and a deeper
understanding of the reality gap's root causes and solutions is necessary. In
this survey, we present a comprehensive overview of the sim-to-real landscape,
highlighting the causes, solutions, and evaluation metrics for the reality gap
and sim-to-real transfer.

</details>


### [32] [GSWorld: Closed-Loop Photo-Realistic Simulation Suite for Robotic Manipulation](https://arxiv.org/abs/2510.20813)
*Guangqi Jiang,Haoran Chang,Ri-Zhao Qiu,Yutong Liang,Mazeyu Ji,Jiyue Zhu,Zhao Dong,Xueyan Zou,Xiaolong Wang*

Main category: cs.RO

TL;DR: GSWorld 是一种新型的机器人操作模拟器，支持基于真实机器人数据进行可重复的政策评估和无机器人训练。


<details>
  <summary>Details</summary>
Motivation: 通过创建一个高保真仿真框架，推动机器人操纵政策的开发和评估，以促进从实际数据中学习的政策与仿真环境的有效结合。

Method: 本论文提出一种新型资产格式 GSDF（高斯场景描述文件），结合了高斯网格表示与机器人 URDF 及其他对象，并通过简化的重建流程构建了包含多个机器人和对象的数据库。

Result: GSWorld 是一种结合 3D 高斯点云与物理引擎的强大、逼真的机器人操作模拟器。

Conclusion: GSWorld 提供了一个全面的框架，可以在不使用真实机器人的情况下，通过仿真增强机器人操控政策的学习和评估。

Abstract: This paper presents GSWorld, a robust, photo-realistic simulator for robotics
manipulation that combines 3D Gaussian Splatting with physics engines. Our
framework advocates "closing the loop" of developing manipulation policies with
reproducible evaluation of policies learned from real-robot data and sim2real
policy training without using real robots. To enable photo-realistic rendering
of diverse scenes, we propose a new asset format, which we term GSDF (Gaussian
Scene Description File), that infuses Gaussian-on-Mesh representation with
robot URDF and other objects. With a streamlined reconstruction pipeline, we
curate a database of GSDF that contains 3 robot embodiments for single-arm and
bimanual manipulation, as well as more than 40 objects. Combining GSDF with
physics engines, we demonstrate several immediate interesting applications: (1)
learning zero-shot sim2real pixel-to-action manipulation policy with
photo-realistic rendering, (2) automated high-quality DAgger data collection
for adapting policies to deployment environments, (3) reproducible benchmarking
of real-robot manipulation policies in simulation, (4) simulation data
collection by virtual teleoperation, and (5) zero-shot sim2real visual
reinforcement learning. Website: https://3dgsworld.github.io/.

</details>


### [33] [VAMOS: A Hierarchical Vision-Language-Action Model for Capability-Modulated and Steerable Navigation](https://arxiv.org/abs/2510.20818)
*Mateo Guaman Castro,Sidharth Rajagopal,Daniel Gorbatov,Matt Schmittle,Rohan Baijal,Octi Zhang,Rosario Scalise,Sidharth Talia,Emma Romig,Celso de Melo,Byron Boots,Abhishek Gupta*

Main category: cs.RO

TL;DR: VAMOS是一种分层的机器人导航学习架构，它通过将语义规划与身体约束分离，提升了机器人在不同环境下的导航能力。


<details>
  <summary>Details</summary>
Motivation: 解决机器人导航中的政策泛化问题，尤其是针对不同物理约束和能力的机器人的环境适应性。

Method: VAMOS采用层次化的VLA，将通用规划器与专门的能力模型相结合，使高层次规划能够在图像空间中直接提出候选路径，并由能力模型进行评估和重新排序。

Result: 在实际实验中，VAMOS在室内和复杂室外导航中表现出更高的成功率，且较传统方法具有3倍的成功率提升。

Conclusion: VAMOS通过分层设计和专门模型的结合，显著提高了机器人在复杂环境中的导航成功率，并支持跨躯体的导航能力。

Abstract: A fundamental challenge in robot navigation lies in learning policies that
generalize across diverse environments while conforming to the unique physical
constraints and capabilities of a specific embodiment (e.g., quadrupeds can
walk up stairs, but rovers cannot). We propose VAMOS, a hierarchical VLA that
decouples semantic planning from embodiment grounding: a generalist planner
learns from diverse, open-world data, while a specialist affordance model
learns the robot's physical constraints and capabilities in safe, low-cost
simulation. We enabled this separation by carefully designing an interface that
lets a high-level planner propose candidate paths directly in image space that
the affordance model then evaluates and re-ranks. Our real-world experiments
show that VAMOS achieves higher success rates in both indoor and complex
outdoor navigation than state-of-the-art model-based and end-to-end learning
methods. We also show that our hierarchical design enables cross-embodied
navigation across legged and wheeled robots and is easily steerable using
natural language. Real-world ablations confirm that the specialist model is key
to embodiment grounding, enabling a single high-level planner to be deployed
across physically distinct wheeled and legged robots. Finally, this model
significantly enhances single-robot reliability, achieving 3X higher success
rates by rejecting physically infeasible plans. Website:
https://vamos-vla.github.io/

</details>
