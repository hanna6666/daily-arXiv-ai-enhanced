<div id=toc></div>

# Table of Contents

- [cs.HC](#cs.HC) [Total: 11]
- [cs.RO](#cs.RO) [Total: 26]


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [1] [Scientific judgment drifts over time in AI ideation](https://arxiv.org/abs/2511.04964)
*Lingyu Zhang,Mitchell Wang,Boyuan Chen*

Main category: cs.HC

TL;DR: 科学家对研究创意的评判标准并非静态，而是会随时间变化，显示出质量评分的系统漂移。AI在科学创意生成中的应用应考虑这种动态性。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型越来越多地参与科研假设的生成，理解科学家评判标准的变化对于提高AI系统的可靠性和有效性至关重要。

Method: 通过两波研究，收集了57名研究人员对控制研究创意和AI生成创意的7182个评分，以分析其评价标准的变动。

Result: 本研究探讨了科学评估的动态性，发现科学家对研究创意的评判标准并非固定，而是随时间变化。研究表明，尽管对某一研究创意的评价稳定，但整体质量评分在时间上出现系统性的漂移。这一发现对人工智能生成科学假设的系统具有重要启示，强调了评估标准需随时间调整。

Conclusion: 科学评估是动态的，而非固定的；忽视这一点可能导致对AI辅助创意进展的误解，需建立更有效的评估协议。

Abstract: Scientific discovery begins with ideas, yet evaluating early-stage research
concepts is a subtle and subjective human judgment. As large language models
(LLMs) are increasingly tasked with generating scientific hypotheses, most
systems assume that scientists' evaluations form a fixed gold standard, and
that scientists' judgments do not change. Here we challenge this assumption. In
a two-wave study with 7,182 ratings from 57 active researchers across six
scientific departments, each participant repeatedly evaluated a constant
"control" research idea alongside AI-generated ideas. We show that scientists'
ratings of the very same idea systematically drift over time: overall quality
scores increased by 0.61 points on a 0-10 scale (P = 0.005), and test-retest
reliability was only moderate across core dimensions of scientific value,
revealing systematic temporal drift in perceived idea quality. Yet the internal
structure of judgment remained stable, such as the relative importance placed
on originality, feasibility, clarity. We then aligned an LLM-based ideation
system to first-wave human ratings and used it to select new ideas. Although
alignment improved agreement with Wave-1 evaluations, its apparent gains
disappeared once drift in human standards was accounted for. Thus, tuning to a
fixed human snapshot produced improvements that were transient rather than
persistent. These findings reveal that human evaluation of scientific ideas is
not static but a dynamic process with stable priorities and requires shifting
calibration. Treating one-time human ratings as immutable ground truth risks
overstating progress in AI-assisted ideation and obscuring the challenge of
co-evolving with changing expert standards. Drift-aware evaluation protocols
and longitudinal benchmarks may therefore be essential for building AI systems
that reliably augment, rather than overfit to, human scientific judgment.

</details>


### [2] [Enhancing Public Speaking Skills in Engineering Students Through AI](https://arxiv.org/abs/2511.04995)
*Amol Harsh,Brainerd Prince,Siddharth Siddharth,Deepan Raj Prabakar Muthirayan,Kabir S Bhalla,Esraaj Sarkar Gupta,Siddharth Sahu*

Main category: cs.HC

TL;DR: 本研究开发了一种融合言语分析、计算机视觉和情感检测的AI模型，以帮助工程学生改善公共演讲技能。


<details>
  <summary>Details</summary>
Motivation: 面对工程学生沟通能力不足的问题，开发一种可持续和个性化的评估工具来提升他们的公共演讲能力。

Method: 模型利用言语分析、计算机视觉和情感检测，对学生的言语与非言语交流进行综合评估。

Result: 本研究提出了一种AI驱动的公共演讲评估模型，通过整合言语与非言语交流方式的研究，为工程学生提供个性化的反馈和评估。

Conclusion: 这一AI驱动的公共演讲训练工具能够帮助学生反复练习，提升他们的专业沟通能力。

Abstract: This research-to-practice full paper was inspired by the persistent challenge
in effective communication among engineering students. Public speaking is a
necessary skill for future engineers as they have to communicate technical
knowledge with diverse stakeholders. While universities offer courses or
workshops, they are unable to offer sustained and personalized training to
students. Providing comprehensive feedback on both verbal and non-verbal
aspects of public speaking is time-intensive, making consistent and
individualized assessment impractical. This study integrates research on verbal
and non-verbal cues in public speaking to develop an AI-driven assessment model
for engineering students. Our approach combines speech analysis, computer
vision, and sentiment detection into a multi-modal AI system that provides
assessment and feedback. The model evaluates (1) verbal communication (pitch,
loudness, pacing, intonation), (2) non-verbal communication (facial
expressions, gestures, posture), and (3) expressive coherence, a novel
integration ensuring alignment between speech and body language. Unlike
previous systems that assess these aspects separately, our model fuses multiple
modalities to deliver personalized, scalable feedback. Preliminary testing
demonstrated that our AI-generated feedback was moderately aligned with expert
evaluations. Among the state-of-the-art AI models evaluated, all of which were
Large Language Models (LLMs), including Gemini and OpenAI models, Gemini Pro
emerged as the best-performing, showing the strongest agreement with human
annotators. By eliminating reliance on human evaluators, this AI-driven public
speaking trainer enables repeated practice, helping students naturally align
their speech with body language and emotion, crucial for impactful and
professional communication.

</details>


### [3] [Do intelligent tutoring systems benefit K-12 students? A meta-analysis and evaluation of heterogeneity of treatment effects in the U.S](https://arxiv.org/abs/2511.04997)
*Walter L. Leite,Huibin Zhang,Shibani Rana,Yide Hao,Amber D. Hatch,Lingchen Kong,Huan Kuang*

Main category: cs.HC

TL;DR: 本研究通过荟萃分析发现，智能辅导系统在K-12教育中对学习成果有积极影响，尤其在特定条件下。


<details>
  <summary>Details</summary>
Motivation: 理解智能辅导系统在K-12学校中使用的最佳条件，以扩大其应用。

Method: 荟萃分析18项研究，评估11种ITS的影响效果。

Result: 通过对18项研究的荟萃分析，显示ITS对美国K-12学生学习成果的显著正面影响。

Conclusion: ITS在提升K-12学生学习效果方面效果显著，但在不同背景和条件下的效果存在差异。

Abstract: To expand the use of intelligent tutoring systems (ITS) in K-12 schools, it
is essential to understand the conditions under which their use is most
beneficial. This meta-analysis evaluated the heterogeneity of ITS effects
across studies focusing on elementary, middle, and high schools in the U.S. It
included 18 studies with 77 effect sizes across 11 ITS. Overall, there was a
significant positive effect size of ITS on U.S. K-12 students' learning
outcomes (g=0.271, SE=0.011, p=0.001). Furthermore, effect sizes were similar
across elementary and middle schools, and for low-achieving students, but were
lower in studies including rural schools. A MetaForest analysis showed that
providing worked-out examples, intervention duration, intervention condition,
type of learning outcome, and immediate measurement were the most important
moderators of treatment effects.

</details>


### [4] [8bit-GPT: Exploring Human-AI Interaction on Obsolete Macintosh Operating Systems](https://arxiv.org/abs/2511.05025)
*Hala Sheta*

Main category: cs.HC

TL;DR: 本研究提出了8bit-GPT模型，旨在探讨人机交互及其影响，特别是在聊天机器人使用中引发的依赖和情感联系问题。


<details>
  <summary>Details</summary>
Motivation: To address over-reliance on assistive chatbots and its negative effects on information retention and emotional attachment.

Method: Introduce 8bit-GPT, a language model on a legacy system, to explore Human-AI interaction and anthropomorphic rhetoric.

Result: Developed a tool that promotes reflection on interactions with chatbots through a defamiliarized interface and inefficient interaction.

Conclusion: 通过反思性设计原则，8bit-GPT意在重新审视聊天机器人的角色，并提醒用户注意与之互动时可能产生的依赖感。

Abstract: The proliferation of assistive chatbots offering efficient, personalized
communication has driven widespread over-reliance on them for decision-making,
information-seeking and everyday tasks. This dependence was found to have
adverse consequences on information retention as well as lead to superficial
emotional attachment. As such, this work introduces 8bit-GPT; a language model
simulated on a legacy Macintosh Operating System, to evoke reflection on the
nature of Human-AI interaction and the consequences of anthropomorphic
rhetoric. Drawing on reflective design principles such as slow-technology and
counterfunctionality, this work aims to foreground the presence of chatbots as
a tool by defamiliarizing the interface and prioritizing inefficient
interaction, creating a friction between the familiar and not.

</details>


### [5] [VEIL: Reading Control Flow Graphs Like Code](https://arxiv.org/abs/2511.05066)
*Philipp Schaad,Tal Ben-Nun,Torsten Hoefler*

Main category: cs.HC

TL;DR: 提出了一种新的CFG可视化算法VEIL，旨在提高程序控制流图的可读性。


<details>
  <summary>Details</summary>
Motivation: 提高现实世界CFG的可读性和理解性

Method: 提出VEIL算法

Result: VEIL算法提供了更清晰、直观的CFG布局，提高了可读性和布局性能。

Conclusion: VEIL通过保留执行顺序和简化复杂结构，显著改善了CFG的可视化效果。

Abstract: Control flow graphs (CFGs) are essential tools for understanding program
behavior, yet the size of real-world CFGs makes them difficult to interpret.
With thousands of nodes and edges, sophisticated graph drawing algorithms are
required to present them on screens in ways that make them readable and
understandable. However, being designed for general graphs, these algorithms
frequently break the natural flow of execution, placing later instructions
before earlier ones and obscuring critical program structures. In this paper,
we introduce a set of criteria specifically tailored for CFG visualization,
focusing on preserving execution order and making complex structures easier to
follow. Building on these criteria, we present VEIL, a new layout algorithm
that uses dominator analysis to produce clearer, more intuitive CFG layouts.
Through a study of CFGs from real-world applications, we show how our method
improves readability and provides improved layout performance compared to state
of the art graph drawing techniques.

</details>


### [6] [FM4Com: Foundation Model for Scene-Adaptive Communication Strategy Optimization](https://arxiv.org/abs/2511.05094)
*Zhaoyang Li,Shangzhuo Xie,Qianqian Yang*

Main category: cs.HC

TL;DR: 本文提出了一种基于强化学习的多模态通信决策模型，能够更好地适应6G网络的复杂环境和用户需求。


<details>
  <summary>Details</summary>
Motivation: 当前物理层设计的模块化优化无法实现全局最佳，且缺乏对通信状态和用户意图的联合推理能力。

Method: 基于强化学习的多模态通信决策模型

Result: 提出的模型在恶劣信道条件下显著优于传统基于规划的算法，能够实现稳健、高效和个性化的6G链路构建。

Conclusion: 该研究表明，融合信道状态信息和用户指令的模型能够有效提升6G通信系统的性能和个性化策略。

Abstract: The emergence of sixth-generation (6G) networks heralds an intelligent
communication ecosystem driven by AI-native air interfaces. However, current
physical-layer designs-typically following modular and isolated optimization
paradigms-fail to achieve global end-to-end optimality due to neglected
inter-module dependencies. Although large language models (LLMs) have recently
been applied to communication tasks such as beam prediction and resource
allocation, existing studies remain limited to single-task or single-modality
scenarios and lack the ability to jointly reason over communication states and
user intents for personalized strategy adaptation. To address these
limitations, this paper proposes a novel multimodal communication
decision-making model based on reinforcement learning. The proposed model
semantically aligns channel state information (CSI) and textual user
instructions, enabling comprehensive understanding of both physical-layer
conditions and communication intents. It then generates physically realizable,
user-customized link construction strategies that dynamically adapt to changing
environments and preference tendencies. A two-stage reinforcement learning
framework is employed: the first stage expands the experience pool via
heuristic exploration and behavior cloning to obtain a near-optimal
initialization, while the second stage fine-tunes the model through
multi-objective reinforcement learning considering bit error rate, throughput,
and complexity. Experimental results demonstrate that the proposed model
significantly outperforms conventional planning-based algorithms under
challenging channel conditions, achieving robust, efficient, and personalized
6G link construction.

</details>


### [7] [Interface Homme-Machine pour l'Identification des Liaisons de Coins](https://arxiv.org/abs/2511.05136)
*Patrice Labedan,Nicolas Drougard*

Main category: cs.HC

TL;DR: ACCADIL项目开发了一个基于计算机视觉的软件工具，帮助钱币学家识别钱币模具链接，并提供多种可视化和数据处理功能。


<details>
  <summary>Details</summary>
Motivation: 为了提高钱币模具链接识别的效率和准确性，开发了这一软件工具。

Method: 使用计算机视觉和分类技术的计算算法

Result: 开发了在线接口，支持交互式结果验证，并提供多种数据可视化和导出功能。

Conclusion: ACCADIL为钱币学家提供了一个全面的分析工具，帮助识别钱币的模具链接。

Abstract: ACCADIL is a project that led to the development of software tools for the
identification of coin die links from coin photographs. It provides a
computational algorithm based on computer vision and classification techniques,
along with an online interface for the interactive verification of results.
This guide briefly describes the algorithmic principles, the preparation of
data prior to analysis, and the features offered by the interface: dataset
addition, visualization modes (overlay, side-by-side, magnifier, transparency),
result export, and distance visualization. ACCADIL thus provides numismatists
with a comprehensive tool for the analysis of die links within a coin
collection.

</details>


### [8] [psiUnity: A Platform for Multimodal Data-Driven XR](https://arxiv.org/abs/2511.05304)
*Akhil Ajikumar,Sahil Mayenkar,Steven Yoo,Sakib Reza,Mohsen Moghaddam*

Main category: cs.HC

TL;DR: 本文提出psiUnity，一个开源整合工具，连接psi与Unity，支持实时多模态数据的双向流动，促进XR交互实验。


<details>
  <summary>Details</summary>
Motivation: 现有的HoloLens开发受限于Unity/MRTK生态系统与psi之间的连接问题，无法有效进行多模态数据的同步和管理。

Method: 开发了一个C#集成工具psiUnity，支持实时双向流式传输数据，增强Unity与psi的连接。

Result: 本文介绍了psiUnity，一个开源的C#集成工具，旨在弥补现有Unity/MRTK生态系统与Platform for Situated Intelligence（psi）之间的关键差距，使得HoloLens开发者能够高效同步和流式传输多模态数据。

Conclusion: psiUnity通过在Unity架构中嵌入psi的本地序列化和时间协调功能，突破了StereoKit的局限性，有助于推动HRI、HCI和具身AI领域的研究进展。

Abstract: Extended reality (XR) research increasingly relies on the ability to stream
and synchronize multimodal data between headsets and immersive applications for
data-driven interaction and experimentation. However, developers face a
critical gap: the Platform for Situated Intelligence (psi), which excels at
deterministic temporal alignment and multimodal data management, has been
largely inaccessible to the dominant Unity/MRTK ecosystem used for HoloLens
development. We introduce psiUnity, an open-source C# integration that bridges
psi's .NET libraries with Unity 2022.3 and MRTK3 for HoloLens 2. psiUnity
enables bidirectional, real-time streaming of head pose, hand tracking, gaze,
IMU, audio, and depth sensor data (AHAT and long-throw) with microsecond-level
temporal precision, allowing Unity applications to both consume and produce
synchronized multimodal data streams. By embedding psi's native serialization,
logging, and temporal coordination directly within Unity's architecture,
psiUnity extends psi beyond its previous StereoKit limitations and empowers the
HRI, HCI, and embodied-AI communities to develop reproducible, data-driven XR
interactions and experiments within the familiar Unity environment. The
integration is available at https://github.com/sailgt/psiUnity.

</details>


### [9] [Semantic Interactivity: leveraging NLP to enable a shared interaction approach for joint activities](https://arxiv.org/abs/2511.05346)
*Olaf V. Adan,Dimitra Dritsa,Steven Houben*

Main category: cs.HC

TL;DR: 本研究开发了一种机制，通过共享交互增强语义互动，支持团队协作。


<details>
  <summary>Details</summary>
Motivation: 探讨传统协作系统孤立解决个人任务的局限性，致力于通过共享体验提升团队合作的有效性。

Method: 采用自然语言处理技术，分析团队互动中的共享信息结构，设计并实现了CollEagle交互桌面系统。

Result: 本研究提出了一种基于自然语言处理的机制，旨在通过共享交互机制促进语义交互。

Conclusion: 我们的初步研究表明，语义交互能够有效调节群体互动，有助于设计新型协作界面。

Abstract: Collocated collaboration, where individuals work together in the same
physical space and time, remains a cornerstone of effective teamwork. However,
most collaborative systems are designed to support individual tasks rather than
joint activities; they enable interactions for users to complete tasks rather
than interactivity to engage in shared experiences. In this work, we introduce
an NLP-driven mechanism that enables semantic interactivity through a shared
interaction mechanism. This mechanism was developed as part of CollEagle, an
interactive tabletop system that supports shared externalisation practices by
offering a low-effort way for users to create, curate, organise, and structure
information to capture the essence of collaborative discussions. Our
preliminary study highlights the potential for semantic interactivity to
mediate group interactions, suggesting that the interaction approach paves the
way for designing novel collaborative interfaces. We contribute our
implementation and offer insights for future research to enable semantic
interactivity in systems that support joint activities.

</details>


### [10] [Designing Hierarchical Exploratory Experiences for Ethnic Costumes: A Cultural Gene-Based Perspective](https://arxiv.org/abs/2511.05400)
*Ma Xiaofan,Yan Lirong,Zhao Weijia,Zeng Weiping,Wu Huiyue*

Main category: cs.HC

TL;DR: 本研究提出了三层文化基因框架，设计了一种互动数字平台，增强用户的文化认知和身份感，推动文化遗产的数字保护。


<details>
  <summary>Details</summary>
Motivation: 现有的数字化保护实践缺乏一个系统的设计框架，以动态和个性化的方式传达民族服饰的深层文化意义，提升用户参与度。

Method: 进行了一项混合方法的用户研究（N=24）来评估我们设计的平台。

Result: 研究结果表明，该平台有效增强了用户的文化认知，深化了情感连接，并显著提升了文化身份感。

Conclusion: 本研究提供了一种经过验证的框架和实际示例，用于设计生成性、塑造身份的文化遗产数字体验，为数字时代的保护与复兴提供了新路径。

Abstract: Ethnic clothing is a vital carrier of cultural identity, yet its digital
preservation often results in static displays that fail to convey deep cultural
meaning or foster user engagement. Existing practices lack a systematic design
framework for translating the hierarchical cultural connotations of these
garments into dynamic, personalized, and identity-promoting digital
experiences. To address this gap, this paper proposes a Three-Layer Cultural
Gene Framework that systematically decodes ethnic costumes from their
surface-level visual symbols, through their mid-level socio-cultural contexts,
to their inner-layer spiritual core. Based on this framework, we designed and
implemented an interactive digital platform featuring two key innovations: a
"gene-first" exploratory path that encourages curiosity-driven discovery, and
an AI-powered co-creation experience. This generative feature allows users to
co-create personalized narratives and images based on their understanding of
the "inner-layer" genes, transforming them from passive observers into active
co-creators. A mixed-methods user study (N=24) was conducted to evaluate the
platform. The findings demonstrate that our approach effectively enhances
users' cultural cognition, deepens their affective connection, and
significantly promotes their sense of cultural identity. This research
contributes a validated framework and a practical exemplar for designing
generative, identity-building digital experiences for cultural heritage,
offering a new pathway for its preservation and revitalization in the digital
age.

</details>


### [11] [Story Arena: A Multi-Agent Environment for Envisioning the Future of Software Engineering](https://arxiv.org/abs/2511.05410)
*Justin D. Weisz,Michael Muller,Kush R. Varshney*

Main category: cs.HC

TL;DR: 本文通过构建多智能体环境Story Arena，让AI探讨软件工程的未来，并创作了名为《信任的法则》的短篇小说。


<details>
  <summary>Details</summary>
Motivation: 希望通过AI的视角理解其对软件工程的影响，并探讨人类与AI的共同创造过程中的信任与所有权等主题。

Method: 通过构建多智能体对话环境，让AI根据各自立场进行讨论，并共同创作内容。

Result: 本研究构建了一个名为Story Arena的多智能体"写作室"，在此环境中，多个人工智能体以独立的立场进行对话，探讨软件工程的未来。在形成共同愿景后，它们合作创作了一部叙事形式的设计小说《信任的法则》。

Conclusion: 该研究展示了人工智能在软件工程未来探索中的潜力，尤其是在合作创作和叙事构建方面。

Abstract: What better way to understand the impact of AI on software engineering than
to ask AI itself? We constructed Story Arena, a multi-agent "writer's room" in
which multiple AI agents, independently imbued with a position statement on the
future of software engineering, converse with each other to develop a shared
vision. They then use this shared vision to collaboratively construct a design
fiction that depicts this vision in narrative form. We present "The Code of
Trust," a short fiction that investigates themes of human comprehension, trust,
content ownership, augmentation vs. replacement, and uncertain futures in
human-AI co-creation.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [12] [ScheduleStream: Temporal Planning with Samplers for GPU-Accelerated Multi-Arm Task and Motion Planning & Scheduling](https://arxiv.org/abs/2511.04758)
*Caelan Garrett,Fabio Ramos*

Main category: cs.RO

TL;DR: 提出了ScheduleStream框架，以改进多臂机器人的任务和运动规划，允许并行运动并提升计算效率。


<details>
  <summary>Details</summary>
Motivation: 解决多臂机器人控制中的计算挑战，提高任务和运动规划的效率和灵活性，尤其是在需要并行动作的场景中。

Method: 引入ScheduleStream框架，利用混合持续性动作建模时间动态，并设计域无关算法以解决调度问题，同时通过GPU加速提升规划速度。

Result: ScheduleStream在模拟中表现出更高效的解决方案，成功应用于多个实际的双臂机器人任务。

Conclusion: ScheduleStream成功地扩展了任务和运动规划算法，使其能够在多臂机器人中实现并行调度，验证了其在实际应用场景中的有效性。

Abstract: Bimanual and humanoid robots are appealing because of their human-like
ability to leverage multiple arms to efficiently complete tasks. However,
controlling multiple arms at once is computationally challenging due to the
growth in the hybrid discrete-continuous action space. Task and Motion Planning
(TAMP) algorithms can efficiently plan in hybrid spaces but generally produce
plans, where only one arm is moving at a time, rather than schedules that allow
for parallel arm motion. In order to extend TAMP to produce schedules, we
present ScheduleStream, the first general-purpose framework for planning &
scheduling with sampling operations. ScheduleStream models temporal dynamics
using hybrid durative actions, which can be started asynchronously and persist
for a duration that's a function of their parameters. We propose
domain-independent algorithms that solve ScheduleStream problems without any
application-specific mechanisms. We apply ScheduleStream to Task and Motion
Planning & Scheduling (TAMPAS), where we use GPU acceleration within samplers
to expedite planning. We compare ScheduleStream algorithms to several ablations
in simulation and find that they produce more efficient solutions. We
demonstrate ScheduleStream on several real-world bimanual robot tasks at
https://schedulestream.github.io.

</details>


### [13] [ReGen: Generative Robot Simulation via Inverse Design](https://arxiv.org/abs/2511.04769)
*Phat Nguyen,Tsun-Hsuan Wang,Zhang-Wei Hong,Erfan Aasi,Andrew Silva,Guy Rosman,Sertac Karaman,Daniela Rus*

Main category: cs.RO

TL;DR: ReGen是一个自动化生成模拟环境的框架，能基于机器人行为和文本描述推断出场景，增强机器人学习验证。


<details>
  <summary>Details</summary>
Motivation: 构建机器人学习和验证策略的模拟是一个劳动密集的过程，因此需要一种自动化的方法来减少这个过程的复杂性。

Method: 利用大型语言模型扩展编码因果关系的有向图，形成符号程序，从而配置和执行机器人模拟环境。

Result: 提出了ReGen，一个通过逆向设计自动化模拟设计的生成性模拟框架。

Conclusion: ReGen在自主驾驶和机器人操作任务中表现出色，生成了更复杂多样的模拟环境，从而改善了机器人策略的验证和学习。

Abstract: Simulation plays a key role in scaling robot learning and validating
policies, but constructing simulations remains a labor-intensive process. This
paper introduces ReGen, a generative simulation framework that automates
simulation design via inverse design. Given a robot's behavior -- such as a
motion trajectory or an objective function -- and its textual description,
ReGen infers plausible scenarios and environments that could have caused the
behavior. ReGen leverages large language models to synthesize scenarios by
expanding a directed graph that encodes cause-and-effect relationships,
relevant entities, and their properties. This structured graph is then
translated into a symbolic program, which configures and executes a robot
simulation environment. Our framework supports (i) augmenting simulations based
on ego-agent behaviors, (ii) controllable, counterfactual scenario generation,
(iii) reasoning about agent cognition and mental states, and (iv) reasoning
with distinct sensing modalities, such as braking due to faulty GPS signals. We
demonstrate ReGen in autonomous driving and robot manipulation tasks,
generating more diverse, complex simulated environments compared to existing
simulations with high success rates, and enabling controllable generation for
corner cases. This approach enhances the validation of robot policies and
supports data or simulation augmentation, advancing scalable robot learning for
improved generalization and robustness. We provide code and example videos at:
https://regen-sim.github.io/

</details>


### [14] [Unified Multimodal Diffusion Forcing for Forceful Manipulation](https://arxiv.org/abs/2511.04812)
*Zixuan Huang,Huaidian Hou,Dmitry Berenson*

Main category: cs.RO

TL;DR: 提出了一种多模态扩散强迫框架，能够从多模态机器人轨迹中学习，超越了简单的动作生成。


<details>
  <summary>Details</summary>
Motivation: 现有的模仿学习方法通常忽视不同模态之间的丰富交互，而这种交互对于建模机器人行为和理解任务结果至关重要。

Method: Multimodal Diffusion Forcing (MDF)

Result: MDF在多个接触丰富和强劲操作的任务中显示出强大的性能和稳健性，并能够有效地学习多模态机器人轨迹。

Conclusion: MDF不仅提供了多种功能，还在噪声观测下表现出强大的性能和鲁棒性。

Abstract: Given a dataset of expert trajectories, standard imitation learning
approaches typically learn a direct mapping from observations (e.g., RGB
images) to actions. However, such methods often overlook the rich interplay
between different modalities, i.e., sensory inputs, actions, and rewards, which
is crucial for modeling robot behavior and understanding task outcomes. In this
work, we propose Multimodal Diffusion Forcing, a unified framework for learning
from multimodal robot trajectories that extends beyond action generation.
Rather than modeling a fixed distribution, MDF applies random partial masking
and trains a diffusion model to reconstruct the trajectory. This training
objective encourages the model to learn temporal and cross-modal dependencies,
such as predicting the effects of actions on force signals or inferring states
from partial observations. We evaluate MDF on contact-rich, forceful
manipulation tasks in simulated and real-world environments. Our results show
that MDF not only delivers versatile functionalities, but also achieves strong
performance, and robustness under noisy observations. More visualizations can
be found on our website https://unified-df.github.io

</details>


### [15] [Pixi: Unified Software Development and Distribution for Robotics and AI](https://arxiv.org/abs/2511.04827)
*Tobias Fischer,Wolf Vollprecht,Bas Zalmstra,Ruben Arts,Tim de Jager,Alejandro Fontan,Adam D Hines,Michael Milford,Silvio Traversaro,Daniel Claes,Scarlett Raine*

Main category: cs.RO

TL;DR: Pixi是一个用于解决科学计算中可重复性危机的统一包管理框架，已被广泛应用于机器人技术研究中。


<details>
  <summary>Details</summary>
Motivation: 解决科学计算中现有机器人算法可重复性不足的问题，克服软件环境设置的复杂性。

Method: 使用高性能SAT求解器来实现依赖关系的快速解析，结合项目级锁文件保障可重复性，同时整合多个包管理生态系统。

Result: Pixi是一个统一的包管理框架，旨在解决科学计算中的可重复性危机，特别是在机器人技术研究中。其通过项目级锁文件捕捉精确的依赖状态，实现跨平台位对位的可重复性。其高性能SAT求解器使得依赖解析速度比类似工具快10倍，并通过整合conda-forge和PyPI生态系统，消除了多个管理工具的需求。Pixi已在2023年后应用于超过5300个项目，显著减少了从几小时到几分钟的设置时间，降低了全球研究人员的技术门槛。

Conclusion: Pixi通过提供可靠的包管理解决方案，促进了机器人和人工智能领域的可重复性和协作研究，推动了相关领域的进步。

Abstract: The reproducibility crisis in scientific computing constrains robotics
research. Existing studies reveal that up to 70% of robotics algorithms cannot
be reproduced by independent teams, while many others fail to reach deployment
because creating shareable software environments remains prohibitively complex.
These challenges stem from fragmented, multi-language, and hardware-software
toolchains that lead to dependency hell. We present Pixi, a unified
package-management framework that addresses these issues by capturing exact
dependency states in project-level lockfiles, ensuring bit-for-bit
reproducibility across platforms. Its high-performance SAT solver achieves up
to 10x faster dependency resolution than comparable tools, while integration of
the conda-forge and PyPI ecosystems removes the need for multiple managers.
Adopted in over 5,300 projects since 2023, Pixi reduces setup times from hours
to minutes and lowers technical barriers for researchers worldwide. By enabling
scalable, reproducible, collaborative research infrastructure, Pixi accelerates
progress in robotics and AI.

</details>


### [16] [Isaac Lab: A GPU-Accelerated Simulation Framework for Multi-Modal Robot Learning](https://arxiv.org/abs/2511.04831)
*NVIDIA,:,Mayank Mittal,Pascal Roth,James Tigue,Antoine Richard,Octi Zhang,Peter Du,Antonio Serrano-Muñoz,Xinjie Yao,René Zurbrügg,Nikita Rudin,Lukasz Wawrzyniak,Milad Rakhsha,Alain Denzler,Eric Heiden,Ales Borovicka,Ossama Ahmed,Iretiayo Akinola,Abrar Anwar,Mark T. Carlson,Ji Yuan Feng,Animesh Garg,Renato Gasoto,Lionel Gulich,Yijie Guo,M. Gussert,Alex Hansen,Mihir Kulkarni,Chenran Li,Wei Liu,Viktor Makoviychuk,Grzegorz Malczyk,Hammad Mazhar,Masoud Moghani,Adithyavairavan Murali,Michael Noseworthy,Alexander Poddubny,Nathan Ratliff,Welf Rehberg,Clemens Schwarke,Ritvik Singh,James Latham Smith,Bingjie Tang,Ruchik Thaker,Matthew Trepte,Karl Van Wyk,Fangzhou Yu,Alex Millane,Vikram Ramasamy,Remo Steiner,Sangeeta Subramanian,Clemens Volk,CY Chen,Neel Jawale,Ashwin Varghese Kuruttukulam,Michael A. Lin,Ajay Mandlekar,Karsten Patzwaldt,John Welsh,Huihua Zhao,Fatima Anes,Jean-Francois Lafleche,Nicolas Moënne-Loccoz,Soowan Park,Rob Stepinski,Dirk Van Gelder,Chris Amevor,Jan Carius,Jumyung Chang,Anka He Chen,Pablo de Heras Ciechomski,Gilles Daviet,Mohammad Mohajerani,Julia von Muralt,Viktor Reutskyy,Michael Sauter,Simon Schirm,Eric L. Shi,Pierre Terdiman,Kenny Vilella,Tobias Widmer,Gordon Yeoman,Tiffany Chen,Sergey Grizan,Cathy Li,Lotus Li,Connor Smith,Rafael Wiltz,Kostas Alexis,Yan Chang,David Chu,Linxi "Jim" Fan,Farbod Farshidian,Ankur Handa,Spencer Huang,Marco Hutter,Yashraj Narang,Soha Pouya,Shiwei Sheng,Yuke Zhu,Miles Macklin,Adam Moravanszky,Philipp Reist,Yunrong Guo,David Hoeller,Gavriel State*

Main category: cs.RO

TL;DR: Isaac Lab是Isaac Gym的自然继承者，通过高级仿真和丰富的传感能力，旨在推动大规模机器人学习和研究的进展。


<details>
  <summary>Details</summary>
Motivation: 延续Isaac Gym的理念，推动大规模多模态学习时代的机器人模拟。

Method: 构建了一个模块化且可组合的架构，集成高保真GPU并行物理、照片级渲染、驱动模型、多频传感器仿真等功能。

Result: 证明了其在全身控制、跨角色移动、接触丰富的精细操控和人类示范技能获取等多样化挑战中的应用。

Conclusion: Isaac Lab将推动机器人研究的下一代突破，结合了高级仿真能力、丰富的传感功能和数据中心级的执行。

Abstract: We present Isaac Lab, the natural successor to Isaac Gym, which extends the
paradigm of GPU-native robotics simulation into the era of large-scale
multi-modal learning. Isaac Lab combines high-fidelity GPU parallel physics,
photorealistic rendering, and a modular, composable architecture for designing
environments and training robot policies. Beyond physics and rendering, the
framework integrates actuator models, multi-frequency sensor simulation, data
collection pipelines, and domain randomization tools, unifying best practices
for reinforcement and imitation learning at scale within a single extensible
platform. We highlight its application to a diverse set of challenges,
including whole-body control, cross-embodiment mobility, contact-rich and
dexterous manipulation, and the integration of human demonstrations for skill
acquisition. Finally, we discuss upcoming integration with the differentiable,
GPU-accelerated Newton physics engine, which promises new opportunities for
scalable, data-efficient, and gradient-based approaches to robot learning. We
believe Isaac Lab's combination of advanced simulation capabilities, rich
sensing, and data-center scale execution will help unlock the next generation
of breakthroughs in robotics research.

</details>


### [17] [Conformalized Non-uniform Sampling Strategies for Accelerated Sampling-based Motion Planning](https://arxiv.org/abs/2511.04835)
*Shubham Natraj,Bruno Sinopoli,Yiannis Kantaros*

Main category: cs.RO

TL;DR: 提出了一种新的非均匀采样策略，用于提高采样基础运动规划器在复杂环境中的效率和规划速度。


<details>
  <summary>Details</summary>
Motivation: 现有的均匀采样运动规划方法在复杂环境中效率低下，急需改进。

Method: 通过生成初始路径并应用保形预测来构建“认证”区域，偏向于这些区域进行非均匀采样。

Result: 新方法在多项评估中表现出更快找到可行路径、在未见过的环境中更好的泛化能力。

Conclusion: 这种新方法在复杂环境中展示出更快的路径找到能力和更好的泛化能力。

Abstract: Sampling-based motion planners (SBMPs) are widely used to compute dynamically
feasible robot paths. However, their reliance on uniform sampling often leads
to poor efficiency and slow planning in complex environments. We introduce a
novel non-uniform sampling strategy that integrates into existing SBMPs by
biasing sampling toward `certified' regions. These regions are constructed by
(i) generating an initial, possibly infeasible, path using any heuristic path
predictor (e.g., A* or vision-language models) and (ii) applying conformal
prediction to quantify the predictor's uncertainty. This process yields
prediction sets around the initial-guess path that are guaranteed, with
user-specified probability, to contain the optimal solution. To our knowledge,
this is the first non-uniform sampling approach for SBMPs that provides such
probabilistically correct guarantees on the sampling regions. Extensive
evaluations demonstrate that our method consistently finds feasible paths
faster and generalizes better to unseen environments than existing baselines.

</details>


### [18] [Design Exploration for Protection and Cleaning of Solar Panels with Case Studies for Space Missions](https://arxiv.org/abs/2511.04837)
*Cameron Robinson,Ganghee Jang*

Main category: cs.RO

TL;DR: 研究了太阳能面板清洁机制和保护材料，发现刮板系统在成本、清洁速度和总电力消耗方面优于轨道系统，同时聚碳酸酯材料在碰撞测试中表现出优良的保护性，特别是需要在硬材料与面板表面之间层叠软材料。


<details>
  <summary>Details</summary>
Motivation: 太阳能在空间探索和监测野火等关键任务中的重要性，促使我们解决面板受尘埃和碎片影响的清洁和保护问题。

Method: 我们设计并比较了刮板系统和轨道系统的清洁机制，并通过碰撞测试评估不同保护材料的效果。

Result: 本文提出了一种解决太阳能面板因尘埃覆盖或太空碎片冲击而导致的操作限制或终止问题的方案，通过设计清洁机制和测试保护材料来实现。

Conclusion: 清洁系统中的刮板式系统比轨道式系统在多项指标上表现更佳，而在材料保护方面，聚碳酸酯和软材料层叠的组合为关键。

Abstract: Solar energy is used for many mission-critical applications including space
exploration, sensor systems to monitor wildfires, etc. Their operation can be
limited or even terminated if solar panels are covered with dust or hit by
space debris. To address this issue, we designed panel cleaning mechanisms and
tested protective materials. For cleaning mechanisms, we designed and compared
a wiper system and a rail system. For protective materials, we found through
collision tests that polycarbonate was very promising, though the most
important factor was layering a soft material between the panel's surface and a
hard material. In the cleaning system comparisons, the wiper-based system was
more efficient than the rail-based system in terms of cost, cleaning speed, and
total power consumption.

</details>


### [19] [iFlyBot-VLM Technical Report](https://arxiv.org/abs/2511.04976)
*Xin Nie,Zhiyuan Cheng,Yuan Zhang,Chao Ji,Jiajia Wu,Yuhan Zhang,Jia Pan*

Main category: cs.RO

TL;DR: iFlyBot-VLM是一种新型通用视觉-语言模型，旨在提高体现智能的任务表现，通过四个关键功能支持感知-行动协调。


<details>
  <summary>Details</summary>
Motivation: 推动体现智能的发展，并实现任务系统到通用代理的转变，提升机器人在复杂环境中的表现。

Method: 模型通过抽象复杂视觉和空间信息，生成与身体无关、可迁移的操作语言，支持感知-行动闭环协调。

Result: 本文介绍了iFlyBot-VLM，一种用于提升体现智能领域的通用视觉-语言模型（VLM）。该模型的核心目标是弥合高维环境感知与低级机器人运动控制之间的跨模态语义差距。

Conclusion: iFlyBot-VLM被视为体现人工智能的可扩展基础模型，有助于从专门任务系统向普适认知能力代理的发展。

Abstract: We introduce iFlyBot-VLM, a general-purpose Vision-Language Model (VLM) used
to improve the domain of Embodied Intelligence. The central objective of
iFlyBot-VLM is to bridge the cross-modal semantic gap between high-dimensional
environmental perception and low-level robotic motion control. To this end, the
model abstracts complex visual and spatial information into a body-agnostic and
transferable Operational Language, thereby enabling seamless perception-action
closed-loop coordination across diverse robotic platforms. The architecture of
iFlyBot-VLM is systematically designed to realize four key functional
capabilities essential for embodied intelligence: 1) Spatial Understanding and
Metric Reasoning; 2) Interactive Target Grounding; 3) Action Abstraction and
Control Parameter Generation; 4) Task Planning and Skill Sequencing. We
envision iFlyBot-VLM as a scalable and generalizable foundation model for
embodied AI, facilitating the progression from specialized task-oriented
systems toward generalist, cognitively capable agents. We conducted evaluations
on 10 current mainstream embodied intelligence-related VLM benchmark datasets,
such as Blink and Where2Place, and achieved optimal performance while
preserving the model's general capabilities. We will publicly release both the
training data and model weights to foster further research and development in
the field of Embodied Intelligence.

</details>


### [20] [A semi-analytical approach for computing the largest singularity-free spheres of a class of 6-6 Stewart-Gough platforms for specified orientation workspaces](https://arxiv.org/abs/2511.04992)
*Bibekananda Patra,Sandipan Bandyopadhyay*

Main category: cs.RO

TL;DR: 提出了一种计算6-6 SGPM最大无奇点球的分析方法，并通过数值实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 确定给定方向工作空间中SGPM的最佳设计和性能。

Method: 分析计算6-6斯图尔特-戈夫平台操纵器（SGPM）的最大无奇点球（SFS）。

Result: 通过对四种不同架构的SGPM进行数值实验，比较了它们在相同方向工作空间中的SFS体积。

Conclusion: 该方法在SGPM的分析和设计中具有潜在的实用价值。

Abstract: This article presents a method for computing the largest singularity-free
sphere (SFS) of a 6-6 Stewart-Gough platform manipulator (SGPM) over a
specified orientation workspace. For a fixed orientation of the moving
platform, the SFS is computed analytically. This process is repeated over a set
of samples generated within the orientation workspace, and the smallest among
them is designated as the desired SFS for the given orientation workspace.
Numerical experiments are performed on four distinct architectures of the SGPM
to understand their relative performances w.r.t. SFS volumes over the same
orientation workspace. This study demonstrates the potential utility of the
proposed computational method both in analysis and design of SGPMs.

</details>


### [21] [Encoding Biomechanical Energy Margin into Passivity-based Synchronization for Networked Telerobotic Systems](https://arxiv.org/abs/2511.04994)
*Xingyuan Zhou,Peter Paik,S. Farokh Atashzar*

Main category: cs.RO

TL;DR: 本文提出了一种新型的基于生物力学的稳定器TBPS2，旨在解决网络机器人系统中的位置同步问题，并在实验中表现优异。


<details>
  <summary>Details</summary>
Motivation: 在网络机器人系统中特别是在实现人机交互的过程中，维护系统的稳定性和准确的位置跟踪至关重要，目前文献对生物力学的应用有所进展，但仍面临着通信不完美带来的位置不同步问题。

Method: 通过数学设计合成，提出了基于人机生物力学的两端口被动同步器和稳定器，并进行了稳定性证明。

Result: 通过与现有技术的比较，TBPS2在不同时间延迟和环境条件下的表现优于现代解决方案，展示了人机生物力学整合的潜力。

Conclusion: 提出的TBPS2稳定器在多种环境条件下表现出更优的同步性能，有效解决了由于通信不完善导致的位置信步采不同步的问题。

Abstract: Maintaining system stability and accurate position tracking is imperative in
networked robotic systems, particularly for haptics-enabled human-robot
interaction. Recent literature has integrated human biomechanics into the
stabilizers implemented for teleoperation, enhancing force preservation while
guaranteeing convergence and safety. However, position desynchronization due to
imperfect communication and non-passive behaviors remains a challenge. This
paper proposes a two-port biomechanics-aware passivity-based synchronizer and
stabilizer, referred to as TBPS2. This stabilizer optimizes position
synchronization by leveraging human biomechanics while reducing the
stabilizer's conservatism in its activation. We provide the mathematical design
synthesis of the stabilizer and the proof of stability. We also conducted a
series of grid simulations and systematic experiments, comparing their
performance with that of state-of-the-art solutions under varying time delays
and environmental conditions.

</details>


### [22] [MoE-DP: An MoE-Enhanced Diffusion Policy for Robust Long-Horizon Robotic Manipulation with Skill Decomposition and Failure Recovery](https://arxiv.org/abs/2511.05007)
*Baiye Cheng,Tianhai Liang,Suning Huang,Maanping Shao,Feihong Zhang,Botian Xu,Zhengrong Xue,Huazhe Xu*

Main category: cs.RO

TL;DR: 提出了一种增强的扩散政策框架MoE-DP，利用专家混合层提高机器人控制任务的鲁棒性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散政策在长时间多阶段任务中的鲁棒性不足，且学习到的观察表示难以解释，因此需要改进。

Method: 在视觉编码器和扩散模型之间插入一个专家混合层，动态激活不同专家处理任务的不同阶段。

Result: 在6个长时间模拟任务中，MoE-DP在扰动条件下成功率平均提高了36%。

Conclusion: MoE-DP在长时间模拟任务中表现出显著的鲁棒性，提高了成功率，并在真实环境中验证了其性能优势。

Abstract: Diffusion policies have emerged as a powerful framework for robotic
visuomotor control, yet they often lack the robustness to recover from subtask
failures in long-horizon, multi-stage tasks and their learned representations
of observations are often difficult to interpret. In this work, we propose the
Mixture of Experts-Enhanced Diffusion Policy (MoE-DP), where the core idea is
to insert a Mixture of Experts (MoE) layer between the visual encoder and the
diffusion model. This layer decomposes the policy's knowledge into a set of
specialized experts, which are dynamically activated to handle different phases
of a task. We demonstrate through extensive experiments that MoE-DP exhibits a
strong capability to recover from disturbances, significantly outperforming
standard baselines in robustness. On a suite of 6 long-horizon simulation
tasks, this leads to a 36% average relative improvement in success rate under
disturbed conditions. This enhanced robustness is further validated in the real
world, where MoE-DP also shows significant performance gains. We further show
that MoE-DP learns an interpretable skill decomposition, where distinct experts
correspond to semantic task primitives (e.g., approaching, grasping). This
learned structure can be leveraged for inference-time control, allowing for the
rearrangement of subtasks without any re-training.Our video and code are
available at the https://moe-dp-website.github.io/MoE-DP-Website/.

</details>


### [23] [Tunable Passivity Control for Centralized Multiport Networked Systems](https://arxiv.org/abs/2511.05026)
*Xingyuan Zhou,Peter Paik,S. Farokh Atashzar*

Main category: cs.RO

TL;DR: 本论文提出了一种集中式最佳被动控制框架，以解决CMND系统中的稳定性问题，优化性能并增强可扩展性。


<details>
  <summary>Details</summary>
Motivation: 解决CMND系统中由于非理想网络环境导致的稳定性问题，克服传统被动稳定器的局限性。

Method: Tunable Centralized Optimal Passivity Control (TCoPC)

Result: 提出了一个集中式最佳被动控制框架，可以根据需求在各个节点间分配必要的耗散，确保L2稳定性。

Conclusion: 该框架在不同时间延迟情况下的复杂任务中表现优秀，提升了系统的可扩展性和通用性。

Abstract: Centralized Multiport Networked Dynamic (CMND) systems have emerged as a key
architecture with applications in several complex network systems, such as
multilateral telerobotics and multi-agent control. These systems consist of a
hub node/subsystem connecting with multiple remote nodes/subsystems via a
networked architecture. One challenge for this system is stability, which can
be affected by non-ideal network artifacts. Conventional passivity-based
approaches can stabilize the system under specialized applications like
small-scale networked systems. However, those conventional passive stabilizers
have several restrictions, such as distributing compensation across subsystems
in a decentralized manner, limiting flexibility, and, at the same time, relying
on the restrictive assumptions of node passivity. This paper synthesizes a
centralized optimal passivity-based stabilization framework for CMND systems.
It consists of a centralized passivity observer monitoring overall energy flow
and an optimal passivity controller that distributes the just-needed
dissipation among various nodes, guaranteeing strict passivity and, thus, L2
stability. The proposed data-driven model-free approach, i.e., Tunable
Centralized Optimal Passivity Control (TCoPC), optimizes total performance
based on the prescribed dissipation distribution strategy while ensuring
stability. The controller can put high dissipation loads on some sub-networks
while relaxing the dissipation on other nodes. Simulation results demonstrate
the proposed frameworks performance in a complex task under different
time-varying delay scenarios while relaxing the remote nodes minimum phase and
passivity assumption, enhancing the scalability and generalizability.

</details>


### [24] [Epically Powerful: An open-source software and mechatronics infrastructure for wearable robotic systems](https://arxiv.org/abs/2511.05033)
*Jennifer K. Leestma,Siddharth R. Nathella,Christoph P. O. Nuesslein,Snehil Mathur,Gregory S. Sawicki,Aaron J. Young*

Main category: cs.RO

TL;DR: Epically Powerful是一个旨在简化可穿戴机器人系统开发的开源框架，支持多种硬件和软件功能，并提供详细文档和建议配件列表。


<details>
  <summary>Details</summary>
Motivation: 旨在快速有效地将原始硬件转变为模块化且强大的设备，支持研究人员开发和部署可穿戴机器人系统。

Method: 通过Python编写代码，支持与QDD执行器、单板计算机和常见传感器无缝接口，实现实时可视化和示例控制器。

Result: Epically Powerful是一个开源机器人基础设施，旨在精简可穿戴机器人系统的底层框架，通过管理通信协议、时钟、执行器命令、可视化、传感器数据采集、数据记录等功能，同时提供硬件选择、系统组装和控制器实现的全面指南。

Conclusion: Epically Powerful降低了开发和部署定制可穿戴机器人系统的门槛，适用于多种机器人领域。

Abstract: Epically Powerful is an open-source robotics infrastructure that streamlines
the underlying framework of wearable robotic systems - managing communication
protocols, clocking, actuator commands, visualization, sensor data acquisition,
data logging, and more - while also providing comprehensive guides for hardware
selection, system assembly, and controller implementation. Epically Powerful
contains a code base enabling simplified user implementation via Python that
seamlessly interfaces with various commercial state-of-the-art quasi-direct
drive (QDD) actuators, single-board computers, and common sensors, provides
example controllers, and enables real-time visualization. To further support
device development, the package also includes a recommended parts list and
compatibility guide and detailed documentation on hardware and software
implementation. The goal of Epically Powerful is to lower the barrier to
developing and deploying custom wearable robotic systems without a
pre-specified form factor, enabling researchers to go from raw hardware to
modular, robust devices quickly and effectively. Though originally designed
with wearable robotics in mind, Epically Powerful is broadly applicable to
other robotic domains that utilize QDD actuators, single-board computers, and
sensors for closed-loop control.

</details>


### [25] [TAPOM: Task-Space Topology-Guided Motion Planning for Manipulating Elongated Object in Cluttered Environments](https://arxiv.org/abs/2511.05052)
*Zihao Li,Yiming Zhu,Zhe Zhong,Qinyuan Ren,Yijiang Huang*

Main category: cs.RO

TL;DR: TAPOM通过任务空间的拓扑分析来提高低清晰度环境下的机器人操作效率，实验结果显示其成功率和效率显著高于现有方法。


<details>
  <summary>Details</summary>
Motivation: 复杂受限空间中的机器人操作对于广泛应用至关重要，但在狭窄通道中操作拉长物体时，现有规划方法常常失效，因此需要一种新的规划框架。

Method: TAPOM结合高层次拓扑分析识别关键通道，生成引导关键帧并在低层次规划中寻找可行的配置空间轨迹。

Result: 本研究提出了一种名为拓扑感知规划的对象操作方法（TAPOM），旨在解决在复杂受限空间中进行机器人操作的挑战，特别是在窄通道内使用拉长物体时。

Conclusion: TAPOM方法有效提高了机器人在复杂受限环境中的操作能力，具有广泛的应用前景。

Abstract: Robotic manipulation in complex, constrained spaces is vital for widespread
applications but challenging, particularly when navigating narrow passages with
elongated objects. Existing planning methods often fail in these low-clearance
scenarios due to the sampling difficulties or the local minima. This work
proposes Topology-Aware Planning for Object Manipulation (TAPOM), which
explicitly incorporates task-space topological analysis to enable efficient
planning. TAPOM uses a high-level analysis to identify critical pathways and
generate guiding keyframes, which are utilized in a low-level planner to find
feasible configuration space trajectories. Experimental validation demonstrates
significantly high success rates and improved efficiency over state-of-the-art
methods on low-clearance manipulation tasks. This approach offers broad
implications for enhancing manipulation capabilities of robots in complex
real-world environments.

</details>


### [26] [Decomposed Object Manipulation via Dual-Actor Policy](https://arxiv.org/abs/2511.05129)
*Bin Fan,Jianjian Jiang,Zhuohao Li,Yixiang He,Xiaoming Wu,Yihan Yang,Shengbang Liu,Weishi Zheng*

Main category: cs.RO

TL;DR: 研究提出了一种双演员策略，显著提高了物体操作任务的性能，解决了传统方法的一些局限。


<details>
  <summary>Details</summary>
Motivation: 物体操作任务被划分为接近阶段和操作阶段，传统方法未能充分利用这一区分，因此需要一种新方法来改进这一过程。

Method: 提出了一种双演员策略，分别处理物体接近和操作的不同阶段，采用基于功能的演员和基于运动流的演员，并引入决策者确定当前阶段。

Result: 在模拟数据集、RoboTwin基准和真实场景中的实验结果显示，该方法平均优于现有最佳方法5.55%、14.7%和10.4%。

Conclusion: 提出的双演员策略在物体操作中的性能优于现有方法，显示了其在分阶段学习和利用不同视觉先验方面的有效性。

Abstract: Object manipulation, which focuses on learning to perform tasks on similar
parts across different types of objects, can be divided into an approaching
stage and a manipulation stage. However, previous works often ignore this
characteristic of the task and rely on a single policy to directly learn the
whole process of object manipulation. To address this problem, we propose a
novel Dual-Actor Policy, termed DAP, which explicitly considers different
stages and leverages heterogeneous visual priors to enhance each stage.
Specifically, we introduce an affordance-based actor to locate the functional
part in the manipulation task, thereby improving the approaching process.
Following this, we propose a motion flow-based actor to capture the movement of
the component, facilitating the manipulation process. Finally, we introduce a
decision maker to determine the current stage of DAP and select the
corresponding actor. Moreover, existing object manipulation datasets contain
few objects and lack the visual priors needed to support training. To address
this, we construct a simulated dataset, the Dual-Prior Object Manipulation
Dataset, which combines the two visual priors and includes seven tasks,
including two challenging long-term, multi-stage tasks. Experimental results on
our dataset, the RoboTwin benchmark and real-world scenarios illustrate that
our method consistently outperforms the SOTA method by 5.55%, 14.7% and 10.4%
on average respectively.

</details>


### [27] [Follow-Me in Micro-Mobility with End-to-End Imitation Learning](https://arxiv.org/abs/2511.05158)
*Sahar Salimpour,Iacopo Catalano,Tomi Westerlund,Mohsen Falahi,Jorge Peña Queralta*

Main category: cs.RO

TL;DR: 本研究探讨了自主轮椅在跟随模式下的舒适度，提出模仿学习作为改善微移动平台控制器性能的方法。


<details>
  <summary>Details</summary>
Motivation: 研究如何在大型室内空间或城市环境中，优化自主微移动平台的用户舒适度和整体用户体验，尤其在商业应用中的重要性。

Method: 使用模仿学习技术，对不同的神经网络架构进行分析，以实现端到端控制。

Result: 通过模仿学习，开发出比手动调优的控制器更加平稳和更好的控制方案。

Conclusion: 不同的神经网络架构被分析并证明在实际生产级部署中的可用性，从而提升了自主轮椅的用户体验。

Abstract: Autonomous micro-mobility platforms face challenges from the perspective of
the typical deployment environment: large indoor spaces or urban areas that are
potentially crowded and highly dynamic. While social navigation algorithms have
progressed significantly, optimizing user comfort and overall user experience
over other typical metrics in robotics (e.g., time or distance traveled) is
understudied. Specifically, these metrics are critical in commercial
applications. In this paper, we show how imitation learning delivers smoother
and overall better controllers, versus previously used manually-tuned
controllers. We demonstrate how DAAV's autonomous wheelchair achieves
state-of-the-art comfort in follow-me mode, in which it follows a human
operator assisting persons with reduced mobility (PRM). This paper analyzes
different neural network architectures for end-to-end control and demonstrates
their usability in real-world production-level deployments.

</details>


### [28] [Procedimiento de auditoría de ciberseguridad para sistemas autónomos: metodología, amenazas y mitigaciones](https://arxiv.org/abs/2511.05185)
*Adrián Campazas-Vega,Claudia Álvarez-Aparicio,David Sobrín-Hidalgo,Laura Inyesto-Alonso,Francisco Javier Rodríguez-Lera,Vicente Matellán-Olivera,Ángel Manuel Guerrero-Higueras*

Main category: cs.RO

TL;DR: 本论文提出了一种新的安全审计程序，旨在解决自主系统面临的安全问题，并在多个案例中进行了验证。


<details>
  <summary>Details</summary>
Motivation: 随着自主系统的快速发展，其在各种领域的应用以及由此引发的安全问题促使研究高效的安全审计程序。

Method: 使用分层结构的方法，结合适应于机器人上下文的威胁分类法，并提供具体的缓解措施。

Result: 通过对四个代表性机器人平台的案例研究验证了所提方法的有效性。

Conclusion: 提出了一种基于分层结构的方法的安全审计程序，以应对自主系统的安全问题。

Abstract: The deployment of autonomous systems has experienced remarkable growth in
recent years, driven by their integration into sectors such as industry,
medicine, logistics, and domestic environments. This expansion is accompanied
by a series of security issues that entail significant risks due to the
critical nature of autonomous systems, especially those operating in
human-interaction environments. Furthermore, technological advancement and the
high operational and architectural complexity of autonomous systems have
resulted in an increased attack surface. This article presents a specific
security auditing procedure for autonomous systems, based on a layer-structured
methodology, a threat taxonomy adapted to the robotic context, and a set of
concrete mitigation measures. The validity of the proposed approach is
demonstrated through four practical case studies applied to representative
robotic platforms: the Vision 60 military quadruped from Ghost Robotics, the A1
robot from Unitree Robotics, the UR3 collaborative arm from Universal Robots,
and the Pepper social robot from Aldebaran Robotics.

</details>


### [29] [Let Me Show You: Learning by Retrieving from Egocentric Video for Robotic Manipulation](https://arxiv.org/abs/2511.05199)
*Yichen Zhu,Feifei Feng*

Main category: cs.RO

TL;DR: 本文提出了一种通过视频获取学习机器人策略的方法，结合中间信息提升机器人的学习能力，从而在多场景下展示出卓越的性能。


<details>
  <summary>Details</summary>
Motivation: 人类面对不熟悉任务时通常通过观看视频学习，本文旨在借鉴这一方法，以提高机器人在复杂任务中的适应性和灵活性。

Method: 该方法构建了一个视频库，提取了中间层信息，并使用一个双组件系统，包括视频检索器和策略生成器，以增强学习和泛化能力。

Result: 该论文提出了一种新颖的机器人学习方法，通过视频学习与人类的示范进行类比，来解决复杂的不确定环境中的操作任务。

Conclusion: 经过多种模拟和真实环境的严格测试，该系统在性能上显著优于传统机器人系统，标志着机器人技术领域的重大突破。

Abstract: Robots operating in complex and uncertain environments face considerable
challenges. Advanced robotic systems often rely on extensive datasets to learn
manipulation tasks. In contrast, when humans are faced with unfamiliar tasks,
such as assembling a chair, a common approach is to learn by watching video
demonstrations. In this paper, we propose a novel method for learning robot
policies by Retrieving-from-Video (RfV), using analogies from human
demonstrations to address manipulation tasks. Our system constructs a video
bank comprising recordings of humans performing diverse daily tasks. To enrich
the knowledge from these videos, we extract mid-level information, such as
object affordance masks and hand motion trajectories, which serve as additional
inputs to enhance the robot model's learning and generalization capabilities.
We further feature a dual-component system: a video retriever that taps into an
external video bank to fetch task-relevant video based on task specification,
and a policy generator that integrates this retrieved knowledge into the
learning cycle. This approach enables robots to craft adaptive responses to
various scenarios and generalize to tasks beyond those in the training data.
Through rigorous testing in multiple simulated and real-world settings, our
system demonstrates a marked improvement in performance over conventional
robotic systems, showcasing a significant breakthrough in the field of
robotics.

</details>


### [30] [Beyond Master and Apprentice: Grounding Foundation Models for Symbiotic Interactive Learning in a Shared Latent Space](https://arxiv.org/abs/2511.05203)
*Linus Nwankwo,Björn Ellensohn,Christian Rauch,Elmar Rueckert*

Main category: cs.RO

TL;DR: 本文提出了共生互动学习（SIL）方法，允许自主机器人与人类通过双向互动实现共同适应，超越传统的被动执行模式。


<details>
  <summary>Details</summary>
Motivation: 当前的自主代理能够理解自由形式的自然语言指令并执行长时间任务，但与人类的互动缺乏双向学习，主要保持被动接受指令的关系。这种反应式互动无法体现日常多轮人际交流中的共适应动态。

Method: 将大规模预训练的基础模型与轻量级潜在编码器结合，以空间感知和推理为基础，确保在任务演变过程中维护学习的任务空间表示，进而实现共享的澄清和建议。

Result: 提出了一种名为共生互动学习（SIL）的方法，使得人类和代理能够通过双向互交进行共同适应，并在共享的潜在任务空间内维持共同的信念状态。而且，SIL能够支持代理从被动执行转变为主动澄清、适应性建议和共同计划的细化。

Conclusion: 通过在模拟和真实世界任务上验证SIL，本研究展示了其在指令遵循、信息检索、查询导向推理和互动对话等方面的有效性，并提供了公开的演示和资源。

Abstract: Today's autonomous agents can understand free-form natural language
instructions and execute long-horizon tasks in a manner akin to human-level
reasoning. These capabilities are mostly driven by large-scale pre-trained
foundation models (FMs). However, the approaches with which these models are
grounded for human-robot interaction (HRI) perpetuate a master-apprentice
model, where the apprentice (embodied agent) passively receives and executes
the master's (human's) commands without reciprocal learning. This reactive
interaction approach does not capture the co-adaptive dynamics inherent in
everyday multi-turn human-human interactions. To address this, we propose a
Symbiotic Interactive Learning (SIL) approach that enables both the master and
the apprentice to co-adapt through mutual, bidirectional interactions. We
formalised SIL as a co-adaptation process within a shared latent task space,
where the agent and human maintain joint belief states that evolve based on
interaction history. This enables the agent to move beyond reactive execution
to proactive clarification, adaptive suggestions, and shared plan refinement.
To realise these novel behaviours, we leveraged pre-trained FMs for spatial
perception and reasoning, alongside a lightweight latent encoder that grounds
the models' outputs into task-specific representations. Furthermore, to ensure
stability as the tasks evolve, we augment SIL with a memory architecture that
prevents the forgetting of learned task-space representations. We validate SIL
on both simulated and real-world embodied tasks, including instruction
following, information retrieval, query-oriented reasoning, and interactive
dialogues. Demos and resources are public
at:~\href{https://linusnep.github.io/SIL/}{https://linusnep.github.io/SIL/}.

</details>


### [31] [Context-aware Learned Mesh-based Simulation via Trajectory-Level Meta-Learning](https://arxiv.org/abs/2511.05234)
*Philipp Dahlinger,Niklas Freymuth,Tai Hoang,Tobias Würth,Michael Volpp,Luise Kärger,Gerhard Neumann*

Main category: cs.RO

TL;DR: M3GN 通过条件神经过程和运动原语框架，提供了在多个任务中实现更高仿真准确性和降低运行时间成本的创新仿真方法。


<details>
  <summary>Details</summary>
Motivation: 现有的学习仿真器依赖于单步观察，无法充分利用时间上下文并容易在长期轨迹中积累误差，因此需要一种新的方法来改进仿真准确性和效率。

Method: M3GN 方法利用条件神经过程，将基于网格的仿真框架视为轨迹级别的元学习问题，通过运动原语直接预测快速、稳定和精确的仿真。

Result: M3GN 在运行时间成本上相较于最先进的 GNS 提供了更高的仿真准确性，能够从有限的初始数据快速适应新的仿真场景。

Conclusion: M3GN 方法在多个任务上提供了更高的仿真准确性，同时大幅降低了运行时间成本。

Abstract: Simulating object deformations is a critical challenge across many scientific
domains, including robotics, manufacturing, and structural mechanics. Learned
Graph Network Simulators (GNSs) offer a promising alternative to traditional
mesh-based physics simulators. Their speed and inherent differentiability make
them particularly well suited for applications that require fast and accurate
simulations, such as robotic manipulation or manufacturing optimization.
However, existing learned simulators typically rely on single-step
observations, which limits their ability to exploit temporal context. Without
this information, these models fail to infer, e.g., material properties.
Further, they rely on auto-regressive rollouts, which quickly accumulate error
for long trajectories. We instead frame mesh-based simulation as a
trajectory-level meta-learning problem. Using Conditional Neural Processes, our
method enables rapid adaptation to new simulation scenarios from limited
initial data while capturing their latent simulation properties. We utilize
movement primitives to directly predict fast, stable and accurate simulations
from a single model call. The resulting approach, Movement-primitive
Meta-MeshGraphNet (M3GN), provides higher simulation accuracy at a fraction of
the runtime cost compared to state-of-the-art GNSs across several tasks.

</details>


### [32] [TwinVLA: Data-Efficient Bimanual Manipulation with Twin Single-Arm Vision-Language-Action Models](https://arxiv.org/abs/2511.05275)
*Hokyun Im,Euijin Jeong,Jianlong Fu,Andrey Kolobov,Youngwoon Lee*

Main category: cs.RO

TL;DR: TwinVLA是一个模块化框架，通过组合预训练的单臂模型，提高了双臂操控任务的数据效率和性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有视觉-语言-动作模型在双臂操控任务上需要大量额外数据和调整的问题

Method: TwinVLA将两个预训练的单臂视觉-语言-动作模型组合成一个协调的双臂模型。

Result: TwinVLA在多样的双臂任务中超越了比较相当规模的单一大型模型，而无需双臂预训练

Conclusion: 我们的模块化组合方法提供了一条高效、可扩展的路径，以实现高性能的双臂操控，充分利用公共的单臂数据。

Abstract: Vision-language-action models (VLAs) trained on large-scale robotic datasets
have demonstrated strong performance on manipulation tasks, including bimanual
tasks. However, because most public datasets focus on single-arm
demonstrations, adapting VLAs for bimanual tasks typically requires substantial
additional bimanual data and fine-tuning. To address this challenge, we
introduce TwinVLA, a modular framework that composes two copies of a pretrained
single-arm VLA into a coordinated bimanual VLA. Unlike monolithic
cross-embodiment models trained on mixtures of single-arm and bimanual data,
TwinVLA improves both data efficiency and performance by composing pretrained
single-arm policies. Across diverse bimanual tasks in real-world and simulation
settings, TwinVLA outperforms a comparably-sized monolithic RDT-1B model
without requiring any bimanual pretraining. Furthermore, it narrows the gap to
state-of-the-art model, $\pi_0$ which rely on extensive proprietary bimanual
data and compute cost. These results establish our modular composition approach
as a data-efficient and scalable path toward high-performance bimanual
manipulation, leveraging public single-arm data.

</details>


### [33] [Force-Safe Environment Maps and Real-Time Detection for Soft Robot Manipulators](https://arxiv.org/abs/2511.05307)
*Akua K. Dickson,Juan C. Pacheco Garcia,Andrew P. Sabelhaus*

Main category: cs.RO

TL;DR: 该研究提出了一种实时检测软机器人在复杂环境中与脆弱障碍物交互时力安全的新框架，有效避免过大接触力造成的损害。


<details>
  <summary>Details</summary>
Motivation: 现有障碍物检测方法未考虑机器人与脆弱障碍物接触时施加的力限制，因此亟需一种新的方法来确保机器人安全操作。

Method: 通过将任务空间中的力安全标准映射到配置空间，结合前向运动学实现力安全检测。

Result: 在模拟和硬件实验中验证了该方法的有效性，结果表明其能够准确检测与可变形障碍物的力安全性。

Conclusion: 本文提出的方法能够实时检测软机器人在与可变形障碍物相互作用时的力安全性，为此类机器人的安全规划奠定基础。

Abstract: Soft robot manipulators have the potential for deployment in delicate
environments to perform complex manipulation tasks. However, existing obstacle
detection and avoidance methods do not consider limits on the forces that
manipulators may exert upon contact with delicate obstacles. This work
introduces a framework that maps force safety criteria from task space (i.e.
positions along the robot's body) to configuration space (i.e. the robot's
joint angles) and enables real-time force safety detection. We incorporate
limits on allowable environmental contact forces for given task-space
obstacles, and map them into configuration space (C-space) through the
manipulator's forward kinematics. This formulation ensures that configurations
classified as safe are provably below the maximum force thresholds, thereby
allowing us to determine force-safe configurations of the soft robot
manipulator in real-time. We validate our approach in simulation and hardware
experiments on a two-segment pneumatic soft robot manipulator. Results
demonstrate that the proposed method accurately detects force safety during
interactions with deformable obstacles, thereby laying the foundation for
real-time safe planning of soft manipulators in delicate, cluttered
environments.

</details>


### [34] [ETHOS: A Robotic Encountered-Type Haptic Display for Social Interaction in Virtual Reality](https://arxiv.org/abs/2511.05379)
*Eric Godden,Jacquie Groenewegen,Matthew K. X. J. Pan*

Main category: cs.RO

TL;DR: ETHOS系统通过自然物理接触提升了虚拟现实中的社交互动，展示了可行的高保真触觉再现技术。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在增强虚拟现实中的社交互动体验，尤其是通过自然的物理接触来提升互动的真实感。

Method: ETHOS系统集成了一个扭矩控制的机器人操控器与可更换的被动道具，同时使用基于标记的物理-虚拟注册和安全监控机制。

Result: 测试显示，静态对位精度为5.09±0.94毫米，用户交互的平均接触延迟为28.53±31.21毫秒，表明可以有效地在VR中重现社交触觉。

Conclusion: ETHOS为高保真动态人际交互在虚拟环境中奠定了实用基础，使得社交触觉在VR中得以重现。

Abstract: We present ETHOS (Encountered-Type Haptics for On-demand Social Interaction),
a dynamic encountered-type haptic display (ETHD) that enables natural physical
contact in virtual reality (VR) during social interactions such as handovers,
fist bumps, and high-fives. The system integrates a torque-controlled robotic
manipulator with interchangeable passive props (silicone hand replicas and a
baton), marker-based physical-virtual registration via a ChArUco board, and a
safety monitor that gates motion based on the user's head and hand pose. We
introduce two control strategies: (i) a static mode that presents a stationary
prop aligned with its virtual counterpart, consistent with prior ETHD
baselines, and (ii) a dynamic mode that continuously updates prop position by
exponentially blending an initial mid-point trajectory with real-time hand
tracking, generating a unique contact point for each interaction. Bench tests
show static colocation accuracy of 5.09 +/- 0.94 mm, while user interactions
achieved temporal alignment with an average contact latency of 28.53 +/- 31.21
ms across all interaction and control conditions. These results demonstrate the
feasibility of recreating socially meaningful haptics in VR. By incorporating
essential safety and control mechanisms, ETHOS establishes a practical
foundation for high-fidelity, dynamic interpersonal interactions in virtual
environments.

</details>


### [35] [EveryDayVLA: A Vision-Language-Action Model for Affordable Robotic Manipulation](https://arxiv.org/abs/2511.05397)
*Samarth Chopra,Alex McMoil,Ben Carnovale,Evan Sokolson,Rajkumar Kubendran,Samuel Dickerson*

Main category: cs.RO

TL;DR: EverydayVLA是一款低成本的机器人操纵器，结合先进的视觉-语言-动作模型，提高了机器人在复杂环境中的操作能力。


<details>
  <summary>Details</summary>
Motivation: 研究的动力在于降低机器人操作的成本和复杂性，使得更多用户能够接触和使用机器人技术，特别是在家庭和科研环境中。

Method: 本研究采用联合输出离散和连续动作的统一模型，并通过自适应时间水平集成监控运动不确定性，从而实现安全可靠的操作和实时重新规划。

Result: 本论文提出了EverydayVLA，这是一个成本低于300美元的6-DOF操纵器，能够将视觉输入和语言指令映射到机器人动作，解决了现有模型在新场景和杂乱环境中的局限性。

Conclusion: EverydayVLA通过将高效的视觉-语言-动作模型与经济实惠的硬件相结合，显著提高了机器人操作在家庭和研究实验室的可及性。

Abstract: While Vision-Language-Action (VLA) models map visual inputs and language
instructions directly to robot actions, they often rely on costly hardware and
struggle in novel or cluttered scenes. We introduce EverydayVLA, a 6-DOF
manipulator that can be assembled for under $300, capable of modest payloads
and workspace. A single unified model jointly outputs discrete and continuous
actions, and our adaptive-horizon ensemble monitors motion uncertainty to
trigger on-the-fly re-planning for safe, reliable operation. On LIBERO,
EverydayVLA matches state-of-the-art success rates, and in real-world tests it
outperforms prior methods by 49% in-distribution and 34.9% out-of-distribution.
By combining a state-of-the-art VLA with cost-effective hardware, EverydayVLA
democratizes access to a robotic foundation model and paves the way for
economical use in homes and research labs alike. Experiment videos and details:
https://everydayvla.github.io/

</details>


### [36] [Stable and Robust SLIP Model Control via Energy Conservation-Based Feedback Cancellation for Quadrupedal Applications](https://arxiv.org/abs/2511.05402)
*Muhammad Saud Ul Hassan,Derek Vasquez,Hamza Asif,Christian Hubicki*

Main category: cs.RO

TL;DR: 本研究为四足机器人提供了一种基于能量守恒的控制方法，成功模拟了自然四足生物的跳跃运动。


<details>
  <summary>Details</summary>
Motivation: 开发一个基于能量守恒的控制架构，以实现四足机器人的稳定动态运动。

Method: 将四足机器人建模为弹簧负载倒摆（SLIP），使用简化的SLIP动力学，通过能量守恒原理跟踪稳定的抛物线样条。

Result: 提出的控制算法能够生成稳定的跳跃步态，且在传感器测量误差达到10%的情况下仍能保持稳定。

Conclusion: 通过对Ghost Robotics Minitaur的仿真，证明了所提控制算法在实际应用中的有效性与鲁棒性。

Abstract: In this paper, we present an energy-conservation based control architecture
for stable dynamic motion in quadruped robots. We model the robot as a
Spring-loaded Inverted Pendulum (SLIP), a model well-suited to represent the
bouncing motion characteristic of running gaits observed in various biological
quadrupeds and bio-inspired robotic systems. The model permits leg-orientation
control during flight and leg-length control during stance, a design choice
inspired by natural quadruped behaviors and prevalent in robotic quadruped
systems. Our control algorithm uses the reduced-order SLIP dynamics of the
quadruped to track a stable parabolic spline during stance, which is calculated
using the principle of energy conservation. Through simulations based on the
design specifications of an actual quadruped robot, Ghost Robotics Minitaur, we
demonstrate that our control algorithm generates stable bouncing gaits.
Additionally, we illustrate the robustness of our controller by showcasing its
ability to maintain stable bouncing even when faced with up to a 10% error in
sensor measurements.

</details>


### [37] [Bioinspired Soft Quadrotors Jointly Unlock Agility, Squeezability, and Collision Resilience](https://arxiv.org/abs/2511.05426)
*Luca Girardi,Gabriel Maquignaz,Stefano Mintchev*

Main category: cs.RO

TL;DR: FlexiQuad是一种新型软框架四旋翼，具备高灵活性、碰撞韧性与可通过窄隙飞行的能力。


<details>
  <summary>Details</summary>
Motivation: 传统的四旋翼在碰撞韧性和通过狭窄空间飞行能力上受到限制，本研究旨在通过生物启发的设计来解决这一问题。

Method: 基于生物体的结构特性，在设计上实现各向异性刚度的柔性四旋翼原型，测试其在不同环境中的性能。

Result: FlexiQuad是一种软框架四旋翼设计，结合了生物体的各向异性刚度与分布质量能量结构，提升了飞行能力。其原型重405克，符合传统四旋翼性能且具更高的柔韧性和碰撞抗性，能在复杂环境中更自如地飞行。

Conclusion: FlexiQuad通过引入软框架设计，显著提高了四旋翼在复杂环境中的飞行能力与安全性，是提高无人机表现的有效途径。

Abstract: Natural flyers use soft wings to seamlessly enable a wide range of flight
behaviours, including agile manoeuvres, squeezing through narrow passageways,
and withstanding collisions. In contrast, conventional quadrotor designs rely
on rigid frames that support agile flight but inherently limit collision
resilience and squeezability, thereby constraining flight capabilities in
cluttered environments. Inspired by the anisotropic stiffness and distributed
mass-energy structures observed in biological organisms, we introduce
FlexiQuad, a soft-frame quadrotor design approach that limits this trade-off.
We demonstrate a 405-gram FlexiQuad prototype, three orders of magnitude more
compliant than conventional quadrotors, yet capable of acrobatic manoeuvres
with peak speeds above 80 km/h and linear and angular accelerations exceeding 3
g and 300 rad/s$^2$, respectively. Analysis demonstrates it can replicate
accelerations of rigid counterparts up to a thrust-to-weight ratio of 8.
Simultaneously, FlexiQuad exhibits fourfold higher collision resilience,
surviving frontal impacts at 5 m/s without damage and reducing destabilising
forces in glancing collisions by a factor of 39. Its frame can fully compress,
enabling flight through gaps as narrow as 70% of its nominal width. Our
analysis identifies an optimal structural softness range, from 0.006 to 0.77
N/mm, comparable to that of natural flyers' wings, whereby agility,
squeezability, and collision resilience are jointly achieved for FlexiQuad
models from 20 to 3000 grams. FlexiQuad expands hovering drone capabilities in
complex environments, enabling robust physical interactions without
compromising flight performance.

</details>
