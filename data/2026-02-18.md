<div id=toc></div>

# Table of Contents

- [cs.HC](#cs.HC) [Total: 12]
- [cs.RO](#cs.RO) [Total: 30]


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [1] [Multi-Agent Home Energy Management Assistant](https://arxiv.org/abs/2602.15219)
*Wooyoung Jung*

Main category: cs.HC

TL;DR: 本研究提出了一种新的多智能体家庭能源管理助手（HEMA），可智能适应实际用例，通过自我一致性分类器分类用户查询并请求专门的代理响应，展现出91.9%的目标达成率，大幅提升了家庭能源管理的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 家居能源管理的复杂性不断增加，亟需先进系统引导用户做出明智的能源决策，而现有模型在定制化和性能评估方面存在局限。

Method: 本研究基于LangChain和LangGraph构建HEMA，采用自我一致性分类器识别用户查询，利用三个专门的代理（分析、知识、控制）生成精准的响应。

Result: 经过295个测试案例的严格评估，HEMA在用户请求的满足率为91.9%，在事实准确性、行动正确性、交互质量和系统效率上表现优异，尤其是相较于其他系统配置。

Conclusion: 本研究展示了基于多智能体架构的家庭能源管理助手（HEMA）的可行性与价值，对人本设计的LLM集成家庭能源管理系统（HEMS）进行了总结，明确了支持人机协作的架构需求和评估标准。

Abstract: The growing complexity in home energy management demands advanced systems that guide occupants toward informed energy decisions. Large language model (LLM)-integrated home energy management systems (HEMS) have shown promise, but prior studies relied on prompt engineering or pre-built platforms with limited customization of agent behavior, or assessed performance through single-turn or -task evaluations. This study introduces a multi-agent home energy management assistant (HEMA), built on LangChain and LangGraph, designed to adaptively and intelligently handle real-world use cases of HEMS with full system customization capability. It carefully classifies user queries via a self-consistency classifier, requests three specialized agents (Analysis, Knowledge, and Control) to prepare accurate, adaptive responses using purpose-built analysis and control tools and retrieval augmented generation under the reasoning and acting mechanism. HEMA was rigorously assessed using two different experimental analyses via an LLM-as-user approach: (1) analytical and informative capabilities using combinatorial test cases of various personas and differing scenarios against three alternative system configurations relying on vanilla LLM and (2) control capabilities using various control scenarios. Out of 295 test cases, HEMA acquired a 91.9% goal achievement rate, successfully fulfilling user requests while providing high levels of factual accuracy, action correctness, interaction quality, and system efficiency, especially when compared to alternative system configurations. Collectively, this study contributes to the advancement of the human-centered design of LLM-integrated HEMS by demonstrating the feasibility and value of agentic architectures, and by clarifying the architectural requirements and evaluation criteria necessary to support adaptive, sustained human-artificial intelligence collaboration in HEMS.

</details>


### [2] [Ground-Truth Depth in Vision Language Models: Spatial Context Understanding in Conversational AI for XR-Robotic Support in Emergency First Response](https://arxiv.org/abs/2602.15237)
*Rodrigo Gutierrez Maquilon,Marita Hueber,Georg Regal,Manfred Tscheligi*

Main category: cs.HC

TL;DR: 本研究展示了通过深度增强的视觉语言模型改善应急响应的情境意识和决策能力。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过深度感知和语言模型的结合来提高紧急情况中的空间推理能力。

Method: 评估一个融合了机器人深度传感器和YOLO检测的视觉语言模型( VLM)的原型，该模型能够表述被检测物体的度量距离。

Result: 在混合现实的有毒烟雾场景中，参与者在三种条件下（视频仅，深度无关 VLM，和深度增强 VLM）评估受害者和出口窗户的距离。

Conclusion: 深度增强提升了目标的准确性和稳定性，提高了情境意识而未增加工作负担，反之，深度无关的辅助则增加了工作负担并略微降低了准确性。

Abstract: Large language models (LLMs) are increasingly used in emergency first response (EFR) applications to support situational awareness (SA) and decision-making, yet most operate on text or 2D imagery and offer little support for core EFR SA competencies like spatial reasoning. We address this gap by evaluating a prototype that fuses robot-mounted depth sensing and YOLO detection with a vision language model (VLM) capable of verbalizing metrically-grounded distances of detected objects (e.g., the chair is 3.02 meters away). In a mixed-reality toxic-smoke scenario, participants estimated distances to a victim and an exit window under three conditions: video-only, depth-agnostic VLM, and depth-augmented VLM. Depth-augmentation improved objective accuracy and stability, e.g., the victim and window distance estimation error dropped, while raising situational awareness without increasing workload. Conversely, depth- agnostic assistance increased workload and slightly worsened accuracy. We contribute to human SA augmentation by demonstrating that metrically grounded, object-centric verbal information supports spatial reasoning in EFR and improves decision-relevant judgments under time pressure.

</details>


### [3] [MyoInteract: A Framework for Fast Prototyping of Biomechanical HCI Tasks using Reinforcement Learning](https://arxiv.org/abs/2602.15245)
*Ankit Bhattarai,Hannah Selder,Florian Fischer,Arthur Fleig,Per Ola Kristensson*

Main category: cs.HC

TL;DR: MyoInteract是一个新的生物机械HCI任务快速原型框架，能在几分钟内设定任务和用户模型，并将训练时间减少98%。


<details>
  <summary>Details</summary>
Motivation: 生物机械RL模拟在HCI研究和交互设计中具有革命性潜力，但现有方法在可用性和可解释性上存在不足。

Method: 通过人类行动周期作为设计视角，开发了MyoInteract框架，提供易用的图形用户界面，快速设定任务和训练参数。

Result: 经过与12名交互设计师的工作坊研究，MyoInteract使生物机械RL的初学者能够在一次会议中成功设定、训练和评估用户的目标导向运动。

Conclusion: MyoInteract框架显著降低了生物机械RL的使用门槛，加快了HCI生物力学研究中的迭代周期。

Abstract: Reinforcement learning (RL)-based biomechanical simulations have the potential to revolutionise HCI research and interaction design, but currently lack usability and interpretability. Using the Human Action Cycle as a design lens, we identify key limitations of biomechanical RL frameworks and develop MyoInteract, a novel framework for fast prototyping of biomechanical HCI tasks. MyoInteract allows designers to setup tasks, user models, and training parameters from an easy-to-use GUI within minutes. It trains and evaluates muscle-actuated simulated users within minutes, reducing training times by up to 98%. A workshop study with 12 interaction designers revealed that MyoInteract allowed novices in biomechanical RL to successfully setup, train, and assess goal-directed user movements within a single session. By transforming biomechanical RL from a days-long expert task into an accessible hour-long workflow, this work significantly lowers barriers to entry and accelerates iteration cycles in HCI biomechanics research.

</details>


### [4] [From Diagnosis to Inoculation: Building Cognitive Resistance to AI Disempowerment](https://arxiv.org/abs/2602.15265)
*Aleksey Komissarov*

Main category: cs.HC

TL;DR: 本研究提出了一种AI素养框架，强调通过引导学习者接触AI失效模式来应对AI交互带来的潜在失能问题。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是针对Sharma等人提出的AI助手互动可能导致的情境性人类失能问题，寻求有效的教育干预措施以提升人们的AI素养。

Method: 研究采用了与AI共同授课的方法，通过案例研究展示了AI素养框架的实施，结合免疫理论的应用，促进学习者对AI失效模式的理解。

Result: 该框架与Sharma等人的失能分类体系存在共鸣，表明两者在问题描述上的一致性，增强了对问题诊断和教育响应的可靠性。

Conclusion: 该研究通过应用免疫理论，提出了一种AI素养框架，强调了在教学过程中对AI失效模式的引导性曝光是必要的，以有效应对人类在与AI互动中可能遭遇的失能现象。此外，框架与Sharma等人的分类体系之间的共鸣进一步增强了对问题诊断和教育回应的支持。

Abstract: Recent empirical research by Sharma et al. (2026) demonstrated that AI assistant interactions carry meaningful potential for situational human disempowerment, including reality distortion, value judgment distortion, and action distortion. While this work provides a critical diagnosis of the problem, concrete pedagogical interventions remain underexplored. I present an AI literacy framework built around eight cross-cutting Learning Outcomes (LOs), developed independently through teaching practice and subsequently found to align with Sharma et al.'s disempowerment taxonomy. I report a case study from a publicly available online course, where a co-teaching methodology--with AI serving as an active voice co-instructor--was used to deliver this framework. Drawing on inoculation theory (McGuire, 1961)--a well-established persuasion research framework recently applied to misinformation prebunking by the Cambridge school (van der Linden, 2022; Roozenbeek & van der Linden, 2019)--I argue that AI literacy cannot be acquired through declarative knowledge alone, but requires guided exposure to AI failure modes, including the sycophantic validation and authority projection patterns identified by Sharma et al. This application of inoculation theory to AI-specific distortion is, to my knowledge, novel. I discuss the convergence between the pedagogically-derived framework and Sharma et al.'s empirically-derived taxonomy, and argue that this convergence--two independent approaches arriving at similar problem descriptions--strengthens the case for both the diagnosis and the proposed educational response.

</details>


### [5] [Supporting Multimodal Data Interaction on Refreshable Tactile Displays: An Architecture to Combine Touch and Conversational AI](https://arxiv.org/abs/2602.15280)
*Samuel Reinders,Munazza Zaib,Matthew Butler,Bongshin Lee,Ingrid Zukerman,Lizhen Qu,Kim Marriott*

Main category: cs.HC

TL;DR: 本研究提出了一种新型的多模态数据交互架构，结合对话式人工智能与可刷新触觉显示器，以提升盲人和低视力人群的数据可视化体验，并给出了一种开源实现。


<details>
  <summary>Details</summary>
Motivation: 结合对话式人工智能与可刷新触觉显示器（RTDs），为盲人或低视力人群创造可访问的数据可视化提供了重要潜力。

Method: 提出了一种多模态数据交互架构，以及一个开源的参考实现。

Result: 我们的系统是首个将触摸输入与对话代理结合在RTD上的实现，能够支持依据触摸上下文与口语进行的指示查询。

Conclusion: 本研究为未来在多模态的可访问数据可视化领域提供了技术基础。

Abstract: Combining conversational AI with refreshable tactile displays (RTDs) offers significant potential for creating accessible data visualization for people who are blind or have low vision (BLV). To support researchers and developers building accessible data visualizations with RTDs, we present a multimodal data interaction architecture along with an open-source reference implementation. Our system is the first to combine touch input with a conversational agent on an RTD, enabling deictic queries that fuse touch context with spoken language, such as "what is the trend between these points?" The architecture addresses key technical challenges, including touch sensing on RTDs, visual-to-tactile encoding, integrating touch context with conversational AI, and synchronizing multimodal output. Our contributions are twofold: (1) a technical architecture integrating RTD hardware, external touch sensing, and conversational AI to enable multimodal data interaction; and (2) an open-source reference implementation demonstrating its feasibility. This work provides a technical foundation to support future research in multimodal accessible data visualization.

</details>


### [6] [StatCounter: A Longitudinal Study of a Portable Scholarly Metric Display](https://arxiv.org/abs/2602.15413)
*Jonas Oppenlaender*

Main category: cs.HC

TL;DR: 本研究考察了一种手持电子设备如何在日常生活中展示学术指标，并分析其对学术动机、注意力和反思的影响。


<details>
  <summary>Details</summary>
Motivation: 研究旨在了解如何在非传统环境中通过技术手段赋予学术指标新的意义，促使个体对学术表现的持续关注与反思。

Method: 本研究采用第一人称的纵向自我民族志方法，分析了携带设备过程中对学术指标的感知和反应。

Result: 发现设备的存在使学术指标从偶尔参考转变为学术生活的背景，影响了学术身份的叙事和个体的情感体验。

Conclusion: 本研究深入探讨了随时随地访问学术指标如何改变学术身份和评价的意义，提出了设计具有反思意义的学术评价工具的机会和框架。

Abstract: This study explores a handheld, battery-operated e-ink device displaying Google Scholar citation statistics. The StatCounter places academic metrics into the flow of daily life rather than a desktop context. The work draws on a first-person, longitudinal auto-ethnographic inquiry examining how constant access to scholarly metrics influences motivation, attention, reflection, and emotional responses across work and non-work settings. The ambient proximity and pervasive availability of scholarly metrics invites frequent micro-checks, short reflective pauses, but also introduces moments of second-guessing when numbers drop or stagnate. Carrying the device prompts new narratives about academic identity, including a sense of companionship during travel and periods away from the office. Over time, the presence of the device turns metrics from an occasional reference into an ambient background of scholarly life. The study contributes insight into how situated, embodied access to academic metrics reshapes their meaning, and frames opportunities for designing tools that engage with scholarly evaluation in reflective ways.

</details>


### [7] [Reflecting on 1,000 Social Media Journeys: Generational Patterns in Platform Transition](https://arxiv.org/abs/2602.15489)
*Artur Solomonik,Nicolas Ruiz,Hendrik Heuer*

Main category: cs.HC

TL;DR: 本研究介绍了社交媒体旅程的概念，分析了用户社交媒体经历的推动与拉动因素，为平台设计和治理提供了新见解。


<details>
  <summary>Details</summary>
Motivation: 尽管社交媒体用户众多，但我们仍未完全理解用户为何偏爱某一平台而非另一平台。本研究旨在填补这一知识空白，并考察用户在不同平台之间的转移原因。

Method: 对来自1000名美国参与者的配额样本数据进行收集与分析，以系统地研究用户的社交媒体经历，识别推动和拉动的因素。

Result: 本研究识别了社交媒体生态系统中的推动和拉动因素，揭示了不同代际根据个人需求采用社交媒体平台的方式。

Conclusion: 本研究通过全面分析用户在社交媒体上的经历，提出了社交媒体旅程的概念，为平台设计、治理和监管提供了新的见解。

Abstract: Social media has billions of users, but we still do not fully understand why users prefer one platform over another. Establishing new platforms among already popular competitors is difficult. Prior research has richly documented people's experiences within individual platforms, yet situating those experiences within the entirety of a user's social media experience remains challenging. What platforms have people used, and why have they transitioned between them? We collected data from a quota-based sample of 1,000 U.S. participants. We introduce the concept of \emph{Social Media Journeys} to study the entirety of their social media experiences systematically. We identify push and pull factors across the social media landscape. We also show how different generations adopted social media platforms based on personal needs. With this work, we advance HCI by moving towards holistic perspectives when discussing social media technology, offering new insights for platform design, governance, and regulation.

</details>


### [8] ["What Are You Doing?": Effects of Intermediate Feedback from Agentic LLM In-Car Assistants During Multi-Step Processing](https://arxiv.org/abs/2602.15569)
*Johannes Kirmayr,Raphael Wennmacher,Khanh Huynh,Lukas Stappen,Elisabeth André,Florian Alt*

Main category: cs.HC

TL;DR: 探索自主智能助手如何在驾驶等注意力关键场景中传达反馈，发现中间反馈提高用户体验及信任，并提出设计建议。


<details>
  <summary>Details</summary>
Motivation: 探讨自主执行多步任务的智能助手如何在注意力关键的场景中有效地与用户沟通进度和推理。

Method: 通过对45名参与者进行受控的混合方法研究，比较计划步骤和中间结果反馈与仅提供最终响应的无反馈操作。

Result: 中间反馈显著提高了用户的感知速度、信任和用户体验，同时减少了任务负担，并在不同的任务复杂性和互动环境中保持了这些效果。

Conclusion: 用户倾向于一种自适应的反馈方式，初期高透明度以建立信任，随后逐步减少详细信息，根据任务风险和情境背景调整。

Abstract: Agentic AI assistants that autonomously perform multi-step tasks raise open questions for user experience: how should such systems communicate progress and reasoning during extended operations, especially in attention-critical contexts such as driving? We investigate feedback timing and verbosity from agentic LLM-based in-car assistants through a controlled, mixed-methods study (N=45) comparing planned steps and intermediate results feedback against silent operation with final-only response. Using a dual-task paradigm with an in-car voice assistant, we found that intermediate feedback significantly improved perceived speed, trust, and user experience while reducing task load - effects that held across varying task complexities and interaction contexts. Interviews further revealed user preferences for an adaptive approach: high initial transparency to establish trust, followed by progressively reducing verbosity as systems prove reliable, with adjustments based on task stakes and situational context. We translate our empirical findings into design implications for feedback timing and verbosity in agentic assistants, balancing transparency and efficiency.

</details>


### [9] [Meflex: A Multi-agent Scaffolding System for Entrepreneurial Ideation Iteration via Nonlinear Business Plan Writing](https://arxiv.org/abs/2602.15631)
*Lan Luo,Dongyijie Primo Pan,Junhua Zhu,Muzhi Zhou,Pan Hui*

Main category: cs.HC

TL;DR: Meflex系统是一种基于大型语言模型的写作工具，通过非线性创意画布和反思支持帮助创业教育，减轻认知负担并促进深层次的创业思维。


<details>
  <summary>Details</summary>
Motivation: 传统商业计划写作方法过于僵化，无法反映创业思维的动态特性，这对初学者造成了认知负担。

Method: 通过与30名参与者进行探索性用户研究，评估Meflex系统的可用性和认知影响。

Result: Meflex系统有效结合商业计划写作的支撑和非线性创意画布，支持通过反思和元反思推动迭代创意。

Conclusion: Meflex系统显著促进了商业计划写作，提升了发散思维和元反思意识，同时减轻了在复杂创意发展过程中的认知负担。

Abstract: Business plan (BP) writing plays a key role in entrepreneurship education by helping learners construct, evaluate, and iteratively refine their ideas. However, conventional BP writing remains a rigid, linear process that often fails to reflect the dynamic and recursive nature of entrepreneurial ideation. This mismatch is particularly challenging for novice entrepreneurial students, who struggle with the substantial cognitive demands of developing and refining ideas. While reflection and meta-reflection are critical strategies for fostering divergent and convergent thinking, existing writing tools rarely scaffold these higher-order processes. To address this gap, we present the Meflex System, a large language model (LLM)-based writing tool that integrates BP writing scaffolding with a nonlinear idea canvas to support iterative ideation through reflection and meta-reflection. We report findings from an exploratory user study with 30 participants that examined the system's usability and cognitive impact. Results show that Meflex effectively scaffolds BP writing, promotes divergent thinking through LLM-supported reflection, and enhances meta-reflective awareness while reducing cognitive load during complex idea development. These findings highlight the potential of non-linear LLM-based writing tools to foster deeper and coherent entrepreneurial thinking.

</details>


### [10] [How to Disclose? Strategic AI Disclosure in Crowdfunding](https://arxiv.org/abs/2602.15698)
*Ning Wang,Chen Liang*

Main category: cs.HC

TL;DR: 本研究探讨了强制性AI披露对众筹表现的影响，发现披露策略显著调节这一影响，强调了透明度管理的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能逐渐融入众筹实践，探索不同披露策略如何影响投资者决策显得至关重要。

Method: 利用Kickstarter的强制性AI披露政策作为自然实验，同时结合四个在线实验进行分析。

Result: 强制性AI披露使得众筹资金减少39.8%，支持者数量减少23.9%。披露策略的选择对这些负面效果具有系统性的调节作用。

Conclusion: 强制性AI披露显著降低了众筹表现，但不同的披露策略对该效果具有调节作用。

Abstract: As artificial intelligence (AI) increasingly integrates into crowdfunding practices, strategic disclosure of AI involvement has become critical. Yet, empirical insights into how different disclosure strategies influence investor decisions remain limited. Drawing on signaling theory and Aristotle's rhetorical framework, we examine how mandatory AI disclosure affects crowdfunding performance and how substantive signals (degree of AI involvement) and rhetorical signals (logos/explicitness, ethos/authenticity, pathos/emotional tone) moderate these effects. Leveraging Kickstarter's mandatory AI disclosure policy as a natural experiment and four supplementary online experiments, we find that mandatory AI disclosure significantly reduces crowdfunding performance: funds raised decline by 39.8% and backer counts by 23.9% for AI-involved projects. However, this adverse effect is systematically moderated by disclosure strategy. Greater AI involvement amplifies the negative effects of AI disclosure, while high authenticity and high explicitness mitigate them. Interestingly, excessive positive emotional tone (a strategy creators might intuitively adopt to counteract AI skepticism) backfires and exacerbates negative outcomes. Supplementary randomized experiments identify two underlying mechanisms: perceived creator competence and AI washing concerns. Substantive signals primarily affect competence judgments, whereas rhetorical signals operate through varied pathways: either mediator alone or both in sequence. These findings provide theoretical and practical insights for entrepreneurs, platforms, and policymakers strategically managing AI transparency in high-stakes investment contexts.

</details>


### [11] [Beyond Labels: Information-Efficient Human-in-the-Loop Learning using Ranking and Selection Queries](https://arxiv.org/abs/2602.15738)
*Belén Martín-Urcelay,Yoonsang Lee,Matthieu R. Bloch,Christopher J. Rozell*

Main category: cs.HC

TL;DR: 本文提出了一种人机协同的框架，通过丰富的查询类型和主动学习算法，提高了信息获取效率，并显著减少了样本复杂度和学习时间。


<details>
  <summary>Details</summary>
Motivation: 传统的机器学习系统将专家的角色限制在标注神 oracle，无法充分捕捉人类判断的细微差别，导致信息交流的不足。

Method: 利用带有人类反馈的框架，结合丰富的查询类型（如项目排名和示例选择），设计主动学习算法，并采用概率人类响应模型和变分近似。

Result: 通过实验，展示了使用我们的方法在样本复杂度上显著减少，特别是在词汇情感分类任务中，学习时间比传统的仅标签主动学习减少了57%。

Conclusion: 我们提出的框架显著降低了样本复杂度，并提高了信息获取的效率，能够有效地在标签仅的主动学习中减少学习时间。

Abstract: Integrating human expertise into machine learning systems often reduces the role of experts to labeling oracles, a paradigm that limits the amount of information exchanged and fails to capture the nuances of human judgment. We address this challenge by developing a human-in-the-loop framework to learn binary classifiers with rich query types, consisting of item ranking and exemplar selection. We first introduce probabilistic human response models for these rich queries motivated by the relationship experimentally observed between the perceived implicit score of an item and its distance to the unknown classifier. Using these models, we then design active learning algorithms that leverage the rich queries to increase the information gained per interaction. We provide theoretical bounds on sample complexity and develop a tractable and computationally efficient variational approximation. Through experiments with simulated annotators derived from crowdsourced word-sentiment and image-aesthetic datasets, we demonstrate significant reductions on sample complexity. We further extend active learning strategies to select queries that maximize information rate, explicitly balancing informational value against annotation cost. This algorithm in the word sentiment classification task reduces learning time by more than 57\% compared to traditional label-only active learning.

</details>


### [12] [Unraveling Entangled Feeds: Rethinking Social Media Design to Enhance User Well-being](https://arxiv.org/abs/2602.15745)
*Ashlee Milton,Dan Runningen,Loren Terveen,Harmanpreet Kaur,Stevie Chancellor*

Main category: cs.HC

TL;DR: 本研究发现社交媒体平台的算法设计影响用户心理健康，用户通过工作坊提出了改善互动的建议，强调了用户控制的必要性。


<details>
  <summary>Details</summary>
Motivation: 探讨社交媒体算法对用户心理健康的潜在影响，并理解用户如何解释他们的体验。

Method: 通过与21名心理疾病患者的设计工作坊，探索他们与社交媒体平台的互动与理解。

Result: 用户发展了因果解释，揭示了算法设计中的断裂现象，并提出了改善用户体验的设计建议。

Conclusion: 本研究强调了在社交媒体平台的算法设计中，用户心理健康的重要性，并提出了回归用户控制权的设计方案。

Abstract: Social media platforms have rapidly adopted algorithmic curation with little consideration for the potential harm to users' mental well-being. We present findings from design workshops with 21 participants diagnosed with mental illness about their interactions with social media platforms. We find that users develop cause-and-effect explanations, or folk theories, to understand their experiences with algorithmic curation. These folk theories highlight a breakdown in algorithmic design that we explain using the framework of entanglement, a phenomenon where there is a disconnect between users' actions and platform outcomes on an emotional level. Participants' designs to address entanglement and mitigate harms centered on contextualizing their engagement and restoring explicit user control on social media. The conceptualization of entanglement and the resulting design recommendations have implications for social computing and recommender systems research, particularly in evaluating and designing social media platforms that support users' mental well-being.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [13] [CLOT: Closed-Loop Global Motion Tracking for Whole-Body Humanoid Teleoperation](https://arxiv.org/abs/2602.15060)
*Tengjie Zhu,Guanyu Cai,Yang Zhaohui,Guanzhu Ren,Haohui Xie,ZiRui Wang,Junsong Wu,Jingbo Wang,Xiaokang Yang,Yao Mu,Yichao Yan,Yichao Yan*

Main category: cs.RO

TL;DR: CLOT是一个实时类人机器人远程操作系统，通过闭环全球运动跟踪和数据驱动随机化策略，实现高动态、无漂移的操作，验证了在长期执行中的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 长期的全身类人机器人远程操作面临挑战，特别是在全尺寸类人机器人中，由于全球姿态漂移的问题。

Method: 提出CLOT，一个实时全身类人机器人远程操作系统，通过高频定位反馈实现闭环的全球运动跟踪。结合数据驱动随机化策略和对抗运动先验来平滑和稳定地进行全球纠正。

Result: CLOT能够在长时间内实现无漂移的人与类人机器人模仿，且在模拟和真实环境中验证了其高动态运动、高精度跟踪和强鲁棒性。

Conclusion: CLOT为类人机器人远程操作提供了有效的解决方案，减少了操作中的不稳定性和漂移问题。

Abstract: Long-horizon whole-body humanoid teleoperation remains challenging due to accumulated global pose drift, particularly on full-sized humanoids. Although recent learning-based tracking methods enable agile and coordinated motions, they typically operate in the robot's local frame and neglect global pose feedback, leading to drift and instability during extended execution. In this work, we present CLOT, a real-time whole-body humanoid teleoperation system that achieves closed-loop global motion tracking via high-frequency localization feedback. CLOT synchronizes operator and robot poses in a closed loop, enabling drift-free human-to-humanoid mimicry over long timehorizons. However, directly imposing global tracking rewards in reinforcement learning, often results in aggressive and brittle corrections. To address this, we propose a data-driven randomization strategy that decouples observation trajectories from reward evaluation, enabling smooth and stable global corrections. We further regularize the policy with an adversarial motion prior to suppress unnatural behaviors. To support CLOT, we collect 20 hours of carefully curated human motion data for training the humanoid teleoperation policy. We design a transformer-based policy and train it for over 1300 GPU hours. The policy is deployed on a full-sized humanoid with 31 DoF (excluding hands). Both simulation and real-world experiments verify high-dynamic motion, high-precision tracking, and strong robustness in sim-to-real humanoid teleoperation. Motion data, demos and code can be found in our website.

</details>


### [14] [Safe-SDL:Establishing Safety Boundaries and Control Mechanisms for AI-Driven Self-Driving Laboratories](https://arxiv.org/abs/2602.15061)
*Zihan Zhang,Haohui Que,Junhan Chang,Xin Zhang,Hao Wei,Tong Zhu*

Main category: cs.RO

TL;DR: 本论文提出了Safe-SDL框架，该框架通过建立安全边界和控制机制来解决自驱动实验室的安全挑战，重点讨论了AI生成命令与其物理安全影响之间的脱节问题，并提出了三种协同组件以确保安全性。


<details>
  <summary>Details</summary>
Motivation: 自驱动实验室的出现通过将AI与机器人自动化整合，变革了科学发现的方法论，但也引入了前所未有的安全挑战。

Method: 论文提出了一个综合框架Safe-SDL，包含三个组件：正式定义的操作设计域(Odds)、控制障碍函数(CBFs)和新颖的事务安全协议(CRUTD)，以确保AI实验室的安全。

Result: Evaluation against LabSafety Bench reveals significant safety failures in current foundation models, indicating建筑安全机制的重要性。

Conclusion: Safe-SDL为AI驱动的自适应实验室提供了安全部署的理论基础和实践指导，奠定了负责任加速AI驱动发现的基础。

Abstract: The emergence of Self-Driving Laboratories (SDLs) transforms scientific discovery methodology by integrating AI with robotic automation to create closed-loop experimental systems capable of autonomous hypothesis generation, experimentation, and analysis. While promising to compress research timelines from years to weeks, their deployment introduces unprecedented safety challenges differing from traditional laboratories or purely digital AI. This paper presents Safe-SDL, a comprehensive framework for establishing robust safety boundaries and control mechanisms in AI-driven autonomous laboratories. We identify and analyze the critical ``Syntax-to-Safety Gap'' -- the disconnect between AI-generated syntactically correct commands and their physical safety implications -- as the central challenge in SDL deployment. Our framework addresses this gap through three synergistic components: (1) formally defined Operational Design Domains (ODDs) that constrain system behavior within mathematically verified boundaries, (2) Control Barrier Functions (CBFs) that provide real-time safety guarantees through continuous state-space monitoring, and (3) a novel Transactional Safety Protocol (CRUTD) that ensures atomic consistency between digital planning and physical execution. We ground our theoretical contributions through analysis of existing implementations including UniLabOS and the Osprey architecture, demonstrating how these systems instantiate key safety principles. Evaluation against the LabSafety Bench reveals that current foundation models exhibit significant safety failures, demonstrating that architectural safety mechanisms are essential rather than optional. Our framework provides both theoretical foundations and practical implementation guidance for safe deployment of autonomous scientific systems, establishing the groundwork for responsible acceleration of AI-driven discovery.

</details>


### [15] [How Do We Research Human-Robot Interaction in the Age of Large Language Models? A Systematic Review](https://arxiv.org/abs/2602.15063)
*Yufeng Wang,Yuan Xu,Anastasia Nikolova,Yuxuan Wang,Jianyu Wang,Chongyang Wang,Xin Tong*

Main category: cs.RO

TL;DR: 本文系统性研究了大规模语言模型对人类与机器人交互的影响，发现其在基本机制上产生了变革，并指出当前研究的多样性和未来研究的指导方针。


<details>
  <summary>Details</summary>
Motivation: 探讨大规模语言模型在以人为中心的机器人与人类交互中的影响，尽管已有研究强调其技术潜力，但缺乏系统性考察其人本影响的研究。

Method: 根据PRISMA指南进行系统文献检索，筛选出86篇符合纳入标准的文章。

Result: 发现大规模语言模型正在转变机器人感知上下文、生成社交互动和与人类需求持续对齐的基本机制；当前的研究大多为探索性，集中在不同方面，导致实验设置、研究方法和评估指标的多样性。

Conclusion: 识别出关键设计考虑因素和挑战，为未来大规模语言模型与人机交互的研究提供了清晰的概述和指导方针。

Abstract: Advances in large language models (LLMs) are profoundly reshaping the field of human-robot interaction (HRI). While prior work has highlighted the technical potential of LLMs, few studies have systematically examined their human-centered impact (e.g., human-oriented understanding, user modeling, and levels of autonomy), making it difficult to consolidate emerging challenges in LLM-driven HRI systems. Therefore, we conducted a systematic literature search following the PRISMA guideline, identifying 86 articles that met our inclusion criteria. Our findings reveal that: (1) LLMs are transforming the fundamentals of HRI by reshaping how robots sense context, generate socially grounded interactions, and maintain continuous alignment with human needs in embodied settings; and (2) current research is largely exploratory, with different studies focusing on different facets of LLM-driven HRI, resulting in wide-ranging choices of experimental setups, study methods, and evaluation metrics. Finally, we identify key design considerations and challenges, offering a coherent overview and guidelines for future research at the intersection of LLMs and HRI.

</details>


### [16] [Augmenting Human Balance with Generic Supernumerary Robotic Limbs](https://arxiv.org/abs/2602.15092)
*Xuanyun Qiu,Dorian Verdel,Hector Cervantes-Culebro,Alexis Devillard,Etienne Burdet*

Main category: cs.RO

TL;DR: 本文提出了一种新框架，通过层次化架构解决超数机器人肢体的平衡问题，实验表明效果显著。


<details>
  <summary>Details</summary>
Motivation: 超数机器人肢体在转变人类活动方面潜力巨大，但当前的技术挑战限制了其可用性。

Method: 提出一个层次化的三层架构，包含预测层、规划层和控制层，解决SLs与人类系统中保持平衡的问题。

Result: 通过对十名参与者进行前向和侧向弯曲任务的评估，结果显示该框架显著降低了姿态不稳定性，提高了平衡能力。

Conclusion: 该研究框架为安全和多功能的人类-超数机器人肢体交互奠定了基础。

Abstract: Supernumerary robotic limbs (SLs) have the potential to transform a wide range of human activities, yet their usability remains limited by key technical challenges, particularly in ensuring safety and achieving versatile control. Here, we address the critical problem of maintaining balance in the human-SLs system, a prerequisite for safe and comfortable augmentation tasks. Unlike previous approaches that developed SLs specifically for stability support, we propose a general framework for preserving balance with SLs designed for generic use. Our hierarchical three-layer architecture consists of: (i) a prediction layer that estimates human trunk and center of mass (CoM) dynamics, (ii) a planning layer that generates optimal CoM trajectories to counteract trunk movements and computes the corresponding SL control inputs, and (iii) a control layer that executes these inputs on the SL hardware. We evaluated the framework with ten participants performing forward and lateral bending tasks. The results show a clear reduction in stance instability, demonstrating the framework's effectiveness in enhancing balance. This work paves the path towards safe and versatile human-SLs interactions. [This paper has been submitted for publication to IEEE.]

</details>


### [17] [A ROS2 Benchmarking Framework for Hierarchical Control Strategies in Mobile Robots for Mediterranean Greenhouses](https://arxiv.org/abs/2602.15162)
*Fernando Cañadas-Aránega,Francisco J. Mañas-Álvarez,José L- Guzmán,José C. Moreno,José L. Blanco-Claraco*

Main category: cs.RO

TL;DR: 本论文提出了一个用于农业工业环境中移动机器人控制策略评估的综合基准测试框架，通过标准化指标与扰动场景，便于公平比较与系统性评估。


<details>
  <summary>Details</summary>
Motivation: 提高移动机器人在农业工业环境中（如地中海温室）的控制性能和稳定性，通过制定标准化的基准测试来便于控制策略的比较与评估。

Method: 提出一个综合的基准测试框架，结合三维环境模型、物理仿真器和层次控制架构，涵盖低、中、高级控制层，并定义三类基准，模拟扰动场景以复制真实农业条件。

Result: 建立了统一的性能评估指标如称方差绝对误差(SAE)、方差控制输入(SCI)和综合性能指数，增强了通过插件架构整合用户定义的控制器和规划者的能力。

Conclusion: 提供了一个强大且可扩展的工具，以便在真实条件下定量比较经典、预测和基于规划的控制策略，为仿真分析与现实农业应用之间架起桥梁。

Abstract: Mobile robots operating in agroindustrial environments, such as Mediterranean greenhouses, are subject to challenging conditions, including uneven terrain, variable friction, payload changes, and terrain slopes, all of which significantly affect control performance and stability. Despite the increasing adoption of robotic platforms in agriculture, the lack of standardized, reproducible benchmarks impedes fair comparisons and systematic evaluations of control strategies under realistic operating conditions. This paper presents a comprehensive benchmarking framework for evaluating mobile robot controllers in greenhouse environments. The proposed framework integrates an accurate three dimensional model of the environment, a physics based simulator, and a hierarchical control architecture comprising low, mid, and high level control layers. Three benchmark categories are defined to enable modular assessment, ranging from actuator level control to full autonomous navigation. Additionally, three disturbance scenarios payload variation, terrain type, and slope are explicitly modeled to replicate real world agricultural conditions. To ensure objective and reproducible evaluation, standardized performance metrics are introduced, including the Squared Absolute Error (SAE), the Squared Control Input (SCI), and composite performance indices. Statistical analysis based on repeated trials is employed to mitigate the influence of sensor noise and environmental variability. The framework is further enhanced by a plugin based architecture that facilitates seamless integration of user defined controllers and planners. The proposed benchmark provides a robust and extensible tool for the quantitative comparison of classical, predictive, and planning based control strategies in realistic conditions, bridging the gap between simulation based analysis and real world agroindustrial applications.

</details>


### [18] [DexEvolve: Evolutionary Optimization for Robust and Diverse Dexterous Grasp Synthesis](https://arxiv.org/abs/2602.15201)
*René Zurbrügg,Andrei Cramariuc,Marco Hutter*

Main category: cs.RO

TL;DR: 提出了一种可扩展的抓取生成和优化方法，实现了多样化和物理可行的抓取方案，大幅提高了抓取稳定性和覆盖度。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决数据驱动的抓取预测在生成和使用多样化抓取数据集方面所面临的挑战，尤其是在限制于狭窄的抓取器形态和生成昂贵的数据集时的困难。

Method: 提出一个可扩展的生成-精炼管道，通过在高保真模拟器中进行进化搜索和优化，持续提高抓取质量而不丢弃之前生成的候选抓取。

Result: 在Handles数据集和DexGraspNet子集上的实验表明，提出的方法每个物体能够实现超过120种不同的稳定抓取，比未优化的分析方法提高了1.7-6倍，并在独特抓取覆盖率上超过扩散模型的方法46-60%。

Conclusion: 该方法促进了高效抓取生成，强调了多样性在训练和实际部署中的重要性，同时展示了高保真模拟器在优化抓取中的潜力。

Abstract: Dexterous grasping is fundamental to robotics, yet data-driven grasp prediction heavily relies on large, diverse datasets that are costly to generate and typically limited to a narrow set of gripper morphologies. Analytical grasp synthesis can be used to scale data collection, but necessary simplifying assumptions often yield physically infeasible grasps that need to be filtered in high-fidelity simulators, significantly reducing the total number of grasps and their diversity.
  We propose a scalable generate-and-refine pipeline for synthesizing large-scale, diverse, and physically feasible grasps. Instead of using high-fidelity simulators solely for verification and filtering, we leverage them as an optimization stage that continuously improves grasp quality without discarding precomputed candidates. More specifically, we initialize an evolutionary search with a seed set of analytically generated, potentially suboptimal grasps. We then refine these proposals directly in a high-fidelity simulator (Isaac Sim) using an asynchronous, gradient-free evolutionary algorithm, improving stability while maintaining diversity. In addition, this refinement stage can be guided toward human preferences and/or domain-specific quality metrics without requiring a differentiable objective. We further distill the refined grasp distribution into a diffusion model for robust real-world deployment, and highlight the role of diversity for both effective training and during deployment. Experiments on a newly introduced Handles dataset and a DexGraspNet subset demonstrate that our approach achieves over 120 distinct stable grasps per object (a 1.7-6x improvement over unrefined analytical methods) while outperforming diffusion-based alternatives by 46-60\% in unique grasp coverage.

</details>


### [19] [SEG-JPEG: Simple Visual Semantic Communications for Remote Operation of Automated Vehicles over Unreliable Wireless Networks](https://arxiv.org/abs/2602.15258)
*Sebastian Donnelly,Ruth Anderson,George Economides,James Broughton,Peter Ball,Alexander Rast,Andrew Bradley*

Main category: cs.RO

TL;DR: 本论文探讨了通过计算机视觉辅助的语义通信来减少遥控自动驾驶车辆图像传输的数据需求，成功在低数据速率下实现高效的遥控操作。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶车辆的快速发展，确保可靠的远程操作在现实世界中尤为重要，尤其是在公共网络基础设施受限的情况下。

Method: 通过将检测到的道路用户的分割编码成低分辨率灰度图像中的彩色高亮，降低了数据传输率，使图像传输的延迟大幅降低，同时保持了视觉清晰度。

Result: 通过应用计算机视觉辅助的语义通信技术，能够有效减少传统图像压缩技术所导致的数据损失和数据损坏问题，从而使遥控自动驾驶车辆的远程操作成为可能。

Conclusion: 该研究表明，采用该技术的远程操作自动车辆的广泛部署在当前公共4G/5G移动网络上是可行的，这可能加速自动驾驶车辆在全国范围内的推广。

Abstract: Remote Operation is touted as being key to the rapid deployment of automated vehicles. Streaming imagery to control connected vehicles remotely currently requires a reliable, high throughput network connection, which can be limited in real-world remote operation deployments relying on public network infrastructure. This paper investigates how the application of computer vision assisted semantic communication can be used to circumvent data loss and corruption associated with traditional image compression techniques. By encoding the segmentations of detected road users into colour coded highlights within low resolution greyscale imagery, the required data rate can be reduced by 50 \% compared with conventional techniques, while maintaining visual clarity. This enables a median glass-to-glass latency of below 200ms even when the network data rate is below 500kbit/s, while clearly outlining salient road users to enhance situational awareness of the remote operator. The approach is demonstrated in an area of variable 4G mobile connectivity using an automated last-mile delivery vehicle. With this technique, the results indicate that large-scale deployment of remotely operated automated vehicles could be possible even on the often constrained public 4G/5G mobile network, providing the potential to expedite the nationwide roll-out of automated vehicles.

</details>


### [20] [OSCAR: An Ovipositor-Inspired Self-Propelling Capsule Robot for Colonoscopy](https://arxiv.org/abs/2602.15309)
*Mostafa A. Atalla,Anand S. Sekar,Remi van Starkenburg,David J. Jager,Aimée Sakes,Michaël Wiertlewski,Paul Breedveld*

Main category: cs.RO

TL;DR: OSCAR是一种模仿寄生黄蜂产卵器的自推进胶囊机器人，能够在结肠中稳定运动，生成可控推力，从而提高结肠镜检查的安全性和有效性。


<details>
  <summary>Details</summary>
Motivation: 传统结肠镜检查中的轴向环路会增加患者的不适感，因此需要避免这种情况。

Method: OSCAR通过弹簧加载凸轮系统实现了模仿寄生黄蜂产卵器的运动模式，该系统驱动十二个圆周滑块以协调的、相位偏移的顺序运动。

Result: 在体外猪结肠的综合力特性实验中，平均稳态牵引力为0.85 N，符合模型预测，同时验证了推力生成的速度无关性，并与相位不对称性线性相关，强调了胶囊的可预测性能和可扩展性。

Conclusion: 通过将相位编码的摩擦各向异性与预测模型相结合，OSCAR实现了在低法向载荷下可控的推力生成，从而为机器人胶囊结肠镜检查提供了更安全和更稳健的自推进运动。

Abstract: Self-propelling robotic capsules eliminate shaft looping of conventional colonoscopy, reducing patient discomfort. However, reliably moving within the slippery, viscoelastic environment of the colon remains a significant challenge. We present OSCAR, an ovipositor-inspired self-propelling capsule robot that translates the transport strategy of parasitic wasps into a propulsion mechanism for colonoscopy. OSCAR mechanically encodes the ovipositor-inspired motion pattern through a spring-loaded cam system that drives twelve circumferential sliders in a coordinated, phase-shifted sequence. By tuning the motion profile to maximize the retract phase relative to the advance phase, the capsule creates a controlled friction anisotropy at the interface that generates net forward thrust. We developed an analytical model incorporating a Kelvin-Voigt formulation to capture the viscoelastic stick--slip interactions between the sliders and the tissue, linking the asymmetry between advance and retract phase durations to mean thrust, and slider-reversal synchronization to thrust stability. Comprehensive force characterization experiments in ex-vivo porcine colon revealed a mean steady-state traction force of 0.85 N, closely matching the model. Furthermore, experiments confirmed that thrust generation is speed-independent and scales linearly with the phase asymmetry, in agreement with theoretical predictions, underscoring the capsule's predictable performance and scalability. In locomotion validation experiments, OSCAR demonstrated robust performance, achieving an average speed of 3.08 mm/s, a velocity sufficient to match the cecal intubation times of conventional colonoscopy. By coupling phase-encoded friction anisotropy with a predictive model, OSCAR delivers controllable thrust generation at low normal loads, enabling safer and more robust self-propelling locomotion for robotic capsule colonoscopy.

</details>


### [21] [Feasibility-aware Imitation Learning from Observation with Multimodal Feedback](https://arxiv.org/abs/2602.15351)
*Kei Takahashi,Hikaru Sasaki,Takamitsu Matsubara*

Main category: cs.RO

TL;DR: FABCO是一种考虑可行性的模仿学习框架，通过机器人动力学模型和可行性估计，改善了机器人控制策略的学习。


<details>
  <summary>Details</summary>
Motivation: 传统的模仿学习方法因演示者和机器人之间的物理差异而面临挑战，尤其是在可行性和有效性方面。

Method: FABCO通过结合观察的行为克隆与可行性估计，利用机器人动力学模型评估演示动作的可行性，从而提升模仿学习的效果和稳定性。

Result: FABCO通过结合观察行为克隆和可行性估计，使机器人能够学习稳健的控制策略，在15名参与者的实验中，FABCO在模仿学习性能上提高了3.2倍以上。

Conclusion: FABCO有效解决了演示数据与机器人执行能力之间的差异，提升了模仿学习的可行性和性能。

Abstract: Imitation learning frameworks that learn robot control policies from demonstrators' motions via hand-mounted demonstration interfaces have attracted increasing attention. However, due to differences in physical characteristics between demonstrators and robots, this approach faces two limitations: i) the demonstration data do not include robot actions, and ii) the demonstrated motions may be infeasible for robots. These limitations make policy learning difficult. To address them, we propose Feasibility-Aware Behavior Cloning from Observation (FABCO). FABCO integrates behavior cloning from observation, which complements robot actions using robot dynamics models, with feasibility estimation. In feasibility estimation, the demonstrated motions are evaluated using a robot-dynamics model, learned from the robot's execution data, to assess reproducibility under the robot's dynamics. The estimated feasibility is used for multimodal feedback and feasibility-aware policy learning to improve the demonstrator's motions and learn robust policies. Multimodal feedback provides feasibility through the demonstrator's visual and haptic senses to promote feasible demonstrated motions. Feasibility-aware policy learning reduces the influence of demonstrated motions that are infeasible for robots, enabling the learning of policies that robots can execute stably. We conducted experiments with 15 participants on two tasks and confirmed that FABCO improves imitation learning performance by more than 3.2 times compared to the case without feasibility feedback.

</details>


### [22] [A Comparison of Bayesian Prediction Techniques for Mobile Robot Trajectory Tracking](https://arxiv.org/abs/2602.15354)
*Jose Luis Peralta-Cabezas,Miguel Torres-Torriti,Marcelo Guarini-Hermann*

Main category: cs.RO

TL;DR: 本文比较了多种机器人跟踪的估计和预测技术，分析了它们在估计误差、计算效率及对噪声鲁棒性方面的表现。


<details>
  <summary>Details</summary>
Motivation: 随着多机器人系统的应用需求增加，寻找高效、鲁棒的跟踪技术成为必要。

Method: 分析比较了卡尔曼滤波器及其变种和序列蒙特卡罗采样方法，包括粒子滤波器和高斯混合 sigma 点粒子滤波器。

Result: 本研究比较了多种机器人跟踪的估计和预测技术的性能，包括传统的卡尔曼滤波器及其变种、基于序列蒙特卡罗采样方法的技术等。

Conclusion: 研究指出不同方法在估计误差、计算努力和对非高斯噪声的鲁棒性方面有显著差异。

Abstract: This paper presents a performance comparison of different estimation and prediction techniques applied to the problem of tracking multiple robots. The main performance criteria are the magnitude of the estimation or prediction error, the computational effort and the robustness of each method to non-Gaussian noise. Among the different techniques compared are the well known Kalman filters and their different variants (e.g. extended and unscented), and the more recent techniques relying on Sequential Monte Carlo Sampling methods, such as particle filters and Gaussian Mixture Sigma Point Particle Filter.

</details>


### [23] [Fluoroscopy-Constrained Magnetic Robot Control via Zernike-Based Field Modeling and Nonlinear MPC](https://arxiv.org/abs/2602.15357)
*Xinhao Chen,Hongkun Yao,Anuruddha Bhattacharjee,Suraj Raval,Lamar O. Mair,Yancy Diaz-Mercado,Axel Krieger*

Main category: cs.RO

TL;DR: 本文提出了一种新型控制框架，能够提高磁驱动手术机器人在低帧率和噪声条件下的控制精度，实验结果显示其在药物递送中的有效性和安全性。


<details>
  <summary>Details</summary>
Motivation: 解决在荧光成像条件下，控制磁驱动手术机器人时面临的低帧率和噪声反馈的问题，从而提高手术精度并减少组织创伤。

Method: 结合非线性模型预测控制(NMPC)、基于Zernike多项式的可微分磁场模型和卡尔曼滤波器的控制框架。

Result: 在反馈频率降至3Hz并添加高斯噪声的情况下，该控制方法仍保持高精度；在脊柱模型实验中，成功执行药物递送轨迹，均方根位置误差为1.18mm。

Conclusion: 所提出的控制方法在模拟临床环境下具有高精度和稳定性，能够有效执行药物递送轨迹，并确保与关键解剖边界的安全间隔。

Abstract: Magnetic actuation enables surgical robots to navigate complex anatomical pathways while reducing tissue trauma and improving surgical precision. However, clinical deployment is limited by the challenges of controlling such systems under fluoroscopic imaging, which provides low frame rate and noisy pose feedback. This paper presents a control framework that remains accurate and stable under such conditions by combining a nonlinear model predictive control (NMPC) framework that directly outputs coil currents, an analytically differentiable magnetic field model based on Zernike polynomials, and a Kalman filter to estimate the robot state. Experimental validation is conducted with two magnetic robots in a 3D-printed fluid workspace and a spine phantom replicating drug delivery in the epidural space. Results show the proposed control method remains highly accurate when feedback is downsampled to 3 Hz with added Gaussian noise (sigma = 2 mm), mimicking clinical fluoroscopy. In the spine phantom experiments, the proposed method successfully executed a drug delivery trajectory with a root mean square (RMS) position error of 1.18 mm while maintaining safe clearance from critical anatomical boundaries.

</details>


### [24] [ActionCodec: What Makes for Good Action Tokenizers](https://arxiv.org/abs/2602.15397)
*Zibin Dong,Yicheng Liu,Shiduo Zhang,Baijun Ye,Yifu Yuan,Fei Ni,Jingjing Gong,Xipeng Qiu,Hang Zhao,Yinchuan Li,Jianye Hao*

Main category: cs.RO

TL;DR: 本文通过从VLA优化的角度建立设计原则，提出高效的动作标记器ActionCodec，显著提升了模型性能和效率。


<details>
  <summary>Details</summary>
Motivation: 传统的动作标记设计更多关注于重构精度，而忽视了其对Vision-Language-Action (VLA)模型优化的直接影响。

Method: 建立从VLA优化的角度出发的设计原则，并根据信息论见解，识别一组最佳实践，推出高性能的动作标记器ActionCodec。

Result: ActionCodec显著提高了训练效率和VLA性能，在LIBERO基准上，经过ActionCodec微调的SmolVLM2-2.2B达到了95.5%的成功率，最新架构的性能进一步提升至97.4%。

Conclusion: 我们的设计原则和发布的模型为社区开发更有效的动作标记器提供了明确的路线图。

Abstract: Vision-Language-Action (VLA) models leveraging the native autoregressive paradigm of Vision-Language Models (VLMs) have demonstrated superior instruction-following and training efficiency. Central to this paradigm is action tokenization, yet its design has primarily focused on reconstruction fidelity, failing to address its direct impact on VLA optimization. Consequently, the fundamental question of \textit{what makes for good action tokenizers} remains unanswered. In this paper, we bridge this gap by establishing design principles specifically from the perspective of VLA optimization. We identify a set of best practices based on information-theoretic insights, including maximized temporal token overlap, minimized vocabulary redundancy, enhanced multimodal mutual information, and token independence. Guided by these principles, we introduce \textbf{ActionCodec}, a high-performance action tokenizer that significantly enhances both training efficiency and VLA performance across diverse simulation and real-world benchmarks. Notably, on LIBERO, a SmolVLM2-2.2B fine-tuned with ActionCodec achieves a 95.5\% success rate without any robotics pre-training. With advanced architectural enhancements, this reaches 97.4\%, representing a new SOTA for VLA models without robotics pre-training. We believe our established design principles, alongside the released model, will provide a clear roadmap for the community to develop more effective action tokenizers.

</details>


### [25] [Hybrid F' and ROS2 Architecture for Vision-Based Autonomous Flight: Design and Experimental Validation](https://arxiv.org/abs/2602.15398)
*Abdelrahman Metwally,Monijesu James,Aleksey Fedoseev,Miguel Altamirano Cabrera,Dzmitry Tsetserukou,Andrey Somov*

Main category: cs.RO

TL;DR: 本研究提出了一种结合NASA的F'飞行软件框架与ROS2中间件的自主航空系统架构，经过32.25分钟的室内飞行测试，验证了系统的实时性能和高效性。


<details>
  <summary>Details</summary>
Motivation: 随着自主航空系统的需求增加，亟需平衡确定性实时控制与先进感知能力的架构。

Method: 将NASA的F'飞行软件框架与ROS2中间件通过Protocol Buffers连接，进行室内四旋翼飞行测试。

Result: 飞行测试中，视觉系统达到87.19 Hz的位置估计，数据连续性为99.90，平均延迟为11.47毫秒，所有15个地面指令100%成功执行，CPU和RAM使用率保持低水平。

Conclusion: 本研究结果验证了结合认证等级确定性与灵活自主性的混合飞行软件架构在自主航空器中的可行性。

Abstract: Autonomous aerospace systems require architectures that balance deterministic real-time control with advanced perception capabilities. This paper presents an integrated system combining NASA's F' flight software framework with ROS2 middleware via Protocol Buffers bridging. We evaluate the architecture through a 32.25-minute indoor quadrotor flight test using vision-based navigation. The vision system achieved 87.19 Hz position estimation with 99.90\% data continuity and 11.47 ms mean latency, validating real-time performance requirements. All 15 ground commands executed successfully with 100 % success rate, demonstrating robust F'--PX4 integration. System resource utilization remained low (15.19 % CPU, 1,244 MB RAM) with zero stale telemetry messages, confirming efficient operation on embedded platforms. Results validate the feasibility of hybrid flight-software architectures combining certification-grade determinism with flexible autonomy for autonomous aerial vehicles.

</details>


### [26] [One Agent to Guide Them All: Empowering MLLMs for Vision-and-Language Navigation via Explicit World Representation](https://arxiv.org/abs/2602.15400)
*Zerui Li,Hongpei Zheng,Fangguo Zhao,Aidan Chan,Jian Zhou,Sihao Lin,Shijie Li,Qi Wu*

Main category: cs.RO

TL;DR: 本研究提出了一种解耦设计的导航框架，利用交互式度量世界表示和反事实推理，在多种环境中验证了其有效性，达到了新的零-shot最优表现。


<details>
  <summary>Details</summary>
Motivation: 构建一个有效的导航智能体，需要同时理解高层次的语义指令和精确的空间感知。

Method: 提出了一种解耦设计，将低层次的空间状态估计与高层次的语义规划分离，使用交互式度量世界表示，结合反事实推理，增强了智能体的决策能力。

Result: 在模拟和真实环境中进行全面实验，方法在R2R-CE基准测试中取得了48.8%的成功率，RxR-CE中为42.2%。

Conclusion: 该解耦框架证明了作为一种强大的、领域不变的接口，支持更好的Vision-and-Language导航，实际应用中展示了零-shot从模拟到真实的迁移能力。

Abstract: A navigable agent needs to understand both high-level semantic instructions and precise spatial perceptions. Building navigation agents centered on Multimodal Large Language Models (MLLMs) demonstrates a promising solution due to their powerful generalization ability. However, the current tightly coupled design dramatically limits system performance. In this work, we propose a decoupled design that separates low-level spatial state estimation from high-level semantic planning. Unlike previous methods that rely on predefined, oversimplified textual maps, we introduce an interactive metric world representation that maintains rich and consistent information, allowing MLLMs to interact with and reason on it for decision-making. Furthermore, counterfactual reasoning is introduced to further elicit MLLMs' capacity, while the metric world representation ensures the physical validity of the produced actions. We conduct comprehensive experiments in both simulated and real-world environments. Our method establishes a new zero-shot state-of-the-art, achieving 48.8\% Success Rate (SR) in R2R-CE and 42.2\% in RxR-CE benchmarks. Furthermore, to validate the versatility of our metric representation, we demonstrate zero-shot sim-to-real transfer across diverse embodiments, including a wheeled TurtleBot 4 and a custom-built aerial drone. These real-world deployments verify that our decoupled framework serves as a robust, domain-invariant interface for embodied Vision-and-Language navigation.

</details>


### [27] [Lyapunov-Based $\mathcal{L}_2$-Stable PI-Like Control of a Four-Wheel Independently Driven and Steered Robot](https://arxiv.org/abs/2602.15424)
*Branimir Ćaran,Vladimir Milić,Bojan Jerbić*

Main category: cs.RO

TL;DR: 提出了一种基于Lyapunov的PI类控制器用于四轮移动机器人的运动控制，确保了实时操作的稳定性与性能，通过实验证实了其有效性和坚固性。


<details>
  <summary>Details</summary>
Motivation: 研究目标是实现四轮移动机器人的$	extbf{L}_2$稳定运动控制，提高实时操作的安全性和有效性。

Method: 基于Lyapunov的方法合成PI类控制器，利用显性模型进行系统化设计，确保稳定性与性能。

Result: 通过实验验证，该控制法律保持PI类形式，具备显著的稳定性属性，并在实际四轮移动机器人平台上表现出良好的效果与强健性。

Conclusion: 所提出的PI类控制器在四轮移动机器人上有效且稳健地运作，证明了它在实时应用中的可行性和稳定性特性。

Abstract: In this letter, Lyapunov-based synthesis of a PI-like controller is proposed for $\mathcal{L}_2$-stable motion control of an independently driven and steered four-wheel mobile robot. An explicit, structurally verified model is used to enable systematic controller design with stability and performance guarantees suitable for real-time operation. A Lyapunov function is constructed to yield explicit bounds and $\mathcal{L}_2$ stability results, supporting feedback synthesis that reduces configuration dependent effects. The resulting control law maintains a PI-like form suitable for standard embedded implementation while preserving rigorous stability properties. Effectiveness and robustness are demonstrated experimentally on a real four-wheel mobile robot platform.

</details>


### [28] [Improving MLLMs in Embodied Exploration and Question Answering with Human-Inspired Memory Modeling](https://arxiv.org/abs/2602.15513)
*Ji Li,Jing Xia,Mingyi Li,Shiyan Hu*

Main category: cs.RO

TL;DR: 本研究提出了一种非参数记忆框架，通过显性区分情节记忆和语义记忆，改善了大规模语言模型在长期观察下的表现，尤其是在复杂推理和探索任务中。


<details>
  <summary>Details</summary>
Motivation: 在长期观察和有限上下文预算的情况下，基于多模态大语言模型的具身代理的应用仍然存在挑战；现有的方法在动态环境中表现不佳。

Method: 本研究提出了一种非参数记忆框架，利用语义相似性召回情节经验，并通过视觉推理进行验证；同时引入了一种程序风格的规则提取机制，将经验转换为结构化的可重用语义记忆。

Result: 在多个具身问答和探索基准测试中，表现出最佳性能，LLM-Match提高了7.3%，LLM MatchXSPL提高了11.4%，GOAT-Bench的成功率提高了7.7%。

Conclusion: 我们的非参数记忆框架在探索和问答任务中取得了最佳性能，改进了代理的探索效率和推理能力。

Abstract: Deploying Multimodal Large Language Models as the brain of embodied agents remains challenging, particularly under long-horizon observations and limited context budgets. Existing memory assisted methods often rely on textual summaries, which discard rich visual and spatial details and remain brittle in non-stationary environments. In this work, we propose a non-parametric memory framework that explicitly disentangles episodic and semantic memory for embodied exploration and question answering. Our retrieval-first, reasoning-assisted paradigm recalls episodic experiences via semantic similarity and verifies them through visual reasoning, enabling robust reuse of past observations without rigid geometric alignment. In parallel, we introduce a program-style rule extraction mechanism that converts experiences into structured, reusable semantic memory, facilitating cross-environment generalization. Extensive experiments demonstrate state-of-the-art performance on embodied question answering and exploration benchmarks, yielding a 7.3% gain in LLM-Match and an 11.4% gain in LLM MatchXSPL on A-EQA, as well as +7.7% success rate and +6.8% SPL on GOAT-Bench. Analyses reveal that our episodic memory primarily improves exploration efficiency, while semantic memory strengthens complex reasoning of embodied agents.

</details>


### [29] [Efficient Knowledge Transfer for Jump-Starting Control Policy Learning of Multirotors through Physics-Aware Neural Architectures](https://arxiv.org/abs/2602.15533)
*Welf Rehberg,Mihir Kulkarni,Philipp Weiss,Kostas Alexis*

Main category: cs.RO

TL;DR: 通过基于库的初始化方案和相似性度量，实现了高效的多旋翼政策训练，节省了大量环境交互。


<details>
  <summary>Details</summary>
Motivation: 利用从训练类似系统中获得的知识，通过跨形态知识转移加速机器人控制政策的训练。

Method: 一种基于库的初始化方案，结合物理感知神经控制架构，利用强化学习控制器和监督控制分配网络，加速多旋翼配置的政策训练。

Result: 通过使用基于政策评价的相似性度量，识别适合初始化的政策，从而重用以前训练的政策。仿真实验和现实世界实验验证了该控制架构实现了最先进的控制性能，平均节省了73.5%的环境交互。

Conclusion: 该初始化方案有效减少了训练所需的环境交互，为强化学习中的跨形态迁移提供了新途径。

Abstract: Efficiently training control policies for robots is a major challenge that can greatly benefit from utilizing knowledge gained from training similar systems through cross-embodiment knowledge transfer. In this work, we focus on accelerating policy training using a library-based initialization scheme that enables effective knowledge transfer across multirotor configurations. By leveraging a physics-aware neural control architecture that combines a reinforcement learning-based controller and a supervised control allocation network, we enable the reuse of previously trained policies. To this end, we utilize a policy evaluation-based similarity measure that identifies suitable policies for initialization from a library. We demonstrate that this measure correlates with the reduction in environment interactions needed to reach target performance and is therefore suited for initialization. Extensive simulation and real-world experiments confirm that our control architecture achieves state-of-the-art control performance, and that our initialization scheme saves on average up to $73.5\%$ of environment interactions (compared to training a policy from scratch) across diverse quadrotor and hexarotor designs, paving the way for efficient cross-embodiment transfer in reinforcement learning.

</details>


### [30] [Estimating Human Muscular Fatigue in Dynamic Collaborative Robotic Tasks with Learning-Based Models](https://arxiv.org/abs/2602.15684)
*Feras Kiki,Pouya P. Niaz,Alireza Madani,Cagatay Basdogan*

Main category: cs.RO

TL;DR: 本研究提出了一种基于数据的框架，通过表面肌电图(sEMG)评估人类肌肉疲劳，旨在优化身体人机交互(pHRI)中的性能与安全性。


<details>
  <summary>Details</summary>
Motivation: 评估肌肉疲劳对于保障人机交互（pHRI）的安全和提升性能至关重要。

Method: 研究使用了基于机器学习的回归模型（如随机森林、XGBoost和线性回归）和卷积神经网络（CNN），分析肌电图特征以预测疲劳进度。

Result: 实验结果显示，CNN实现了平均20.8%的疲劳预测误差，优于其他机器学习模型。对于未见的任务，模型在准确性上也显示出一定的鲁棒性。

Conclusion: 该研究表明，不同的机器学习和深度学习方法能够有效评估重复性人机交互过程中的剩余工作能力，CNN提供了最佳的预测准确性，具有在不需重新训练的情况下适应新动作模式的潜力。

Abstract: Assessing human muscle fatigue is critical for optimizing performance and safety in physical human-robot interaction(pHRI). This work presents a data-driven framework to estimate fatigue in dynamic, cyclic pHRI using arm-mounted surface electromyography(sEMG). Subject-specific machine-learning regression models(Random Forest, XGBoost, and Linear Regression predict the fraction of cycles to fatigue(FCF) from three frequency-domain and one time-domain EMG features, and are benchmarked against a convolutional neural network(CNN) that ingests spectrograms of filtered EMG. Framing fatigue estimation as regression (rather than classification) captures continuous progression toward fatigue, supporting earlier detection, timely intervention, and adaptive robot control. In experiments with ten participants, a collaborative robot under admittance control guided repetitive lateral (left-right) end-effector motions until muscular fatigue. Average FCF RMSE across participants was 20.8+/-4.3% for the CNN, 23.3+/-3.8% for Random Forest, 24.8+/-4.5% for XGBoost, and 26.9+/-6.1% for Linear Regression. To probe cross-task generalization, one participant additionally performed unseen vertical (up-down) and circular repetitions; models trained only on lateral data were tested directly and largely retained accuracy, indicating robustness to changes in movement direction, arm kinematics, and muscle recruitment, while Linear Regression deteriorated. Overall, the study shows that both feature-based ML and spectrogram-based DL can estimate remaining work capacity during repetitive pHRI, with the CNN delivering the lowest error and the tree-based models close behind. The reported transfer to new motion patterns suggests potential for practical fatigue monitoring without retraining for every task, improving operator protection and enabling fatigue-aware shared autonomy, for safer fatigue-adaptive pHRI control.

</details>


### [31] [Selective Perception for Robot: Task-Aware Attention in Multimodal VLA](https://arxiv.org/abs/2602.15543)
*Young-Chae Son,Jung-Woo Lee,Yoon-Ji Choi,Dae-Kwan Ko,Soo-Chul Lim*

Main category: cs.RO

TL;DR: 本文提出一种动态信息融合框架，提升VLA模型在机器人任务中的推理效率和控制性能。


<details>
  <summary>Details</summary>
Motivation: 旨在提高现有静态融合方法在多视角输入中的计算效率，并减少与任务无关的背景信息噪声。

Method: 提出了一种动态信息融合框架，利用轻量自适应路由架构实时分析文本提示和来自手腕安装摄像头的观察，预测多摄像机视图的任务相关性。

Result: 在真实机器人操作场景的实验结果中，所提出的方法在推理效率和控制性能方面显著优于现有的VLA模型。

Conclusion: 动态信息融合在资源受限的实时机器人控制环境中具有有效性和实用性。

Abstract: In robotics, Vision-Language-Action (VLA) models that integrate diverse multimodal signals from multi-view inputs have emerged as an effective approach. However, most prior work adopts static fusion that processes all visual inputs uniformly, which incurs unnecessary computational overhead and allows task-irrelevant background information to act as noise. Inspired by the principles of human active perception, we propose a dynamic information fusion framework designed to maximize the efficiency and robustness of VLA models. Our approach introduces a lightweight adaptive routing architecture that analyzes the current text prompt and observations from a wrist-mounted camera in real-time to predict the task-relevance of multiple camera views. By conditionally attenuating computations for views with low informational utility and selectively providing only essential visual features to the policy network, Our framework achieves computation efficiency proportional to task relevance. Furthermore, to efficiently secure large-scale annotation data for router training, we established an automated labeling pipeline utilizing Vision-Language Models (VLMs) to minimize data collection and annotation costs. Experimental results in real-world robotic manipulation scenarios demonstrate that the proposed approach achieves significant improvements in both inference efficiency and control performance compared to existing VLA models, validating the effectiveness and practicality of dynamic information fusion in resource-constrained, real-time robot control environments.

</details>


### [32] [Robot-Assisted Social Dining as a White Glove Service](https://arxiv.org/abs/2602.15767)
*Atharva S Kashyap,Ugne Aleksandra Morkute,Patricia Alves-Oliveira*

Main category: cs.RO

TL;DR: 研究了机器人辅助喂养在现实社交饮食场景中的设计挑战，提出了机器人应具备的关键特征，以提升用户的独立性和就餐体验。


<details>
  <summary>Details</summary>
Motivation: 旨在帮助需要喂养辅助的残疾人士在社交饮食环境中独立就餐，提升他们的就餐体验和尊严。

Method: 通过与残疾人士的投机性参与设计，结合半结构化访谈和自定义基于AI的视觉故事板工具，探索适用于现实社交饮食场景的设计理念。

Result: 揭示了理想的外部社交就餐场景，并提出机器人应具备的特征，包括多模态输入和低调输出、上下文敏感的社交行为、超越喂食的角色、适应餐桌上的不同关系。

Conclusion: 本研究为在现实世界和团体环境中进行机器人辅助喂养提供了重要启示与设计原则。

Abstract: Robot-assisted feeding enables people with disabilities who require assistance eating to enjoy a meal independently and with dignity. However, existing systems have only been tested in-lab or in-home, leaving in-the-wild social dining contexts (e.g., restaurants) largely unexplored. Designing a robot for such contexts presents unique challenges, such as dynamic and unsupervised dining environments that a robot needs to account for and respond to. Through speculative participatory design with people with disabilities, supported by semi-structured interviews and a custom AI-based visual storyboarding tool, we uncovered ideal scenarios for in-the-wild social dining. Our key insight suggests that such systems should: embody the principles of a white glove service where the robot (1) supports multimodal inputs and unobtrusive outputs; (2) has contextually sensitive social behavior and prioritizes the user; (3) has expanded roles beyond feeding; (4) adapts to other relationships at the dining table. Our work has implications for in-the-wild and group contexts of robot-assisted feeding.

</details>


### [33] [VLM-DEWM: Dynamic External World Model for Verifiable and Resilient Vision-Language Planning in Manufacturing](https://arxiv.org/abs/2602.15549)
*Guoqin Tang,Qingxuan Jia,Gang Chen,Tong Li,Zeyuan Huang,Zihang Lv,Ning Ji*

Main category: cs.RO

TL;DR: VLM-DEWM是一种融合动态外部世界模型的视觉语言模型架构，提高了机器人在动态制造环境中的决策能力和故障恢复效率。


<details>
  <summary>Details</summary>
Motivation: 传统的视觉语言模型在动态工作单元中面临无法持久跟踪状态和推理不透明的问题，限制了其应用效果。

Method: 提出了一种通过动态外部世界模型（DEWM）解耦VLM推理与世界状态管理的认知架构，每个决策的外部化推理追踪（ERT）结构化为行动提案、世界信念和因果假设。

Result: 与基线内存增强VLM系统相比，VLM-DEWM在状态追踪准确性上提高至93%，故障恢复成功率提高至95%，并显著降低了计算开销。

Conclusion: VLM-DEWM被确立为动态制造环境中长时间机器人操作的可验证和韧性解决方案。

Abstract: Vision-language model (VLM) shows promise for high-level planning in smart manufacturing, yet their deployment in dynamic workcells faces two critical challenges: (1) stateless operation, they cannot persistently track out-of-view states, causing world-state drift; and (2) opaque reasoning, failures are difficult to diagnose, leading to costly blind retries. This paper presents VLM-DEWM, a cognitive architecture that decouples VLM reasoning from world-state management through a persistent, queryable Dynamic External World Model (DEWM). Each VLM decision is structured into an Externalizable Reasoning Trace (ERT), comprising action proposal, world belief, and causal assumption, which is validated against DEWM before execution. When failures occur, discrepancy analysis between predicted and observed states enables targeted recovery instead of global replanning. We evaluate VLM-DEWM on multi-station assembly, large-scale facility exploration, and real-robot recovery under induced failures. Compared to baseline memory-augmented VLM systems, VLM DEWM improves state-tracking accuracy from 56% to 93%, increases recovery success rate from below 5% to 95%, and significantly reduces computational overhead through structured memory. These results establish VLM-DEWM as a verifiable and resilient solution for long-horizon robotic operations in dynamic manufacturing environments.

</details>


### [34] [Constraining Streaming Flow Models for Adapting Learned Robot Trajectory Distributions](https://arxiv.org/abs/2602.15567)
*Jieting Long,Dechuan Liu,Weidong Cai,Ian Manchester,Weiming Zhi*

Main category: cs.RO

TL;DR: CASF框架结合约束相关度量，增强流动策略的适应能力，确保机器人在执行过程中遵守安全与任务特定约束。


<details>
  <summary>Details</summary>
Motivation: 机器人运动分布通常表现出多模态特性，需要灵活的生成模型以进行准确的表示。

Method: 提出了一种增强流动策略的框架（CASF），利用约束相关的度量在执行过程中重塑学习到的速度场。

Result: CASF允许实时时间适应轨迹，确保机器人动作遵守关节限制、避免碰撞，并保持在可行的工作空间内，同时保持流动策略的多模态性和反应性。

Conclusion: CASF能够在模拟和真实世界的操控任务中产生满足约束的轨迹，且这些轨迹平滑、可行且动态一致，优于标准的后处理投影基线。

Abstract: Robot motion distributions often exhibit multi-modality and require flexible generative models for accurate representation. Streaming Flow Policies (SFPs) have recently emerged as a powerful paradigm for generating robot trajectories by integrating learned velocity fields directly in action space, enabling smooth and reactive control. However, existing formulations lack mechanisms for adapting trajectories post-training to enforce safety and task-specific constraints. We propose Constraint-Aware Streaming Flow (CASF), a framework that augments streaming flow policies with constraint-dependent metrics that reshape the learned velocity field during execution. CASF models each constraint, defined in either the robot's workspace or configuration space, as a differentiable distance function that is converted into a local metric and pulled back into the robot's control space. Far from restricted regions, the resulting metric reduces to the identity; near constraint boundaries, it smoothly attenuates or redirects motion, effectively deforming the underlying flow to maintain safety. This allows trajectories to be adapted in real time, ensuring that robot actions respect joint limits, avoid collisions, and remain within feasible workspaces, while preserving the multi-modal and reactive properties of streaming flow policies. We demonstrate CASF in simulated and real-world manipulation tasks, showing that it produces constraint-satisfying trajectories that remain smooth, feasible, and dynamically consistent, outperforming standard post-hoc projection baselines.

</details>


### [35] [Grip as Needed, Glide on Demand: Ultrasonic Lubrication for Robotic Locomotion](https://arxiv.org/abs/2602.15608)
*Mostafa A. Atalla,Daan van Bemmel,Jack Cummings,Paul Breedveld,Michaël Wiertlewski,Aimée Sakes*

Main category: cs.RO

TL;DR: 本研究介绍了一种新型超声波润滑方法，可主动控制机器人运动中的摩擦力，展示了在多种表面条件下优秀的运动效率。


<details>
  <summary>Details</summary>
Motivation: 传统上，机器人的摩擦力被视为固定的，被表面材料和环境条件决定。本研究旨在发展一种新的方法来主动调控摩擦，以提高机械系统的运动能力和效率。

Method: 通过激励超声波频率的共振结构，实现在不同表面条件下的摩擦状态切换，设计并测试了两种摩擦控制模块，并整合到仿生系统中进行实验。

Result: 本研究提出了一种超声波润滑技术，能实时控制机器人运动中的摩擦力，从而提高运动效率和设计灵活性。

Conclusion: 超声波润滑可以作为一种有效的主动摩擦控制机制，广泛适用于不同表面，显著降低摩擦力并实现高效的双向运动。

Abstract: Friction is the essential mediator of terrestrial locomotion, yet in robotic systems it is almost always treated as a passive property fixed by surface materials and conditions. Here, we introduce ultrasonic lubrication as a method to actively control friction in robotic locomotion. By exciting resonant structures at ultrasonic frequencies, contact interfaces can dynamically switch between "grip" and "slip" states, enabling locomotion. We developed two friction control modules, a cylindrical design for lumen-like environments and a flat-plate design for external surfaces, and integrated them into bio-inspired systems modeled after inchworm and wasp ovipositor locomotion. Both systems achieved bidirectional locomotion with nearly perfect locomotion efficiencies that exceeded 90%. Friction characterization experiments further demonstrated substantial friction reduction across various surfaces, including rigid, soft, granular, and biological tissue interfaces, under dry and wet conditions, and on surfaces with different levels of roughness, confirming the broad applicability of ultrasonic lubrication to locomotion tasks. These findings establish ultrasonic lubrication as a viable active friction control mechanism for robotic locomotion, with the potential to reduce design complexity and improve efficiency of robotic locomotion systems.

</details>


### [36] [SpecFuse: A Spectral-Temporal Fusion Predictive Control Framework for UAV Landing on Oscillating Marine Platforms](https://arxiv.org/abs/2602.15633)
*Haichao Liu,Yufeng Hu,Shuang Wang,Kangjun Guo,Jun Ma,Jinni Zhou*

Main category: cs.RO

TL;DR: 本研究提出了一种新型的控制框架SpecFuse，用于无人机在波动海洋平台上的自主着陆，显著提高了运动预测精度和成功率。


<details>
  <summary>Details</summary>
Motivation: 无人机在波动的海洋平台上自主着陆面临多频振荡、风干扰和运动预测中的预测相位延迟等限制。

Method: 提出了一种名为SpecFuse的光谱-时间融合预测控制框架，该框架结合了频域波分解和时域递归状态估计，以实现无载人水面车辆的高精度6自由度运动预测。

Result: 通过2,000次模拟和8次湖泊实验，方法实现了3.2厘米的预测误差，4.46厘米的着陆偏差，以及在模拟/现实世界中98.7%/87.5%的成功率，嵌入式硬件延迟为82毫秒，准确性比最先进的方法提高了44%-48%。

Conclusion: 该框架的鲁棒性支持关键海上任务，如搜救和环境监测，所有代码、实验配置和数据集将作为开源发布，以促进可重复性。

Abstract: Autonomous landing of Uncrewed Aerial Vehicles (UAVs) on oscillating marine platforms is severely constrained by wave-induced multi-frequency oscillations, wind disturbances, and prediction phase lags in motion prediction. Existing methods either treat platform motion as a general random process or lack explicit modeling of wave spectral characteristics, leading to suboptimal performance under dynamic sea conditions. To address these limitations, we propose SpecFuse: a novel spectral-temporal fusion predictive control framework that integrates frequency-domain wave decomposition with time-domain recursive state estimation for high-precision 6-DoF motion forecasting of Uncrewed Surface Vehicles (USVs). The framework explicitly models dominant wave harmonics to mitigate phase lags, refining predictions in real time via IMU data without relying on complex calibration. Additionally, we design a hierarchical control architecture featuring a sampling-based HPO-RRT* algorithm for dynamic trajectory planning under non-convex constraints and a learning-augmented predictive controller that fuses data-driven disturbance compensation with optimization-based execution. Extensive validations (2,000 simulations + 8 lake experiments) show our approach achieves a 3.2 cm prediction error, 4.46 cm landing deviation, 98.7% / 87.5% success rates (simulation / real-world), and 82 ms latency on embedded hardware, outperforming state-of-the-art methods by 44%-48% in accuracy. Its robustness to wave-wind coupling disturbances supports critical maritime missions such as search and rescue and environmental monitoring. All code, experimental configurations, and datasets will be released as open-source to facilitate reproducibility.

</details>


### [37] [Spatially-Aware Adaptive Trajectory Optimization with Controller-Guided Feedback for Autonomous Racing](https://arxiv.org/abs/2602.15642)
*Alexander Wachter,Alexander Willert,Marc-Philip Ecker,Christian Hartl-Nesic*

Main category: cs.RO

TL;DR: 该研究提出了一种结合多个优化技术的闭环框架，成功地优化了在不同抓地力条件下的自动赛车轨迹。


<details>
  <summary>Details</summary>
Motivation: 通过利用跟踪误差作为轨道特征的信号，构建自适应的加速度约束图，以逐步优化轨迹。

Method: 构建了一个闭环框架，结合了基于NURBS的轨迹表示、CMA-ES全局轨迹优化和基于控制器的空间反馈。

Result: 在模拟中，实现了与最大静态加速度参数化控制器相比，17.38%的圈速减少，真实硬件测试中在各种轮胎复合材料下获得了7.60%的圈速提升。

Conclusion: 该方法在不同的抓地力条件下表现出了稳健性，并在真实硬件测试中提高了7.60%的圈速。

Abstract: We present a closed-loop framework for autonomous raceline optimization that combines NURBS-based trajectory representation, CMA-ES global trajectory optimization, and controller-guided spatial feedback. Instead of treating tracking errors as transient disturbances, our method exploits them as informative signals of local track characteristics via a Kalman-inspired spatial update. This enables the construction of an adaptive, acceleration-based constraint map that iteratively refines trajectories toward near-optimal performance under spatially varying track and vehicle behavior. In simulation, our approach achieves a 17.38% lap time reduction compared to a controller parametrized with maximum static acceleration. On real hardware, tested with different tire compounds ranging from high to low friction, we obtain a 7.60% lap time improvement without explicitly parametrizing friction. This demonstrates robustness to changing grip conditions in real-world scenarios.

</details>


### [38] [Lifelong Scalable Multi-Agent Realistic Testbed and A Comprehensive Study on Design Choices in Lifelong AGV Fleet Management Systems](https://arxiv.org/abs/2602.15721)
*Jingtian Yan,Yulun Zhang,Zhenting Liu,Han Zhang,He Jiang,Jingkai Chen,Stephen F. Smith,Jiaoyang Li*

Main category: cs.RO

TL;DR: 本文介绍了 LSMART，一种开放源代码模拟器，用于在舰队管理系统中评估多智能体路径寻找算法，考虑了动态规划、规划时机和恢复策略等复杂因素。


<details>
  <summary>Details</summary>
Motivation: 受益于自动化仓库等应用的需求，本文旨在构建一个能够支持灵活目标分配和持续管理的多智能体路径寻找系统。

Method: 提出 LSMART 模拟器，通过考虑多个设计选择，包括规划和执行的并行化、规划方法的选择以及在失败时的恢复策略，来评估多智能体路径寻找算法。

Result: 实验结果基于最新的方法，为设计中心化的终身 AGV 舰队管理系统提供了有效的指导。

Conclusion: LSMART 提供了一个包含复杂设计选择的开放源代码模拟器，以有效评估多智能体路径寻找算法在自动化引导车辆舰队管理系统中的应用。

Abstract: We present Lifelong Scalable Multi-Agent Realistic Testbed (LSMART), an open-source simulator to evaluate any Multi-Agent Path Finding (MAPF) algorithm in a Fleet Management System (FMS) with Automated Guided Vehicles (AGVs). MAPF aims to move a group of agents from their corresponding starting locations to their goals. Lifelong MAPF (LMAPF) is a variant of MAPF that continuously assigns new goals for agents to reach. LMAPF applications, such as autonomous warehouses, often require a centralized, lifelong system to coordinate the movement of a fleet of robots, typically AGVs. However, existing works on MAPF and LMAPF often assume simplified kinodynamic models, such as pebble motion, as well as perfect execution and communication for AGVs. Prior work has presented SMART, a software capable of evaluating any MAPF algorithms while considering agent kinodynamics, communication delays, and execution uncertainties. However, SMART is designed for MAPF, not LMAPF. Generalizing SMART to an FMS requires many more design choices. First, an FMS parallelizes planning and execution, raising the question of when to plan. Second, given planners with varying optimality and differing agent-model assumptions, one must decide how to plan. Third, when the planner fails to return valid solutions, the system must determine how to recover. In this paper, we first present LSMART, an open-source simulator that incorporates all these considerations to evaluate any MAPF algorithms in an FMS. We then provide experiment results based on state-of-the-art methods for each design choice, offering guidance on how to effectively design centralized lifelong AGV Fleet Management Systems. LSMART is available at https://smart-mapf.github.io/lifelong-smart.

</details>


### [39] [MeshMimic: Geometry-Aware Humanoid Motion Learning through 3D Scene Reconstruction](https://arxiv.org/abs/2602.15733)
*Qiang Zhang,Jiahao Ma,Peiran Liu,Shuai Shi,Zeran Su,Zifan Wang,Jingkai Sun,Wei Cui,Jialin Yu,Gang Han,Wen Zhao,Pihai Sun,Kangning Yin,Jiaxu Wang,Jiahang Cao,Lingfeng Zhang,Hao Cheng,Xiaoshuai Hao,Yiding Ji,Junwei Liang,Jian Tang,Renjing Xu,Yijie Guo*

Main category: cs.RO

TL;DR: MeshMimic是一个创新框架，利用视频学习人形机器人与地形的耦合交互，取得了在多样复杂地形上可靠的表现，且可通过低成本管道实现。


<details>
  <summary>Details</summary>
Motivation: 旨在解决传统人形机器人运动设计的局限性，克服对昂贵运动捕捉数据的依赖，以及运动与场景之间的物理不一致性问题。

Method: 通过结合3D场景重建和体现智能的方法，利用最先进的3D视觉模型来分析人类轨迹和地形几何结构，并应用基于运动学一致性的优化算法和接触不变的重定向方法提取高质量运动数据。

Result: 实验结果表明MeshMimic在多种复杂地形上表现出强大的动态性能。

Conclusion: MeshMimic提供了一种低成本的训练方案，可以在非结构化环境中促进人形机器人复杂物理交互的自主演化。

Abstract: Humanoid motion control has witnessed significant breakthroughs in recent years, with deep reinforcement learning (RL) emerging as a primary catalyst for achieving complex, human-like behaviors. However, the high dimensionality and intricate dynamics of humanoid robots make manual motion design impractical, leading to a heavy reliance on expensive motion capture (MoCap) data. These datasets are not only costly to acquire but also frequently lack the necessary geometric context of the surrounding physical environment. Consequently, existing motion synthesis frameworks often suffer from a decoupling of motion and scene, resulting in physical inconsistencies such as contact slippage or mesh penetration during terrain-aware tasks. In this work, we present MeshMimic, an innovative framework that bridges 3D scene reconstruction and embodied intelligence to enable humanoid robots to learn coupled "motion-terrain" interactions directly from video. By leveraging state-of-the-art 3D vision models, our framework precisely segments and reconstructs both human trajectories and the underlying 3D geometry of terrains and objects. We introduce an optimization algorithm based on kinematic consistency to extract high-quality motion data from noisy visual reconstructions, alongside a contact-invariant retargeting method that transfers human-environment interaction features to the humanoid agent. Experimental results demonstrate that MeshMimic achieves robust, highly dynamic performance across diverse and challenging terrains. Our approach proves that a low-cost pipeline utilizing only consumer-grade monocular sensors can facilitate the training of complex physical interactions, offering a scalable path toward the autonomous evolution of humanoid robots in unstructured environments.

</details>


### [40] [FAST-EQA: Efficient Embodied Question Answering with Global and Local Region Relevancy](https://arxiv.org/abs/2602.15813)
*Haochen Zhang,Nirav Savaliya,Faizan Siddiqui,Enna Sachdeva*

Main category: cs.RO

TL;DR: FAST-EQA是一种优化的Embodied Question Answering框架，通过问题引导的视觉目标识别和场景记忆管理，提升探索效率和回答可靠性。


<details>
  <summary>Details</summary>
Motivation: 在真实场景中，快速推理和有效的搜索策略是Embodied Question Answering的核心挑战。

Method: FAST-EQA框架具备目标识别、兴趣区域评分与Chain-of-Thought推理，维护有限的场景记忆以应对多目标问题。

Result: 在HMEQA和EXPRESS-Bench上，FAST-EQA表现优越，且在OpenEQA和MT-HM3D上也表现良好。

Conclusion: 通过优化注意力引导和探索策略，FAST-EQA在速度和回答质量上均超越了以往方法。

Abstract: Embodied Question Answering (EQA) combines visual scene understanding, goal-directed exploration, spatial and temporal reasoning under partial observability. A central challenge is to confine physical search to question-relevant subspaces while maintaining a compact, actionable memory of observations. Furthermore, for real-world deployment, fast inference time during exploration is crucial. We introduce FAST-EQA, a question-conditioned framework that (i) identifies likely visual targets, (ii) scores global regions of interest to guide navigation, and (iii) employs Chain-of-Thought (CoT) reasoning over visual memory to answer confidently. FAST-EQA maintains a bounded scene memory that stores a fixed-capacity set of region-target hypotheses and updates them online, enabling robust handling of both single and multi-target questions without unbounded growth. To expand coverage efficiently, a global exploration policy treats narrow openings and doors as high-value frontiers, complementing local target seeking with minimal computation. Together, these components focus the agent's attention, improve scene coverage, and improve answer reliability while running substantially faster than prior approaches. On HMEQA and EXPRESS-Bench, FAST-EQA achieves state-of-the-art performance, while performing competitively on OpenEQA and MT-HM3D.

</details>


### [41] [Perceptive Humanoid Parkour: Chaining Dynamic Human Skills via Motion Matching](https://arxiv.org/abs/2602.15827)
*Zhen Wu,Xiaoyu Huang,Lujie Yang,Yuanhang Zhang,Koushil Sreenath,Xi Chen,Pieter Abbeel,Rocky Duan,Angjoo Kanazawa,Carmelo Sferrazza,Guanya Shi,C. Karen Liu*

Main category: cs.RO

TL;DR: 本文介绍了感知人形跑酷（PHP）框架，使人形机器人能够自主执行基于视觉的长距离跑酷，并在复杂障碍物课程中展现人类般的动态动作和决策能力。


<details>
  <summary>Details</summary>
Motivation: 尽管近年来在类人 locomotion 领域取得了进展，但模仿人类高度动态的运动表现仍然是一个未解决的挑战，尤其是在复杂环境中的灵活跑酷。

Method: 该方法利用运动匹配技术，通过最近邻搜索在特征空间中组合重新定位的人类技能成长期运动轨迹，并使用运动跟踪强化学习专家政策进行策略提炼，最终形成一个单一的、多技能的学生策略。

Result: 我们的框架通过对Unitree G1类人机器人进行的广泛实地实验验证，展示了高度动态的跑酷技能，能够攀爬高达1.25米的障碍，并适应实时障碍变化。

Conclusion: 本论文提出的感知人形跑酷框架（PHP）使人形机器人能够在复杂环境中自主管理长时间的跑酷行为，展示出高水平的动态灵活性和适应性。

Abstract: While recent advances in humanoid locomotion have achieved stable walking on varied terrains, capturing the agility and adaptivity of highly dynamic human motions remains an open challenge. In particular, agile parkour in complex environments demands not only low-level robustness, but also human-like motion expressiveness, long-horizon skill composition, and perception-driven decision-making. In this paper, we present Perceptive Humanoid Parkour (PHP), a modular framework that enables humanoid robots to autonomously perform long-horizon, vision-based parkour across challenging obstacle courses. Our approach first leverages motion matching, formulated as nearest-neighbor search in a feature space, to compose retargeted atomic human skills into long-horizon kinematic trajectories. This framework enables the flexible composition and smooth transition of complex skill chains while preserving the elegance and fluidity of dynamic human motions. Next, we train motion-tracking reinforcement learning (RL) expert policies for these composed motions, and distill them into a single depth-based, multi-skill student policy, using a combination of DAgger and RL. Crucially, the combination of perception and skill composition enables autonomous, context-aware decision-making: using only onboard depth sensing and a discrete 2D velocity command, the robot selects and executes whether to step over, climb onto, vault or roll off obstacles of varying geometries and heights. We validate our framework with extensive real-world experiments on a Unitree G1 humanoid robot, demonstrating highly dynamic parkour skills such as climbing tall obstacles up to 1.25m (96% robot height), as well as long-horizon multi-obstacle traversal with closed-loop adaptation to real-time obstacle perturbations.

</details>


### [42] [Dex4D: Task-Agnostic Point Track Policy for Sim-to-Real Dexterous Manipulation](https://arxiv.org/abs/2602.15828)
*Yuxuan Kuang,Sungjae Park,Katerina Fragkiadaki,Shubham Tulsiani*

Main category: cs.RO

TL;DR: Dex4D框架通过在仿真中学习任务无关的灵巧技能，能够零次转移到现实世界中执行多样的灵巧操作，与以往基线相比表现出一致的改进。


<details>
  <summary>Details</summary>
Motivation: 当前在灵巧操作中，实现能够完成各种日常任务的通用策略仍然是一项开放的挑战，因大规模收集真实世界的操作数据既昂贵又难以扩展。

Method: Dex4D利用仿真学习一个条件化的3D点轨迹无关策略，能够将任意物体操纵到任何期望姿态，并在仿真中对数千个物体进行训练。

Result: 在仿真和真实机器人上进行的广泛实验表明，该方法支持多样灵巧操作任务的零次部署，并在新的物体、场景布局和背景上展示了强大的泛化能力。

Conclusion: Dex4D展示了其框架的鲁棒性和可扩展性，为多样操作任务提供了有效的解决方案。

Abstract: Learning generalist policies capable of accomplishing a plethora of everyday tasks remains an open challenge in dexterous manipulation. In particular, collecting large-scale manipulation data via real-world teleoperation is expensive and difficult to scale. While learning in simulation provides a feasible alternative, designing multiple task-specific environments and rewards for training is similarly challenging. We propose Dex4D, a framework that instead leverages simulation for learning task-agnostic dexterous skills that can be flexibly recomposed to perform diverse real-world manipulation tasks. Specifically, Dex4D learns a domain-agnostic 3D point track conditioned policy capable of manipulating any object to any desired pose. We train this 'Anypose-to-Anypose' policy in simulation across thousands of objects with diverse pose configurations, covering a broad space of robot-object interactions that can be composed at test time. At deployment, this policy can be zero-shot transferred to real-world tasks without finetuning, simply by prompting it with desired object-centric point tracks extracted from generated videos. During execution, Dex4D uses online point tracking for closed-loop perception and control. Extensive experiments in simulation and on real robots show that our method enables zero-shot deployment for diverse dexterous manipulation tasks and yields consistent improvements over prior baselines. Furthermore, we demonstrate strong generalization to novel objects, scene layouts, backgrounds, and trajectories, highlighting the robustness and scalability of the proposed framework.

</details>
