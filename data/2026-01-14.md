<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 23]
- [cs.HC](#cs.HC) [Total: 11]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Contact-aware Path Planning for Autonomous Neuroendovascular Navigation](https://arxiv.org/abs/2601.07945)
*Aabha Tamhankar,Ron Alterovitz,Ajit S. Puri,Giovanni Pittiglio*

Main category: cs.RO

TL;DR: 提出了一种高效的神经血管导航路径规划算法，具有高收敛率和低跟踪误差，适用性良好。


<details>
  <summary>Details</summary>
Motivation: 发展一种确定性且高效的接触感知路径规划算法，以改善神经血管导航的精确度和效率。

Method: 利用预手术和术中影像信息，通过采样基础的路径规划算法和运动原语进行树扩展，智能预测和利用与解剖结构的交互。

Result: 该算法在不同的解剖模型中实现了快速路径计算，保持了极小的精度损失。

Conclusion: 该算法在多种血管解剖结构中显示了100%的收敛率，并且在最坏情况下的计算时间不超过22.8秒，跟踪误差小于0.64毫米，在94%的患者的解剖模型上表现有效。

Abstract: We propose a deterministic and time-efficient contact-aware path planner for neurovascular navigation. The algorithm leverages information from pre- and intra-operative images of the vessels to navigate pre-bent passive tools, by intelligently predicting and exploiting interactions with the anatomy. A kinematic model is derived and employed by the sampling-based planner for tree expansion that utilizes simplified motion primitives. This approach enables fast computation of the feasible path, with negligible loss in accuracy, as demonstrated in diverse and representative anatomies of the vessels. In these anatomical demonstrators, the algorithm shows a 100% convergence rate within 22.8s in the worst case, with sub-millimeter tracking errors (less than 0.64 mm), and is found effective on anatomical phantoms representative of around 94% of patients.

</details>


### [2] [Fiducial Exoskeletons: Image-Centric Robot State Estimation](https://arxiv.org/abs/2601.08034)
*Cameron Smith,Basile Van Hoorick,Vitor Guizilini,Yue Wang*

Main category: cs.RO

TL;DR: 本文提出Fiducial Exoskeletons，通过单图像推断重构3D机器人状态估计，简化传统流程，增强状态精度与控制性能。


<details>
  <summary>Details</summary>
Motivation: 传统的机器人状态估计依赖高精度的执行器和手动校准，流程繁琐，限制了低成本硬件的应用。

Method: 将机器人状态估计视为从单幅RGB图像估计每个链接的6D姿态，通过轻量级全局优化来恢复关节状态，并引入Fiducial Exoskeleton作为简化方案。

Result: 在低成本机器人臂上展示了该方法，显著简化了设置，同时提高了校准和后续3D控制性能。发布了代码和可打印的硬件设计。

Conclusion: Fiducial Exoskeletons的设计极大简化了机器人状态估计流程，提升了校准精度与控制性能，适用于成本较低的硬件。

Abstract: We introduce Fiducial Exoskeletons, an image-based reformulation of 3D robot state estimation that replaces cumbersome procedures and motor-centric pipelines with single-image inference. Traditional approaches - especially robot-camera extrinsic estimation - often rely on high-precision actuators and require time-consuming routines such as hand-eye calibration. In contrast, modern learning-based robot control is increasingly trained and deployed from RGB observations on lower-cost hardware.
  Our key insight is twofold. First, we cast robot state estimation as 6D pose estimation of each link from a single RGB image: the robot-camera base transform is obtained directly as the estimated base-link pose, and the joint state is recovered via a lightweight global optimization that enforces kinematic consistency with the observed link poses (optionally warm-started with encoder readings). Second, we make per-link 6D pose estimation robust and simple - even without learning - by introducing the fiducial exoskeleton: a lightweight 3D-printed mount with a fiducial marker on each link and known marker-link geometry.
  This design yields robust camera-robot extrinsics, per-link SE(3) poses, and joint-angle state from a single image, enabling robust state estimation even on unplugged robots. Demonstrated on a low-cost robot arm, fiducial exoskeletons substantially simplify setup while improving calibration, state accuracy, and downstream 3D control performance. We release code and printable hardware designs to enable further algorithm-hardware co-design.

</details>


### [3] [Efficient Incremental SLAM via Information-Guided and Selective Optimization](https://arxiv.org/abs/2601.08110)
*Reza Arablouei*

Main category: cs.RO

TL;DR: 提出了一种高效的增量SLAM后端，通过信息引导门控和选择性部分优化方法，在显著降低计算成本的同时，保持批处理优化的准确性。


<details>
  <summary>Details</summary>
Motivation: 在增量SLAM中实现准确性与效率的平衡，减少不必要的计算。

Method: 信息引导门控（IGG）与选择性部分优化（SPO）的结合

Result: 与传统增量方法相比，提出的方法在计算上显著节省，同时保持了批处理求解器的估计准确性。

Conclusion: 该方法在动态信息丰富的环境中，提供了准确性与效率之间的合理平衡，是一种稳健且可扩展的实时解决方案。

Abstract: We present an efficient incremental SLAM back-end that achieves the accuracy of full batch optimization while substantially reducing computational cost. The proposed approach combines two complementary ideas: information-guided gating (IGG) and selective partial optimization (SPO). IGG employs an information-theoretic criterion based on the log-determinant of the information matrix to quantify the contribution of new measurements, triggering global optimization only when a significant information gain is observed. This avoids unnecessary relinearization and factorization when incoming data provide little additional information. SPO executes multi-iteration Gauss-Newton (GN) updates but restricts each iteration to the subset of variables most affected by the new measurements, dynamically refining this active set until convergence. Together, these mechanisms retain all measurements to preserve global consistency while focusing computation on parts of the graph where it yields the greatest benefit. We provide theoretical analysis showing that the proposed approach maintains the convergence guarantees of full GN. Extensive experiments on benchmark SLAM datasets show that our approach consistently matches the estimation accuracy of batch solvers, while achieving significant computational savings compared to conventional incremental approaches. The results indicate that the proposed approach offers a principled balance between accuracy and efficiency, making it a robust and scalable solution for real-time operation in dynamic data-rich environments.

</details>


### [4] [A Pin-Array Structure for Gripping and Shape Recognition of Convex and Concave Terrain Profiles](https://arxiv.org/abs/2601.08143)
*Takuya Kato,Kentaro Uno,Kazuya Yoshida*

Main category: cs.RO

TL;DR: 本论文提出了一种新型抓取器，用于在极端环境中的移动机器人，具备抓取和识别不规则地形的能力，能够精准测量地形形状，展示了其良好的性能及应用前景。


<details>
  <summary>Details</summary>
Motivation: 在极端环境中，移动机器人需要能够抓取和识别地形形状的抓取器，以提高在崎岖地形（如悬崖和洞壁）上的表现。

Method: 开发了一种具有针阵结构的抓取器，能够适应不规则地形，精确测量地形的形状，并同时抓取凸凹地形。

Result: 通过原型展示了抓取器的机制，并评估了其抓取和地形识别性能，证明了针阵设计在3D地形映射和不规则地形自适应抓取中的良好应用。

Conclusion: 该抓取器在困难环境中的应用潜力强，可以有效解决移动机器人在未知自然环境中因抓取失误或抓取点丢失而失控的问题。

Abstract: This paper presents a gripper capable of grasping and recognizing terrain shapes for mobile robots in extreme environments. Multi-limbed climbing robots with grippers are effective on rough terrains, such as cliffs and cave walls. However, such robots may fall over by misgrasping the surface or getting stuck owing to the loss of graspable points in unknown natural environments. To overcome these issues, we need a gripper capable of adaptive grasping to irregular terrains, not only for grasping but also for measuring the shape of the terrain surface accurately. We developed a gripper that can grasp both convex and concave terrains and simultaneously measure the terrain shape by introducing a pin-array structure. We demonstrated the mechanism of the gripper and evaluated its grasping and terrain recognition performance using a prototype. Moreover, the proposed pin-array design works well for 3D terrain mapping as well as adaptive grasping for irregular terrains.

</details>


### [5] [Robust Subpixel Localization of Diagonal Markers in Large-Scale Navigation via Multi-Layer Screening and Adaptive Matching](https://arxiv.org/abs/2601.08161)
*Jing Tao,Banglei Guan,Yang Shang,Shunkun Liang,Qifeng Yu*

Main category: cs.RO

TL;DR: 本研究提出了一种高精度定位方法，通过三层框架和自适应模板匹配克服传统滑动窗口技术的计算效率问题，可以有效应对复杂背景干扰。


<details>
  <summary>Details</summary>
Motivation: 解决大规模飞行导航中的定位失败和传统计算方法的低效率问题。

Method: 提出一种三层框架方法，通过多层角点筛选和自适应模板匹配实现高精度定位。

Result: 通过光照均衡和结构信息提取实现降维，并采用粗到细的候选选择策略以降低滑动窗口的计算成本。

Conclusion: 该方法在复杂大规模环境中有效提取和定位对角标记，适用于导航任务中的视域测量。

Abstract: This paper proposes a robust, high-precision positioning methodology to address localization failures arising from complex background interference in large-scale flight navigation and the computational inefficiency inherent in conventional sliding window matching techniques. The proposed methodology employs a three-tiered framework incorporating multi-layer corner screening and adaptive template matching. Firstly, dimensionality is reduced through illumination equalization and structural information extraction. A coarse-to-fine candidate selection strategy minimizes sliding window computational costs, enabling rapid estimation of the marker's position. Finally, adaptive templates are generated for candidate points, achieving subpixel precision through improved template matching with correlation coefficient extremum fitting. Experimental results demonstrate the method's effectiveness in extracting and localizing diagonal markers in complex, large-scale environments, making it ideal for field-of-view measurement in navigation tasks.

</details>


### [6] [A brain-inspired information fusion method for enhancing robot GPS outages navigation](https://arxiv.org/abs/2601.08244)
*Yaohua Liu,Hengjun Zhang,Binkai Ou*

Main category: cs.RO

TL;DR: 本论文提出了一种基于脉冲神经网络的GPS/INS融合网络，能够在GPS失效的情况下提升导航精度和可靠性。


<details>
  <summary>Details</summary>
Motivation: 低成本惯性导航系统在GPS失效时导航精度迅速降低，迫切需要改进定位连续性。

Method: 提出了一种基于脉冲神经网络的脑启发式GPS/INS融合网络，通过脉冲Transformer和脉冲编码器同时提取IMU信号的空间特征与时间动态。

Result: 在实际场地测试和公共数据集的实验中，BGFN表现出更高的导航准确性和可靠性。

Conclusion: BGFN相较于传统深度学习方法在导航性能上具有更高的准确性和更强的可靠性，特别是在GPS长时间失效的情况下。

Abstract: Low-cost inertial navigation systems (INS) are prone to sensor biases and measurement noise, which lead to rapid degradation of navigation accuracy during global positioning system (GPS) outages. To address this challenge and improve positioning continuity in GPS-denied environments, this paper proposes a brain-inspired GPS/INS fusion network (BGFN) based on spiking neural networks (SNNs). The BGFN architecture integrates a spiking Transformer with a spiking encoder to simultaneously extract spatial features from inertial measurement unit (IMU) signals and capture their temporal dynamics. By modeling the relationship between vehicle attitude, specific force, angular rate, and GPS-derived position increments, the network leverages both current and historical IMU data to estimate vehicle motion. The effectiveness of the proposed method is evaluated through real-world field tests and experiments on public datasets. Compared to conventional deep learning approaches, the results demonstrate that BGFN achieves higher accuracy and enhanced reliability in navigation performance, particularly under prolonged GPS outages.

</details>


### [7] [FSAG: Enhancing Human-to-Dexterous-Hand Finger-Specific Affordance Grounding via Diffusion Models](https://arxiv.org/abs/2601.08246)
*Yifan Han,Pengfei Yi,Junyan Li,Hanqing Wang,Gaojing Zhang,Qi Peng Liu,Wenzhao Lian*

Main category: cs.RO

TL;DR: 本文提出了一种利用预训练生成扩散模型的语义优先提取管道，实现了高效的多指抓取合成，能够在不需要特定硬件数据集的情况下进行跨手泛化。


<details>
  <summary>Details</summary>
Motivation: 当前的多指抓取合成于高维和运动学多样性方面存在挑战，传统方法依赖于昂贵的抓取数据集，限制了新手形设计的可扩展性。

Method: 通过使用预训练生成扩散模型中的语义优先，提取与时序对齐的抓取能力，然后将其与深度图像中的3D场景几何体结合，形成语义基础的接触目标，最终通过运动学重定标模块实现各种多指手的抓取映射。

Result: 系统可以生成稳定且功能适当的多接触抓取，并在常见物体和工具之间保持高成功率，同时在未见物体实例和不同姿态变化上表现出强大的泛化能力。

Conclusion: 提出了一种数据高效的框架，能够在不依赖于特定硬件抓取数据集的情况下进行灵活的抓取合成，并且展示出了在不同手形态和新物体实例上的良好泛化能力。

Abstract: Dexterous grasp synthesis remains a central challenge: the high dimensionality and kinematic diversity of multi-fingered hands prevent direct transfer of algorithms developed for parallel-jaw grippers. Existing approaches typically depend on large, hardware-specific grasp datasets collected in simulation or through costly real-world trials, hindering scalability as new dexterous hand designs emerge. To this end, we propose a data-efficient framework, which is designed to bypass robot grasp data collection by exploiting the rich, object-centric semantic priors latent in pretrained generative diffusion models. Temporally aligned and fine-grained grasp affordances are extracted from raw human video demonstrations and fused with 3D scene geometry from depth images to infer semantically grounded contact targets. A kinematics-aware retargeting module then maps these affordance representations to diverse dexterous hands without per-hand retraining. The resulting system produces stable, functionally appropriate multi-contact grasps that remain reliably successful across common objects and tools, while exhibiting strong generalization across previously unseen object instances within a category, pose variations, and multiple hand embodiments. This work (i) introduces a semantic affordance extraction pipeline leveraging vision-language generative priors for dexterous grasping, (ii) demonstrates cross-hand generalization without constructing hardware-specific grasp datasets, and (iii) establishes that a single depth modality suffices for high-performance grasp synthesis when coupled with foundation-model semantics. Our results highlight a path toward scalable, hardware-agnostic dexterous manipulation driven by human demonstrations and pretrained generative models.

</details>


### [8] [Spiking Neural-Invariant Kalman Fusion for Accurate Localization Using Low-Cost IMUs](https://arxiv.org/abs/2601.08248)
*Yaohua Liu,Qiao Xu,Yemin Wang,Hui Yi Leong,Binkai Ou*

Main category: cs.RO

TL;DR: 提出了一种新颖的基于大脑的状态估计框架，结合了脉冲神经网络和不变扩展卡尔曼滤波器，以提高廉价惯性测量单元在移动机器人定位中的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 低成本惯性测量单元在移动机器人定位中普遍使用，但因其复杂的非线性和时变噪声特性，直接用于快速定位时会严重降低定位精度。

Method: 通过将脉冲神经网络（SNN）与不变扩展卡尔曼滤波器（InEKF）相结合，SNN从受随机噪声影响的IMU数据中提取运动相关特征，并通过代理梯度下降算法进行训练，以动态调整卡尔曼滤波的协方差噪声参数。

Result: 在KITTI数据集及使用低成本IMU的移动机器人实际收集的数据上进行的广泛实验表明，该方法在定位精度上优于现有技术，并表现出对传感器噪声的强鲁棒性。

Conclusion: 该方法显示出在实际移动机器人应用中提升定位精度和鲁棒性的潜力。

Abstract: Low-cost inertial measurement units (IMUs) are widely utilized in mobile robot localization due to their affordability and ease of integration. However, their complex, nonlinear, and time-varying noise characteristics often lead to significant degradation in localization accuracy when applied directly for dead reckoning. To overcome this limitation, we propose a novel brain-inspired state estimation framework that combines a spiking neural network (SNN) with an invariant extended Kalman filter (InEKF). The SNN is designed to extract motion-related features from long sequences of IMU data affected by substantial random noise and is trained via a surrogate gradient descent algorithm to enable dynamic adaptation of the covariance noise parameter within the InEKF. By fusing the SNN output with raw IMU measurements, the proposed method enhances the robustness and accuracy of pose estimation. Extensive experiments conducted on the KITTI dataset and real-world data collected using a mobile robot equipped with a low-cost IMU demonstrate that the proposed approach outperforms state-of-the-art methods in localization accuracy and exhibits strong robustness to sensor noise, highlighting its potential for real-world mobile robot applications.

</details>


### [9] [ActiveVLA: Injecting Active Perception into Vision-Language-Action Models for Precise 3D Robotic Manipulation](https://arxiv.org/abs/2601.08325)
*Zhenyang Liu,Yongchong Gu,Yikai Wang,Xiangyang Xue,Yanwei Fu*

Main category: cs.RO

TL;DR: 提出了一种新的视-语言-行动框架ActiveVLA，通过主动感知能力提升机器人在复杂任务中的高精度操作能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法未能充分重视主动感知，对静态摄像头的依赖限制了长时间任务和精细操作的表现。

Method: ActiveVLA框架分为两个阶段：1) 关键区域定位，2) 主动感知优化，使用动态视角选择和3D放大技术。

Result: ActiveVLA在三个仿真基准上表现优异，成功实现精确的3D操作。

Conclusion: ActiveVLA能无缝转移到真实场景，帮助机器人在复杂环境中学习高精度任务。

Abstract: Recent advances in robot manipulation have leveraged pre-trained vision-language models (VLMs) and explored integrating 3D spatial signals into these models for effective action prediction, giving rise to the promising vision-language-action (VLA) paradigm. However, most existing approaches overlook the importance of active perception: they typically rely on static, wrist-mounted cameras that provide an end-effector-centric viewpoint. As a result, these models are unable to adaptively select optimal viewpoints or resolutions during task execution, which significantly limits their performance in long-horizon tasks and fine-grained manipulation scenarios. To address these limitations, we propose ActiveVLA, a novel vision-language-action framework that empowers robots with active perception capabilities for high-precision, fine-grained manipulation. ActiveVLA adopts a coarse-to-fine paradigm, dividing the process into two stages: (1) Critical region localization. ActiveVLA projects 3D inputs onto multi-view 2D projections, identifies critical 3D regions, and supports dynamic spatial awareness. (2) Active perception optimization. Drawing on the localized critical regions, ActiveVLA uses an active view selection strategy to choose optimal viewpoints. These viewpoints aim to maximize amodal relevance and diversity while minimizing occlusions. Additionally, ActiveVLA applies a 3D zoom-in to improve resolution in key areas. Together, these steps enable finer-grained active perception for precise manipulation. Extensive experiments demonstrate that ActiveVLA achieves precise 3D manipulation and outperforms state-of-the-art baselines on three simulation benchmarks. Moreover, ActiveVLA transfers seamlessly to real-world scenarios, enabling robots to learn high-precision tasks in complex environments.

</details>


### [10] [Safe Heterogeneous Multi-Agent RL with Communication Regularization for Coordinated Target Acquisition](https://arxiv.org/abs/2601.08327)
*Gabriele Calzolari,Vidya Sumathy,Christoforos Kanellakis,George Nikolakopoulos*

Main category: cs.RO

TL;DR: 本文提出了一种去中心化的多代理强化学习框架，以支持在复杂环境中团队协作，实现目标发现和获取。


<details>
  <summary>Details</summary>
Motivation: 在部分可观测、通信受限和动态交互的环境中，代理需要有效地共同发现和获取目标。

Method: 采用去中心化的多代理强化学习框架，使用多代理近端策略优化算法和图注意力网络编码器。

Result: 通过全面的消融研究证明了提出的奖励函数的有效性，仿真结果显示任务执行安全稳定。

Conclusion: 该框架有效支持结构异质团队的协同目标发现和获取。

Abstract: This paper introduces a decentralized multi-agent reinforcement learning framework enabling structurally heterogeneous teams of agents to jointly discover and acquire randomly located targets in environments characterized by partial observability, communication constraints, and dynamic interactions. Each agent's policy is trained with the Multi-Agent Proximal Policy Optimization algorithm and employs a Graph Attention Network encoder that integrates simulated range-sensing data with communication embeddings exchanged among neighboring agents, enabling context-aware decision-making from both local sensing and relational information. In particular, this work introduces a unified framework that integrates graph-based communication and trajectory-aware safety through safety filters. The architecture is supported by a structured reward formulation designed to encourage effective target discovery and acquisition, collision avoidance, and de-correlation between the agents' communication vectors by promoting informational orthogonality. The effectiveness of the proposed reward function is demonstrated through a comprehensive ablation study. Moreover, simulation results demonstrate safe and stable task execution, confirming the framework's effectiveness.

</details>


### [11] [Large Language Models to Enhance Multi-task Drone Operations in Simulated Environments](https://arxiv.org/abs/2601.08405)
*Yizhan Feng,Hichem Snoussi,Jing Teng,Abel Cherouat,Tian Wang*

Main category: cs.RO

TL;DR: 本研究提出了一种新方法，通过将微调的CodeT5与AirSim模拟器结合，实现自然语言到可执行代码的转换，提高无人机操作效率。


<details>
  <summary>Details</summary>
Motivation: 利用大语言模型的快速发展，改善人机无人机交互的机会，降低操作门槛，并增强无人机技术在复杂场景中的应用。

Method: 将微调的CodeT5模型与基于Unreal Engine的AirSim无人机模拟器集成，使用自然语言命令有效执行多任务操作。

Result: 在模拟环境中，展示了该方法在任务执行效率和命令理解能力方面的优越表现。

Conclusion: 提出的方法降低了操作门槛，使用户能够通过提示或命令描述与模拟无人机交互，并计划以模块化方式扩展模型功能。

Abstract: Benefiting from the rapid advancements in large language models (LLMs), human-drone interaction has reached unprecedented opportunities. In this paper, we propose a method that integrates a fine-tuned CodeT5 model with the Unreal Engine-based AirSim drone simulator to efficiently execute multi-task operations using natural language commands. This approach enables users to interact with simulated drones through prompts or command descriptions, allowing them to easily access and control the drone's status, significantly lowering the operational threshold. In the AirSim simulator, we can flexibly construct visually realistic dynamic environments to simulate drone applications in complex scenarios. By combining a large dataset of (natural language, program code) command-execution pairs generated by ChatGPT with developer-written drone code as training data, we fine-tune the CodeT5 to achieve automated translation from natural language to executable code for drone tasks. Experimental results demonstrate that the proposed method exhibits superior task execution efficiency and command understanding capabilities in simulated environments. In the future, we plan to extend the model functionality in a modular manner, enhancing its adaptability to complex scenarios and driving the application of drone technologies in real-world environments.

</details>


### [12] [Teaching Robots Like Dogs: Learning Agile Navigation from Luring, Gesture, and Speech](https://arxiv.org/abs/2601.08422)
*Taerim Yoon,Dongho Kang,Jin Cheng,Fatemeh Zargarbashi,Yijiang Huang,Minsung Ahn,Stelian Coros,Sungjoon Choi*

Main category: cs.RO

TL;DR: 本文提出了一种人机协作框架，使四足机器人可以通过物理人类引导学习解读人际社会信号并执行适当行为，在导航行为学习中实现数据高效性，同时兼容多模式自然人类输入。


<details>
  <summary>Details</summary>
Motivation: 灵活的四足机器人需要学习如何解读人类的社会信号，以便能够在复杂环境中与人类有效互动。

Method: 提出了一个人机协作框架，通过物理引导学习，并使用基于物理的仿真重构交互场景，结合进阶的目标提示策略，适应性地提供命令和导航目标。

Result: 在六个真实世界的灵活导航场景中进行评估，方法在几乎所有试验中成功，任务成功率为97.15%，所需演示数据少于1小时。

Conclusion: 所提出的框架有效提高了机器人对人类输入的响应能力和导航准确性，展示了高数据效率的潜力。

Abstract: In this work, we aim to enable legged robots to learn how to interpret human social cues and produce appropriate behaviors through physical human guidance. However, learning through physical engagement can place a heavy burden on users when the process requires large amounts of human-provided data. To address this, we propose a human-in-the-loop framework that enables robots to acquire navigational behaviors in a data-efficient manner and to be controlled via multimodal natural human inputs, specifically gestural and verbal commands. We reconstruct interaction scenes using a physics-based simulation and aggregate data to mitigate distributional shifts arising from limited demonstration data. Our progressive goal cueing strategy adaptively feeds appropriate commands and navigation goals during training, leading to more accurate navigation and stronger alignment between human input and robot behavior. We evaluate our framework across six real-world agile navigation scenarios, including jumping over or avoiding obstacles. Our experimental results show that our proposed method succeeds in almost all trials across these scenarios, achieving a 97.15% task success rate with less than 1 hour of demonstration data in total.

</details>


### [13] [Large Multimodal Models for Embodied Intelligent Driving: The Next Frontier in Self-Driving?](https://arxiv.org/abs/2601.08434)
*Long Zhang,Yuchen Xia*

Main category: cs.RO

TL;DR: 本文提出了一种语义与策略双驱动混合决策框架，以解决自主驾驶中的持续学习和联合决策挑战，结合LMMs和DRL，验证了其在车道变换规划任务中的优越性能。


<details>
  <summary>Details</summary>
Motivation: 面对当前模块化设计在开放世界场景中面临的局限性，亟需一种新方法来支持持续环境理解和逻辑推理，以推动自主驾驶向体现智能的发展。

Method: 该框架融合了大型多模态模型（LMMs）和深度强化学习（DRL）来实现语义理解和实时策略优化。

Result: 实验结果验证了本框架在车道变换规划任务中的性能优越性，展示了联合决策的能力。

Conclusion: 本文提出的语义与策略双驱动混合决策框架有效提升了自主驾驶的能力，尤其在开放世界场景中。

Abstract: The advent of Large Multimodal Models (LMMs) offers a promising technology to tackle the limitations of modular design in autonomous driving, which often falters in open-world scenarios requiring sustained environmental understanding and logical reasoning. Besides, embodied artificial intelligence facilitates policy optimization through closed-loop interactions to achieve the continuous learning capability, thereby advancing autonomous driving toward embodied intelligent (El) driving. However, such capability will be constrained by relying solely on LMMs to enhance EI driving without joint decision-making. This article introduces a novel semantics and policy dual-driven hybrid decision framework to tackle this challenge, ensuring continuous learning and joint decision. The framework merges LMMs for semantic understanding and cognitive representation, and deep reinforcement learning (DRL) for real-time policy optimization. We starts by introducing the foundational principles of EI driving and LMMs. Moreover, we examine the emerging opportunities this framework enables, encompassing potential benefits and representative use cases. A case study is conducted experimentally to validate the performance superiority of our framework in completing lane-change planning task. Finally, several future research directions to empower EI driving are identified to guide subsequent work.

</details>


### [14] [Real2Sim based on Active Perception with automatically VLM-generated Behavior Trees](https://arxiv.org/abs/2601.08454)
*Alessandro Adami,Sebastian Zudaire,Ruggero Carli,Pietro Falco*

Main category: cs.RO

TL;DR: 本文提出了一种自主生成和执行行为树的Real2Sim框架，通过多模态推理进行物理参数的高效估计，从而改进传统的现实到仿真流程。


<details>
  <summary>Details</summary>
Motivation: 需要可靠估计物理参数以构建真实环境的准确仿真模型，而传统方法受限于手动测量和预定义流程。

Method: 采用视觉-语言模型进行多模态推理，根据用户请求和环境观察生成行为树，指导机器人执行相关动作进行参数估计。

Result: 在多种场景中成功估计了对象质量、表面高度以及摩擦相关量，包括遮挡物体和不完整模型的情况。

Conclusion: 提出的自主Real2Sim框架实现了解释性、以意图驱动的流程，结合高层推理与物理驱动的机器人交互。

Abstract: Constructing an accurate simulation model of real-world environments requires reliable estimation of physical parameters such as mass, geometry, friction, and contact surfaces. Traditional real-to-simulation (Real2Sim) pipelines rely on manual measurements or fixed, pre-programmed exploration routines, which limit their adaptability to varying tasks and user intents. This paper presents a Real2Sim framework that autonomously generates and executes Behavior Trees for task-specific physical interactions to acquire only the parameters required for a given simulation objective, without relying on pre-defined task templates or expert-designed exploration routines. Given a high-level user request, an incomplete simulation description, and an RGB observation of the scene, a vision-language model performs multi-modal reasoning to identify relevant objects, infer required physical parameters, and generate a structured Behavior Tree composed of elementary robotic actions. The resulting behavior is executed on a torque-controlled Franka Emika Panda, enabling compliant, contact-rich interactions for parameter estimation. The acquired measurements are used to automatically construct a physics-aware simulation. Experimental results on the real manipulator demonstrate estimation of object mass, surface height, and friction-related quantities across multiple scenarios, including occluded objects and incomplete prior models. The proposed approach enables interpretable, intent-driven, and autonomously Real2Sim pipelines, bridging high-level reasoning with physically-grounded robotic interaction.

</details>


### [15] [AME-2: Agile and Generalized Legged Locomotion via Attention-Based Neural Map Encoding](https://arxiv.org/abs/2601.08485)
*Chong Zhang,Victor Klemm,Fan Yang,Marco Hutter*

Main category: cs.RO

TL;DR: 本研究提出了AME-2，一个统一的强化学习框架，结合注意力机制和学习型映射管道，旨在实现快速且高效的跨地形的行走控制。


<details>
  <summary>Details</summary>
Motivation: 实现跨地形的敏捷和广义行走需要感知和控制的紧密集成，尤其是在遮挡和稀疏支撑点的情况下，现有方法通常在泛化和可解释性方面存在局限性。

Method: 介绍了一种基于注意力的映射编码器的统一强化学习框架，以及一个快速、不确定性感知的学习型映射管道。

Result: 在四足和双足机器人上验证AME-2，并在仿真和现实实验中展现出强大的敏捷性和泛化能力。

Conclusion: AME-2展示了在仿真和现实世界中对未知地形具有强大的敏捷性和泛化能力的控制器。

Abstract: Achieving agile and generalized legged locomotion across terrains requires tight integration of perception and control, especially under occlusions and sparse footholds. Existing methods have demonstrated agility on parkour courses but often rely on end-to-end sensorimotor models with limited generalization and interpretability. By contrast, methods targeting generalized locomotion typically exhibit limited agility and struggle with visual occlusions. We introduce AME-2, a unified reinforcement learning (RL) framework for agile and generalized locomotion that incorporates a novel attention-based map encoder in the control policy. This encoder extracts local and global mapping features and uses attention mechanisms to focus on salient regions, producing an interpretable and generalized embedding for RL-based control. We further propose a learning-based mapping pipeline that provides fast, uncertainty-aware terrain representations robust to noise and occlusions, serving as policy inputs. It uses neural networks to convert depth observations into local elevations with uncertainties, and fuses them with odometry. The pipeline also integrates with parallel simulation so that we can train controllers with online mapping, aiding sim-to-real transfer. We validate AME-2 with the proposed mapping pipeline on a quadruped and a biped robot, and the resulting controllers demonstrate strong agility and generalization to unseen terrains in simulation and in real-world experiments.

</details>


### [16] [Older Adults' Preferences for Feedback Cadence from an Exercise Coach Robot](https://arxiv.org/abs/2601.08819)
*Roshni Kaushik,Reid Simmons*

Main category: cs.RO

TL;DR: 研究探讨了老年人对机器人教练反馈节奏的反应，结果揭示节奏改变对反馈感知的相互影响，为设计个性化反馈提供了参考。


<details>
  <summary>Details</summary>
Motivation: 了解老年人如何响应机器人教练的不同反馈节奏，以实现个性化交互。

Method: 通过在线研究，让老年人评估机器人在不同节奏下的口头与非口头反馈视频。

Result: 研究表明，改变一种反馈形式的节奏会影响对另一种反馈形式的感知。

Conclusion: 老年人对机器人教练反馈的反应受反馈节奏的影响，设计更合适的反馈频率可以提升互动效果。

Abstract: People can respond to feedback and guidance in different ways, and it is important for robots to personalize their interactions and utilize verbal and nonverbal communication cues. We aim to understand how older adults respond to different cadences of verbal and nonverbal feedback of a robot exercise coach. We conducted an online study of older adults, where participants evaluated videos of the robot giving feedback at different cadences for each modality. The results indicate that changing the cadence of one modality affects the perception of both it and the other modality. We can use the results from this study to better design the frequency of the robot coach's feedback during an exercise session with this population.

</details>


### [17] [AUV Trajectory Learning for Underwater Acoustic Energy Transfer and Age Minimization](https://arxiv.org/abs/2601.08491)
*Mohamed Afouene Melki,Mohammad Shehab,Mohamed-Slim Alouini*

Main category: cs.RO

TL;DR: 本文提出了一种可持续的水下物联网解决方案，通过自主水下航行器实现信息上传和声能传输，采用深度强化学习算法优化信息老化和能量收集。


<details>
  <summary>Details</summary>
Motivation: 应对传统依赖电池的水下物联网设备在寿命、废弃物处理及环境安全方面的限制，寻求可持续的能源和通信方案。

Method: 开发了两种深度强化学习(DRL)算法，分别提供高复杂度高性能的频分双工(FDD)方案和低复杂度中等性能的时分双工(TDD)方案。

Result: 实验结果表明，提出的FDD和TDD解决方案在信息老化时间和能量收集效率方面优于基线方法。

Conclusion: 提出的FDD和TDD方案显著降低了平均信息老化时间，提高了能量收集和数据收集的公平性。

Abstract: Internet of underwater things (IoUT) is increasingly gathering attention with the aim of monitoring sea life and deep ocean environment, underwater surveillance as well as maintenance of underwater installments. However, conventional IoUT devices, reliant on battery power, face limitations in lifespan and pose environmental hazards upon disposal. This paper introduces a sustainable approach for simultaneous information uplink from the IoUT devices and acoustic energy transfer (AET) to the devices via an autonomous underwater vehicle (AUV), potentially enabling them to operate indefinitely. To tackle the time-sensitivity, we adopt age of information (AoI), and Jain's fairness index. We develop two deep-reinforcement learning (DRL) algorithms, offering a high-complexity, high-performance frequency division duplex (FDD) solution and a low-complexity, medium-performance time division duplex (TDD) approach. The results elucidate that the proposed FDD and TDD solutions significantly reduce the average AoI and boost the harvested energy as well as data collection fairness compared to baseline approaches.

</details>


### [18] [Simplifying ROS2 controllers with a modular architecture for robot-agnostic reference generation](https://arxiv.org/abs/2601.08514)
*Davide Risi,Vincenzo Petrone,Antonio Langella,Lorenzo Pagliara,Enrico Ferrentino,Pasquale Chiacchio*

Main category: cs.RO

TL;DR: 本文介绍了一种新颖的ROS2模块化架构，通过分离参考生成和控制法则，提升了参考处理的重用性和可靠性，并在多个机器人平台上进行了验证。


<details>
  <summary>Details</summary>
Motivation: 实现机器人控制的高复用性和高效性，减少重复代码，提高对复杂控制系统的支持。

Method: 设计了一种新的参考生成组件，能够处理单点和轨迹参考，并通过ros2_control机制将信息传递给下游控制器。

Result: 实验结果表明，引用在所有测试场景中都能可靠追踪，减少了重复的引用处理代码，控制器实现也更专注于控制法则。

Conclusion: 该研究成功地提出了一种模块化的架构，能够有效地解耦参考生成和控制法则，从而提高了机器人控制器的复用性和可靠性。

Abstract: This paper introduces a novel modular architecture for ROS2 that decouples the logic required to acquire, validate, and interpolate references from the control laws that track them. The design includes a dedicated component, named Reference Generator, that receives references, in the form of either single points or trajectories, from external nodes (e.g., planners), and writes single-point references at the controller's sampling period via the existing ros2_control chaining mechanism to downstream controllers. This separation removes duplicated reference-handling code from controllers and improves reusability across robot platforms. We implement two reference generators: one for handling joint-space references and one for Cartesian references, along with a set of new controllers (PD with gravity compensation, Cartesian pose, and admittance controllers) and validate the approach on simulated and real Universal Robots and Franka Emika manipulators. Results show that (i) references are tracked reliably in all tested scenarios, (ii) reference generators reduce duplicated reference-handling code across chained controllers to favor the construction and reuse of complex controller pipelines, and (iii) controller implementations remain focused only on control laws.

</details>


### [19] [Keyframe-based Dense Mapping with the Graph of View-Dependent Local Maps](https://arxiv.org/abs/2601.08520)
*Krzysztof Zielinski,Dominik Belter*

Main category: cs.RO

TL;DR: 提出了一种基于关键帧的新型映射系统，利用RGB-D传感器数据更新局部NDT地图，并在闭环检测后纠正全局地图。


<details>
  <summary>Details</summary>
Motivation: 针对现有地图构建方法的局限性，旨在提高基于RGB-D相机的环境映射精度和效率。

Method: 利用RGB-D传感器数据更新本地NDT地图，并将地方地图存储在姿态图中，构建全局地图。

Result: 通过与Octomap和NDT-OM进行比较，验证了该方法的有效性，并展示了应用实例。

Conclusion: 所提出的方法能够在精度和效率上优于传统方法，为环境映射提供了新选择。

Abstract: In this article, we propose a new keyframe-based mapping system. The proposed method updates local Normal Distribution Transform maps (NDT) using data from an RGB-D sensor. The cells of the NDT are stored in 2D view-dependent structures to better utilize the properties and uncertainty model of RGB-D cameras. This method naturally represents an object closer to the camera origin with higher precision. The local maps are stored in the pose graph which allows correcting global map after loop closure detection. We also propose a procedure that allows merging and filtering local maps to obtain a global map of the environment. Finally, we compare our method with Octomap and NDT-OM and provide example applications of the proposed mapping method.

</details>


### [20] [QP-Based Control of an Underactuated Aerial Manipulator under Constraints](https://arxiv.org/abs/2601.08523)
*Nesserine Laribi,Mohammed Rida Mokhtari,Abdelaziz Benallegue,Abdelhafid El-Hadri,Mehdi Benallegue*

Main category: cs.RO

TL;DR: 提出了一种约束感知的控制框架，增强欠驱动无人机的轨迹跟踪性能，同时确保安全性和可行性。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够在考虑安全性和可行性的约束下实现精确轨迹跟踪的无人机操控系统

Method: 将控制问题表述为一个二次规划，计算动态一致的广义加速度，并考虑欠驱动、执行器界限和系统约束

Result: 通过高保真度的物理基础模拟验证了所提出方法在处理参数扰动、粘性关节摩擦及现实感知和状态估计效应下的有效性

Conclusion: 提出的方法能够在现实操作条件下实现精确跟踪、平滑控制输入和可靠的约束满足

Abstract: This paper presents a constraint-aware control framework for underactuated aerial manipulators, enabling accurate end-effector trajectory tracking while explicitly accounting for safety and feasibility constraints. The control problem is formulated as a quadratic program that computes dynamically consistent generalized accelerations subject to underactuation, actuator bounds, and system constraints. To enhance robustness against disturbances, modeling uncertainties, and steady-state errors, a passivity-based integral action is incorporated at the torque level without compromising feasibility. The effectiveness of the proposed approach is demonstrated through high-fidelity physics-based simulations, which include parameter perturbations, viscous joint friction, and realistic sensing and state-estimation effects. This demonstrates accurate tracking, smooth control inputs, and reliable constraint satisfaction under realistic operating conditions.

</details>


### [21] [VLingNav: Embodied Navigation with Adaptive Reasoning and Visual-Assisted Linguistic Memory](https://arxiv.org/abs/2601.08665)
*Shaoan Wang,Yuanfei Luo,Xingyu Chen,Aocheng Luo,Dongyue Li,Chang Liu,Sheng Chen,Yangang Zhang,Junzhi Yu*

Main category: cs.RO

TL;DR: VLingNav是针对体体现导航的新模型，采用自适应推理和记忆机制，表现出优异的导航性能，并能在现实世界应用中实现强大迁移能力。


<details>
  <summary>Details</summary>
Motivation: 大多数现有的VLA模型在面对复杂的长时间导航任务时，缺乏明确的推理能力和持久的记忆，因此提出VLingNav旨在增强这方面的能力。

Method: 提出了一种基于语言驱动的认知的VLA模型VLingNav，采用了自适应Chain-of-Thought机制和视觉辅助语言记忆模块，并结合在线专家指导的强化学习阶段进行训练。

Result: VLingNav结合自适应的推理机制和视觉辅助记忆，能够更好地处理长时间的空间依赖，同时超越纯模仿学习，获得更强的自我探索导航行为。

Conclusion: VLingNav在多种体体现导航基准测试中实现了最先进的性能，并且能够在零-shot情境下转移到现实世界的机器人平台，执行各种导航任务，表现出强大的跨领域和跨任务的迁移能力。

Abstract: VLA models have shown promising potential in embodied navigation by unifying perception and planning while inheriting the strong generalization abilities of large VLMs. However, most existing VLA models rely on reactive mappings directly from observations to actions, lacking the explicit reasoning capabilities and persistent memory required for complex, long-horizon navigation tasks. To address these challenges, we propose VLingNav, a VLA model for embodied navigation grounded in linguistic-driven cognition. First, inspired by the dual-process theory of human cognition, we introduce an adaptive chain-of-thought mechanism, which dynamically triggers explicit reasoning only when necessary, enabling the agent to fluidly switch between fast, intuitive execution and slow, deliberate planning. Second, to handle long-horizon spatial dependencies, we develop a visual-assisted linguistic memory module that constructs a persistent, cross-modal semantic memory, enabling the agent to recall past observations to prevent repetitive exploration and infer movement trends for dynamic environments. For the training recipe, we construct Nav-AdaCoT-2.9M, the largest embodied navigation dataset with reasoning annotations to date, enriched with adaptive CoT annotations that induce a reasoning paradigm capable of adjusting both when to think and what to think about. Moreover, we incorporate an online expert-guided reinforcement learning stage, enabling the model to surpass pure imitation learning and to acquire more robust, self-explored navigation behaviors. Extensive experiments demonstrate that VLingNav achieves state-of-the-art performance across a wide range of embodied navigation benchmarks. Notably, VLingNav transfers to real-world robotic platforms in a zero-shot manner, executing various navigation tasks and demonstrating strong cross-domain and cross-task generalization.

</details>


### [22] [A Hybrid Model-based and Data-based Approach Developed for a Prosthetic Hand Wrist](https://arxiv.org/abs/2601.08711)
*Shifa Sulaiman,Francesco Schetter,Mehul Menon,Fanny Ficuciello*

Main category: cs.RO

TL;DR: 本研究提出了一种结合ANN与SMC的控制器，以提高假肢手腕的运动控制效率，表现出优异的动态响应和较低的计算负担。


<details>
  <summary>Details</summary>
Motivation: 提高假肢手的控制精度和灵活度，尤其是在模仿人类手复杂运动的能力方面。

Method: 结合人工神经网络（ANN）和滑模控制器（SMC）设计的模型控制器，通过对肘部运动的控制实现有效调节。

Result: 所提出的控制器在性能上优于其他针对同样腕部的控制策略，并通过模拟研究和实验验证了其有效性。

Conclusion: 该研究表明，所提出的模型控制器在提高PRISMA HAND II假手腕动态响应速度和减少计算负担方面表现优异。

Abstract: The incorporation of advanced control algorithms into prosthetic hands significantly enhances their ability to replicate the intricate motions of a human hand. This work introduces a model-based controller that combines an Artificial Neural Network (ANN) approach with a Sliding Mode Controller (SMC) designed for a tendon-driven soft continuum wrist integrated into a prosthetic hand known as "PRISMA HAND II". Our research focuses on developing a controller that provides a fast dynamic response with reduced computational effort during wrist motions. The proposed controller consists of an ANN for computing bending angles together with an SMC to regulate tendon forces. Kinematic and dynamic models of the wrist are formulated using the Piece-wise Constant Curvature (PCC) hypothesis. The performance of the proposed controller is compared with other control strategies developed for the same wrist. Simulation studies and experimental validations of the fabricated wrist using the controller are included in the paper.

</details>


### [23] [Real-Time Localization Framework for Autonomous Basketball Robots](https://arxiv.org/abs/2601.08713)
*Naren Medarametla,Sreejon Mondal*

Main category: cs.RO

TL;DR: 提出一种基于视觉数据的混合定位算法，以提高机器人在Robocon 2025中的定位精度和效率。


<details>
  <summary>Details</summary>
Motivation: 提升机器人在动态环境中的定位能力，特别是在Robocon 2025比赛中，准确可靠的定位对于提高射击精度和避开碰撞至关重要。

Method: 提出一种混合定位算法，结合经典技术与基于视觉数据的学习方法，实现在篮球场上的自我定位。

Result: 该算法能够利用篮球场地面的视觉数据进行有效的自我定位。

Conclusion: 混合定位算法能够改善机器人的定位精度和操作效率，适用于动态比赛环境。

Abstract: Localization is a fundamental capability for autonomous robots, enabling them to operate effectively in dynamic environments. In Robocon 2025, accurate and reliable localization is crucial for improving shooting precision, avoiding collisions with other robots, and navigating the competition field efficiently. In this paper, we propose a hybrid localization algorithm that integrates classical techniques with learning based methods that rely solely on visual data from the court's floor to achieve self-localization on the basketball field.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [24] [From Tool to Teacher: Rethinking Search Systems as Instructive Interfaces](https://arxiv.org/abs/2601.08035)
*David Elsweiler*

Main category: cs.HC

TL;DR: 本论文探讨了如何从教育学角度优化信息获取系统，帮助用户更好地发展搜索策略和批判意识。


<details>
  <summary>Details</summary>
Motivation: 当前信息获取系统主要优化检索效率，缺乏帮助用户提升搜索策略和批判意识的功能。

Method: 通过分析教育和行为科学中的教学框架，并应用于信息系统设计，展示不同设计选择如何影响用户的学习和技能发展。

Result: 本论文提出了一种教育学视角来分析信息获取系统的设计，强调这些系统不仅应优化信息检索，更要助力用户的搜索策略和批判意识的提升。通过教育和行为科学中的七种教学框架，研究了现有和新兴系统功能如何影响用户学习，特别是评估能力、元认知反思和策略转移等技能的推广。

Conclusion: 该论文为信息获取系统的教育价值提供了概念性视角，并提出了促进用户成为更有效、反思性和韧性的信息检索者的设计建议。

Abstract: Information access systems such as search engines and generative AI are central to how people seek, evaluate, and interpret information. Yet most systems are designed to optimise retrieval rather than to help users develop better search strategies or critical awareness. This paper introduces a pedagogical perspective on information access, conceptualising search and conversational systems as instructive interfaces that can teach, guide, and scaffold users' learning. We draw on seven didactic frameworks from education and behavioural science to analyse how existing and emerging system features, including query suggestions, source labels, and conversational or agentic AI, support or limit user learning. Using two illustrative search tasks, we demonstrate how different design choices promote skills such as critical evaluation, metacognitive reflection, and strategy transfer. The paper contributes a conceptual lens for evaluating the instructional value of information access systems and outlines design implications for technologies that foster more effective, reflective, and resilient information seekers.

</details>


### [25] [The Impact of AI Generated Content on Decision Making for Topics Requiring Expertise](https://arxiv.org/abs/2601.08178)
*Shangqian Li,Tianwa Chen,Gianluca Demartini*

Main category: cs.HC

TL;DR: 本研究探讨了AI生成内容与人类信息在决策支持中的作用，发现前者在某些情境下同样有效，但用户在缺乏专业知识时仍依赖于初始观点。


<details>
  <summary>Details</summary>
Motivation: 弥补在线决策与意见变化过程中领域知识与AI生成内容之间相互作用的不明确性

Method: 进行实验室基础的解释性序列研究，针对大学生进行调查

Result: 参与者在专业领域话题上的观点不易改变，AI生成的信息与人类撰写的信息同样有效

Conclusion: AI生成的信息在某些情况下能够替代人类专家的信息，但用户在缺乏专业知识时更倾向于依赖提供的结论，难以进行深度独立推理

Abstract: Modelling users' online decision-making and opinion change is a complex issue that needs to consider users' personal determinants, the nature of the topic and the information retrieval activities. Furthermore, generative-AIbased products like ChatGPT gradually become an essential element for the retrieval of online information. However, the interaction between domainspecific knowledge and AI-generated content during online decision-making is unclear. We conducted a lab-based explanatory sequential study with university students to overcome this research gap. In the experiment, we surveyed participants about a set of general domain topics that are easy to grasp and another set of domain-specific topics that require adequate levels of chemical science knowledge to fully comprehend. We provided participants with decision-supporting information that was either produced using generative AI or collected from selected expert human-written sources to explore the role of AI-generated content compared to ordinary information during decision-making. Our result revealed that participants are less likely to change opinions on domain-specific topics. Since participants without professional knowledge had difficulty performing in-depth and independent reasoning based on the information, they favoured relying on conclusions presented in the provided materials and tended to stick to their initial opinion. Besides, information that is labelled as AI-generated is equivalently helpful as information labelled as dedicatedly human-written for participants in this experiment, indicating the vast potential as well as concerns for AI replacing human experts to help users tackle professional topics or issues.

</details>


### [26] [Simulations for Augmented Reality Evaluation for Mass Casualty Incident Triage](https://arxiv.org/abs/2601.08186)
*Cassidy R. Nelson,Joseph L. Gabbard,Jason B. Moats,Ranjana K. Mehta*

Main category: cs.HC

TL;DR: 本论文探讨了增强现实在大规模伤亡事故应对中的应用，提出了两种模拟策略以验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 随着大规模伤亡事故的风险上升，提升应对能力变得至关重要。增强现实被认为是一个有前景的工具，但需要经过充分的概念验证。

Method: 本研究提出两种渐进的增强现实模拟策略，旨在弥合计算机模拟与现场响应之间的差距。

Result: 通过新模拟策略的应用，可以更好地评估并提升增强现实在MCI响应中的有效性。

Conclusion: 本研究提出的两种增强现实模拟策略可以有效地连接计算机模拟与实际现场响应，促进大规模伤亡事故的应对能力提升。

Abstract: Mass casualty incidents (MCIs) are a high-risk, sensitive domain with profound implications for patient and responder safety. Augmented reality has shown promise as an assistive tool for high-stress work domains and MCI triage both in the field and for pre-field training. However, the vulnerability of MCIs makes it challenging to evaluate new tools designed to enhance MCI response. In other words, profound evolutions like the integration of augmented reality into field response require thorough proof-of-concept evaluations before being launched into real-world response. This paper describes two progressive simulation strategies for augmented reality that bridge the gap between computer-based simulation and actual field response.

</details>


### [27] [From Fixed to Flexible: Shaping AI Personality in Context-Sensitive Interaction](https://arxiv.org/abs/2601.08194)
*Shakyani Jayasiriwardene,Hongyu Zhou,Weiwei Jiang,Benjamin Tag,Emmanuel Stamatakis,Anusha Withana,Zhanna Sarsenbayeva*

Main category: cs.HC

TL;DR: 本研究探讨了动态可调的对话代理个性如何影响用户期望与信任，强调了以人为中心的AI设计的重要性。


<details>
  <summary>Details</summary>
Motivation: 探讨用户期待在对话代理的个性可以动态调整时如何形成和演变。

Method: 进行了一项在线混合方法研究，涉及60名参与者，使用潜在构型分析来描述个性类，并使用轨迹分析来追踪个性调整的发展模式。

Result: 研究发现不同的个性概况在初始和最终配置阶段显现，调整轨迹受到情境敏感性影响。参与者对对话代理的自主性给予了高度评价，认为其更具人性化，并报告了更高的信任感。

Conclusion: 本研究强调了设计应该能够随用户调整的对话代理的重要性，以推进更加响应和以人为中心的人工智能。

Abstract: Conversational agents are increasingly expected to adapt across contexts and evolve their personalities through interactions, yet most remain static once configured. We present an exploratory study of how user expectations form and evolve when agent personality is made dynamically adjustable. To investigate this, we designed a prototype conversational interface that enabled users to adjust an agent's personality along eight research-grounded dimensions across three task contexts: informational, emotional, and appraisal. We conducted an online mixed-methods study with 60 participants, employing latent profile analysis to characterize personality classes and trajectory analysis to trace evolving patterns of personality adjustment. These approaches revealed distinct personality profiles at initial and final configuration stages, and adjustment trajectories, shaped by context-sensitivity. Participants also valued the autonomy, perceived the agent as more anthropomorphic, and reported greater trust. Our findings highlight the importance of designing conversational agents that adapt alongside their users, advancing more responsive and human-centred AI.

</details>


### [28] [Scoping Review: Mental Health XR Games at ISMAR, IEEEVR, & TVCG](https://arxiv.org/abs/2601.08203)
*Cassidy R. Nelson*

Main category: cs.HC

TL;DR: 该论文对扩展现实严肃游戏在心理健康领域的应用进行了文献综述，发现XR社区对此主题探索有限，建议未来进一步研究。


<details>
  <summary>Details</summary>
Motivation: 心理健康治疗的可及性差距促使探索扩展现实严肃游戏，将治疗带到患者家中，并提升治疗动力和参与度。

Method: 进行文献综述，评估XR社区在心理健康严肃游戏领域的贡献，识别204篇相关文献，深入分析6款XR严肃游戏。

Result: 发现XR心理健康严肃游戏的相关研究数量相对较少，表明该领域仍待探索。

Conclusion: 评估的游戏元素和心理基础为XR研究者提供了未来研究方向，强化了该领域的探索价值。

Abstract: Extended reality serious games for mental health are a promising research avenue to address the accessibility gap in mental health treatment by bringing therapy to patients in their homes, offering highly adaptable and immersive yet safe therapy opportunities, and increasing motivation and engagement with therapeutic exercises. However, the sensitive use case of mental health demands thoughtful integration with mental health concepts and a comprehensive understanding of prior literature. This paper presents a scoping literature review of the ISMAR, IEEEVR, and TVCG communities to assess the contributions of the XR community to the mental health serious game domain and explore potential weaknesses and strengths for future work by XR researchers. To this end, this review identified 204 possibly relevant articles in the XR community and fully evaluated 6 XR serious games for mental health. This relatively small number of articles for final inclusion suggests that XR mental health serious games are largely underexplored by the XR community (or not reported within the XR community). There is value in exploring the existing literature space as it is. Thus, this paper evaluates these six papers in terms of game elements and underlying psychological foundations, and discuss future directions for XR researchers in this wide-open research space within our community.

</details>


### [29] [Data-Induced Groupings and How To Find Them](https://arxiv.org/abs/2601.08256)
*Yilan Jiang,Cindy Xiong Bearfield,Steven Franconeri,Eugene Wu*

Main category: cs.HC

TL;DR: 该研究揭示了可视化设计与数据值之间的相互作用，提出了识别和改善用户对数据分组理解的模型。


<details>
  <summary>Details</summary>
Motivation: 探讨可视化设计与数据值如何相互影响，以改善用户对数据的解释与推理能力。

Method: 进行两项用户研究，使用点图作为案例研究，以识别数据诱导的分组现象。构建模型预测用户如何看待点图中的点分组。

Result: 即使在名义数据中，用户在两种条件下仍依赖数据诱导的分组，尽管这些分组与趋势无关。

Conclusion: 模型可以帮助可视化设计师识别潜在的用户感知分组，并提供更好的设计建议以突显期望的分组。

Abstract: Making sense of a visualization requires the reader to consider both the visualization design and the underlying data values. Existing work in the visualization community has largely considered affordances driven by visualization design elements, such as color or chart type, but how visual design interacts with data values to impact interpretation and reasoning has remained under-explored. Dot plots and bar graphs are commonly used to help users identify groups of points that form trends and clusters, but are liable to manifest groupings that are artifacts of spatial arrangement rather than inherent patterns in the data itself. These ``Data-induced Groups'' can drive suboptimal data comparisons and potentially lead the user to incorrect conclusions. We conduct two user studies using dot plots as a case study to understand the prevalence of data-induced groupings. We find that users rely on data-induced groupings in both conditions despite the fact that trend-based groupings are irrelevant in nominal data. Based on the study results, we build a model to predict whether users are likely to perceive a given set of dot plot points as a group. We discuss two use cases illustrating how the model can assist visualization designers by both diagnosing potential user-perceived groupings in dot plots and offering redesigns that better accentuate desired groupings through data rearrangement.

</details>


### [30] [Characterizing Personality from Eye-Tracking: The Role of Gaze and Its Absence in Interactive Search Environments](https://arxiv.org/abs/2601.08287)
*Jiaman He,Marta Micheli,Damiano Spina,Dana McKay,Johanne R. Trippas,Noriko Kando*

Main category: cs.HC

TL;DR: 本研究通过眼动跟踪数据和视线缺失期的多模态时间序列模型，探索个性特征与搜索行为的关联，结果表明结合缺失信息能显著提高个性预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 尽管个性特征影响个人信息获取过程，但很少有研究将个性与可观察的搜索行为联系起来，因此需要对此进行探索。

Method: 通过多模态时间序列模型，结合眼动跟踪数据和用户视线缺失时间段，对个性特征进行建模和预测。

Result: 研究发现，通过结合时间序列信号和缺失信息的完整模型，在预测五大个性特征的准确性和宏观F1分数上提高了10-15%，验证了模型的有效性和个性推断的可能性。

Conclusion: 个性可以通过搜索相关的凝视行为推断，并且将缺失的凝视数据纳入时间序列多模态建模中具有价值。

Abstract: Personality traits influence how individuals engage, behave, and make decisions during the information-seeking process. However, few studies have linked personality to observable search behaviors. This study aims to characterize personality traits through a multimodal time-series model that integrates eye-tracking data and gaze missingness-periods when the user's gaze is not captured. This approach is based on the idea that people often look away when they think, signaling disengagement or reflection. We conducted a user study with 25 participants, who used an interactive application on an iPad, allowing them to engage with digital artifacts from a museum. We rely on raw gaze data from an eye tracker, minimizing preprocessing so that behavioral patterns can be preserved without substantial data cleaning. From this perspective, we trained models to predict personality traits using gaze signals. Our results from a five-fold cross-validation study demonstrate strong predictive performance across all five dimensions: Neuroticism (Macro F1 = 77.69%), Conscientiousness (74.52%), Openness (77.52%), Agreeableness (73.09%), and Extraversion (76.69%). The ablation study examines whether the absence of gaze information affects the model performance, demonstrating that incorporating missingness improves multimodal time-series modeling. The full model, which integrates both time-series signals and missingness information, achieves 10-15% higher accuracy and macro F1 scores across all Big Five traits compared to the model without time-series signals and missingness. These findings provide evidence that personality can be inferred from search-related gaze behavior and demonstrate the value of incorporating missing gaze data into time-series multimodal modeling.

</details>


### [31] [Rewriting Video: Text-Driven Reauthoring of Video Footage](https://arxiv.org/abs/2601.08565)
*Sitong Wang,Anh Truong,Lydia B. Chilton,Dingzeyu Li*

Main category: cs.HC

TL;DR: 本研究探讨了如何利用生成AI简化视频编辑，通过文本提示重新创作视频，揭示了人机感知差距及创作中的张力，为未来设计提供了洞见。


<details>
  <summary>Details</summary>
Motivation: 现有视频编辑复杂且耗时，生成AI技术表明可以简化这一过程，让视频编辑像文本重写一样简单。

Method: 通过技术探测器和研究进行文本驱动的视频重新创作

Result: 提出了一种生成重建算法和互动工具Rewrite Kit，支持创作者通过文本提示操控视频内容。

Conclusion: 文本驱动的视频重新创作存在人机感知差距，同时呈现出新机遇与挑战，需设计未来的合作创作视频工具。

Abstract: Video is a powerful medium for communication and storytelling, yet reauthoring existing footage remains challenging. Even simple edits often demand expertise, time, and careful planning, constraining how creators envision and shape their narratives. Recent advances in generative AI suggest a new paradigm: what if editing a video were as straightforward as rewriting text? To investigate this, we present a tech probe and a study on text-driven video reauthoring. Our approach involves two technical contributions: (1) a generative reconstruction algorithm that reverse-engineers video into an editable text prompt, and (2) an interactive probe, Rewrite Kit, that allows creators to manipulate these prompts. A technical evaluation of the algorithm reveals a critical human-AI perceptual gap. A probe study with 12 creators surfaced novel use cases such as virtual reshooting, synthetic continuity, and aesthetic restyling. It also highlighted key tensions around coherence, control, and creative alignment in this new paradigm. Our work contributes empirical insights into the opportunities and challenges of text-driven video reauthoring, offering design implications for future co-creative video tools.

</details>


### [32] [Enhancing Financial Literacy and Management through Goal-Directed Design and Gamification in Personal Finance Application](https://arxiv.org/abs/2601.08640)
*Phuong Lien To*

Main category: cs.HC

TL;DR: 本研究通过Alan Cooper的设计方法开发了一款财务管理应用，以提高年轻人的财务素养，结合个性化功能与游戏化元素。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在通过有效的工具提升年轻人的财务管理能力，以应对现代社会对财务素养的需求。

Method: 研究采用访谈、问卷和可用性测试等方法，设计出符合年轻人需求的财务管理应用。

Result: 本研究开发了一款旨在提升年轻人财务管理能力的应用程序，采用了Alan Cooper的目标导向设计方法。

Conclusion: 研究结果凸显了游戏化学习和个性化体验在促进年轻用户改善财务行为方面的有效性。

Abstract: This study explores the development of a financial management application for young people using Alan Cooper's Goal-Directed Design method. Through interviews, surveys, and usability testing, the application was designed to improve financial literacy by combining personalised features and gamification. Findings highlight the effectiveness of gamified learning and tailored experiences in encouraging better financial behaviour among young users.

</details>


### [33] [Tailored Immersive Environments: Advancing Neurodivergent Support Through Virtual Reality](https://arxiv.org/abs/2601.08652)
*Elia Moscoso-Thompson,Katia Lupinetti,Irene Capasso,Fabrizio Ravicchio,Brigida Bonino,Franca Giannini,Andrea Canessa,Silvio Sabatini,Lucia Ferlino,Chiara Malagoli*

Main category: cs.HC

TL;DR: 本文介绍了一种虚拟现实系统，旨在帮助神经多样性个体（特别是自闭症谱系障碍者）通过个性化的环境练习日常任务，并研究了其在不同难度水平下的应用。


<details>
  <summary>Details</summary>
Motivation: 在日常生活中，自闭症谱系障碍（ASD）个体面临重大挑战，因此需要一种有效的训练工具来帮助他们应对这些挑战。

Method: 开发了一种虚拟现实系统，该系统能够根据用户的特定能力和训练需求自动个性化虚拟环境，并在四个合成用户档案上进行评估。

Result: 该方法在同一难度水平内能够生成大量不同场景，且特定档案下的非约束特征方差较大，显示出系统的适应性。

Conclusion: 该虚拟现实系统能够根据神经多样性个体的能力和训练需求进行自动个性化，为克服日常挑战提供了有效的支持。

Abstract: Every day life tasks can present significant challenges for neurodivergent individuals, particularly those with Autism Spectrum Disorders (ASD) who are characterized by specific sensitivities. This contribution describes a virtual reality system that allows neurodivergent individuals to experience everyday situations in order to practice and implement strategies for overcoming their daily challenges. The key strength of the proposed system is the automatic personalization of the virtual environment, based on both the individual's abilities and their specific training needs. The proposed method has been evaluated on four synthetic user profiles, also proposing a metric able to evaluate the variance of the features within the same difficulty level. The results show that the method can produce a significant number of scenarios for the various difficulty levels. Furthermore, within the same difficulty, there is a wide variance of the non-constrained features for the specific profile.

</details>


### [34] [Auditing Student-AI Collaboration: A Case Study of Online Graduate CS Students](https://arxiv.org/abs/2601.08697)
*Nifu Dan*

Main category: cs.HC

TL;DR: 这项研究探讨了学生在学术任务中对人工智能协作的偏好和期望，结果揭示了学生对自动化的期望与实际AI能力之间存在差距，并提出了改善人工智能系统设计的建议。


<details>
  <summary>Details</summary>
Motivation: 随着生成性人工智能在高等教育中的逐步嵌入，了解学生与AI合作的偏好及其对学术任务的影响变得尤为重要。

Method: 本研究采用两轮顺序互补的调查方法，第一轮通过现有任务框架评估学生对12项学术任务的AI使用偏好及实际使用情况，第二轮则通过开放式问题探讨如何设计AI系统以满足学生的关切。

Result: 本研究通过混合方法审核学生与人工智能的合作偏好，旨在找出当前人工智能能力与学生对学术工作自动化的期望之间的差距。

Conclusion: 研究表明，学生在使用人工智能时既希望获得便利又担忧自动化过度，提出了对人工智能系统设计的具体建议，以满足学生的需求和期望。

Abstract: As generative AI becomes embedded in higher education, it increasingly shapes how students complete academic tasks. While these systems offer efficiency and support, concerns persist regarding over-automation, diminished student agency, and the potential for unreliable or hallucinated outputs. This study conducts a mixed-methods audit of student-AI collaboration preferences by examining the alignment between current AI capabilities and students' desired levels of automation in academic work. Using two sequential and complementary surveys, we capture students' perceived benefits, risks, and preferred boundaries when using AI. The first survey employs an existing task-based framework to assess preferences for and actual usage of AI across 12 academic tasks, alongside primary concerns and reasons for use. The second survey, informed by the first, explores how AI systems could be designed to address these concerns through open-ended questions. This study aims to identify gaps between existing AI affordances and students' normative expectations of collaboration, informing the development of more effective and trustworthy AI systems for education.

</details>
