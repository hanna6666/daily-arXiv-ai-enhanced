<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 23]
- [cs.HC](#cs.HC) [Total: 9]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Wake Vectoring for Efficient Morphing Flight](https://arxiv.org/abs/2512.05211)
*Ioannis Mandralis,Severin Schumacher,Morteza Gharib*

Main category: cs.RO

TL;DR: 本研究提出了一种被动气流引导机制，解决了变形飞行机器人在飞行中重配置时失去垂直推力的问题。


<details>
  <summary>Details</summary>
Motivation: 变形飞行机器人具有在复杂环境中导航和无缝转换领空与地面运动的潜力，但在飞行中重配置会导致推力降低，影响稳定性和控制能力。

Method: 引入了一种被动气流引导机制，该机制通过内置的偏转器捕获并重定向旋翼尾流，恢复在变形过程中失去的垂直推力。

Result: 在没有产生有效推力的配置中，实现了多达40%的垂直推力恢复，显著增强了变形过程中的悬停和机动能力。

Conclusion: 该研究展示了一种新的变形飞行机器人设计方向，通过被动气动结构实现高效灵活的飞行，避免了额外的机械复杂性。

Abstract: Morphing aerial robots have the potential to transform autonomous flight, enabling navigation through cluttered environments, perching, and seamless transitions between aerial and terrestrial locomotion. Yet mid-flight reconfiguration presents a critical aerodynamic challenge: tilting propulsors to achieve shape change reduces vertical thrust, undermining stability and control authority. Here, we introduce a passive wake vectoring mechanism that recovers lost thrust during morphing. Integrated into a novel robotic system, Aerially Transforming Morphobot (ATMO), internal deflectors intercept and redirect rotor wake downward, passively steering airflow momentum that would otherwise be wasted. This electronics-free solution achieves up to a 40% recovery of vertical thrust in configurations where no useful thrust would otherwise be produced, substantially extending hover and maneuvering capabilities during transformation. Our findings highlight a new direction for morphing aerial robot design, where passive aerodynamic structures, inspired by thrust vectoring in rockets and aircraft, enable efficient, agile flight without added mechanical complexity.

</details>


### [2] [Search at Scale: Improving Numerical Conditioning of Ergodic Coverage Optimization for Multi-Scale Domains](https://arxiv.org/abs/2512.05229)
*Yanis Lahrach,Christian Hughes,Ian Abraham*

Main category: cs.RO

TL;DR: 本研究提出一种规模无关和自适应的遍历覆盖优化方法，解决了数值缩放敏感性问题，并在多个覆盖问题中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 当前的遍历覆盖规划方法对几何覆盖问题的多种约束表现出良好的适应性，但在问题空间的数值缩放上高度敏感，导致优化公式在缩放变化时变得脆弱和不稳定。

Method: 本研究开发了一种基于最大均值差异（MMD）度量的规模无关和自适应的遍历覆盖优化方法，允许优化器解决差异约束的规模，同时调整超参数以适应问题领域，确保物理一致性。

Result: 我们还推导出一种在对数空间中的遍历度量变体，为数值条件提供额外的支持，而不损失性能，并将我们的方法与现有的覆盖规划方法进行了比较。

Conclusion: 我们的研究展示了该方法在多个覆盖问题中的效用。

Abstract: Recent methods in ergodic coverage planning have shown promise as tools that can adapt to a wide range of geometric coverage problems with general constraints, but are highly sensitive to the numerical scaling of the problem space. The underlying challenge is that the optimization formulation becomes brittle and numerically unstable with changing scales, especially under potentially nonlinear constraints that impose dynamic restrictions, due to the kernel-based formulation. This paper proposes to address this problem via the development of a scale-agnostic and adaptive ergodic coverage optimization method based on the maximum mean discrepancy metric (MMD). Our approach allows the optimizer to solve for the scale of differential constraints while annealing the hyperparameters to best suit the problem domain and ensure physical consistency. We also derive a variation of the ergodic metric in the log space, providing additional numerical conditioning without loss of performance. We compare our approach with existing coverage planning methods and demonstrate the utility of our approach on a wide range of coverage problems.

</details>


### [3] [Invariance Co-training for Robot Visual Generalization](https://arxiv.org/abs/2512.05230)
*Jonathan Yang,Chelsea Finn,Dorsa Sadigh*

Main category: cs.RO

TL;DR: 本研究提出了两个辅助任务，通过多样化的数据训练以提升机器人政策在多种环境下的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 由于当前大型机器人数据集缺乏丰富的变化，导致机器人的普遍政策在不同观察条件下的泛化能力有限。

Method: 引入状态相似性和对观察扰动的不变性这两个辅助任务，对机器人政策进行系统性审查。

Result: 通过联合训练机器人演示数据和从非物理基础的模拟中生成的合成视觉数据，显著提高了对未见的相机视角、照明配置和干扰条件的泛化能力。

Conclusion: 利用多样化的数据共同训练可以显著提高机器人的表现，这种方法比现有的生成增强方法提高了18%的性能。

Abstract: Reasoning from diverse observations is a fundamental capability for generalist robot policies to operate in a wide range of environments. Despite recent advancements, many large-scale robotic policies still remain sensitive to key sources of observational variation such as changes in camera perspective, lighting, and the presence of distractor objects. We posit that the limited generalizability of these models arises from the substantial diversity required to robustly cover these quasistatic axes, coupled with the current scarcity of large-scale robotic datasets that exhibit rich variation across them. In this work, we propose to systematically examine what robots need to generalize across these challenging axes by introducing two key auxiliary tasks, state similarity and invariance to observational perturbations, applied to both demonstration data and static visual data. We then show that via these auxiliary tasks, leveraging both more-expensive robotic demonstration data and less-expensive, visually rich synthetic images generated from non-physics-based simulation (for example, Unreal Engine) can lead to substantial increases in generalization to unseen camera viewpoints, lighting configurations, and distractor conditions. Our results demonstrate that co-training on this diverse data improves performance by 18 percent over existing generative augmentation methods. For more information and videos, please visit https://invariance-cotraining.github.io

</details>


### [4] [XR-DT: Extended Reality-Enhanced Digital Twin for Agentic Mobile Robots](https://arxiv.org/abs/2512.05270)
*Tianyi Wang,Jiseop Byeon,Ahmad Yehia,Huihai Wang,Yiming Xu,Tianyi Zeng,Ziran Wang,Junfeng Jiao,Christian Claudel*

Main category: cs.RO

TL;DR: 该论文提出了一种扩展现实增强的数字双胞胎框架（XR-DT），旨在提升人机交互的安全性与可解释性，通过整合实时传感器数据和人类反馈，实现动态任务中的鲁棒性和协作。


<details>
  <summary>Details</summary>
Motivation: 在协作工作空间中，人机交互的安全性、效率和可解释性已成为亟待解决的挑战。当前对人类行为预测的研究进展较大，但对人类如何感知、解读和信任机器人的推理关注不足，这限制了其在安全关键和社会嵌入环境中的应用

Method: 提出了一个扩展现实增强的数字双胞胎框架（XR-DT），将物理和虚拟空间连接起来，实现人机之间的双向理解。该框架集成了虚拟、增强和混合现实层，融合实时传感器数据、Unity游戏引擎中的模拟环境和通过可穿戴AR设备捕获的人类反馈。设计了一个具有统一扩散策略的代理移动机器人系统，允许上下文感知的任务适应。同时，提出了一种链式思维提示机制，使多模态大型语言模型能够理解人类指令和环境上下文，并利用基于AutoGen的多代理协调层强化动态任务中的鲁棒性和协作

Result: 初步实验结果证明了人类和机器人轨迹预测的准确性，验证了XR-DT框架在HRI任务中的有效性。

Conclusion: 通过将人类意图、环境动态和机器人认知嵌入XR-DT框架，我们的系统实现了可解释、值得信赖和自适应的人机交互。

Abstract: As mobile robots increasingly operate alongside humans in shared workspaces, ensuring safe, efficient, and interpretable Human-Robot Interaction (HRI) has become a pressing challenge. While substantial progress has been devoted to human behavior prediction, limited attention has been paid to how humans perceive, interpret, and trust robots' inferences, impeding deployment in safety-critical and socially embedded environments. This paper presents XR-DT, an eXtended Reality-enhanced Digital Twin framework for agentic mobile robots, that bridges physical and virtual spaces to enable bi-directional understanding between humans and robots. Our hierarchical XR-DT architecture integrates virtual-, augmented-, and mixed-reality layers, fusing real-time sensor data, simulated environments in the Unity game engine, and human feedback captured through wearable AR devices. Within this framework, we design an agentic mobile robot system with a unified diffusion policy for context-aware task adaptation. We further propose a chain-of-thought prompting mechanism that allows multimodal large language models to reason over human instructions and environmental context, while leveraging an AutoGen-based multi-agent coordination layer to enhance robustness and collaboration in dynamic tasks. Initial experimental results demonstrate accurate human and robot trajectory prediction, validating the XR-DT framework's effectiveness in HRI tasks. By embedding human intention, environmental dynamics, and robot cognition into the XR-DT framework, our system enables interpretable, trustworthy, and adaptive HRI.

</details>


### [5] [Disturbance Compensation for Safe Kinematic Control of Robotic Systems with Closed Architecture](https://arxiv.org/abs/2512.05292)
*Fan Zhang,Jinfeng Chen,Joseph J. B. Mvogo Ahanda,Hanz Richter,Ge Lv,Bin Hu,Qin Lin*

Main category: cs.RO

TL;DR: 开发了一种易于集成的外环控制器，结合了扰动拒绝控制和强健控制屏障函数，提升了工业机械手的跟踪性能和安全性。


<details>
  <summary>Details</summary>
Motivation: 在商业机器人系统中，内环扭矩控制器通常不可用户修改，而外环控制器则可接受用户命令，因此需要优化该外环控制。

Method: 结合扰动拒绝控制与强健控制屏障函数，设计兼具高性能跟踪和安全控制的外环控制器。

Result: 通过稳定性分析、形式安全保证证明和对PUMA机器人 manipulator的硬件实验，验证了所提方案的有效性。

Conclusion: 所提方案在实现简单性、鲁棒性、跟踪精度和安全性方面表现优于现有技术。

Abstract: In commercial robotic systems, it is common to encounter a closed inner-loop torque controller that is not user-modifiable. However, the outer-loop controller, which sends kinematic commands such as position or velocity for the inner-loop controller to track, is typically exposed to users. In this work, we focus on the development of an easily integrated add-on at the outer-loop layer by combining disturbance rejection control and robust control barrier function for high-performance tracking and safe control of the whole dynamic system of an industrial manipulator. This is particularly beneficial when 1) the inner-loop controller is imperfect, unmodifiable, and uncertain; and 2) the dynamic model exhibits significant uncertainty. Stability analysis, formal safety guarantee proof, and hardware experiments with a PUMA robotic manipulator are presented. Our solution demonstrates superior performance in terms of simplicity of implementation, robustness, tracking precision, and safety compared to the state of the art. Video: https://youtu.be/zw1tanvrV8Q

</details>


### [6] [Seabed-to-Sky Mapping of Maritime Environments with a Dual Orthogonal SONAR and LiDAR Sensor Suite](https://arxiv.org/abs/2512.05303)
*Christian Westerdahl,Jonas Poulsen,Daniel Holmelund,Peter Nicholas Hansen,Fletcher Thompson,Roberto Galeazzi*

Main category: cs.RO

TL;DR: 本研究提出了一种新的GNSS独立映射系统，结合LiDAR和声纳技术，实现了实时的海洋环境三维建模。


<details>
  <summary>Details</summary>
Motivation: 随着关键海洋基础设施权限的增长，迫切需要一种更可靠、成本效益更高的映射系统以增强海洋情境感知。

Method: 提出一种统一的GNSS独立映射系统，融合LiDAR-IMU与双向前方声纳，生成从自主水面车辆得到的连续的海床至天空映射。

Result: 系统在现实数据上验证，实时操作约2.65 Hz的地图更新和2.85 Hz的里程计，同时生成涵盖空气-水域的统一3D模型。

Conclusion: 该系统解决了现有海洋基础设施映射的不足，为实现更可靠的海洋情境感知提供了一种新方法。

Abstract: Critical maritime infrastructure increasingly demands situational awareness both above and below the surface, yet existing ''seabed-to-sky'' mapping pipelines either rely on GNSS (vulnerable to shadowing/spoofing) or expensive bathymetric sonars. We present a unified, GNSS-independent mapping system that fuses LiDAR-IMU with a dual, orthogonally mounted Forward Looking Sonars (FLS) to generate consistent seabed-to-sky maps from an Autonomous Surface Vehicle. On the acoustic side, we extend orthogonal wide-aperture fusion to handle arbitrary inter-sonar translations (enabling heterogeneous, non-co-located models) and extract a leading edge from each FLS to form line-scans. On the mapping side, we modify LIO-SAM to ingest both stereo-derived 3D sonar points and leading-edge line-scans at and between keyframes via motion-interpolated poses, allowing sparse acoustic updates to contribute continuously to a single factor-graph map. We validate the system on real-world data from Belvederekanalen (Copenhagen), demonstrating real-time operation with approx. 2.65 Hz map updates and approx. 2.85 Hz odometry while producing a unified 3D model that spans air-water domains.

</details>


### [7] [State-Conditional Adversarial Learning: An Off-Policy Visual Domain Transfer Method for End-to-End Imitation Learning](https://arxiv.org/abs/2512.05335)
*Yuxiang Liu,Shengfan Cao*

Main category: cs.RO

TL;DR: 该论文研究了一种在稀缺目标领域数据下的视觉领域转移方法，通过状态条件对抗学习实现源领域和目标领域的模仿学习，实验表明该方法有效。


<details>
  <summary>Details</summary>
Motivation: 探讨在现实环境中如何有效利用有限的目标领域数据进行模仿学习，并解决目标领域缺乏专家指导的问题。

Method: 提出状态条件对抗学习框架，利用判别器估计条件的KL散度项，以对齐源领域和目标领域的潜在分布。

Result: 该研究提出了一种视觉领域转移的方法，用于在一个现实且具有挑战性的环境中进行端到端的模仿学习。在目标领域数据严格离线、无专家指导及稀缺的情况下，提出了基于理论分析的状态条件对抗学习框架，以实现源领域和目标领域观察模型的对齐。

Conclusion: 通过实验验证，该方法在视觉多样化的自动驾驶环境中，展现了稳健的转移能力和强大的样本效率。

Abstract: We study visual domain transfer for end-to-end imitation learning in a realistic and challenging setting where target-domain data are strictly off-policy, expert-free, and scarce. We first provide a theoretical analysis showing that the target-domain imitation loss can be upper bounded by the source-domain loss plus a state-conditional latent KL divergence between source and target observation models. Guided by this result, we propose State- Conditional Adversarial Learning, an off-policy adversarial framework that aligns latent distributions conditioned on system state using a discriminator-based estimator of the conditional KL term. Experiments on visually diverse autonomous driving environments built on the BARC-CARLA simulator demonstrate that SCAL achieves robust transfer and strong sample efficiency.

</details>


### [8] [Spatiotemporal Tubes for Differential Drive Robots with Model Uncertainty](https://arxiv.org/abs/2512.05495)
*Ratnangshu Das,Ahan Basu,Christos Verginis,Pushpak Jagtap*

Main category: cs.RO

TL;DR: 本文提出一种新型控制框架，通过时空管确保差动驱动机器人在动态不确定性和外部干扰下满足时间约束，同时实现高效、鲁棒的控制。


<details>
  <summary>Details</summary>
Motivation: 在动态环境下确保差动驱动机器人安全有效地达到目标，同时应对不确定性和干扰。

Method: 采用圆形时空管的定义方法，通过取样合成算法构建可行的时空管，并设计闭式控制律以维持机器人在管内。

Result: 提出了一种基于时空管（STT）的控制框架，用于具有动态不确定性和外部干扰的差动驱动移动机器人，确保满足时间到达-避免-停留（T-RAS）规范。

Conclusion: 通过对差动驱动机器人的仿真研究验证了该框架，并与最新方法进行基准测试，显示出卓越的鲁棒性、准确性和计算效率。

Abstract: This paper presents a Spatiotemporal Tube (STT)-based control framework for differential-drive mobile robots with dynamic uncertainties and external disturbances, guaranteeing the satisfaction of Temporal Reach-Avoid-Stay (T-RAS) specifications. The approach employs circular STT, characterized by smoothly time-varying center and radius, to define dynamic safe corridors that guide the robot from the start region to the goal while avoiding obstacles. In particular, we first develop a sampling-based synthesis algorithm to construct a feasible STT that satisfies the prescribed timing and safety constraints with formal guarantees. To ensure that the robot remains confined within this tube, we then design analytically a closed-form, approximation-free control law. The resulting controller is computationally efficient, robust to disturbances and {model uncertainties}, and requires no model approximations or online optimization. The proposed framework is validated through simulation studies on a differential-drive robot and benchmarked against state-of-the-art methods, demonstrating superior robustness, accuracy, and computational efficiency.

</details>


### [9] [A Hyperspectral Imaging Guided Robotic Grasping System](https://arxiv.org/abs/2512.05578)
*Zheng Sun,Zhipeng Dong,Shixiong Wang,Zhongyi Chu,Fei Chen*

Main category: cs.RO

TL;DR: 本研究提出了一种新颖的高光谱成像引导机器人抓取系统，显著提高了物体识别及抓取能力，展示了该技术的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 探索高光谱成像与机器人抓取系统的集成，以提高物体识别和分析的准确性，克服当前部署复杂性和成本高的问题。

Method: 设计了一种新颖的高光谱成像引导机器人抓取系统，包括PRISM机制和SpectralGrasp框架，前者用于高精度成像，后者基于高光谱图像生成抓取策略。

Result: 该系统在纺织品识别方面明显优于人类表现，同时在排序成功率上超过基于RGB的方法，并通过一系列比较实验验证了其有效性。

Conclusion: 研究表明，将高光谱成像与机器人抓取系统相结合，有助于在复杂动态环境中增强物体识别和抓取能力。

Abstract: Hyperspectral imaging is an advanced technique for precisely identifying and analyzing materials or objects. However, its integration with robotic grasping systems has so far been explored due to the deployment complexities and prohibitive costs. Within this paper, we introduce a novel hyperspectral imaging-guided robotic grasping system. The system consists of PRISM (Polyhedral Reflective Imaging Scanning Mechanism) and the SpectralGrasp framework. PRISM is designed to enable high-precision, distortion-free hyperspectral imaging while simplifying system integration and costs. SpectralGrasp generates robotic grasping strategies by effectively leveraging both the spatial and spectral information from hyperspectral images. The proposed system demonstrates substantial improvements in both textile recognition compared to human performance and sorting success rate compared to RGB-based methods. Additionally, a series of comparative experiments further validates the effectiveness of our system. The study highlights the potential benefits of integrating hyperspectral imaging with robotic grasping systems, showcasing enhanced recognition and grasping capabilities in complex and dynamic environments. The project is available at: https://zainzh.github.io/PRISM.

</details>


### [10] [A Comprehensive Framework for Automated Quality Control in the Automotive Industry](https://arxiv.org/abs/2512.05579)
*Panagiota Moraiti,Panagiotis Giannikos,Athanasios Mastrogeorgiou,Panagiotis Mavridis,Linghao Zhou,Panagiotis Chatzakos*

Main category: cs.RO

TL;DR: 本文提出了一种先进的机器人检查解决方案，用于自动化汽车制造中的质量控制，集成协作机器人和高分辨率相机，采用深度学习模型和图像处理技术以提高缺陷检测的准确性。


<details>
  <summary>Details</summary>
Motivation: 随着汽车制造业对质量控制的要求不断提高，自动化解决方案可以提高检测效率和准确性，减少人为错误。

Method: 该方案结合了一对协作机器人和高分辨率相机，通过YOLO11n深度学习模型和一系列图像处理技术进行缺陷检测。

Result: 实验结果显示该系统在不同缺陷上表现出实时高精度，且有效降低了误检率。

Conclusion: 该方案展现了在汽车制造中质量控制自动化的潜力和灵活性，能够适应不同的生产环境。

Abstract: This paper presents a cutting-edge robotic inspection solution designed to automate quality control in automotive manufacturing. The system integrates a pair of collaborative robots, each equipped with a high-resolution camera-based vision system to accurately detect and localize surface and thread defects in aluminum high-pressure die casting (HPDC) automotive components. In addition, specialized lenses and optimized lighting configurations are employed to ensure consistent and high-quality image acquisition. The YOLO11n deep learning model is utilized, incorporating additional enhancements such as image slicing, ensemble learning, and bounding-box merging to significantly improve performance and minimize false detections. Furthermore, image processing techniques are applied to estimate the extent of the detected defects. Experimental results demonstrate real-time performance with high accuracy across a wide variety of defects, while minimizing false detections. The proposed solution is promising and highly scalable, providing the flexibility to adapt to various production environments and meet the evolving demands of the automotive industry.

</details>


### [11] [An Integrated System for WEEE Sorting Employing X-ray Imaging, AI-based Object Detection and Segmentation, and Delta Robot Manipulation](https://arxiv.org/abs/2512.05599)
*Panagiotis Giannikos,Lampis Papakostas,Evangelos Katralis,Panagiotis Mavridis,George Chryssinas,Myrto Inglezou,Nikolaos Panagopoulos,Antonis Porichis,Athanasios Mastrogeorgiou,Panagiotis Chatzakos*

Main category: cs.RO

TL;DR: 本文提出了一种创新的电池回收方法，结合了双能量X光成像系统与智能检测算法，能够有效识别与提取电子废弃物中的电池。


<details>
  <summary>Details</summary>
Motivation: 随着电池使用量的急剧增长，电池回收变得越来越重要，尤其是在不当处理可能造成安全隐患的背景下。

Method: 该方法利用双能量X射线成像技术与YOLO和U-Net模型相结合，实现对电池含有物品的高精度检测和分割，同时使用Delta机器人进行选择性提取。

Result: 在NVIDIA Isaac Sim中开发的逼真仿真环境和实际设置中验证了方法的有效性。

Conclusion: 我们提出的集成双能量成像系统与先进预处理算法的电池回收方案能够在各种电子废弃物中有效识别和分类电池，推动电池回收的自动化进程。

Abstract: Battery recycling is becoming increasingly critical due to the rapid growth in battery usage and the limited availability of natural resources. Moreover, as battery energy densities continue to rise, improper handling during recycling poses significant safety hazards, including potential fires at recycling facilities. Numerous systems have been proposed for battery detection and removal from WEEE recycling lines, including X-ray and RGB-based visual inspection methods, typically driven by AI-powered object detection models (e.g., Mask R-CNN, YOLO, ResNets). Despite advances in optimizing detection techniques and model modifications, a fully autonomous solution capable of accurately identifying and sorting batteries across diverse WEEEs types has yet to be realized. In response to these challenges, we present our novel approach which integrates a specialized X-ray transmission dual energy imaging subsystem with advanced pre-processing algorithms, enabling high-contrast image reconstruction for effective differentiation of dense and thin materials in WEEE. Devices move along a conveyor belt through a high-resolution X-ray imaging system, where YOLO and U-Net models precisely detect and segment battery-containing items. An intelligent tracking and position estimation algorithm then guides a Delta robot equipped with a suction gripper to selectively extract and properly discard the targeted devices. The approach is validated in a photorealistic simulation environment developed in NVIDIA Isaac Sim and on the real setup.

</details>


### [12] [Scenario-aware Uncertainty Quantification for Trajectory Prediction with Statistical Guarantees](https://arxiv.org/abs/2512.05682)
*Yiming Shu,Jiahui Xu,Linghuan Kong,Fangni Zhang,Guodong Yin,Chen Sun*

Main category: cs.RO

TL;DR: 提出一种新框架，通过关键点识别和场景分析来量化轨迹预测的不确定性和可靠性，以增强自主驾驶的安全性。


<details>
  <summary>Details</summary>
Motivation: 自主驾驶系统中的安全性要求对轨迹预测的不确定性进行可靠的量化，但现有深度学习预测器缺乏适应多样化真实场景的不确定性感知框架。

Method: 通过将预测轨迹和真实轨迹映射到Frenet坐标系下的参考路径上，并使用CopulaCPTS进行不确定性测量，结合均值误差和校准的置信区间构建不同场景的可靠性模型。

Result: 本研究提出了一种新颖的场景感知不确定性量化框架，通过这一框架，预测的轨迹被附加了预测区间和可靠性评估。

Conclusion: 该框架在不同驾驶场景中有效地实现了不确定性量化和可靠性评估，增强了自主驾驶系统的安全性。

Abstract: Reliable uncertainty quantification in trajectory prediction is crucial for safety-critical autonomous driving systems, yet existing deep learning predictors lack uncertainty-aware frameworks adaptable to heterogeneous real-world scenarios. To bridge this gap, we propose a novel scenario-aware uncertainty quantification framework to provide the predicted trajectories with prediction intervals and reliability assessment. To begin with, predicted trajectories from the trained predictor and their ground truth are projected onto the map-derived reference routes within the Frenet coordinate system. We then employ CopulaCPTS as the conformal calibration method to generate temporal prediction intervals for distinct scenarios as the uncertainty measure. Building upon this, within the proposed trajectory reliability discriminator (TRD), mean error and calibrated confidence intervals are synergistically analyzed to establish reliability models for different scenarios. Subsequently, the risk-aware discriminator leverages a joint risk model that integrates longitudinal and lateral prediction intervals within the Frenet coordinate to identify critical points. This enables segmentation of trajectories into reliable and unreliable segments, holding the advantage of informing downstream planning modules with actionable reliability results. We evaluated our framework using the real-world nuPlan dataset, demonstrating its effectiveness in scenario-aware uncertainty quantification and reliability assessment across diverse driving contexts.

</details>


### [13] [HiMoE-VLA: Hierarchical Mixture-of-Experts for Generalist Vision-Language-Action Policies](https://arxiv.org/abs/2512.05693)
*Zhiying Du,Bei Liu,Yaobo Liang,Yichao Shen,Haidong Cao,Xiangyu Zheng,Zhiyuan Feng,Zuxuan Wu,Jiaolong Yang,Yu-Gang Jiang*

Main category: cs.RO

TL;DR: 提出了一种新的视觉-语言-动作框架HiMoE-VLA，旨在处理多样性的机器人数据，缓解现有方法在异质性上的不足。


<details>
  <summary>Details</summary>
Motivation: 基础模型对于具身智能的发展依赖于大规模、高质量的机器人示范数据，而现有方法无法有效处理数据的异质性，影响了其在新环境下的性能。

Method: 提出了层次混合专家（HiMoE）架构的动作模块，适应性处理多层次的异质性，将其逐步抽象为共享的知识表征。

Result: 通过大量实验，HiMoE-VLA在模拟基准和实际机器人平台上相较于现有基准模型表现出一致的性能提升。

Conclusion: HiMoE-VLA在多样的机器人和动作空间中实现了更高的准确性和强健的泛化能力。

Abstract: The development of foundation models for embodied intelligence critically depends on access to large-scale, high-quality robot demonstration data. Recent approaches have sought to address this challenge by training on large collections of heterogeneous robotic datasets. However, unlike vision or language data, robotic demonstrations exhibit substantial heterogeneity across embodiments and action spaces as well as other prominent variations such as senor configurations and action control frequencies. The lack of explicit designs for handling such heterogeneity causes existing methods to struggle with integrating diverse factors, thereby limiting their generalization and leading to degraded performance when transferred to new settings. In this paper, we present HiMoE-VLA, a novel vision-language-action (VLA) framework tailored to effectively handle diverse robotic data with heterogeneity. Specifically, we introduce a Hierarchical Mixture-of-Experts (HiMoE) architecture for the action module which adaptively handles multiple sources of heterogeneity across layers and gradually abstracts them into shared knowledge representations. Through extensive experimentation with simulation benchmarks and real-world robotic platforms, HiMoE-VLA demonstrates a consistent performance boost over existing VLA baselines, achieving higher accuracy and robust generalization across diverse robots and action spaces. The code and models are publicly available at https://github.com/ZhiyingDu/HiMoE-VLA.

</details>


### [14] [Bayesian Active Inference for Intelligent UAV Anti-Jamming and Adaptive Trajectory Planning](https://arxiv.org/abs/2512.05711)
*Ali Krayani,Seyedeh Fatemeh Sadati,Lucio Marcenaro,Carlo Regazzoni*

Main category: cs.RO

TL;DR: 提出了一种基于分层轨迹规划的框架，使无人机能够在对抗干扰环境中高效运行。


<details>
  <summary>Details</summary>
Motivation: 在对抗性干扰条件下，无人机的轨迹规划需要更高的灵活性和适应性，以确保任务的成功完成。

Method: 利用贝叶斯主动推理，结合专家生成的示范和概率生成建模，进行高层符号规划和低层运动策略的编码，进行在线推理以适应干扰条件。

Result: 仿真结果显示，该方法接近专家性能，显著减少了通信干扰和任务成本，比无模型强化学习的基线方法更具优势。

Conclusion: 提出的框架在动态环境中保持了强大的泛化能力，证明其在无人机轨迹规划中的潜力。

Abstract: This paper proposes a hierarchical trajectory planning framework for UAVs operating under adversarial jamming conditions. Leveraging Bayesian Active Inference, the approach combines expert-generated demonstrations with probabilistic generative modeling to encode high-level symbolic planning, low-level motion policies, and wireless signal feedback. During deployment, the UAV performs online inference to anticipate interference, localize jammers, and adapt its trajectory accordingly, without prior knowledge of jammer locations. Simulation results demonstrate that the proposed method achieves near-expert performance, significantly reducing communication interference and mission cost compared to model-free reinforcement learning baselines, while maintaining robust generalization in dynamic environments.

</details>


### [15] [3D Path Planning for Robot-assisted Vertebroplasty from Arbitrary Bi-plane X-ray via Differentiable Rendering](https://arxiv.org/abs/2512.05803)
*Blanca Inigo,Benjamin D. Killeen,Rebecca Choi,Michelle Song,Ali Uneri,Majid Khan,Christopher Bailey,Axel Krieger,Mathias Unberath*

Main category: cs.RO

TL;DR: 本文提出了一种基于可微渲染的框架，通过双平面2D X光图像实现了CT-free的3D路径规划，经过验证表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 机器人人工系统正在通过提高准确性和最小化辐射暴露来转变图像引导干预。然而，在手术路径规划中，通常需要将术中2D图像与术前3D CT扫描进行配准，这一过程既繁琐又成本高昂，特别是在不常规进行术前CT扫描的脊柱骨水泥注射等手术中。

Method: 提出了一种基于可微渲染的框架，利用双平面2D X光图像进行3D经椎弓根路径规划，集成了由统计形状模型（SSM）生成的椎骨图谱，并使用学习到的相似性损失动态调整SSM的形状和姿态。

Result: 在两个阶段评估了该框架：第一，通过正交X光进行椎骨重建；第二，通过临床医生参与的路径规划使用任意视角的X光。结果表明，在重建指标上（DICE: 0.75 vs. 0.65）表现优于归一化互相关基线，并且在与顶尖模型ReVerteR的比较中表现相当（DICE: 0.77），同时对任意视角保持泛化。双侧规划的成功率达到了82%（合成数据）和75%（尸体数据），超过了2D到3D基线的66%和31%。

Conclusion: 我们的框架促进了无CT的多功能3D路径规划，能够有效适应真实世界中的成像多样性。

Abstract: Robotic systems are transforming image-guided interventions by enhancing accuracy and minimizing radiation exposure. A significant challenge in robotic assistance lies in surgical path planning, which often relies on the registration of intraoperative 2D images with preoperative 3D CT scans. This requirement can be burdensome and costly, particularly in procedures like vertebroplasty, where preoperative CT scans are not routinely performed. To address this issue, we introduce a differentiable rendering-based framework for 3D transpedicular path planning utilizing bi-planar 2D X-rays. Our method integrates differentiable rendering with a vertebral atlas generated through a Statistical Shape Model (SSM) and employs a learned similarity loss to refine the SSM shape and pose dynamically, independent of fixed imaging geometries. We evaluated our framework in two stages: first, through vertebral reconstruction from orthogonal X-rays for benchmarking, and second, via clinician-in-the-loop path planning using arbitrary-view X-rays. Our results indicate that our method outperformed a normalized cross-correlation baseline in reconstruction metrics (DICE: 0.75 vs. 0.65) and achieved comparable performance to the state-of-the-art model ReVerteR (DICE: 0.77), while maintaining generalization to arbitrary views. Success rates for bipedicular planning reached 82% with synthetic data and 75% with cadaver data, exceeding the 66% and 31% rates of a 2D-to-3D baseline, respectively. In conclusion, our framework facilitates versatile, CT-free 3D path planning for robot-assisted vertebroplasty, effectively accommodating real-world imaging diversity without the need for preoperative CT scans.

</details>


### [16] [Global stability of vehicle-with-driver dynamics via Sum-of-Squares programming](https://arxiv.org/abs/2512.05806)
*Martino Gulisano,Marco Gabiccini*

Main category: cs.RO

TL;DR: 该研究通过SOS技术优化Lyapunov函数，估计七状态车辆系统的安全不变子集，能够有效实现实时安全评估。


<details>
  <summary>Details</summary>
Motivation: 旨在确保车辆系统在驾驶过程中的安全性，并通过优化手段改进安全集的计算。

Method: 通过原始的Sum-of-Squares(SOS)迭代程序优化Lyapunov函数来计算安全集。

Result: 在两个状态的基准测试中，该方法准确地恢复了预定的安全区域，并在非线性车辆模型与其操作范围约束下，应用于不同驾驶场景的安全集评估。

Conclusion: SOS技术能够高效提供基于Lyapunov的安全区域，支持实时安全评估的潜力。

Abstract: This work estimates safe invariant subsets of the Region of Attraction (ROA) for a seven-state vehicle-with-driver system, capturing both asymptotic stability and the influence of state-safety bounds along the system trajectory. Safe sets are computed by optimizing Lyapunov functions through an original iterative Sum-of-Squares (SOS) procedure. The method is first demonstrated on a two-state benchmark, where it accurately recovers a prescribed safe region as the 1-level set of a polynomial Lyapunov function. We then describe the distinguishing characteristics of the studied vehicle-with-driver system: the control dynamics mimic human driver behavior through a delayed preview-tracking model that, with suitable parameter choices, can also emulate digital controllers. To enable SOS optimization, a polynomial approximation of the nonlinear vehicle model is derived, together with its operating-envelope constraints. The framework is then applied to understeering and oversteering scenarios, and the estimated safe sets are compared with reference boundaries obtained from exhaustive simulations. The results show that SOS techniques can efficiently deliver Lyapunov-defined safe regions, supporting their potential use for real-time safety assessment, for example as a supervisory layer for active vehicle control.

</details>


### [17] [Real-time Remote Tracking and Autonomous Planning for Whale Rendezvous using Robots](https://arxiv.org/abs/2512.05808)
*Sushmita Bhattacharya,Ninad Jadhav,Hammad Izhar,Karen Li,Kevin George,Robert Wood,Stephanie Gil*

Main category: cs.RO

TL;DR: 介绍了一种使用无人机进行实时抹香鲸海上会合的系统，通过模型基础的强化学习结合传感器数据和鲸鱼潜水模型来指导导航决策。


<details>
  <summary>Details</summary>
Motivation: 为了解决海洋中抹香鲸的实时追踪和会合问题，提升无人机与鲸鱼之间的交互与导航能力。

Method: 采用基于模型的强化学习，将现场传感器数据与鲸鱼潜水模型相结合，解决实时声学跟踪、分布式通信以及信号处理等挑战。

Result: 在多米尼加海域与抹香鲸成功进行海上会合，并在陆地上进行硬件实验，以及利用海洋生物学家的观察数据进行的模拟实验。

Conclusion: 该系统有效实现了无人机与抹香鲸的实时会合，为未来海洋生物研究和自动化技术提供了新的可能性。

Abstract: We introduce a system for real-time sperm whale rendezvous at sea using an autonomous uncrewed aerial vehicle. Our system employs model-based reinforcement learning that combines in situ sensor data with an empirical whale dive model to guide navigation decisions. Key challenges include (i) real-time acoustic tracking in the presence of multiple whales, (ii) distributed communication and decision-making for robot deployments, and (iii) on-board signal processing and long-range detection from fish-trackers. We evaluate our system by conducting rendezvous with sperm whales at sea in Dominica, performing hardware experiments on land, and running simulations using whale trajectories interpolated from marine biologists' surface observations.

</details>


### [18] [Toward Efficient and Robust Behavior Models for Multi-Agent Driving Simulation](https://arxiv.org/abs/2512.05812)
*Fabian Konstantinidis,Moritz Sackmann,Ulrich Hofmann,Christoph Stiller*

Main category: cs.RO

TL;DR: 优化交通参与者的行为模型，通过采用实例中心场景表示和对称上下文编码器，提升了多智能体驾驶模拟的效率与现实性。


<details>
  <summary>Details</summary>
Motivation: 在可扩展的多智能体驾驶模拟中，需要既现实又计算效率高的行为模型，以增强交通参与者的交互模拟能力。

Method: 引入实例中心场景表示来优化每个交通参与者和地图元素的行为模型，利用查询中心对称上下文编码器与相对位置编码建模交互，并使用对抗逆强化学习学习行为模型。

Result: 该方法以令牌数量的增加为基础，表现出高效的扩展性，显著降低了训练和推理时间，同时在位置准确性和鲁棒性上超过了多个基于代理的基线.

Conclusion: 该方法在训练和推理时间上显著缩短，同时在位置准确性和鲁棒性方面超越多个基于代理的基准。

Abstract: Scalable multi-agent driving simulation requires behavior models that are both realistic and computationally efficient. We address this by optimizing the behavior model that controls individual traffic participants. To improve efficiency, we adopt an instance-centric scene representation, where each traffic participant and map element is modeled in its own local coordinate frame. This design enables efficient, viewpoint-invariant scene encoding and allows static map tokens to be reused across simulation steps. To model interactions, we employ a query-centric symmetric context encoder with relative positional encodings between local frames. We use Adversarial Inverse Reinforcement Learning to learn the behavior model and propose an adaptive reward transformation that automatically balances robustness and realism during training. Experiments demonstrate that our approach scales efficiently with the number of tokens, significantly reducing training and inference times, while outperforming several agent-centric baselines in terms of positional accuracy and robustness.

</details>


### [19] [Optimal Safety-Aware Scheduling for Multi-Agent Aerial 3D Printing with Utility Maximization under Dependency Constraints](https://arxiv.org/abs/2512.05815)
*Marios-Nektarios Stamatopoulos,Shridhar Velhal,Avijit Banerjee,George Nikolakopoulos*

Main category: cs.RO

TL;DR: 本文提出了一种新颖的框架，旨在实现多架无人机在空中3D打印中的无冲突协作，优化任务分配和调度，并通过动态选择起始时间和位置解决潜在冲突。


<details>
  <summary>Details</summary>
Motivation: 为了实现多架无人机在空中3D打印过程中的无冲突协作，提出一种新的协调和任务规划框架。

Method: 通过建立一个优化问题，该问题考虑了构建任务的子任务分配、无人机的团队、有限的体积和电池，生成一个最优的任务分配和调度计划。

Result: 提出的框架有效地解决了无人机在同时操作中可能发生的冲突，并通过动态选择每个任务的起始时间和位置，实现了无碰撞的并行执行。

Conclusion: 框架在Gazebo仿真环境中的有效性得到了验证，能够在满足物料和电池约束的同时协调打印任务。

Abstract: This article presents a novel coordination and task-planning framework to enable the simultaneous conflict-free collaboration of multiple unmanned aerial vehicles (UAVs) for aerial 3D printing. The proposed framework formulates an optimization problem that takes a construction mission divided into sub-tasks and a team of autonomous UAVs, along with limited volume and battery. It generates an optimal mission plan comprising task assignments and scheduling while accounting for task dependencies arising from the geometric and structural requirements of the 3D design, inter-UAV safety constraints, material usage, and total flight time of each UAV. The potential conflicts occurring during the simultaneous operation of the UAVs are addressed at a segment level by dynamically selecting the starting time and location of each task to guarantee collision-free parallel execution. An importance prioritization is proposed to accelerate the computation by guiding the solution toward more important tasks. Additionally, a utility maximization formulation is proposed to dynamically determine the optimal number of UAVs required for a given mission, balancing the trade-off between minimizing makespan and the deployment of excess agents. The proposed framework's effectiveness is evaluated through a Gazebo-based simulation setup, where agents are coordinated by a mission control module allocating the printing tasks based on the generated optimal scheduling plan while remaining within the material and battery constraints of each UAV.

</details>


### [20] [Physically-Based Simulation of Automotive LiDAR](https://arxiv.org/abs/2512.05932)
*L. Dudzik,M. Roschani,A. Sielemann,K. Trampert,J. Ziehn,J. Beyerer,C. Neumann*

Main category: cs.RO

TL;DR: 该论文提出了一种用于模拟汽车飞行时间（ToF）LiDAR的分析模型，考虑了多种因素，并通过光学实验确定模型参数。


<details>
  <summary>Details</summary>
Motivation: 汽车LiDAR技术在自动驾驶中的应用日益重要，因此有必要对其性能进行准确建模和模拟。

Method: 模型采用近红外领域的物理基础渲染（PBR），假设单次反射和自反射，考虑传感器发射的光以及环境光干扰，通过光学实验获取模型参数。

Result: 对两个不同的汽车LiDAR系统进行校准和测试，成功提取了相关模型参数。

Conclusion: 所提出的模型可有效模拟汽车LiDAR的工作情况，为进一步的研究和开发提供了基础。

Abstract: We present an analytic model for simulating automotive time-of-flight (ToF) LiDAR that includes blooming, echo pulse width, and ambient light, along with steps to determine model parameters systematically through optical laboratory measurements. The model uses physically based rendering (PBR) in the near-infrared domain. It assumes single-bounce reflections and retroreflections over rasterized rendered images from shading or ray tracing, including light emitted from the sensor as well as stray light from other, non-correlated sources such as sunlight. Beams from the sensor and sensitivity of the receiving diodes are modeled with flexible beam steering patterns and with non-vanishing diameter.
  Different (all non-real time) computational approaches can be chosen based on system properties, computing capabilities, and desired output properties.
  Model parameters include system-specific properties, namely the physical spread of the LiDAR beam, combined with the sensitivity of the receiving diode; the intensity of the emitted light; the conversion between the intensity of reflected light and the echo pulse width; and scenario parameters such as environment lighting, positioning, and surface properties of the target(s) in the relevant infrared domain. System-specific properties of the model are determined from laboratory measurements of the photometric luminance on different target surfaces aligned with a goniometer at 0.01° resolution, which marks the best available resolution for measuring the beam pattern.
  The approach is calibrated for and tested on two automotive LiDAR systems, the Valeo Scala Gen. 2 and the Blickfeld Cube 1. Both systems differ notably in their properties and available interfaces, but the relevant model parameters could be extracted successfully.

</details>


### [21] [Correspondence-Oriented Imitation Learning: Flexible Visuomotor Control with 3D Conditioning](https://arxiv.org/abs/2512.05953)
*Yunhao Cao,Zubin Bhaumik,Jessie Jia,Xingyi He,Kuan Fang*

Main category: cs.RO

TL;DR: COIL是一种新颖的条件策略学习框架，支持可变时空颗粒度的任务表示，利用自监督训练和时空注意机制实现了优秀的操控性能。


<details>
  <summary>Details</summary>
Motivation: 旨在为视觉运动控制提供一种灵活而高效的方法，通过自适应的任务表示来满足不同用户需求和任务要求。

Method: 提出了一种条件策略学习框架，名为COIL，专注于三维视觉运动控制，支持灵活的任务表示。

Result: 通过设计一个具有时空注意机制的条件策略，有效融合多种输入模态的信息。

Conclusion: COIL在稀疏和密集规格下的真实世界操控任务中，相比于之前的方法显示了更优的性能，并具备跨任务、物体和运动模式的泛化能力。

Abstract: We introduce Correspondence-Oriented Imitation Learning (COIL), a conditional policy learning framework for visuomotor control with a flexible task representation in 3D. At the core of our approach, each task is defined by the intended motion of keypoints selected on objects in the scene. Instead of assuming a fixed number of keypoints or uniformly spaced time intervals, COIL supports task specifications with variable spatial and temporal granularity, adapting to different user intents and task requirements. To robustly ground this correspondence-oriented task representation into actions, we design a conditional policy with a spatio-temporal attention mechanism that effectively fuses information across multiple input modalities. The policy is trained via a scalable self-supervised pipeline using demonstrations collected in simulation, with correspondence labels automatically generated in hindsight. COIL generalizes across tasks, objects, and motion patterns, achieving superior performance compared to prior methods on real-world manipulation tasks under both sparse and dense specifications.

</details>


### [22] [SIMPACT: Simulation-Enabled Action Planning using Vision-Language Models](https://arxiv.org/abs/2512.05955)
*Haowen Liu,Shaoxiong Yao,Haonan Chen,Jiawei Gao,Jiayuan Mao,Jia-Bin Huang,Yilun Du*

Main category: cs.RO

TL;DR: SIMPACT通过在测试时引入物理模拟，使视觉语言模型具备物理推理能力，并在机器人操作任务中达到最新效果。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型(VLM)在常识和语义推理方面表现出色，但对物理动态的理解存在缺陷，这限制了其在精细化机器人操作任务中的应用。

Method: 提出了一种名为SIMPACT的框架，该框架在测试时通过模拟环节为VLM提供物理推理能力，无需额外训练。

Result: SIMPACT能够从单一RGB-D观察构建物理模拟，使VLM提出合理的行动提议，观察模拟结果，并迭代地优化推理。

Conclusion: 通过将物理理解与高效模拟嵌入VLM推理中，我们的方法在五个具有挑战性的真实世界操作任务中表现出色，展示了朝向可推广的具身智能的潜力。

Abstract: Vision-Language Models (VLMs) exhibit remarkable common-sense and semantic reasoning capabilities. However, they lack a grounded understanding of physical dynamics. This limitation arises from training VLMs on static internet-scale visual-language data that contain no causal interactions or action-conditioned changes. Consequently, it remains challenging to leverage VLMs for fine-grained robotic manipulation tasks that require physical understanding, reasoning, and corresponding action planning. To overcome this, we present SIMPACT, a test-time, SIMulation-enabled ACTion Planning framework that equips VLMs with physical reasoning through simulation-in-the-loop world modeling, without requiring any additional training. From a single RGB-D observation, SIMPACT efficiently constructs physics simulations, enabling the VLM to propose informed actions, observe simulated rollouts, and iteratively refine its reasoning. By integrating language reasoning with physics prediction, our simulation-enabled VLM can understand contact dynamics and action outcomes in a physically grounded way. Our method demonstrates state-of-the-art performance on five challenging, real-world rigid-body and deformable manipulation tasks that require fine-grained physical reasoning, outperforming existing general-purpose robotic manipulation models. Our results demonstrate that embedding physics understanding via efficient simulation into VLM reasoning at test time offers a promising path towards generalizable embodied intelligence. Project webpage can be found at https://simpact-bot.github.io

</details>


### [23] [Training-Time Action Conditioning for Efficient Real-Time Chunking](https://arxiv.org/abs/2512.05964)
*Kevin Black,Allen Z. Ren,Michael Equi,Sergey Levine*

Main category: cs.RO

TL;DR: 提出训练时RTC代替推理时RTC，能降低计算开销，同时确保任务性能和速度不变。


<details>
  <summary>Details</summary>
Motivation: 希望提高视语言动作模型在实时控制中的效率，并减少推理延迟带来的计算开销。

Method: 提出了一种新的训练时实时分块方法，模拟推理延迟并直接以动作前缀为条件，而无需修改模型架构或机器人运行时。

Result: 在模拟实验中，训练时RTC在更长的推理延迟情况下优于推理时RTC；在真实实验中，训练时RTC在任务性能和速度方面与推理时RTC持平，同时计算成本更低。

Conclusion: 训练时动作条件化可以作为推理时内插的实用替代方案，适用于实时机器人控制。

Abstract: Real-time chunking (RTC) enables vision-language-action models (VLAs) to generate smooth, reactive robot trajectories by asynchronously predicting action chunks and conditioning on previously committed actions via inference-time inpainting. However, this inpainting method introduces computational overhead that increases inference latency. In this work, we propose a simple alternative: simulating inference delay at training time and conditioning on action prefixes directly, eliminating any inference-time overhead. Our method requires no modifications to the model architecture or robot runtime, and can be implemented with only a few additional lines of code. In simulated experiments, we find that training-time RTC outperforms inference-time RTC at higher inference delays. In real-world experiments on box building and espresso making tasks with the $π_{0.6}$ VLA, we demonstrate that training-time RTC maintains both task performance and speed parity with inference-time RTC while being computationally cheaper. Our results suggest that training-time action conditioning is a practical drop-in replacement for inference-time inpainting in real-time robot control.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [24] [Systematically Evaluating Equivalent Purpose for Digital Maps](https://arxiv.org/abs/2512.05310)
*Brandon Biggs,David Sloan,Brett Oppegaard,Nicholas A. Giudice,James M. Coughlan,Bruce N. Walker*

Main category: cs.HC

TL;DR: 提出一套系统框架（MEP Framework）评估数字地图的可及性，尤其是为视障人士提供等效信息，以增强其地图依赖的参与度。


<details>
  <summary>Details</summary>
Motivation: 数字地图对盲人和低视力人士（BLVIs）仍然不够可及，尽管全球有相关立法遵循Web内容无障碍指南（WCAG）。

Method: 提出地图等效目的框架（MEP Framework），通过三个项目（一般化、空间信息和空间关系）定义目的，并建立15个可测量标准评估等效信息的传达。

Result: 通过所提出的MEP Framework评估了八种文本地图表示，与视觉地图基准对比，发现传统方法如表格和逐步指引不符合标准，而音频地图、多个用户域（MUD）地图及音频描述符合标准。

Conclusion: MEP Framework提供了一种可复制的方法论，以全面评估数字地图的可及性，加强WCAG对‘等效目的’的澄清，并指导合规且可用的地图创建，以支持BLVIs在地图依赖的职业和公民参与中。

Abstract: Digital geographic maps remain largely inaccessible to blind and low-vision individuals (BLVIs), despite global legislation adopting the Web Content Accessibility Guidelines (WCAG). A critical gap exists in defining "equivalent purpose" for maps under WCAG Success Criterion 1.1.1, which requires that non-text content provide a text alternative that serves the "equivalent purpose". This paper proposes a systematic framework for evaluating map accessibility, called the Map Equivalent-Purpose Framework (MEP Framework), defining purpose through three items (Generalized, Spatial Information, and Spatial Relationships), and establishing 15 measurable criteria for equivalent information communication. Eight text map representations were evaluated against visual map baselines using the proposed MEP Framework. Results show that legacy methods such as tables and turn-by-turn directions fail to meet the MEP Framework criteria, while Audiom Maps, Multi User Domain (MUD) Maps, and Audio Descriptions meet the criteria. The evaluation highlights the necessity of holistic, systematic approaches to ensure non-visual maps convey all generalized spatial information and relationships present in visual maps. The MEP Framework provides a replicable methodology for comprehensively assessing digital map accessibility, clarifying WCAG's "equivalent purpose", and guiding compliant and usable map creation. Compliant maps will support BLVIs' participation in map-dependent professions and civic engagement.

</details>


### [25] [CLIO: A Tour Guide Robot with Co-speech Actions for Visual Attention Guidance and Enhanced User Engagement](https://arxiv.org/abs/2512.05389)
*Yuxuan Chen,Ian Leong Ting Lo,Bao Guo,Netitorn Kawmali,Chun Kit Chan,Ruoyu Wang,Jia Pan,Lei Yang*

Main category: cs.HC

TL;DR: 	extit{CLIO}是一个通过共语行动引导游客注意力的导览机器人，利用面部追踪、头部运动和激光指针来增强用户参与感，经过用户研究验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 当前音频指南无法有效帮助游客聚焦于展品细节，因此需要一种新方式来提高游客的参与和注意力。

Method: 	extit{CLIO}使用人脸追踪和显性动作（如头部运动、激光指针）来引导游客，同时结合大语言模型（LLM）来协调行为与叙述脚本。

Result: 用户研究表明，	extit{CLIO}的设计能够有效引导游客的视觉注意力，且相比仅有音频指导的系统，参与度显著提升。

Conclusion: 	extit{CLIO}展示了相较于仅提供音频指导的基线系统，能够显著提升游客的参与度和视觉关注引导效果。

Abstract: While audio guides can offer rich information about an exhibit, it is challenging for visitors to focus on specific exhibit details based only on the verbal description. We present \textit{CLIO}, a tour guide robot with co-speech actions to direct visitors' visual attention and thus enhance the overall user engagement in a guided tour. \textit{CLIO} is equipped with designed actions to engage visitors. It builds eye contact with the visitor through tracking a visitor's face and blinking its eyes, or orient their attention by its head movement and laser pointer. We further use a Large Language Model (LLM) to coordinate the designed actions with a given narrative script for exhibition. We conducted a user study to evaluate the \textit{CLIO} system in a mock-up exhibition of historical photographs. We collected feedback from questionnaires and quantitative data from a mobile eye tracker. Experimental results validated that the engaging actions are well designed and demonstrated its efficacy in guiding visual attention of the visitors. It was evidenced that \textit{CLIO} achieved an enhanced engagement compared to the baseline system with only audio guidance.

</details>


### [26] [Simulating Life Paths with Digital Twins: AI-Generated Future Selves Influence Decision-Making and Expand Human Choice](https://arxiv.org/abs/2512.05397)
*Rachel Poonsiriwong,Chayapatr Archiwaranguprok,Constanze Albrecht,Peggy Yin,Nattavudh Powthavee,Hal Hershfield,Monchai Lertsutthiwong,Kavin Winson,Pat Pataranutaporn*

Main category: cs.HC

TL;DR: 研究通过AI数字双胞胎帮助年轻成人进行重大决策，发现不同的选项展示方式对决策有不同影响，同时提升了对选择的意识。


<details>
  <summary>Details</summary>
Motivation: 应对重大的生活转折和高风险决策时，人们往往难以想象未来自我如何接受其选择后果，因此需要新的方法来帮助他们。

Method: 使用随机对照试验的方式，参与者分为不同组别，体验基于面部年龄进展、声音克隆和对话模型的个性化数字化身，以模拟未来生活情境。

Result: 本研究提出使用AI赋能的数字双胞胎来帮助人们更好地应对重大生活决策的后果。这些数字双胞胎模拟了未来生活场景，使个人能够更清晰地进行未来预想，而不是仅仅追求最佳结果。

Conclusion: 结果表明，单一选项的数字双胞胎会导致更多的选择偏向，而平衡的选项展示则能引导参与者双向移动。引入系统生成的第三选项则显著增加了新选择的采用。

Abstract: Major life transitions demand high-stakes decisions, yet people often struggle to imagine how their future selves will live with the consequences. To support this limited capacity for mental time travel, we introduce AI-enabled digital twins that have ``lived through'' simulated life scenarios. Rather than predicting optimal outcomes, these simulations extend prospective cognition by making alternative futures vivid enough to support deliberation without assuming which path is best. We evaluate this idea in a randomized controlled study (N=192) using multimodal synthesis - facial age progression, voice cloning, and large language model dialogue - to create personalized avatars representing participants 30 years forward. Young adults 18 to 28 years old described pending binary decisions and were assigned to guided imagination or one of four avatar conditions: single-option, balanced dual-option, or expanded three-option with a system-generated novel alternative. Results showed asymmetric effects: single-sided avatars increased shifts toward the presented option, while balanced presentation produced movement toward both. Introducing a system-generated third option increased adoption of this new alternative compared to control, suggesting that AI-generated future selves can expand choice by surfacing paths that might otherwise go unnoticed. Participants rated evaluative reasoning and eudaimonic meaning-making as more important than emotional or visual vividness. Perceived persuasiveness and baseline agency predicted decision change. These findings advance understanding of AI-mediated episodic prospection and raise questions about autonomy in AI-augmented decisions.

</details>


### [27] [From Vision to Touch: Bridging Visual and Tactile Principles for Accessible Data Representation](https://arxiv.org/abs/2512.05433)
*Kim Marriott,Matthew Butler,Leona Holloway,Bill Jolley,Bongshin Lee,Bruce Maguire,Danielle Albers Szafir*

Main category: cs.HC

TL;DR: 本研究提出了触觉信息图形的设计框架，旨在明确其相对于文本描述的优势，并为未来研究指明方向。


<details>
  <summary>Details</summary>
Motivation: 探讨触觉图形对盲人和低视力人群的益处，以补充现有的文本描述，填补设计与理解之间的空白。

Method: 提出一个框架，涵盖编码、感知和认知三个方面，研究视觉信息图形的已知益处，并探讨其在触觉信息图形中的适用性。

Result: 建立了触觉优先设计信息图形的初步理论基础，并识别了未来研究的方向。

Conclusion: 触觉图形在展示空间关系方面具有潜在优势，未来的研究应关注其设计和应用。

Abstract: Tactile graphics are widely used to present maps and statistical diagrams to blind and low vision (BLV) people, with accessibility guidelines recommending their use for graphics where spatial relationships are important. Their use is expected to grow with the advent of commodity refreshable tactile displays. However, in stark contrast to visual information graphics, we lack a clear understanding of the benefits that well-designed tactile information graphics offer over text descriptions for BLV people. To address this gap, we introduce a framework considering the three components of encoding, perception and cognition to examine the known benefits for visual information graphics and explore their applicability to tactile information graphics. This work establishes a preliminary theoretical foundation for the tactile-first design of information graphics and identifies future research avenues.

</details>


### [28] [EXR: An Interactive Immersive EHR Visualization in Extended Reality](https://arxiv.org/abs/2512.05438)
*Benoit Marteau,Shaun Q. Y. Tan,Jieru Li,Andrew Hornback,Yishan Zhong,Shaunna Wang,Christian Lowson,Jason Woloff,Joshua M. Pahys,Steven W. Hwang,Coleman Hilton,May D. Wang*

Main category: cs.HC

TL;DR: 本研究设计并实施了一种XR平台，用于沉浸式可视化电子健康记录，集成了EHR数据和医疗成像，能够支持临床决策。


<details>
  <summary>Details</summary>
Motivation: 提升电子健康记录的可视化和交互体验，改善临床决策支持。

Method: 设计和实现一个扩展现实(XR)平台，用于沉浸式、交互式可视化电子健康记录(EHR)

Result: 通过将结构化和非结构化患者数据可视化到共享的3D环境中，实现直观探索和实时协作。

Conclusion: 集成的XR解决方案可以成为下一代临床决策支持工具的基础，先进的数据基础设施可以在交互和空间丰富的环境中直接访问。

Abstract: This paper presents the design and implementation of an Extended Reality (XR) platform for immersive, interactive visualization of Electronic Health Records (EHRs). The system extends beyond conventional 2D interfaces by visualizing both structured and unstructured patient data into a shared 3D environment, enabling intuitive exploration and real-time collaboration. The modular infrastructure integrates FHIR-based EHR data with volumetric medical imaging and AI-generated segmentation, ensuring interoperability with modern healthcare systems. The platform's capabilities are demonstrated using synthetic EHR datasets and computed tomography (CT)-derived spine models processed through an AI-powered segmentation pipeline. This work suggests that such integrated XR solutions could form the foundation for next-generation clinical decision-support tools, where advanced data infrastructures are directly accessible in an interactive and spatially rich environment.

</details>


### [29] [Classification and taxonomy of mobile application usability issues](https://arxiv.org/abs/2512.05450)
*Pawel Weichbroth*

Main category: cs.HC

TL;DR: 本研究通过三角测量策略探索移动应用的可用性问题，提出了16个可用性问题类别及新颖的三层应用-用户-资源分类系统。


<details>
  <summary>Details</summary>
Motivation: 尽管对移动应用可用性测试的研究已有多年，但用户体验的问题仍然零散且未得到充分探索。

Method: 采用两种研究方法（系统性文献综述和访谈）及两种数据来源（学术文献和专家知识），进行可用性问题的探讨。

Result: 提出了包含16个可用性问题类别的目录，以及三层应用-用户-资源（AUR）分类系统，深入分析了可用性问题的根源及其影响方面。

Conclusion: 研究为人机交互领域做出贡献，且为软件供应商提供了改进质量保障程序的建议，进一步研究可集中于开发测量模型以确认变量的关系。

Abstract: Despite years of research on testing the usability of mobile applications, our understanding of the issues their users experience still remains fragmented and underexplored. While most earlier studies has provided interesting insights, they have varying limitations in methodology, input diversity, and depth of analysis. On the contrary, this study employs a triangulation strategy, using two research methods (systematic literature review and interview) and two data sources (scholarly literature and expert knowledge) to explore the traits underlying usability issues. Our study contributes to the field of human-computer interaction (HCI) by presenting a catalog of 16 usability issue categories, enriched with corresponding keywords and extended into a taxonomy, as well as a novel three-tier app-user-resource (AUR) classification system. At the first app level, usability issues arise from user interface design, as well as from efficiency, errors, and operability. At the second user level, they influence cognitive load, effectiveness, ease of use, learnability, memorability, and understandability. At the third resource level, usability issues stem from network quality and hardware, such as battery life, CPU speed, physical device button size and availability, RAM capacity, and screen size. The root cause of the usability issues is the user interface design. Detailed findings and takeaways for both researchers and practitioners are also discussed. Further research could focus on developing a measurement model for the identified variables to confirm the direction and strength of their relationships with perceived usability. Software vendors can also benefit by updating existing quality assurance programs, reviews and audits tools, as well as testing checklists.

</details>


### [30] [When Scaffolding Breaks: Investigating Student Interaction with LLM-Based Writing Support in Real-Time K-12 EFL Classrooms](https://arxiv.org/abs/2512.05506)
*Junho Myung,Hyunseung Lim,Hana Oh,Hyoungwook Jin,Nayeon Kang,So-Yeon Ahn,Hwajung Hong,Alice Oh,Juho Kim*

Main category: cs.HC

TL;DR: 大型语言模型可以支持学生英文写作，但其使用在课堂中面临挑战，如学生动力不足及课堂互动问题。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型在K-12课堂实时教学中的有效性，填补现有研究的空白。

Method: 部署研究

Result: 在韩国一所中学的157名八年级学生中进行的研究发现，LMS在提高语法正确句子写作能力方面有效，但对低能力学生的激励作用有限

Conclusion: LLMs可以改善学生的写作技能，但需注意不同水平学生的需求，并建议优化课堂管理以识别困难学生。

Abstract: Large language models (LLMs) are promising tools for scaffolding students' English writing skills, but their effectiveness in real-time K-12 classrooms remains underexplored. Addressing this gap, our study examines the benefits and limitations of using LLMs as real-time learning support, considering how classroom constraints, such as diverse proficiency levels and limited time, affect their effectiveness. We conducted a deployment study with 157 eighth-grade students in a South Korean middle school English class over six weeks. Our findings reveal that while scaffolding improved students' ability to compose grammatically correct sentences, this step-by-step approach demotivated lower-proficiency students and increased their system reliance. We also observed challenges to classroom dynamics, where extroverted students often dominated the teacher's attention, and the system's assistance made it difficult for teachers to identify struggling students. Based on these findings, we discuss design guidelines for integrating LLMs into real-time writing classes as inclusive educational tools.

</details>


### [31] [User Negotiations of Authenticity, Ownership, and Governance on AI-Generated Video Platforms: Evidence from Sora](https://arxiv.org/abs/2512.05519)
*Bohui Shen,Shrikar Bhatta,Alex Ireebanije,Zexuan Liu,Abhinav Choudhry,Ece Gumusel,Kyrie Zhixuan Zhou*

Main category: cs.HC

TL;DR: 本研究探讨了用户如何在AI生成视频平台Sora上对视频的真实性、创作权以及平台治理进行评估和协商，强调了用户在数字生态系统中的作用。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成视频平台的发展，出现了诸多伦理挑战，了解用户的应对方式有助于改进平台治理和保护用户权益。

Method: 定性内容分析和主题分析

Result: 用户评论分析显示出用户如何理解和应对AI生成视频的多样性和复杂性。

Conclusion: 用户在平台上经历了对真实性、著作权和平台管理的多重协商，影响了未来的治理挑战。

Abstract: As AI-generated video platforms rapidly advance, ethical challenges such as copyright infringement emerge. This study examines how users make sense of AI-generated videos on OpenAI's Sora by conducting a qualitative content analysis of user comments. Through a thematic analysis, we identified four dynamics that characterize how users negotiate authenticity, authorship, and platform governance on Sora. First, users acted as critical evaluators of realism, assessing micro-details such as lighting, shadows, fluid motion, and physics to judge whether AI-generated scenes could plausibly exist. Second, users increasingly shifted from passive viewers to active creators, expressing curiosity about prompts, techniques, and creative processes. Text prompts were perceived as intellectual property, generating concerns about plagiarism and remixing norms. Third, users reported blurred boundaries between real and synthetic media, worried about misinformation, and even questioned the authenticity of other commenters, suspecting bot-generated engagement. Fourth, users contested platform governance: some perceived moderation as inconsistent or opaque, while others shared tactics for evading prompt censorship through misspellings, alternative phrasing, emojis, or other languages. Despite this, many users also enforced ethical norms by discouraging the misuse of real people's images or disrespectful content. Together, these patterns highlighted how AI-mediated platforms complicate notions of reality, creativity, and rule-making in emerging digital ecosystems. Based on the findings, we discuss governance challenges in Sora and how user negotiations inform future platform governance.

</details>


### [32] [Eye of the Beholder: Towards Measuring Visualization Complexity](https://arxiv.org/abs/2512.05536)
*Johannes Ellemose,Niklas Elmqvist*

Main category: cs.HC

TL;DR: 本研究通过众包调查评估了多种可视化的复杂性，并比较了三种评估方法，发现零-shot LLM表现优异。


<details>
  <summary>Details</summary>
Motivation: 虽然有许多设计指南存在，但对特定图形特征如何影响感知视觉复杂性的研究仍然有限。

Method: 进行了一项众包研究，收集了人类对不同可视化的复杂性评级，并评估了三种估计方法：图像分析度量、使用手动编码可视化特征的多线性回归以及使用大型语言模型的自动特征提取。

Result: 图像复杂性度量与人类感知的可视化复杂性无相关性；手动特征编码产生了合理的预测模型但需求较高的努力；零-shot LLM在复杂性评级和特征提取方面表现出色。

Conclusion: 视觉复杂性是主观感受的，但是可以通过零-shot LLM提示有效估计，为评估可视化的复杂性提供了一种可扩展的方法。

Abstract: Constructing expressive and legible visualizations is a key activity for visualization designers. While numerous design guidelines exist, research on how specific graphical features affect perceived visual complexity remains limited. In this paper, we report on a crowdsourced study to collect human ratings of perceived complexity for diverse visualizations. Using these ratings as ground truth, we then evaluated three methods to estimate this perceived complexity: image analysis metrics, multilinear regression using manually coded visualization features, and automated feature extraction using a large language model (LLM). Image complexity metrics showed no correlation with human-perceived visualization complexity. Manual feature coding produced a reasonable predictive model but required substantial effort. In contrast, a zero-shot LLM (GPT-4o mini) demonstrated strong capabilities in both rating complexity and extracting relevant features. Our findings suggest that visualization complexity is truly in the eye of the beholder, yet can be effectively approximated using zero-shot LLM prompting, offering a scalable approach for evaluating the complexity of visualizations. The dataset and code for the study and data analysis can be found at https://osf.io/w85a4/

</details>
