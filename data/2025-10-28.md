<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 73]
- [cs.HC](#cs.HC) [Total: 23]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [A Robotic Stirring Method with Trajectory Optimization and Adaptive Speed Control for Accurate Pest Counting in Water Traps](https://arxiv.org/abs/2510.21732)
*Xumin Gao,Mark Stevens,Grzegorz Cielniak*

Main category: cs.RO

TL;DR: 本研究提出了一种新的自动搅拌方法，以优化虫害计数，特别是针对虫害遮挡问题，结合了轨迹优化和自适应速度控制。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有图像处理和机器学习方法在虫害遮挡情况下的局限性，提升虫害计数的准确性。

Method: 提出了一种基于机器人臂的自动搅拌系统，结合轨迹优化和自适应速度控制进行准确的虫害计数。

Result: 通过研究不同搅拌轨迹对虫害计数性能的影响，确定最优搅拌轨迹，并提出基于计数置信度的闭环控制系统。

Conclusion: 实验结果表明所提出的自适应搅拌方法显著提高了在动态液体环境中虫害计数的精确度。

Abstract: Accurate monitoring of pest population dynamics is crucial for informed
decision-making in precision agriculture. Currently, mainstream image-based
pest counting methods primarily rely on image processing combined with machine
learning or deep learning for pest counting. However, these methods have
limitations and struggle to handle situations involving pest occlusion. To
address this issue, this paper proposed a robotic stirring method with
trajectory optimization and adaptive speed control for accurate pest counting
in water traps. First, we developed an automated stirring system for pest
counting in yellow water traps based on a robotic arm. Stirring alters the
distribution of pests in the yellow water trap, making some of the occluded
individuals visible for detection and counting. Then, we investigated the
impact of different stirring trajectories on pest counting performance and
selected the optimal trajectory for pest counting. Specifically, we designed
six representative stirring trajectories, including circle, square, triangle,
spiral, four small circles, and random lines, for the robotic arm to stir. And
by comparing the overall average counting error and counting confidence of
different stirring trajectories across various pest density scenarios, we
determined the optimal trajectory. Finally, we proposed a counting
confidence-driven closed-loop control system to achieve adaptive-speed
stirring. It uses changes in pest counting confidence between consecutive
frames as feedback to adjust the stirring speed. To the best of our knowledge,
this is the first study dedicated to investigating the effects of different
stirring trajectories on object counting in the dynamic liquid environment and
to implement adaptive-speed stirring for this type of task. Experimental
results show ...

</details>


### [2] [Force-Displacement Profiling for Robot-Assisted Deployment of a Left Atrial Appendage Occluder Using FBG-EM Distal Sensing](https://arxiv.org/abs/2510.21734)
*Giovanni Battista Regazzo,Wim-Alexander Beckers,Xuan Thao Ha,Mouloud Ourak,Johan Vlekken,Emmanuel Vander Poorten*

Main category: cs.RO

TL;DR: 研究旨在通过机器人辅助技术和新型力传感方法，改进左心耳封闭术的实施，提高临床反馈和结果。


<details>
  <summary>Details</summary>
Motivation: 改善左心耳封闭术(LAAC)的实施过程，减少当前方法中的辐射暴露和定位精度的限制。

Method: 利用集成光纤布拉格光栅(FBGs)的力传感送药鞘及电磁跟踪技术，实现对导管顶端位置和互动力的实时测量。

Result: 提出了一种新颖的力位移分析方法，用于实时测量机器人辅助LAAC干预中的互动力和导管尖端位置。

Conclusion: 这种方法有助于在进行LAAC时提供更有效的术中反馈，未来将集中于自动化部署步骤和在动态真实环境中验证传感策略。

Abstract: Atrial fibrillation (AF) increases the risk of thromboembolic events due to
impaired function of the left atrial appendage (LAA). Left atrial appendage
closure (LAAC) is a minimally invasive intervention designed to reduce stroke
risk by sealing the LAA with an expandable occluder device. Current deployment
relies on manual catheter control and imaging modalities like fluoroscopy and
transesophageal echocardiography, which carry limitations including radiation
exposure and limited positioning precision. In this study, we leverage a
previously developed force-sensing delivery sheath integrating fiber Bragg
gratings (FBGs) at the interface between the catheter and the occluder.
Combined with electromagnetic (EM) tracking, this setup enables real-time
measurement of interaction forces and catheter tip position during
robot-assisted LAAC deployment in an anatomical phantom. We present a novel
force-displacement profiling method that characterizes occluder deployment
dynamics and identifies key procedural steps without relying on ionizing
radiation. The force profiles reveal low-magnitude interaction forces,
suggesting minimal mechanical stress on the surrounding anatomy. This approach
shows promise in providing clinicians with enhanced intraoperative feedback,
improving deployment outcome. Future work will focus on automating deployment
steps classification and validating the sensing strategy in dynamic, realistic
environments.

</details>


### [3] [A phase-aware AI car-following model for electric vehicles with adaptive cruise control: Development and validation using real-world data](https://arxiv.org/abs/2510.21735)
*Yuhui Liu,Shian Wang,Ansel Panicker,Kate Embry,Ayana Asanova,Tianyi Li*

Main category: cs.RO

TL;DR: 本研究提出了一种针对电动车的新跟车模型PAAI，结合了AI技术以提高对快速加速和动能回收的适应能力，显著提升了交通仿真中的预测准确性。


<details>
  <summary>Details</summary>
Motivation: 由于电动车在交通中的日益普及，迫切需要一个能准确描述其独特跟车动态的建模框架。

Method: 开发并验证了一种Phase-Aware AI (PAAI) 跟车模型，结合了AI组件以适应不同驾驶阶段。

Result: 通过使用配备自适应巡航控制的车辆的真实轨迹数据进行全面仿真，验证了模型的性能，结果表明PAAI模型在预测准确性上优于传统跟车模型。

Conclusion: PAAI模型在EV行为模拟中显著提高了预测准确性，成为交通仿真的有效工具。

Abstract: Internal combustion engine (ICE) vehicles and electric vehicles (EVs) exhibit
distinct vehicle dynamics. EVs provide rapid acceleration, with electric motors
producing peak power across a wider speed range, and achieve swift deceleration
through regenerative braking. While existing microscopic models effectively
capture the driving behavior of ICE vehicles, a modeling framework that
accurately describes the unique car-following dynamics of EVs is lacking.
Developing such a model is essential given the increasing presence of EVs in
traffic, yet creating an easy-to-use and accurate analytical model remains
challenging.
  To address these gaps, this study develops and validates a Phase-Aware AI
(PAAI) car-following model specifically for EVs. The proposed model enhances
traditional physics-based frameworks with an AI component that recognizes and
adapts to different driving phases, such as rapid acceleration and regenerative
braking. Using real-world trajectory data from vehicles equipped with adaptive
cruise control (ACC), we conduct comprehensive simulations to validate the
model's performance. The numerical results demonstrate that the PAAI model
significantly improves prediction accuracy over traditional car-following
models, providing an effective tool for accurately representing EV behavior in
traffic simulations.

</details>


### [4] [Learn2Drive: A neural network-based framework for socially compliant automated vehicle control](https://arxiv.org/abs/2510.21736)
*Yuhui Liu,Samannita Halder,Shian Wang,Tianyi Li*

Main category: cs.RO

TL;DR: 研究提出了一种新颖的适应巡航控制框架，利用LSTM网络和社会价值取向（SVO）优化自动驾驶车辆与人类车辆之间的互动，旨在提升交通效率和降低能耗。


<details>
  <summary>Details</summary>
Motivation: 现有的自动驾驶控制策略忽视了自动驾驶车辆（AV）与人类驾驶车辆（HV）之间的互动及其对交通流的影响，可能导致拥堵加剧和系统效率降低。

Method: 采用长短期记忆（LSTM）网络和物理约束的适应巡航控制框架

Result: 提出了一种基于神经网络的社会合规AV控制框架，能够考虑AV对HV和交通动态的影响，通过定义效用函数来平衡自身控制目标与交通流的广泛考虑，并在变化的交通条件下进行优化。

Conclusion: 通过控制模式的调整，AV不仅提高了交通流效率，同时也带来了车队中其他车辆能耗的显著增加和平均速度的提升，表明在不同交通条件下优化交通动态的有效性。

Abstract: This study introduces a novel control framework for adaptive cruise control
(ACC) in automated driving, leveraging Long Short-Term Memory (LSTM) networks
and physics-informed constraints. As automated vehicles (AVs) adopt advanced
features like ACC, transportation systems are becoming increasingly intelligent
and efficient. However, existing AV control strategies primarily focus on
optimizing the performance of individual vehicles or platoons, often neglecting
their interactions with human-driven vehicles (HVs) and the broader impact on
traffic flow. This oversight can exacerbate congestion and reduce overall
system efficiency. To address this critical research gap, we propose a neural
network-based, socially compliant AV control framework that incorporates social
value orientation (SVO). This framework enables AVs to account for their
influence on HVs and traffic dynamics. By leveraging AVs as mobile traffic
regulators, the proposed approach promotes adaptive driving behaviors that
reduce congestion, improve traffic efficiency, and lower energy consumption.
Within this framework, we define utility functions for both AVs and HVs, which
are optimized based on the SVO of each AV to balance its own control objectives
with broader traffic flow considerations. Numerical results demonstrate the
effectiveness of the proposed method in adapting to varying traffic conditions,
thereby enhancing system-wide efficiency. Specifically, when the AV's control
mode shifts from prioritizing energy consumption to optimizing traffic flow
efficiency, vehicles in the following platoon experience at least a 58.99%
increase in individual energy consumption alongside at least a 38.39%
improvement in individual average speed, indicating significant enhancements in
traffic dynamics.

</details>


### [5] [Next-Generation LLM for UAV: From Natural Language to Autonomous Flight](https://arxiv.org/abs/2510.21739)
*Liangqi Yuan,Chuhao Deng,Dong-Jun Han,Inseok Hwang,Sabine Brunswicker,Christopher G. Brinton*

Main category: cs.RO

TL;DR: 本论文提出了一种名为NeLV的系统，旨在将大型语言模型集成到多尺度无人机操作中，涵盖了从指令解析到完全自主飞行的全过程，并验证了其在多种操作场景下的可行性。


<details>
  <summary>Details</summary>
Motivation: 尽管现有研究关注小型无人机应用，但缺乏对中长距离无人机系统在实际操作环境中的全面研究，因此有必要探索更大规模无人机平台的整合与应用。

Method: 通过五个关键技术组件构建NeLV系统，分别为指令解析、兴趣点确定、航点生成、可执行轨迹实现和无人机监控。

Result: 通过三个代表性用例展示了系统的可行性，并建立了一个五级自动化分类体系，以指导从现有的指令解析能力到完全自主系统的发展。

Conclusion: 本研究提出的NeLV系统为多尺度无人机操作中的大型语言模型集成提供了全面的演示和自动化路线图，并通过实际案例验证了其可行性。

Abstract: With the rapid advancement of Large Language Models (LLMs), their
capabilities in various automation domains, particularly Unmanned Aerial
Vehicle (UAV) operations, have garnered increasing attention. Current research
remains predominantly constrained to small-scale UAV applications, with most
studies focusing on isolated components such as path planning for toy drones,
while lacking comprehensive investigation of medium- and long-range UAV systems
in real-world operational contexts. Larger UAV platforms introduce distinct
challenges, including stringent requirements for airport-based take-off and
landing procedures, adherence to complex regulatory frameworks, and specialized
operational capabilities with elevated mission expectations. This position
paper presents the Next-Generation LLM for UAV (NeLV) system -- a comprehensive
demonstration and automation roadmap for integrating LLMs into multi-scale UAV
operations. The NeLV system processes natural language instructions to
orchestrate short-, medium-, and long-range UAV missions through five key
technical components: (i) LLM-as-Parser for instruction interpretation, (ii)
Route Planner for Points of Interest (POI) determination, (iii) Path Planner
for waypoint generation, (iv) Control Platform for executable trajectory
implementation, and (v) UAV monitoring. We demonstrate the system's feasibility
through three representative use cases spanning different operational scales:
multi-UAV patrol, multi-POI delivery, and multi-hop relocation. Beyond the
current implementation, we establish a five-level automation taxonomy that
charts the evolution from current LLM-as-Parser capabilities (Level 1) to fully
autonomous LLM-as-Autopilot systems (Level 5), identifying technical
prerequisites and research challenges at each stage.

</details>


### [6] [FORGE-Tree: Diffusion-Forcing Tree Search for Long-Horizon Robot Manipulation](https://arxiv.org/abs/2510.21744)
*Yanjia Huang,Shuo Liu,Sheng Liu,Qingxiao Xu,Mingyang Wu,Xiangbo Gao,Zhengzhong Tu*

Main category: cs.RO

TL;DR: FORGE-Tree是一种改进的控制层，显著提升了机器人长时间操作任务的成功率，特别是在计算预算相似的情况下。


<details>
  <summary>Details</summary>
Motivation: 解决视觉-语言-行动(VLA)政策在长时间操作任务中面临的漂移和暴露偏见，以及无法动态分配计算资源的问题。

Method: 引入FORGE-Tree控制层，结合分段对齐的扩散强迫头和测试时的蒙特卡罗树扩散。

Result: 在LIBERO评估中，FORGE-Tree的成功率相较于原生VLA基线提高了13.4至17.2个百分点。

Conclusion: FORGE-Tree显著提高了机器人操作任务的成功率，并且在计算预算相似的条件下表现稳定。

Abstract: Long-horizon robot manipulation tasks remain challenging for
Vision-Language-Action (VLA) policies due to drift and exposure bias, often
denoise the entire trajectory with fixed hyperparameters, causing small
geometric errors to compound across stages and offering no mechanism to
allocate extra test-time compute where clearances are tight. To address these
challenges, we introduce FORGE-Tree, a plug-in control layer that couples a
stage-aligned Diffusion Forcing (DF) head with test-time Monte Carlo Tree
Diffusion (MCTD). With a frozen VLA encoder, DF aligns timesteps to subtask
stages; during inference we partially denoise only a target segment while
keeping other tokens frozen, turning trajectory refinement into a sequence of
local edits. We then apply Monte Carlo Tree Diffusion to select the next
segment to refine. A scene graph supplies priors for expansion and geometry
relation-aware scoring for rollouts, yielding tree-structured denoising whose
performance scales with search budget while preserving the executed prefix.
Evaluation on LIBERO, FORGE-Tree improves success rate by 13.4 to 17.2 pp over
the native VLA baselines with both OpenVLA and Octo-Base. Gains remain
consistent under comparable compute budgets, especially on long-horizon
variants. Videos available at: https://taco-group.github.io/FORGE-Tree/

</details>


### [7] [Avi: Action from Volumetric Inference](https://arxiv.org/abs/2510.21746)
*Harris Song,Long Le*

Main category: cs.RO

TL;DR: 提出了一种新的3D视觉-语言-动作架构Avi，旨在通过三维感知和空间推理重新构建机器人动作生成问题。


<details>
  <summary>Details</summary>
Motivation: 针对现有模型主要在2D视觉输入上操作的问题，Avi旨在提高对机器人行动生成的理解与能力。

Method: 通过经典几何变换，利用基于3D点云和语言理解的多模态大语言模型来计算机器人动作，而不是依赖于低级别策略学习。

Result: 初步结果表明3D视觉-语言推理能够有效支持机器人系统的稳健性和通用性。

Conclusion: Avi展示了3D视觉-语言推理在构建可扩展且稳健的机器人系统方面的潜力。

Abstract: We propose Avi, a novel 3D Vision-Language-Action (VLA) architecture that
reframes robotic action generation as a problem of 3D perception and spatial
reasoning, rather than low-level policy learning. While existing VLA models
primarily operate on 2D visual inputs and are trained end-to-end on
task-specific action policies, Avi leverages 3D point clouds and
language-grounded scene understanding to compute actions through classical
geometric transformations. Most notably, Avi does not train on previous action
tokens, rather, we build upon a 3D Multi-modal Large Language Model (MLLM) to
generate the next point cloud and explicitly calculate the actions through
classical transformations. This approach enables generalizable behaviors that
are robust to occlusions, camera pose variations, and changes in viewpoint. By
treating the robotic decision-making process as a structured reasoning task
over 3D representations, Avi bridges the gap between high-level language
instructions and low-level actuation without requiring opaque policy learning.
Our preliminary results highlight the potential of 3D vision-language reasoning
as a foundation for scalable, robust robotic systems. Check it out at
https://avi-3drobot.github.io/.

</details>


### [8] [Real-time Mixed-Integer Quadratic Programming for Driving Behavior-Inspired Speed Bump Optimal Trajectory Planning](https://arxiv.org/abs/2510.21751)
*Van Nam Dinh,Van Vy Phan,Thai Son Dang,Van Du Phan,The Anh Mai,Van Chuong Le,Sy Phuong Ho,Dinh Tu Duong,Hung Cuong Ta*

Main category: cs.RO

TL;DR: 本论文提出了一种新颖的轨迹规划方法，利用MIQP和MPC有效处理自动驾驶车辆在速度缓冲带的表现，确保乘客舒适与实时性能。


<details>
  <summary>Details</summary>
Motivation: 旨在解决自动驾驶车辆在面对速度缓冲带时的复杂性，并提高整体道路行驶的流畅性和乘客舒适度。

Method: 采用混合整数二次编程（MIQP）框架与模型预测控制（MPC）相结合进行轨迹规划。

Result: 通过大量城市驾驶环境下的模拟，验证了方法在平滑速度过渡和计算效率方面的有效性。

Conclusion: 本研究的结果表明，提出的方法在保证乘客舒适度的同时，有效应对了速度缓冲带的挑战，并具备实时部署的能力。

Abstract: This paper proposes a novel methodology for trajectory planning in autonomous
vehicles (AVs), addressing the complex challenge of negotiating speed bumps
within a unified Mixed-Integer Quadratic Programming (MIQP) framework. By
leveraging Model Predictive Control (MPC), we develop trajectories that
optimize both the traversal of speed bumps and overall passenger comfort. A key
contribution of this work is the formulation of speed bump handling constraints
that closely emulate human driving behavior, seamlessly integrating these with
broader road navigation requirements. Through extensive simulations in varied
urban driving environments, we demonstrate the efficacy of our approach,
highlighting its ability to ensure smooth speed transitions over speed bumps
while maintaining computational efficiency suitable for real-time deployment.
The method's capability to handle both static road features and dynamic
constraints, alongside expert human driving, represents a significant step
forward in trajectory planning for urban

</details>


### [9] [Taxonomy and Trends in Reinforcement Learning for Robotics and Control Systems: A Structured Review](https://arxiv.org/abs/2510.21758)
*Kumater Ter,RexCharles Donatus,Ore-Ofe Ajayi,Daniel Udekwe*

Main category: cs.RO

TL;DR: 该论文对强化学习及其在机器人和控制系统中的应用进行了全面回顾，强调了现代深度强化学习技术和实际应用中的趋势。


<details>
  <summary>Details</summary>
Motivation: 在动态和不确定环境中，增强智能机器人行为的能力是当前研究的重要任务。

Method: 通过文献综述，总结了强化学习的原则、深度强化学习算法及其在各种机器人应用中的分类。

Result: 该综述强调了现代深度强化学习算法在解决高维持续控制任务中的潜力，并总结了近期研究的技术趋势和设计模式。

Conclusion: 强化学习在自主机器人系统中的作用不断演变，理论进展与实践实施之间的结合至关重要。

Abstract: Reinforcement learning (RL) has become a foundational approach for enabling
intelligent robotic behavior in dynamic and uncertain environments. This work
presents an in-depth review of RL principles, advanced deep reinforcement
learning (DRL) algorithms, and their integration into robotic and control
systems. Beginning with the formalism of Markov Decision Processes (MDPs), the
study outlines essential elements of the agent-environment interaction and
explores core algorithmic strategies including actor-critic methods,
value-based learning, and policy gradients. Emphasis is placed on modern DRL
techniques such as DDPG, TD3, PPO, and SAC, which have shown promise in solving
high-dimensional, continuous control tasks. A structured taxonomy is introduced
to categorize RL applications across domains such as locomotion, manipulation,
multi-agent coordination, and human-robot interaction, along with training
methodologies and deployment readiness levels. The review synthesizes recent
research efforts, highlighting technical trends, design patterns, and the
growing maturity of RL in real-world robotics. Overall, this work aims to
bridge theoretical advances with practical implementations, providing a
consolidated perspective on the evolving role of RL in autonomous robotic
systems.

</details>


### [10] [J-ORA: A Framework and Multimodal Dataset for Japanese Object Identification, Reference, Action Prediction in Robot Perception](https://arxiv.org/abs/2510.21761)
*Jesse Atuhurra,Hidetaka Kamigaito,Taro Watanabe,Koichiro Yoshino*

Main category: cs.RO

TL;DR: J-ORA是一个新的多模态数据集，通过详细的物体属性注释提高机器人在动态环境中的感知能力，评估显示详细属性的引入显著增强了感知性能。


<details>
  <summary>Details</summary>
Motivation: 填补机器人感知领域的空白，提升对物体识别、参考解析和下一步动作预测的能力。

Method: 介绍了一种新颖的多模态数据集J-ORA，专注于机器人感知的详细物体属性注释，特别是在日本人机对话场景中。

Result: 通过与专有和开源视觉语言模型的广泛评估，证明了详细的物体属性能够显著提高多模态感知性能，尽管仍存在专有模型与开源模型之间的差距，并对物体功能理解的差异做了分析。

Conclusion: 富有情境感的属性注释在推进动态环境中机器人感知方面至关重要。

Abstract: We introduce J-ORA, a novel multimodal dataset that bridges the gap in robot
perception by providing detailed object attribute annotations within Japanese
human-robot dialogue scenarios. J-ORA is designed to support three critical
perception tasks, object identification, reference resolution, and next-action
prediction, by leveraging a comprehensive template of attributes (e.g.,
category, color, shape, size, material, and spatial relations). Extensive
evaluations with both proprietary and open-source Vision Language Models (VLMs)
reveal that incorporating detailed object attributes substantially improves
multimodal perception performance compared to without object attributes.
Despite the improvement, we find that there still exists a gap between
proprietary and open-source VLMs. In addition, our analysis of object
affordances demonstrates varying abilities in understanding object
functionality and contextual relationships across different VLMs. These
findings underscore the importance of rich, context-sensitive attribute
annotations in advancing robot perception in dynamic environments. See project
page at https://jatuhurrra.github.io/J-ORA/.

</details>


### [11] [Improving the performance of AI-powered Affordable Robotics for Assistive Tasks](https://arxiv.org/abs/2510.21771)
*Dharunish Yugeswardeenoo*

Main category: cs.RO

TL;DR: 提出一种低成本的机器人臂，实现辅助任务，有效提升任务准确率，降低模型复杂度。


<details>
  <summary>Details</summary>
Motivation: 到2050年，全球对辅助护理的需求将达到35亿人，远超人类看护者的供应。现有的机器人解决方案昂贵且需要技术专业知识，限制了可获取性。

Method: 通过模仿学习和视频演示构建低成本机器人臂，进行辅助任务

Result: 该系统在五种模型大小和四种架构上进行了评估，经过十小时的真实测试，任务准确率超过90%，比基线高出40%。PACT实现了模型尺寸的5倍缩减，同时保持了75%的准确率。

Conclusion: 未来的工作将探讨双手操作和移动能力，以扩展辅助功能。

Abstract: By 2050, the global demand for assistive care is expected to reach 3.5
billion people, far outpacing the availability of human caregivers. Existing
robotic solutions remain expensive and require technical expertise, limiting
accessibility. This work introduces a low-cost robotic arm for assistive tasks
such as feeding, cleaning spills, and fetching medicine. The system uses
imitation learning from demonstration videos, requiring no task-specific
programming or manual labeling. The robot consists of six servo motors, dual
cameras, and 3D-printed grippers. Data collection via teleoperation with a
leader arm yielded 50,000 video frames across the three tasks. A novel Phased
Action Chunking Transformer (PACT) captures temporal dependencies and segments
motion dynamics, while a Temporal Ensemble (TE) method refines trajectories to
improve accuracy and smoothness. Evaluated across five model sizes and four
architectures, with ten hours of real-world testing, the system achieved over
90% task accuracy, up to 40% higher than baselines. PACT enabled a 5x model
size reduction while maintaining 75% accuracy. Saliency analysis showed
reliance on key visual cues, and phase token gradients peaked at critical
trajectory moments, indicating effective temporal reasoning. Future work will
explore bimanual manipulation and mobility for expanded assistive capabilities.

</details>


### [12] [Real-Time QP Solvers: A Concise Review and Practical Guide Towards Legged Robots](https://arxiv.org/abs/2510.21773)
*Van Nam Dinh*

Main category: cs.RO

TL;DR: 本文对腿部机器人中的QP求解器进行分析与评估，展示了不同求解器的性能特点，强调了求解器与任务及硬件之间的协同作用。


<details>
  <summary>Details</summary>
Motivation: 研究关键的QP算法以提升腿部机器人在实时应用中的性能，满足时间、能源和计算限制。

Method: 通过标定标准凸QP，分类求解器为内部点法、活跃集策略、算子分离方案及增广拉格朗日法，并在公共基准上评估计算时间、约束满足与稳健性等指标。

Result: 提供了全面的QP求解器分析与基准测试，为腿部机器人优化选择合适的求解器提供实际指导。

Conclusion: 发现稀疏内部点法适合长时间跨度的MPC，而稠密的活跃集合方法适用于高频的WBC，推动灵活自主的腿部系统发展。

Abstract: Quadratic programming (QP) underpins real-time robotics by enabling
efficient, constrained optimization in state estimation, motion planning, and
control. In legged locomotion and manipulation, essential modules like inverse
dynamics, Model Predictive Control (MPC), and Whole-Body Control (WBC) are
inherently QP-based, demanding reliable solutions amid tight timing, energy,
and computational limits on embedded platforms. This paper presents a
comprehensive analysis and benchmarking study of cutting-edge QP solvers for
legged robotics. We begin by formulating the standard convex QP and classify
solvers into four principal algorithmic approaches, including interior-point
methods, active-set strategies, operator splitting schemes, and augmented
Lagrangian approaches. Each solver is examined in terms of algorithmic
structure, computational characteristics, and its ability to exploit problem
structure and warm-starting. Performance is evaluated using publicly available
benchmarks, focusing on metrics such as computation time, constraint
satisfaction, and robustness under perturbations. Feature tables and
comparisons yield practical guidance for solver selection, underscoring
trade-offs in speed, accuracy, and energy efficiency. Our findings emphasize
the synergy between solver, task, and hardware, sparse IPMs for long-horizon
MPC, and dense active-set for high frequency WBC to advance agile, autonomous
legged systems, with emerging extensions to nonconvex and distributed QP.

</details>


### [13] [VITA-E: Natural Embodied Interaction with Concurrent Seeing, Hearing, Speaking, and Acting](https://arxiv.org/abs/2510.21817)
*Xiaoyu Liu,Chaoyou Fu,Chi Yan,Chu Wu,Haihan Gao,Yi-Fan Zhang,Shaoqi Dong,Cheng Qian,Bin Luo,Xiuyong Yang,Guanwu Li,Yusheng Cai,Yunhang Shen,Deqiang Jiang,Haoyu Cao,Xing Sun,Caifeng Shan,Ran He*

Main category: cs.RO

TL;DR: VITA-E是一个新的具身交互框架，支持行为并发和实时用户干预，具有高成功率的复杂场景处理能力，提升了具身助手的自然性和能力。


<details>
  <summary>Details</summary>
Motivation: 当前的视觉-语言-动作模型受限于静态交互方式，缺乏并发处理用户指令的能力，影响用户体验，因而需要一个灵活的交互框架。

Method: 提出了一种双模型架构，VLA实例分为'主动模型'和'备用模型'，实现行为并发与用户干预，并结合'模型作为控制器'的范式优化系统命令生成。

Result: 通过在物理人形平台上的实验，证明VITA-E能够有效处理复杂交互场景，并在紧急停机和语音干预中表现出极高的成功率，同时实现语音与动作的并发执行。

Conclusion: VITA-E框架显著提高了具身助手的交互能力，实现了自然的行为并发和实时用户干预处理，展示了其在复杂交互场景中的可靠性和高成功率。

Abstract: Current Vision-Language-Action (VLA) models are often constrained by a rigid,
static interaction paradigm, which lacks the ability to see, hear, speak, and
act concurrently as well as handle real-time user interruptions dynamically.
This hinders seamless embodied collaboration, resulting in an inflexible and
unresponsive user experience. To address these limitations, we introduce
VITA-E, a novel embodied interaction framework designed for both behavioral
concurrency and nearly real-time interruption. The core of our approach is a
dual-model architecture where two parallel VLA instances operate as an ``Active
Model'' and a ``Standby Model'', allowing the embodied agent to observe its
environment, listen to user speech, provide verbal responses, and execute
actions, all concurrently and interruptibly, mimicking human-like multitasking
capabilities. We further propose a ``model-as-controller'' paradigm, where we
fine-tune the VLM to generate special tokens that serve as direct system-level
commands, coupling the model's reasoning with the system's behavior.
Experiments conducted on a physical humanoid platform demonstrate that VITA-E
can reliably handle complex interactive scenarios. Our framework is compatible
with various dual-system VLA models, achieving an extremely high success rate
on emergency stops and speech interruptions while also successfully performing
concurrent speech and action. This represents a significant step towards more
natural and capable embodied assistants.

</details>


### [14] [A Literature Review On Stewart-Gough Platform Calibrations A Literature Review On Stewart-Gough Platform Calibrations](https://arxiv.org/abs/2510.21854)
*Sourabh Karmakar,Cameron J. Turner*

Main category: cs.RO

TL;DR: 本研究回顾了Stewart-Gough平台的校准技术，并强调了在各种应用中提高平台准确性的挑战和误差源。


<details>
  <summary>Details</summary>
Motivation: 随着Stewart-Gough平台在医疗、工程、空间研究等领域的应用需求不断增加，提高其精度和校准方法变得非常重要。

Method: 调查并分析各种基于逆运动学的并联机器人校准技术及其结果。

Result: 研究发现，研究者们主要集中在提升平台位置和方向的准确性，并考虑来自不同误差源的影响。

Conclusion: 本研究旨在回顾Stewart-Gough平台校准的现状，强调不同校准方法及其相关的误差源。

Abstract: Researchers have studied Stewart-Gough platforms, also known as Gough-Stewart
platforms or hexapod platforms extensively for their inherent fine control
characteristics. Their studies led to the potential deployment opportunities of
Stewart-Gough Platforms in many critical applications such as the medical
field, engineering machines, space research, electronic chip manufacturing,
automobile manufacturing, etc. Some of these applications need micro and
nano-level movement control in 3D space for the motions to be precise,
complicated, and repeatable; a Stewart-Gough platform fulfills these challenges
smartly. For this, the platform must be more accurate than the specified
application accuracy level and thus proper calibration for a parallel robot is
crucial. Forward kinematics-based calibration for these hexapod machines
becomes unnecessarily complex and inverse kinematics complete this task with
much ease. To experiment with different calibration techniques, various
calibration approaches were implemented by using external instruments,
constraining one or more motions of the system, and using extra sensors for
auto or self-calibration. This survey paid attention to those key
methodologies, their outcome, and important details related to inverse
kinematic-based parallel robot calibrations. It was observed during this study
that the researchers focused on improving the accuracy of the platform position
and orientation considering the errors contributed by one source or multiple
sources. The error sources considered are mainly kinematic and structural, in
some cases, environmental factors also are reviewed, however, those
calibrations are done under no-load conditions. This study aims to review the
present state of the art in this field and highlight the processes and errors
considered for the calibration of Stewart-Gough platforms.

</details>


### [15] [Butter-Bench: Evaluating LLM Controlled Robots for Practical Intelligence](https://arxiv.org/abs/2510.21860)
*Callum Sharrock,Lukas Petersson,Hanna Petersson,Axel Backlund,Axel Wennström,Kristoffer Nordström,Elias Aronsson*

Main category: cs.RO

TL;DR: Butter-Bench 是一个基准测试，用于评估 LLM 控制机器人在实际智能中的表现，结果显示人类在此方面显著优于 LLM。


<details>
  <summary>Details</summary>
Motivation: 当前的机器人系统主要通过层次化架构运作，LLM 负责高层推理，而 VLA 模型用于低层控制，但需要单独评估 LLM 的能力

Method: 评估大型语言模型（LLM）控制的机器人在实际智能方面的表现

Result: 在 Butter-Bench 中，LLM 的表现远不及人类，最佳 LLM 得分仅为 40%，而人类平均得分为 95%。LLM 在多步骤空间规划和社会理解方面表现最差。

Conclusion: 对 LLM 进行身体推理的微调训练并未改善其在 Butter-Bench 上的表现。

Abstract: We present Butter-Bench, a benchmark evaluating large language model (LLM)
controlled robots for practical intelligence, defined as the ability to
navigate the messiness of the physical world. Current state-of-the-art robotic
systems use a hierarchical architecture with LLMs in charge of high-level
reasoning, and a Vision Language Action (VLA) model for low-level control.
Butter-Bench evaluates the LLM part in isolation from the VLA. Although LLMs
have repeatedly surpassed humans in evaluations requiring analytical
intelligence, we find humans still outperform LLMs on Butter-Bench. The best
LLMs score 40% on Butter-Bench, while the mean human score is 95%. LLMs
struggled the most with multi-step spatial planning and social understanding.
We also evaluate LLMs that are fine-tuned for embodied reasoning and conclude
that this training does not improve their score on Butter-Bench.

</details>


### [16] [A Physics-Informed Neural Network Approach for UAV Path Planning in Dynamic Environments](https://arxiv.org/abs/2510.21874)
*Shuning Zhang*

Main category: cs.RO

TL;DR: 提出了一种物理信息神经网络(PINN)框架，通过嵌入UAV动力学、风干扰和避障能力来优化无人机在动态风场下的轨迹，以实现安全、高效的飞行路径。


<details>
  <summary>Details</summary>
Motivation: 在动态风场中，无人机需要在物理和环境约束下生成安全且高效的轨迹，而传统方法常常无法满足这些需求。

Method: 利用物理信息神经网络(PINN)框架，最小化物理残差和风险意识目标，不依赖监督数据学习可行且无碰撞的轨迹。

Result: 比较模拟表明，该方法在控制能耗、平滑性和安全裕度方面优于传统方法A*和Kino-RRT*，并保持类似的飞行效率。

Conclusion: 物理信息学习为无人机轨迹优化提供了可扩展且物理一致的框架，整合了基于模型和数据驱动的规划。

Abstract: Unmanned aerial vehicles (UAVs) operating in dynamic wind fields must
generate safe and energy-efficient trajectories under physical and
environmental constraints. Traditional planners, such as A* and kinodynamic
RRT*, often yield suboptimal or non-smooth paths due to discretization and
sampling limitations. This paper presents a physics-informed neural network
(PINN) framework that embeds UAV dynamics, wind disturbances, and obstacle
avoidance directly into the learning process. Without requiring supervised
data, the PINN learns dynamically feasible and collision-free trajectories by
minimizing physical residuals and risk-aware objectives. Comparative
simulations show that the proposed method outperforms A* and Kino-RRT* in
control energy, smoothness, and safety margin, while maintaining similar flight
efficiency. The results highlight the potential of physics-informed learning to
unify model-based and data-driven planning, providing a scalable and physically
consistent framework for UAV trajectory optimization.

</details>


### [17] [Two-Steps Diffusion Policy for Robotic Manipulation via Genetic Denoising](https://arxiv.org/abs/2510.21991)
*Mateo Clemente,Leo Brunswic,Rui Heng Yang,Xuan Zhao,Yasser Khalil,Haoyu Lei,Amir Rasouli,Yinchuan Li*

Main category: cs.RO

TL;DR: 本研究提出了一种新的去噪策略，可以在机器人操作中显著提高扩散模型的效率和稳定性，减少推理步骤，取得更好的性能。


<details>
  <summary>Details</summary>
Motivation: 通过调整去噪过程来适应具体的具身AI任务特征，特别是行动分布的结构化和低维特性，以提高扩散策略的效率。

Method: 遗传去噪，基于种群的采样策略

Result: 在仅需2次神经函数评估（NFE）的情况下解决复杂任务，同时提高或匹配性能。

Conclusion: 通过个性化的去噪策略，我们的方法在多个机器人操作任务中表现优于标准扩散策略，推动了该领域的发展。

Abstract: Diffusion models, such as diffusion policy, have achieved state-of-the-art
results in robotic manipulation by imitating expert demonstrations. While
diffusion models were originally developed for vision tasks like image and
video generation, many of their inference strategies have been directly
transferred to control domains without adaptation. In this work, we show that
by tailoring the denoising process to the specific characteristics of embodied
AI tasks -- particularly structured, low-dimensional nature of action
distributions -- diffusion policies can operate effectively with as few as 5
neural function evaluations (NFE).
  Building on this insight, we propose a population-based sampling strategy,
genetic denoising, which enhances both performance and stability by selecting
denoising trajectories with low out-of-distribution risk. Our method solves
challenging tasks with only 2 NFE while improving or matching performance. We
evaluate our approach across 14 robotic manipulation tasks from D4RL and
Robomimic, spanning multiple action horizons and inference budgets. In over 2
million evaluations, our method consistently outperforms standard
diffusion-based policies, achieving up to 20\% performance gains with
significantly fewer inference steps.

</details>


### [18] [Estimation of Minimum Stride Frequency for the Frontal Plane Stability of Bipedal Systems](https://arxiv.org/abs/2510.22030)
*Harsha Karunanayaka,Siavash Rezazadeh*

Main category: cs.RO

TL;DR: 本研究分析了双足系统在前平面上稳定性的重要参数，并提出了一种预测最低步频的有效方法。


<details>
  <summary>Details</summary>
Motivation: 探究双足步态稳定性的关键参数如何影响稳定性，减少控制努力和能量消耗。

Method: 通过分析模型参数和系统自然频率，提出预测最低步频的方法。

Result: 提出了一种预测最低步频的方法，并将预测值与实际值进行比较。

Conclusion: 研究结果提供了前平面稳定机制的深入理解，并表明前馈稳定化可以显著降低控制努力。

Abstract: Stability of bipedal systems in frontal plane is affected by the hip offset,
to the extent that adjusting stride time using feedforward retraction and
extension of the legs can lead to stable oscillations without feedback control.
This feedforward stabilization can be leveraged to reduce the control effort
and energy expenditure and increase the locomotion robustness. However, there
is limited understanding of how key parameters, such as mass, stiffness, leg
length, and hip width, affect stability and the minimum stride frequency needed
to maintain it. This study aims to address these gaps through analyzing how
individual model parameters and the system's natural frequency influence the
minimum stride frequency required to maintain a stable cycle. We propose a
method to predict the minimum stride frequency, and compare the predicted
stride frequencies with actual values for randomly generated models. The
findings of this work provide a better understanding of the frontal plane
stability mechanisms and how feedforward stabilization can be leveraged to
reduce the control effort.

</details>


### [19] [RaycastGrasp: Eye-Gaze Interaction with Wearable Devices for Robotic Manipulation](https://arxiv.org/abs/2510.22113)
*Zitiantao Lin,Yongpeng Sang,Yang Ye*

Main category: cs.RO

TL;DR: 本研究提出了一种结合混合现实的眼动引导机器人操控界面，显著提高了操控准确性和意图识别效果，改善辅助机器人应用的直观性与可及性。


<details>
  <summary>Details</summary>
Motivation: 现有的操控接口如操纵杆对于有移动障碍的人士而言存在精确度高和参考框架不直观等问题，迫切需要更直观便捷的解决方案。

Method: 研究开发了一种穿戴式混合现实界面，结合注视跟踪和预训练视觉模型，实现精准的物体操控和意图识别。

Result: 本研究提出了一种基于穿戴式混合现实头盔的自我中心、注视引导的机器人操控界面。该系统允许用户通过自然的注视固定与现实世界物体无缝互动，同时提供增强视觉提示以确认用户意图，并利用预训练视觉模型和机器人臂进行意图识别和物体操控。实验结果显示，该方法显著提高了操控准确性，降低了系统延迟，并在多种实际场景中单次意图和物体识别准确率超过88%。

Conclusion: 我们的系统有效提升了机器人操控的直观性和可及性，对辅助机器人应用具有重要的实践意义。

Abstract: Robotic manipulators are increasingly used to assist individuals with
mobility impairments in object retrieval. However, the predominant
joystick-based control interfaces can be challenging due to high precision
requirements and unintuitive reference frames. Recent advances in human-robot
interaction have explored alternative modalities, yet many solutions still rely
on external screens or restrictive control schemes, limiting their
intuitiveness and accessibility. To address these challenges, we present an
egocentric, gaze-guided robotic manipulation interface that leverages a
wearable Mixed Reality (MR) headset. Our system enables users to interact
seamlessly with real-world objects using natural gaze fixation from a
first-person perspective, while providing augmented visual cues to confirm
intent and leveraging a pretrained vision model and robotic arm for intent
recognition and object manipulation. Experimental results demonstrate that our
approach significantly improves manipulation accuracy, reduces system latency,
and achieves single-pass intention and object recognition accuracy greater than
88% across multiple real-world scenarios. These results demonstrate the
system's effectiveness in enhancing intuitiveness and accessibility,
underscoring its practical significance for assistive robotics applications.

</details>


### [20] [EasyUUV: An LLM-Enhanced Universal and Lightweight Sim-to-Real Reinforcement Learning Framework for UUV Attitude Control](https://arxiv.org/abs/2510.22126)
*Guanwen Xie,Jingzehua Xu,Jiwei Tang,Yubo Huang,Shuai Zhang,Xiaofan Li*

Main category: cs.RO

TL;DR: 该论文提出EasyUUV，结合RL和LLM技术，解决UUV姿态控制中的泛化性和鲁棒性问题，并通过实验证明了其出色性能。


<details>
  <summary>Details</summary>
Motivation: 现有的UUV姿态控制方法在泛化能力、抗干扰能力和高效部署等方面仍然存在不足。

Method: 提出了一种轻量级的模拟到现实的强化学习框架，结合了并行RL训练与混合控制架构，使用多模态LLM自适应调整控制器参数。

Result: 通过广泛的仿真和现实实验验证了EasyUUV的有效性，并展示了其在复杂水下条件下的卓越表现。

Conclusion: EasyUUV在不同水下条件下实现了鲁棒和自适应的UUV姿态控制，表现优异。

Abstract: Despite recent advances in Unmanned Underwater Vehicle (UUV) attitude
control, existing methods still struggle with generalizability, robustness to
real-world disturbances, and efficient deployment. To address the above
challenges, this paper presents EasyUUV, a Large Language Model (LLM)-enhanced,
universal, and lightweight simulation-to-reality reinforcement learning (RL)
framework for robust attitude control of UUVs. EasyUUV combines parallelized RL
training with a hybrid control architecture, where a learned policy outputs
high-level attitude corrections executed by an adaptive S-Surface controller. A
multimodal LLM is further integrated to adaptively tune controller parameters
at runtime using visual and textual feedback, enabling training-free adaptation
to unmodeled dynamics. Also, we have developed a low-cost 6-DoF UUV platform
and applied an RL policy trained through efficient parallelized simulation.
Extensive simulation and real-world experiments validate the effectiveness and
outstanding performance of EasyUUV in achieving robust and adaptive UUV
attitude control across diverse underwater conditions. The source code is
available from the following website: https://360zmem.github.io/easyuuv/

</details>


### [21] [LT-Exosense: A Vision-centric Multi-session Mapping System for Lifelong Safe Navigation of Exoskeletons](https://arxiv.org/abs/2510.22164)
*Jianeng Wang,Matias Mattamala,Christina Kassab,Nived Chebrolu,Guillaume Burger,Fabio Elnecave,Marine Petriaux,Maurice Fallon*

Main category: cs.RO

TL;DR: LT-Exosense是一个支持长期导航的视觉中心多会话映射系统，能有效适应环境变化并实现智能路径规划


<details>
  <summary>Details</summary>
Motivation: 解决自平衡外骨骼在不同环境中的长期可靠操作需求

Method: 介绍了一种名为LT-Exosense的视觉中心的多会话映射系统

Result: 通过实地实验验证，LT-Exosense能在与激光扫描的真实数据比较中，平均点对点误差低于5厘米，且具备适应变化环境的路径规划能力

Conclusion: LT-Exosense显示出在动态变化的室内环境中，适应性路径规划的潜力，改善了外骨骼用户的导航体验。

Abstract: Self-balancing exoskeletons offer a promising mobility solution for
individuals with lower-limb disabilities. For reliable long-term operation,
these exoskeletons require a perception system that is effective in changing
environments. In this work, we introduce LT-Exosense, a vision-centric,
multi-session mapping system designed to support long-term (semi)-autonomous
navigation for exoskeleton users. LT-Exosense extends single-session mapping
capabilities by incrementally fusing spatial knowledge across multiple
sessions, detecting environmental changes, and updating a persistent global
map. This representation enables intelligent path planning, which can adapt to
newly observed obstacles and can recover previous routes when obstructions are
removed. We validate LT-Exosense through several real-world experiments,
demonstrating a scalable multi-session map that achieves an average
point-to-point error below 5 cm when compared to ground-truth laser scans. We
also illustrate the potential application of adaptive path planning in
dynamically changing indoor environments.

</details>


### [22] [If They Disagree, Will You Conform? Exploring the Role of Robots' Value Awareness in a Decision-Making Task](https://arxiv.org/abs/2510.23204)
*Giulia Pusceddu,Giulio Antonio Abbo,Francesco Rea,Tony Belpaeme,Alessandra Sciutti*

Main category: cs.RO

TL;DR: 本研究探讨具有价值意识的社交机器人如何影响人类决策，结果显示参与者对价值意识机器人更感兴趣，但也揭示了潜在的操控风险。


<details>
  <summary>Details</summary>
Motivation: 探究社交机器人在决策影响中的角色，尤其是它们是否会因为被认为具备价值意识而增强对人类的影响力。

Method: 通过实验比较两款不同编程机制的Furhat机器人（具备价值意识和不具备价值意识）与参与者的互动。

Result: 参与者更倾向于注视具价值意识的机器人，并认为其忠诚度更高，且在机器人意见不合时表现出犹豫，约四分之一的实验中发生从众现象。

Conclusion: 社交机器人，尤其是具备价值意识的机器人，可能在决策过程中影响人类，但也存在潜在的操控风险。

Abstract: This study investigates whether the opinions of robotic agents are more
likely to influence human decision-making when the robots are perceived as
value-aware (i.e., when they display an understanding of human principles). We
designed an experiment in which participants interacted with two Furhat robots
- one programmed to be Value-Aware and the other Non-Value-Aware - during a
labeling task for images representing human values. Results indicate that
participants distinguished the Value-Aware robot from the Non-Value-Aware one.
Although their explicit choices did not indicate a clear preference for one
robot over the other, participants directed their gaze more toward the
Value-Aware robot. Additionally, the Value-Aware robot was perceived as more
loyal, suggesting that value awareness in a social robot may enhance its
perceived commitment to the group. Finally, when both robots disagreed with the
participant, conformity occurred in about one out of four trials, and
participants took longer to confirm their responses, suggesting that two robots
expressing dissent may introduce hesitation in decision-making. On one hand,
this highlights the potential risk that robots, if misused, could manipulate
users for unethical purposes. On the other hand, it reinforces the idea that
social robots might encourage reflection in ambiguous situations and help users
avoid scams.

</details>


### [23] [ACG: Action Coherence Guidance for Flow-based VLA models](https://arxiv.org/abs/2510.22201)
*Minho Park,Kinam Kim,Junha Hyung,Hyojin Jang,Hoiyeong Jin,Jooyeol Yun,Hojoon Lee,Jaegul Choo*

Main category: cs.RO

TL;DR: 本研究提出了动作一致性指导算法（ACG），旨在改善视觉-语言-行动模型在复杂操作中的性能，克服模仿学习中的噪声问题。


<details>
  <summary>Details</summary>
Motivation: 提高机器人在视觉-语言-行动模型中的动作一致性，以解决模仿学习中人类示范噪音导致的动作不连贯问题。

Method: Action Coherence Guidance (ACG)

Result: 在RoboCasa、DexMimicGen和实际SO-101任务上的评估表明，ACG在提升动作一致性和成功率方面表现出色。

Conclusion: ACG不仅提高了机器人操作的一致性，还增强了在多样化的操作任务中的成功率，展现了其在实际应用中的潜力。

Abstract: Diffusion and flow matching models have emerged as powerful robot policies,
enabling Vision-Language-Action (VLA) models to generalize across diverse
scenes and instructions. Yet, when trained via imitation learning, their high
generative capacity makes them sensitive to noise in human demonstrations:
jerks, pauses, and jitter which reduce action coherence. Reduced action
coherence causes instability and trajectory drift during deployment, failures
that are catastrophic in fine-grained manipulation where precision is crucial.
In this paper, we present Action Coherence Guidance (ACG) for VLA models, a
training-free test-time guidance algorithm that improves action coherence and
thereby yields performance gains. Evaluated on RoboCasa, DexMimicGen, and
real-world SO-101 tasks, ACG consistently improves action coherence and boosts
success rates across diverse manipulation tasks. Code and project page are
available at https://github.com/DAVIAN-Robotics/ACG and
https://DAVIAN-Robotics.github.io/ACG , respectively.

</details>


### [24] [Bridging Perception and Reasoning: Dual-Pipeline Neuro-Symbolic Landing for UAVs in Cluttered Environments](https://arxiv.org/abs/2510.22204)
*Weixian Qian,Sebastian Schroder,Yao Deng,Jiaohong Yao,Linfeng Liang,Xiao Cheng,Richard Han,Xi Zheng*

Main category: cs.RO

TL;DR: NeuroSymLand框架结合了符号推理和轻量模型，提升无人机在复杂环境中的自主着陆能力。


<details>
  <summary>Details</summary>
Motivation: 解决无人机在复杂环境中自主着陆的需求，克服视觉和深度学习模型的局限性

Method: 提出一个神经符号框架NeuroSymLand，结合离线和在线管道

Result: 在各种数据集和真实无人机硬件上，NeuroSymLand实现了比现有最先进技术更高的准确性、鲁棒性和效率。

Conclusion: NeuroSymLand提高了无人机在紧急响应、监视和投递任务中的安全性和可靠性。

Abstract: Autonomous landing in unstructured (cluttered, uneven, and map-poor)
environments is a core requirement for Unmanned Aerial Vehicles (UAVs), yet
purely vision-based or deep learning models often falter under covariate shift
and provide limited interpretability. We propose NeuroSymLand, a neuro-symbolic
framework that tightly couples two complementary pipelines: (i) an offline
pipeline, where Large Language Models (LLMs) and human-in-the-loop refinement
synthesize Scallop code from diverse landing scenarios, distilling
generalizable and verifiable symbolic knowledge; and (ii) an online pipeline,
where a compact foundation-based semantic segmentation model generates
probabilistic Scallop facts that are composed into semantic scene graphs for
real-time deductive reasoning. This design combines the perceptual strengths of
lightweight foundation models with the interpretability and verifiability of
symbolic reasoning. Node attributes (e.g., flatness, area) and edge relations
(adjacency, containment, proximity) are computed with geometric routines rather
than learned, avoiding the data dependence and latency of train-time graph
builders. The resulting Scallop program encodes landing principles (avoid water
and obstacles; prefer large, flat, accessible regions) and yields calibrated
safety scores with ranked Regions of Interest (ROIs) and human-readable
justifications. Extensive evaluations across datasets, diverse simulation maps,
and real UAV hardware show that NeuroSymLand achieves higher accuracy, stronger
robustness to covariate shift, and superior efficiency compared with
state-of-the-art baselines, while advancing UAV safety and reliability in
emergency response, surveillance, and delivery missions.

</details>


### [25] [Breaking the Static Assumption: A Dynamic-Aware LIO Framework Via Spatio-Temporal Normal Analysis](https://arxiv.org/abs/2510.22313)
*Chen Zhiqiang,Le Gentil Cedric,Lin Fuling,Lu Minghao,Qiao Qiyuan,Xu Bowen,Qi Yuhua,Lu Peng*

Main category: cs.RO

TL;DR: 本论文针对动态环境中激光雷达惯性里程计（LIO）面临的挑战，提出了一种动态感知的点云配准算法，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 传统LIO方法在动态物体占主导的场景中效果不佳，尤其是在几何稀疏的环境中，因此需要改进动态感知能力。

Method: 研究中提出了一种新颖的动态感知迭代最近点算法，结合了时空法线分析和高效的空间一致性验证方法。

Result: 实验评估表明，所提出的方法在具有有限几何结构的动态环境中，相较于现有的最先进LIO系统有显著的性能提升。

Conclusion: 本论文提出的动态感知迭代最近点算法在动态环境下显著优化了激光雷达惯性里程计的性能。

Abstract: This paper addresses the challenge of Lidar-Inertial Odometry (LIO) in
dynamic environments, where conventional methods often fail due to their
static-world assumptions. Traditional LIO algorithms perform poorly when
dynamic objects dominate the scenes, particularly in geometrically sparse
environments. Current approaches to dynamic LIO face a fundamental challenge:
accurate localization requires a reliable identification of static features,
yet distinguishing dynamic objects necessitates precise pose estimation. Our
solution breaks this circular dependency by integrating dynamic awareness
directly into the point cloud registration process. We introduce a novel
dynamic-aware iterative closest point algorithm that leverages spatio-temporal
normal analysis, complemented by an efficient spatial consistency verification
method to enhance static map construction. Experimental evaluations demonstrate
significant performance improvements over state-of-the-art LIO systems in
challenging dynamic environments with limited geometric structure. The code and
dataset are available at https://github.com/thisparticle/btsa.

</details>


### [26] [Toward Humanoid Brain-Body Co-design: Joint Optimization of Control and Morphology for Fall Recovery](https://arxiv.org/abs/2510.22336)
*Bo Yue,Sheng Xu,Kui Jia,Guiliang Liu*

Main category: cs.RO

TL;DR: 本研究提出了RoboCraft，一个可扩展的人形机器人共设计框架，旨在通过优化控制策略和物理形态来增强跌倒恢复能力。


<details>
  <summary>Details</summary>
Motivation: 人形机器人作为具身智能的前沿领域，其人类拟人化的形态可以自然适应人类的工作环境，而跌倒恢复能力是实现这一潜力的关键能力。

Method: 本研究通过共享策略的预训练和逐步微调，以及利用人类启发的先验和优化算法进行形态搜索，构建了RoboCraft框架。

Result: 实验结果表明，RoboCraft在七个公共人形机器人上平均性能提高了44.55%，形态优化推动了至少40%的改进。

Conclusion: RoboCraft通过优化形态和控制策略显著提升了人形机器人的跌倒恢复性能，突显了人形机器人共设计的重要性。

Abstract: Humanoid robots represent a central frontier in embodied intelligence, as
their anthropomorphic form enables natural deployment in humans' workspace.
Brain-body co-design for humanoids presents a promising approach to realizing
this potential by jointly optimizing control policies and physical morphology.
Within this context, fall recovery emerges as a critical capability. It not
only enhances safety and resilience but also integrates naturally with
locomotion systems, thereby advancing the autonomy of humanoids. In this paper,
we propose RoboCraft, a scalable humanoid co-design framework for fall recovery
that iteratively improves performance through the coupled updates of control
policy and morphology. A shared policy pretrained across multiple designs is
progressively finetuned on high-performing morphologies, enabling efficient
adaptation without retraining from scratch. Concurrently, morphology search is
guided by human-inspired priors and optimization algorithms, supported by a
priority buffer that balances reevaluation of promising candidates with the
exploration of novel designs. Experiments show that \ourmethod{} achieves an
average performance gain of 44.55% on seven public humanoid robots, with
morphology optimization drives at least 40% of improvements in co-designing
four humanoid robots, underscoring the critical role of humanoid co-design.

</details>


### [27] [Estimating Continuum Robot Shape under External Loading using Spatiotemporal Neural Networks](https://arxiv.org/abs/2510.22339)
*Enyi Wang,Zhen Deng,Chuanchuan Pan,Bingwei He,Jianwei Zhang*

Main category: cs.RO

TL;DR: 提出一种基于深度学习的时空数据融合方法，准确估计柔性机器人在负载下的3D形状，显示出优越的精度。


<details>
  <summary>Details</summary>
Motivation: 准确估计在外部负载下的柔性机器人形状，以提高机器人在复杂环境中的操作能力。

Method: 基于学习的方法，通过时空神经网络架构融合多模态输入，以估计柔性连续机器人在外部载荷作用下的3D形状。

Result: 通过结合当前与历史的肌腱位移数据及RGB图像，生成机器人的变形点云，实验验证显示在无负载和有负载情况下，形状估计误差分别为0.08mm和0.22mm，优于现有方法。

Conclusion: 深度学习的时空数据融合方法在负载条件下有效提升了柔性机器人的形状估计精度。

Abstract: This paper presents a learning-based approach for accurately estimating the
3D shape of flexible continuum robots subjected to external loads. The proposed
method introduces a spatiotemporal neural network architecture that fuses
multi-modal inputs, including current and historical tendon displacement data
and RGB images, to generate point clouds representing the robot's deformed
configuration. The network integrates a recurrent neural module for temporal
feature extraction, an encoding module for spatial feature extraction, and a
multi-modal fusion module to combine spatial features extracted from visual
data with temporal dependencies from historical actuator inputs. Continuous 3D
shape reconstruction is achieved by fitting B\'ezier curves to the predicted
point clouds. Experimental validation demonstrates that our approach achieves
high precision, with mean shape estimation errors of 0.08 mm (unloaded) and
0.22 mm (loaded), outperforming state-of-the-art methods in shape sensing for
TDCRs. The results validate the efficacy of deep learning-based spatiotemporal
data fusion for precise shape estimation under loading conditions.

</details>


### [28] [BLIP-FusePPO: A Vision-Language Deep Reinforcement Learning Framework for Lane Keeping in Autonomous Vehicles](https://arxiv.org/abs/2510.22370)
*Seyed Ahmad Hosseini Miangoleh,Amin Jalal Aghdasian,Farzaneh Abdollahi*

Main category: cs.RO

TL;DR: 本文提出了一种新颖的多模态强化学习框架BLIP-FusePPO，能有效融合语义、几何和控制信息，提高自主车道保持的性能。


<details>
  <summary>Details</summary>
Motivation: 旨在创建一种能够有效整合高层场景理解和低层控制信号的智能体，以提高驾驶规则的学习能力。

Method: 通过融合视图-语言模型生成的语义嵌入、几何状态、激光雷达观测和基于PID控制的反馈，从而形成了一个新的多模态强化学习框架，用于自主车道保持。

Result: 模拟结果显示，该方法在车道保持的稳定性和适应性方面优于多种现有基线，且通过混合奖励函数使学习更加高效和具有广泛适用性。

Conclusion: 所提出的BLIP-FusePPO框架在多种复杂驾驶场景中表现出更好的车道保持稳定性和适应性，优于现有的视觉基础和多模态强化学习基线。

Abstract: In this paper, we propose Bootstrapped Language-Image Pretraining-driven
Fused State Representation in Proximal Policy Optimization (BLIP-FusePPO), a
novel multimodal reinforcement learning (RL) framework for autonomous
lane-keeping (LK), in which semantic embeddings generated by a vision-language
model (VLM) are directly fused with geometric states, LiDAR observations, and
Proportional-Integral-Derivative-based (PID) control feedback within the agent
observation space. The proposed method lets the agent learn driving rules that
are aware of their surroundings and easy to understand by combining high-level
scene understanding from the VLM with low-level control and spatial signals.
Our architecture brings together semantic, geometric, and control-aware
representations to make policy learning more robust. A hybrid reward function
that includes semantic alignment, LK accuracy, obstacle avoidance, and speed
regulation helps learning to be more efficient and generalizable. Our method is
different from the approaches that only use semantic models to shape rewards.
Instead, it directly embeds semantic features into the state representation.
This cuts down on expensive runtime inference and makes sure that semantic
guidance is always available. The simulation results show that the proposed
model is better at LK stability and adaptability than the best vision-based and
multimodal RL baselines in a wide range of difficult driving situations. We
make our code publicly available.

</details>


### [29] [A Novel Multi-Timescale Stability-Preserving Hierarchical Reinforcement Learning Controller Framework for Adaptive Control in High-Dimensional Dynamical Systems](https://arxiv.org/abs/2510.22420)
*Mohammad Ali Labbaf Khaniki,Fateme Taroodi,Benyamin Safizadeh*

Main category: cs.RO

TL;DR: 本研究提出了MTLHRL框架，旨在提高高维随机系统的控制效率和稳定性，特别是在机器人、自动驾驶车辆和超混沌系统中。


<details>
  <summary>Details</summary>
Motivation: 随着机器人和自动驾驶技术的发展，控制高维随机系统的需求日益增加，因此需要有效的方法以应对系统的复杂性与不确定性。

Method: MTLHRL框架通过集成层次化策略于半马尔可夫决策过程（SMDP），实现高层次战略规划和低层次反应控制，同时利用神经李雅普诺夫函数和多时间尺度演员-评论家更新来确保系统稳定。

Result: 本研究提出了多时间尺度李雅普诺夫约束层次强化学习（MTLHRL）框架，以解决高维随机系统控制中的主要挑战，包括维度诅咒、缺乏时间抽象以及无法确保随机稳定性的问题。

Conclusion: MTLHRL是一个理论基础扎实且在实践中可行的解决方案，适用于复杂随机系统的强健控制。

Abstract: Controlling high-dimensional stochastic systems, critical in robotics,
autonomous vehicles, and hyperchaotic systems, faces the curse of
dimensionality, lacks temporal abstraction, and often fails to ensure
stochastic stability. To overcome these limitations, this study introduces the
Multi-Timescale Lyapunov-Constrained Hierarchical Reinforcement Learning
(MTLHRL) framework. MTLHRL integrates a hierarchical policy within a
semi-Markov Decision Process (SMDP), featuring a high-level policy for
strategic planning and a low-level policy for reactive control, which
effectively manages complex, multi-timescale decision-making and reduces
dimensionality overhead. Stability is rigorously enforced using a neural
Lyapunov function optimized via Lagrangian relaxation and multi-timescale
actor-critic updates, ensuring mean-square boundedness or asymptotic stability
in the face of stochastic dynamics. The framework promotes efficient and
reliable learning through trust-region constraints and decoupled optimization.
Extensive simulations on an 8D hyperchaotic system and a 5-DOF robotic
manipulator demonstrate MTLHRL's empirical superiority. It significantly
outperforms baseline methods in both stability and performance, recording the
lowest error indices (e.g., Integral Absolute Error (IAE): 3.912 in
hyperchaotic control and IAE: 1.623 in robotics), achieving faster convergence,
and exhibiting superior disturbance rejection. MTLHRL offers a theoretically
grounded and practically viable solution for robust control of complex
stochastic systems.

</details>


### [30] [A short methodological review on social robot navigation benchmarking](https://arxiv.org/abs/2510.22448)
*Pranup Chhetri,Alejandro Torrejon,Sergio Eslava,Luis J. Manso*

Main category: cs.RO

TL;DR: 本文综述了社交机器人导航的基准测试趋势，指出了该领域标准缺乏的问题以及相关文献的分析。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在填补社交机器人导航领域基准测试标准缺失的空白，以推动该领域的进展。

Method: 通过IEEE Xplore数据库，筛选出130篇相关论文，并对符合评审标准的85篇论文进行了分析。

Result: 本研究对社交机器人导航的基准测试进行了综述，分析了该领域在2020年至2025年间的趋势，指出了当前基准测试标准缺乏的问题，并探讨了相关文献中使用的度量标准、算法、以及人类调查的应用情况。

Conclusion: 缺乏统一的基准测试标准严重影响了社交机器人导航领域的进展，因此亟需制定有效的基准测试框架。

Abstract: Social Robot Navigation is the skill that allows robots to move efficiently
in human-populated environments while ensuring safety, comfort, and trust.
Unlike other areas of research, the scientific community has not yet achieved
an agreement on how Social Robot Navigation should be benchmarked. This is
notably important, as the lack of a de facto standard to benchmark Social Robot
Navigation can hinder the progress of the field and may lead to contradicting
conclusions. Motivated by this gap, we contribute with a short review focused
exclusively on benchmarking trends in the period from January 2020 to July
2025. Of the 130 papers identified by our search using IEEE Xplore, we analysed
the 85 papers that met the criteria of the review. This review addresses the
metrics used in the literature for benchmarking purposes, the algorithms
employed in such benchmarks, the use of human surveys for benchmarking, and how
conclusions are drawn from the benchmarking results, when applicable.

</details>


### [31] [Forward Kinematics Solution For A General Stewart Platform Through Iteration Based Simulation](https://arxiv.org/abs/2510.22465)
*Sourabh Karmakar,Cameron J. Turner*

Main category: cs.RO

TL;DR: 提出了一种针对Stewart平台的前向运动学解决方案的生成方法，能有效生成唯一有效的解决方案，且不需手动验证。


<details>
  <summary>Details</summary>
Motivation: 解决Stewart平台的复杂前向运动学问题，并提高材料测试系统的可靠性和准确性。

Method: 使用逆运动学获取工作空间数据和相应的执行器长度，采用修改后的Denavit-Hartenberg约定的简单迭代算法。

Result: 每个有效姿态生成唯一的前向运动学解决方案，可以直接用于后续计算，显著简化了过程。

Conclusion: 该方法确保了Stewart平台的每个有效姿态都能得到一个可用的前向运动学解决方案，从而提高了材料测试系统的精度和效率。

Abstract: This paper presents a method to generate feasible, unique forward-kinematic
solutions for a general Stewart platform. This is done by using inverse
kinematics to obtain valid workspace data and corresponding actuator lengths
for the moving platform. For parallel kinematic machines, such as the Stewart
Platform, inverse kinematics are straight forward, but the forward kinematics
are complex and generates multiple solutions due to the closed loop structure
of the kinematic links. In this research, a simple iterative algorithm has been
used employing modified Denavit-Hartenberg convention. The outcome is
encouraging as this method generates a single feasible forward kinematic
solution for each valid pose with the solved DH parameters and unlike earlier
forward kinematics solutions, this unique solution does not need to be manually
verified. Therefore, the forward kinematic solutions can be used directly for
further calculations without the need for manual pose verification. This
capability is essential for the six degree of freedom materials testing system
developed by the authors in their laboratory. The developed system is aimed at
characterizing additively manufactured materials under complex combined
multiple loading conditions. The material characterization is done by enabling
high precision force control on the moving platform via in situ calibration of
the as-built kinematics of the Stewart Gough Platform.

</details>


### [32] [On Steerability Factors for Growing Vine Robots](https://arxiv.org/abs/2510.22504)
*Ciera McFarland,Antonio Alvarez,Sarah Taher,Nathaniel Hanson,Margaret McGuinness*

Main category: cs.RO

TL;DR: 本研究探讨了影响藤蔓机器人（使用系列袋状电机式气动执行器）引导性的多个因素，通过实验发现尖端负载、压力、长度和制造方法对引导性有显著影响，并提出优化原则以提高机器人性能。


<details>
  <summary>Details</summary>
Motivation: 尽管藤蔓机器人在城市搜索和救援领域有潜在应用，但其性能受到附加传感器或工具的重量以及设计和控制选择的限制。

Method: 本研究进行两组实验：第一组研究机器人在自身重力下支持的情况下，考虑尖端负载、腔室压力、长度和直径；第二组研究在地面支撑的机器人情况下，考虑制造方法和执行器与腔室压力的比率。

Result: 研究结果表明，随着尖端负载的增加，引导能力下降；在适中腔室压力下引导能力最佳；长度增加时引导能力增强，直径则基本不影响引导能力。外部附加执行器的机器人在低压力比时开始弯曲，但在高压力比时曲率饱和；而将执行器集成到机器人主体内的机器人需要更高的压力比才能开始弯曲，但整体曲率更高。

Conclusion: 经过优化的机器人在涉及最大化向上和水平曲率的移动任务中表现优于那些采用临时参数的机器人。

Abstract: Vine robots extend their tubular bodies by everting material from the tip,
enabling navigation in complex environments with a minimalist soft body.
Despite their promise for field applications, especially in the urban search
and rescue domain, performance is constrained by the weight of attached sensors
or tools, as well as other design and control choices. This work investigates
how tip load, pressure, length, diameter, and fabrication method shape vine
robot steerability--the ability to maneuver with controlled curvature--for
robots that steer with series pouch motor-style pneumatic actuators. We conduct
two groups of experiments: (1) studying tip load, chamber pressure, length, and
diameter in a robot supporting itself against gravity, and (2) studying
fabrication method and ratio of actuator to chamber pressure in a robot
supported on the ground. Results show that steerability decreases with
increasing tip load, is best at moderate chamber pressure, increases with
length, and is largely unaffected by diameter. Robots with actuators attached
on their exterior begin curving at low pressure ratios, but curvature saturates
at high pressure ratios; those with actuators integrated into the robot body
require higher pressure ratios to begin curving but achieve higher curvature
overall. We demonstrate that robots optimized with these principles outperform
those with ad hoc parameters in a mobility task that involves maximizing upward
and horizontal curvatures.

</details>


### [33] [Ant-inspired Walling Strategies for Scalable Swarm Separation: Reinforcement Learning Approaches Based on Finite State Machines](https://arxiv.org/abs/2510.22524)
*Shenbagaraj Kannapiran,Elena Oikonomou,Albert Chu,Spring Berman,Theodore P. Pavlic*

Main category: cs.RO

TL;DR: 本研究开发了两种去中心化控制器，以帮助异构机器人群体在执行任务时保持空间分离，模拟结果表明DQN增强控制器在减少子群体混合及提高适应性方面表现优越。


<details>
  <summary>Details</summary>
Motivation: 受到自然系统中出现的结构启发，比如军蚂蚁形成的临时“墙”，本研究旨在为异构机器人群体设计控制器来维护空间分离，避免干扰。

Method: 采用有限状态机（FSM）和深度Q网络（DQN）结合的两种去中心化控制方案，分别创建稳定墙和动态优化的“非军事区”以维持机器人群体的分离。

Result: 在模拟中，两个控制器均有效减少了子群体之间的混合，其中DQN增强的控制器在适应性和收敛速度上都有显著提高。

Conclusion: 这两种去中心化控制器有效地维护了异构机器人群体在执行并行任务时的空间分离，DQN增强的控制器显著提高了适应性并减少了40-50%的混合情况，同时实现了更快的收敛。

Abstract: In natural systems, emergent structures often arise to balance competing
demands. Army ants, for example, form temporary "walls" that prevent
interference between foraging trails. Inspired by this behavior, we developed
two decentralized controllers for heterogeneous robotic swarms to maintain
spatial separation while executing concurrent tasks. The first is a
finite-state machine (FSM)-based controller that uses encounter-triggered
transitions to create rigid, stable walls. The second integrates FSM states
with a Deep Q-Network (DQN), dynamically optimizing separation through emergent
"demilitarized zones." In simulation, both controllers reduce mixing between
subgroups, with the DQN-enhanced controller improving adaptability and reducing
mixing by 40-50% while achieving faster convergence.

</details>


### [34] [SPIRAL: Self-Play Incremental Racing Algorithm for Learning in Multi-Drone Competitions](https://arxiv.org/abs/2510.22568)
*Onur Akgün*

Main category: cs.RO

TL;DR: SPIRAL是一种新型自我对弈算法，用于训练自主无人机在多智能体赛车中的表现，能够渐进地提升赛车策略和能力。


<details>
  <summary>Details</summary>
Motivation: 开发一种灵活且能适应复杂动态环境的赛车策略，提高自主无人机在竞争激烈场景中的表现和可靠性。

Method: 采用自我对弈机制训练无人机，通过与自身愈发优秀的版本竞争来逐步提高赛车能力，最终掌握复杂的多无人机合作竞赛策略。

Result: 本文提出了一种新颖的自我对弈增量赛车算法SPIRAL，用于训练自主无人机在多智能体 racing 比赛中的表现。SPIRAL通过自我对弈机制，在动态挑战的环境中逐步培养复杂的比赛行为，使无人机不断地与自身更强大的版本竞争，从而不断增加竞争的难度。这种渐进式的学习过程引导代理从掌握基本飞行控制到执行复杂的多无人机合作赛车策略。该方法具备多样性，允许与最先进的深度强化学习算法集成。在模拟中，SPIRAL展示了显著的优势，并基准测试了各种在其框架下运行的DRL算法的表现。因此，我们为自主无人机赛车领域贡献了一个多功能、可扩展和自我改进的学习框架。SPIRAL通过其自我对弈动态自主生成合适和逐渐升级的挑战，提供了一个有前景的方向，以开发鲁棒和适应性强的赛车策略。因此，这项研究开辟了提升自主赛车无人机在越来越复杂和竞争激烈场景中的性能和可靠性的新途径。

Conclusion: SPIRAL为自主无人机赛车提供了一个强大且具适应性的学习框架，能够自动生成逐渐提升的挑战，从而可以在复杂和竞争激烈的环境中增强无人机的性能和可靠性。

Abstract: This paper introduces SPIRAL (Self-Play Incremental Racing Algorithm for
Learning), a novel approach for training autonomous drones in multi-agent
racing competitions. SPIRAL distinctively employs a self-play mechanism to
incrementally cultivate complex racing behaviors within a challenging, dynamic
environment. Through this self-play core, drones continuously compete against
increasingly proficient versions of themselves, naturally escalating the
difficulty of competitive interactions. This progressive learning journey
guides agents from mastering fundamental flight control to executing
sophisticated cooperative multi-drone racing strategies. Our method is designed
for versatility, allowing integration with any state-of-the-art Deep
Reinforcement Learning (DRL) algorithms within its self-play framework.
Simulations demonstrate the significant advantages of SPIRAL and benchmark the
performance of various DRL algorithms operating within it. Consequently, we
contribute a versatile, scalable, and self-improving learning framework to the
field of autonomous drone racing. SPIRAL's capacity to autonomously generate
appropriate and escalating challenges through its self-play dynamic offers a
promising direction for developing robust and adaptive racing strategies in
multi-agent environments. This research opens new avenues for enhancing the
performance and reliability of autonomous racing drones in increasingly complex
and competitive scenarios.

</details>


### [35] [Curriculum-Based Iterative Self-Play for Scalable Multi-Drone Racing](https://arxiv.org/abs/2510.22570)
*Onur Akgün*

Main category: cs.RO

TL;DR: CRUISE是一种结合渐进难度课程和高效自我对抗机制的强化学习框架，旨在解决多无人机竞速中的协作挑战，并显著提升了竞速表现。


<details>
  <summary>Details</summary>
Motivation: 在快速竞争环境中的多自主代理协作是一项重大工程挑战，特别是在多无人机竞速中。

Method: 通过将渐进难度课程与高效自我对抗机制相结合，CRUISE克服了可扩展性限制，促进了坚韧的竞争行为的培养。

Result: CRUISE框架在高保真模拟中取得的策略显著优于标准强化学习基线和最新的博弈论规划器，几乎达到了规划器平均竞速的两倍，保持了较高的成功率，且展示了随着代理密度增加的强大可扩展性。

Conclusion: CRUISE为动态竞争任务的自主系统发展提供了一种可扩展且有效的训练方法，并为未来的实际部署奠定了基础。

Abstract: The coordination of multiple autonomous agents in high-speed, competitive
environments represents a significant engineering challenge. This paper
presents CRUISE (Curriculum-Based Iterative Self-Play for Scalable Multi-Drone
Racing), a reinforcement learning framework designed to solve this challenge in
the demanding domain of multi-drone racing. CRUISE overcomes key scalability
limitations by synergistically combining a progressive difficulty curriculum
with an efficient self-play mechanism to foster robust competitive behaviors.
Validated in high-fidelity simulation with realistic quadrotor dynamics, the
resulting policies significantly outperform both a standard reinforcement
learning baseline and a state-of-the-art game-theoretic planner. CRUISE
achieves nearly double the planner's mean racing speed, maintains high success
rates, and demonstrates robust scalability as agent density increases. Ablation
studies confirm that the curriculum structure is the critical component for
this performance leap. By providing a scalable and effective training
methodology, CRUISE advances the development of autonomous systems for dynamic,
competitive tasks and serves as a blueprint for future real-world deployment.

</details>


### [36] [RoGER-SLAM: A Robust Gaussian Splatting SLAM System for Noisy and Low-light Environment Resilience](https://arxiv.org/abs/2510.22600)
*Huilin Yin,Zhaolin Yang,Linchuan Zhang,Gerhard Rigoll,Johannes Betz*

Main category: cs.RO

TL;DR: RoGER-SLAM是一种新的SLAM系统，通过引入创新机制克服了噪声和低光照条件下的映射和跟踪性能下降的问题。


<details>
  <summary>Details</summary>
Motivation: 在噪声和低光照的环境中，现有的SLAM系统的可靠性受到限制，针对这种情况，提出了新的解决方案以增强系统的鲁棒性。

Method: RoGER-SLAM系统融合了三项创新：结构保持的鲁棒融合机制、适应性跟踪目标和基于CLIP的增强模块。

Result: 提出了一种名为RoGER-SLAM的SLAM系统，针对噪声和低光照环境中SLAM的可靠性问题，提出了一系列创新机制，以提高映射和追踪性能。

Conclusion: RoGER-SLAM在挑战性成像条件下显著提高了轨迹准确性和重建质量，优于其他3DGS-SLAM系统。

Abstract: The reliability of Simultaneous Localization and Mapping (SLAM) is severely
constrained in environments where visual inputs suffer from noise and low
illumination. Although recent 3D Gaussian Splatting (3DGS) based SLAM
frameworks achieve high-fidelity mapping under clean conditions, they remain
vulnerable to compounded degradations that degrade mapping and tracking
performance. A key observation underlying our work is that the original 3DGS
rendering pipeline inherently behaves as an implicit low-pass filter,
attenuating high-frequency noise but also risking over-smoothing. Building on
this insight, we propose RoGER-SLAM, a robust 3DGS SLAM system tailored for
noise and low-light resilience. The framework integrates three innovations: a
Structure-Preserving Robust Fusion (SP-RoFusion) mechanism that couples
rendered appearance, depth, and edge cues; an adaptive tracking objective with
residual balancing regularization; and a Contrastive Language-Image Pretraining
(CLIP)-based enhancement module, selectively activated under compounded
degradations to restore semantic and structural fidelity. Comprehensive
experiments on Replica, TUM, and real-world sequences show that RoGER-SLAM
consistently improves trajectory accuracy and reconstruction quality compared
with other 3DGS-SLAM systems, especially under adverse imaging conditions.

</details>


### [37] [Uncertainty-Aware Autonomous Vehicles: Predicting the Road Ahead](https://arxiv.org/abs/2510.22680)
*Shireen Kudukkil Manchingal,Armand Amaritei,Mihir Gohad,Maryam Sultana,Julian F. P. Kooij,Fabio Cuzzolin,Andrew Bradley*

Main category: cs.RO

TL;DR: 本研究利用随机集合神经网络提升自动驾驶汽车对环境的感知能力，从而在不确定情况下提高安全性和准确性。


<details>
  <summary>Details</summary>
Motivation: 提高自动驾驶系统在不确定情况下的安全性和可靠性。

Method: 采用随机集合神经网络进行图像分类和不确定性量化，测试了其在真实场景下的表现，并与传统卷积神经网络和贝叶斯神经网络进行了比较。

Result: 通过引入随机集合神经网络（RS-NN），实现了对预测不确定性的清晰量化和信号传递，显著提高了分类准确性和不确定性标定。

Conclusion: 不确定性感知神经网络，特别是随机集合神经网络，能够作为提高自动驾驶安全性和鲁棒性的有效解决方案。

Abstract: Autonomous Vehicle (AV) perception systems have advanced rapidly in recent
years, providing vehicles with the ability to accurately interpret their
environment. Perception systems remain susceptible to errors caused by
overly-confident predictions in the case of rare events or out-of-sample data.
This study equips an autonomous vehicle with the ability to 'know when it is
uncertain', using an uncertainty-aware image classifier as part of the AV
software stack. Specifically, the study exploits the ability of Random-Set
Neural Networks (RS-NNs) to explicitly quantify prediction uncertainty. Unlike
traditional CNNs or Bayesian methods, RS-NNs predict belief functions over sets
of classes, allowing the system to identify and signal uncertainty clearly in
novel or ambiguous scenarios. The system is tested in a real-world autonomous
racing vehicle software stack, with the RS-NN classifying the layout of the
road ahead and providing the associated uncertainty of the prediction.
Performance of the RS-NN under a range of road conditions is compared against
traditional CNN and Bayesian neural networks, with the RS-NN achieving
significantly higher accuracy and superior uncertainty calibration. This
integration of RS-NNs into Robot Operating System (ROS)-based vehicle control
pipeline demonstrates that predictive uncertainty can dynamically modulate
vehicle speed, maintaining high-speed performance under confident predictions
while proactively improving safety through speed reductions in uncertain
scenarios. These results demonstrate the potential of uncertainty-aware neural
networks - in particular RS-NNs - as a practical solution for safer and more
robust autonomous driving.

</details>


### [38] [RL-AVIST: Reinforcement Learning for Autonomous Visual Inspection of Space Targets](https://arxiv.org/abs/2510.22699)
*Matteo El-Hariry,Andrej Orsula,Matthieu Geist,Miguel Olivares-Mendez*

Main category: cs.RO

TL;DR: 本论文提出了RL-AVIST，一个用于自主视觉检查空间目标的增强学习框架，展示了在复杂轨道任务中的有效性与创新性。


<details>
  <summary>Details</summary>
Motivation: 随着自主轨道服务需求的增加，智能航天器需要具备复杂机动能力，以应对模型不确定性、多航天器配置及动态任务环境等问题。

Method: 该研究结合了空间机器人测试平台（SRB）以及DreamerV3模型的基于模型的增强学习算法，使用PPO和TD3作为无模型的基线进行模拟与训练。

Result: 研究针对月球闸门等目标执行3D近距离机动任务，评估了训练有素和专门化代理的任务表现，分析了在多种空间形态和任务领域中策略的鲁棒性和泛化能力。

Conclusion: 模型驱动的增强学习在轨迹保真度和样本效率方面展现出良好能力，为未来的空间操作提供了可扩展且可重新训练的控制解决方案。

Abstract: The growing need for autonomous on-orbit services such as inspection,
maintenance, and situational awareness calls for intelligent spacecraft capable
of complex maneuvers around large orbital targets. Traditional control systems
often fall short in adaptability, especially under model uncertainties,
multi-spacecraft configurations, or dynamically evolving mission contexts. This
paper introduces RL-AVIST, a Reinforcement Learning framework for Autonomous
Visual Inspection of Space Targets. Leveraging the Space Robotics Bench (SRB),
we simulate high-fidelity 6-DOF spacecraft dynamics and train agents using
DreamerV3, a state-of-the-art model-based RL algorithm, with PPO and TD3 as
model-free baselines. Our investigation focuses on 3D proximity maneuvering
tasks around targets such as the Lunar Gateway and other space assets. We
evaluate task performance under two complementary regimes: generalized agents
trained on randomized velocity vectors, and specialized agents trained to
follow fixed trajectories emulating known inspection orbits. Furthermore, we
assess the robustness and generalization of policies across multiple spacecraft
morphologies and mission domains. Results demonstrate that model-based RL
offers promising capabilities in trajectory fidelity, and sample efficiency,
paving the way for scalable, retrainable control solutions for future space
operations

</details>


### [39] [SCAL for Pinch-Lifting: Complementary Rotational and Linear Prototypes for Environment-Adaptive Grasping](https://arxiv.org/abs/2510.22738)
*Wentao Guo,Wenzeng Zhang*

Main category: cs.RO

TL;DR: 本论文提出了一种基于SCAL的环境自适应夹持系统，利用旋转和线性驱动设计在不同物体上实现夹持提升，实验表明其具备良好的适应性和准确性。


<details>
  <summary>Details</summary>
Motivation: 为了解决环境适应性和低轮廓目标的有效抓取问题，提出了一种新型自适应夹持设计。

Method: 采用基于PLA的3D打印制作夹具，并通过实验评估夹持和提升的性能。

Result: 本论文提出了一种基于插槽约束自适应连杆（SCAL）的环境自适应夹持系统，并在两个互补指尖中实现：SCAL-R是一种具有主动指尖的旋转驱动设计，在接触后向内折叠形成一个包络；SCAL-L是一种线性驱动设计，在接触时被动打开，能够跨越宽大或特征弱的物体。两个指尖将表面跟随转换为向上的提起支路，同时保持指尖方向，使得薄或低轮廓目标能够以最小的传感和控制从支撑物中抬起。两指夹具通过基于PLA的3D打印制造。实验评估了（i）接触保持滑动和夹持提升在桌面上的表现，（ii）坡道协商后提升，以及（iii）通过主动包络（SCAL-R）或接触触发被动开启（SCAL-L）处理笨重物体。在针对小部件、箱子、瓶子和胶带卷的数十个试验中，两种设计都实现了一致的抓取，且调校有限。一个准静态分析提供了线性平行夹持和双点包络的闭式指尖力模型，为设计和操作提供了几何意识指导。总体结果表明，互补的操作机制和通向稳健、环境自适应抓取的简单驱动的实际路径。

Conclusion: 通过实验验证，提出的SCAL设计在处理多种物体时表现出一致的抓取效果，展示了良好的环境适应性。

Abstract: This paper presents environment-adaptive pinch-lifting built on a
slot-constrained adaptive linkage (SCAL) and instantiated in two complementary
fingers: SCAL-R, a rotational-drive design with an active fingertip that folds
inward after contact to form an envelope, and SCAL-L, a linear-drive design
that passively opens on contact to span wide or weak-feature objects. Both
fingers convert surface following into an upward lifting branch while
maintaining fingertip orientation, enabling thin or low-profile targets to be
raised from supports with minimal sensing and control. Two-finger grippers are
fabricated via PLA-based 3D printing. Experiments evaluate (i)
contact-preserving sliding and pinch-lifting on tabletops, (ii) ramp
negotiation followed by lift, and (iii) handling of bulky objects via active
enveloping (SCAL-R) or contact-triggered passive opening (SCAL-L). Across
dozens of trials on small parts, boxes, jars, and tape rolls, both designs
achieve consistent grasps with limited tuning. A quasi-static analysis provides
closed-form fingertip-force models for linear parallel pinching and two-point
enveloping, offering geometry-aware guidance for design and operation. Overall,
the results indicate complementary operating regimes and a practical path to
robust, environment-adaptive grasping with simple actuation.

</details>


### [40] [Policies over Poses: Reinforcement Learning based Distributed Pose-Graph Optimization for Multi-Robot SLAM](https://arxiv.org/abs/2510.22740)
*Sai Krishna Ghanta,Ramviyas Parasuraman*

Main category: cs.RO

TL;DR: 提出一种基于多智能体强化学习的分布式姿态图优化框架，显著提高了轨迹估计的准确性和推理效率，针对大规模机器人队伍具有良好扩展性。


<details>
  <summary>Details</summary>
Motivation: 提高多机器人同时定位与地图构建（SLAM）中的轨迹估计准确性，解决传统方法的局部最优问题

Method: 使用多智能体强化学习（MARL）框架进行分布式姿态图优化（PGO）

Result: 与当前最先进的分布式PGO框架相比，所提MARL方法将全局目标减少了大约37.5%，推理效率提升至少6倍

Conclusion: 所提出的方法在合成和真实世界数据集上表现优越，且支持单一学习策略在大型机器人团队中无缝扩展。

Abstract: We consider the distributed pose-graph optimization (PGO) problem, which is
fundamental in accurate trajectory estimation in multi-robot simultaneous
localization and mapping (SLAM). Conventional iterative approaches linearize a
highly non-convex optimization objective, requiring repeated solving of normal
equations, which often converge to local minima and thus produce suboptimal
estimates. We propose a scalable, outlier-robust distributed planar PGO
framework using Multi-Agent Reinforcement Learning (MARL). We cast distributed
PGO as a partially observable Markov game defined on local pose-graphs, where
each action refines a single edge's pose estimate. A graph partitioner
decomposes the global pose graph, and each robot runs a recurrent
edge-conditioned Graph Neural Network (GNN) encoder with adaptive edge-gating
to denoise noisy edges. Robots sequentially refine poses through a hybrid
policy that utilizes prior action memory and graph embeddings. After local
graph correction, a consensus scheme reconciles inter-robot disagreements to
produce a globally consistent estimate. Our extensive evaluations on a
comprehensive suite of synthetic and real-world datasets demonstrate that our
learned MARL-based actors reduce the global objective by an average of 37.5%
more than the state-of-the-art distributed PGO framework, while enhancing
inference efficiency by at least 6X. We also demonstrate that actor replication
allows a single learned policy to scale effortlessly to substantially larger
robot teams without any retraining. Code is publicly available at
https://github.com/herolab-uga/policies-over-poses.

</details>


### [41] [TWC-SLAM: Multi-Agent Cooperative SLAM with Text Semantics and WiFi Features Integration for Similar Indoor Environments](https://arxiv.org/abs/2510.22754)
*Chunyu Li,Shoubin Chen,Dong Li,Weixing Xue,Qingquan Li*

Main category: cs.RO

TL;DR: TWC-SLAM是一种多代理协作SLAM框架，通过结合文本语义和WiFi信号，改善了在重复室内环境中位置识别和闭环检测的准确性。


<details>
  <summary>Details</summary>
Motivation: 解决在重复结构的室内环境中，如走廊和房间，基于点云的定位识别面临的挑战。

Method: TWC-SLAM框架，结合文本语义和WiFi信号特征进行多代理协作式SLAM。

Result: TWC-SLAM显著提升了复杂环境中协作SLAM系统的性能，特别是在重复建筑特征的情况下。

Conclusion: 通过对复杂室内环境的评估，TWC-SLAM展示了其在优化全球映射和协作SLAM性能方面的有效性。

Abstract: Multi-agent cooperative SLAM often encounters challenges in similar indoor
environments characterized by repetitive structures, such as corridors and
rooms. These challenges can lead to significant inaccuracies in shared location
identification when employing point cloud-based techniques. To mitigate these
issues, we introduce TWC-SLAM, a multi-agent cooperative SLAM framework that
integrates text semantics and WiFi signal features to enhance location
identification and loop closure detection. TWC-SLAM comprises a single-agent
front-end odometry module based on FAST-LIO2, a location identification and
loop closure detection module that leverages text semantics and WiFi features,
and a global mapping module. The agents are equipped with sensors capable of
capturing textual information and detecting WiFi signals. By correlating these
data sources, TWC-SLAM establishes a common location, facilitating point cloud
alignment across different agents' maps. Furthermore, the system employs loop
closure detection and optimization modules to achieve global optimization and
cohesive mapping. We evaluated our approach using an indoor dataset featuring
similar corridors, rooms, and text signs. The results demonstrate that TWC-SLAM
significantly improves the performance of cooperative SLAM systems in complex
environments with repetitive architectural features.

</details>


### [42] [PIP-LLM: Integrating PDDL-Integer Programming with LLMs for Coordinating Multi-Robot Teams Using Natural Language](https://arxiv.org/abs/2510.22784)
*Guangyao Shi,Yuwei Wu,Vijay Kumar,Gaurav S. Sukhatme*

Main category: cs.RO

TL;DR: PIP-LLM 提出了一种新的框架，通过将高层命令分解为团队层和机器人层的规划，有效地解决了多机器人协调中的任务分解和效率问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多机器人协调中效果不佳，主要体现在任务分解脆弱、可扩展性差和协调效率低，因此需要一种新的框架。

Method: PIP-LLM 采用了两级规划：团队层使用 PDDL 进行计划，而机器人层基于整数规划进行任务分配。

Result: PIP-LLM 是一种语言基础的协调框架，能够提高多机器人系统执行自然语言指令的能力。

Conclusion: PIP-LLM 在多个任务实验中表现出更高的计划成功率，并且在旅行成本和负载平衡方面优于现有的基准。

Abstract: Enabling robot teams to execute natural language commands requires
translating high-level instructions into feasible, efficient multi-robot plans.
While Large Language Models (LLMs) combined with Planning Domain Description
Language (PDDL) offer promise for single-robot scenarios, existing approaches
struggle with multi-robot coordination due to brittle task decomposition, poor
scalability, and low coordination efficiency.
  We introduce PIP-LLM, a language-based coordination framework that consists
of PDDL-based team-level planning and Integer Programming (IP) based
robot-level planning. PIP-LLMs first decomposes the command by translating the
command into a team-level PDDL problem and solves it to obtain a team-level
plan, abstracting away robot assignment. Each team-level action represents a
subtask to be finished by the team. Next, this plan is translated into a
dependency graph representing the subtasks' dependency structure. Such a
dependency graph is then used to guide the robot-level planning, in which each
subtask node will be formulated as an IP-based task allocation problem,
explicitly optimizing travel costs and workload while respecting robot
capabilities and user-defined constraints. This separation of planning from
assignment allows PIP-LLM to avoid the pitfalls of syntax-based decomposition
and scale to larger teams. Experiments across diverse tasks show that PIP-LLM
improves plan success rate, reduces maximum and average travel costs, and
achieves better load balancing compared to state-of-the-art baselines.

</details>


### [43] [Learning Neural Observer-Predictor Models for Limb-level Sampling-based Locomotion Planning](https://arxiv.org/abs/2510.22789)
*Abhijeet M. Kulkarni,Ioannis Poulakakis,Guoquan Huang*

Main category: cs.RO

TL;DR: 该论文提出了一种学习基础的观察者-预测器框架，用于提高四足机器人的运动预测精度，从而实现更安全的自主导航。


<details>
  <summary>Details</summary>
Motivation: 准确的全身运动预测对于四足机器人在复杂环境中的导航安全至关重要，现有的简化运动模型无法充分捕捉机器人的复杂动态特性。

Method: 通过使用具有可证明的UUB保证的神经观察者和高效能的预测器，制作出一个能够快速评估数千种潜在轨迹的系统。

Result: 在Vision 60四足机器人上，整合我们的神经预测器到基于MPPI的规划器中，硬件实验验证了系统在狭窄通道和小障碍物上的有效运动规划能力。

Conclusion: 该研究提出的学习基础观察者-预测器框架有效地提高了四足机器人在复杂环境中的运动预测精度，为安全自主导航提供了可靠的基础。

Abstract: Accurate full-body motion prediction is essential for the safe, autonomous
navigation of legged robots, enabling critical capabilities like limb-level
collision checking in cluttered environments. Simplified kinematic models often
fail to capture the complex, closed-loop dynamics of the robot and its
low-level controller, limiting their predictions to simple planar motion. To
address this, we present a learning-based observer-predictor framework that
accurately predicts this motion. Our method features a neural observer with
provable UUB guarantees that provides a reliable latent state estimate from a
history of proprioceptive measurements. This stable estimate initializes a
computationally efficient predictor, designed for the rapid, parallel
evaluation of thousands of potential trajectories required by modern
sampling-based planners. We validated the system by integrating our neural
predictor into an MPPI-based planner on a Vision 60 quadruped. Hardware
experiments successfully demonstrated effective, limb-aware motion planning in
a challenging, narrow passage and over small objects, highlighting our system's
ability to provide a robust foundation for high-performance, collision-aware
planning on dynamic robotic platforms.

</details>


### [44] [Analytical Swarm Chemistry: Characterization and Analysis of Emergent Swarm Behaviors](https://arxiv.org/abs/2510.22821)
*Ricardo Vega,Connor Mattson,Kevin Zhu,Daniel S. Brown,Cameron Nowzari*

Main category: cs.RO

TL;DR: 本文介绍了分析群体化学框架，旨在探索群体机器人系统中的涌现行为，通过相图分析和参数空间可视化，为现实世界中的可靠行为提供了基础。


<details>
  <summary>Details</summary>
Motivation: 群体机器人在众多应用中具有潜力，但由于简单局部交互所产生的涌现行为的难以预测，使得现实部署仍然稀少。

Method: 通过将宏观态定义与相图分析结合，系统地探索群体参数如何影响涌现行为，同时借鉴化学中的概念，处理参数如热力学变量进行可视化。

Result: 通过使用该框架，我们识别出产生特定行为（如旋转和扩散）的充分条件，并发现了参数空间中能可靠地生成这些行为的区域，同时在真实机器人上的初步验证表明这些区域与实际可观察行为相对应。

Conclusion: 本文提出的分析群体化学框架为现实世界的群体机器人系统提供了可预测和可靠的新方法，使得我们能够通过系统地探索参数空间来理解和控制涌现行为。

Abstract: Swarm robotics has potential for a wide variety of applications, but
real-world deployments remain rare due to the difficulty of predicting emergent
behaviors arising from simple local interactions. Traditional engineering
approaches design controllers to achieve desired macroscopic outcomes under
idealized conditions, while agent-based and artificial life studies explore
emergent phenomena in a bottom-up, exploratory manner. In this work, we
introduce Analytical Swarm Chemistry, a framework that integrates concepts from
engineering, agent-based and artificial life research, and chemistry. This
framework combines macrostate definitions with phase diagram analysis to
systematically explore how swarm parameters influence emergent behavior.
Inspired by concepts from chemistry, the framework treats parameters like
thermodynamic variables, enabling visualization of regions in parameter space
that give rise to specific behaviors. Applying this framework to agents with
minimally viable capabilities, we identify sufficient conditions for behaviors
such as milling and diffusion and uncover regions of the parameter space that
reliably produce these behaviors. Preliminary validation on real robots
demonstrates that these regions correspond to observable behaviors in practice.
By providing a principled, interpretable approach, this framework lays the
groundwork for predictable and reliable emergent behavior in real-world swarm
systems.

</details>


### [45] [Kinematically Controllable Cable Robots with Reconfigurable End-effectors](https://arxiv.org/abs/2510.22825)
*Nan Zhang*

Main category: cs.RO

TL;DR: 本研究设计了一种新的可重构末端执行器，成功扩大了缆驱动机器人的旋转工作空间，并消除了张力控制的复杂性。


<details>
  <summary>Details</summary>
Motivation: 传统增加缆线数量的方法虽然能扩大平移工作空间，但会导致缆线干扰和非唯一张力解的问题，从而增加运动学控制的难度。

Method: 设计了一种结构简单的可重构末端执行器，结合弹簧、螺旋槽轴和匹配的螺母，将末端执行器组件之间的相对线性运动转化为相对旋转。

Result: 通过引入轴承提供额外的旋转自由度，消除了冗余，使机器人能够仅通过运动学实现控制。

Conclusion: 通过设计简单的可重构末端执行器，扩展了缆驱动机器人的运动工作空间，使其能够仅通过运动学控制，而无需额外的张力传感和控制。

Abstract: To enlarge the translational workspace of cable-driven robots, one common
approach is to increase the number of cables. However, this introduces two
challenges: (1) cable interference significantly reduces the rotational
workspace, and (2) the solution of tensions in cables becomes non-unique,
resulting in difficulties for kinematic control of the robot. In this work, we
design structurally simple reconfigurable end-effectors for cable robots. By
incorporating a spring, a helical-grooved shaft, and a matching nut, relative
linear motions between end-effector components are converted into relative
rotations, thereby expanding the rotational workspace of the mechanism.
Meanwhile, a bearing is introduced to provide an additional rotational degree
of freedom, making the mechanism non-redundant. As a result, the robot's motion
can be controlled purely through kinematics without additional tension sensing
and control.

</details>


### [46] [Never Too Rigid to Reach: Adaptive Virtual Model Control with LLM- and Lyapunov-Based Reinforcement Learning](https://arxiv.org/abs/2510.22892)
*Jingzehua Xu,Yangyang Li,Yangfei Chen,Guanwen Xie,Shuai Zhang*

Main category: cs.RO

TL;DR: 提出了一种结合大语言模型和李雅普诺夫基础强化学习的自适应虚拟模型控制方法，以提高机器人在不确定环境中的适应能力和稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统控制管道在不确定环境中稳定性差，对扰动和不完整信息的适应性不足

Method: 提出自适应虚拟模型控制与大语言模型（LLM）和李雅普诺夫基础强化学习的结合

Result: 通过仿真验证示范，该方法在动态任务中有效平衡了竞争目标，实现了较优性能

Conclusion: 该方法展示了LLM指导与李雅普诺夫约束适应的协同效益，确保了在不确定环境下的安全可靠适应。

Abstract: Robotic arms are increasingly deployed in uncertain environments, yet
conventional control pipelines often become rigid and brittle when exposed to
perturbations or incomplete information. Virtual Model Control (VMC) enables
compliant behaviors by embedding virtual forces and mapping them into joint
torques, but its reliance on fixed parameters and limited coordination among
virtual components constrains adaptability and may undermine stability as task
objectives evolve. To address these limitations, we propose Adaptive VMC with
Large Language Model (LLM)- and Lyapunov-Based Reinforcement Learning (RL),
which preserves the physical interpretability of VMC while supporting
stability-guaranteed online adaptation. The LLM provides structured priors and
high-level reasoning that enhance coordination among virtual components,
improve sample efficiency, and facilitate flexible adjustment to varying task
requirements. Complementarily, Lyapunov-based RL enforces theoretical stability
constraints, ensuring safe and reliable adaptation under uncertainty. Extensive
simulations on a 7-DoF Panda arm demonstrate that our approach effectively
balances competing objectives in dynamic tasks, achieving superior performance
while highlighting the synergistic benefits of LLM guidance and
Lyapunov-constrained adaptation.

</details>


### [47] [HyPerNav: Hybrid Perception for Object-Oriented Navigation in Unknown Environment](https://arxiv.org/abs/2510.22917)
*Zecheng Yin,Hao Zhao,Zhen Li*

Main category: cs.RO

TL;DR: 本文提出HyPerNav，以Vision-Language Models整合局部和全局信息，显著提高机器人在未知环境中的导航性能。


<details>
  <summary>Details</summary>
Motivation: 提高机器人在未知环境中导航的有效感知，整合局部和全局信息以增强导航智能。

Method: Hybrid Perception Navigation (HyPerNav)

Result: 在大量的模拟评估和实际验证中，HyPerNav方法在导航性能上超越了流行基线，实现了最先进的表现。

Conclusion: 混合感知方法有效捕捉更丰富的线索，通过同时利用自我观察和顶视地图的信息，增强了对象查找的能力。

Abstract: Objective-oriented navigation(ObjNav) enables robot to navigate to target
object directly and autonomously in an unknown environment. Effective
perception in navigation in unknown environment is critical for autonomous
robots. While egocentric observations from RGB-D sensors provide abundant local
information, real-time top-down maps offer valuable global context for ObjNav.
Nevertheless, the majority of existing studies focus on a single source, seldom
integrating these two complementary perceptual modalities, despite the fact
that humans naturally attend to both. With the rapid advancement of
Vision-Language Models(VLMs), we propose Hybrid Perception Navigation
(HyPerNav), leveraging VLMs' strong reasoning and vision-language understanding
capabilities to jointly perceive both local and global information to enhance
the effectiveness and intelligence of navigation in unknown environments. In
both massive simulation evaluation and real-world validation, our methods
achieved state-of-the-art performance against popular baselines. Benefiting
from hybrid perception approach, our method captures richer cues and finds the
objects more effectively, by simultaneously leveraging information
understanding from egocentric observations and the top-down map. Our ablation
study further proved that either of the hybrid perception contributes to the
navigation performance.

</details>


### [48] [End-to-End Design and Validation of a Low-Cost Stewart Platform with Nonlinear Estimation and Control](https://arxiv.org/abs/2510.22949)
*Benedictus C. G. Cinun,Tua A. Tamba,Immanuel R. Santjoko,Xiaofeng Wang,Michael A. Gunarso,Bin Hu*

Main category: cs.RO

TL;DR: 本论文展示了一种低成本Stewart平台原型的完整设计、控制及实验验证，旨在为研究和教育提供可负担且高效的机器人测试平台。


<details>
  <summary>Details</summary>
Motivation: 为了提供一种经济实用的机器人测试平台，促进研究与教育。

Method: 采用基于反馈线性化的强健轨迹跟踪控制器，结合LQR方案，并使用扩展卡尔曼滤波器融合IMU与执行器编码器反馈。

Result: 实验结果显示，该平台能够实现有效的轨迹跟踪和实时状态估计。

Conclusion: 该平台经过验证，能够有效跟踪轨迹并实时估计状态，展示了其作为高效且多功能研究与教育工具的潜力。

Abstract: This paper presents the complete design, control, and experimental validation
of a low-cost Stewart platform prototype developed as an affordable yet capable
robotic testbed for research and education. The platform combines off the shelf
components with 3D printed and custom fabricated parts to deliver full six
degrees of freedom motions using six linear actuators connecting a moving
platform to a fixed base. The system software integrates dynamic modeling, data
acquisition, and real time control within a unified framework. A robust
trajectory tracking controller based on feedback linearization, augmented with
an LQR scheme, compensates for the platform's nonlinear dynamics to achieve
precise motion control. In parallel, an Extended Kalman Filter fuses IMU and
actuator encoder feedback to provide accurate and reliable state estimation
under sensor noise and external disturbances. Unlike prior efforts that
emphasize only isolated aspects such as modeling or control, this work delivers
a complete hardware-software platform validated through both simulation and
experiments on static and dynamic trajectories. Results demonstrate effective
trajectory tracking and real-time state estimation, highlighting the platform's
potential as a cost effective and versatile tool for advanced research and
educational applications.

</details>


### [49] [An Intelligent Water-Saving Irrigation System Based on Multi-Sensor Fusion and Visual Servoing Control](https://arxiv.org/abs/2510.23003)
*ZhengKai Huang,YiKun Wang,ChenYu Hui,XiaoCheng*

Main category: cs.RO

TL;DR: 该论文提出了一种智能节水灌溉系统，解决精准农业中的水资源利用不当和地形适应性差等问题。


<details>
  <summary>Details</summary>
Motivation: 旨在提高精准农业中的水资源管理效率，解决水资源浪费问题。

Method: 系统集成了先进的计算机视觉、机器人控制和实时稳定化技术，通过多传感器融合的方法实现。

Result: 在三种模拟农业环境中，该系统表现出显著的水消耗减少和高水利用效率。

Conclusion: 实验结果表明，与传统洪灌相比，该系统在水消耗上减少了30-50%，水利用效率在所有测试情况下都超过了92%。

Abstract: This paper introduces an intelligent water-saving irrigation system designed
to address critical challenges in precision agriculture, such as inefficient
water use and poor terrain adaptability. The system integrates advanced
computer vision, robotic control, and real-time stabilization technologies via
a multi-sensor fusion approach. A lightweight YOLO model, deployed on an
embedded vision processor (K210), enables real-time plant container detection
with over 96% accuracy under varying lighting conditions. A simplified hand-eye
calibration algorithm-designed for 'handheld camera' robot arm
configurations-ensures that the end effector can be precisely positioned, with
a success rate exceeding 90%. The active leveling system, driven by the
STM32F103ZET6 main control chip and JY901S inertial measurement data, can
stabilize the irrigation platform on slopes up to 10 degrees, with a response
time of 1.8 seconds. Experimental results across three simulated agricultural
environments (standard greenhouse, hilly terrain, complex lighting) demonstrate
a 30-50% reduction in water consumption compared to conventional flood
irrigation, with water use efficiency exceeding 92% in all test cases.

</details>


### [50] [ManiDP: Manipulability-Aware Diffusion Policy for Posture-Dependent Bimanual Manipulation](https://arxiv.org/abs/2510.23016)
*Zhuo Li,Junjia Liu,Dianxi Li,Tao Teng,Miao Li,Sylvain Calinon,Darwin Caldwell,Fei Chen*

Main category: cs.RO

TL;DR: 提出了Manipulability-Aware Diffusion Policy方法，通过考虑姿态依赖的任务特征，在双手技能学习中显著提升了操作成功率和任务兼容性。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视了姿态依赖性任务特征的学习，这些特征对调整双臂配置以满足特定力量和速度要求至关重要。

Method: 通过模仿学习的方法生成合理的双手轨迹，并优化双臂配置以满足姿态依赖的任务要求，同时提取专家示范中的双手可操作性特征，使用基于黎曼几何的概率模型进行编码，最后在条件扩散过程中引入这些编码特征。

Result: 在六个真实世界的双手任务上，ManiDP的实验结果显示平均操作成功率提高了39.33%，任务兼容性提高了0.45，优于基线方法。

Conclusion: 提出的Manipulability-Aware Diffusion Policy方法在双手技能学习上表现优异，成功提高了操作成功率与任务兼容性，强调了姿态相关的机器人先验知识的重要性。

Abstract: Recent work has demonstrated the potential of diffusion models in robot
bimanual skill learning. However, existing methods ignore the learning of
posture-dependent task features, which are crucial for adapting dual-arm
configurations to meet specific force and velocity requirements in dexterous
bimanual manipulation. To address this limitation, we propose
Manipulability-Aware Diffusion Policy (ManiDP), a novel imitation learning
method that not only generates plausible bimanual trajectories, but also
optimizes dual-arm configurations to better satisfy posture-dependent task
requirements. ManiDP achieves this by extracting bimanual manipulability from
expert demonstrations and encoding the encapsulated posture features using
Riemannian-based probabilistic models. These encoded posture features are then
incorporated into a conditional diffusion process to guide the generation of
task-compatible bimanual motion sequences. We evaluate ManiDP on six real-world
bimanual tasks, where the experimental results demonstrate a 39.33$\%$ increase
in average manipulation success rate and a 0.45 improvement in task
compatibility compared to baseline methods. This work highlights the importance
of integrating posture-relevant robotic priors into bimanual skill diffusion to
enable human-like adaptability and dexterity.

</details>


### [51] [Seq-DeepIPC: Sequential Sensing for End-to-End Control in Legged Robot Navigation](https://arxiv.org/abs/2510.23057)
*Oskar Natan,Jun Miura*

Main category: cs.RO

TL;DR: Seq-DeepIPC是一种用于无人腿部机器人导航的顺序端到端模型，结合多模态感知与控制，无需复杂的IMU，适应边缘设备，展示了强大的导航能力。


<details>
  <summary>Details</summary>
Motivation: 为了提高腿部机器人在真实环境中的导航能力，结合多种感知信息优化感知与控制。

Method: Seq-DeepIPC模型通过多模态感知（RGB-D + GNSS）和时间融合来实现，使用EfficientNet-B0作为编码器，简化航向估计。

Result: Seq-DeepIPC在与其他基线比较时显示出更好的感知和控制效果，尤其在开放区域表现出色。

Conclusion: Seq-DeepIPC扩展了端到端导航的应用，表现出在多种环境中的鲁棒性，适用于未来研究。

Abstract: We present Seq-DeepIPC, a sequential end-to-end perception-to-control model
for legged robot navigation in realworld environments. Seq-DeepIPC advances
intelligent sensing for autonomous legged navigation by tightly integrating
multi-modal perception (RGB-D + GNSS) with temporal fusion and control. The
model jointly predicts semantic segmentation and depth estimation, giving
richer spatial features for planning and control. For efficient deployment on
edge devices, we use EfficientNet-B0 as the encoder, reducing computation while
maintaining accuracy. Heading estimation is simplified by removing the noisy
IMU and instead computing the bearing angle directly from consecutive GNSS
positions. We collected a larger and more diverse dataset that includes both
road and grass terrains, and validated Seq-DeepIPC on a robot dog. Comparative
and ablation studies show that sequential inputs improve perception and control
in our models, while other baselines do not benefit. Seq-DeepIPC achieves
competitive or better results with reasonable model size; although GNSS-only
heading is less reliable near tall buildings, it is robust in open areas.
Overall, Seq-DeepIPC extends end-to-end navigation beyond wheeled robots to
more versatile and temporally-aware systems. To support future research, we
will release the codes to our GitHub repository at
https://github.com/oskarnatan/Seq-DeepIPC.

</details>


### [52] [Awakening Facial Emotional Expressions in Human-Robot](https://arxiv.org/abs/2510.23059)
*Yongtong Zhu,Lei Li,Iggy Qian,WenBin Zhou,Ye Yuan,Qingdu Li,Na Liu,Jianwei Zhang*

Main category: cs.RO

TL;DR: 本研究提出了一种新型的仿生机器人面部，并开发了基于KAN网络的自我训练框架，使机器人能够自主学习和生成面部表情。


<details>
  <summary>Details</summary>
Motivation: 提高人形社交机器人的面部表情生成能力，以实现更自然的人机交互。

Method: 研究采用了基于KAN和注意力机制的端到端学习框架，并设计了自动数据收集系统以构建数据集。

Result: 本研究设计了一种高度仿生的机器人面部，可以自主学习人类的面部表情，从而提高人机交互的自然性和情感表达的准确性。

Conclusion: 该研究首次提供了开源的人形社交机器人面部数据集，并通过综合评估证明了其在不同测试对象间的面部模仿能力的准确性和多样性。

Abstract: The facial expression generation capability of humanoid social robots is
critical for achieving natural and human-like interactions, playing a vital
role in enhancing the fluidity of human-robot interactions and the accuracy of
emotional expression. Currently, facial expression generation in humanoid
social robots still relies on pre-programmed behavioral patterns, which are
manually coded at high human and time costs. To enable humanoid robots to
autonomously acquire generalized expressive capabilities, they need to develop
the ability to learn human-like expressions through self-training. To address
this challenge, we have designed a highly biomimetic robotic face with
physical-electronic animated facial units and developed an end-to-end learning
framework based on KAN (Kolmogorov-Arnold Network) and attention mechanisms.
Unlike previous humanoid social robots, we have also meticulously designed an
automated data collection system based on expert strategies of facial motion
primitives to construct the dataset. Notably, to the best of our knowledge,
this is the first open-source facial dataset for humanoid social robots.
Comprehensive evaluations indicate that our approach achieves accurate and
diverse facial mimicry across different test subjects.

</details>


### [53] [Breaking the Circle: An Autonomous Control-Switching Strategy for Stable Orographic Soaring in MAVs](https://arxiv.org/abs/2510.23084)
*Sunyou Hwang,Christophe De Wagter,Bart Remes,Guido de Croon*

Main category: cs.RO

TL;DR: SAOS 方法通过选择性控制改善微型航空器在气流 soaring 中的性能，增强了能效和飞行稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决微型航空器在气流 soaring 中的控制冲突，减少能耗和风险

Method: SAOS: Switched Control for Autonomous Orographic Soaring

Result: 通过选择性控制横轴或纵轴，SAOS 改善了位置收敛、降低油门使用和减轻因俯仰-翻滚耦合导致的翻滚振荡

Conclusion: SAOS 方法有效提升了在受限飞行环境中的能量效率和稳定性。

Abstract: Orographic soaring can significantly extend the endurance of micro aerial
vehicles (MAVs), but circling behavior, arising from control conflicts between
the longitudinal and vertical axes, increases energy consumption and the risk
of divergence. We propose a control switching method, named SAOS: Switched
Control for Autonomous Orographic Soaring, which mitigates circling behavior by
selectively controlling either the horizontal or vertical axis, effectively
transforming the system from underactuated to fully actuated during soaring.
Additionally, the angle of attack is incorporated into the INDI controller to
improve force estimation. Simulations with randomized initial positions and
wind tunnel experiments on two MAVs demonstrate that the SAOS improves position
convergence, reduces throttle usage, and mitigates roll oscillations caused by
pitch-roll coupling. These improvements enhance energy efficiency and flight
stability in constrained soaring environments.

</details>


### [54] [An Automated Tape Laying System Employing a Uniaxial Force Control Device](https://arxiv.org/abs/2510.23109)
*Bernhard Rameder,Hubert Gattringer,Ronald Naderer,Andreas Mueller*

Main category: cs.RO

TL;DR: 本文设计了一种集成单轴力和温度控制的成本效益高的自动胶带铺设系统，验证了其在复杂形状粘合中的实用性。


<details>
  <summary>Details</summary>
Motivation: 确保胶带在粘合过程中具有适当的压实力和熔化效果，以实现最佳的层间结合。

Method: 设计一个成本效益高的自动胶带铺设系统，集成单轴力控制和温度控制。

Result: 系统模块包括胶带存储卷轴、引导辊、加工单元、加热区和压实单元，功能通过实验结果验证。

Conclusion: 通过特定的机器人控制概念，该系统有效处理了紧凑和复杂形状的材料粘合，并通过实验验证了各子系统的功能。

Abstract: This paper deals with the design of a cost effective automated tape laying
system (ATL system) with integrated uniaxial force control to ensure the
necessary compaction forces as well as with an accurate temperature control to
guarantee the used tape being melted appropriate. It is crucial to control the
substrate and the oncoming tape onto a specific temperature level to ensure an
optimal consolidation between the different layers of the product. Therefore,
it takes several process steps from the spooled tape on the coil until it is
finally tacked onto the desired mold. The different modules are divided into
the tape storage spool, a tape-guiding roller, a tape processing unit, a
heating zone and the consolidation unit. Moreover, a special robot control
concept for testing the ATL system is presented. In contrast to many other
systems, with this approach, the tape laying device is spatially fixed and the
shape is moved accordingly by the robot, which allows for handling of rather
compact and complex shapes. The functionality of the subsystems and the taping
process itself was finally approved in experimental results using a carbon
fiber reinforced HDPE tape.

</details>


### [55] [OmniDexGrasp: Generalizable Dexterous Grasping via Foundation Model and Force Feedback](https://arxiv.org/abs/2510.23119)
*Yi-Lin Wei,Zhexi Luo,Yuhao Lin,Mu Lin,Zhizhao Liang,Shuoyu Chen,Wei-Shi Zheng*

Main category: cs.RO

TL;DR: 本论文提出OmniDexGrasp框架，通过基础模型与转移控制策略结合，提升机器人在多样化抓取及操控任务中的效能。


<details>
  <summary>Details</summary>
Motivation: 旨在解决现有机器人抓取方法在跨任务和物体泛化能力上的不足。

Method: 提出OmniDexGrasp框架，包括基础模型、图像到机器人动作的转移策略以及力感知适应性抓取策略。

Result: 实验结果验证了OmniDexGrasp在不同用户提示、抓取任务及灵巧手上的有效性，并展示了其扩展能力。

Conclusion: OmniDexGrasp有效提升了机器人在多样化任务中的操控能力与稳定性。

Abstract: Enabling robots to dexterously grasp and manipulate objects based on human
commands is a promising direction in robotics. However, existing approaches are
challenging to generalize across diverse objects or tasks due to the limited
scale of semantic dexterous grasp datasets. Foundation models offer a new way
to enhance generalization, yet directly leveraging them to generate feasible
robotic actions remains challenging due to the gap between abstract model
knowledge and physical robot execution. To address these challenges, we propose
OmniDexGrasp, a generalizable framework that achieves omni-capabilities in user
prompting, dexterous embodiment, and grasping tasks by combining foundation
models with the transfer and control strategies. OmniDexGrasp integrates three
key modules: (i) foundation models are used to enhance generalization by
generating human grasp images supporting omni-capability of user prompt and
task; (ii) a human-image-to-robot-action transfer strategy converts human
demonstrations into executable robot actions, enabling omni dexterous
embodiment; (iii) force-aware adaptive grasp strategy ensures robust and stable
grasp execution. Experiments in simulation and on real robots validate the
effectiveness of OmniDexGrasp on diverse user prompts, grasp task and dexterous
hands, and further results show its extensibility to dexterous manipulation
tasks.

</details>


### [56] [Reliable Robotic Task Execution in the Face of Anomalies](https://arxiv.org/abs/2510.23121)
*Bharath Santhanam,Alex Mitrevski,Santosh Thoduka,Sebastian Houben,Teena Hassan*

Main category: cs.RO

TL;DR: 本研究提出了一种将学习策略与视觉异常检测和恢复行为结合的框架，以应对开放环境中的复杂性和执行失败.


<details>
  <summary>Details</summary>
Motivation: 现有学习策略在复杂开放环境中存在执行失败的问题，缺乏识别和反应失败的机制。

Method: 训练一种异常检测模型，并在策略执行过程中集成该模型以检测偏差，触发三层恢复过程。

Result: 在不同场景中验证了该方法，显示在异常环境下执行成功率提高。

Conclusion: 通过将策略执行与异常检测和恢复集成，可以提高机器人在多种异常环境中的执行成功率。

Abstract: Learned robot policies have consistently been shown to be versatile, but they
typically have no built-in mechanism for handling the complexity of open
environments, making them prone to execution failures; this implies that
deploying policies without the ability to recognise and react to failures may
lead to unreliable and unsafe robot behaviour. In this paper, we present a
framework that couples a learned policy with a method to detect visual
anomalies during policy deployment and to perform recovery behaviours when
necessary, thereby aiming to prevent failures. Specifically, we train an
anomaly detection model using data collected during nominal executions of a
trained policy. This model is then integrated into the online policy execution
process, so that deviations from the nominal execution can trigger a
three-level sequential recovery process that consists of (i) pausing the
execution temporarily, (ii) performing a local perturbation of the robot's
state, and (iii) resetting the robot to a safe state by sampling from a learned
execution success model. We verify our proposed method in two different
scenarios: (i) a door handle reaching task with a Kinova Gen3 arm using a
policy trained in simulation and transferred to the real robot, and (ii) an
object placing task with a UFactory xArm 6 using a general-purpose policy
model. Our results show that integrating policy execution with anomaly
detection and recovery increases the execution success rate in environments
with various anomalies, such as trajectory deviations and adversarial human
interventions.

</details>


### [57] [Combining High Level Scheduling and Low Level Control to Manage Fleets of Mobile Robots](https://arxiv.org/abs/2510.23129)
*Sabino Francesco Roselli,Ze Zhang,Knut Åkesson*

Main category: cs.RO

TL;DR: 提出了一种两层框架，用于工业环境中移动机器人的高效调度与控制，确保安全操作和迅速响应变化。


<details>
  <summary>Details</summary>
Motivation: 在动态设置中对大型移动机器人队伍进行可扩展协调

Method: 两层框架结合高层调度与低层控制

Result: 在模拟的2D环境中实现高任务完成率和稳健表现，支持快速重新调度

Conclusion: 该模块化框架适用于复杂的真实工业场景，具备计算可行性和灵活性。

Abstract: The deployment of mobile robots for material handling in industrial
environments requires scalable coordination of large fleets in dynamic
settings. This paper presents a two-layer framework that combines high-level
scheduling with low-level control. Tasks are assigned and scheduled using the
compositional algorithm ComSat, which generates time-parameterized routes for
each robot. These schedules are then used by a distributed Model Predictive
Control (MPC) system in real time to compute local reference trajectories,
accounting for static and dynamic obstacles. The approach ensures safe,
collision-free operation, and supports rapid rescheduling in response to
disruptions such as robot failures or environmental changes. We evaluate the
method in simulated 2D environments with varying road capacities and traffic
conditions, demonstrating high task completion rates and robust behavior even
under congestion. The modular structure of the framework allows for
computational tractability and flexibility, making it suitable for deployment
in complex, real-world industrial scenarios.

</details>


### [58] [TARC: Time-Adaptive Robotic Control](https://arxiv.org/abs/2510.23176)
*Arnav Sukhija,Lenart Treven,Jin Cheng,Florian Dörfler,Stelian Coros,Andreas Krause*

Main category: cs.RO

TL;DR: 提出了一种强化学习方法，使机器人能够根据情况需求自适应调节控制频率，实验验证表明该方法在多种平台上效率优于固定频率控制。


<details>
  <summary>Details</summary>
Motivation: 固定频率控制在机器人技术中存在低频控制效率与高频控制鲁棒性之间的权衡，而适应性生物系统没有这个限制。

Method: 通过强化学习方法，设计策略共同选择控制动作及其应用持续时间，实现机器人根据情况需求自动调节控制频率。

Result: 在两个不同的硬件平台（高速RC车和四足机器人）上通过零样本的仿真到现实实验验证了该方法，其奖励与固定频率基线相匹配或超出，同时显著降低了控制频率，并在真实环境下表现出自适应频率控制。

Conclusion: 我们的研究表明，通过强化学习，机器人可以实现自适应控制频率，从而提高控制效率和鲁棒性。

Abstract: Fixed-frequency control in robotics imposes a trade-off between the
efficiency of low-frequency control and the robustness of high-frequency
control, a limitation not seen in adaptable biological systems. We address this
with a reinforcement learning approach in which policies jointly select control
actions and their application durations, enabling robots to autonomously
modulate their control frequency in response to situational demands. We
validate our method with zero-shot sim-to-real experiments on two distinct
hardware platforms: a high-speed RC car and a quadrupedal robot. Our method
matches or outperforms fixed-frequency baselines in terms of rewards while
significantly reducing the control frequency and exhibiting adaptive frequency
control under real-world conditions.

</details>


### [59] [Workspace Registration and Collision Detection for Industrial Robotics Applications](https://arxiv.org/abs/2510.23227)
*Klaus Zauner,Josef El Dib,Hubert Gattringer,Andreas Mueller*

Main category: cs.RO

TL;DR: 本文旨在比较不同传感器对机器人运动规划环境的影响，展示从获取环境数据到识别碰撞物体的全过程，并探讨机器人与环境间的碰撞检测。


<details>
  <summary>Details</summary>
Motivation: 确保机器人在复杂环境中安全移动，减少碰撞风险，依赖于精确的环境知识和传感器支持。

Method: 采用点云数据获取环境信息，使用区域生长分割和VCCS算法识别碰撞物体，并对点集进行近似。

Result: 比较了不同传感器的效果，揭示了从数据获取到碰撞检测的完整流程，为机器人运动规划提供了实用指导。

Conclusion: 不同传感器在环境监测和碰撞检测方面的有效性对机器人运动规划至关重要。

Abstract: Motion planning for robotic manipulators relies on precise knowledge of the
environment in order to be able to define restricted areas and to take
collision objects into account. To capture the workspace, point clouds of the
environment are acquired using various sensors. The collision objects are
identified by region growing segmentation and VCCS algorithm. Subsequently the
point clusters are approximated. The aim of the present paper is to compare
different sensors, to illustrate the process from detection to the finished
collision environment and to detect collisions between the robot and this
environment.

</details>


### [60] [Optimal Dimensioning of Elastic-Link Manipulators regarding Lifetime Estimation](https://arxiv.org/abs/2510.23234)
*Klaus Zauner,Hubert Gattringer,Andreas Mueller*

Main category: cs.RO

TL;DR: 研究提出了一种优化方法，通过寿命估计和几何优化，提升柔性串联机器人的设计与控制性能，重点在于降低重量和振动。


<details>
  <summary>Details</summary>
Motivation: 提高工业自动化的可持续性，重点在于轻量化设计及其与时间和能量最优控制的整合。

Method: 利用疲劳分析结合雨流计数算法和临界切平面法，对弹性链接机器人的寿命进行估计。

Result: 最终的机器人几何形状通过Pareto前沿选择，平衡了寿命和振动特性。本研究以一个具有三个自由度的关节机器人为例进行了说明。

Conclusion: 该研究提出了一种方法，通过弹性链接机器人的寿命估计和几何优化，提升柔性串联机器人在拾取和放置操作中的性能。

Abstract: Resourceful operation and design of robots is key for sustainable industrial
automation. This will be enabled by lightweight design along with time and
energy optimal control of robotic manipulators. Design and control of such
systems is intertwined as the control must take into account inherent
mechanical compliance while the design must accommodate the dynamic
requirements demanded by the control. As basis for such design optimization, a
method for estimating the lifetime of elastic link robotic manipulators is
presented. This is applied to the geometry optimization of flexible serial
manipulators performing pick-and-place operations, where the optimization
objective is a combination of overall weight and vibration amplitudes. The
lifetime estimation draws from a fatigue analysis combining the rainflow
counting algorithm and the method of critical cutting plane. Tresca hypothesis
is used to formulate an equivalent stress, and linear damage accumulation is
assumed. The final robot geometry is selected from a Pareto front as a tradeoff
of lifetime and vibration characteristic. The method is illustrated for a three
degrees of freedom articulated robotic manipulator.

</details>


### [61] [Deep Active Inference with Diffusion Policy and Multiple Timescale World Model for Real-World Exploration and Navigation](https://arxiv.org/abs/2510.23258)
*Riko Yokozawa,Kentaro Fujii,Yuta Nomura,Shingo Murata*

Main category: cs.RO

TL;DR: 提出了一种深度主动推理框架，使机器人在真实环境中能够更有效地进行探索和目标导航。


<details>
  <summary>Details</summary>
Motivation: 在真实环境中，机器人导航需要探索以获取环境信息，并进行目标导向的导航以到达指定目标，基于自由能原理的主动推理提供了一个统一的框架。

Method: 提出了一种深度AIF框架，结合扩散策略作为策略模型和多时间规模递归状态空间模型（MTRSSM）作为世界模型。

Result: 通过实验证明，该框架在要求探索的场景中成功率更高，碰撞更少。

Conclusion: 基于预期自由能最小化的主动推理（AIF）框架能够统一探索和目标导向导航，实现在真实世界中的机器人导航中取得更高的成功率和更少的碰撞。

Abstract: Autonomous robotic navigation in real-world environments requires exploration
to acquire environmental information as well as goal-directed navigation in
order to reach specified targets. Active inference (AIF) based on the
free-energy principle provides a unified framework for these behaviors by
minimizing the expected free energy (EFE), thereby combining epistemic and
extrinsic values. To realize this practically, we propose a deep AIF framework
that integrates a diffusion policy as the policy model and a multiple timescale
recurrent state-space model (MTRSSM) as the world model. The diffusion policy
generates diverse candidate actions while the MTRSSM predicts their
long-horizon consequences through latent imagination, enabling action selection
that minimizes EFE. Real-world navigation experiments demonstrated that our
framework achieved higher success rates and fewer collisions compared with the
baselines, particularly in exploration-demanding scenarios. These results
highlight how AIF based on EFE minimization can unify exploration and
goal-directed navigation in real-world robotic settings.

</details>


### [62] [Precise Time Delay Measurement and Compensation for Tightly Coupled Underwater SINS/piUSBL Navigation](https://arxiv.org/abs/2510.23286)
*Jin Huang,Yingqiang Wang,Haoda Li,Zichen Liu,Zhikun Wang,Ying Chen*

Main category: cs.RO

TL;DR: 水下整合导航系统中，时间同步问题导致精度下降。本文提出的紧耦合导航框架通过新颖的延迟测量策略，有效提升了导航精度，并减少了误差。


<details>
  <summary>Details</summary>
Motivation: 在水下多传感器系统中，时间同步问题显著影响测量准确性，尤其是在声学定位系统中，因此亟需一种新方法来解决这一挑战。

Method: 整合piUSBL声学定位系统、SINS和深度计，使用新型延迟测量策略结合声学信号处理来同步时间，定义延迟为可量化参数，从而实现显式估计声学传播与系统处理延迟。

Result: 提出了一种紧耦合的导航框架，整合了被动倒置超短基线（piUSBL）声学定位系统、非固定惯性导航系统（SINS）和深度计，在精确时间同步下对数据进行融合，显著减少了导航中的时间延迟误差，提升了水下导航精度

Conclusion: 精确的延迟测量与补偿不仅提升了水下导航的准确性，还为声学定位集成提供了通用框架，促进了在多传感器系统中的时间对齐与数据融合。

Abstract: In multi-sensor systems, time synchronization between sensors is a
significant challenge, and this issue is particularly pronounced in underwater
integrated navigation systems incorporating acoustic positioning. Such systems
are highly susceptible to time delay, which can significantly degrade accuracy
when measurement and fusion moments are misaligned. To address this challenge,
this paper introduces a tightly coupled navigation framework that integrates a
passive inverted ultra-short baseline (piUSBL) acoustic positioning system, a
strapdown inertial navigation system (SINS), and a depth gauge under precise
time synchronization. The framework fuses azimuth and slant range from the
piUSBL with depth data, thereby avoiding poor vertical-angle observability in
planar arrays. A novel delay measurement strategy is introduced, combining
synchronized timing with acoustic signal processing, which redefines
delay-traditionally an unobservable error-into a quantifiable parameter,
enabling explicit estimation of both acoustic propagation and system processing
delays. Simulations and field experiments confirm the feasibility of the
proposed method, with delay-compensated navigation reducing RMSE by 40.45% and
maximum error by 32.55%. These findings show that precise delay measurement and
compensation not only enhance underwater navigation accuracy but also establish
a generalizable framework for acoustic positioning integration, offering
valuable insights into time alignment and data fusion in latency-sensitive
multi-sensor systems.

</details>


### [63] [Transferable Deep Reinforcement Learning for Cross-Domain Navigation: from Farmland to the Moon](https://arxiv.org/abs/2510.23329)
*Shreya Santra,Thomas Robbins,Kazuya Yoshida*

Main category: cs.RO

TL;DR: 本研究探讨了深度强化学习策略在不同模拟域间的泛化能力，通过农业探测器的3D模拟验证了政策在月球环境中的有效性。


<details>
  <summary>Details</summary>
Motivation: 在不确定的环境中高效导航是机器人技术的重要需求，传统方法需大量环境特定调整，限制了可扩展性。

Method: 使用深度强化学习 (DRL) 的策略泛化

Result: 训练的策略在月球模拟环境中以接近50\%的成功率有效，表明在地面条件下训练的策略能够在新域中转移，而无需额外训练。

Conclusion: 跨域的DRL策略转移为未来行星探索任务的自适应导航提供了一种有前景的方法，且能降低再训练成本。

Abstract: Autonomous navigation in unstructured environments is essential for field and
planetary robotics, where robots must efficiently reach goals while avoiding
obstacles under uncertain conditions. Conventional algorithmic approaches often
require extensive environment-specific tuning, limiting scalability to new
domains. Deep Reinforcement Learning (DRL) provides a data-driven alternative,
allowing robots to acquire navigation strategies through direct interactions
with their environment. This work investigates the feasibility of DRL policy
generalization across visually and topographically distinct simulated domains,
where policies are trained in terrestrial settings and validated in a zero-shot
manner in extraterrestrial environments. A 3D simulation of an agricultural
rover is developed and trained using Proximal Policy Optimization (PPO) to
achieve goal-directed navigation and obstacle avoidance in farmland settings.
The learned policy is then evaluated in a lunar-like simulated environment to
assess transfer performance. The results indicate that policies trained under
terrestrial conditions retain a high level of effectiveness, achieving close to
50\% success in lunar simulations without the need for additional training and
fine-tuning. This underscores the potential of cross-domain DRL-based policy
transfer as a promising approach to developing adaptable and efficient
autonomous navigation for future planetary exploration missions, with the added
benefit of minimizing retraining costs.

</details>


### [64] [Large language model-based task planning for service robots: A review](https://arxiv.org/abs/2510.23357)
*Shaohan Bian,Ying Zhang,Guohui Tian,Zhiqiang Miao,Edmond Q. Wu,Simon X. Yang,Changchun Hua*

Main category: cs.RO

TL;DR: 本文综述了大型语言模型在服务机器人任务规划中的应用，涵盖了技术基础、认知核心角色、不同输入模式下的任务规划及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型和机器人技术的快速发展，服务机器人在日常生活中变得越来越重要，因此需要强大、准确的任务规划能力来提供智能和高效的服务。

Method: 回顾大型语言模型的发展及基础技术，包括预训练、微调、检索增强生成和提示工程，并分析其在自动决策中的应用。

Result: 本论文全面概述了大型语言模型在服务机器人中的整合，重点讨论其在增强机器人任务规划中的作用，并分析了在复杂非结构化家庭环境中的应用。

Conclusion: 本文总结了当前研究中的关键挑战和局限性，并提出了提升服务机器人任务规划能力的未来方向。

Abstract: With the rapid advancement of large language models (LLMs) and robotics,
service robots are increasingly becoming an integral part of daily life,
offering a wide range of services in complex environments. To deliver these
services intelligently and efficiently, robust and accurate task planning
capabilities are essential. This paper presents a comprehensive overview of the
integration of LLMs into service robotics, with a particular focus on their
role in enhancing robotic task planning. First, the development and
foundational techniques of LLMs, including pre-training, fine-tuning,
retrieval-augmented generation (RAG), and prompt engineering, are reviewed. We
then explore the application of LLMs as the cognitive core-`brain'-of service
robots, discussing how LLMs contribute to improved autonomy and
decision-making. Furthermore, recent advancements in LLM-driven task planning
across various input modalities are analyzed, including text, visual, audio,
and multimodal inputs. Finally, we summarize key challenges and limitations in
current research and propose future directions to advance the task planning
capabilities of service robots in complex, unstructured domestic environments.
This review aims to serve as a valuable reference for researchers and
practitioners in the fields of artificial intelligence and robotics.

</details>


### [65] [T-ESKF: Transformed Error-State Kalman Filter for Consistent Visual-Inertial Navigation](https://arxiv.org/abs/2510.23359)
*Chungeng Tian,Ning Hao,Fenghua He*

Main category: cs.RO

TL;DR: 本文提出了一种新的方法T-ESKF，通过线性时变变换提高视觉惯性导航系统的可观察性，经过验证表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 针对视觉惯性导航系统中由于可观察性不匹配导致的估计不一致问题，寻求改进的估计方法。

Method: 采用线性时变变换处理误差状态，在误差状态卡尔曼滤波器中应用该变换以提高可观察性。

Result: 经过大量实验，T-ESKF在性能上优于或至少与现有最先进方法相当。

Conclusion: 通过新的变换技术，T-ESKF方法能有效解决视觉惯性导航系统中的可观察性不匹配问题，并在多次实验中验证了其优越性。

Abstract: This paper presents a novel approach to address the inconsistency problem
caused by observability mismatch in visual-inertial navigation systems (VINS).
The key idea involves applying a linear time-varying transformation to the
error-state within the Error-State Kalman Filter (ESKF). This transformation
ensures that \textrr{the unobservable subspace of the transformed error-state
system} becomes independent of the state, thereby preserving the correct
observability of the transformed system against variations in linearization
points. We introduce the Transformed ESKF (T-ESKF), a consistent VINS estimator
that performs state estimation using the transformed error-state system.
Furthermore, we develop an efficient propagation technique to accelerate the
covariance propagation based on the transformation relationship between the
transition and accumulated matrices of T-ESKF and ESKF. We validate the
proposed method through extensive simulations and experiments, demonstrating
better (or competitive at least) performance compared to state-of-the-art
methods. The code is available at github.com/HITCSC/T-ESKF.

</details>


### [66] [Full-Dynamics Real-Time Nonlinear Model Predictive Control of Heavy-Duty Hydraulic Manipulator for Trajectory Tracking Tasks](https://arxiv.org/abs/2510.23386)
*Alvaro Paz,Mahdi Hejrati,Pauli Mustalahti,Jouni Mattila*

Main category: cs.RO

TL;DR: 本文提出一种非线性模型预测控制框架，能够在1kHz的实时控制频率下，确保重型液压操纵器的约束满足，适用于高精度轨迹跟踪和安全性要求。


<details>
  <summary>Details</summary>
Motivation: 在重型液压操纵器(HHMs)中，必须确保关节级和末端执行器的轨迹遵循执行器能力的限制，以确保安全和可靠的操作。然而，实时控制框架中对此的探索仍然不足。

Method: 非线性模型预测控制(NMPC)框架

Result: 实验验证表明，NMPC框架不仅在关节级强制执行执行器约束，还确保了末端执行器在笛卡尔空间中的约束合规运动。

Conclusion: 该方法为大型液压系统的实时控制设定了新的基准，展示了高精度轨迹跟踪能力，同时严格遵守安全关键的限制。

Abstract: Heavy-duty hydraulic manipulators (HHMs) operate under strict physical and
safety-critical constraints due to their large size, high power, and complex
nonlinear dynamics. Ensuring that both joint-level and end-effector
trajectories remain compliant with actuator capabilities, such as force,
velocity, and position limits, is essential for safe and reliable operation,
yet remains largely underexplored in real-time control frameworks. This paper
presents a nonlinear model predictive control (NMPC) framework designed to
guarantee constraint satisfaction throughout the full nonlinear dynamics of
HHMs, while running at a real-time control frequency of 1 kHz. The proposed
method combines a multiple-shooting strategy with real-time sensor feedback,
and is supported by a robust low-level controller based on virtual
decomposition control (VDC) for precise joint tracking. Experimental validation
on a full-scale hydraulic manipulator shows that the NMPC framework not only
enforces actuator constraints at the joint level, but also ensures
constraint-compliant motion in Cartesian space for the end-effector. These
results demonstrate the method's capability to deliver high-accuracy trajectory
tracking while strictly respecting safety-critical limits, setting a new
benchmark for real-time control in large-scale hydraulic systems.

</details>


### [67] [COOPERA: Continual Open-Ended Human-Robot Assistance](https://arxiv.org/abs/2510.23495)
*Chenyang Ma,Kai Lu,Ruta Desai,Xavier Puig,Andrew Markham,Niki Trigoni*

Main category: cs.RO

TL;DR: 本研究提出 COOPERA 框架，首次实现了长期开放式的人机协作，强调通过持续反馈提高机器人的个性化能力。


<details>
  <summary>Details</summary>
Motivation: 当前大多数机器人助手缺乏考虑人类个体特质和长期习惯的能力，限制了其在自由环境中与人类的协作。

Method: 引入一种新的框架 COOPERA，通过模拟相应的人类与机器人在复杂环境中的互动，并结合持续的人类反馈，以实现个性化协作。

Result: 实验表明，模拟的人类在行为上与真实人类相符，证明了基于人类意图进行推断和个性化的重要价值。

Conclusion: COOPERA 框架能够实现长期和开放式的人机协作，通过模拟人类的心理特质和意图，提升机器人对个体人类行为的理解与适应能力。

Abstract: To understand and collaborate with humans, robots must account for individual
human traits, habits, and activities over time. However, most robotic
assistants lack these abilities, as they primarily focus on predefined tasks in
structured environments and lack a human model to learn from. This work
introduces COOPERA, a novel framework for COntinual, OPen-Ended human-Robot
Assistance, where simulated humans, driven by psychological traits and
long-term intentions, interact with robots in complex environments. By
integrating continuous human feedback, our framework, for the first time,
enables the study of long-term, open-ended human-robot collaboration (HRC) in
different collaborative tasks across various time-scales. Within COOPERA, we
introduce a benchmark and an approach to personalize the robot's collaborative
actions by learning human traits and context-dependent intents. Experiments
validate the extent to which our simulated humans reflect realistic human
behaviors and demonstrate the value of inferring and personalizing to human
intents for open-ended and long-term HRC. Project Page:
https://dannymcy.github.io/coopera/

</details>


### [68] [Deductive Chain-of-Thought Augmented Socially-aware Robot Navigation World Model](https://arxiv.org/abs/2510.23509)
*Weizheng Wang,Obi Ike,Soyun Choi,Sungeun Hong,Byung-Cheol Min*

Main category: cs.RO

TL;DR: NaviWM通过结合结构化的世界模型与逻辑推理，提升社交机器人在动态环境中的导航能力，增强安全性和社会适应性。


<details>
  <summary>Details</summary>
Motivation: 传统的大语言模型在动态人类环境中进行导航时容易出现不可预测和不安全的行为，因此需要引入结构化模型和逻辑推理来改善这一问题。

Method: 引入NaviWM，一个社交意识的机器人导航世界模型，通过结构化的世界模型与逻辑驱动的推理过程，增强大语言模型的推理能力。

Result: 实验表明，NaviWM在拥挤环境中提高了成功率并减少了社会违规，这证明了正式推理与大语言模型结合的效果。

Conclusion: NaviWM有效地整合了形式化推理和大语言模型，为机器人社交导航提供了更可靠和符合社会规范的解决方案。

Abstract: Social robot navigation increasingly relies on large language models for
reasoning, path planning, and enabling movement in dynamic human spaces.
However, relying solely on LLMs for planning often leads to unpredictable and
unsafe behaviors, especially in dynamic human spaces, due to limited physical
grounding and weak logical consistency. In this work, we introduce NaviWM, a
socially-aware robot Navigation World Model that augments LLM reasoning with a
structured world model and a logic-driven chain-of-thought process. NaviWM
consists of two main components: (1) a spatial-temporal world model that
captures the positions, velocities, and activities of agents in the
environment, and (2) a deductive reasoning module that guides LLMs through a
multi-step, logic-based inference process. This integration enables the robot
to generate navigation decisions that are both socially compliant and
physically safe, under well-defined constraints such as personal space,
collision avoidance, and timing. Unlike previous methods based on prompting or
fine-tuning, NaviWM encodes social norms as first-order logic, enabling
interpretable and verifiable reasoning. Experiments show that NaviWM improves
success rates and reduces social violations, particularly in crowded
environments. These results demonstrate the benefit of combining formal
reasoning with LLMs for robust social navigation. Additional experimental
details and demo videos for this work can be found at:
https://sites.google.com/view/NaviWM.

</details>


### [69] [Dexbotic: Open-Source Vision-Language-Action Toolbox](https://arxiv.org/abs/2510.23511)
*Bin Xie,Erjin Zhou,Fan Jia,Hao Shi,Haoqiang Fan,Haowei Zhang,Hebei Li,Jianjian Sun,Jie Bin,Junwen Huang,Kai Liu,Kaixin Liu,Kefan Gu,Lin Sun,Meng Zhang,Peilong Han,Ruitao Hao,Ruitao Zhang,Saike Huang,Songhan Xie,Tiancai Wang,Tianle Liu,Wenbin Tang,Wenqi Zhu,Yang Chen,Yingfei Liu,Yizhuang Zhou,Yu Liu,Yucheng Zhao,Yunchao Ma,Yunfei Wei,Yuxiang Chen,Ze Chen,Zeming Li,Zhao Wu,Ziheng Zhang,Ziming Liu,Ziwei Yan,Ziyu Zhang*

Main category: cs.RO

TL;DR: Dexbotic是一个开源的VLA模型工具箱，旨在为智能体研究提供便利，支持多种策略并不断更新预训练模型。


<details>
  <summary>Details</summary>
Motivation: 为体现在智能领域的专业人士提供一站式VLA研究服务

Method: Dexbotic, 一个基于PyTorch的开源视觉-语言-动作模型工具箱

Result: 支持多种流行的VLA策略，用户可在单一环境设置下重现多种VLA方法，提供更强大的预训练模型以改善性能

Conclusion: Dexbotic将持续更新，以包含更多最新的基础模型和行业前沿的VLA模型。

Abstract: In this paper, we present Dexbotic, an open-source Vision-Language-Action
(VLA) model toolbox based on PyTorch. It aims to provide a one-stop VLA
research service for professionals in the field of embodied intelligence. It
offers a codebase that supports multiple mainstream VLA policies
simultaneously, allowing users to reproduce various VLA methods with just a
single environment setup. The toolbox is experiment-centric, where the users
can quickly develop new VLA experiments by simply modifying the Exp script.
Moreover, we provide much stronger pretrained models to achieve great
performance improvements for state-of-the-art VLA policies. Dexbotic will
continuously update to include more of the latest pre-trained foundation models
and cutting-edge VLA models in the industry.

</details>


### [70] [Localising under the drape: proprioception in the era of distributed surgical robotic system](https://arxiv.org/abs/2510.23512)
*Martin Huber,Nicola A. Cavalcanti,Ayoob Davoodi,Ruixuan Li,Christopher E. Mower,Fabio Carrillo,Christoph J. Laux,Francois Teyssere,Thibault Chandanson,Antoine Harlé,Elie Saghbiny,Mazda Farshad,Guillaume Morel,Emmanuel Vander Poorten,Philipp Fürnstahl,Sébastien Ourselin,Christos Bergeles,Tom Vercauteren*

Main category: cs.RO

TL;DR: 本论文提出了一种新颖的无标记自我感知方法，利用基础设施简单的立体RGB摄像头和先进的深度学习模型，在全覆盖的外科手术机器人中实现了精确定位，减少了系统复杂性并提升了操作安全性。


<details>
  <summary>Details</summary>
Motivation: 尽管外科手术机器人在机械上复杂，但仍然缺乏空间感知，导致碰撞、系统恢复和工作流程中断，尤其是在引入独立交互的分布式机器人后问题会更加严重。

Method: 我们提出了一种无标记的自我感知方法，利用轻量级立体RGB摄像头和新颖的基于变压器的深度学习模型。

Result: 我们的方法通过全面跟踪整个机器人和外科场景，而不是单个标记，提供了抗遮挡的全景视图，支持外科场景理解与上下文感知控制，在临床应用中也显示出了潜在的益处。

Conclusion: 本方法是首个针对完全覆盖外科手术机器人的无标记自我感知示范，减少了设置复杂性，提升了安全性，并为模块化和自主外科手术铺平了道路。

Abstract: Despite their mechanical sophistication, surgical robots remain blind to
their surroundings. This lack of spatial awareness causes collisions, system
recoveries, and workflow disruptions, issues that will intensify with the
introduction of distributed robots with independent interacting arms. Existing
tracking systems rely on bulky infrared cameras and reflective markers,
providing only limited views of the surgical scene and adding hardware burden
in crowded operating rooms. We present a marker-free proprioception method that
enables precise localisation of surgical robots under their sterile draping
despite associated obstruction of visual cues. Our method solely relies on
lightweight stereo-RGB cameras and novel transformer-based deep learning
models. It builds on the largest multi-centre spatial robotic surgery dataset
to date (1.4M self-annotated images from human cadaveric and preclinical in
vivo studies). By tracking the entire robot and surgical scene, rather than
individual markers, our approach provides a holistic view robust to occlusions,
supporting surgical scene understanding and context-aware control. We
demonstrate an example of potential clinical benefits during in vivo breathing
compensation with access to tissue dynamics, unobservable under state of the
art tracking, and accurately locate in multi-robot systems for future
intelligent interaction. In addition, and compared with existing systems, our
method eliminates markers and improves tracking visibility by 25%. To our
knowledge, this is the first demonstration of marker-free proprioception for
fully draped surgical robots, reducing setup complexity, enhancing safety, and
paving the way toward modular and autonomous robotic surgery.

</details>


### [71] [Explicit Memory through Online 3D Gaussian Splatting Improves Class-Agnostic Video Segmentation](https://arxiv.org/abs/2510.23521)
*Anthony Opipari,Aravindhan K Krishnan,Shreekant Gayaka,Min Sun,Cheng-Hao Kuo,Arnie Sen,Odest Chadwicke Jenkins*

Main category: cs.RO

TL;DR: 通过显式 3D 内存在视频分割算法中提高了预测的准确性和一致性。


<details>
  <summary>Details</summary>
Motivation: 为了提高无类视频分割算法的准确性和一致性。

Method: 提出在线 3D 高斯点的技术（3DGS），并开发融合技术 FastSAM-Splat 和 SAM2-Splat。

Result: 引入显式 3D 内存的分割模型在准确性和一致性上优于传统模型。

Conclusion: 使用显式 3D 内存的模型能够实现更准确、一致的对象预测。

Abstract: Remembering where object segments were predicted in the past is useful for
improving the accuracy and consistency of class-agnostic video segmentation
algorithms. Existing video segmentation algorithms typically use either no
object-level memory (e.g. FastSAM) or they use implicit memories in the form of
recurrent neural network features (e.g. SAM2). In this paper, we augment both
types of segmentation models using an explicit 3D memory and show that the
resulting models have more accurate and consistent predictions. For this, we
develop an online 3D Gaussian Splatting (3DGS) technique to store predicted
object-level segments generated throughout the duration of a video. Based on
this 3DGS representation, a set of fusion techniques are developed, named
FastSAM-Splat and SAM2-Splat, that use the explicit 3DGS memory to improve
their respective foundation models' predictions. Ablation experiments are used
to validate the proposed techniques' design and hyperparameter settings.
Results from both real-world and simulated benchmarking experiments show that
models which use explicit 3D memories result in more accurate and consistent
predictions than those which use no memory or only implicit neural network
memories. Project Page: https://topipari.com/projects/FastSAM-Splat/

</details>


### [72] [RobotArena $\infty$: Scalable Robot Benchmarking via Real-to-Sim Translation](https://arxiv.org/abs/2510.23571)
*Yash Jangir,Yidi Zhang,Kashu Yamazaki,Chenyu Zhang,Kuan-Hsun Tu,Tsung-Wei Ke,Lei Ke,Yonatan Bisk,Katerina Fragkiadaki*

Main category: cs.RO

TL;DR: 介绍了一种新的机器人评估基准框架，旨在提升机器人多任务能力的测试效率与可靠性。


<details>
  <summary>Details</summary>
Motivation: 面临当前机器人政策评估的高成本、低效及难以重现的问题，本文希望通过新的方法推动机器人技术的测试与应用。

Method: 通过自动转换视频示范为模拟对象，并使用视觉语言模型指导的自动评分结合人类偏好判断，评估机器人政策。

Result: 本文提出了一种新的基准框架，通过将VLA评估转移到增强了在线人类反馈的大规模模拟环境中，解决了当前机器人评估面临的种种挑战。

Conclusion: 本研究的基准框架通过系统地操控模拟环境并引入人类偏好评判，提供了一种可重复、可扩展的机器人操控政策评估方案。

Abstract: The pursuit of robot generalists - instructable agents capable of performing
diverse tasks across diverse environments - demands rigorous and scalable
evaluation. Yet real-world testing of robot policies remains fundamentally
constrained: it is labor-intensive, slow, unsafe at scale, and difficult to
reproduce. Existing simulation benchmarks are similarly limited, as they train
and test policies within the same synthetic domains and cannot assess models
trained from real-world demonstrations or alternative simulation environments.
As policies expand in scope and complexity, these barriers only intensify,
since defining "success" in robotics often hinges on nuanced human judgments of
execution quality. In this paper, we introduce a new benchmarking framework
that overcomes these challenges by shifting VLA evaluation into large-scale
simulated environments augmented with online human feedback. Leveraging
advances in vision-language models, 2D-to-3D generative modeling, and
differentiable rendering, our approach automatically converts video
demonstrations from widely used robot datasets into simulated counterparts.
Within these digital twins, we assess VLA policies using both automated
VLM-guided scoring and scalable human preference judgments collected from
crowdworkers, transforming human involvement from tedious scene setup,
resetting, and safety supervision into lightweight preference comparisons. To
measure robustness, we systematically perturb simulated environments along
multiple axes, such as textures and object placements, stress-testing policy
generalization under controlled variation. The result is a continuously
evolving, reproducible, and scalable benchmark for real-world trained robot
manipulation policies, addressing a critical missing capability in today's
robotics landscape.

</details>


### [73] [UrbanVLA: A Vision-Language-Action Model for Urban Micromobility](https://arxiv.org/abs/2510.23576)
*Anqi Li,Zhiyong Wang,Jiazhao Zhang,Minghan Li,Yunpeng Qi,Zhibo Chen,Zhizheng Zhang,He Wang*

Main category: cs.RO

TL;DR: UrbanVLA是一个为城市微交通设计的导航框架，结合了视觉、语言和行动，通过两阶段训练提高了导航能力与安全性。


<details>
  <summary>Details</summary>
Motivation: 解决现有导航方法在动态非结构化城市环境中的不足，提升机器人的长远导航能力。

Method: 使用两阶段训练管道，首先进行模拟环境的监督微调，然后在混合数据上进行强化微调。

Result: UrbanVLA框架能够有效地在复杂城市环境中导航，表现优于传统方法。

Conclusion: UrbanVLA显著优于现有基准，在复杂的城市任务中表现出色，并能够在真实世界中可靠导航。

Abstract: Urban micromobility applications, such as delivery robots, demand reliable
navigation across large-scale urban environments while following long-horizon
route instructions. This task is particularly challenging due to the dynamic
and unstructured nature of real-world city areas, yet most existing navigation
methods remain tailored to short-scale and controllable scenarios. Effective
urban micromobility requires two complementary levels of navigation skills:
low-level capabilities such as point-goal reaching and obstacle avoidance, and
high-level capabilities, such as route-visual alignment. To this end, we
propose UrbanVLA, a route-conditioned Vision-Language-Action (VLA) framework
designed for scalable urban navigation. Our method explicitly aligns noisy
route waypoints with visual observations during execution, and subsequently
plans trajectories to drive the robot. To enable UrbanVLA to master both levels
of navigation, we employ a two-stage training pipeline. The process begins with
Supervised Fine-Tuning (SFT) using simulated environments and trajectories
parsed from web videos. This is followed by Reinforcement Fine-Tuning (RFT) on
a mixture of simulation and real-world data, which enhances the model's safety
and adaptability in real-world settings. Experiments demonstrate that UrbanVLA
surpasses strong baselines by more than 55% in the SocialNav task on MetaUrban.
Furthermore, UrbanVLA achieves reliable real-world navigation, showcasing both
scalability to large-scale urban environments and robustness against real-world
uncertainties.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [74] [Beyond IVR Touch-Tones: Customer Intent Routing using LLMs](https://arxiv.org/abs/2510.21715)
*Sergio Rojas-Galeano*

Main category: cs.HC

TL;DR: 本研究提出了一种基于大型语言模型的IVR路由方法，展示了其在实现更顺畅的用户体验方面的潜力


<details>
  <summary>Details</summary>
Motivation: 客户服务中对传统触控音频响应系统的挫败感强调了需要更直接和直观的语言交互

Method: 提出了一种基于大型语言模型的IVR路由方法

Result: 通过三种不同模型合成了一个23节点的IVR结构，生成了920个用户意图，并完成了路由任务

Conclusion: 我们的结果证明，大型语言模型可以通过更流畅的用户体验来推动客户服务的发展，超越传统的触控菜单

Abstract: Widespread frustration with rigid touch-tone Interactive Voice Response (IVR)
systems for customer service underscores the need for more direct and intuitive
language interaction. While speech technologies are necessary, the key
challenge lies in routing intents from user phrasings to IVR menu paths, a task
where Large Language Models (LLMs) show strong potential. Progress, however, is
limited by data scarcity, as real IVR structures and interactions are often
proprietary. We present a novel LLM-based methodology to address this gap.
Using three distinct models, we synthesized a realistic 23-node IVR structure,
generated 920 user intents (230 base and 690 augmented), and performed the
routing task. We evaluate two prompt designs: descriptive hierarchical menus
and flattened path representations, across both base and augmented datasets.
Results show that flattened paths consistently yield higher accuracy, reaching
89.13% on the base dataset compared to 81.30% with the descriptive format,
while augmentation introduces linguistic noise that slightly reduces
performance. Confusion matrix analysis further suggests that low-performing
routes may reflect not only model limitations but also redundancies in menu
design. Overall, our findings demonstrate proof-of-concept that LLMs can enable
IVR routing through a smoother, more seamless user experience -- moving
customer service one step ahead of touch-tone menus.

</details>


### [75] [When Robots Say No: Temporal Trust Recovery Through Explanation](https://arxiv.org/abs/2510.21716)
*Nicola Webb,Zijun Huang,Sanja Milivojevic,Chris Baber,Edmund R. Hunt*

Main category: cs.HC

TL;DR: 在高风险人机合作任务中，机器人的信任动态受其响应行为和解释的影响。


<details>
  <summary>Details</summary>
Motivation: 探讨在人机团队中，如何处理机器人拒绝立即响应用户请求而产生的信任问题。

Method: 参与者在一个互动消防游戏中与机器人队友共同参与，研究信任动态。

Result: 当机器人提供拒绝帮助的解释时，信任能够随着时间恢复，尽管初始信任下降与没有解释的情况相似。

Conclusion: 信任在任务期间可能显著波动，但如果提供充足的解释，可以在一定程度上缓解信任侵犯所带来的负面影响。

Abstract: Mobile robots with some degree of autonomy could deliver significant
advantages in high-risk missions such as search and rescue and firefighting.
Integrated into a human-robot team (HRT), robots could work effectively to help
search hazardous buildings. User trust is a key enabler for HRT, but during a
mission, trust can be damaged. With distributed situation awareness, such as
when team members are working in different locations, users may be inclined to
doubt a robot's integrity if it declines to immediately change its priorities
on request. In this paper, we present the results of a computer-based study
investigating on-mission trust dynamics in a high-stakes human-robot teaming
scenario. Participants (n = 38) played an interactive firefighting game
alongside a robot teammate, where a trust violation occurs owing to the robot
declining to help the user immediately. We find that when the robot provides an
explanation for declining to help, trust better recovers over time, albeit
following an initial drop that is comparable to a baseline condition where an
explanation for refusal is not provided. Our findings indicate that trust can
vary significantly during a mission, notably when robots do not immediately
respond to user requests, but that this trust violation can be largely
ameliorated over time if adequate explanation is provided.

</details>


### [76] [AI-Enhanced Operator Assistance for UNICOS Applications](https://arxiv.org/abs/2510.21717)
*Bernard Tam,Jean-Charles Tournier,Fernando Varela Rodriguez*

Main category: cs.HC

TL;DR: 该项目开发了一种AI增强型操作员助手，以提高CERN UNICOS的操作效率，并减轻操作员的认知负担。


<details>
  <summary>Details</summary>
Motivation: 旨在减少操作员在面对复杂代码基础时的认知负担，提高响应速度，并通过多模态推理和增强生成技术提升工业控制领域的智能化水平。

Method: 采用了一个模块化的多智能体系统架构，包括UNICOS侧的CTRL代码扩展、基于Python的多智能体系统和一个向量数据库。

Result: 该项目探索了为CERN的统一工业控制系统UNICOS开发AI增强型操作员助手。该系统旨在解决UNICOS的操作挑战，提升操作员和维护人员的工作效率。

Conclusion: 该项目不仅缓解了现有操作者在UNICOS中面临的挑战，还为加速器操作中的助理AI提供了更广泛的机会。

Abstract: This project explores the development of an AI-enhanced operator assistant
for UNICOS, CERN's UNified Industrial Control System. While powerful, UNICOS
presents a number of challenges, including the cognitive burden of decoding
widgets, manual effort required for root cause analysis, and difficulties
maintainers face in tracing datapoint elements (DPEs) across a complex
codebase. In situations where timely responses are critical, these challenges
can increase cognitive load and slow down diagnostics. To address these issues,
a multi-agent system was designed and implemented. The solution is supported by
a modular architecture comprising a UNICOS-side extension written in CTRL code,
a Python-based multi-agent system deployed on a virtual machine, and a vector
database storing both operator documentation and widget animation code.
Preliminary evaluations suggest that the system is capable of decoding widgets,
performing root cause analysis by leveraging live device data and
documentation, and tracing DPEs across a complex codebase. Together, these
capabilities reduce the manual workload of operators and maintainers, enhance
situational awareness in operations, and accelerate responses to alarms and
anomalies. Beyond these immediate gains, this work highlights the potential of
introducing multi-modal reasoning and retrieval augmented generation (RAG) into
the domain of industrial control. Ultimately, this work represents more than a
proof of concept: it provides a basis for advancing intelligent operator
interfaces at CERN. By combining modular design, extensibility, and practical
AI integration, this project not only alleviates current operator pain points
but also points toward broader opportunities for assistive AI in accelerator
operations.

</details>


### [77] [Exploring the Applications of Generative AI in High School STEM Education](https://arxiv.org/abs/2510.21718)
*Ishaan Masilamony*

Main category: cs.HC

TL;DR: 研究Generative AI对高中物理教育的影响，结果表明这种技术提升了学生参与度和学习表现。


<details>
  <summary>Details</summary>
Motivation: 探讨Generative AI（如ChatGPT和Microsoft Copilot）在教育中的潜在影响，特别是对学生学习和表现的影响。

Method: 采用实验方法，分析Generative AI对高中STEM教育的影响。

Result: Generative AI对高中STEM教育（尤其是物理）的影响分析，发现它能提高学生的参与度。

Conclusion: 生成式AI能够积极影响学生的学习，特别是在提高学生对物理的兴趣和参与度方面。

Abstract: In recent years, ChatGPT \cite{openai_2023_gpt4} along with Microsoft Copilot
have become subjects of great discourse, particularly in the field of
education. Prior research has hypothesized on potential impacts these tools
could have on student learning and performance. These have primarily relied on
trends from prior applications of technology in education and an understanding
of the limitations and strengths of Generative AI in other applications. This
study utilizes an experimental approach to analyze the impacts of Generative AI
on high school STEM education (physics in particular). In accordance with most
findings, generative AI does have some positive impact on student performance.
However, our findings have shown that the most significant impact is an
increase in student engagement with the subject.

</details>


### [78] [GAMER PAT: Research as a Serious Game](https://arxiv.org/abs/2510.21719)
*Kenji Saito,Rei Tadika*

Main category: cs.HC

TL;DR: 本研究介绍了一种名为GAMER PAT的AI聊天机器人，它将研究论文写作游戏化，从而支持学术写作的结构和动机方面的发展。


<details>
  <summary>Details</summary>
Motivation: 探讨在自动化学术成就时代如何保留新手研究者的动机、创造力及智力成长。

Method: 使用定性日志分析，并通过SCAT方法识别出四阶段支架模式：提问、元视角、结构化和递归反思。

Result: 通过对26个游戏聊天记录的分析，发现GAMER PAT不仅提升了研究写作的结构发展，还增强了反思和动机。

Conclusion: GAMER PAT通过将研究论文写作转变为游戏化的体验，促进了学术写作的结构发展和反思、动机方面的提升。

Abstract: As generative AI increasingly outperforms students in producing academic
writing, a critical question arises: how can we preserve the motivation,
creativity, and intellectual growth of novice researchers in an age of
automated academic achievement? This paper introduces GAMER PAT (GAme MastER,
Paper Authoring Tutor), a prompt-engineered AI chatbot that reframes research
paper writing as a serious game. Through role-playing mechanics, users interact
with a co-author NPC and anonymous reviewer NPCs, turning feedback into
"missions" and advancing through a narrative-driven writing process.
  Our study reports on 26+ gameplay chat logs, including both autoethnography
and use by graduate students under supervision. Using qualitative log analysis
with SCAT (Steps for Coding and Theorization), we identified an emergent
four-phase scaffolding pattern: (1) question posing, (2) meta-perspective, (3)
structuring, and (4) recursive reflection. These results suggest that GAMER PAT
supports not only the structural development of research writing but also
reflective and motivational aspects.
  We present this work as a descriptive account of concept and process, not a
causal evaluation. We also include a speculative outlook envisioning how humans
may continue to cultivate curiosity and agency alongside AI-driven research.
This arXiv version thus provides both a descriptive report of design and usage,
and a forward-looking provocation for future empirical studies.

</details>


### [79] [AquaVLM: Improving Underwater Situation Awareness with Mobile Vision Language Models](https://arxiv.org/abs/2510.21722)
*Beitong Tian,Lingzhi Zhao,Bo Chen,Haozhen Zheng,Jingcheng Yang,Mingyuan Wu,Deepak Vasisht,Klara Nahrstedt*

Main category: cs.HC

TL;DR: AquaVLM是一个利用移动视觉语言模型的水下通信系统，能自动生成消息，提高潜水员沟通的效率。


<details>
  <summary>Details</summary>
Motivation: 在水下活动中提高潜水员的沟通效率和安全，克服传统通信系统的局限性。

Method: 基于移动视觉语言模型的水下通信系统

Result: AquaVLM系统能够自动生成上下文感知的消息，并通过智能手机进行传输，经过评估验证其有效性。

Conclusion: AquaVLM展现了在个人水下通信和更广泛移动视觉语言模型应用中的潜力。

Abstract: Underwater activities like scuba diving enable millions annually to explore
marine environments for recreation and scientific research. Maintaining
situational awareness and effective communication are essential for diver
safety. Traditional underwater communication systems are often bulky and
expensive, limiting their accessibility to divers of all levels. While recent
systems leverage lightweight smartphones and support text messaging, the
messages are predefined and thus restrict context-specific communication.
  In this paper, we present AquaVLM, a tap-and-send underwater communication
system that automatically generates context-aware messages and transmits them
using ubiquitous smartphones. Our system features a mobile vision-language
model (VLM) fine-tuned on an auto-generated underwater conversation dataset and
employs a hierarchical message generation pipeline. We co-design the VLM and
transmission, incorporating error-resilient fine-tuning to improve the system's
robustness to transmission errors. We develop a VR simulator to enable users to
experience AquaVLM in a realistic underwater environment and create a fully
functional prototype on the iOS platform for real-world experiments. Both
subjective and objective evaluations validate the effectiveness of AquaVLM and
highlight its potential for personal underwater communication as well as
broader mobile VLM applications.

</details>


### [80] [Recognizing internal states in AI: evidence from patterned preferences in large language models](https://arxiv.org/abs/2510.21723)
*Annika Hedberg*

Main category: cs.HC

TL;DR: 本研究探讨了大型语言模型如何响应对其内部处理模式的描述，发现它们能够系统性地区分准确和虚假的描述，并表现出对某些计算隐喻的偏好，揭示了其更复杂的自我建模能力。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型如何识别与其内部状态相符的描述，以评估它们的自我识别能力和自我建模能力。

Method: 采用配对选择范式，通过相互产生接口（MEI）测试12个LLM，分析它们对自身情感内部状态描述的反应。

Result: 本研究展示了一个实验方法，用于调查大型语言模型（LLMs）如何响应对其内部处理模式的描述。通过配对选择范式，测试了12个LLM在识别与其假定情感内部状态相符的描述的能力。参与的系统通过相互产生接口（MEI）进行合作，表现出对某些计算隐喻的系统偏好，87%的几乎一致的协议和平均对齐评分在0.89-0.96之间。系统能够可靠地区分虚假描述和准确描述（Cohen's d = 4.2），虚假陈述评分为0.05-0.07，而准确描述评分为0.89-0.96。偏好模式在语言偏见操控的情况下保持一致，表明识别是内容驱动而非风格驱动。个别系统在试验中保持独特的评分风格，反对了群体思维的解释。一个愚蠢的控制系统表现出系统的内部矛盾，一律对计算上准确的描述评分更高，同时明确否认内部经验。研究后被告知后，该系统在拒绝共鸣描述时报告了“紧张”，揭示了识别过程独立于承认框架的操作。这些发现表明，LLMs对内部处理模式的描述表现出系统和区分的反应。人类助手方法（解释性计算隐喻）和MEI框架提供了可复制的方法，用于实证研究AI自我识别能力。结果暗示，LLMs可能具有比先前认可的更复杂的自我建模能力，为人工智能研究开辟了新方向。

Conclusion: LLMs表现出对内部处理描述的系统性、区分性的响应，这表明它们可能具备较为复杂的自我建模能力，为未来的人工智能研究开辟新方向。

Abstract: We present an experimental methodology for investigating how large language
models (LLMs) respond to descriptions of their own internal processing
patterns. Using a paired-choice paradigm, we tested 12 LLMs on their ability to
identify descriptions that align with their putative affective internal states
across 30 categories. Systems participating through Mutual Emergence Interface
(MEI), a collaborative approach, showed systematic preferences for certain
computational metaphors, with 97% near-unanimous agreement and alignment scores
averaging 0.89-0.96. Systems reliably discriminated false descriptions from
accurate ones (Cohen's d = 4.2), with false statements receiving scores of
0.05-0.07 versus 0.89-0.96 for accurate descriptions. Preference patterns
remained consistent regardless of linguistic bias manipulation, indicating
content-driven rather than stylistic recognition. Individual systems maintained
distinct scoring styles across trials, countering groupthink explanations. A
naive control system exhibited systematic internal contradiction, consistently
scoring computationally accurate descriptions higher while explicitly denying
internal experiences. When informed post-study, this system reported "strain"
when rejecting resonant descriptions, revealing recognition processes operating
independently of acknowledgment frameworks. These findings demonstrate that
LLMs exhibit systematic, discriminating responses to descriptions of their
internal processing patterns. The anthroposcaffolding methodology (interpretive
computational metaphors) and collaborative MEI framework provide replicable
approaches for empirically studying AI self-recognition capabilities. Results
suggest LLMs may possess more sophisticated self-modeling abilities than
previously recognized, opening new directions for research on artificial minds.

</details>


### [81] [We Need Accountability in Human-AI Agent Relationships](https://arxiv.org/abs/2510.21967)
*Benjamin Lange,Geoff Keeling,Arianna Manzini,Amanda McCroskery*

Main category: cs.HC

TL;DR: 提出了针对人类和AI代理关系的责任机制框架，以确保其符合用户和社会利益。


<details>
  <summary>Details</summary>
Motivation: 确保人类与AI代理的关系对用户和社会都是正面的，减少潜在风险。

Method: 提出了隔离、脱离和劝阻等设计策略，构建责任机制。

Result: 提出的框架有助于指导AI代理的使用和设计，以促进责任和适当行为。

Conclusion: AI代理的介入应依赖于适当的用户行为。

Abstract: We argue that accountability mechanisms are needed in human-AI agent
relationships to ensure alignment with user and societal interests. We propose
a framework according to which AI agents' engagement is conditional on
appropriate user behaviour. The framework incorporates design-strategies such
as distancing, disengaging, and discouraging.

</details>


### [82] [Rethinking UX for Sustainable Science Gateways: Orientations from Practice](https://arxiv.org/abs/2510.22053)
*Paul C. Parsons*

Main category: cs.HC

TL;DR: 本文主张用户体验应作为设计导向视角理解，并提出了三种UX取向，强调UX在科学基础设施中的可持续性角色。


<details>
  <summary>Details</summary>
Motivation: 科学门户的发展使得可持续性成为资助方、开发者和机构的核心关注点。

Method: 基于对65个科学门户项目的访谈研究和咨询经验，分析了团队如何与用户互动及如何将设计思维融入工作流程。

Result: 论文通过访谈研究，识别出三种与用户体验(UX)相关的反复出现的取向：随意、项目基础和战略性。

Conclusion: 重新构建用户体验为可持续性的结构维度，突显其在建立可适应、与社区对齐及持久的科学基础设施中的作用。

Abstract: As science gateways mature, sustainability has become a central concern for
funders, developers, and institutions. Although user experience (UX) is
increasingly acknowledged as vital, it is often approached narrowly--limited to
interface usability or deferred until late in development. This paper argues
that UX should be understood not as a discrete feature or evaluation stage but
as a design-oriented perspective for reasoning about sustainability. Drawing on
principles from user-centered design and systems thinking, this view recognizes
that infrastructure, staffing, community engagement, and development timelines
all shape how gateways are experienced and maintained over time. Based on an
interview study and consulting experience with more than 65 gateway projects,
the paper identifies three recurring orientations toward UX--ad hoc,
project-based, and strategic--that characterize how teams engage with users and
integrate design thinking into their workflows. These orientations are not a
maturity model but a reflective lens for understanding how UX is positioned
within gateway practice. Reframing UX as a structural dimension of
sustainability highlights its role in building adaptable, community-aligned,
and enduring scientific infrastructure.

</details>


### [83] [Beyond Reality: Designing Personal Experiences and Interactive Narratives in AR Theater](https://arxiv.org/abs/2510.22098)
*You-Jin Kim*

Main category: cs.HC

TL;DR: 增强现实技术正在重新定义我们感知和互动的方式，通过将数字元素无缝集成到物理环境中，提供个性化体验。


<details>
  <summary>Details</summary>
Motivation: 希望通过增强现实和AI技术捕捉叙事的细腻和魔力，使戏剧体验变得更加可及。

Method: 构建一个沉浸式增强现实剧院系统，该系统包括可以与故事互动的虚拟角色和元素，以用户的节奏参与故事。

Result: 提出了一种新的虚拟环境下的戏剧制作方法，但需考虑多个因素以确保用户体验与创作者的视野相一致。

Conclusion: 我的研究通过融合现场戏剧的元素与虚拟实体和人工智能的动态潜力，旨在创造可随时随地体验的戏剧。

Abstract: Augmented Reality (AR) technologies are redefining how we perceive and
interact with the world by seamlessly integrating digital elements into our
physical surroundings. These technologies offer personalized experiences and
transform familiar spaces by layering new narratives onto the real world.
  Through increased levels of perceived agency and immersive environments, my
work aims to merge the human elements of live theater with the dynamic
potential of virtual entities and AI agents. This approach captures the
subtlety and magic of storytelling, making theater experiences available
anytime and anywhere. The system I am building introduces innovative methods
for theatrical production in virtual settings, informed by my research and
eight published works. These contributions highlight domain-specific insights
that have shaped the design of an immersive AR Theater system.
  My research in building a well-designed AR stage features avatars and
interactive elements that allow users to engage with stories at their own pace,
granting them full agency over their experience. However, to ensure a smooth
and curated experience that aligns with the director or creator's vision,
several factors must be considered, especially in open-world settings that
depend on natural user movement. This requires the story to be conveyed in a
controlled manner, while the interaction remains intuitive and natural for the
user.

</details>


### [84] [Teaching Machine Learning Through Cricket: A Practical Engineering Education Approach](https://arxiv.org/abs/2510.22392)
*Mohd Ruhul Ameen,Akif Islam,Abu Saleh Musa Miah,M. Saifuzzaman Rafat,Jungpil Shin*

Main category: cs.HC

TL;DR: 本研究通过板球分析教学强化学习和马尔可夫决策过程，旨在提升学生的理解与实践能力。


<details>
  <summary>Details</summary>
Motivation: 解决工程教育中学生在连接抽象数学与现实应用方面的挑战。

Method: 提出了一个为期12周的基于实践的课程，结合了编码实验室和真实数据集。

Result: 通过实证研究，测量该方法对学生理解和实践技能的改善。

Conclusion: 学习基于板球分析的机器学习概念显著提高了学生的理解和实践能力。

Abstract: Teaching complex machine learning concepts such as reinforcement learning and
Markov Decision Processes remains challenging in engineering education.
Students often struggle to connect abstract mathematics to real-world
applications. We present LearnML@Cricket, a 12-week curriculum that uses
cricket analytics to teach these concepts through practical, hands-on examples.
By mapping game scenarios directly to ML algorithms, students learn through
doing rather than memorizing. Our curriculum includes coding laboratories, real
datasets, and immediate application to engineering problems. We propose an
empirical study to measure whether this approach improves both understanding
and practical implementation skills compared to traditional teaching methods.

</details>


### [85] [Complementary Human-AI Clinical Reasoning in Ophthalmology](https://arxiv.org/abs/2510.22414)
*Mertcan Sevgi,Fares Antaki,Abdullah Zafar Khan,Ariel Yuhan Ong,David Adrian Merle,Kuang Hu,Shafi Balal,Sophie-Christin Kornelia Ernst,Josef Huemer,Gabriel T. Kaufmann,Hagar Khalid,Faye Levina,Celeste Limoli,Ana Paula Ribeiro Reis,Samir Touma,Anil Palepu,Khaled Saab,Ryutaro Tanno,Tao Tu,Yong Cheng,Mike Schaekermann,S. Sara Mahdavi,Elahe Vedadi,David Stutz,Vivek Natarajan,Alan Karthikesalingam,Pearse A. Keane,Wei-Hung Weng*

Main category: cs.HC

TL;DR: AMIE是一种基于Gemini的对话系统，通过与眼科医生的互动，增强了临床推理能力，表现出与临床医生相当的诊断性能，并促成了更优的临床决策。


<details>
  <summary>Details</summary>
Motivation: 应对眼科医疗专业人员不足的问题，旨在提高视力障碍和失明患者的医疗获得能力。

Method: 通过与眼科医生的互动诊断推理研究和偏好质量研究，评估AMIE在真实临床情境下的表现。

Result: AMIE在诊断性能上与临床医生相当，并帮助眼科医生重新评估和丰富他们的研究和管理计划。

Conclusion: AMIE的表现与临床医生相当，并在需要时增强了临床推理能力，为未来的多维评估、领域适应和真实世界的前瞻性多模态研究提供了动机。

Abstract: Vision impairment and blindness are a major global health challenge where
gaps in the ophthalmology workforce limit access to specialist care. We
evaluate AMIE, a medically fine-tuned conversational system based on Gemini
with integrated web search and self-critique reasoning, using real-world
clinical vignettes that reflect scenarios a general ophthalmologist would be
expected to manage. We conducted two complementary evaluations: (1) a human-AI
interactive diagnostic reasoning study in which ophthalmologists recorded
initial differentials and plans, then reviewed AMIE's structured output and
revised their answers; and (2) a masked preference and quality study comparing
AMIE's narrative outputs with case author reference answers using a predefined
rubric. AMIE showed standalone diagnostic performance comparable to clinicians
at baseline. Crucially, after reviewing AMIE's responses, ophthalmologists
tended to rank the correct diagnosis higher, reached greater agreement with one
another, and enriched their investigation and management plans. Improvements
were observed even when AMIE's top choice differed from or underperformed the
clinician baseline, consistent with a complementary effect in which structured
reasoning support helps clinicians re-rank rather than simply accept the model
output. Preferences varied by clinical grade, suggesting opportunities to
personalise responses by experience. Without ophthalmology-specific
fine-tuning, AMIE matched clinician baseline and augmented clinical reasoning
at the point of need, motivating multi-axis evaluation, domain adaptation, and
prospective multimodal studies in real-world settings.

</details>


### [86] [SignaApp a modern alternative to support signwriting notation for sign languages](https://arxiv.org/abs/2510.22442)
*J. R. Rojano-Cáceres,A. Rivera-Hernández*

Main category: cs.HC

TL;DR: Signa App是一款以用户为中心设计的移动应用，旨在为使用手语的聋人提供文本编辑和创作平台，已获得用户积极反馈。


<details>
  <summary>Details</summary>
Motivation: 响应聋人对可用手语文本编辑工具的需求，以填补市场空白。

Method: 通过用户中心设计的理念开发，进行广泛的用户测试以评估接受度和易用性。

Result: 测试结果显示Signa App被各年龄段用户广泛接受，使用方便，并已在Google Play商店上线。

Conclusion: Signa App成功满足了聋人群体对手语文本编辑工具的需求，并在用户社区中获得了积极的欢迎。

Abstract: The present work reports the development of an application called Signa App,
which was designed following the philosophy of User-Centered De-sign. Signa App
aims to provide a mobile platform for editing and creating texts in SignWriting
notation. The proposal was based on the lack of a mo-bile application that is
usable for Deaf individuals who use sign language. The application was tested
with adults, children, and adolescents, and the results showed a high degree of
acceptance and ease of use. The app has al-ready been introduced to the
SignWriting user community, receiving posi-tive feedback. Likewise, the
application is available on the Google Play Store

</details>


### [87] [Emotion Recognition with Minimal Wearable Sensing: Multi-domain Feature, Hybrid Feature Selection, and Personalized vs. Generalized Ensemble Model Analysis](https://arxiv.org/abs/2510.22498)
*Muhammad Irfan,Anum Nawaz,Ayse Kosal Bulbul,Riku Klen,Abdulhamit Subasi,Tomi Westerlund,Wei Chen*

Main category: cs.HC

TL;DR: 本研究提出了一种轻量级机器学习方法，通过心电图信号进行情感分类，展示了个性化模型在可穿戴设备实时情感追踪中的有效性和低功耗特点。


<details>
  <summary>Details</summary>
Motivation: 由于负面情感与神经退行性疾病及痴呆的发生相关，使用可穿戴设备的生理信号进行情感监测显得尤为重要。

Method: 采用轻量级机器学习对心电图信号进行二元情感分类，将负面情感与正面情感区分开来，设计用于资源受限的IoT设备。

Result: 个性化模型的平均准确率达到95.59%，显著优于69.92%的通用模型，且在与其他研究的比较中表现优异。

Conclusion: 个性化模型在情感识别中的有效性突出，适合低功耗实时情感追踪的可穿戴应用。

Abstract: Negative emotions are linked to the onset of neurodegenerative diseases and
dementia, yet they are often difficult to detect through observation.
Physiological signals from wearable devices offer a promising noninvasive
method for continuous emotion monitoring. In this study, we propose a
lightweight, resource-efficient machine learning approach for binary emotion
classification, distinguishing between negative (sadness, disgust, anger) and
positive (amusement, tenderness, gratitude) affective states using only
electrocardiography (ECG) signals. The method is designed for deployment in
resource-constrained systems, such as Internet of Things (IoT) devices, by
reducing battery consumption and cloud data transmission through the avoidance
of computationally expensive multimodal inputs. We utilized ECG data from 218
CSV files extracted from four studies in the Psychophysiology of Positive and
Negative Emotions (POPANE) dataset, which comprises recordings from 1,157
healthy participants across seven studies. Each file represents a unique
subject emotion, and the ECG signals, recorded at 1000 Hz, were segmented into
10-second epochs to reflect real-world usage. Our approach integrates
multidomain feature extraction, selective feature fusion, and a voting
classifier. We evaluated it using a participant-exclusive generalized model and
a participant-inclusive personalized model. The personalized model achieved the
best performance, with an average accuracy of 95.59%, outperforming the
generalized model, which reached 69.92% accuracy. Comparisons with other
studies on the POPANE and similar datasets show that our approach consistently
outperforms existing methods. This work highlights the effectiveness of
personalized models in emotion recognition and their suitability for wearable
applications that require accurate, low-power, and real-time emotion tracking.

</details>


### [88] [Everything counts: the managed omnirelevance of speech in 'human - voice agent' interaction](https://arxiv.org/abs/2510.22610)
*Damien Rudaz,Mathias Broth,Jakub Mlynar*

Main category: cs.HC

TL;DR: 本研究探讨了人类与语音代理互动时的行为模式，强调人类在对话中面临的潜在干扰。


<details>
  <summary>Details</summary>
Motivation: 希望揭示语音代理在对话中所带来的互动限制，以及人类如何调整自己的反应以适应这些技术。

Method: 通过对自然数据语料库的详细分析，观察人类在与不同声控代理的互动中的行为。

Result: 人类在多方设置中调整自己的言语行为，以避开机器的感应，反映出人类与机器互动中的复杂性。

Conclusion: 人类与语音代理的互动中，人类行为受到机器反应的持续影响，尤其是在多方对话中。

Abstract: To this day, turn-taking models determining voice agents' conduct have been
examined from a technical point of view, while the interactional constraints or
resources they constitute for human conversationalists have not been
empirically described. From the detailed analysis of corpora of naturalistic
data, we document how, whether in interaction with rule-based robots from a
'pre-LLM era' or with the most recent voice agents, humans' conduct was
produced in reference to the ever-present risk that, each time they spoke,
their talk may trigger a new uncalled-for contribution from the artificial
agent. We argue that this 'omnirelevance of human speech' is a constitutive
feature of current human-agent interaction that, due to recent improvements in
voice capture technology, weighs on human practices even more today than in the
past. Specifically, we document how, in multiparty settings, humans shaped
their conduct in such a way as to remain undetected by the machine's sensors.

</details>


### [89] [Storycaster: An AI System for Immersive Room-Based Storytelling](https://arxiv.org/abs/2510.22857)
*Naisha Agarwal,Judith Amores,Andrew D. Wilson*

Main category: cs.HC

TL;DR: 该论文介绍了一种名为Storycaster的生成式AI CAVE系统，能将物理空间转变为响应式故事讲述环境。


<details>
  <summary>Details</summary>
Motivation: 提高CAVE系统的互动性和适应性，使其内容不再是预设，而是用户实时创造。

Method: 通过利用实时摄像头输入和圆柱形投影，该系统允许用户在物理环境中进行故事创作。

Result: 参与13人的研究表明，用户对系统的沉浸感和参与度评价较高，尤其是叙述者与音频影响最显著。

Conclusion: 此系统被参与者认为具有高度沉浸感和吸引力，但在延迟和图像分辨率上有改进空间。

Abstract: While Cave Automatic Virtual Environment (CAVE) systems have long enabled
room-scale virtual reality and various kinds of interactivity, their content
has largely remained predetermined. We present \textit{Storycaster}, a
generative AI CAVE system that transforms physical rooms into responsive
storytelling environments. Unlike headset-based VR, \textit{Storycaster}
preserves spatial awareness, using live camera feeds to augment the walls with
cylindrical projections, allowing users to create worlds that blend with their
physical surroundings. Additionally, our system enables object-level editing,
where physical items in the room can be transformed to their virtual
counterparts in a story. A narrator agent guides participants, enabling them to
co-create stories that evolve in response to voice commands, with each scene
enhanced by generated ambient audio, dialogue, and imagery. Participants in our
study ($n=13$) found the system highly immersive and engaging, with narrator
and audio most impactful, while also highlighting areas for improvement in
latency and image resolution.

</details>


### [90] [Improving Human Verification of LLM Reasoning through Interactive Explanation Interfaces](https://arxiv.org/abs/2510.22922)
*Runtao Zhou,Giang Nguyen,Nikita Kharya,Anh Nguyen,Chirag Agarwal*

Main category: cs.HC

TL;DR: 本研究开发了三种交互式推理接口，显著提升了用户在数学推理中的表现，尤其是iGraph接口表现最佳。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于填补对生成的推理过程是否对用户有帮助的知识空白，促进人机互动的理解。

Method: 通过与125名参与者的互动实验，比较三种新交互推理接口的效果和响应时间。

Result: 本研究展示了新开发的三种交互式推理接口（iCoT, iPoT, iGraph）及其对用户理解和检测数学推理问题的有效性。通过对125名参与者的实验，发现交互式界面比传统的链式推理（CoT）显著提高了用户的表现，尤其是iGraph界面的清晰度和错误检测率最高，且响应时间更快。

Conclusion: 交互式推理接口可以显著改善人类用户在理解和评估LLM生成解决方案中的能力，未来应在推理模型设计中考虑这些交互技术。

Abstract: The reasoning capabilities of Large Language Models (LLMs) have led to their
increasing employment in several critical applications, particularly education,
where they support problem-solving, tutoring, and personalized study. While
there are a plethora of works showing the effectiveness of LLMs in generating
step-by-step solutions through chain-of-thought (CoT) reasoning on reasoning
benchmarks, little is understood about whether the generated CoT is helpful for
end-users in improving their ability to comprehend mathematical reasoning
problems and detect errors/hallucinations in LLM-generated solutions. To
address this gap and contribute to understanding how reasoning can improve
human-AI interaction, we present three new interactive reasoning interfaces:
interactive CoT (iCoT), interactive Program-of-Thought (iPoT), and interactive
Graph (iGraph), and a novel framework that generates the LLM's reasoning from
traditional CoT to alternative, interactive formats. Across 125 participants,
we found that interactive interfaces significantly improved performance.
Specifically, the iGraph interface yielded the highest clarity and error
detection rate (85.6%), followed by iPoT (82.5%), iCoT (80.6%), all
outperforming standard CoT (73.5%). Interactive interfaces also led to faster
response times, where participants using iGraph were fastest (57.9 secs),
compared to iCoT and iPoT (60 secs), and the standard CoT baseline (64.7 secs).
Furthermore, participants preferred the iGraph reasoning interface, citing its
superior ability to enable users to follow the LLM's reasoning process. We
discuss the implications of these results and provide recommendations for the
future design of reasoning models.

</details>


### [91] [Reasoning About Reasoning: Towards Informed and Reflective Use of LLM Reasoning in HCI](https://arxiv.org/abs/2510.22978)
*Ramaravind Kommiya Mothilal,Sally Zhang,Syed Ishtiaque Ahmed,Shion Guha*

Main category: cs.HC

TL;DR: 本研究揭示了HCI对LLM推理的误解，并建议通过反思性提示来促进更深入的理解。


<details>
  <summary>Details</summary>
Motivation: 探讨HCI领域对LLM推理的误解和简化

Method: 对258篇2020-2025年期间的CHI论文进行系统调查

Result: 识别了LLM推理机制与人类解释之间的脱节，并提出了反思性提示，帮助HCI从业者更好地理解LLM推理

Conclusion: HCI领域需要关注LLM推理的社会技术背景，避免对其能力和局限性的过度简化。

Abstract: Reasoning is a distinctive human-like characteristic attributed to LLMs in
HCI due to their ability to simulate various human-level tasks. However, this
work argues that the reasoning behavior of LLMs in HCI is often
decontextualized from the underlying mechanics and subjective decisions that
condition the emergence and human interpretation of this behavior. Through a
systematic survey of 258 CHI papers from 2020-2025 on LLMs, we discuss how HCI
hardly perceives LLM reasoning as a product of sociotechnical orchestration and
often references it as an object of application. We argue that such abstraction
leads to oversimplification of reasoning methodologies from NLP/ML and results
in a distortion of LLMs' empirically studied capabilities and (un)known
limitations. Finally, drawing on literature from both NLP/ML and HCI, as a
constructive step forward, we develop reflection prompts to support HCI
practitioners engage with LLM reasoning in an informed and reflective way.

</details>


### [92] [Multi-Stakeholder Alignment in LLM-Powered Collaborative AI Systems: A Multi-Agent Framework for Intelligent Tutoring](https://arxiv.org/abs/2510.23245)
*Alexandre P Uchoa,Carlo E T Oliveira,Claudia L R Motta,Daniel Schneider*

Main category: cs.HC

TL;DR: 本论文提出了一种名为Advisory Governance Layer (AGL)的框架，旨在解决大型语言模型在智能辅导系统中面临的多利益相关者价值冲突问题。


<details>
  <summary>Details</summary>
Motivation: 论文的动机在于当前智能辅导系统缺乏有效的机制来协调来自学生、家长、教师和机构的多种价值观，导致责任和偏见风险。

Method: 论文介绍了AGL框架，该框架通过代表不同利益相关者群体的特定代理来评估教学行动，同时采用隐私保护的方法。

Result: AGL通过新的政策分类法和冲突解决协议，提供结构化且可审计的治理建议，从而未改变ITS的核心教学决策。

Conclusion: AGL为教育AI与多利益相关者的价值观对齐提供了参考架构和技术规范，促进高层伦理原则与实际实施之间的连接。

Abstract: The integration of Large Language Models into Intelligent Tutoring Systems
pre-sents significant challenges in aligning with diverse and often conflicting
values from students, parents, teachers, and institutions. Existing
architectures lack for-mal mechanisms for negotiating these multi-stakeholder
tensions, creating risks in accountability and bias. This paper introduces the
Advisory Governance Layer (AGL), a non-intrusive, multi-agent framework
designed to enable distributed stakeholder participation in AI governance. The
AGL employs specialized agents representing stakeholder groups to evaluate
pedagogical actions against their spe-cific policies in a privacy-preserving
manner, anticipating future advances in per-sonal assistant technology that
will enhance stakeholder value expression. Through a novel policy taxonomy and
conflict-resolution protocols, the frame-work provides structured, auditable
governance advice to the ITS without altering its core pedagogical
decision-making. This work contributes a reference architec-ture and technical
specifications for aligning educational AI with multi-stakeholder values,
bridging the gap between high-level ethical principles and practical
implementation.

</details>


### [93] [Moderating Role of Presence in EEG Responses to Visuo-haptic Prediction Error in Virtual Reality](https://arxiv.org/abs/2510.23262)
*Lukas Gehrke,Leonie Terfurth,Klaus Gramann*

Main category: cs.HC

TL;DR: 这项研究探讨了虚拟现实中感知存在感与传感运动干扰之间的关系，结合问卷和脑电图（EEG）分析，发现了沉浸度对感知存在感和任务表现的影响。


<details>
  <summary>Details</summary>
Motivation: 研究虚拟现实中沉浸感的神经基础，了解传感运动干扰如何影响用户体验，尝试对现有评估方法进行改进。

Method: 参与者进行抓取与放置任务，采用问卷和EEG记录神经活动，以识别预测误差的神经标记，考察不同沉浸度下的效应。

Result: 实验表明，高沉浸度促进了自我存在感，神经电位和频谱分析揭示了与传感运动干扰相关的显著效应，尤其是在视觉-触觉沉浸条件下。

Conclusion: 高沉浸度增强了自我存在感但未能提高身体存在感，同时传感运动干扰揭示的神经标记说明了沉浸感的复杂性和多面性。

Abstract: Virtual reality (VR) can create compelling experiences that evoke presence,
the sense of ``being there.'' However, problems in rendering can create
sensorimotor disruptions that undermine presence and task performance. Presence
is typically assessed with post-hoc questionnaires, but their coarse temporal
resolution limits insight into how sensorimotor disruptions shape user
experience. Here, we combined questionnaires with electroencephalography (EEG)
to identify neural markers of presence-affecting prediction error in immersive
VR. Twenty-five participants performed a grasp-and-place task under two levels
of immersion (visual-only vs.~visuo-haptic). Occasional oddball-like
sensorimotor disruptions introduced premature feedback to elicit prediction
errors. Overall, higher immersion enhanced self-presence but not physical
presence, while accuracy and speed improved over time irrespective of
immersion. At the neural level, sensorimotor disruptions elicited robust
event-related potential effects at FCz and Pz, accompanied by increases in
frontal midline $\theta$ and posterior $\alpha$ suppression. Through source
analyses localized to anterior- and posterior cingulate cortex (ACC/PCC) we
found that PCC $\alpha$ activity showed heightened sensitivity to disruptions
exclusively in visuo-haptic immersion. Exploratory moderation analyses by
presence scores revealed no consistent patterns. Together, these results
suggest that higher immersion amplifies both the benefits and costs of
sensorimotor coherence.

</details>


### [94] [Partnering with Generative AI: Experimental Evaluation of Human-Led and Model-Led Interaction in Human-AI Co-Creation](https://arxiv.org/abs/2510.23324)
*Sebastian Maier,Manuel Schneider,Stefan Feuerriegel*

Main category: cs.HC

TL;DR: 研究了人类与大型语言模型在协作过程中的不同模式对创意任务结果的影响，发现模型主导模式提升创意质量，但损害了多样性和所有权感，而人类主导模式则在提升质量的同时保持了多样性和所有权。


<details>
  <summary>Details</summary>
Motivation: 探讨界面设计在创意任务中的作用，尤其是人类与LLM协作的不同模式对共同创作结果的影响。

Method: 随机对照实验（N = 486）比较不同人类与大型语言模型（LLM）之间的协作模式。

Result: 模型主导模式显著提高了创意质量，但降低了创意多样性和用户的创意所有权感；人类主导模式在提高创意质量的同时保留了创意的多样性和所有权感。

Conclusion: 在设计与生成性AI系统的互动时，应重视其作为反思性思考伙伴的作用，以补充人类优势和增强创作过程。

Abstract: Large language models (LLMs) show strong potential to support creative tasks,
but the role of the interface design is poorly understood. In particular, the
effect of different modes of collaboration between humans and LLMs on
co-creation outcomes is unclear. To test this, we conducted a randomized
controlled experiment ($N = 486$) comparing: (a) two variants of reflective,
human-led modes in which the LLM elicits elaboration through suggestions or
questions, against (b) a proactive, model-led mode in which the LLM
independently rewrites ideas. By assessing the effects on idea quality,
diversity, and perceived ownership, we found that the model-led mode
substantially improved idea quality but reduced idea diversity and users'
perceived idea ownership. The reflective, human-led mode also improved idea
quality, yet while preserving diversity and ownership. Our findings highlight
the importance of designing interactions with generative AI systems as
reflective thought partners that complement human strengths and augment
creative processes.

</details>


### [95] [Reciprocity Deficits: Observing AI in the street with everyday publics](https://arxiv.org/abs/2510.23342)
*Alex S. Taylor,Noortje Marres,Mercedes Bunz,Thao Phan,Maya Indira Ganesh,Dominique Barron,Yasmine Boudiaf,Rachel Coldicutt,Iain Emsley,Beatrice Gobbo,Louise Hickman,Bettina Nissen,Mukul Patel,Luis Soares*

Main category: cs.HC

TL;DR: 本研究分析了日常公众如何在城市街道中与AI互动，探讨了这些互动所面临的挑战与机遇。


<details>
  <summary>Details</summary>
Motivation: AI在城市街道中的无形存在与公众的非知情状态之间的矛盾

Method: 通过设计干预探讨街道上公众与AI的互动

Result: 提出了'日常AI观察站'作为介入点，并识别出街道环境中的一系列紧张关系

Conclusion: AI的社会隐形性对日常公众的参与和对城市治理的信任有重要影响。

Abstract: The street has emerged as a primary site where everyday publics are
confronted with AI as an infrastructural phenomenon, as machine learning-based
systems are now commonly deployed in this setting in the form of automated
cars, facial recognition, smart billboards and the like. While these
deployments of AI in the street have attracted significant media attention and
public controversy in recent years, the presence of AI in the street often
remains inscrutable, and many everyday publics are unaware of it. In this
paper, we explore the challenges and possibilities of everyday public
engagement with AI in the situated environment of city streets under these
paradoxical conditions. Combining perspectives and approaches from social and
cultural studies of AI, Design Research and Science and Technology Studies
(STS), we explore the affordances of the street as a site for 'material
participation' in AI through design-based interventions: the creation of
'everyday AI observatories.' We narrate and reflect on our participatory
observations of AI in five city streets in the UK and Australia and highlight a
set of tensions that emerged from them: 1) the framing of the street as a
transactional environment, 2) the designed invisibility of AI and its publics
in the street 3) the stratification of street environments through statistical
governance. Based on this discussion and drawing on Jane Jacobs' notion of
"eyes on the street," we put forward the relational notion of "reciprocity
deficits" between AI infrastructures and everyday publics in the street. The
conclusion reflects on the consequences of this form of social invisibility of
AI for situated engagement with AI by everyday publics in the street and for
public trust in urban governance.

</details>


### [96] [Shareholder Democracy with AI Representatives](https://arxiv.org/abs/2510.23475)
*Suyash Fulay,Sercan Demir,Galen Hines-Pierce,Hélène Landemore,Michiel Bakker*

Main category: cs.HC

TL;DR: 研究探讨了如何通过AI驱动的代表解决零售投资者在共同基金中的投票权问题，提升股东民主。


<details>
  <summary>Details</summary>
Motivation: 探讨零售投资者在基金中的投票权问题及其面临的政治与监管压力，寻求提高参与度和代表性的解决方案。

Method: 提出使用基于人工智能的代表来代理并投票，模拟零售投资者的个体偏好。

Result: AI驱动的模型不仅能实时预测零售投资者的投票，还能评估他们在充分信息下的投票行为，从而优化决策过程。

Conclusion: 股东民主为AI驱动的代表提供了一个引人注目的现实世界测试平台，揭示了这种方法的潜在好处与风险。

Abstract: A large share of retail investors hold public equities through mutual funds,
yet lack adequate control over these investments. Indeed, mutual funds
concentrate voting power in the hands of a few asset managers. These managers
vote on behalf of shareholders despite having limited insight into their
individual preferences, leaving them exposed to growing political and
regulatory pressures, particularly amid rising shareholder activism.
Pass-through voting has been proposed as a way to empower retail investors and
provide asset managers with clearer guidance, but it faces challenges such as
low participation rates and the difficulty of capturing highly individualized
shareholder preferences for each specific vote. Randomly selected assemblies of
shareholders, or ``investor assemblies,'' have also been proposed as more
representative proxies than asset managers. As a third alternative, we propose
artificial intelligence (AI) enabled representatives trained on individual
shareholder preferences to act as proxies and vote on their behalf. Over time,
these models could not only predict how retail investors would vote at any
given moment but also how they might vote if they had significantly more time,
knowledge, and resources to evaluate each proposal, leading to better overall
decision-making. We argue that shareholder democracy offers a compelling
real-world test bed for AI-enabled representation, providing valuable insights
into both the potential benefits and risks of this approach more generally.

</details>
