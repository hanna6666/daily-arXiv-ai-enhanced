<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 34]
- [cs.HC](#cs.HC) [Total: 13]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [RoboOmni: Proactive Robot Manipulation in Omni-modal Context](https://arxiv.org/abs/2510.23763)
*Siyin Wang,Jinlan Fu,Feihong Liu,Xinzhe He,Huangxuan Wu,Junhao Shi,Kexin Huang,Zhaoye Fei,Jingjing Gong,Zuxuan Wu,Yugang Jiang,See-Kiong Ng,Tat-Seng Chua,Xipeng Qiu*

Main category: cs.RO

TL;DR: 本研究提出RoboOmni，一个新的框架，通过跨模态上下文指令实现主动用户意图识别，显著提升机器人操作的表现。


<details>
  <summary>Details</summary>
Motivation: 当前的机器人操作大多依赖显式指令，而人类的交互更倾向于隐式意图表达；因此，需要一种新的机制使机器人能够主动推断用户的意图。

Method: RoboOmni利用听觉和视觉信号的时空融合来进行意图识别，并支持直接的语音交互。构建了包含多种环境声音和场景的OmniAction数据集，以填补主动意图识别的训练数据不足。

Result: 本研究提出了一种新的跨模态上下文指令设置，即通过语音对话、环境声音和视觉线索而非显式命令来推导用户意图。为了解决这一新设置，提出了RoboOmni框架，集成了意图识别、互动确认和动作执行。该框架能够时空融合听觉和视觉信号，以实现更强的意图识别能力，并支持直接的语音交互。同时，为了应对机器人操作中缺乏主动意图识别的训练数据，构建了OmniAction数据集，包括140,000个事件，5,000多个说话者，2,400个事件声音，640个背景和六种上下文指令类型。实验结果表明，RoboOmni在成功率、推理速度、意图识别和主动辅助方面均超过了基于文本和语音识别的基线。

Conclusion: RoboOmni的引入为机器人与人类的互动提供了一种新的方式，使得机器人能够更有效地理解并响应用户的非显式指令。

Abstract: Recent advances in Multimodal Large Language Models (MLLMs) have driven rapid
progress in Vision-Language-Action (VLA) models for robotic manipulation.
Although effective in many scenarios, current approaches largely rely on
explicit instructions, whereas in real-world interactions, humans rarely issue
instructions directly. Effective collaboration requires robots to infer user
intentions proactively. In this work, we introduce cross-modal contextual
instructions, a new setting where intent is derived from spoken dialogue,
environmental sounds, and visual cues rather than explicit commands. To address
this new setting, we present RoboOmni, a Perceiver-Thinker-Talker-Executor
framework based on end-to-end omni-modal LLMs that unifies intention
recognition, interaction confirmation, and action execution. RoboOmni fuses
auditory and visual signals spatiotemporally for robust intention recognition,
while supporting direct speech interaction. To address the absence of training
data for proactive intention recognition in robotic manipulation, we build
OmniAction, comprising 140k episodes, 5k+ speakers, 2.4k event sounds, 640
backgrounds, and six contextual instruction types. Experiments in simulation
and real-world settings show that RoboOmni surpasses text- and ASR-based
baselines in success rate, inference speed, intention recognition, and
proactive assistance.

</details>


### [2] [Motivating Students' Self-study with Goal Reminder and Emotional Support](https://arxiv.org/abs/2510.23860)
*Hyung Chan Cho,Go-Eum Cha,Yanfu Liu,Sooyeon Jeong*

Main category: cs.RO

TL;DR: 本研究探讨了社交机器人作为大学生自学伙伴的潜力，发现提供任务提醒及情感支持的机器人能显著提升学习效果和满意度。


<details>
  <summary>Details</summary>
Motivation: 探索社交机器人在自学 context 中的潜力，尤其是在支持大学生的学习任务中。

Method: 通过探究性Wizard-of-Oz研究比较社交机器人提供任务提醒和情感支持与仅提供物理存在的效果。

Result: 目标提醒和情感支持条件的参与者在使用便利性上报告更高的满意度，目标提醒条件也显示出更强的未来使用意愿。参与者对机器人的满意度与他们将机器人视为社交存在的感知相关，并且这被认为是他们在自学任务中目标达成的预测因素。

Conclusion: 社交辅助机器人可以通过功能性和情感互动在自学中提供支持。

Abstract: While the efficacy of social robots in supporting people in learning tasks
has been extensively investigated, their potential impact in assisting students
in self-studying contexts has not been investigated much. This study explores
how a social robot can act as a peer study companion for college students
during self-study tasks by delivering task-oriented goal reminder and positive
emotional support. We conducted an exploratory Wizard-of-Oz study to explore
how these robotic support behaviors impacted students' perceived focus,
productivity, and engagement in comparison to a robot that only provided
physical presence (control). Our study results suggest that participants in the
goal reminder and the emotional support conditions reported greater ease of
use, with the goal reminder condition additionally showing a higher willingness
to use the robot in future study sessions. Participants' satisfaction with the
robot was correlated with their perception of the robot as a social other, and
this perception was found to be a predictor for their level of goal achievement
in the self-study task. These findings highlight the potential of socially
assistive robots to support self-study through both functional and emotional
engagement.

</details>


### [3] [Stand, Walk, Navigate: Recovery-Aware Visual Navigation on a Low-Cost Wheeled Quadruped](https://arxiv.org/abs/2510.23902)
*Jans Solano,Diego Quiroz*

Main category: cs.RO

TL;DR: 本研究提出了一种低成本的四足轮腿机器人恢复意识视觉惯性导航系统，结合了视觉感知和深度强化学习，能在多样地形中实现灵活移动和自主恢复。


<details>
  <summary>Details</summary>
Motivation: 致力于克服现有高成本轮腿机器人在障碍物应对与跌倒恢复方面的不足。

Method: 结合深度相机的视觉感知和深度强化学习策略，开发低成本四足轮腿机器人的导航系统。

Result: 模拟实验展示了在不规则地形上敏捷移动和可靠的跌倒恢复能力，同时在结构化室内空间中实现目标导向导航。

Conclusion: 该方法降低了在预算有限的机器人平台上部署自主导航和强健运动策略的门槛。

Abstract: Wheeled-legged robots combine the efficiency of wheels with the obstacle
negotiation of legs, yet many state-of-the-art systems rely on costly actuators
and sensors, and fall-recovery is seldom integrated, especially for
wheeled-legged morphologies. This work presents a recovery-aware
visual-inertial navigation system on a low-cost wheeled quadruped. The proposed
system leverages vision-based perception from a depth camera and deep
reinforcement learning policies for robust locomotion and autonomous recovery
from falls across diverse terrains. Simulation experiments show agile mobility
with low-torque actuators over irregular terrain and reliably recover from
external perturbations and self-induced failures. We further show goal directed
navigation in structured indoor spaces with low-cost perception. Overall, this
approach lowers the barrier to deploying autonomous navigation and robust
locomotion policies in budget-constrained robotic platforms.

</details>


### [4] [Adaptive Keyframe Selection for Scalable 3D Scene Reconstruction in Dynamic Environments](https://arxiv.org/abs/2510.23928)
*Raman Jha,Yang Zhou,Giuseppe Loianno*

Main category: cs.RO

TL;DR: 提出了一种结合误差和动量的自适应关键帧选择方法，以改善动态环境下的3D重建质量。


<details>
  <summary>Details</summary>
Motivation: 在动态环境中，实时感知的数据瓶颈问题促使提出一种方法，动态选择最具信息量的帧，以生成高质量的3D世界表示。

Method: 该方法包含两个模块：一个基于误差（光度和结构相似性误差）的选择模块，和一个基于动量的动态调整模块。

Result: 提出了一种自适应关键帧选择方法，以提高动态环境下的3D场景重建质量。该方法集成了基于误差的选择模块和基于动量的更新模块，动态调整关键帧选择阈值。实验表明，相较于传统的静态关键帧选择策略，显著提升了重建质量，特别在复杂的视觉场景中表现出色。

Conclusion: 实验结果表明，该自适应关键帧选择方法相较于传统静态选择策略，在3D重建质量上有显著提高，适用于复杂动态环境。

Abstract: In this paper, we propose an adaptive keyframe selection method for improved
3D scene reconstruction in dynamic environments. The proposed method integrates
two complementary modules: an error-based selection module utilizing
photometric and structural similarity (SSIM) errors, and a momentum-based
update module that dynamically adjusts keyframe selection thresholds according
to scene motion dynamics. By dynamically curating the most informative frames,
our approach addresses a key data bottleneck in real-time perception. This
allows for the creation of high-quality 3D world representations from a
compressed data stream, a critical step towards scalable robot learning and
deployment in complex, dynamic environments. Experimental results demonstrate
significant improvements over traditional static keyframe selection strategies,
such as fixed temporal intervals or uniform frame skipping. These findings
highlight a meaningful advancement toward adaptive perception systems that can
dynamically respond to complex and evolving visual scenes. We evaluate our
proposed adaptive keyframe selection module on two recent state-of-the-art 3D
reconstruction networks, Spann3r and CUT3R, and observe consistent improvements
in reconstruction quality across both frameworks. Furthermore, an extensive
ablation study confirms the effectiveness of each individual component in our
method, underlining their contribution to the overall performance gains.

</details>


### [5] [A Comprehensive General Model of Tendon-Actuated Concentric Tube Robots with Multiple Tubes and Tendons](https://arxiv.org/abs/2510.23954)
*Pejman Kheradmand,Behnam Moradkhani,Raghavasimhan Sankaranarayanan,Kent K. Yamamoto,Tanner J. Zachem,Patrick J. Codd,Yash Chitalia,Pierre E. Dupont*

Main category: cs.RO

TL;DR: 本文提出了一种新模型来解决肌腱驱动同心管机器人模型的局限性，通过实验验证了该模型的有效性。


<details>
  <summary>Details</summary>
Motivation: 开发一个完整的、通用的机械模型来解决肌腱驱动的同心管机器人和同心管机器人各自的局限性。

Method: 基于Cosserat杆的框架，能够模拟多个同心管的扭曲和拉伸，同时保证弯曲的共享中心线。

Result: 提出了一个基于Cosserat杆的框架，可以精确建模具有任意数量同心管的系统，并通过实验验证了模型的准确性。

Conclusion: 该模型为高级肌腱驱动同心管机器人的形状估计和控制提供了基础。

Abstract: Tendon-actuated concentric tube mechanisms combine the advantages of
tendon-driven continuum robots and concentric tube robots while addressing
their respective limitations. They overcome the restricted degrees of freedom
often seen in tendon-driven designs, and mitigate issues such as snapping
instability associated with concentric tube robots. However, a complete and
general mechanical model for these systems remains an open problem. In this
work, we propose a Cosserat rod-based framework for modeling the general case
of $n$ concentric tubes, each actuated by $m_i$ tendons, where $i = \{1,
\ldots, n\}$. The model allows each tube to twist and elongate while enforcing
a shared centerline for bending. We validate the proposed framework through
experiments with two-tube and three tube assemblies under various tendon
routing configurations, achieving tip prediction errors $<4\%$ of the robot's
total length. We further demonstrate the model's generality by applying it to
existing robots in the field, where maximum tip deviations remain around $5\%$
of the total length. This model provides a foundation for accurate shape
estimation and control of advanced tendon-actuated concentric tube robots.

</details>


### [6] [Adaptive-twist Soft Finger Mechanism for Grasping by Wrapping](https://arxiv.org/abs/2510.23963)
*Hiroki Ishikawa,Kyosuke Ishibashi,Ko Yamamoto*

Main category: cs.RO

TL;DR: 本研究提出了一种新型柔性机器人手指，能够通过自适应扭曲变形来抓取不同物体，且采用了变刚度机制来提高抓取效果。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够适应密集物体间隙的柔性机器人手指，以实现有效的抓取和操控能力。

Method: 通过有限元分析（FEA）设计了变刚度机制，并基于分析结果确定设计参数，随后进行了一系列实验以验证其抓取性能。

Result: 提出了一种能够通过变量刚度机制实现适应性扭曲变形的柔性机器人手指，并进行了实验验证。

Conclusion: 该柔性手指能够有效抓取多种物体，并展示出良好的抓取能力和适应性。

Abstract: This paper presents a soft robot finger capable of adaptive-twist deformation
to grasp objects by wrapping them. For a soft hand to grasp and pick-up one
object from densely contained multiple objects, a soft finger requires the
adaptive-twist deformation function in both in-plane and out-of-plane
directions. The function allows the finger to be inserted deeply into a limited
gap among objects. Once inserted, the soft finger requires appropriate control
of grasping force normal to contact surface, thereby maintaining the twisted
deformation. In this paper, we refer to this type of grasping as grasping by
wrapping. To achieve these two functions by a single actuation source, we
propose a variable stiffness mechanism that can adaptively change the stiffness
as the pressure is higher. We conduct a finite element analysis (FEA) on the
proposed mechanism and determine its design parameter based on the FEA result.
Using the developed soft finger, we report basic experimental results and
demonstrations on grasping various objects.

</details>


### [7] [A Survey on Collaborative SLAM with 3D Gaussian Splatting](https://arxiv.org/abs/2510.23988)
*Phuc Nguyen Xuan,Thanh Nguyen Canh,Huu-Hung Nguyen,Nak Young Chong,Xiem HoangVan*

Main category: cs.RO

TL;DR: 本调查回顾了3D高斯呈现下的多机器人协作SLAM的发展，分析了系统架构、主要技术组件，并总结数据集和评估指标，指出未来研究挑战与方向。


<details>
  <summary>Details</summary>
Motivation: 随着多机器人系统的应用增多，实时高保真渲染的需求增长，3D高斯渲染作为场景表示方法在机器人领域的多机器人协作SLAM中显得尤为重要。

Method: 通过对现有方法的分类，分析多智能体一致性、数据融合、语义提取等核心技术，结合实际数据集与评估标准进行性能评估。

Result: 对多机器人协作的SLAM领域进行了系统性的分类与分析，提出了当前存在的挑战和未来的研究方向。

Conclusion: 文中总结了多机器人SLAM面临的关键挑战，并指出了如终身映射、语义关联及建图等未来研究方向。

Abstract: This survey comprehensively reviews the evolving field of multi-robot
collaborative Simultaneous Localization and Mapping (SLAM) using 3D Gaussian
Splatting (3DGS). As an explicit scene representation, 3DGS has enabled
unprecedented real-time, high-fidelity rendering, ideal for robotics. However,
its use in multi-robot systems introduces significant challenges in maintaining
global consistency, managing communication, and fusing data from heterogeneous
sources. We systematically categorize approaches by their architecture --
centralized, distributed -- and analyze core components like multi-agent
consistency and alignment, communication-efficient, Gaussian representation,
semantic distillation, fusion and pose optimization, and real-time scalability.
In addition, a summary of critical datasets and evaluation metrics is provided
to contextualize performance. Finally, we identify key open challenges and
chart future research directions, including lifelong mapping, semantic
association and mapping, multi-model for robustness, and bridging the Sim2Real
gap.

</details>


### [8] [VOCALoco: Viability-Optimized Cost-aware Adaptive Locomotion](https://arxiv.org/abs/2510.23997)
*Stanley Wu,Mohamad H. Danesh,Simon Li,Hanna Yurchyk,Amin Abyaneh,Anas El Houssaini,David Meger,Hsiu-Chin Lin*

Main category: cs.RO

TL;DR: VOCALoco是一个模块化技能选择框架，通过感知输入动态调整腿部机器人在复杂地形上的步态, 克服了基于深度强化学习的局限性。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有腿部机器人在复杂地形上使用深度强化学习时的安全性和可解释性问题。

Method: VOCALoco基于预训练的步态策略，评估其在特定地形中的可行性和能耗，通过预测执行安全性和预计运输成本，从而选择安全且高效的策略。

Result: VOCALoco在楼梯攀爬任务中，无论是在模拟还是现实场景下，相比于传统策略表现出更好的稳健性和安全性。

Conclusion: VOCALoco框架显著提高了机器人的攀爬和下行安全性与稳健性，优于传统的全连接深度强化学习策略。

Abstract: Recent advancements in legged robot locomotion have facilitated traversal
over increasingly complex terrains. Despite this progress, many existing
approaches rely on end-to-end deep reinforcement learning (DRL), which poses
limitations in terms of safety and interpretability, especially when
generalizing to novel terrains. To overcome these challenges, we introduce
VOCALoco, a modular skill-selection framework that dynamically adapts
locomotion strategies based on perceptual input. Given a set of pre-trained
locomotion policies, VOCALoco evaluates their viability and energy-consumption
by predicting both the safety of execution and the anticipated cost of
transport over a fixed planning horizon. This joint assessment enables the
selection of policies that are both safe and energy-efficient, given the
observed local terrain. We evaluate our approach on staircase locomotion tasks,
demonstrating its performance in both simulated and real-world scenarios using
a quadrupedal robot. Empirical results show that VOCALoco achieves improved
robustness and safety during stair ascent and descent compared to a
conventional end-to-end DRL policy

</details>


### [9] [Improved Accuracy of Robot Localization Using 3-D LiDAR in a Hippocampus-Inspired Model](https://arxiv.org/abs/2510.24029)
*Andrew Gerstenslager,Bekarys Dukenbaev,Ali A. Minai*

Main category: cs.RO

TL;DR: 提出了一个三维边界向量细胞模型，改进了在复杂环境中定位的精确性。


<details>
  <summary>Details</summary>
Motivation: 现有的二维BVC模型在存在水平对称性的环境中易受空间歧义影响。

Method: 通过处理LiDAR数据捕捉垂直轮廓，实现更好的边界检测。

Result: 与二维基线相比，在三维复杂环境中，提出的模型显著减少了空间别名现象。

Conclusion: 添加垂直维度的BVC模型在三维环境中显著提高了导航和映射的能力。

Abstract: Boundary Vector Cells (BVCs) are a class of neurons in the brains of
vertebrates that encode environmental boundaries at specific distances and
allocentric directions, playing a central role in forming place fields in the
hippocampus. Most computational BVC models are restricted to two-dimensional
(2D) environments, making them prone to spatial ambiguities in the presence of
horizontal symmetries in the environment. To address this limitation, we
incorporate vertical angular sensitivity into the BVC framework, thereby
enabling robust boundary detection in three dimensions, and leading to
significantly more accurate spatial localization in a biologically-inspired
robot model.
  The proposed model processes LiDAR data to capture vertical contours, thereby
disambiguating locations that would be indistinguishable under a purely 2D
representation. Experimental results show that in environments with minimal
vertical variation, the proposed 3D model matches the performance of a 2D
baseline; yet, as 3D complexity increases, it yields substantially more
distinct place fields and markedly reduces spatial aliasing. These findings
show that adding a vertical dimension to BVC-based localization can
significantly enhance navigation and mapping in real-world 3D spaces while
retaining performance parity in simpler, near-planar scenarios.

</details>


### [10] [SynAD: Enhancing Real-World End-to-End Autonomous Driving Models through Synthetic Data Integration](https://arxiv.org/abs/2510.24052)
*Jongsuk Kim,Jaeyoung Lee,Gyojin Han,Dongjae Lee,Minki Jeong,Junmo Kim*

Main category: cs.RO

TL;DR: 提出了一种名为SynAD的新框架，通过合成数据增强真实世界的端到端自动驾驶模型。


<details>
  <summary>Details</summary>
Motivation: 解决依赖真实数据限制的多样性问题，探索合成场景生成在端到端自动驾驶模型中的应用。

Method: 通过指定具有最全面驾驶信息的智能体为自我车辆，同时将路径级场景投影到地图上，并利用Map-to-BEV网络提取鸟瞰图特征，最后制定有效的训练策略。

Result: 实验结果表明，SynAD不仅增强了模型的安全性，还为更全面的自动驾驶模型奠定了基础。

Conclusion: SynAD成功整合了合成和真实数据，显著提升了自动驾驶的安全性能。

Abstract: Recent advancements in deep learning and the availability of high-quality
real-world driving datasets have propelled end-to-end autonomous driving.
Despite this progress, relying solely on real-world data limits the variety of
driving scenarios for training. Synthetic scenario generation has emerged as a
promising solution to enrich the diversity of training data; however, its
application within E2E AD models remains largely unexplored. This is primarily
due to the absence of a designated ego vehicle and the associated sensor
inputs, such as camera or LiDAR, typically provided in real-world scenarios. To
address this gap, we introduce SynAD, the first framework designed to enhance
real-world E2E AD models using synthetic data. Our method designates the agent
with the most comprehensive driving information as the ego vehicle in a
multi-agent synthetic scenario. We further project path-level scenarios onto
maps and employ a newly developed Map-to-BEV Network to derive bird's-eye-view
features without relying on sensor inputs. Finally, we devise a training
strategy that effectively integrates these map-based synthetic data with real
driving data. Experimental results demonstrate that SynAD effectively
integrates all components and notably enhances safety performance. By bridging
synthetic scenario generation and E2E AD, SynAD paves the way for more
comprehensive and robust autonomous driving models.

</details>


### [11] [Language-Conditioned Representations and Mixture-of-Experts Policy for Robust Multi-Task Robotic Manipulation](https://arxiv.org/abs/2510.24055)
*Xiucheng Zhang,Yang Jiang,Hongwei Qing,Jiashuo Bai*

Main category: cs.RO

TL;DR: 本研究提出了一种结合语言和视觉的多任务操控框架，显著提升了成功率。


<details>
  <summary>Details</summary>
Motivation: 解决多任务机器人操控中的感知模糊和任务冲突

Method: 结合语言条件视觉表示模块（LCVR）和语言条件混合专家密度策略（LMoE-DP）的框架

Result: 在真实机器人基准测试中，成功率提高了33.75%和25%，总成功率达到79%

Conclusion: 结合语义基础和专家专门化使得多任务操作更加稳健有效。

Abstract: Perceptual ambiguity and task conflict limit multitask robotic manipulation
via imitation learning. We propose a framework combining a Language-Conditioned
Visual Representation (LCVR) module and a Language-conditioned
Mixture-ofExperts Density Policy (LMoE-DP). LCVR resolves perceptual
ambiguities by grounding visual features with language instructions, enabling
differentiation between visually similar tasks. To mitigate task conflict,
LMoE-DP uses a sparse expert architecture to specialize in distinct, multimodal
action distributions, stabilized by gradient modulation. On real-robot
benchmarks, LCVR boosts Action Chunking with Transformers (ACT) and Diffusion
Policy (DP) success rates by 33.75% and 25%, respectively. The full framework
achieves a 79% average success, outperforming the advanced baseline by 21%. Our
work shows that combining semantic grounding and expert specialization enables
robust, efficient multi-task manipulation

</details>


### [12] [Balanced Collaborative Exploration via Distributed Topological Graph Voronoi Partition](https://arxiv.org/abs/2510.24067)
*Tianyi Ding,Ronghao Zheng,Senlin Zhang,Meiqin Liu*

Main category: cs.RO

TL;DR: 本研究提出了一种新方法，针对多机器人在复杂环境中进行协作探索，提高了效率和工作均匀性，使用了拓扑地图和分布式算法。


<details>
  <summary>Details</summary>
Motivation: 解决多机器人在障碍密集和非凸环境中进行在线协作探索的问题，特别是如何进行有效的区域划分和任务分配。

Method: 提出了一种新颖的拓扑地图结构，结合分布式权重拓扑图Voronoi算法，进行区域划分和任务分配，并利用局部规划优化探索目标的访问顺序。

Result: 研究结果表明，与现有方法相比，该方法在探索效率、完整性和工作负载平衡方面表现出显著改进。

Conclusion: 该研究展示了在复杂环境中多机器人协作探索的有效方法，显著提升了探索效率和工作均衡性。

Abstract: This work addresses the collaborative multi-robot autonomous online
exploration problem, particularly focusing on distributed exploration planning
for dynamically balanced exploration area partition and task allocation among a
team of mobile robots operating in obstacle-dense non-convex environments.
  We present a novel topological map structure that simultaneously
characterizes both spatial connectivity and global exploration completeness of
the environment. The topological map is updated incrementally to utilize known
spatial information for updating reachable spaces, while exploration targets
are planned in a receding horizon fashion under global coverage guidance.
  A distributed weighted topological graph Voronoi algorithm is introduced
implementing balanced graph space partitions of the fused topological maps.
Theoretical guarantees are provided for distributed consensus convergence and
equitable graph space partitions with constant bounds.
  A local planner optimizes the visitation sequence of exploration targets
within the balanced partitioned graph space to minimize travel distance, while
generating safe, smooth, and dynamically feasible motion trajectories.
  Comprehensive benchmarking against state-of-the-art methods demonstrates
significant improvements in exploration efficiency, completeness, and workload
balance across the robot team.

</details>


### [13] [Dynamically-Consistent Trajectory Optimization for Legged Robots via Contact Point Decomposition](https://arxiv.org/abs/2510.24069)
*Sangmin Kim,Hajun Kim,Gijeong Kim,Min-Gyu Kim,Hae-Won Park*

Main category: cs.RO

TL;DR: 该论文提出了一种创新的基于相位的轨迹优化框架，确保腿足机器人在运动中满足动力学和接触约束。


<details>
  <summary>Details</summary>
Motivation: 在腿足机器人中，生成可靠的运动需要同时计算机器人的路径和接触序列，并准确考虑动力学。

Method: 利用线性微分方程的叠加特性解耦各接触点的平移动力学，并通过Bézier多项式的微分矩阵推导出机器人的位置与力之间的解析关系，确保平移动力学的满足，同时利用Bézier多项式的凸闭包特性确保摩擦锥约束的符合。

Result: 提出了一种基于相位的轨迹优化方法，能够在整个轨迹中确保平移动力学和摩擦锥约束的可行性。

Conclusion: 使用该框架，可以为腿足机器人生成动态可靠的运动，且兼容多种步态序列。

Abstract: To generate reliable motion for legged robots through trajectory
optimization, it is crucial to simultaneously compute the robot's path and
contact sequence, as well as accurately consider the dynamics in the problem
formulation. In this paper, we present a phase-based trajectory optimization
that ensures the feasibility of translational dynamics and friction cone
constraints throughout the entire trajectory. Specifically, our approach
leverages the superposition properties of linear differential equations to
decouple the translational dynamics for each contact point, which operates
under different phase sequences. Furthermore, we utilize the differentiation
matrix of B{\'e}zier polynomials to derive an analytical relationship between
the robot's position and force, thereby ensuring the consistent satisfaction of
translational dynamics. Additionally, by exploiting the convex closure property
of B{\'e}zier polynomials, our method ensures compliance with friction cone
constraints. Using the aforementioned approach, the proposed trajectory
optimization framework can generate dynamically reliable motions with various
gait sequences for legged robots. We validate our framework using a quadruped
robot model, focusing on the feasibility of dynamics and motion generation.

</details>


### [14] [ZTRS: Zero-Imitation End-to-end Autonomous Driving with Trajectory Scoring](https://arxiv.org/abs/2510.24108)
*Zhenxin Li,Wenhao Yao,Zi Wang,Xinglong Sun,Jingde Chen,Nadine Chang,Maying Shen,Jingyu Song,Zuxuan Wu,Shiyi Lan,Jose M. Alvarez*

Main category: cs.RO

TL;DR: ZTRS是一个端到端的自主驾驶框架，利用强化学习从原始传感器数据学习，无需模仿学习，表现优越。


<details>
  <summary>Details</summary>
Motivation: 避免模仿学习的局限性，并利用原始传感器数据进行端到端训练

Method: ZTRS框架利用无模仿学习的强化学习方法

Result: ZTRS在Navhard上达到最先进的结果，并在HUGSIM上超过基于模仿学习的基准

Conclusion: ZTRS展示了在复杂环境下进行有效规划的潜力，推动了无模仿学习的应用。

Abstract: End-to-end autonomous driving maps raw sensor inputs directly into
ego-vehicle trajectories to avoid cascading errors from perception modules and
to leverage rich semantic cues. Existing frameworks largely rely on Imitation
Learning (IL), which can be limited by sub-optimal expert demonstrations and
covariate shift during deployment. On the other hand, Reinforcement Learning
(RL) has recently shown potential in scaling up with simulations, but is
typically confined to low-dimensional symbolic inputs (e.g. 3D objects and
maps), falling short of full end-to-end learning from raw sensor data. We
introduce ZTRS (Zero-Imitation End-to-End Autonomous Driving with Trajectory
Scoring), a framework that combines the strengths of both worlds: sensor inputs
without losing information and RL training for robust planning. To the best of
our knowledge, ZTRS is the first framework that eliminates IL entirely by only
learning from rewards while operating directly on high-dimensional sensor data.
ZTRS utilizes offline reinforcement learning with our proposed Exhaustive
Policy Optimization (EPO), a variant of policy gradient tailored for enumerable
actions and rewards. ZTRS demonstrates strong performance across three
benchmarks: Navtest (generic real-world open-loop planning), Navhard (open-loop
planning in challenging real-world and synthetic scenarios), and HUGSIM
(simulated closed-loop driving). Specifically, ZTRS achieves the
state-of-the-art result on Navhard and outperforms IL-based baselines on
HUGSIM. Code will be available at https://github.com/woxihuanjiangguo/ZTRS.

</details>


### [15] [PFEA: An LLM-based High-Level Natural Language Planning and Feedback Embodied Agent for Human-Centered AI](https://arxiv.org/abs/2510.24109)
*Wenbin Ding,Jun Chen,Mingjia Chen,Fei Xie,Qi Mao,Philip Dames*

Main category: cs.RO

TL;DR: 本文探讨了基于视觉-语言模型（VLMs）的智能机器人操作代理的实施，提出了一种新型的机器人实体代理框架，显著提高了复杂自然语言指令任务的执行成功率。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）的快速发展，人机交互的质量对智能机器人的要求越来越高，尤其是在自然语言交互和复杂任务规划方面。

Method: 开发了一个包含人机语音交互模块、视觉-语言代理模块和行动执行模块的机器人实体代理框架，视觉-语言代理模块包括任务规划器、指令转换器和任务反馈评估器。

Result: 提出了一种新颖的机器人实体代理框架，该框架在模拟和真实环境中相比于传统方法提高了28%的任务成功率。

Conclusion: 实验结果表明，所提出的代理在自然语言指令任务的执行上具有显著优势，能更好地适应人类中心的人工智能需求。

Abstract: The rapid advancement of Large Language Models (LLMs) has marked a
significant breakthrough in Artificial Intelligence (AI), ushering in a new era
of Human-centered Artificial Intelligence (HAI). HAI aims to better serve human
welfare and needs, thereby placing higher demands on the intelligence level of
robots, particularly in aspects such as natural language interaction, complex
task planning, and execution. Intelligent agents powered by LLMs have opened up
new pathways for realizing HAI. However, existing LLM-based embodied agents
often lack the ability to plan and execute complex natural language control
tasks online. This paper explores the implementation of intelligent robotic
manipulating agents based on Vision-Language Models (VLMs) in the physical
world. We propose a novel embodied agent framework for robots, which comprises
a human-robot voice interaction module, a vision-language agent module and an
action execution module. The vision-language agent itself includes a
vision-based task planner, a natural language instruction converter, and a task
performance feedback evaluator. Experimental results demonstrate that our agent
achieves a 28\% higher average task success rate in both simulated and real
environments compared to approaches relying solely on LLM+CLIP, significantly
improving the execution success rate of high-level natural language instruction
tasks.

</details>


### [16] [LagMemo: Language 3D Gaussian Splatting Memory for Multi-modal Open-vocabulary Multi-goal Visual Navigation](https://arxiv.org/abs/2510.24118)
*Haotian Zhou,Xiaole Wang,He Li,Fusheng Sun,Shengyu Guo,Guolei Qi,Jianghuan Xu,Huijing Zhao*

Main category: cs.RO

TL;DR: LagMemo是一种新型导航系统，能在多模态开放词汇环境中有效导航并超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决传统视觉导航方法在多目标、多模态及开放词汇环境下的局限性

Method: 构建基于语言的3D高斯记忆导航系统LagMemo

Result: LagMemo能够有效地实现多模态开放词汇目标定位，并在多目标视觉导航中优于现有的最先进方法

Conclusion: LagMemo通过语言记忆模块提高了多目标视觉导航的有效性，展示了其在实际应用中的潜力。

Abstract: Navigating to a designated goal using visual information is a fundamental
capability for intelligent robots. Most classical visual navigation methods are
restricted to single-goal, single-modality, and closed set goal settings. To
address the practical demands of multi-modal, open-vocabulary goal queries and
multi-goal visual navigation, we propose LagMemo, a navigation system that
leverages a language 3D Gaussian Splatting memory. During exploration, LagMemo
constructs a unified 3D language memory. With incoming task goals, the system
queries the memory, predicts candidate goal locations, and integrates a local
perception-based verification mechanism to dynamically match and validate goals
during navigation. For fair and rigorous evaluation, we curate GOAT-Core, a
high-quality core split distilled from GOAT-Bench tailored to multi-modal
open-vocabulary multi-goal visual navigation. Experimental results show that
LagMemo's memory module enables effective multi-modal open-vocabulary goal
localization, and that LagMemo outperforms state-of-the-art methods in
multi-goal visual navigation. Project page:
https://weekgoodday.github.io/lagmemo

</details>


### [17] [Blindfolded Experts Generalize Better: Insights from Robotic Manipulation and Videogames](https://arxiv.org/abs/2510.24194)
*Ev Zisselman,Mirco Mutti,Shelly Francis-Meretzki,Elisei Shafer,Aviv Tamar*

Main category: cs.RO

TL;DR: 本研究提出通过训练盲目专家来提升行为克隆的泛化能力，实验证明该方法在少量示范下效果更佳。


<details>
  <summary>Details</summary>
Motivation: 提升行为克隆技术在多个任务中的泛化能力，尤其是在仅有有限示范的情况下。

Method: 通过隐藏任务信息来训练盲目专家，以促使其进行非平凡探索，从而克隆该专家的行为。

Result: 实验结果表明，盲目专家在现实世界的机器人任务和Procgen基准中的视频游戏任务上表现优异。

Conclusion: 采用盲目专家的行为克隆方法在未见任务上的泛化能力较强，且在较少的示范任务中依然有效。

Abstract: Behavioral cloning is a simple yet effective technique for learning
sequential decision-making from demonstrations. Recently, it has gained
prominence as the core of foundation models for the physical world, where
achieving generalization requires countless demonstrations of a multitude of
tasks. Typically, a human expert with full information on the task demonstrates
a (nearly) optimal behavior. In this paper, we propose to hide some of the
task's information from the demonstrator. This ``blindfolded'' expert is
compelled to employ non-trivial exploration to solve the task. We show that
cloning the blindfolded expert generalizes better to unseen tasks than its
fully-informed counterpart. We conduct experiments of real-world robot peg
insertion tasks with (limited) human demonstrations, alongside videogames from
the Procgen benchmark. Additionally, we support our findings with theoretical
analysis, which confirms that the generalization error scales with
$\sqrt{I/m}$, where $I$ measures the amount of task information available to
the demonstrator, and $m$ is the number of demonstrated tasks. Both theory and
practice indicate that cloning blindfolded experts generalizes better with
fewer demonstrated tasks. Project page with videos and code:
https://sites.google.com/view/blindfoldedexperts/home

</details>


### [18] [Manipulate as Human: Learning Task-oriented Manipulation Skills by Adversarial Motion Priors](https://arxiv.org/abs/2510.24257)
*Ziqi Ma,Changda Tian,Yue Gao*

Main category: cs.RO

TL;DR: 本文提出了一种新颖的方法HMAMP，通过对抗运动先验来学习人类风格的操作技能，目标是使机器人以更自然的方式与人类互动。


<details>
  <summary>Details</summary>
Motivation: 为实现机器人与人类的自然互动，需使其以类似人类的方式操作工具和物体。

Method: 利用对抗网络建模工具和物体操作的复杂动态，结合真实数据与仿真数据训练判别器，以生成符合人类运动统计特性的运动轨迹。

Result: 在重锤任务中，HMAMP表现优于现有基准方法，并在真实机器人臂任务中展示了应用潜力。

Conclusion: HMAMP显著提升了机器人在物体操作任务中的表现，具有实际应用潜力。

Abstract: In recent years, there has been growing interest in developing robots and
autonomous systems that can interact with human in a more natural and intuitive
way. One of the key challenges in achieving this goal is to enable these
systems to manipulate objects and tools in a manner that is similar to that of
humans. In this paper, we propose a novel approach for learning human-style
manipulation skills by using adversarial motion priors, which we name HMAMP.
The approach leverages adversarial networks to model the complex dynamics of
tool and object manipulation, as well as the aim of the manipulation task. The
discriminator is trained using a combination of real-world data and simulation
data executed by the agent, which is designed to train a policy that generates
realistic motion trajectories that match the statistical properties of human
motion. We evaluated HMAMP on one challenging manipulation task: hammering, and
the results indicate that HMAMP is capable of learning human-style manipulation
skills that outperform current baseline methods. Additionally, we demonstrate
that HMAMP has potential for real-world applications by performing real robot
arm hammering tasks. In general, HMAMP represents a significant step towards
developing robots and autonomous systems that can interact with humans in a
more natural and intuitive way, by learning to manipulate tools and objects in
a manner similar to how humans do.

</details>


### [19] [DynaRend: Learning 3D Dynamics via Masked Future Rendering for Robotic Manipulation](https://arxiv.org/abs/2510.24261)
*Jingyi Tian,Le Wang,Sanping Zhou,Sen Wang,Jiayi Li,Gang Hua*

Main category: cs.RO

TL;DR: DynaRend提出了一种新颖的表示学习框架，通过掩码重建和未来预测，有效地抓取3D几何、动态和语义，显著提升了机器人的操作成功率和环境适应性。


<details>
  <summary>Details</summary>
Motivation: 解决在机器人操作政策中缺乏多样化真实世界训练数据的问题，并同时学习几何、语义和动态信息。

Method: DynaRend：通过掩码重建和未来预测，利用可微分体积渲染学习三维感知和动态信息的三平面特征。

Result: DynaRend可以有效捕捉空间几何、未来动态和任务语义，并成功转移到下游的机器人操作任务中。

Conclusion: 在RLBench、Colosseum基准测试及现实世界实验中，DynaRend显示出在政策成功率、对环境干扰的泛化能力和多样化操作任务的现实应用性上的显著改进。

Abstract: Learning generalizable robotic manipulation policies remains a key challenge
due to the scarcity of diverse real-world training data. While recent
approaches have attempted to mitigate this through self-supervised
representation learning, most either rely on 2D vision pretraining paradigms
such as masked image modeling, which primarily focus on static semantics or
scene geometry, or utilize large-scale video prediction models that emphasize
2D dynamics, thus failing to jointly learn the geometry, semantics, and
dynamics required for effective manipulation. In this paper, we present
DynaRend, a representation learning framework that learns 3D-aware and
dynamics-informed triplane features via masked reconstruction and future
prediction using differentiable volumetric rendering. By pretraining on
multi-view RGB-D video data, DynaRend jointly captures spatial geometry, future
dynamics, and task semantics in a unified triplane representation. The learned
representations can be effectively transferred to downstream robotic
manipulation tasks via action value map prediction. We evaluate DynaRend on two
challenging benchmarks, RLBench and Colosseum, as well as in real-world robotic
experiments, demonstrating substantial improvements in policy success rate,
generalization to environmental perturbations, and real-world applicability
across diverse manipulation tasks.

</details>


### [20] [Global-State-Free Obstacle Avoidance for Quadrotor Control in Air-Ground Cooperation](https://arxiv.org/abs/2510.24315)
*Baozhe Zhang,Xinwei Chen,Qingcheng Chen,Chao Xu,Fei Gao,Yanjun Cao*

Main category: cs.RO

TL;DR: 本研究提出了一种基于调制的新型障碍物避免算法CoNi-OA，专门针对UAV-UGV协作，在动态和不确定环境中确保实时且安全的轨迹生成，无需全球状态估计和障碍物预测。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决CoNi-MPC在面临环境信息缺失时，UAV在动态和不可预测环境中的障碍物规避挑战。

Method: 本研究提出的CoNi-OA采用基于调制的方法，利用UAV的单帧LiDAR数据生成调制矩阵，从而调整四旋翼的速度进行障碍物规避。

Result: CoNi-OA 能够在UGV的非惯性框架内实时生成无碰撞轨迹，并降低计算需求，确保在动态、不可预测环境中的安全。

Conclusion: CoNi-OA提供了一种高效的障碍物避免算法，能够在不依赖全球状态估计或障碍物预测的情况下，确保UAV-UGV协作的安全性和实时性。

Abstract: CoNi-MPC provides an efficient framework for UAV control in air-ground
cooperative tasks by relying exclusively on relative states, eliminating the
need for global state estimation. However, its lack of environmental
information poses significant challenges for obstacle avoidance. To address
this issue, we propose a novel obstacle avoidance algorithm, Cooperative
Non-inertial frame-based Obstacle Avoidance (CoNi-OA), designed explicitly for
UAV-UGV cooperative scenarios without reliance on global state estimation or
obstacle prediction. CoNi-OA uniquely utilizes a single frame of raw LiDAR data
from the UAV to generate a modulation matrix, which directly adjusts the
quadrotor's velocity to achieve obstacle avoidance. This modulation-based
method enables real-time generation of collision-free trajectories within the
UGV's non-inertial frame, significantly reducing computational demands (less
than 5 ms per iteration) while maintaining safety in dynamic and unpredictable
environments. The key contributions of this work include: (1) a
modulation-based obstacle avoidance algorithm specifically tailored for UAV-UGV
cooperation in non-inertial frames without global states; (2) rapid, real-time
trajectory generation based solely on single-frame LiDAR data, removing the
need for obstacle modeling or prediction; and (3) adaptability to both static
and dynamic environments, thus extending applicability to featureless or
unknown scenarios.

</details>


### [21] [NVSim: Novel View Synthesis Simulator for Large Scale Indoor Navigation](https://arxiv.org/abs/2510.24335)
*Mingyu Jeong,Eunsung Kim,Sehun Park,Andrew Jaeyong Choi*

Main category: cs.RO

TL;DR: 这篇论文提出了NVSim框架，通过常见图像序列自动构建大规模室内模拟器，克服了传统3D扫描的限制，并演示了系统生成有效导航图的能力。


<details>
  <summary>Details</summary>
Motivation: 解决传统3D扫描的成本和可扩展性限制，特别是在稀疏观察的地面上处理视觉伪影。

Method: 采用3D Gaussian Splatting技术及Floor-Aware Gaussian Splatting，结合新算法构建可导航的大规模室内模拟器。

Result: 成功生成有效的大规模导航图，并可通过真实数据进行验证。

Conclusion: NVSim框架在生成可导航地面和构建拓扑图方面表现出色，展示了从真实世界数据中生成导航图的能力。

Abstract: We present NVSim, a framework that automatically constructs large-scale,
navigable indoor simulators from only common image sequences, overcoming the
cost and scalability limitations of traditional 3D scanning. Our approach
adapts 3D Gaussian Splatting to address visual artifacts on sparsely observed
floors a common issue in robotic traversal data. We introduce Floor-Aware
Gaussian Splatting to ensure a clean, navigable ground plane, and a novel
mesh-free traversability checking algorithm that constructs a topological graph
by directly analyzing rendered views. We demonstrate our system's ability to
generate valid, large-scale navigation graphs from real-world data. A video
demonstration is avilable at https://youtu.be/tTiIQt6nXC8

</details>


### [22] [Flatness-based trajectory planning for 3D overhead cranes with friction compensation and collision avoidance](https://arxiv.org/abs/2510.24457)
*Jorge Vicente-Martinez,Edgar Ramirez-Laboreo*

Main category: cs.RO

TL;DR: 本文提出了一种基于微分平坦性的方法，能够在考虑复杂物理和动态约束的情况下生成3D起重机的最佳轨迹，验证了摩擦建模的重要性。


<details>
  <summary>Details</summary>
Motivation: 提出一个方法，以直接纳入复杂的物理和动态约束，如非线性摩擦和避免碰撞。

Method: 基于微分平坦性的方法生成三维悬挂起重机的最佳轨迹。

Result: 比较模拟研究表明，忽视干摩擦会导致执行器饱和和碰撞。

Conclusion: 考虑干摩擦建模是确保快速安全的起重机轨迹的基本需求。

Abstract: This paper presents an optimal trajectory generation method for 3D overhead
cranes by leveraging differential flatness. This framework enables the direct
inclusion of complex physical and dynamic constraints, such as nonlinear
friction and collision avoidance for both payload and rope. Our approach allows
for aggressive movements by constraining payload swing only at the final point.
A comparative simulation study validates our approach, demonstrating that
neglecting dry friction leads to actuator saturation and collisions. The
results show that friction modeling is a fundamental requirement for fast and
safe crane trajectories.

</details>


### [23] [Supervisory Measurement-Guided Noise Covariance Estimation](https://arxiv.org/abs/2510.24508)
*Haoying Li,Yifan Peng,Junfeng Wu*

Main category: cs.RO

TL;DR: 本文提出了一种双层优化的噪声协方差估计方法，利用贝叶斯视角提高了噪声协方差估计的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 准确的传感器噪声协方差是可靠状态估计的关键，但在实际应用中，由于环境变化和前端预处理等原因，识别这些协方差非常困难。

Method: 通过将噪声协方差估计公式化为双层优化，使用不变扩展卡尔曼滤波器估计轨迹，并在上层使用导数滤波器进行并行计算，用以动态更新协方差。

Result: 通过提出一种双层优化方法，将噪声协方差估计问题有效解决，从而提高信息利用率和计算效率。

Conclusion: 实验表明，与现有基准相比，我们的方法在合成和真实世界数据集上显示出更高的效率。

Abstract: Reliable state estimation hinges on accurate specification of sensor noise
covariances, which weigh heterogeneous measurements. In practice, these
covariances are difficult to identify due to environmental variability,
front-end preprocessing, and other reasons. We address this by formulating
noise covariance estimation as a bilevel optimization that, from a Bayesian
perspective, factorizes the joint likelihood of so-called odometry and
supervisory measurements, thereby balancing information utilization with
computational efficiency. The factorization converts the nested Bayesian
dependency into a chain structure, enabling efficient parallel computation: at
the lower level, an invariant extended Kalman filter with state augmentation
estimates trajectories, while a derivative filter computes analytical gradients
in parallel for upper-level gradient updates. The upper level refines the
covariance to guide the lower-level estimation. Experiments on synthetic and
real-world datasets show that our method achieves higher efficiency over
existing baselines.

</details>


### [24] [Stochastic Prize-Collecting Games: Strategic Planning in Multi-Robot Systems](https://arxiv.org/abs/2510.24515)
*Malintha Fernando,Petter Ögren,Silun Zhang*

Main category: cs.RO

TL;DR: 本文提出了SPCG作为TOP的扩展，在自利机器人之间规划并进行竞争，提出了有效算法，并在实验中验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 解决多机器人系统中的竞争问题，扩展以往机器人协作的模型，更好地适应奖赏稀缺的环境。

Method: 提出随机奖赏收集博弈 (SPCG) 作为团队定向问题 (TOP) 的扩展，研究自利机器人的相互竞争与规划。

Result: 通过理论研究和算法实验，展示SPCG在特定图形下存在唯一的纯纳什均衡，并通过两种算法（ORS和FORL）提高了多机器人系统的政策学习效率。

Conclusion: 在多机器人任务中，SPCG能实现高达95%的最优性，为未来的竞争环境中的机器人规划提供了有效的解决方案。

Abstract: The Team Orienteering Problem (TOP) generalizes many real-world multi-robot
scheduling and routing tasks that occur in autonomous mobility, aerial
logistics, and surveillance applications. While many flavors of the TOP exist
for planning in multi-robot systems, they assume that all the robots cooperate
toward a single objective; thus, they do not extend to settings where the
robots compete in reward-scarce environments. We propose Stochastic
Prize-Collecting Games (SPCG) as an extension of the TOP to plan in the
presence of self-interested robots operating on a graph, under energy
constraints and stochastic transitions. A theoretical study on complete and
star graphs establishes that there is a unique pure Nash equilibrium in SPCGs
that coincides with the optimal routing solution of an equivalent TOP given a
rank-based conflict resolution rule. This work proposes two algorithms: Ordinal
Rank Search (ORS) to obtain the ''ordinal rank'' --one's effective rank in
temporarily-formed local neighborhoods during the games' stages, and Fictitious
Ordinal Response Learning (FORL) to obtain best-response policies against one's
senior-rank opponents. Empirical evaluations conducted on road networks and
synthetic graphs under both dynamic and stationary prize distributions show
that 1) the state-aliasing induced by OR-conditioning enables learning policies
that scale more efficiently to large team sizes than those trained with the
global index, and 2) Policies trained with FORL generalize better to imbalanced
prize distributions than those with other multi-agent training methods.
Finally, the learned policies in the SPCG achieved between 87% and 95%
optimality compared to an equivalent TOP solution obtained by mixed-integer
linear programming.

</details>


### [25] [GeVI-SLAM: Gravity-Enhanced Stereo Visua Inertial SLAM for Underwater Robots](https://arxiv.org/abs/2510.24533)
*Yuan Shen,Yuze Hong,Guangyang Zeng,Tengfei Zhang,Pui Yi Chui,Ziyang Hong,Junfeng Wu*

Main category: cs.RO

TL;DR: 提出了一种新的水下机器人SLAM系统GeVI-SLAM，能够在低加速度条件下稳定工作，展示出优异的准确性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决水下机器人在视觉退化和惯性测量单元运动激励不足下的挑战

Method: GeVI-SLAM系统，将重力增强与立体视觉惯性同时定位地图技术相结合

Result: GeVI-SLAM在准确性和稳定性上优于现有最先进的方法。在IMU初始化中消除规模估计的需求，并通过最小的计算时间解决4自由度PnP问题。

Conclusion: 通过对模拟和真实世界数据的广泛实验证明，GeVI-SLAM在精度和稳定性方面均有所提升。

Abstract: Accurate visual inertial simultaneous localization and mapping (VI SLAM) for
underwater robots remains a significant challenge due to frequent visual
degeneracy and insufficient inertial measurement unit (IMU) motion excitation.
In this paper, we present GeVI-SLAM, a gravity-enhanced stereo VI SLAM system
designed to address these issues. By leveraging the stereo camera's direct
depth estimation ability, we eliminate the need to estimate scale during IMU
initialization, enabling stable operation even under low acceleration dynamics.
With precise gravity initialization, we decouple the pitch and roll from the
pose estimation and solve a 4 degrees of freedom (DOF) Perspective-n-Point
(PnP) problem for pose tracking. This allows the use of a minimal 3-point
solver, which significantly reduces computational time to reject outliers
within a Random Sample Consensus framework. We further propose a
bias-eliminated 4-DOF PnP estimator with provable consistency, ensuring the
relative pose converges to the true value as the feature number increases. To
handle dynamic motion, we refine the full 6-DOF pose while jointly estimating
the IMU covariance, enabling adaptive weighting of the gravity prior. Extensive
experiments on simulated and real-world data demonstrate that GeVI-SLAM
achieves higher accuracy and greater stability compared to state-of-the-art
methods.

</details>


### [26] [An Adaptive Inspection Planning Approach Towards Routine Monitoring in Uncertain Environments](https://arxiv.org/abs/2510.24554)
*Vignesh Kottayam Viswanathan,Yifan Bai,Scott Fredriksson,Sumeet Satpute,Christoforos Kanellakis,George Nikolakopoulos*

Main category: cs.RO

TL;DR: 提出一种分层框架，支持机器人在不确定环境中进行检验，能够在保持全局覆盖目标的同时，快速适应当地形态变化。


<details>
  <summary>Details</summary>
Motivation: 在环境模型已知的情况下，现有方法能够规划和安全追踪检验路线，然而，模型与实际情况之间的差异可能影响地表形态或引入路径障碍。

Method: 提出了一个分层框架来支持机器人在环境不确定性下进行检验。

Result: 该框架将检验任务分为生成基于历史地图的初始全局视图规划和局部视图重新规划，以适应当前的检验场景形态。

Conclusion: 通过在实际地下矿井的四足机器人部署验证了该方法的有效性。

Abstract: In this work, we present a hierarchical framework designed to support robotic
inspection under environment uncertainty. By leveraging a known environment
model, existing methods plan and safely track inspection routes to visit points
of interest. However, discrepancies between the model and actual site
conditions, caused by either natural or human activities, can alter the surface
morphology or introduce path obstructions. To address this challenge, the
proposed framework divides the inspection task into: (a) generating the initial
global view-plan for region of interests based on a historical map and (b)
local view replanning to adapt to the current morphology of the inspection
scene. The proposed hierarchy preserves global coverage objectives while
enabling reactive adaptation to the local surface morphology. This enables the
local autonomy to remain robust against environment uncertainty and complete
the inspection tasks. We validate the approach through deployments in
real-world subterranean mines using quadrupedal robot.

</details>


### [27] [Spatiotemporal Calibration of Doppler Velocity Logs for Underwater Robots](https://arxiv.org/abs/2510.24571)
*Hongxu Zhao,Guangyang Zeng,Yunling Shao,Tengfei Zhang,Junfeng Wu*

Main category: cs.RO

TL;DR: 提出了一种新的统一迭代校准框架（UIC），用于改善水下SLAM系统中传感器的外部参数及时钟偏差的校准，支持多种传感器配置。


<details>
  <summary>Details</summary>
Motivation: 解决现有DVL校准方法的不足之处，提供一个能够联立估计外参数和时间偏差的有效框架。

Method: 采用最大后验（MAP）估计和高斯过程（GP）运动先验进行DVL校准，通过交替更新运动状态和校准参数实现。

Result: 提出了一种统一迭代校准（UIC）框架，针对多种传感器配置进行Doppler速度记录仪（DVL）校准，实现高精度性能。

Conclusion: UIC框架通过高效的运动状态更新和梯度校准变量更新，为水下SLAM系统及其他多传感器校准问题提供了可靠的解决方案。

Abstract: The calibration of extrinsic parameters and clock offsets between sensors for
high-accuracy performance in underwater SLAM systems remains insufficiently
explored. Existing methods for Doppler Velocity Log (DVL) calibration are
either constrained to specific sensor configurations or rely on oversimplified
assumptions, and none jointly estimate translational extrinsics and time
offsets. We propose a Unified Iterative Calibration (UIC) framework for general
DVL sensor setups, formulated as a Maximum A Posteriori (MAP) estimation with a
Gaussian Process (GP) motion prior for high-fidelity motion interpolation. UIC
alternates between efficient GP-based motion state updates and gradient-based
calibration variable updates, supported by a provably statistically consistent
sequential initialization scheme. The proposed UIC can be applied to IMU,
cameras and other modalities as co-sensors. We release an open-source
DVL-camera calibration toolbox. Beyond underwater applications, several aspects
of UIC-such as the integration of GP priors for MAP-based calibration and the
design of provably reliable initialization procedures-are broadly applicable to
other multi-sensor calibration problems. Finally, simulations and real-world
tests validate our approach.

</details>


### [28] [Towards Quadrupedal Jumping and Walking for Dynamic Locomotion using Reinforcement Learning](https://arxiv.org/abs/2510.24584)
*Jørgen Anker Olsen,Lars Rønhaug Pettersen,Kostas Alexis*

Main category: cs.RO

TL;DR: 该论文提出了一种基于课程的强化学习框架，用于训练机器人`Olympus`的跳跃策略，展示了较高的跳跃精度和性能。


<details>
  <summary>Details</summary>
Motivation: 开发高性能的跳跃策略以提高机器人`Olympus`的动态运动能力。

Method: 使用投射运动法则改善稀疏跳跃奖励，并采用参考状态初始化方案加速动态跳跃行为的探索。

Result: 开发了针对机器人`Olympus`的垂直和水平跳跃的独立策略，并验证了其在各种地形上的表现。

Conclusion: 实验验证了机器人能够在不同地形上行走和跳跃，高水平地跨越Sim2Real差距，展示了优于以往工作的跳跃性能。

Abstract: This paper presents a curriculum-based reinforcement learning framework for
training precise and high-performance jumping policies for the robot `Olympus'.
Separate policies are developed for vertical and horizontal jumps, leveraging a
simple yet effective strategy. First, we densify the inherently sparse jumping
reward using the laws of projectile motion. Next, a reference state
initialization scheme is employed to accelerate the exploration of dynamic
jumping behaviors without reliance on reference trajectories. We also present a
walking policy that, when combined with the jumping policies, unlocks versatile
and dynamic locomotion capabilities. Comprehensive testing validates walking on
varied terrain surfaces and jumping performance that exceeds previous works,
effectively crossing the Sim2Real gap. Experimental validation demonstrates
horizontal jumps up to 1.25 m with centimeter accuracy and vertical jumps up to
1.0 m. Additionally, we show that with only minor modifications, the proposed
method can be used to learn omnidirectional jumping.

</details>


### [29] [GroundLoc: Efficient Large-Scale Outdoor LiDAR-Only Localization](https://arxiv.org/abs/2510.24623)
*Nicolai Steinke,Daniel Goehring*

Main category: cs.RO

TL;DR: GroundLoc是一种基于LiDAR的定位系统，能在大型户外环境中使用先前地图对移动机器人进行定位，展示了优于现有方法的定位精度和效率。


<details>
  <summary>Details</summary>
Motivation: 为了解决大规模户外环境中移动机器人的定位问题，开发了一种高效且易于存储的定位系统。

Method: 使用鸟瞰图像投影和R2D2或SIFT进行关键点识别与选择，以实现BEV图像地图的配准。

Result: GroundLoc在SemanticKITTI和HeLiPR数据集上超越了当前最先进的方法，且在线运行时间满足需求。

Conclusion: GroundLoc在多个传感器下的多次定位评估中均展现出卓越的性能，尤其在平均轨迹误差方面表现优异。

Abstract: In this letter, we introduce GroundLoc, a LiDAR-only localization pipeline
designed to localize a mobile robot in large-scale outdoor environments using
prior maps. GroundLoc employs a Bird's-Eye View (BEV) image projection focusing
on the perceived ground area and utilizes the place recognition network R2D2,
or alternatively, the non-learning approach Scale-Invariant Feature Transform
(SIFT), to identify and select keypoints for BEV image map registration. Our
results demonstrate that GroundLoc outperforms state-of-the-art methods on the
SemanticKITTI and HeLiPR datasets across various sensors. In the multi-session
localization evaluation, GroundLoc reaches an Average Trajectory Error (ATE)
well below 50 cm on all Ouster OS2 128 sequences while meeting online runtime
requirements. The system supports various sensor models, as evidenced by
evaluations conducted with Velodyne HDL-64E, Ouster OS2 128, Aeva Aeries II,
and Livox Avia sensors. The prior maps are stored as 2D raster image maps,
which can be created from a single drive and require only 4 MB of storage per
square kilometer. The source code is available at
https://github.com/dcmlr/groundloc.

</details>


### [30] [Multi-Agent Scenario Generation in Roundabouts with a Transformer-enhanced Conditional Variational Autoencoder](https://arxiv.org/abs/2510.24671)
*Li Li,Tobias Brinkmann,Till Temmen,Markus Eisenbarth,Jakob Andert*

Main category: cs.RO

TL;DR: 提出了一种CVAE-T模型，能够有效生成多智能体交通场景，为智能驾驶功能的验证提供支持。


<details>
  <summary>Details</summary>
Motivation: 随着智能驾驶功能日益集成，确保其功能和鲁棒性面临更大挑战。传统路测相比，基于场景的虚拟测试在时间和成本效率、可重复性以及边缘案例探索方面具有显著优势。

Method: Transformer增强的条件变分自编码器(CVAE-T)模型

Result: 提出的模型能够准确重建原始场景，并生成现实且多样的合成场景。

Conclusion: 分析表明，该模型能生成用于智能驾驶功能验证的场景，且对多智能体交互行为的评估提供了有价值的视角。

Abstract: With the increasing integration of intelligent driving functions into
serial-produced vehicles, ensuring their functionality and robustness poses
greater challenges. Compared to traditional road testing, scenario-based
virtual testing offers significant advantages in terms of time and cost
efficiency, reproducibility, and exploration of edge cases. We propose a
Transformer-enhanced Conditional Variational Autoencoder (CVAE-T) model for
generating multi-agent traffic scenarios in roundabouts, which are
characterized by high vehicle dynamics and complex layouts, yet remain
relatively underexplored in current research. The results show that the
proposed model can accurately reconstruct original scenarios and generate
realistic, diverse synthetic scenarios. Besides, two Key-Performance-Indicators
(KPIs) are employed to evaluate the interactive behavior in the generated
scenarios. Analysis of the latent space reveals partial disentanglement, with
several latent dimensions exhibiting distinct and interpretable effects on
scenario attributes such as vehicle entry timing, exit timing, and velocity
profiles. The results demonstrate the model's capability to generate scenarios
for the validation of intelligent driving functions involving multi-agent
interactions, as well as to augment data for their development and iterative
improvement.

</details>


### [31] [Feature Matching-Based Gait Phase Prediction for Obstacle Crossing Control of Powered Transfemoral Prosthesis](https://arxiv.org/abs/2510.24676)
*Jiaxuan Zhang,Yuquan Leng,Yixuan Guo,Chenglong Fu*

Main category: cs.RO

TL;DR: 本研究提出了一种利用惯性传感器和遗传算法指导电动股骨假肢在障碍物穿越中的方法，证明了其在噪声控制下的高准确性，具有显著的实用价值。


<details>
  <summary>Details</summary>
Motivation: 针对使用电动股骨假肢的截肢者在复杂地形和障碍物穿越时的困难，提出改进方法。

Method: 采用惯性传感器监测健侧踝关节，并通过遗传算法计算最佳神经网络结构，预测大腿和膝关节的所需角度。

Result: 在噪声标准差小于1的情况下，该方法在150Hz下步态阶段估计准确率达到100%，大腿角度预测误差为8.71%，膝关节角度预测误差为6.78%。

Conclusion: 该方法能准确预测步态进展和关节角度，对于电动股骨假肢在障碍物穿越中的应用具有重要实用价值。

Abstract: For amputees with powered transfemoral prosthetics, navigating obstacles or
complex terrain remains challenging. This study addresses this issue by using
an inertial sensor on the sound ankle to guide obstacle-crossing movements. A
genetic algorithm computes the optimal neural network structure to predict the
required angles of the thigh and knee joints. A gait progression prediction
algorithm determines the actuation angle index for the prosthetic knee motor,
ultimately defining the necessary thigh and knee angles and gait progression.
Results show that when the standard deviation of Gaussian noise added to the
thigh angle data is less than 1, the method can effectively eliminate noise
interference, achieving 100\% accuracy in gait phase estimation under 150 Hz,
with thigh angle prediction error being 8.71\% and knee angle prediction error
being 6.78\%. These findings demonstrate the method's ability to accurately
predict gait progression and joint angles, offering significant practical value
for obstacle negotiation in powered transfemoral prosthetics.

</details>


### [32] [Fare: Failure Resilience in Learned Visual Navigation Control](https://arxiv.org/abs/2510.24680)
*Zishuo Wang,Joel Loo,David Hsu*

Main category: cs.RO

TL;DR: Fare框架引入失败识别与恢复机制，使模仿学习政策在复杂环境中实现更好的导航与恢复能力。


<details>
  <summary>Details</summary>
Motivation: 现有的模仿学习（IL）政策在处理分布外(OOD)场景时容易出现不可预测的失败，因此需要开发能够自动检测和恢复失败的策略。

Method: Fare框架通过内嵌OOD检测与失败识别机制，结合恢复启发式，优化模仿学习策略。

Result: Fare框架成功构建出具有失败弹性的IL政策，能够在没有明确失败数据的情况下识别和检测OOD场景的失败，并提供相应的恢复策略。

Conclusion: 通过Fare框架的应用，模仿学习政策在复杂环境中的长距离导航表现得到了显著增强。

Abstract: While imitation learning (IL) enables effective visual navigation, IL
policies are prone to unpredictable failures in out-of-distribution (OOD)
scenarios. We advance the notion of failure-resilient policies, which not only
detect failures but also recover from them automatically. Failure recognition
that identifies the factors causing failure is key to informing recovery: e.g.
pinpointing image regions triggering failure detections can provide cues to
guide recovery. We present Fare, a framework to construct failure-resilient IL
policies, embedding OOD-detection and recognition in them without using
explicit failure data, and pairing them with recovery heuristics. Real-world
experiments show that Fare enables failure recovery across two different policy
architectures, enabling robust long-range navigation in complex environments.

</details>


### [33] [A Framework for the Systematic Evaluation of Obstacle Avoidance and Object-Aware Controllers](https://arxiv.org/abs/2510.24683)
*Caleb Escobedo,Nataliya Nechyporenko,Shreyas Kadekodi,Alessandro Roncone*

Main category: cs.RO

TL;DR: 提出了一种框架用于分析对象感知控制器，该框架关注机器人运动中的碰撞预防，并强调运动学、运动特征和虚拟约束的设计。


<details>
  <summary>Details</summary>
Motivation: 确保机器人在动态对象环境中的安全操作。

Method: 采用基本机器人-障碍物实验场景对机器人行为进行验证，比较三种典型的对象感知控制器。

Result: 发现对象感知控制器的设计常常缺乏运动学考虑、控制点连续性和运动特征的稳定性。

Conclusion: 该框架能够用于未来设计、比较和基准测试障碍物避免方法。

Abstract: Real-time control is an essential aspect of safe robot operation in the real
world with dynamic objects. We present a framework for the analysis of
object-aware controllers, methods for altering a robot's motion to anticipate
and avoid possible collisions. This framework is focused on three design
considerations: kinematics, motion profiles, and virtual constraints.
Additionally, the analysis in this work relies on verification of robot
behaviors using fundamental robot-obstacle experimental scenarios. To showcase
the effectiveness of our method we compare three representative object-aware
controllers. The comparison uses metrics originating from the design
considerations. From the analysis, we find that the design of object-aware
controllers often lacks kinematic considerations, continuity of control points,
and stability in movement profiles. We conclude that this framework can be used
in the future to design, compare, and benchmark obstacle avoidance methods.

</details>


### [34] [Embodying Physical Computing into Soft Robots](https://arxiv.org/abs/2510.24692)
*Jun Wang,Ziyang Zhou,Ardalan Kahak,Suyi Li*

Main category: cs.RO

TL;DR: 该论文讨论了将物理计算嵌入软机器人中的框架，提出三种独特的策略，以提高软机器人在日常使用中的鲁棒性和智能。


<details>
  <summary>Details</summary>
Motivation: 推动软机器人在日常应用中的鲁棒性和智能化，以适应更复杂的任务。

Method: 通过分析文献中三种物理计算策略，展示其工作原理及现状。

Result: 提出了物理计算的多种方法，软机器人能够实现复杂行为，例如协调运动、负载分类和基于逻辑规则的编程操作。

Conclusion: 这些嵌入的物理计算方法将为软机器人赋予复杂行为能力，并为未来的发展提供视角。

Abstract: Softening and onboarding computers and controllers is one of the final
frontiers in soft robotics towards their robustness and intelligence for
everyday use. In this regard, embodying soft and physical computing presents
exciting potential. Physical computing seeks to encode inputs into a mechanical
computing kernel and leverage the internal interactions among this kernel's
constituent elements to compute the output. Moreover, such input-to-output
evolution can be re-programmable. This perspective paper proposes a framework
for embodying physical computing into soft robots and discusses three unique
strategies in the literature: analog oscillators, physical reservoir computing,
and physical algorithmic computing. These embodied computers enable the soft
robot to perform complex behaviors that would otherwise require CMOS-based
electronics -- including coordinated locomotion with obstacle avoidance,
payload weight and orientation classification, and programmable operation based
on logical rules. This paper will detail the working principles of these
embodied physical computing methods, survey the current state-of-the-art, and
present a perspective for future development.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [35] [Reality Distortion Room: A Study of User Locomotion Responses to Spatial Augmented Reality Effects](https://arxiv.org/abs/2510.23840)
*You-Jin Kim,Andrew D. Wilson,Jennifer Jacobs,Tobias Höllerer*

Main category: cs.HC

TL;DR: 本研究探讨了利用增强现实技术，在物理空间中通过视觉效果促进用户运动的可能性。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过视觉效果在增强现实环境中鼓励用户主动移动，提高用户体验。

Method: 使用Microsoft RoomAlive系统，通过投影映射实现不同的视觉效果，观察用户在标准客厅中的反应。

Result: 实验展示了不同的变形和增强效果对用户反应的影响，并提出了多种空间变形的视觉效果。

Conclusion: 研究结果表明，增强现实技术能有效激励用户在有限空间内移动，具有推广应用的潜力。

Abstract: Reality Distortion Room (RDR) is a proof-of-concept augmented reality system
using projection mapping and unencumbered interaction with the Microsoft
RoomAlive system to study a user's locomotive response to visual effects that
seemingly transform the physical room the user is in. This study presents five
effects that augment the appearance of a physical room to subtly encourage user
motion. Our experiment demonstrates users' reactions to the different
distortion and augmentation effects in a standard living room, with the
distortion effects projected as wall grids, furniture holograms, and small
particles in the air. The augmented living room can give the impression of
becoming elongated, wrapped, shifted, elevated, and enlarged. The study results
support the implementation of AR experiences in limited physical spaces by
providing an initial understanding of how users can be subtly encouraged to
move throughout a room.

</details>


### [36] [Spatial Orchestra: Locomotion Music Instruments through Spatial Exploration](https://arxiv.org/abs/2510.23848)
*You-Jin Kim,Myungin Lee,Marko Peljhan,JoAnn Kuchera-Morin,Tobias Höllerer*

Main category: cs.HC

TL;DR: Spatial Orchestra使用增强现实技术，使不同技能水平的用户通过步入虚拟气泡来演奏音乐，体验音乐和空间意识的交互。


<details>
  <summary>Details</summary>
Motivation: 希望让更多人能够轻松接触和创建音乐，增进空间意识与音乐表现之间的联系。

Method: 利用增强现实技术，通过自然的步态和定位，用户能够与色彩编码的音符气泡互动。

Result: Spatial Orchestra是一个增强现实体验，允许用户通过在虚拟气泡中走动来轻松演奏音乐。用户与变化的声音气泡互动，每个气泡对应一个大提琴音符，并通过身体的动作和姿态来表达音乐，创造出与空间意识和音乐节奏之间复杂关系的独特体验。

Conclusion: 强化人与音乐和空间的互动关系，提供创新的音乐创作方式。

Abstract: Spatial Orchestra demonstrates how easy it is to play musical instruments
using basic input like natural locomotion, which is accessible to most. Unlike
many musical instruments, our work allows individuals of all skill levels to
effortlessly create music by walking into virtual bubbles. Our Augmented
Reality experience involves interacting with ever-shifting sound bubbles that
the user engages with by stepping into color-coded bubbles within the assigned
area using a standalone AR headset. Each bubble corresponds to a cello note,
and omits sound from the center of the bubble, and lets the user hear and
express in spatial audio, effectively transforming participants into musicians.
This interactive element enables users to explore the intersection of spatial
awareness, musical rhythm that extends to bodily expression through playful
movements and dance-like gestures within the bubble-filled environment. This
unique experience illuminates the intricate relationship between spatial
awareness and the art of musical performance.

</details>


### [37] [Large Language Model Agent Personality and Response Appropriateness: Evaluation by Human Linguistic Experts, LLM-as-Judge, and Natural Language Processing Model](https://arxiv.org/abs/2510.23875)
*Eswari Jayakumar,Niladri Sekhar Dash,Debasmita Mukherjee*

Main category: cs.HC

TL;DR: 本研究通过结合语言分析与代理开发，提出了一种新的评估LLM代理个性的方式，展示了传统深度学习方法的不足。


<details>
  <summary>Details</summary>
Motivation: 有效评估LLM代理的个性尚具挑战性，需要一种新的方法来填补这一空白。

Method: 结合代理开发与语言分析来评估LLM代理的个性

Result: 开发了一种灵活的问题库，基于语言评估标准和人类认知学习水平，实现了更全面的评估。通过对代理响应进行评估，发现纯深度学习解决方案的局限性。

Conclusion: 跨学科设计在代理开发中起着关键作用，为未来的个性评估提供了新的思路。

Abstract: While Large Language Model (LLM)-based agents can be used to create highly
engaging interactive applications through prompting personality traits and
contextual data, effectively assessing their personalities has proven
challenging. This novel interdisciplinary approach addresses this gap by
combining agent development and linguistic analysis to assess the prompted
personality of LLM-based agents in a poetry explanation task. We developed a
novel, flexible question bank, informed by linguistic assessment criteria and
human cognitive learning levels, offering a more comprehensive evaluation than
current methods. By evaluating agent responses with natural language processing
models, other LLMs, and human experts, our findings illustrate the limitations
of purely deep learning solutions and emphasize the critical role of
interdisciplinary design in agent development.

</details>


### [38] [MORA: AI-Mediated Story-Based practice for Speech Sound Disorder from Clinic to Home](https://arxiv.org/abs/2510.23887)
*Sumin Hong,Xavier Briggs,Qingxiao Zheng,Yao Du,Jinjun Xiong,Toby Jia-jun Li*

Main category: cs.HC

TL;DR: 本研究提出了一个名为MORA的互动故事练习系统，旨在通过以动态对话叙事为基础的练习，提升学前儿童在言语声音障碍治疗中的参与度和有效性，同时确保言语语言病理学家的专业支持和治疗计划的适应性。


<details>
  <summary>Details</summary>
Motivation: 为了解决学前儿童在家庭练习中遇到的互动不足问题，提升治疗效果，本研究开发了互动式故事练习系统MORA，力求填补临床治疗与家庭实践之间的鸿沟。

Method: 通过与六名注册SLP的形成性研究和七名SLP的专家评审，MORA的设计理念得到了验证，确保了其与现有基于发音的治疗方法的一致性。

Result: 本研究提出了一种名为MORA的互动式故事练习系统，旨在解决学前儿童在言语声音障碍治疗中面临的挑战。通过将目标声音嵌入动态对话叙事中，MORA鼓励儿童积极产生言语，进而实现声音的泛化和重复练习。系统提供可视提示、明确指导和反馈，使儿童能够有效地独立或与看护人一起练习。同时，MORA支持与言语语言病理学家(SLPs)的AI协作工作流，方便SLPs配置目标材料、审查记录的发音评分，并异步调整治疗计划。第一阶段的研究与SLPs的讨论为系统设计提供了依据，显示出MORA与现有治疗方法的强大关联性并提升儿童参与感和读写能力。

Conclusion: MORA系统展示了在言语声音障碍领域的广泛适用性，对于提升儿童的参与度和治疗效果具有潜力，特别是在家庭实践和临床治疗之间架起了桥梁。

Abstract: Speech sound disorder is among the most common communication challenges in
preschool children. Home-based practice is essential for effective therapy and
for acquiring generalization of target sounds, yet sustaining engaging and
consistent practice remains difficult. Existing story-based activities, despite
their potential for sound generalization and educational benefits, are often
underutilized due to limited interactivity. Moreover, many practice tools fail
to sufficiently integrate speech-language pathologists into the process,
resulting in weak alignment with clinical treatment plans. To address these
limitations, we present MORA, an interactive story-based practice system. MORA
introduces three key innovations. First, it embeds target sounds and vocabulary
into dynamic, character-driven conversational narratives, requiring children to
actively produce speech to progress the story, thereby creating natural
opportunities for exposure, repetition, and generalization. Second, it provides
visual cues, explicit instruction, and feedback, allowing children to practice
effectively either independently or with caregivers. Third, it supports an
AI-in-the-loop workflow, enabling SLPs to configure target materials, review
logged speech with phoneme-level scoring, and adapt therapy plans
asynchronously -- bridging the gap between clinic and home practice while
respecting professional expertise. A formative study with six licensed SLPs
informed the system's design rationale, and an expert review with seven SLPs
demonstrated strong alignment with established articulation-based treatments,
as well as potential to enhance children's engagement and literacy.
Furthermore, discussions highlight the design considerations for professional
support and configurability, adaptive and multimodal child interaction, while
highlighting MORA's broader applicability across speech and language disorders.

</details>


### [39] [Towards AI as Colleagues: Multi-Agent System Improves Structured Professional Ideation](https://arxiv.org/abs/2510.23904)
*Kexin Quan,Dina Albassam,Mengke Wu,Zijian Ding,Jessie Chin*

Main category: cs.HC

TL;DR: MultiColleagues通过允许AI代理之间对话和合作，提高了社交存在感，产生了质量和新颖性显著更高的创意。


<details>
  <summary>Details</summary>
Motivation: 当前大多数AI系统仅设计用于管理任务和执行预定义步骤，限制了它们与人类共同解决问题或贡献新想法的能力。

Method: 通过与20名参与者进行的比较研究，将MultiColleagues与单代理基线进行对比。

Result: MultiColleagues作为多智能体对话系统，能够让AI代理通过对话进行想法分享，并积极与用户进行协作构思。

Conclusion: 本研究表明AI代理超越传统的过程合作伙伴，能够与人类共同分享意图、增强群体动态，并合作推动创意进步。

Abstract: Most AI systems today are designed to manage tasks and execute predefined
steps. This makes them effective for process coordination but limited in their
ability to engage in joint problem-solving with humans or contribute new ideas.
We introduce MultiColleagues, a multi-agent conversational system that shows
how AI agents can act as colleagues by conversing with each other, sharing new
ideas, and actively involving users in collaborative ideation. In a
within-subjects study with 20 participants, we compared MultiColleagues to a
single-agent baseline. Results show that MultiColleagues fostered stronger
perceptions of social presence, produced ideas rated significantly higher in
quality and novelty, and encouraged deeper elaboration. These findings
demonstrate the potential of AI agents to move beyond process partners toward
colleagues that share intent, strengthen group dynamics, and collaborate with
humans to advance ideas.

</details>


### [40] [Toward Socially-Aware LLMs: A Survey of Multimodal Approaches to Human Behavior Understanding](https://arxiv.org/abs/2510.23947)
*Zihan Liu,Parisa Rabbani,Veda Duddu,Kyle Fan,Madison Lee,Yun Huang*

Main category: cs.HC

TL;DR: LLM驱动的多模态系统在社会行为解读中的应用状况分析，强调了多方面的不足及未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 研究者希望更好地理解LLM驱动的多模态系统在解读人类社会行为方面的应用。

Method: 进行了176篇文献的系统性综述，采用四维编码框架进行分类。

Result: 发现模式识别应用广泛，但互动推理支持不足，重语言轻视听觉线索，评估方式偏向静态基准，伦理讨论局限于法律风险。

Conclusion: 需要在社会能力、伦理和交互意识方面评估多模态系统的研究议程。

Abstract: LLM-powered multimodal systems are increasingly used to interpret human
social behavior, yet how researchers apply the models' 'social competence'
remains poorly understood. This paper presents a systematic literature review
of 176 publications across different application domains (e.g., healthcare,
education, and entertainment). Using a four-dimensional coding framework
(application, technical, evaluative, and ethical), we find (1) frequent use of
pattern recognition and information extraction from multimodal sources, but
limited support for adaptive, interactive reasoning; (2) a dominant
'modality-to-text' pipeline that privileges language over rich audiovisual
cues, striping away nuanced social cues; (3) evaluation practices reliant on
static benchmarks, with socially grounded, human-centered assessments rare; and
(4) Ethical discussions focused mainly on legal and rights-related risks (e.g.,
privacy), leaving societal risks (e.g., deception) overlooked--or at best
acknowledged but left unaddressed. We outline a research agenda for evaluating
socially competent, ethically informed, and interaction-aware multi-modal
systems.

</details>


### [41] [Modeling Object Attention in Mobile AR for Intrinsic Cognitive Security](https://arxiv.org/abs/2510.24004)
*Shane Dirksen,Radha Kumaran,You-Jin Kim,Yilin Wang,Tobias Höllerer*

Main category: cs.HC

TL;DR: 该研究探讨移动AR中对象回忆的影响因素，并开发了PLS-SEM模型来预测和改进回忆率。


<details>
  <summary>Details</summary>
Motivation: 研究移动增强现实（AR）中的注意力及其对对象回忆的影响，尤其是可能的认知攻击。

Method: 从四个移动AR研究中收集数据，使用部分最小二乘法结构方程模型（PLS-SEM）进行分析，并与随机森林和多层感知器分类器进行基准比较。

Result: 通过使用PLS-SEM模型，提供了对对象回忆的预测，展示了主要影响因素。

Conclusion: PLS-SEM能够有效预测对象回忆，且提供设计和评估移动AR的可解释性。

Abstract: We study attention in mobile Augmented Reality (AR) using object recall as a
proxy outcome. We observe that the ability to recall an object (physical or
virtual) that was encountered in a mobile AR experience depends on many
possible impact factors and attributes, with some objects being readily
recalled while others are not, and some people recalling objects overall much
better or worse than others. This opens up a potential cognitive attack in
which adversaries might create conditions that make an AR user not recall
certain potentially mission-critical objects. We explore whether a calibrated
predictor of object recall can help shield against such cognitive attacks. We
pool data from four mobile AR studies (with a total of 1,152 object recall
probes) and fit a Partial Least Squares Structural Equation Model (PLS-SEM)
with formative Object, Scene, and User State composites predicting recall, also
benchmarking against Random Forest and multilayer perceptron classifiers.
PLS-SEM attains the best F1 score in three of four studies. Additionally, path
estimates identify lighting, augmentation density, AR registration stability,
cognitive load, and AR familiarity as primary drivers. The model outputs
per-object recall probabilities that can drive interface adjustments when
predicted recall falls. Overall, PLS-SEM provides competitive accuracy with
interpretable levers for design and evaluation in mobile AR.

</details>


### [42] [Understanding Reader Perception Shifts upon Disclosure of AI Authorship](https://arxiv.org/abs/2510.24011)
*Hiroki Nakano,Jo Takezawa,Fabrice Matulic,Chi-Lan Yang,Koji Yatani*

Main category: cs.HC

TL;DR: 本研究表明，披露AI参与会对作者的信任度和亲和度产生负面影响，但提高AI素养可以减轻这些影响。


<details>
  <summary>Details</summary>
Motivation: 探讨在AI写作支持普及的背景下，如何揭示AI的使用对读者感知的影响，以填补该领域的研究空白。

Method: 对261名参与者进行研究，分析990份反馈，探讨不同AI参与程度对作者印象的影响。

Result: 通过对261名参与者的研究，我们发现披露AI参与程度会降低对作者在信任、关怀、能力和可亲近性等方面的印象，尤其是在社会和人际写作中下降最为明显。

Conclusion: 结果强调了AI介导写作的复杂社会动态，并为创建透明、符合语境的写作系统提供了设计启示，旨在更好地维护信任感和真实性。

Abstract: As AI writing support becomes ubiquitous, how disclosing its use affects
reader perception remains a critical, underexplored question. We conducted a
study with 261 participants to examine how revealing varying levels of AI
involvement shifts author impressions across six distinct communicative acts.
Our analysis of 990 responses shows that disclosure generally erodes
perceptions of trustworthiness, caring, competence, and likability, with the
sharpest declines in social and interpersonal writing. A thematic analysis of
participants' feedback links these negative shifts to a perceived loss of human
sincerity, diminished author effort, and the contextual inappropriateness of
AI. Conversely, we find that higher AI literacy mitigates these negative
perceptions, leading to greater tolerance or even appreciation for AI use. Our
results highlight the nuanced social dynamics of AI-mediated authorship and
inform design implications for creating transparent, context-sensitive writing
systems that better preserve trust and authenticity.

</details>


### [43] [VR-Assisted Guide Dog Training: A 360° PanoHaptic System for Right-Hand Commands Analysis](https://arxiv.org/abs/2510.24057)
*Qirong Zhu,Ansheng Wang,Shinji Tanaka,Yasutoshi Makino,Hiroyuki Shinoda*

Main category: cs.HC

TL;DR: 本论文提出了一种虚拟现实导盲犬培训系统，通过模拟环境提高新手训练师的技能，增加导盲犬的可用性。


<details>
  <summary>Details</summary>
Motivation: 由于训练师的数量有限，视障人士对导盲犬的可用性受到限制，因此需要一种新的培训系统来帮助新手训练师更好地理解导盲犬的行为和发出指令。

Method: 采用虚拟现实技术，集成全景视觉信息和触觉反馈，为用户提供沉浸式的培训体验。

Result: 提出了一个基于虚拟现实的导盲犬训练系统，通过沉浸式培训环境提高训练的质量与效率。

Conclusion: 该系统通过改进指令的时机、准确性和表现力，旨在加快技能的习得，提升训练质量，缓解合格训练师的短缺。

Abstract: This paper presents a VR-based guide dog training system designed to assist
novice trainers in understanding guide dog behavior and issuing appropriate
training commands. Guide dogs play a vital role in supporting independent
mobility for visually impaired individuals, yet the limited number of skilled
trainers restricts their availability. Training is highly demanding, requiring
accurate observation of the dog's status and precise command issuance,
especially through right-hand gestures. While the trainer's left hand holds the
harness to perceive haptic cues, the right hand is used to indicate directions,
maintain attention, and provide comfort, with motion patterns varying by
scenario and the dog's progress. Currently, novices learn mainly by observing
experts or watching videos, which lacks immersion and makes it difficult to
adopt the trainer's perspective for understanding behavior or synchronizing
command timing.
  To address these limitations, the proposed system introduces a VR-based
assistive platform integrating panoramic visuals and haptic feedback to create
an immersive training environment. The visual module provides contextual
guidance, including cues for command execution and real-time comparison of the
user's posture with standard actions, while the haptic module delivers tactile
feedback for command gestures. Users can re-experience training sessions across
diverse scenarios and dog proficiency levels, allowing independent and repeated
practice. By improving the timing, accuracy, and expressiveness of right-hand
commands, the system aims to accelerate skill acquisition, enhance training
quality, and mitigate the shortage of qualified trainers, ultimately increasing
the availability of guide dogs for visually impaired individuals.

</details>


### [44] [Building AI Literacy at Home: How Families Navigate Children's Self-Directed Learning with AI](https://arxiv.org/abs/2510.24070)
*Jingyi Xie,Chuhao Wu,Ge Wang,Rui Yu,He Zhang,Ronald Metoyer,Si Chen*

Main category: cs.HC

TL;DR: 随着生成性AI融入儿童学习空间，家庭面临引导使用的新挑战，研究发现家庭共同构建儿童的AI素养，同时在实际期望和批判性素养之间存在矛盾。


<details>
  <summary>Details</summary>
Motivation: 在儿童学习环境中，生成性AI的整合带来了家庭在引导使用方面的新挑战，尤其是在儿童寻求自主权的关键阶段。

Method: 通过与13对亲子进行焦点小组讨论，考察父母如何看待和支持儿童的AI素养发展。

Result: 父母描述了由屏幕时间、自我激励和知识增长驱动的参与阶段，尽管许多人将AI主要视为学习工具，但很少考虑其非教育角色或风险。

Conclusion: 研究揭示了家庭如何共同构建儿童的AI素养，并暴露出实际期望与批判性素养之间的紧张关系，提供了在促进自我导向学习的同时平衡自主性和监督的设计启示。

Abstract: As generative AI becomes embedded in children's learning spaces, families
face new challenges in guiding its use. Middle childhood (ages 7-13) is a
critical stage where children seek autonomy even as parental influence remains
strong. Using self-directed learning (SDL) as a lens, we examine how parents
perceive and support children's developing AI literacy through focus groups
with 13 parent-child pairs. Parents described evolving phases of engagement
driven by screen time, self-motivation, and growing knowledge. While many
framed AI primarily as a study tool, few considered its non-educational roles
or risks, such as privacy and infrastructural embedding. Parents also noted
gaps in their own AI understanding, often turning to joint exploration and
engagement as a form of co-learning. Our findings reveal how families
co-construct children's AI literacy, exposing tensions between practical
expectations and critical literacies, and provide design implications that
foster SDL while balancing autonomy and oversight.

</details>


### [45] [Advancing Interdisciplinary Approaches to Online Safety Research](https://arxiv.org/abs/2510.24227)
*Senuri Wijenayake,Joanne Gray,Asangi Jayatilaka,Louise La Sala,Nalin Arachchilage,Ryan M. Kelly,Sanchari Das*

Main category: cs.HC

TL;DR: 针对在线空间负面经历增加的情况，工作坊旨在通过跨学科合作，提高HCI及其他领域对在线安全的关注，以便更有效地解决用户需求和政策问题。


<details>
  <summary>Details</summary>
Motivation: 随着负面在线经历的日益普遍，HCI社区亟需关注在线安全问题，但各子领域研究碎片化，缺乏有效沟通与协作。

Method: 通过组织跨学科的工作坊，汇集HCI及其他领域的研究人员、政策制定者和实践者，共同探讨在线安全的挑战和需求。

Result: 该工作坊希望识别在线安全研究的共同挑战，突显当前知识的空白，并制定相应的跨学科研究计划。

Conclusion: 本工作坊旨在通过跨学科的对话加强在线安全研究，并建立合作环境，以应对当前知识空缺和共同研究优先事项。

Abstract: The growing prevalence of negative experiences in online spaces demands
urgent attention from the human-computer interaction (HCI) community. However,
research on online safety remains fragmented across different HCI subfields,
with limited communication and collaboration between disciplines. This siloed
approach risks creating ineffective responses, including design solutions that
fail to meet the diverse needs of users, and policy efforts that overlook
critical usability concerns. This workshop aims to foster interdisciplinary
dialogue on online safety by bringing together researchers from within and
beyond HCI - including but not limited to Social Computing, Digital Design,
Internet Policy, Cybersecurity, Ethics, and Social Sciences. By uniting
researchers, policymakers, industry practitioners, and community advocates we
aim to identify shared challenges in online safety research, highlight gaps in
current knowledge, and establish common research priorities. The workshop will
support the development of interdisciplinary research plans and establish
collaborative environments - both within and beyond Australia - to action them.

</details>


### [46] [Detecting the Use of Generative AI in Crowdsourced Surveys: Implications for Data Integrity](https://arxiv.org/abs/2510.24594)
*Dapeng Zhang,Marina Katoh,Weiping Pei*

Main category: cs.HC

TL;DR: 生成性人工智能对众包数据收集提出了新挑战，尤其是在调查研究中，AI生成的响应数量显著增加。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在理解和评估生成性人工智能对众包数据收集及其在公共舆论和行为研究中潜在影响的挑战。

Method: 我们采用了LLM基础检测和签名基础检测两种方法，进行七项调查研究的实验，比较了不同时间点收集的调查响应。

Result: 本研究探讨了生成性人工智能（GenAI）对众包数据收集的影响，特别是在基于调查的研究中。我们比较了2022年前后的调查数据，发现AI生成的响应显著增加，提示众包数据可能受到干扰。

Conclusion: 研究表明，生成性人工智能可能会破坏数据完整性，影响研究结果，呼吁对研究诚信的保护和对新方法论挑战的解决。

Abstract: The widespread adoption of generative AI (GenAI) has introduced new
challenges in crowdsourced data collection, particularly in survey-based
research. While GenAI offers powerful capabilities, its unintended use in
crowdsourcing, such as generating automated survey responses, threatens the
integrity of empirical research and complicates efforts to understand public
opinion and behavior. In this study, we investigate and evaluate two approaches
for detecting AI-generated responses in online surveys: LLM-based detection and
signature-based detection. We conducted experiments across seven survey
studies, comparing responses collected before 2022 with those collected after
the release of ChatGPT. Our findings reveal a significant increase in
AI-generated responses in the post-2022 studies, highlighting how GenAI may
silently distort crowdsourced data. This work raises broader concerns about
evolving landscape of data integrity, where GenAI can compromise data quality,
mislead researchers, and influence downstream findings in fields such as
health, politics, and social behavior. By surfacing detection strategies and
empirical evidence of GenAI's impact, we aim to contribute to ongoing
conversation about safeguarding research integrity and supporting scholars
navigating these methodological and ethical challenges.

</details>


### [47] [What Does It Take? Developing a Smartphone App that Motivates Older Adults to be Physically Active](https://arxiv.org/abs/2510.24638)
*Sabrina Haque,Kyle Henry,Troyee Saha,Kimberly Vanhoose,Jobaidul Boni,Samantha Moss,Kate Hyun,Kathy Siepker,Xiangli Gu,Angela Liegey-Dougall,Stephen Mattingly,Christoph Csallner*

Main category: cs.HC

TL;DR: 该研究分析了"Senior Fit"移动健身应用在老年人中的适用性与互动性，强调了设计包容性健身工具的重要性。


<details>
  <summary>Details</summary>
Motivation: 提升老年人的身体活动水平是改善其健康和福祉的关键，而传统干预方法在可扩展性上存在问题，因此探索手机应用的有效性具有重要意义。

Method: 通过对25名65-85岁参与者的持续测试，基于反馈不断优化应用的可用性和可及性。

Result: 本研究探讨了一款针对老年人的独立移动健身应用"Senior Fit"的可行性和参与度，发现老年人重视视频演示和提醒等功能，但对手动记录和个性化设置感到沮丧，同时指出社交支持的可及性问题。

Conclusion: 开发适合老年人的健身应用需要集成灵活的记录方式、明确的反馈，以及低门槛的社交支持，以便于长期使用。

Abstract: Maintaining physical activity is essential for older adults' health and
well-being, yet participation remains low. Traditional paper-based and
in-person interventions have been effective but face scalability issues.
Smartphone apps offer a potential solution, but their effectiveness in
real-world use remains underexplored. Most prior studies take place in
controlled environments, use specialized hardware, or rely on in-person
training sessions or researcher-led setup. This study examines the feasibility
and engagement of Senior Fit, a standalone mobile fitness app designed for
older adults. We conducted continuous testing with 25 participants aged 65-85,
refining the app based on their feedback to improve usability and
accessibility. Our findings underscore both the potential and key challenges in
designing digital health interventions. Older adults valued features such as
video demonstrations and reminders that made activity feel accessible and
motivating, yet some expressed frustration with manual logging and limited
personalization. The Facebook group provided encouragement for some but
excluded others unfamiliar with the platform. These results highlight the need
for fitness apps that integrate flexible tracking, clear feedback, and
low-barrier social support. We contribute design recommendations for creating
inclusive mobile fitness tools that align with older adults' routines and
capabilities, offering insights for future long-term, real-world deployments.

</details>
