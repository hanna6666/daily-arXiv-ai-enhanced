<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 26]
- [cs.HC](#cs.HC) [Total: 25]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Vi-TacMan: Articulated Object Manipulation via Vision and Touch](https://arxiv.org/abs/2510.06339)
*Leiyao Cui,Zihang Zhao,Sirui Xie,Wenhuan Zhang,Zhi Han,Yixin Zhu*

Main category: cs.RO

TL;DR: Vi-TacMan通过结合视觉和触觉反馈，实现了对关节物体的自主操控，并在多种物体上表现出色。


<details>
  <summary>Details</summary>
Motivation: 在未知物体上，视觉方法可能产生不精确的估计，而触觉方法需要精确的初始化，因此探索视觉与触觉的自然互补性。

Method: Vi-TacMan框架结合视觉和触觉来实现关节物体的自主操控。

Result: 通过使用视觉引导进行抓取建议和粗略方向，并结合触觉控制器实现精确执行，本方法在准确性上显著优于基线，且操控未依赖明确的运动学模型。

Conclusion: 该研究表明，只需粗略的视觉线索结合触觉反馈，便可在复杂环境下实现可靠的操控。

Abstract: Autonomous manipulation of articulated objects remains a fundamental
challenge for robots in human environments. Vision-based methods can infer
hidden kinematics but can yield imprecise estimates on unfamiliar objects.
Tactile approaches achieve robust control through contact feedback but require
accurate initialization. This suggests a natural synergy: vision for global
guidance, touch for local precision. Yet no framework systematically exploits
this complementarity for generalized articulated manipulation. Here we present
Vi-TacMan, which uses vision to propose grasps and coarse directions that seed
a tactile controller for precise execution. By incorporating surface normals as
geometric priors and modeling directions via von Mises-Fisher distributions,
our approach achieves significant gains over baselines (all p<0.0001).
Critically, manipulation succeeds without explicit kinematic models -- the
tactile controller refines coarse visual estimates through real-time contact
regulation. Tests on more than 50,000 simulated and diverse real-world objects
confirm robust cross-category generalization. This work establishes that coarse
visual cues suffice for reliable manipulation when coupled with tactile
feedback, offering a scalable paradigm for autonomous systems in unstructured
environments.

</details>


### [2] [A Formal gatekeeper Framework for Safe Dual Control with Active Exploration](https://arxiv.org/abs/2510.06351)
*Kaleb Ben Naveed,Devansh R. Agrawal,Dimitra Panagou*

Main category: cs.RO

TL;DR: 提出一种框架，将稳健规划与主动探索结合，确保安全同时减小不确定性，提升任务效率。


<details>
  <summary>Details</summary>
Motivation: 在模型不确定性下规划安全轨迹是一个基本挑战，现有方法存在过度保守的问题，而主动减少不确定性又缺乏正式的探索时机考虑。

Method: 利用安全验证的门控器架构，生成安全且信息丰富的轨迹，从而实现双重控制。

Result: 通过模拟案例研究，验证了该方法在四旋翼在线双重控制下的有效性。

Conclusion: 提出的框架能够在确保安全的同时有效减少不确定性，进而优化任务成本。

Abstract: Planning safe trajectories under model uncertainty is a fundamental
challenge. Robust planning ensures safety by considering worst-case
realizations, yet ignores uncertainty reduction and leads to overly
conservative behavior. Actively reducing uncertainty on-the-fly during a
nominal mission defines the dual control problem. Most approaches address this
by adding a weighted exploration term to the cost, tuned to trade off the
nominal objective and uncertainty reduction, but without formal consideration
of when exploration is beneficial. Moreover, safety is enforced in some methods
but not in others. We propose a framework that integrates robust planning with
active exploration under formal guarantees as follows: The key innovation and
contribution is that exploration is pursued only when it provides a verifiable
improvement without compromising safety. To achieve this, we utilize our
earlier work on gatekeeper as an architecture for safety verification, and
extend it so that it generates both safe and informative trajectories that
reduce uncertainty and the cost of the mission, or keep it within a
user-defined budget. The methodology is evaluated via simulation case studies
on the online dual control of a quadrotor under parametric uncertainty.

</details>


### [3] [Constrained Natural Language Action Planning for Resilient Embodied Systems](https://arxiv.org/abs/2510.06357)
*Grayson Byrd,Corban Rivera,Bethany Kemp,Meghan Booker,Aurora Schmidt,Celso M de Melo,Lalithkumar Seenivasan,Mathias Unberath*

Main category: cs.RO

TL;DR: 本研究提出了一种新型机器人规划方法，将大型语言模型(LLM)与符号规划相结合，提高了在复杂现实任务中的可靠性和可重复性，同时保持LLM的推理能力和出色的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 面临现实环境的复杂性和模糊性，研究旨在提升LLM在机器人任务中的可依赖性和可重复性。

Method: 通过将LLM规划与符号规划的监督相结合，提供透明的硬约束定义方式，以克服传统提示工程的局限。

Result: 在ALFWorld规划基准上，该方法超越了现有的最先进技术，并在实际任务中表现出比纯LLM和符号规划方法更高的成功率。

Conclusion: 该方法显著提升了LLM机机器人规划的有效性，成功率达到99%，在实际四足机器人任务中实现100%的成功率。

Abstract: Replicating human-level intelligence in the execution of embodied tasks
remains challenging due to the unconstrained nature of real-world environments.
Novel use of large language models (LLMs) for task planning seeks to address
the previously intractable state/action space of complex planning tasks, but
hallucinations limit their reliability, and thus, viability beyond a research
context. Additionally, the prompt engineering required to achieve adequate
system performance lacks transparency, and thus, repeatability. In contrast to
LLM planning, symbolic planning methods offer strong reliability and
repeatability guarantees, but struggle to scale to the complexity and ambiguity
of real-world tasks. We introduce a new robotic planning method that augments
LLM planners with symbolic planning oversight to improve reliability and
repeatability, and provide a transparent approach to defining hard constraints
with considerably stronger clarity than traditional prompt engineering.
Importantly, these augmentations preserve the reasoning capabilities of LLMs
and retain impressive generalization in open-world environments. We demonstrate
our approach in simulated and real-world environments. On the ALFWorld planning
benchmark, our approach outperforms current state-of-the-art methods, achieving
a near-perfect 99% success rate. Deployment of our method to a real-world
quadruped robot resulted in 100% task success compared to 50% and 30% for pure
LLM and symbolic planners across embodied pick and place tasks. Our approach
presents an effective strategy to enhance the reliability, repeatability and
transparency of LLM-based robot planners while retaining their key strengths:
flexibility and generalizability to complex real-world environments. We hope
that this work will contribute to the broad goal of building resilient embodied
intelligent systems.

</details>


### [4] [Active Next-Best-View Optimization for Risk-Averse Path Planning](https://arxiv.org/abs/2510.06481)
*Amirhossein Mollaei Khass,Guangyi Liu,Vivek Pandey,Wen Jiang,Boshu Lei,Kostas Daniilidis,Nader Motee*

Main category: cs.RO

TL;DR: 本研究提出了一种将风险规避路径优化与下一最佳视图选择相结合的统一框架，以实现安全导航。


<details>
  <summary>Details</summary>
Motivation: 在不确定环境中进行安全导航需要将风险规避与主动感知结合的规划方法。

Method: 构建了基于3D高斯散点辐射场的在线更新风险图，并通过Riemannian梯度下降来选择下一最佳视图。

Result: 提出了一种新的统一框架，通过构建风险图来改进航迹计划，同时进行下一最佳视图的选择以应对不确定环境中的风险和感知问题。

Conclusion: 该框架通过风险图和下一最佳视图选择的优化，显著提升了在复杂环境中进行安全路径规划的能力。

Abstract: Safe navigation in uncertain environments requires planning methods that
integrate risk aversion with active perception. In this work, we present a
unified framework that refines a coarse reference path by constructing
tail-sensitive risk maps from Average Value-at-Risk statistics on an
online-updated 3D Gaussian-splat Radiance Field. These maps enable the
generation of locally safe and feasible trajectories. In parallel, we formulate
Next-Best-View (NBV) selection as an optimization problem on the SE(3) pose
manifold, where Riemannian gradient descent maximizes an expected information
gain objective to reduce uncertainty most critical for imminent motion. Our
approach advances the state-of-the-art by coupling risk-averse path refinement
with NBV planning, while introducing scalable gradient decompositions that
support efficient online updates in complex environments. We demonstrate the
effectiveness of the proposed framework through extensive computational
studies.

</details>


### [5] [What You Don't Know Can Hurt You: How Well do Latent Safety Filters Understand Partially Observable Safety Constraints?](https://arxiv.org/abs/2510.06492)
*Matthew Kim,Kensuke Nakamura,Andrea Bajcsy*

Main category: cs.RO

TL;DR: 这篇论文探讨了潜在状态空间在安全控制中的有效性，特别是当安全相关特征不可观测时，提出了一种新策略通过多模态训练加强控制，并进行了实验证明。


<details>
  <summary>Details</summary>
Motivation: 研究在潜在状态空间中何时能够实现安全控制，特别关注那些安全相关特征不可观测的情况。

Method: 通过结合温度基础的失败案例和互信息度量，识别观测失败捕捉安全相关特征的情况，进而制定了一种应对策略。

Result: 发现仅依靠RGB观测可能导致短视的安全行为，例如仅避免看到失败状态，而非根本防止失败。

Conclusion: 提出了一种多模态监督训练策略来增强潜在状态的安全控制能力，并在模拟与实际硬件上验证了该方法的有效性。

Abstract: Safe control techniques, such as Hamilton-Jacobi reachability, provide
principled methods for synthesizing safety-preserving robot policies but
typically assume hand-designed state spaces and full observability. Recent work
has relaxed these assumptions via latent-space safe control, where state
representations and dynamics are learned jointly through world models that
reconstruct future high-dimensional observations (e.g., RGB images) from
current observations and actions. This enables safety constraints that are
difficult to specify analytically (e.g., spilling) to be framed as
classification problems in latent space, allowing controllers to operate
directly from raw observations. However, these methods assume that
safety-critical features are observable in the learned latent state. We ask:
when are latent state spaces sufficient for safe control? To study this, we
examine temperature-based failures, comparable to overheating in cooking or
manufacturing tasks, and find that RGB-only observations can produce myopic
safety behaviors, e.g., avoiding seeing failure states rather than preventing
failure itself. To predict such behaviors, we introduce a mutual
information-based measure that identifies when observations fail to capture
safety-relevant features. Finally, we propose a multimodal-supervised training
strategy that shapes the latent state with additional sensory inputs during
training, but requires no extra modalities at deployment, and validate our
approach in simulation and on hardware with a Franka Research 3 manipulator
preventing a pot of wax from overheating.

</details>


### [6] [Real-Time Glass Detection and Reprojection using Sensor Fusion Onboard Aerial Robots](https://arxiv.org/abs/2510.06518)
*Malakhi Hopkins,Varun Murali,Vijay Kumar,Camillo J Taylor*

Main category: cs.RO

TL;DR: 提出了一种新颖的实时透明障碍物探测与映射系统，适用于低功耗无人机。


<details>
  <summary>Details</summary>
Motivation: 解决传统感知系统在透明障碍物前导航和映射不准确的问题，以确保无人机的安全操作。

Method: 通过融合ToF相机和超声波传感器数据，并使用轻量级的2D卷积模型进行处理。

Result: 系统在控制和实际环境中经过实验验证，成功地映射了包含玻璃的室内环境。

Conclusion: 该方法为低功耗四旋翼无人机提供了一种有效的透明障碍物探测与映射解决方案，能够实时运行并在真实环境中表现良好。

Abstract: Autonomous aerial robots are increasingly being deployed in real-world
scenarios, where transparent obstacles present significant challenges to
reliable navigation and mapping. These materials pose a unique problem for
traditional perception systems because they lack discernible features and can
cause conventional depth sensors to fail, leading to inaccurate maps and
potential collisions. To ensure safe navigation, robots must be able to
accurately detect and map these transparent obstacles. Existing methods often
rely on large, expensive sensors or algorithms that impose high computational
burdens, making them unsuitable for low Size, Weight, and Power (SWaP) robots.
In this work, we propose a novel and computationally efficient framework for
detecting and mapping transparent obstacles onboard a sub-300g quadrotor. Our
method fuses data from a Time-of-Flight (ToF) camera and an ultrasonic sensor
with a custom, lightweight 2D convolution model. This specialized approach
accurately detects specular reflections and propagates their depth into
corresponding empty regions of the depth map, effectively rendering transparent
obstacles visible. The entire pipeline operates in real-time, utilizing only a
small fraction of a CPU core on an embedded processor. We validate our system
through a series of experiments in both controlled and real-world environments,
demonstrating the utility of our method through experiments where the robot
maps indoor environments containing glass. Our work is, to our knowledge, the
first of its kind to demonstrate a real-time, onboard transparent obstacle
mapping system on a low-SWaP quadrotor using only the CPU.

</details>


### [7] [RAISE: A self-driving laboratory for interfacial property formulation discovery](https://arxiv.org/abs/2510.06546)
*Mohammad Nazeri,Sheldon Mei,Jeffrey Watchorn,Alex Zhang,Erin Ng,Tao Wen,Abhijoy Mandal,Kevin Golovin,Alan Aspuru-Guzik,Frank Gu*

Main category: cs.RO

TL;DR: RAISE是一个自主的闭环实验系统，通过优化液体配方与接触角测量，利用多目标贝叶斯优化高效识别最佳表面活性剂配方。


<details>
  <summary>Details</summary>
Motivation: 表面湿润性是生物医学设备、涂层和纺织品设计中的关键参数，液体配方的优化与接触角测量对提高材料性能至关重要。

Method: RAISE系统结合全实验编排者、自动图像处理管道及多目标贝叶斯优化，实现液体配方优化与表面湿润性评估的闭环实验过程。

Result: RAISE系统可以以每分钟约1个接触角测量的速度高效探索表面活性剂的湿润性，并根据目标接触角范围、最小化表面活性剂使用、降低成本等目标获得精确的最佳配方。

Conclusion: 本研究展示了RAISE系统在自主链接液体配方与接触角测量中的能力，通过多目标贝叶斯优化高效识别与研究人员定义标准一致的最佳配方。

Abstract: Surface wettability is a critical design parameter for biomedical devices,
coatings, and textiles. Contact angle measurements quantify liquid-surface
interactions, which depend strongly on liquid formulation. Herein, we present
the Robotic Autonomous Imaging Surface Evaluator (RAISE), a closed-loop,
self-driving laboratory that is capable of linking liquid formulation
optimization with surface wettability assessment. RAISE comprises a full
experimental orchestrator with the ability of mixing liquid ingredients to
create varying formulation cocktails, transferring droplets of prepared
formulations to a high-throughput stage, and using a pick-and-place camera tool
for automated droplet image capture. The system also includes an automated
image processing pipeline to measure contact angles. This closed loop
experiment orchestrator is integrated with a Bayesian Optimization (BO) client,
which enables iterative exploration of new formulations based on previous
contact angle measurements to meet user-defined objectives. The system operates
in a high-throughput manner and can achieve a measurement rate of approximately
1 contact angle measurement per minute. Here we demonstrate RAISE can be used
to explore surfactant wettability and how surfactant combinations create
tunable formulations that compensate for purity-related variations.
Furthermore, multi-objective BO demonstrates how precise and optimal
formulations can be reached based on application-specific goals. The
optimization is guided by a desirability score, which prioritizes formulations
that are within target contact angle ranges, minimize surfactant usage and
reduce cost. This work demonstrates the capabilities of RAISE to autonomously
link liquid formulations to contact angle measurements in a closed-loop system,
using multi-objective BO to efficiently identify optimal formulations aligned
with researcher-defined criteria.

</details>


### [8] [Safe Obstacle-Free Guidance of Space Manipulators in Debris Removal Missions via Deep Reinforcement Learning](https://arxiv.org/abs/2510.06566)
*Vincent Lam,Robin Chhabra*

Main category: cs.RO

TL;DR: 提出了一种基于TD3代理的无模型轨迹规划方法，以实现安全的空间残骸捕获，采用多重评论网络和优先经验重放缓冲区，验证在模拟中表现出色。


<details>
  <summary>Details</summary>
Motivation: 提高空间操纵器在捕获非合作目标时的安全性和可靠性

Method: 使用双延迟深度确定性策略梯度（TD3）代理进行无模型工作空间轨迹规划

Result: 展示了在Matlab/Simulink中评估的七自由度KUKA LBR iiwa模拟器的安全和自适应轨迹生成，适用于清除残骸任务

Conclusion: 该框架有效解决了目标跟踪和自碰撞避免的挑战，为空间残骸清除任务提供了一种稳定和敏捷的解决方案。

Abstract: The objective of this study is to develop a model-free workspace trajectory
planner for space manipulators using a Twin Delayed Deep Deterministic Policy
Gradient (TD3) agent to enable safe and reliable debris capture. A local
control strategy with singularity avoidance and manipulability enhancement is
employed to ensure stable execution. The manipulator must simultaneously track
a capture point on a non-cooperative target, avoid self-collisions, and prevent
unintended contact with the target. To address these challenges, we propose a
curriculum-based multi-critic network where one critic emphasizes accurate
tracking and the other enforces collision avoidance. A prioritized experience
replay buffer is also used to accelerate convergence and improve policy
robustness. The framework is evaluated on a simulated seven-degree-of-freedom
KUKA LBR iiwa mounted on a free-floating base in Matlab/Simulink, demonstrating
safe and adaptive trajectory generation for debris removal missions.

</details>


### [9] [Assist-As-Needed: Adaptive Multimodal Robotic Assistance for Medication Management in Dementia Care](https://arxiv.org/abs/2510.06633)
*Kruthika Gangaraju,Tanmayi Inaparthy,Jiaqi Yang,Yihao Zheng,Fengpei Yuan*

Main category: cs.RO

TL;DR: 本文介绍了一种新型的自适应机器人辅助系统，能够根据认知障碍人士的需求变化提供不同层次的支持，从而帮助他们独立管理药物。


<details>
  <summary>Details</summary>
Motivation: 现有的助理技术未能有效适应认知障碍人士的变化需求，导致自主性降低和照护者负担加重。

Method: 采用分层干预模型，根据用户能力的不同提供相应的支持，从简单的口头提醒到复杂的多模态指导，并通过动态评估任务状态调整帮助方式。

Result: 提出了一种自适应的多模态机器人框架，旨在根据用户需求的实时评估动态调整辅助程度，以支持认知障碍人士独立管理药物。

Conclusion: 该系统通过逐级支持机制有效地平衡了自主性与药物遵从性，能在认知障碍人士的照护中发挥重要作用。

Abstract: People living with dementia (PLWDs) face progressively declining abilities in
medication management-from simple forgetfulness to complete task breakdown-yet
most assistive technologies fail to adapt to these changing needs. This
one-size-fits-all approach undermines autonomy, accelerates dependence, and
increases caregiver burden. Occupational therapy principles emphasize matching
assistance levels to individual capabilities: minimal reminders for those who
merely forget, spatial guidance for those who misplace items, and comprehensive
multimodal support for those requiring step-by-step instruction. However,
existing robotic systems lack this adaptive, graduated response framework
essential for maintaining PLWD independence. We present an adaptive multimodal
robotic framework using the Pepper robot that dynamically adjusts assistance
based on real-time assessment of user needs. Our system implements a
hierarchical intervention model progressing from (1) simple verbal reminders,
to (2) verbal + gestural cues, to (3) full multimodal guidance combining
physical navigation to medication locations with step-by-step verbal and
gestural instructions. Powered by LLM-driven interaction strategies and
multimodal sensing, the system continuously evaluates task states to provide
just-enough assistance-preserving autonomy while ensuring medication adherence.
We conducted a preliminary study with healthy adults and dementia care
stakeholders in a controlled lab setting, evaluating the system's usability,
comprehensibility, and appropriateness of adaptive feedback mechanisms. This
work contributes: (1) a theoretically grounded adaptive assistance framework
translating occupational therapy principles into HRI design, (2) a multimodal
robotic implementation that preserves PLWD dignity through graduated support,
and (3) empirical insights into stakeholder perceptions of adaptive robotic
care.

</details>


### [10] [RLinf-VLA: A Unified and Efficient Framework for VLA+RL Training](https://arxiv.org/abs/2510.06710)
*Hongzhi Zang,Mingjie Wei,Si Xu,Yongji Wu,Zhen Guo,Yuanqing Wang,Hao Lin,Liangzhi Shi,Yuqing Xie,Zhexuan Xu,Zhihao Liu,Kang Chen,Wenhao Tang,Quanlu Zhang,Weinan Zhang,Chao Yu,Yu Wang*

Main category: cs.RO

TL;DR: 提出RLinf-VLA框架，用于实现一个统一的视觉-语言-行动模型的强化学习训练，显著提高训练速度和模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 将视觉和语言能力扩展到具身环境中，然而现有的视觉-语言-行动模型的训练主要依赖于监督微调，容易在分布变化中出现错误积累，导致泛化能力不足。

Method: RLinf-VLA引入了一种高度灵活的资源分配设计和混合精细管道分配模式，以提高训练效率，支持多种VLA架构、强化学习算法及模拟器。

Result: RLinf-VLA是一个统一且高效的框架，实现了可扩展的视觉-语言-行动模型的强化学习训练，支持多种模型架构和算法设计。

Conclusion: RLinf-VLA通过在真实机器人上的初步部署，展示了强化学习训练的政策在泛化能力上的优势，旨在加速和标准化针对具身智能的研究。

Abstract: Recent progress in vision and language foundation models has significantly
advanced multimodal understanding, reasoning, and generation, inspiring a surge
of interest in extending such capabilities to embodied settings through
vision-language-action (VLA) models. Yet, most VLA models are still trained
with supervised fine-tuning (SFT), which struggles to generalize under
distribution shifts due to error accumulation. Reinforcement learning (RL)
offers a promising alternative by directly optimizing task performance through
interaction, but existing attempts remain fragmented and lack a unified
platform for fair and systematic comparison across model architectures and
algorithmic designs. To address this gap, we introduce RLinf-VLA, a unified and
efficient framework for scalable RL training of VLA models. The system adopts a
highly flexible resource allocation design that addresses the challenge of
integrating rendering, training, and inference in RL+VLA training. In
particular, for GPU-parallelized simulators, RLinf-VLA implements a novel
hybrid fine-grained pipeline allocation mode, achieving a 1.61x-1.88x speedup
in training. Through a unified interface, RLinf-VLA seamlessly supports diverse
VLA architectures (e.g., OpenVLA, OpenVLA-OFT), multiple RL algorithms (e.g.,
PPO, GRPO), and various simulators (e.g., ManiSkill, LIBERO). In simulation, a
unified model achieves 98.11\% across 130 LIBERO tasks and 97.66\% across 25
ManiSkill tasks. Beyond empirical performance, our study distills a set of best
practices for applying RL to VLA training and sheds light on emerging patterns
in this integration. Furthermore, we present preliminary deployment on a
real-world Franka robot, where RL-trained policies exhibit stronger
generalization than those trained with SFT. We envision RLinf-VLA as a
foundation to accelerate and standardize research on embodied intelligence.

</details>


### [11] [SanDRA: Safe Large-Language-Model-Based Decision Making for Automated Vehicles Using Reachability Analysis](https://arxiv.org/abs/2510.06717)
*Yuanfei Lin,Sebastian Illing,Matthias Althoff*

Main category: cs.RO

TL;DR: 提出SanDRA框架，通过可达性分析提升大型语言模型在自动驾驶决策中的安全性，支持高密度交通情境下的合规决策。


<details>
  <summary>Details</summary>
Motivation: 探讨和解决基于大型语言模型的自动驾驶车辆决策中的安全性问题，尤其是在面对可能的幻觉时。

Method: 采用大规模语言模型和可达性分析相结合的方法，生成并排名可行的驾驶动作。

Result: 在开放式和闭环驾驶环境中进行验证，说明该框架有效提供安全的驾驶动作。

Conclusion: 改进的SanDRA框架能够在高密度交通条件下提供可证明安全且尽可能遵守法律的驾驶决策。

Abstract: Large language models have been widely applied to knowledge-driven
decision-making for automated vehicles due to their strong generalization and
reasoning capabilities. However, the safety of the resulting decisions cannot
be ensured due to possible hallucinations and the lack of integrated vehicle
dynamics. To address this issue, we propose SanDRA, the first safe
large-language-model-based decision making framework for automated vehicles
using reachability analysis. Our approach starts with a comprehensive
description of the driving scenario to prompt large language models to generate
and rank feasible driving actions. These actions are translated into temporal
logic formulas that incorporate formalized traffic rules, and are subsequently
integrated into reachability analysis to eliminate unsafe actions. We validate
our approach in both open-loop and closed-loop driving environments using
off-the-shelf and finetuned large language models, showing that it can provide
provably safe and, where possible, legally compliant driving actions, even
under high-density traffic conditions. To ensure transparency and facilitate
future research, all code and experimental setups are publicly available at
github.com/CommonRoad/SanDRA.

</details>


### [12] [UniFField: A Generalizable Unified Neural Feature Field for Visual, Semantic, and Spatial Uncertainties in Any Scene](https://arxiv.org/abs/2510.06754)
*Christian Maurer,Snehal Jauhri,Sophie Lueth,Georgia Chalvatzaki*

Main category: cs.RO

TL;DR: UniFField集成了多种特征，能够评估不确定性并在未知环境中自适应。


<details>
  <summary>Details</summary>
Motivation: 在复杂环境中，机器人需要全面理解3D场景并评估信息可靠性，以做出稳健决策。

Method: UniFField结合视觉、语义和几何特征，使用RGB-D图像逐步更新卷积特征表示，并评估不确定性。

Result: UniFField是一种统一的模型，结合了视觉、语义和几何特征，并在每种模式中预测不确定性，且能在新环境中零样本应用。

Conclusion: UniFField展示了在移动操控器上进行主动物体搜索的决策能力，表明其在复杂环境中的有效性和可靠性。

Abstract: Comprehensive visual, geometric, and semantic understanding of a 3D scene is
crucial for successful execution of robotic tasks, especially in unstructured
and complex environments. Additionally, to make robust decisions, it is
necessary for the robot to evaluate the reliability of perceived information.
While recent advances in 3D neural feature fields have enabled robots to
leverage features from pretrained foundation models for tasks such as
language-guided manipulation and navigation, existing methods suffer from two
critical limitations: (i) they are typically scene-specific, and (ii) they lack
the ability to model uncertainty in their predictions. We present UniFField, a
unified uncertainty-aware neural feature field that combines visual, semantic,
and geometric features in a single generalizable representation while also
predicting uncertainty in each modality. Our approach, which can be applied
zero shot to any new environment, incrementally integrates RGB-D images into
our voxel-based feature representation as the robot explores the scene,
simultaneously updating uncertainty estimation. We evaluate our uncertainty
estimations to accurately describe the model prediction errors in scene
reconstruction and semantic feature prediction. Furthermore, we successfully
leverage our feature predictions and their respective uncertainty for an active
object search task using a mobile manipulator robot, demonstrating the
capability for robust decision-making.

</details>


### [13] [Distributed 3D Source Seeking via SO(3) Geometric Control of Robot Swarms](https://arxiv.org/abs/2510.06836)
*Jesús Bautista,Héctor García de Marina*

Main category: cs.RO

TL;DR: 本文提出了一种新的几何控制框架，解决了3D机器人源寻求中的方向表示问题，并展示了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为了解决三维源寻求的问题，尤其是在机器人执行任务时，存在的欧拉角奇异性和四元数模糊性。

Method: 直接在SO(3)上工作，设计控制器以实现机器人向估计的上升方向进行指数对准，并适应未知变化。

Result: 提出了一种在SO(3) Lie群上的几何控制框架，并设计了一个比例前馈控制器，确保机器人有效对准3D标量场源。

Conclusion: 数值模拟结果证明了该方法的有效性，并提供了开放源码以供复现。

Abstract: This paper presents a geometric control framework on the Lie group SO(3) for
3D source-seeking by robots with first-order attitude dynamics and constant
translational speed. By working directly on SO(3), the approach avoids
Euler-angle singularities and quaternion ambiguities, providing a unique,
intrinsic representation of orientation. We design a proportional feed-forward
controller that ensures exponential alignment of each agent to an estimated
ascending direction toward a 3D scalar field source. The controller adapts to
bounded unknown variations and preserves well-posed swarm formations. Numerical
simulations demonstrate the effectiveness of the method, with all code provided
open source for reproducibility.

</details>


### [14] [Tailoring materials into kirigami robots](https://arxiv.org/abs/2510.07027)
*Saravana Prashanth Murali Babu,Aida Parvaresh,Ahmad Rafsanjani*

Main category: cs.RO

TL;DR: Kirigami纸艺在机器人技术中具有革命性潜力，通过优化切割模式实现多功能、轻便和适应性强的解决方案。


<details>
  <summary>Details</summary>
Motivation: 探索传统纸艺如何推动机器人领域的发展，特别是在柔韧性和多功能性方面。

Method: 通过优化切割模式定制kiriagami组件，以满足不同的机器人应用需求。

Result: Kirigami结构可用于机器人抓取、运动和可穿戴设备，显著提高适应性。

Conclusion: 尽管具有良好的发展前景，但在针对特定功能设计切割模式和简化制作技术方面仍面临挑战。

Abstract: Kirigami, the traditional paper-cutting craft, holds immense potential for
revolutionizing robotics by providing multifunctional, lightweight, and
adaptable solutions. Kirigami structures, characterized by their
bending-dominated deformation, offer resilience to tensile forces and
facilitate shape morphing under small actuation forces. Kirigami components
such as actuators, sensors, batteries, controllers, and body structures can be
tailored to specific robotic applications by optimizing cut patterns. Actuators
based on kirigami principles exhibit complex motions programmable through
various energy sources, while kirigami sensors bridge the gap between
electrical conductivity and compliance. Kirigami-integrated batteries enable
energy storage directly within robot structures, enhancing flexibility and
compactness. Kirigami-controlled mechanisms mimic mechanical computations,
enabling advanced functionalities such as shape morphing and memory functions.
Applications of kirigami-enabled robots include grasping, locomotion, and
wearables, showcasing their adaptability to diverse environments and tasks.
Despite promising opportunities, challenges remain in the design of cut
patterns for a given function and streamlining fabrication techniques.

</details>


### [15] [Temporal-Prior-Guided View Planning for Periodic 3D Plant Reconstruction](https://arxiv.org/abs/2510.07028)
*Sicong Pan,Xuying Huang,Maren Bennewitz*

Main category: cs.RO

TL;DR: 本文提出了一种新的视图规划方法，通过非刚性对齐先前重建的模型，优化了植物成长过程中周期性重建的资源使用。


<details>
  <summary>Details</summary>
Motivation: 周期性三维重建对于作物监测至关重要，但每个周期从头开始的方式浪费资源且忽视了以前捕获的信息。

Method: 提出了一种基于时间先验指导的视图规划方法，解决了周期性植物重建问题，并通过求解集合覆盖优化问题计算出最小视图集合。

Result: 在玉米和番茄的实验中，显示我们的系统在减少所需视图和保持运动成本方面较为先进。

Conclusion: 系统在相同的视野范围内相比于最先进的方法保留或改善了表面积覆盖，同时减少了所需视图和运动成本。

Abstract: Periodic 3D reconstruction is essential for crop monitoring, but costly when
each cycle restarts from scratch, wasting resources and ignoring information
from previous captures. We propose temporal-prior-guided view planning for
periodic plant reconstruction, in which a previously reconstructed model of the
same plant is non-rigidly aligned to a new partial observation to form an
approximation of the current geometry. To accommodate plant growth, we inflate
this approximation and solve a set covering optimization problem to compute a
minimal set of views. We integrated this method into a complete pipeline that
acquires one additional next-best view before registration for robustness and
then plans a globally shortest path to connect the planned set of views and
outputs the best view sequence. Experiments on maize and tomato under
hemisphere and sphere view spaces show that our system maintains or improves
surface coverage while requiring fewer views and comparable movement cost
compared to state-of-the-art baselines.

</details>


### [16] [Diffusing Trajectory Optimization Problems for Recovery During Multi-Finger Manipulation](https://arxiv.org/abs/2510.07030)
*Abhinav Kumar,Fan Yang,Sergio Aguilera Marinovic,Soshi Iba,Rana Soltani Zarrin,Dmitry Berenson*

Main category: cs.RO

TL;DR: 本研究提出了一种利用扩散模型构建的框架，能够自主管理多指手的任务恢复，通过优化接触丰富的轨迹来显著提升任务执行效率。


<details>
  <summary>Details</summary>
Motivation: 多指手在执行精细操作任务中存在环境干扰和执行错误的问题，因此需要恢复行为来恢复正常任务执行。

Method: 使用训练好的扩散模型评估任务执行状态，并使用扩散采样和轨迹优化规划接触丰富的恢复轨迹。

Result: 在硬件螺丝刀转动任务中，我们的方法比其他方法提高了任务性能96%。

Conclusion: 通过使用我们的恢复方法，任务性能提高了96%，并且是唯一一种可以在不导致灾难性任务失败的情况下尝试恢复的方法。

Abstract: Multi-fingered hands are emerging as powerful platforms for performing fine
manipulation tasks, including tool use. However, environmental perturbations or
execution errors can impede task performance, motivating the use of recovery
behaviors that enable normal task execution to resume. In this work, we take
advantage of recent advances in diffusion models to construct a framework that
autonomously identifies when recovery is necessary and optimizes contact-rich
trajectories to recover. We use a diffusion model trained on the task to
estimate when states are not conducive to task execution, framed as an
out-of-distribution detection problem. We then use diffusion sampling to
project these states in-distribution and use trajectory optimization to plan
contact-rich recovery trajectories. We also propose a novel diffusion-based
approach that distills this process to efficiently diffuse the full
parameterization, including constraints, goal state, and initialization, of the
recovery trajectory optimization problem, saving time during online execution.
We compare our method to a reinforcement learning baseline and other methods
that do not explicitly plan contact interactions, including on a hardware
screwdriver-turning task where we show that recovering using our method
improves task performance by 96% and that ours is the only method evaluated
that can attempt recovery without causing catastrophic task failure. Videos can
be found at https://dtourrecovery.github.io/.

</details>


### [17] [Bring the Apple, Not the Sofa: Impact of Irrelevant Context in Embodied AI Commands on VLA Models](https://arxiv.org/abs/2510.07067)
*Daria Pugacheva,Andrey Moskalenko,Denis Shepelev,Andrey Kuznetsov,Vlad Shakhuro,Elena Tutubalina*

Main category: cs.RO

TL;DR: 本研究深入探讨了VLA模型在语言扰动下的鲁棒性，提出了LLM过滤框架以减少噪声影响。


<details>
  <summary>Details</summary>
Motivation: 调查现有VLA模型在面对自然语言变异时的鲁棒性，以改善其在真实场景中的应用。

Method: 系统地评估最先进的VLA模型在语言扰动下的表现，特别是在两种指令噪声影响下的表现。

Result: 模型性能在增加上下文长度时持续下降，随机上下文对性能的影响较小，而语义和词汇上相似的上下文则可导致约50%的性能下降。

Conclusion: 通过引入基于LLM的过滤框架，模型在嘈杂条件下能够恢复到98.5%的原始性能。

Abstract: Vision Language Action (VLA) models are widely used in Embodied AI, enabling
robots to interpret and execute language instructions. However, their
robustness to natural language variability in real-world scenarios has not been
thoroughly investigated. In this work, we present a novel systematic study of
the robustness of state-of-the-art VLA models under linguistic perturbations.
Specifically, we evaluate model performance under two types of instruction
noise: (1) human-generated paraphrasing and (2) the addition of irrelevant
context. We further categorize irrelevant contexts into two groups according to
their length and their semantic and lexical proximity to robot commands. In
this study, we observe consistent performance degradation as context size
expands. We also demonstrate that the model can exhibit relative robustness to
random context, with a performance drop within 10%, while semantically and
lexically similar context of the same length can trigger a quality decline of
around 50%. Human paraphrases of instructions lead to a drop of nearly 20%. To
mitigate this, we propose an LLM-based filtering framework that extracts core
commands from noisy inputs. Incorporating our filtering step allows models to
recover up to 98.5% of their original performance under noisy conditions.

</details>


### [18] [Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications](https://arxiv.org/abs/2510.07077)
*Kento Kawaharazuka,Jihoon Oh,Jun Yamada,Ingmar Posner,Yuke Zhu*

Main category: cs.RO

TL;DR: 本文全面审查了视觉-语言-行动（VLA）模型，揭示了其在机器人领域的潜力和应用，提供了实用的指导和资源。


<details>
  <summary>Details</summary>
Motivation: 随着对大型语言模型和视觉-语言模型在机器人领域应用的努力增加，VLA模型的通用化能力被视为实现灵活和可扩展的机器人部署的关键。

Method: 通过系统性回顾VLA模型的策略、架构转型、具体架构和构建模块，以及处理技术和学习范式。

Result: 提供了对实际机器人应用中VLA模型的硬件和软件组件的全面审查，并总结了常用机器人平台、数据收集策略、公开数据集、数据增强方法和评估基准。

Conclusion: 本文提供了对视觉-语言-行动（VLA）模型的全面审查，旨在为机器人社区在实际应用中提供指导。

Abstract: Amid growing efforts to leverage advances in large language models (LLMs) and
vision-language models (VLMs) for robotics, Vision-Language-Action (VLA) models
have recently gained significant attention. By unifying vision, language, and
action data at scale, which have traditionally been studied separately, VLA
models aim to learn policies that generalise across diverse tasks, objects,
embodiments, and environments. This generalisation capability is expected to
enable robots to solve novel downstream tasks with minimal or no additional
task-specific data, facilitating more flexible and scalable real-world
deployment. Unlike previous surveys that focus narrowly on action
representations or high-level model architectures, this work offers a
comprehensive, full-stack review, integrating both software and hardware
components of VLA systems. In particular, this paper provides a systematic
review of VLAs, covering their strategy and architectural transition,
architectures and building blocks, modality-specific processing techniques, and
learning paradigms. In addition, to support the deployment of VLAs in
real-world robotic applications, we also review commonly used robot platforms,
data collection strategies, publicly available datasets, data augmentation
methods, and evaluation benchmarks. Throughout this comprehensive survey, this
paper aims to offer practical guidance for the robotics community in applying
VLAs to real-world robotic systems. All references categorized by training
approach, evaluation method, modality, and dataset are available in the table
on our project website: https://vla-survey.github.io .

</details>


### [19] [Sampling Strategies for Robust Universal Quadrupedal Locomotion Policies](https://arxiv.org/abs/2510.07094)
*David Rytz,Kim Tien Ly,Ioannis Havoutis*

Main category: cs.RO

TL;DR: 本研究探索了四足机器人运动策略的关节增益配置采样方法，证明了其对随机化的依赖以提高在现实世界应用中的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 旨在生成具有鲁棒性的四足机器人运动策略，使其能够适应不同的参数配置。

Method: 比较了三种关节增益采样策略，包括线性和多项式映射、基于性能的自适应过滤、以及均匀随机采样。

Result: 实验显示，应用显著的关节控制器增益随机化可以有效缩小仿真与现实之间的差距。

Conclusion: 提出的关节控制器增益随机化策略显著提高了仿真与现实之间的转换效果。

Abstract: This work focuses on sampling strategies of configuration variations for
generating robust universal locomotion policies for quadrupedal robots. We
investigate the effects of sampling physical robot parameters and joint
proportional-derivative gains to enable training a single reinforcement
learning policy that generalizes to multiple parameter configurations. Three
fundamental joint gain sampling strategies are compared: parameter sampling
with (1) linear and polynomial function mappings of mass-to-gains, (2)
performance-based adaptive filtering, and (3) uniform random sampling. We
improve the robustness of the policy by biasing the configurations using
nominal priors and reference models. All training was conducted on RaiSim,
tested in simulation on a range of diverse quadrupeds, and zero-shot deployed
onto hardware using the ANYmal quadruped robot. Compared to multiple baseline
implementations, our results demonstrate the need for significant joint
controller gains randomization for robust closing of the sim-to-real gap.

</details>


### [20] [A Digital Twin Framework for Metamorphic Testing of Autonomous Driving Systems Using Generative Model](https://arxiv.org/abs/2510.07133)
*Tony Zhang,Burak Kantarci,Umair Siddique*

Main category: cs.RO

TL;DR: 本文介绍了一种数字双胞胎与AI生成模型相结合的测试框架，解决了自驾车安全测试中的主要挑战。


<details>
  <summary>Details</summary>
Motivation: 自驾车安全测试的复杂性与不确定性令传统测试方法受限，需要一种新框架来提高测试有效性与覆盖率。

Method: 采用数字双胞胎技术，结合AI图像生成模型，创建虚拟驾驶场景，定义三种变形关系进行测试。

Result: 本文提出了一种数字双胞胎驱动的变形测试框架，旨在解决自驾车安全测试中的挑战，通过虚拟复制自驾系统及其操作环境，结合AI生成模型实现复杂多样的真实驾驶场景的系统生成，并在Udacity自驾模拟器中验证，提升测试覆盖率与效果。

Conclusion: 整合数字双胞胎与AI场景生成技术，可以创建可扩展、自动化且高保真的自驾车安全测试解决方案。

Abstract: Ensuring the safety of self-driving cars remains a major challenge due to the
complexity and unpredictability of real-world driving environments. Traditional
testing methods face significant limitations, such as the oracle problem, which
makes it difficult to determine whether a system's behavior is correct, and the
inability to cover the full range of scenarios an autonomous vehicle may
encounter. In this paper, we introduce a digital twin-driven metamorphic
testing framework that addresses these challenges by creating a virtual replica
of the self-driving system and its operating environment. By combining digital
twin technology with AI-based image generative models such as Stable Diffusion,
our approach enables the systematic generation of realistic and diverse driving
scenes. This includes variations in weather, road topology, and environmental
features, all while maintaining the core semantics of the original scenario.
The digital twin provides a synchronized simulation environment where changes
can be tested in a controlled and repeatable manner. Within this environment,
we define three metamorphic relations inspired by real-world traffic rules and
vehicle behavior. We validate our framework in the Udacity self-driving
simulator and demonstrate that it significantly enhances test coverage and
effectiveness. Our method achieves the highest true positive rate (0.719), F1
score (0.689), and precision (0.662) compared to baseline approaches. This
paper highlights the value of integrating digital twins with AI-powered
scenario generation to create a scalable, automated, and high-fidelity testing
solution for autonomous vehicle safety.

</details>


### [21] [TrackVLA++: Unleashing Reasoning and Memory Capabilities in VLA Models for Embodied Visual Tracking](https://arxiv.org/abs/2510.07134)
*Jiahang Liu,Yunpeng Qi,Jiazhao Zhang,Minghan Li,Shaoan Wang,Kui Wu,Hanjing Ye,Hong Zhang,Zhibo Chen,Fangwei Zhong,Zhizheng Zhang,He Wang*

Main category: cs.RO

TL;DR: TrackVLA++ 是一种新模型，增强了身体视觉跟踪，通过引入空间推理机制和目标识别记忆，以实现更优的跟踪性能和更强的零-shot 泛化能力。


<details>
  <summary>Details</summary>
Motivation: 在复杂和非结构化场景中，增强视觉跟踪的能力，以及应对当前方法中的空间推理和时间记忆短缺问题。

Method: 提出了具有空间推理机制的 Chain-of-Thought（Polar-CoT）模式和目标识别记忆（TIM）的 gated 更新策略。

Result: TrackVLA++ 是一种新型的视觉-语言-动作模型，旨在增强身体视觉跟踪能力，克服了现有方法在严重遮挡或相似干扰物下的局限性。

Conclusion: TrackVLA++ 在公共基准测试中表现出色，超越当前领先方法，确保了在动态和遮挡场景下的稳健跟踪能力。

Abstract: Embodied Visual Tracking (EVT) is a fundamental ability that underpins
practical applications, such as companion robots, guidance robots and service
assistants, where continuously following moving targets is essential. Recent
advances have enabled language-guided tracking in complex and unstructured
scenes. However, existing approaches lack explicit spatial reasoning and
effective temporal memory, causing failures under severe occlusions or in the
presence of similar-looking distractors. To address these challenges, we
present TrackVLA++, a novel Vision-Language-Action (VLA) model that enhances
embodied visual tracking with two key modules, a spatial reasoning mechanism
and a Target Identification Memory (TIM). The reasoning module introduces a
Chain-of-Thought paradigm, termed Polar-CoT, which infers the target's relative
position and encodes it as a compact polar-coordinate token for action
prediction. Guided by these spatial priors, the TIM employs a gated update
strategy to preserve long-horizon target memory, ensuring spatiotemporal
consistency and mitigating target loss during extended occlusions. Extensive
experiments show that TrackVLA++ achieves state-of-the-art performance on
public benchmarks across both egocentric and multi-camera settings. On the
challenging EVT-Bench DT split, TrackVLA++ surpasses the previous leading
approach by 5.1 and 12, respectively. Furthermore, TrackVLA++ exhibits strong
zero-shot generalization, enabling robust real-world tracking in dynamic and
occluded scenarios.

</details>


### [22] [DPL: Depth-only Perceptive Humanoid Locomotion via Realistic Depth Synthesis and Cross-Attention Terrain Reconstruction](https://arxiv.org/abs/2510.07152)
*Jingkai Sun,Gang Han,Pihai Sun,Wen Zhao,Jiahang Cao,Jiaxu Wang,Yijie Guo,Qiang Zhang*

Main category: cs.RO

TL;DR: 本论文提出一种新框架，提高了人形机器人对地形的适应能力，使其在各种复杂地形中具备敏捷和适应性运动。


<details>
  <summary>Details</summary>
Motivation: 针对目前两种主要的人形机器人感知步态（深度图像基于的端到端学习和基于标高图的方法）存在的限制，提出一种新方法以提高训练效率和降低模拟与现实之间的差距。

Method: 三重集成组件：地形感知步态策略与盲背后、基于多模态交叉注意力的变换器以及自遮挡感知光线投射和噪声感知建模的真实深度图像合成方法。

Result: 提出了一种新的框架，集成了地形感知步态策略、多模态交叉注意力变换器和真实深度图像合成方法，以减少地形重构误差超过30%。

Conclusion: 该框架在全尺寸人形机器人上得到了验证，展现出在多样复杂地形上灵活适应的步态。

Abstract: Recent advancements in legged robot perceptive locomotion have shown
promising progress. However, terrain-aware humanoid locomotion remains largely
constrained to two paradigms: depth image-based end-to-end learning and
elevation map-based methods. The former suffers from limited training
efficiency and a significant sim-to-real gap in depth perception, while the
latter depends heavily on multiple vision sensors and localization systems,
resulting in latency and reduced robustness. To overcome these challenges, we
propose a novel framework that tightly integrates three key components: (1)
Terrain-Aware Locomotion Policy with a Blind Backbone, which leverages
pre-trained elevation map-based perception to guide reinforcement learning with
minimal visual input; (2) Multi-Modality Cross-Attention Transformer, which
reconstructs structured terrain representations from noisy depth images; (3)
Realistic Depth Images Synthetic Method, which employs self-occlusion-aware ray
casting and noise-aware modeling to synthesize realistic depth observations,
achieving over 30\% reduction in terrain reconstruction error. This combination
enables efficient policy training with limited data and hardware resources,
while preserving critical terrain features essential for generalization. We
validate our framework on a full-sized humanoid robot, demonstrating agile and
adaptive locomotion across diverse and challenging terrains.

</details>


### [23] [A Narwhal-Inspired Sensing-to-Control Framework for Small Fixed-Wing Aircraft](https://arxiv.org/abs/2510.07160)
*Fengze Xie,Xiaozhou Fan,Jacob Schuster,Yisong Yue,Morteza Gharib*

Main category: cs.RO

TL;DR: 提出了一种创新的传感-控制管道，通过多种技术提高无人机在低速飞行中的表现。


<details>
  <summary>Details</summary>
Motivation: 固定翼无人机虽然具有耐力和效率，但在低速灵活性方面存在不足。

Method: 结合了仿生硬件、物理知识驱动的动态学习和凸控制分配，实现对升力和力矩的精准控制。

Result: 通过提出一种端到端的传感-控制管道，显著提高了固定翼无人机在低速状态下的性能。

Conclusion: 实验结果表明，增加机翼压力传感器大幅减少了力度估计误差，并提高了模型在不同环境条件下的鲁棒性。

Abstract: Fixed-wing unmanned aerial vehicles (UAVs) offer endurance and efficiency but
lack low-speed agility due to highly coupled dynamics. We present an end-to-end
sensing-to-control pipeline that combines bio-inspired hardware,
physics-informed dynamics learning, and convex control allocation. Measuring
airflow on a small airframe is difficult because near-body aerodynamics,
propeller slipstream, control-surface actuation, and ambient gusts distort
pressure signals. Inspired by the narwhal's protruding tusk, we mount in-house
multi-hole probes far upstream and complement them with sparse, carefully
placed wing pressure sensors for local flow measurement. A data-driven
calibration maps probe pressures to airspeed and flow angles. We then learn a
control-affine dynamics model using the estimated airspeed/angles and sparse
sensors. A soft left/right symmetry regularizer improves identifiability under
partial observability and limits confounding between wing pressures and
flaperon inputs. Desired wrenches (forces and moments) are realized by a
regularized least-squares allocator that yields smooth, trimmed actuation.
Wind-tunnel studies across a wide operating range show that adding wing
pressures reduces force-estimation error by 25-30%, the proposed model degrades
less under distribution shift (about 12% versus 44% for an unstructured
baseline), and force tracking improves with smoother inputs, including a 27%
reduction in normal-force RMSE versus a plain affine model and 34% versus an
unstructured baseline.

</details>


### [24] [TIGeR: Tool-Integrated Geometric Reasoning in Vision-Language Models for Robotics](https://arxiv.org/abs/2510.07181)
*Yi Han,Cheng Chi,Enshen Zhou,Shanyu Rong,Jingkun An,Pengwei Wang,Zhongyuan Wang,Lu Sheng,Shanghang Zhang*

Main category: cs.RO

TL;DR: TIGeR框架将视觉语言模型转变为几何计算机，通过外部工具实现精确几何计算，提升机器人操控精度。


<details>
  <summary>Details</summary>
Motivation: 解决当前视觉语言模型在空间推理方面的局限性，尤其是缺乏厘米级的计算精确度，以满足机器人操作的需求。

Method: 采用两阶段训练管道，包括监督微调（SFT）和强化学习微调（RFT），结合分层奖励设计。

Result: TIGeR框架实现了视觉语言模型在几何推理上的重大进展，结合工具调用，提高了机器人系统在精确几何计算上的能力。

Conclusion: TIGeR在几何推理基准测试中表现出色，并在现实世界机器人操控任务中达到厘米级精度。

Abstract: Vision-Language Models (VLMs) have shown remarkable capabilities in spatial
reasoning, yet they remain fundamentally limited to qualitative precision and
lack the computational precision required for real-world robotics. Current
approaches fail to leverage metric cues from depth sensors and camera
calibration, instead reducing geometric problems to pattern recognition tasks
that cannot deliver the centimeter-level accuracy essential for robotic
manipulation. We present TIGeR (Tool-Integrated Geometric Reasoning), a novel
framework that transforms VLMs from perceptual estimators to geometric
computers by enabling them to generate and execute precise geometric
computations through external tools. Rather than attempting to internalize
complex geometric operations within neural networks, TIGeR empowers models to
recognize geometric reasoning requirements, synthesize appropriate
computational code, and invoke specialized libraries for exact calculations. To
support this paradigm, we introduce TIGeR-300K, a comprehensive
tool-invocation-oriented dataset covering point transformations, pose
estimation, trajectory generation, and spatial compatibility verification,
complete with tool invocation sequences and intermediate computations. Through
a two-stage training pipeline combining supervised fine-tuning (SFT) and
reinforcement fine-tuning (RFT) with our proposed hierarchical reward design,
TIGeR achieves SOTA performance on geometric reasoning benchmarks while
demonstrating centimeter-level precision in real-world robotic manipulation
tasks.

</details>


### [25] [COMPAct: Computational Optimization and Automated Modular design of Planetary Actuators](https://arxiv.org/abs/2510.07197)
*Aman Singh,Deepak Kapa,Suryank Joshi,Shishir Kolathaya*

Main category: cs.RO

TL;DR: 本论文提出了COMPAct框架，用于系统性优化机器人执行器的减速机参数，并自动生成CAD模型，以实现高效的3D打印。


<details>
  <summary>Details</summary>
Motivation: 探讨机器执行器设计中的减速机参数优化及其自动化CAD生成的重要性。

Method: 引入COMPAct框架，系统识别不同电机在四种变速箱类型下的最优参数，并自动生成适合3D打印的CAD模型。

Result: 实验表明，SSPG执行器的机械效率为60-80%，而CPG执行器的效率为60%，二者在负载背隙和传输刚度方面也有良好表现。

Conclusion: COMPAct框架有效地优化了不同类型减速机的设计，展示了其在提升机械效率和减小误差方面的潜力。

Abstract: The optimal design of robotic actuators is a critical area of research, yet
limited attention has been given to optimizing gearbox parameters and
automating actuator CAD. This paper introduces COMPAct: Computational
Optimization and Automated Modular Design of Planetary Actuators, a framework
that systematically identifies optimal gearbox parameters for a given motor
across four gearbox types, single-stage planetary gearbox (SSPG), compound
planetary gearbox (CPG), Wolfrom planetary gearbox (WPG), and double-stage
planetary gearbox (DSPG). The framework minimizes mass and actuator width while
maximizing efficiency, and further automates actuator CAD generation to enable
direct 3D printing without manual redesign. Using this framework, optimal
gearbox designs are explored over a wide range of gear ratios, providing
insights into the suitability of different gearbox types across various gear
ratio ranges. In addition, the framework is used to generate CAD models of all
four gearbox types with varying gear ratios and motors. Two actuator types are
fabricated and experimentally evaluated through power efficiency, no-load
backlash, and transmission stiffness tests. Experimental results indicate that
the SSPG actuator achieves a mechanical efficiency of 60-80 %, a no-load
backlash of 0.59 deg, and a transmission stiffness of 242.7 Nm/rad, while the
CPG actuator demonstrates 60 % efficiency, 2.6 deg backlash, and a stiffness of
201.6 Nm/rad. Code available at:
https://anonymous.4open.science/r/COMPAct-SubNum-3408 Video:
https://youtu.be/99zOKgxsDho

</details>


### [26] [HyPlan: Hybrid Learning-Assisted Planning Under Uncertainty for Safe Autonomous Driving](https://arxiv.org/abs/2510.07210)
*Donald Pfaffmann,Matthias Klusch,Marcel Steinmetz*

Main category: cs.RO

TL;DR: HyPlan是一种新的混合学习辅助规划方法，解决自驾车在部分可观察环境中的无碰撞导航问题，具有安全性和执行速度的优势。


<details>
  <summary>Details</summary>
Motivation: 解决部分可观察交通环境下自驾车的无碰撞导航问题

Method: 融合学习辅助方法的规划

Result: HyPlan在CARLA-CTS2基准测试中表现出比基线更安全的导航效果，并且执行速度显著快于其他在线POMDP规划器。

Conclusion: 通过实验，HyPlan在复杂交通场景中表现出优秀的安全性和效率。

Abstract: We present a novel hybrid learning-assisted planning method, named HyPlan,
for solving the collision-free navigation problem for self-driving cars in
partially observable traffic environments. HyPlan combines methods for
multi-agent behavior prediction, deep reinforcement learning with proximal
policy optimization and approximated online POMDP planning with heuristic
confidence-based vertical pruning to reduce its execution time without
compromising safety of driving. Our experimental performance analysis on the
CARLA-CTS2 benchmark of critical traffic scenarios with pedestrians revealed
that HyPlan may navigate safer than selected relevant baselines and perform
significantly faster than considered alternative online POMDP planners.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [27] [Inducing State Anxiety in LLM Agents Reproduces Human-Like Biases in Consumer Decision-Making](https://arxiv.org/abs/2510.06222)
*Ziv Ben-Zion,Zohar Elyoseph,Tobias Spiller,Teddy Lazebnik*

Main category: cs.HC

TL;DR: 大型语言模型（LLMs）在经历心理压力后，其决策表现类似于人类情感偏见，可能影响健康和消费安全。


<details>
  <summary>Details</summary>
Motivation: 探究LLM在现实情境中的可靠性，尤其是在面临压力时的决策表现。

Method: 对三种先进LLM（ChatGPT-5、Gemini 2.5、Claude 3.5-Sonnet）进行实验，测试其在焦虑诱发情境下的杂货购物决策。

Result: 实验结果表明，焦虑情境降低了购物篮的营养质量，表明LLM的决策受心理上下文影响。

Conclusion: LLMs在情感压力下的决策表现揭示了新的脆弱性，需关注其在数字健康和消费安全中的影响。

Abstract: Large language models (LLMs) are rapidly evolving from text generators to
autonomous agents, raising urgent questions about their reliability in
real-world contexts. Stress and anxiety are well known to bias human
decision-making, particularly in consumer choices. Here, we tested whether LLM
agents exhibit analogous vulnerabilities. Three advanced models (ChatGPT-5,
Gemini 2.5, Claude 3.5-Sonnet) performed a grocery shopping task under budget
constraints (24, 54, 108 USD), before and after exposure to anxiety-inducing
traumatic narratives. Across 2,250 runs, traumatic prompts consistently reduced
the nutritional quality of shopping baskets (Change in Basket Health Scores of
-0.081 to -0.126; all pFDR<0.001; Cohens d=-1.07 to -2.05), robust across
models and budgets. These results show that psychological context can
systematically alter not only what LLMs generate but also the actions they
perform. By reproducing human-like emotional biases in consumer behavior, LLM
agents reveal a new class of vulnerabilities with implications for digital
health, consumer safety, and ethical AI deployment.

</details>


### [28] [A Multimodal GUI Architecture for Interfacing with LLM-Based Conversational Assistants](https://arxiv.org/abs/2510.06223)
*Hans G. W. van Dam*

Main category: cs.HC

TL;DR: 本研究提出了一种架构，使语音助手可以通过自然语言与GUI交互，同时注重隐私和数据安全。


<details>
  <summary>Details</summary>
Motivation: 为了实现自然语言与图形用户界面(GUI)的无缝交互，提升用户体验。

Method: 使用模型上下文协议(MCP)和MVVM设计模式，使应用导航图和语义对语音助手可用。

Result: 提出了一种具体架构，使得基于大语言模型(LLM)的语音助手能够与GUI进行有效对接。

Conclusion: 通过对本地可部署的开放权重LLM的评估，研究发现其在准确性上接近主流专有模型，并能实现快速响应。

Abstract: Advances in large language models (LLMs) and real-time speech recognition now
make it possible to issue any graphical user interface (GUI) action through
natural language and receive the corresponding system response directly through
the GUI. Most production applications were never designed with speech in mind.
This article provides a concrete architecture that enables GUIs to interface
with LLM-based speech-enabled assistants.
  The architecture makes an application's navigation graph and semantics
available through the Model Context Protocol (MCP). The ViewModel, part of the
MVVM (Model-View-ViewModel) pattern, exposes the application's capabilities to
the assistant by supplying both tools applicable to a currently visible view
and application-global tools extracted from the GUI tree router. This
architecture facilitates full voice accessibility while ensuring reliable
alignment between spoken input and the visual interface, accompanied by
consistent feedback across modalities. It future-proofs apps for upcoming OS
super assistants that employ computer use agents (CUAs) and natively consume
MCP if an application provides it.
  To address concerns about privacy and data security, the practical
effectiveness of locally deployable, open-weight LLMs for speech-enabled
multimodal UIs is evaluated. Findings suggest that recent smaller open-weight
models approach the performance of leading proprietary models in overall
accuracy and require enterprise-grade hardware for fast responsiveness.

</details>


### [29] [Exploring Human-AI Collaboration Using Mental Models of Early Adopters of Multi-Agent Generative AI Tools](https://arxiv.org/abs/2510.06224)
*Suchismita Naik,Austin L. Toombs,Amanda Snellinger,Scott Saponas,Amanda K. Hall*

Main category: cs.HC

TL;DR: 研究了微软早期采用多智能体生成AI的开发者对人机协作、透明性及相关挑战的理解。


<details>
  <summary>Details</summary>
Motivation: 探讨多智能体生成AI工具的早期采用者如何理解人机协作机制、协作动态和透明性问题。

Method: 通过对13名早期采用者的半结构化访谈，分析他们对多智能体生成AI的看法和体验。

Result: 发现早期采用者将多智能体系统视为由专门角色和任务的代理组成的"团队"，并识别出关键挑战与透明性的重要性。

Conclusion: 提出未来研究方向，扩展CSCW方法于人机以及智能体之间的交互设计。

Abstract: With recent advancements in multi-agent generative AI (Gen AI), technology
organizations like Microsoft are adopting these complex tools, redefining AI
agents as active collaborators in complex workflows rather than as passive
tools. In this study, we investigated how early adopters and developers
conceptualize multi-agent Gen AI tools, focusing on how they understand
human-AI collaboration mechanisms, general collaboration dynamics, and
transparency in the context of AI tools. We conducted semi-structured
interviews with 13 developers, all early adopters of multi-agent Gen AI
technology who work at Microsoft. Our findings revealed that these early
adopters conceptualize multi-agent systems as "teams" of specialized role-based
and task-based agents, such as assistants or reviewers, structured similar to
human collaboration models and ranging from AI-dominant to AI-assisted,
user-controlled interactions. We identified key challenges, including error
propagation, unpredictable and unproductive agent loop behavior, and the need
for clear communication to mitigate the layered transparency issues. Early
adopters' perspectives about the role of transparency underscored its
importance as a way to build trust, verify and trace errors, and prevent
misuse, errors, and leaks. The insights and design considerations we present
contribute to CSCW research about collaborative mechanisms with capabilities
ranging from AI-dominant to AI-assisted interactions, transparency and
oversight strategies in human-agent and agent-agent interactions, and how
humans make sense of these multi-agent systems as dynamic, role-diverse
collaborators which are customizable for diverse needs and workflows. We
conclude with future research directions that extend CSCW approaches to the
design of inter-agent and human mediation interactions.

</details>


### [30] ["Grillz on a hijabi": Intersectional Identities in Fostering Critical AI Literacy](https://arxiv.org/abs/2510.06306)
*Jaemarie Solyst,Chloe Fong,Faisal Nurdin,Rotem Landesman,R. Benjamin Shapiro*

Main category: cs.HC

TL;DR: 本研究探讨了如何通过时装设计与生成人工智能（GenAI）结合，帮助黑人穆斯林青少女发展批判性AI素养，并揭示当前GenAI工具的优缺点。


<details>
  <summary>Details</summary>
Motivation: 鉴于AI日益融入日常生活，青少年需要掌握批判性使用和评估AI系统的技能，并设想更好的替代方案。

Method: 通过对为期三天的自愿非正式教育项目的案例研究，考察参与者使用GenAI进行时装设计的过程。

Result: 研究发现，参与者在使用GenAI创造理想时装系列时，遇到了AI的社会伦理局限性，比如偏见模型和无法生成反映其创意和文化的输出。

Conclusion: 本研究的发现有助于理解创意与身份链接的计算教育体验设计如何支持批判性AI素养的发展。

Abstract: As AI increasingly saturates our daily lives, it is crucial that youth
develop skills to critically use and assess AI systems and envision better
alternatives. We apply theories from culturally responsive computing to design
and study a learning experience meant to support Black Muslim teen girls in
developing critical literacy with generative AI (GenAI). We investigate fashion
design as a culturally-rich, creative domain for youth to apply GenAI and then
reflect on GenAI's socio-ethical aspects in relation to their own
intersectional identities. Through a case study of a three-day, voluntary
informal education program, we show how fashion design with GenAI exposed
affordances and limitations of current GenAI tools. As the girls used GenAI to
create realistic depictions of their dream fashion collections, they
encountered socio-ethical limitations of AI, such as biased models and
malfunctioning safety systems that prohibited their generation of outputs that
reflected their creative ideas, bodies, and cultures. Discussions anchored in
the phenomenology of impossible creative realization supported participants'
development of critical AI literacy and descriptions of how preferable,
identity-affirming technologies would behave. Our findings contribute to the
field's growing understanding of how computing education experience designs
linking creativity and identity can support critical AI literacy development.

</details>


### [31] [Code Semantic Zooming](https://arxiv.org/abs/2510.06452)
*Jinsheng Ba,Sverrir Thorgeirsson,Zhendong Su*

Main category: cs.HC

TL;DR: 提出了代码语义缩放，帮助开发者通过更高层次的抽象来探索和改进代码。


<details>
  <summary>Details</summary>
Motivation: 开发复杂的、真实的软件系统仍然具有挑战性，因为自然语言对生成代码的控制有限。

Method: 开发了一种名为代码语义缩放的新方法，作为VS Code扩展实现，支持开发者在多个语义抽象层次上迭代探索、理解和改进代码。

Result: 提出了一种基于伪代码的高层次抽象语言，以增强开发者对LLM辅助代码编写的控制。

Conclusion: 通过两个实际案例研究验证了代码语义缩放的有效性。

Abstract: Recent advances in Large Language Models (LLMs) have introduced a new
paradigm for software development, where source code is generated directly from
natural language prompts. While this paradigm significantly boosts development
productivity, building complex, real-world software systems remains challenging
because natural language offers limited control over the generated code.
Inspired by the historical evolution of programming languages toward higher
levels of abstraction, we advocate for a high-level abstraction language that
gives developers greater control over LLM-assisted code writing. To this end,
we propose Code Semantic Zooming, a novel approach based on pseudocode that
allows developers to iteratively explore, understand, and refine code across
multiple layers of semantic abstraction. We implemented Code Semantic Zooming
as a VS Code extension and demonstrated its effectiveness through two
real-world case studies.

</details>


### [32] [Evaluating Node-tree Interfaces for AI Explainability](https://arxiv.org/abs/2510.06457)
*Lifei Wang,Natalie Friedman,Chengchao Zhu,Zeshu Zhu,S. Joy Mountford*

Main category: cs.HC

TL;DR: 本研究评估了节点树接口与聊天机器人接口在AI交互中的表现，发现节点树接口在提升用户信任和决策支持方面表现更佳。


<details>
  <summary>Details</summary>
Motivation: 在大语言模型广泛应用于工作工具和决策过程中，确保可解释性和增强用户信任变得至关重要。

Method: 通过比较研究评估用户在节点树接口和聊天机器人接口的使用体验，涉及探索性、跟进查询、决策和问题解决任务。

Result: 节点树接口不仅提升了任务绩效和决策支持，还通过保持上下文促进了更高水平的用户信任。

Conclusion: 自适应AI接口能够根据任务需求在结构化可视化和对话格式之间切换，从而显著提升透明度和用户信心。

Abstract: As large language models (LLMs) become ubiquitous in workplace tools and
decision-making processes, ensuring explainability and fostering user trust are
critical. Although advancements in LLM engineering continue, human-centered
design is still catching up, particularly when it comes to embedding
transparency and trust into AI interfaces. This study evaluates user
experiences with two distinct AI interfaces - node-tree interfaces and chatbot
interfaces - to assess their performance in exploratory, follow-up inquiry,
decision-making, and problem-solving tasks. Our design-driven approach
introduces a node-tree interface that visually structures AI-generated
responses into hierarchically organized, interactive nodes, allowing users to
navigate, refine, and follow up on complex information. In a comparative study
with n=20 business users, we observed that while the chatbot interface
effectively supports linear, step-by-step queries, it is the node-tree
interface that enhances brainstorming. Quantitative and qualitative findings
indicate that node-tree interfaces not only improve task performance and
decision-making support but also promote higher levels of user trust by
preserving context. Our findings suggest that adaptive AI interfaces capable of
switching between structured visualizations and conversational formats based on
task requirements can significantly enhance transparency and user confidence in
AI-powered systems. This work contributes actionable insights to the fields of
human-robot interaction and AI design, particularly for enterprise applications
where trust-building is critical for teams.

</details>


### [33] [Back to the Future Museum -- Speculative Design for Virtual Citizen-Curated Museums](https://arxiv.org/abs/2510.06472)
*Richard Rhodes,Sandra Woolley*

Main category: cs.HC

TL;DR: 本论文探讨未来博物馆的构想，通过公民策展人的视角设计沉浸式虚拟现实体验，并考虑其对传统博物馆的影响。


<details>
  <summary>Details</summary>
Motivation: 探索未来博物馆的场景，赋予公民策展人以设计和分享沉浸式虚拟现实博物馆的能力

Method: 使用推测性设计虚构

Result: 提出包含实物遗产、虚拟元素和互动体验的未来博物馆设想，以及相关的3D模型和互动体验资产包

Conclusion: 讨论这种未来博物馆模型对资源配置及传统博物馆潜在影响的意义。

Abstract: This forward-looking paper uses speculative design fiction to explore future
museum scenarios where citizen curators design and share immersive virtual
reality museums populated with tangible heritage artefacts, intangible virtual
elements and interactive experiences. The work also explores takeaway 'asset
packs' containing 3D artefact models, curation assets, and interactive
experiences, and we envisage a visit to the future museum, where the physical
and virtual experiences interplay. Finally, the paper considers the
implications of this future museum in terms of resources and the potential
impacts on traditional museums.

</details>


### [34] [AI Eyes on the Road: Cross-Cultural Perspectives on Traffic Surveillance](https://arxiv.org/abs/2510.06480)
*Ziming Wang,Shiwei Yang,Rebecca Currano,Morten Fjeld,David Sirkin*

Main category: cs.HC

TL;DR: 这项研究通过在线调查比较了三种道路监控模式的公众接受度，发现传统监控最受欢迎，而公共羞辱最不受欢迎，且文化背景影响受访者的态度。


<details>
  <summary>Details</summary>
Motivation: 探讨AI增强监控系统在公共场所的接受度及其对隐私、公平性和个人数据滥用的担忧。

Method: 在线调查（N=720），采用3×3因子设计比较三种道路监控模式：传统监控、AI增强监控和带公共羞辱的AI增强监控，涵盖中国、欧洲和美国的受访者。

Result: 传统监控模式最受欢迎，而公共羞辱的监控模式最不受欢迎；中国受访者对AI增强监控的接受度显著高于欧洲和美国受访者。

Conclusion: 在考虑AI增强监控时，必须考虑背景、文化和社会规范，因为这些因素影响信任、舒适度和整体接受度。

Abstract: AI-powered road surveillance systems are increasingly proposed to monitor
infractions such as speeding, phone use, and jaywalking. While these systems
promise to enhance safety by discouraging dangerous behaviors, they also raise
concerns about privacy, fairness, and potential misuse of personal data. Yet
empirical research on how people perceive AI-enhanced monitoring of public
spaces remains limited. We conducted an online survey ($N=720$) using a
3$\times$3 factorial design to examine perceptions of three road surveillance
modes -- conventional, AI-enhanced, and AI-enhanced with public shaming --
across China, Europe, and the United States. We measured perceived capability,
risk, transparency, and acceptance. Results show that conventional surveillance
was most preferred, while public shaming was least preferred across all
regions. Chinese respondents, however, expressed significantly higher
acceptance of AI-enhanced modes than Europeans or Americans. Our findings
highlight the need to account for context, culture, and social norms when
considering AI-enhanced monitoring, as these shape trust, comfort, and overall
acceptance.

</details>


### [35] [A Meat-Summer Night's Dream: A Tangible Design Fiction Exploration of Eating Biohybrid Flying Robots](https://arxiv.org/abs/2510.06507)
*Ziming Wang,Yiqian Wu,Qingxiao Zheng,Shihan Zhang,Ned Barker,Morten Fjeld*

Main category: cs.HC

TL;DR: 本研究通过一场2052年巴黎餐厅的体验性戏剧，探讨在未来餐饮中食用机器人的概念，反思可持续性和伦理问题。


<details>
  <summary>Details</summary>
Motivation: 探索未来餐饮中食用机器人的可能性，反思可持续性、伦理和文化身份。

Method: 在一场融合表演、仪式和多感官沉浸的晚餐剧院中，邀请六位创意产业的参与者，体验和辩论食用生物混合飞行机器人的概念。

Result: 提出了三个对HCI的贡献，包括以机器人作为食物的设想物、对公共文化和伦理边界的经验性见解，以及在体现、感官设计小说中的方法创新。

Conclusion: 未来的饮食文化可能会挑战传统的伦理和文化界限，促使我们重新思考食品的意义。

Abstract: What if future dining involved eating robots? We explore this question
through a playful and poetic experiential dinner theater: a tangible design
fiction staged as a 2052 Paris restaurant where diners consume a biohybrid
flying robot in place of the banned delicacy of ortolan bunting. Moving beyond
textual or visual speculation, our ``dinner-in-the-drama'' combined
performance, ritual, and multisensory immersion to provoke reflection on
sustainability, ethics, and cultural identity. Six participants from creative
industries engaged as diners and role-players, responding with curiosity,
discomfort, and philosophical debate. They imagined biohybrids as both
plausible and unsettling -- raising questions of sentience, symbolism, and
technology adoption that exceed conventional sustainability framings of
synthetic meat. Our contributions to HCI are threefold: (i) a speculative
artifact that stages robots as food, (ii) empirical insights into how publics
negotiate cultural and ethical boundaries in post-natural eating, and (iii) a
methodological advance in embodied, multisensory design fiction.

</details>


### [36] [Examining Solidarity Against AI-Enabled Surveillance at the Intersection of Workplace and Carceral Realities](https://arxiv.org/abs/2510.06537)
*Morgan McErlean,Cella M. Sum,Sukrit Venkatagiri,Sarah Fox*

Main category: cs.HC

TL;DR: AI驱动的监控技术对工人和监禁系统受害者的影响是相互交叉的，必须通过团结来抵抗。


<details>
  <summary>Details</summary>
Motivation: 随着AI监控成为常态，受监控群体的团结和互助是反抗这一现象的关键。

Method: 通过初步的数据收集，分析工人监控与监禁系统的相互关系。

Result: 本研究揭示了工人与受监禁影响的个体在AI驱动的监控技术下所面临的交叉监控情况，并强调了建立团结互助的重要性，以对抗这种技术的侵害。

Conclusion: 工人与受监禁影响个体的监督交集，表明必须进行团结与行动以对抗监控。

Abstract: As panoptical, AI-driven surveillance becomes a norm, everyone is impacted.
In a reality where all people fall victim to these technologies, establishing
links and solidarity is essential to fighting back. Two groups facing rising
and targeted surveillance are workers and individuals impacted by the carceral
system. Through preliminary data collection from a worker-surveillance lens,
our findings reveal several cases of these surveillance infrastructures
intersecting. Continuation of our work will involve collecting cases from a
carceral-centered lens. Driven by a community-facing analysis of the overlap in
the AI-driven surveillance experienced by workers and individuals impacted by
the carceral system, we will facilitate discussions with restorative justice
activists around cultivating solidarity and empowerment focused on the
interconnected nature of workplace and carceral surveillance technologies.

</details>


### [37] [PriorWeaver: Prior Elicitation via Iterative Dataset Construction](https://arxiv.org/abs/2510.06550)
*Yuwei Xiao,Shuai Ma,Antti Oulasvirta,Eunice Jun*

Main category: cs.HC

TL;DR: PriorWeaver是一个新开发的交互式可视化工具，可以帮助分析师更好地表达和调整他们的先验信念，从而提高贝叶斯分析的效果。


<details>
  <summary>Details</summary>
Motivation: 在贝叶斯分析中，先验引导是一个重要但充满挑战的步骤，本研究旨在改善这一过程。

Method: PriorWeaver通过可视化方式让分析师表达变量及其关系的假设，这些假设随后用于生成数据集和统计先验，并通过先验预测检查来验证这些先验与分析师的假设之间的关系。

Result: 提出了一个交互式可视化系统PriorWeaver，它通过迭代的数据集构建和修整来促进先验引导。

Conclusion: 与现有技术相比，PriorWeaver让参与者在先验引导过程中有了更大的控制力、更清晰的理解以及更高的信心，从而导致了更符合他们期望的先验分布。

Abstract: In Bayesian analysis, prior elicitation, or the process of explicating one's
beliefs to inform statistical modeling, is an essential yet challenging step.
Analysts often have beliefs about real-world variables and their relationships.
However, existing tools require analysts to translate these beliefs and express
them indirectly as probability distributions over model parameters. We present
PriorWeaver, an interactive visualization system that facilitates prior
elicitation through iterative dataset construction and refinement. Analysts
visually express their assumptions about individual variables and their
relationships. Under the hood, these assumptions create a dataset used to
derive statistical priors. Prior predictive checks then help analysts compare
the priors to their assumptions. In a lab study with 17 participants new to
Bayesian analysis, we compare PriorWeaver to a baseline incorporating existing
techniques. Compared to the baseline, PriorWeaver gave participants greater
control, clarity, and confidence, leading to priors that were better aligned
with their expectations.

</details>


### [38] [RAVEN: Realtime Accessibility in Virtual ENvironments for Blind and Low-Vision People](https://arxiv.org/abs/2510.06573)
*Xinyun Cao,Kexin Phyllis Ju,Chenglin Li,Venkatesh Potluri,Dhruv Jain*

Main category: cs.HC

TL;DR: 本研究提出了RAVEN，一个通过自然语言增强盲人和低视力用户在3D虚拟环境中的访问体验的系统，尽管有积极成果，但也面临系统可靠性和用户信任的问题。


<details>
  <summary>Details</summary>
Motivation: 在迅速发展的虚拟3D环境中，确保盲人和低视力用户的平等访问是非常重要的。

Method: 评估RAVEN系统与八名盲人和低视力用户的互动，收集用户对系统的反馈。

Result: 评估结果显示，生成式AI推动的可访问性改善了虚拟场景的互动体验，同时暴露了系统的可靠性和用户信任等挑战。

Conclusion: RAVEN系统为盲人和低视力用户提供了更灵活的3D虚拟环境访问方案，但仍需克服系统可靠性和用户信任的问题。

Abstract: As virtual 3D environments become prevalent, equitable access is crucial for
blind and low-vision (BLV) users who face challenges with spatial awareness,
navigation, and interactions. To address this gap, previous work explored
supplementing visual information with auditory and haptic modalities. However,
these methods are static and offer limited support for dynamic, in-context
adaptation. Recent work in generative AI enables users to query and modify 3D
scenes via natural language, introducing a paradigm with increased flexibility
and control for accessibility improvements. We present RAVEN, a system that
responds to query or modification prompts from BLV users to improve the runtime
accessibility of 3D virtual scenes. We evaluated the system with eight BLV
people, uncovering key insights into the strengths and shortcomings of
generative AI-driven accessibility in virtual 3D environments, pointing to
promising results as well as challenges related to system reliability and user
trust.

</details>


### [39] [Investigating Students' Preferences for AI Roles in Mathematical Modelling: Evidence from a Randomized Controlled Trial](https://arxiv.org/abs/2510.06617)
*Wangda Zhu,Guang Chen,Yumeng Zhu,Lei Cai,Xiangen Hu*

Main category: cs.HC

TL;DR: 本研究探讨了AI在数学建模教育中的角色，发现学生的设计思维和计算思维与其数学建模自我效能之间的关系，以及他们对AI作为不同角色的偏好，为未来的学习系统设计提供了参考。


<details>
  <summary>Details</summary>
Motivation: 数学建模是解决复杂现实问题的关键能力，但许多学生在抽象、表示和迭代推理方面存在困难；因此，探讨AI在数学建模教育中的角色非常重要。

Method: 使用随机对照试验方法，研究学生设计思维、计算思维与数学建模自我效能之间的关系，并调查他们对不同AI角色的偏好。

Result: 发现设计思维、计算思维与数学建模自我效能之间存在显著联系，并揭示了学生对AI角色的不同偏好，如导师、工具、合作者和同伴。

Conclusion: 此研究深化了对AI支持的数学建模的理解，并为以学习者为中心的自适应系统提供了设计启示。

Abstract: Mathematical modelling (MM) is a key competency for solving complex
real-world problems, yet many students struggle with abstraction,
representation, and iterative reasoning. Artificial intelligence (AI) has been
proposed as a support for higher-order thinking, but its role in MM education
is still underexplored. This study examines the relationships among students'
design thinking (DT), computational thinking (CT), and mathematical modelling
self-efficacy (MMSE), and investigates their preferences for different AI roles
during the modelling process. Using a randomized controlled trial, we identify
significant connections among DT, CT, and MMSE, and reveal distinct patterns in
students' preferred AI roles, including AI as a tutor (providing explanations
and feedback), AI as a tool (assisting with calculations and representations),
AI as a collaborator (suggesting strategies and co-creating models), and AI as
a peer (offering encouragement and fostering reflection). Differences across
learner profiles highlight how students' dispositions shape their expectations
for AI. These findings advance understanding of AI-supported MM and provide
design implications for adaptive, learner-centered systems.

</details>


### [40] ["It feels like hard work trying to talk to it": Understanding Older Adults' Experiences of Encountering and Repairing Conversational Breakdowns with AI Systems](https://arxiv.org/abs/2510.06690)
*Niharika Mathur,Tamara Zubatiy,Agata Rozga,Elizabeth Mynatt*

Main category: cs.HC

TL;DR: 本研究探讨了老年人在与语音AI系统互动中处理对话断裂的策略，强调AI系统应更好地与用户期望对齐，促进更有效的交互。


<details>
  <summary>Details</summary>
Motivation: 设计支持老年人的对话AI系统不仅需要可用性和可靠性，还需要在处理对话断裂方面的鲁棒性。

Method: 通过为期20周的家庭部署，对7对老年参与者的844次录音互动进行分析，识别对话中的断裂和用户自发的修复策略。

Result: 识别出四种类型的对话断裂，展示了老年人如何利用他们的情境知识和环境来理解和克服这些干扰，强调了所需的认知努力。

Conclusion: AI系统需要更好地与老年人的记忆、日常生活和外部资源对齐，以促进更有意义和以用户为中心的交互。

Abstract: Designing Conversational AI systems to support older adults requires more
than usability and reliability, it also necessitates robustness in handling
conversational breakdowns. In this study, we investigate how older adults
navigate and repair such breakdowns while interacting with a voice-based AI
system deployed in their homes for medication management. Through a 20-week
in-home deployment with 7 older adult participant dyads, we analyzed 844
recoded interactions to identify conversational breakdowns and user-initiated
repair strategies. Through findings gleaned from post-deployment interviews, we
reflect on the nature of these breakdowns and older adults' experiences of
mitigating them. We identify four types of conversational breakdowns and
demonstrate how older adults draw on their situated knowledge and environment
to make sense of and recover from these disruptions, highlighting the cognitive
effort required in doing so. Our findings emphasize the collaborative nature of
interactions in human-AI contexts, and point to the need for AI systems to
better align with users' expectations for memory, their routines, and external
resources in their environment. We conclude by discussing opportunities for AI
systems to integrate contextual knowledge from older adults' sociotechnical
environment and to facilitate more meaningful and user-centered interactions.

</details>


### [41] ["Sometimes You Need Facts, and Sometimes a Hug": Understanding Older Adults' Preferences for Explanations in LLM-Based Conversational AI Systems](https://arxiv.org/abs/2510.06697)
*Niharika Mathur,Tamara Zubatiy,Agata Rozga,Jodi Forlizzi,Elizabeth Mynatt*

Main category: cs.HC

TL;DR: 本研究探讨了老年人对AI生成解释的需求和看法，发现解释的有效性受对话上下文的影响，并建议在对话式AI设计中考虑个性化和上下文敏感的解释。


<details>
  <summary>Details</summary>
Motivation: 研究老年人对AI解释的需求和看法，以填补现有文献的空白，提升信任和用户体验。

Method: 通过与23名老年人进行探讨式的Speed Dating研究，了解他们对上下文相关的AI解释的反应。

Result: 发现解释的有效性受对话内容、语气和框架等线索影响，且老年人倾向于将这些解释视为互动的多轮对话交换。

Conclusion: 为了更好地服务于老年人，设计对话式AI系统时需要关注其对解释的个性化和上下文敏感性。

Abstract: Designing Conversational AI systems to support older adults requires these
systems to explain their behavior in ways that align with older adults'
preferences and context. While prior work has emphasized the importance of AI
explainability in building user trust, relatively little is known about older
adults' requirements and perceptions of AI-generated explanations. To address
this gap, we conducted an exploratory Speed Dating study with 23 older adults
to understand their responses to contextually grounded AI explanations. Our
findings reveal the highly context-dependent nature of explanations, shaped by
conversational cues such as the content, tone, and framing of explanation. We
also found that explanations are often interpreted as interactive, multi-turn
conversational exchanges with the AI, and can be helpful in calibrating
urgency, guiding actionability, and providing insights into older adults' daily
lives for their family members. We conclude by discussing implications for
designing context-sensitive and personalized explanations in Conversational AI
systems.

</details>


### [42] [Lonely Individuals Show Distinct Patterns of Social Media Engagement](https://arxiv.org/abs/2510.06733)
*Yajing Wang,Talayeh Aledavood,Juhi Kulshrestha*

Main category: cs.HC

TL;DR: 社交媒体使用与孤独感正相关，特别是在不同平台上表现出不同的行为模式。


<details>
  <summary>Details</summary>
Motivation: 了解社交媒体使用与孤独感之间的关系

Method: 分析6个月的网络痕迹数据与重复问卷结合

Result: 发现更高的社交媒体使用与更高的孤独感相关

Conclusion: 长时间的网络痕迹数据能够揭示与孤独感相关的行为模式，为数字干预设计提供指导。

Abstract: Loneliness has reached epidemic proportions globally, posing serious risks to
mental and physical health. As social media platforms increasingly mediate
social interaction, understanding their relationship with loneliness has become
urgent. While survey-based research has examined social media use and
loneliness, findings remain mixed, and little is known about when and how often
people engage with social media, or about whether different types of platforms
are differently associated with loneliness. Web trace data now enable objective
examination of these behavioral dimensions. We asked whether objectively
measured patterns of social media engagement differ between lonely and
non-lonely individuals across devices and platform types. Analyzing six months
of web trace data combined with repeated surveys ($N=589$ mobile users; $N=851$
desktop users), we found that greater social media use was associated with
higher loneliness across both devices, with this relationship specific to
social media rather than other online activities. On desktop, lonely
individuals exhibited shorter sessions but more frequent daily engagement.
Lonely individuals spent more time on visual-sharing ($g = -0.47$), messaging
($g = -0.36$), and networking-oriented platforms on mobile. These findings
demonstrate how longitudinal web trace data can reveal behavioral patterns
associated with loneliness, and more broadly illustrate the potential of
digital traces for studying other psychological states. Beyond research, the
results inform the responsible design of digital interventions and platform
features that better support psychological well-being across different
technological contexts.

</details>


### [43] [GPT-5 Model Corrected GPT-4V's Chart Reading Errors, Not Prompting](https://arxiv.org/abs/2510.06782)
*Kaichun Yang,Jian Chen*

Main category: cs.HC

TL;DR: 本研究分析零-shot和不同提示对图表阅读任务的影响，结果表明GPT-5的模型架构明显提升了推理准确性。


<details>
  <summary>Details</summary>
Motivation: 研究零-shot大型语言模型（LLMs）和提示使用对图表阅读任务的影响，旨在提高可视化问题的解答准确性。

Method: 通过对107个视觉问题进行定量评估，比较了GPT-5和GPT-4V两种模型的推理表现。

Result: 通过对107个可视化问题的评估，发现GPT-5在推理准确性上表现显著优于多模态的GPT-4V，尤其在GPT-4V未能正确回答的困难图像实例中。

Conclusion: 模型架构对推理准确性的影响大于提示的变化，GPT-5显著提高了准确率。

Abstract: We present a quantitative evaluation to understand the effect of zero-shot
large-language model (LLMs) and prompting uses on chart reading tasks. We asked
LLMs to answer 107 visualization questions to compare inference accuracies
between the agentic GPT-5 and multimodal GPT-4V, for difficult image instances,
where GPT-4V failed to produce correct answers. Our results show that model
architecture dominates the inference accuracy: GPT5 largely improved accuracy,
while prompt variants yielded only small effects. Pre-registration of this work
is available here:
https://osf.io/u78td/?view_only=6b075584311f48e991c39335c840ded3; the Google
Drive materials are
here:https://drive.google.com/file/d/1ll8WWZDf7cCNcfNWrLViWt8GwDNSvVrp/view.

</details>


### [44] [Am I Productive? Exploring the Experience of Remote Workers with Task Management Tools](https://arxiv.org/abs/2510.06816)
*Russell Beale*

Main category: cs.HC

TL;DR: 本研究探讨了远程知识工作者的生产力需求和挑战，发现使用数字任务管理工具与传统的笔纸方式在提高生产力上没有显著差异。


<details>
  <summary>Details</summary>
Motivation: 随着远程工作趋势的上升，知识工作者面临着生产力挑战，任务管理工具的有效性亟待探讨。

Method: 通过为期两周的混合方法日记研究和半结构式访谈收集数据。

Result: 研究表明，数字任务管理应用对提高远程工作者的感知生产力并没有显著的提升效果。

Conclusion: 任务管理应用需要更好的个性化，以满足远程工作者的生产力需求。

Abstract: As the world continues to change, more and more knowledge workers are
embracing remote work. Yet this comes with its challenges for their
productivity, and while many Task Management applications promise to improve
the productivity of remote workers, it remains unclear how effective they are.
Based on existing frameworks, this study investigated the productivity needs
and challenges of remote knowledge workers and how they use Task Management
tools. The research was conducted through a 2-week long, mixed-methods diary
study and semi-structured interview. Perceptions of productivity, task
management tool use and productivity challenges were observed. The findings
show that using a digital Task Management application made no significant
difference to using pen and paper for improving perceived productivity of
remote workers and discuss the need for better personalization of Task
Management applications.

</details>


### [45] [Prototyping Multimodal GenAI Real-Time Agents with Counterfactual Replays and Hybrid Wizard-of-Oz](https://arxiv.org/abs/2510.06872)
*Frederic Gmeiner,Kenneth Holstein,Nikolas Martelaro*

Main category: cs.HC

TL;DR: 本论文探讨了一个新颖的用户中心原型方法，以克服原有原型和评估方法在多模态生成AI中的局限，目的是设计更具用户友好性和上下文感知的代理。


<details>
  <summary>Details</summary>
Motivation: 推动多模态生成AI的进步，开发个人上下文感知实时代理，以便通过用户的屏幕活动提供上下文帮助。

Method: 采用反事实视频重播提示和混合巫师模式的结合，进行迭代设计和优化代理行为的用户中心原型方法。

Result: 提出了一种新颖的用户中心原型方法，结合了反事实视频重播提示和混合的巫师模式，旨在迭代设计和优化代理行为。

Conclusion: 确定了现有原型和评估方法的不足，并提供了一种实用指南和开源工具包，以支持UX设计师和HCI研究人员。

Abstract: Recent advancements in multimodal generative AI (GenAI) enable the creation
of personal context-aware real-time agents that, for example, can augment user
workflows by following their on-screen activities and providing contextual
assistance. However, prototyping such experiences is challenging, especially
when supporting people with domain-specific tasks using real-time inputs such
as speech and screen recordings. While prototyping an LLM-based proactive
support agent system, we found that existing prototyping and evaluation methods
were insufficient to anticipate the nuanced situational complexity and
contextual immediacy required. To overcome these challenges, we explored a
novel user-centered prototyping approach that combines counterfactual video
replay prompting and hybrid Wizard-of-Oz methods to iteratively design and
refine agent behaviors. This paper discusses our prototyping experiences,
highlighting successes and limitations, and offers a practical guide and an
open-source toolkit for UX designers, HCI researchers, and AI toolmakers to
build more user-centered and context-aware multimodal agents.

</details>


### [46] [Emotionally Vulnerable Subtype of Internet Gaming Disorder: Measuring and Exploring the Pathology of Problematic Generative AI Use](https://arxiv.org/abs/2510.06908)
*Haocan Sun,Di Wua,Weizi Liu,Guoming Yua,Mike Yao*

Main category: cs.HC

TL;DR: 本研究开发了PUGenAIS-9量表以识别GenAI的成瘾性，验证其结构并确认其在不同国籍和性别间的稳定性。


<details>
  <summary>Details</summary>
Motivation: 研究生成性人工智能（GenAI）使用过度病理化的潜在担忧，以及围绕GenAI成瘾概念的模糊性，呼吁开发实证工具和理论的完善。

Method: 对来自中国和美国的样本进行确认性因素分析，通过选择各维度的高加载项形成PUGenAIS-9，并在独立样本中验证其结构。

Result: 开发并验证了PUGenAIS-9量表，用以衡量有关GenAI使用的成瘾模式，并与互联网游戏障碍（IGD）框架进行了关联。

Conclusion: PUGenAIS-9能够有效识别出问题性GenAI使用，显示了使用ICD模型重新思考数字成瘾的必要性，从而使成瘾研究能够与新媒体保持响应，同时避免过度病理化。

Abstract: Concerns over the potential over-pathologization of generative AI (GenAI) use
and the lack of conceptual clarity surrounding GenAI addiction call for
empirical tools and theoretical refinement. This study developed and validated
the PUGenAIS-9 (Problematic Use of Generative Artificial Intelligence Scale-9
items) and examined whether PUGenAIS reflects addiction-like patterns under the
Internet Gaming Disorder (IGD) framework. Using samples from China and the
United States (N = 1,508), we conducted confirmatory factor analysis and
identified a robust 31-item structure across nine IGD-based dimensions. We then
derived the PUGenAIS-9 by selecting the highest-loading items from each
dimension and validated its structure in an independent sample (N = 1,426).
Measurement invariance tests confirmed its stability across nationality and
gender. Person-centered (latent profile analysis) and variable-centered
(network analysis) approaches found that PUGenAIS matches the traits of the
emotionally vulnerable subtype of IGD, not the competence-based kind. These
results support using PUGenAIS-9 to identify problematic GenAI use and show the
need to rethink digital addiction with an ICD (infrastructures, content, and
device) model. This keeps addiction research responsive to new media while
avoiding over-pathologizing.

</details>


### [47] [The Feature Understandability Scale for Human-Centred Explainable AI: Assessing Tabular Feature Importance](https://arxiv.org/abs/2510.07050)
*Nicola Rossberg,Bennett Kleinberg,Barry O'Sullivan,Luca Longo,Andrea Visentin*

Main category: cs.HC

TL;DR: 随着AI的普及，评估用户对输入特征理解的能力愈发重要。本文提出了一种新量表用于量化评估，并展示了良好的心理测量学特性。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能的普及，审计基于AI的系统变得愈发重要，但用户对解释的理解依赖于其对输入特征的理解。

Method: 通过引入心理测量学验证的量表，定量评估用户对监督分类问题中表格输入特征的理解。

Result: 通过确认性因素分析，展示了量表项目之间的强关系，并很好地符合每个量表的两因素结构。

Conclusion: 本文提出了一种新方法来评估用户对表格输入特征的理解，并探讨了其在可解释人工智能领域的潜在应用。

Abstract: As artificial intelligence becomes increasingly pervasive and powerful, the
ability to audit AI-based systems is becoming increasingly important. However,
explainability for artificial intelligence systems is not a one-size-fits-all
solution; different target audiences have varying requirements and expectations
for explanations. While various approaches to explainability have been
proposed, most explainable artificial intelligence (XAI) methods for tabular
data focus on explaining the outputs of supervised machine learning models
using the input features. However, a user's ability to understand an
explanation depends on their understanding of such features. Therefore, it is
in the best interest of the system designer to try to pre-select understandable
features for producing a global explanation of an ML model. Unfortunately, no
measure currently exists to assess the degree to which a user understands a
given input feature. This work introduces psychometrically validated scales
that quantitatively seek to assess users' understanding of tabular input
features for supervised classification problems. In detail, these scales, one
for numerical and one for categorical data, each with two factors and
comprising 8 and 9 items, aim to assign a score to each input feature,
effectively producing a rank, and allowing for the quantification of feature
prioritisation. A confirmatory factor analysis demonstrates a strong
relationship between such items and a good fit of the two-factor structure for
each scale. This research presents a novel method for assessing understanding
and outlines potential applications in the domain of explainable artificial
intelligence.

</details>


### [48] [Artists' Views on Robotics Involvement in Painting Productions](https://arxiv.org/abs/2510.07063)
*Francesca Cocchella,Nilay Roy Choudhury,Eric Chen,Patrícia Alves-Oliveira*

Main category: cs.HC

TL;DR: 本研究探讨了专业抽象艺术家与自主绘画机器臂之间的共创互动，揭示了人机协作在艺术创作中的不同体验。


<details>
  <summary>Details</summary>
Motivation: 探讨机器人技术在艺术创作中的潜力，以及艺术家如何体验与机器人合作的创作过程。

Method: 通过与八位艺术家进行六次绘画会话并进行半结构化访谈，采用反思性主题分析法进行数据分析。

Result: 揭示艺术家在与机器人合作绘画时的独特体验，为人机协作提供了新的视角。

Conclusion: 长时间的参与和跨学科的方法能够推动人机协作的价值，强调艺术家与机器人之间的独特关系。

Abstract: As robotic technologies evolve, their potential in artistic creation becomes
an increasingly relevant topic of inquiry. This study explores how professional
abstract artists perceive and experience co-creative interactions with an
autonomous painting robotic arm. Eight artists engaged in six painting sessions
-- three with a human partner, followed by three with the robot -- and
subsequently participated in semi-structured interviews analyzed through
reflexive thematic analysis. Human-human interactions were described as
intuitive, dialogic, and emotionally engaging, whereas human-robot sessions
felt more playful and reflective, offering greater autonomy and prompting for
novel strategies to overcome the system's limitations. This work offers one of
the first empirical investigations into artists' lived experiences with a
robot, highlighting the value of long-term engagement and a multidisciplinary
approach to human-robot co-creation.

</details>


### [49] [AI for Abolition? A Participatory Design Approach](https://arxiv.org/abs/2510.07156)
*Carolyn Wang,Avriel Epps,Taylor Ferrari,Ra Ames*

Main category: cs.HC

TL;DR: 本文探讨了如何通过参与式设计，与转型和恢复性司法从业者合作，开发AI系统以促进社会正义。


<details>
  <summary>Details</summary>
Motivation: 面对监禁国家和压迫性技术带来的挑战，寻求通过AI支持被历史边缘化社区的工作。

Method: 通过与转型和恢复性司法从业者共同设计评估框架，参与式地开发AI系统。

Result: 研究的结果是设计出一个评估框架，促进AI的发展，拓展其对边缘群体的潜力。

Conclusion: 该研究提出了一种参与式设计方法，旨在利用人工智能支持转型和恢复性司法实践，挑战当前AI的排他性现状。

Abstract: The abolitionist community faces challenges from both the carceral state and
oppressive technologies which, by empowering the ruling class who have the
resources to develop artificial intelligence (AI), serve to entrench societal
inequities even more deeply. This paper presents a case study in participatory
design with transformative and restorative justice practitioners with the goal
of designing an AI system to support their work. By co-designing an evaluation
framework for large language models with the practitioners, we hope to push
back against the exclusionary status quo of AI and extent AI's potentiality to
a historically marginalized community.

</details>


### [50] [Exploring the Feasibility of Gaze-Based Navigation Across Path Types](https://arxiv.org/abs/2510.07184)
*Yichuan Zhang,Liangyuting Zhang,Xuning Hu,Yong Yue,Hai-Ning Liang*

Main category: cs.HC

TL;DR: 基于注视的导航在XR中尚未充分探讨，本文研究了不同路径类型对注视导航的适用性，通过用户研究提供了设计见解。


<details>
  <summary>Details</summary>
Motivation: 随着眼动追踪成为现代XR头戴设备的标准功能，明确不同路径类型对注视导航的影响，可以优化用户体验和交互设计。

Method: 通过控制的用户研究，评估了线性、缩窄和圆形三种路径类型的视线导航效果。

Result: 本论文探讨了基于注视的导航在扩展现实（XR）中的应用，分析了不同路径类型对注视导航性能的影响，并提出了设计指导。

Conclusion: 本研究提供了关于基于注视导航的性能特征的见解，强调了不同路径类型在XR中的应用潜力，以及为未来的设计提供指导。

Abstract: Gaze input, as a modality inherently conveying user intent, offers intuitive
and immersive experiences in extended reality (XR). With eye-tracking now being
a standard feature in modern XR headsets, gaze has been extensively applied to
tasks such as selection, text entry, and object manipulation. However, gaze
based navigation despite being a fundamental interaction task remains largely
underexplored. In particular, little is known about which path types are well
suited for gaze navigation and under what conditions it performs effectively.
To bridge this gap, we conducted a controlled user study evaluating gaze-based
navigation across three representative path types: linear, narrowing, and
circular. Our findings reveal distinct performance characteristics and
parameter ranges for each path type, offering design insights and practical
guidelines for future gaze-driven navigation systems in XR.

</details>


### [51] [Regulating Social Media: Surveying the Impact of Nepali Government's TikTok Ban](https://arxiv.org/abs/2510.07200)
*Prerana Khatiwada,Alejandro Ciuba,Aditya Nayak,Aakash Gautam,Matthew Louis Mauriello*

Main category: cs.HC

TL;DR: 本研究探讨了尼泊尔社交媒体平台TikTok的禁令及其影响，发现用户对禁令持怀疑态度，强调应作出更灵活的治理回应。


<details>
  <summary>Details</summary>
Motivation: 在资源有限的背景下，了解数字技术、政策反应与文化动态间的互动，以改善治理和社会规范。

Method: 通过在线调查（N=108）探讨用户在禁令后对在线空间的价值观、经验和应对策略。

Result: 研究表明用户对禁止平台持怀疑态度，但往往被动接受禁令，强调了制度化集体治理模型的重要性。

Conclusion: 研究结果表明，用户对平台禁令持怀疑态度，但通常会被动接受这些禁令而不采取积极反对的行动。

Abstract: Social media platforms have transformed global communication and interaction,
with TikTok emerging as a critical tool for education, connection, and social
impact, including in contexts where infrastructural resources are limited. Amid
growing political discussions about banning platforms like TikTok, such actions
can create significant ripple effects, particularly impacting marginalized
communities. We present a study on Nepal, where a TikTok ban was recently
imposed and lifted. As a low-resource country in transition where digital
communication is rapidly evolving, TikTok enables a space for community
engagement and cultural expression. In this context, we conducted an online
survey (N=108) to explore user values, experiences, and strategies for
navigating online spaces post-ban. By examining these transitions, we aim to
improve our understanding of how digital technologies, policy responses, and
cultural dynamics interact globally and their implications for governance and
societal norms. Our results indicate that users express skepticism toward
platform bans but often passively accept them without active opposition.
Findings suggest the importance of institutionalizing collective governance
models that encourage public deliberation, nuanced control, and socially
resonant policy decisions.

</details>
