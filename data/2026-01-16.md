<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 13]
- [cs.HC](#cs.HC) [Total: 16]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Formal Safety Guarantees for Autonomous Vehicles using Barrier Certificates](https://arxiv.org/abs/2601.09740)
*Oumaima Barhoumi,Mohamed H Zaki,Sofiène Tahar*

Main category: cs.RO

TL;DR: 本文开发了一种正式验证的安全框架，为联网与自动驾驶车辆提供可解释且可靠的安全保障，显著减少不安全交互。


<details>
  <summary>Details</summary>
Motivation: 现代AI技术使自动驾驶车辆能够感知复杂场景，预测人类行为，并做出实时驾驶决策，但这些数据驱动的组件通常缺乏可解释性和严格的安全保证，这在动态混合交通环境中与人驾驶车辆的交互引入了不确定性和安全挑战。

Method: 一种正式验证的安全框架，结合了障碍证书（BCs）和可解释的交通冲突指标，特别是作为时空安全指标的碰撞时间（TTC）。利用可满足性模理论（SMT）求解器验证安全条件，并采用自适应控制机制确保车辆实时遵循这些约束。

Result: 在真实的高速公路数据集上的评估显示，unsafe interactions显著减少，TTC低于3秒的事件减少了多达40%，并且在某些车道完全消除了冲突。

Conclusion: 该方法提供了可解释和可证明的安全保障，为安全自主驾驶提供了切实可行的可扩展策略。

Abstract: Modern AI technologies enable autonomous vehicles to perceive complex scenes, predict human behavior, and make real-time driving decisions. However, these data-driven components often operate as black boxes, lacking interpretability and rigorous safety guarantees. Autonomous vehicles operate in dynamic, mixed-traffic environments where interactions with human-driven vehicles introduce uncertainty and safety challenges. This work develops a formally verified safety framework for Connected and Autonomous Vehicles (CAVs) that integrates Barrier Certificates (BCs) with interpretable traffic conflict metrics, specifically Time-to-Collision (TTC) as a spatio-temporal safety metric. Safety conditions are verified using Satisfiability Modulo Theories (SMT) solvers, and an adaptive control mechanism ensures vehicles comply with these constraints in real time. Evaluation on real-world highway datasets shows a significant reduction in unsafe interactions, with up to 40\% fewer events where TTC falls below a 3 seconds threshold, and complete elimination of conflicts in some lanes. This approach provides both interpretable and provable safety guarantees, demonstrating a practical and scalable strategy for safe autonomous driving.

</details>


### [2] [Interprofessional and Agile Development of Mobirobot: A Socially Assistive Robot for Pediatric Therapy Across Clinical and Therapeutic Settings](https://arxiv.org/abs/2601.09838)
*Leonie Dyck,Aiko Galetzka,Maximilian Noller,Anna-Lena Rinke,Jutta Bormann,Jekaterina Miller,Michelle Hochbaum,Julia Siemann,Jördis Alboth,Andre Berwinkel,Johanna Luz,Britta Kley-Zobel,Marcine Cyrys,Nora Flöttmann,Ariane Vogeler,Mariia Melnikova,Ira-Katharina Petras,Michael Siniatchkin,Winfried Barthlen,Anna-Lisa Vollmer*

Main category: cs.RO

TL;DR: 本研究介绍了Mobirobot，一个旨在支持儿童康复的社交辅助机器人，采取人本开发方法，从设计到实施涉及多个利益相关方，初步成果显示其在现实环境中的可行性。


<details>
  <summary>Details</summary>
Motivation: 提高儿童在治疗后恢复过程中对身体活动的参与度，特别是针对创伤、骨折或抑郁障碍的个性化锻炼方案。

Method: 采用敏捷的人本开发方法，涉及多学科团队和最终用户的共同开发过程。

Result: Mobirobot在医院环境中的部署帮助识别了关键设计要求和可用性约束，并通过利益相关者反馈改进了系统设计。

Conclusion: Mobirobot展示了多专业团队主导的发展方法在动态住院环境中的应用潜力，虽然存在一些挑战，但其为进一步研究和临床应用奠定了良好的基础。

Abstract: Introduction: Socially assistive robots hold promise for enhancing therapeutic engagement in paediatric clinical settings. However, their successful implementation requires not only technical robustness but also context-sensitive, co-designed solutions. This paper presents Mobirobot, a socially assistive robot developed to support mobilisation in children recovering from trauma, fractures, or depressive disorders through personalised exercise programmes.
  Methods: An agile, human-centred development approach guided the iterative design of Mobirobot. Multidisciplinary clinical teams and end users were involved throughout the co-development process, which focused on early integration into real-world paediatric surgical and psychiatric settings. The robot, based on the NAO platform, features a simple setup, adaptable exercise routines with interactive guidance, motivational dialogue, and a graphical user interface (GUI) for monitoring and no-code system feedback.
  Results: Deployment in hospital environments enabled the identification of key design requirements and usability constraints. Stakeholder feedback led to refinements in interaction design, movement capabilities, and technical configuration. A feasibility study is currently underway to assess acceptance, usability, and perceived therapeutic benefit, with data collection including questionnaires, behavioural observations, and staff-patient interviews.
  Discussion: Mobirobot demonstrates how multiprofessional, stakeholder-led development can yield a socially assistive system suited for dynamic inpatient settings. Early-stage findings underscore the importance of contextual integration, robustness, and minimal-intrusion design. While challenges such as sensor limitations and patient recruitment remain, the platform offers a promising foundation for further research and clinical application.

</details>


### [3] [How Human Motion Prediction Quality Shapes Social Robot Navigation Performance in Constrained Spaces](https://arxiv.org/abs/2601.09856)
*Andrew Stratton,Phani Teja Singamaneni,Pranav Goyal,Rachid Alami,Christoforos Mavrogiannis*

Main category: cs.RO

TL;DR: 本研究探讨了人类运动预测对机器人导航性能的影响，发现传统预测方法在特定环境下效果不佳，并揭示了机器人与人类互动中的效率和舒适度权衡。


<details>
  <summary>Details</summary>
Motivation: 将移动机器人更好地整合到仓库、医院、制造工厂和家庭中，以确保人类安全、舒适和效率

Method: 针对动态和空间受限环境中的机器人导航进行系统性研究

Result: 研究发现，平均位移误差并非机器人导航性能和人类印象的可靠预测指标；在人类合作的假设在受限环境中失效，且更高效的机器人导航往往以人类效率和舒适为代价。

Conclusion: 人类运动预测质量对机器人导航性能至关重要，需要关注人类效率和舒适度的平衡。

Abstract: Motivated by the vision of integrating mobile robots closer to humans in warehouses, hospitals, manufacturing plants, and the home, we focus on robot navigation in dynamic and spatially constrained environments. Ensuring human safety, comfort, and efficiency in such settings requires that robots are endowed with a model of how humans move around them. Human motion prediction around robots is especially challenging due to the stochasticity of human behavior, differences in user preferences, and data scarcity. In this work, we perform a methodical investigation of the effects of human motion prediction quality on robot navigation performance, as well as human productivity and impressions. We design a scenario involving robot navigation among two human subjects in a constrained workspace and instantiate it in a user study ($N=80$) involving two different robot platforms, conducted across two sites from different world regions. Key findings include evidence that: 1) the widely adopted average displacement error is not a reliable predictor of robot navigation performance and human impressions; 2) the common assumption of human cooperation breaks down in constrained environments, with users often not reciprocating robot cooperation, and causing performance degradations; 3) more efficient robot navigation often comes at the expense of human efficiency and comfort.

</details>


### [4] [SyncTwin: Fast Digital Twin Construction and Synchronization for Safe Robotic Grasping](https://arxiv.org/abs/2601.09920)
*Ruopeng Huang,Boyu Yang,Wenlong Gui,Jeremy Morgan,Erdem Biyik,Jiachen Li*

Main category: cs.RO

TL;DR: SyncTwin 是一个数字双胞胎框架，通过快速的 3D 场景重构与真实-模拟同步，在动态和视觉遮挡条件下实现了安全可靠的抓取。


<details>
  <summary>Details</summary>
Motivation: 在动态和视觉遮挡条件下进行准确和安全的抓取是现实世界机器人操作中的核心挑战。

Method: 使用 VGGT 从 RGB 图像快速重构对象级 3D 资产，构建可重复使用的几何库；通过点云分割更新跟踪真实世界对象状态，并通过彩色 ICP 注册对齐。

Result: 实验表明 SyncTwin 在动态和遮挡场景下提高了抓取精度和运动安全性，让机器人可以安全执行规划的轨迹。

Conclusion: SyncTwin 提高了在动态和遮挡场景下的抓取准确性和运动安全性，验证了数字双胞胎同步在现实世界机器人执行中的有效性。

Abstract: Accurate and safe grasping under dynamic and visually occluded conditions remains a core challenge in real-world robotic manipulation. We present SyncTwin, a digital twin framework that unifies fast 3D scene reconstruction and real-to-sim synchronization for robust and safety-aware grasping in such environments. In the offline stage, we employ VGGT to rapidly reconstruct object-level 3D assets from RGB images, forming a reusable geometry library for simulation. During execution, SyncTwin continuously synchronizes the digital twin by tracking real-world object states via point cloud segmentation updates and aligning them through colored-ICP registration. The updated twin enables motion planners to compute collision-free and dynamically feasible trajectories in simulation, which are safely executed on the real robot through a closed real-to-sim-to-real loop. Experiments in dynamic and occluded scenes show that SyncTwin improves grasp accuracy and motion safety, demonstrating the effectiveness of digital-twin synchronization for real-world robotic execution.

</details>


### [5] [In-the-Wild Compliant Manipulation with UMI-FT](https://arxiv.org/abs/2601.09988)
*Hojung Choi,Yifan Hou,Chuer Pan,Seongheon Hong,Austin Patel,Xiaomeng Xu,Mark R. Cutkosky,Shuran Song*

Main category: cs.RO

TL;DR: UMI-FT 是一种便携式数据采集平台，通过在手指上安装六轴力/扭矩传感器，收集多模态数据以训练自适应合规策略，从而在力敏感任务中表现出色并开源以促进应用。


<details>
  <summary>Details</summary>
Motivation: 现有商业力/扭矩传感器成本高、体积大且易损，限制了大规模的力感知策略学习，因此需要一种新的解决方案。

Method: 开发了一种手持数据采集平台 UMI-FT，在每个手指上安装紧凑的六轴力/扭矩传感器，收集多模态数据以训练自适应合规策略。

Result: 在三个接触丰富、对力敏感的任务中（擦白板、刺入西葫芦和灯泡插入），UMI-FT 的策略能够可靠地调节外部接触力和内部抓持力，超越仅依赖合规或力感知的基线对比。

Conclusion: UMI-FT 提供了一种可扩展的方法，通过自然环境中的演示学习响应的操控策略，同时开源硬件和软件以促进更广泛的采用。

Abstract: Many manipulation tasks require careful force modulation. With insufficient force the task may fail, while excessive force could cause damage. The high cost, bulky size and fragility of commercial force/torque (F/T) sensors have limited large-scale, force-aware policy learning. We introduce UMI-FT, a handheld data-collection platform that mounts compact, six-axis force/torque sensors on each finger, enabling finger-level wrench measurements alongside RGB, depth, and pose. Using the multimodal data collected from this device, we train an adaptive compliance policy that predicts position targets, grasp force, and stiffness for execution on standard compliance controllers. In evaluations on three contact-rich, force-sensitive tasks (whiteboard wiping, skewering zucchini, and lightbulb insertion), UMI-FT enables policies that reliably regulate external contact forces and internal grasp forces, outperforming baselines that lack compliance or force sensing. UMI-FT offers a scalable path to learning compliant manipulation from in-the-wild demonstrations. We open-source the hardware and software to facilitate broader adoption at:https://umi-ft.github.io/.

</details>


### [6] [CoCoPlan: Adaptive Coordination and Communication for Multi-robot Systems in Dynamic and Unknown Environments](https://arxiv.org/abs/2601.10116)
*Xintong Zhang,Junfeng Chen,Yuxiao Zhu,Bing Luo,Meng Guo*

Main category: cs.RO

TL;DR: CoCoPlan 是一个优化多机器人任务和通信的框架，显著提高了任务完成率并降低了通信负担。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在动态任务分配和有限通信条件下有效协调的不足之处。

Method: 采用分支限界架构编码任务分配和通信事件，结合自适应目标函数和通信事件优化模块。

Result: CoCoPlan 提出了一个统一的框架，能够在多机器人系统中有效协调任务和有限的通信，从而提高任务完成率和降低通信开销。

Conclusion: CoCoPlan 在动态环境中有效支持多达100个机器人，性能优于现有方法，展示了更高的任务完成率和更低的通信开销。

Abstract: Multi-robot systems can greatly enhance efficiency through coordination and collaboration, yet in practice, full-time communication is rarely available and interactions are constrained to close-range exchanges. Existing methods either maintain all-time connectivity, rely on fixed schedules, or adopt pairwise protocols, but none adapt effectively to dynamic spatio-temporal task distributions under limited communication, resulting in suboptimal coordination. To address this gap, we propose CoCoPlan, a unified framework that co-optimizes collaborative task planning and team-wise intermittent communication. Our approach integrates a branch-and-bound architecture that jointly encodes task assignments and communication events, an adaptive objective function that balances task efficiency against communication latency, and a communication event optimization module that strategically determines when, where and how the global connectivity should be re-established. Extensive experiments demonstrate that it outperforms state-of-the-art methods by achieving a 22.4% higher task completion rate, reducing communication overhead by 58.6%, and improving the scalability by supporting up to 100 robots in dynamic environments. Hardware experiments include the complex 2D office environment and large-scale 3D disaster-response scenario.

</details>


### [7] [Terrain-Adaptive Mobile 3D Printing with Hierarchical Control](https://arxiv.org/abs/2601.10208)
*Shuangshan Nors Li,J. Nathan Kutz*

Main category: cs.RO

TL;DR: 本研究提出了一种集成AI驱动的干扰预测与多模态传感器融合的闭环系统，以解决移动3D打印在不规则地形上的精度与机动性问题。


<details>
  <summary>Details</summary>
Motivation: 解决传统gantry系统精度高但缺乏机动性与移动平台在不平坦地面上打印质量不佳之间的矛盾。

Method: 采用AI模块与IMU、视觉及深度传感器融合，构建三层控制架构，进行路径规划、预测协调及硬件执行。

Result: 户外实验表明，系统在存在坡度和表面不规则性的地形上实现了打印精度达到亚厘米。

Conclusion: 该研究展示了在不平坦地形上实现亚厘米打印精度，同时保持平台的完全机动性，为不规则环境中的自主施工奠定了实际基础。

Abstract: Mobile 3D printing on unstructured terrain remains challenging due to the conflict between platform mobility and deposition precision. Existing gantry-based systems achieve high accuracy but lack mobility, while mobile platforms struggle to maintain print quality on uneven ground. We present a framework that tightly integrates AI-driven disturbance prediction with multi-modal sensor fusion and hierarchical hardware control, forming a closed-loop perception-learning-actuation system. The AI module learns terrain-to-perturbation mappings from IMU, vision, and depth sensors, enabling proactive compensation rather than reactive correction. This intelligence is embedded into a three-layer control architecture: path planning, predictive chassis-manipulator coordination, and precision hardware execution. Through outdoor experiments on terrain with slopes and surface irregularities, we demonstrate sub-centimeter printing accuracy while maintaining full platform mobility. This AI-hardware integration establishes a practical foundation for autonomous construction in unstructured environments.

</details>


### [8] [A Unified Framework for Kinematic Simulation of Rigid Foldable Structures](https://arxiv.org/abs/2601.10225)
*Dongwook Kwak,Geonhee Cho,Jiook Chung,Jinkyu Yang*

Main category: cs.RO

TL;DR: 本文提供了一种自动化工具，简化了刚性折叠结构的约束矩阵生成过程。


<details>
  <summary>Details</summary>
Motivation: 需要统一的运动学分析方法来处理各种折纸启发的结构，尤其是刚性折叠结构的环路约束。

Method: 该方法利用最小扩展数据结构构建面-铰接图，提取最小循环基础以捕获所有约束，并通过螺旋理论组装速度级约束矩阵。

Result: 提出了一种自动化方法，生成任意刚性折叠结构的Pfaffian约束矩阵。

Conclusion: 该框架能够有效计算和可视化刚性折叠结构的展开和折叠运动，避免了繁琐的约束计算。

Abstract: Origami-inspired structures with rigid panels now span thick, kirigami, and multi-sheet realizations, making unified kinematic analysis essential. Yet a general method that consolidates their loop constraints has been lacking. We present an automated approach that generates the Pfaffian constraint matrix for arbitrary rigid foldable structures (RFS). From a minimally extended data schema, the tool constructs the facet-hinge graph, extracts a minimum cycle basis that captures all constraints, and assembles a velocity-level constraint matrix via screw theory that encodes coupled rotation and translation loop closure. The framework computes and visualizes deploy and fold motions across diverse RFS while eliminating tedious and error-prone constraint calculations.

</details>


### [9] [Proactive Local-Minima-Free Robot Navigation: Blending Motion Prediction with Safe Control](https://arxiv.org/abs/2601.10233)
*Yifan Xue,Ze Zhang,Knut Åkesson,Nadia Figueroa*

Main category: cs.RO

TL;DR: 本研究提出了一个新的框架，通过在线学习障碍函数和自动参数调节算法，提高移动机器人在动态环境中的导航安全性和效率。


<details>
  <summary>Details</summary>
Motivation: 移动机器人在复杂动态环境中安全高效导航的挑战

Method: 使用神经网络进行能量基础学习，在线生成障碍物的多模态运动预测，并利用调制控制屏障函数构建安全高效的导航策略。

Result: 提出了一种基于高斯过程的在线学习障碍函数的方法，以及自主参数调节算法，以适应变形的预测基障碍函数，显著提升了安全性和效率。

Conclusion: 该框架在仿真和实际实验中表现优异，超越了现有基准，证明了其在复杂动态环境中的可靠性。

Abstract: This work addresses the challenge of safe and efficient mobile robot navigation in complex dynamic environments with concave moving obstacles. Reactive safe controllers like Control Barrier Functions (CBFs) design obstacle avoidance strategies based only on the current states of the obstacles, risking future collisions. To alleviate this problem, we use Gaussian processes to learn barrier functions online from multimodal motion predictions of obstacles generated by neural networks trained with energy-based learning. The learned barrier functions are then fed into quadratic programs using modulated CBFs (MCBFs), a local-minimum-free version of CBFs, to achieve safe and efficient navigation. The proposed framework makes two key contributions. First, it develops a prediction-to-barrier function online learning pipeline. Second, it introduces an autonomous parameter tuning algorithm that adapts MCBFs to deforming, prediction-based barrier functions. The framework is evaluated in both simulations and real-world experiments, consistently outperforming baselines and demonstrating superior safety and efficiency in crowded dynamic environments.

</details>


### [10] [The impact of tactile sensor configurations on grasp learning efficiency -- a comparative evaluation in simulation](https://arxiv.org/abs/2601.10268)
*Eszter Birtalan,Miklós Koller*

Main category: cs.RO

TL;DR: 研究触觉传感器配置对机器人手部设计的影响，发现最佳配置可提升性能。


<details>
  <summary>Details</summary>
Motivation: 研究触觉传感器在机器人领域的应用，特别是对机械手设计和假肢的影响，以提高抓握稳定性。

Method: 使用模拟评估不同的触觉传感器配置，分析其对强化学习的影响。

Result: 通过模拟评估了6种不同的触觉传感器配置，发现一个配置在两个不同的设置中表现最佳。

Conclusion: 这些结果能够为未来的机器人手设计研究提供指导，包括假肢。

Abstract: Tactile sensors are breaking into the field of robotics to provide direct information related to contact surfaces, including contact events, slip events and even texture identification. These events are especially important for robotic hand designs, including prosthetics, as they can greatly improve grasp stability. Most presently published robotic hand designs, however, implement them in vastly different densities and layouts on the hand surface, often reserving the majority of the available space. We used simulations to evaluate 6 different tactile sensor configurations with different densities and layouts, based on their impact on reinforcement learning. Our two-setup system allows for robust results that are not dependent on the use of a given physics simulator, robotic hand model or machine learning algorithm. Our results show setup-specific, as well as generalized effects across the 6 sensorized simulations, and we identify one configuration as consistently yielding the best performance across both setups. These results could help future research aimed at robotic hand designs, including prostheses.

</details>


### [11] [CHORAL: Traversal-Aware Planning for Safe and Efficient Heterogeneous Multi-Robot Routing](https://arxiv.org/abs/2601.10340)
*David Morilla-Cabello,Eduardo Montijano*

Main category: cs.RO

TL;DR: 本研究提出了一种集成的语义感知框架用于协调异构机器人，提升环境监测的导航效果，实验结果证明了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 在复杂的环境中，采用异构机器人团队进行监测可以显著提升任务性能和可行性；目前的方法多假设机器人团队具同质性，限制了环境适应能力和各自优势的利用。

Method: 通过构建度量-语义地图，并采用开放词汇视觉模型，识别检查区域及各平台的路径，整合进异构车辆路由 formulatio，实现任务分配和路径计算。

Result: 提出了一种集成的语义感知框架CHORAL，用于协调异构机器人，能够有效识别需要细致检查的区域，并计算出适合各个机器人平台的能力-aware路径。

Conclusion: 通过显式考虑每个平台的导航能力，我们的方法在规划更安全、更高效的路线方面展现了良好的效果，框架CHORAL也已开源以支持不同机器人团队的重现性和部署。

Abstract: Monitoring large, unknown, and complex environments with autonomous robots poses significant navigation challenges, where deploying teams of heterogeneous robots with complementary capabilities can substantially improve both mission performance and feasibility. However, effectively modeling how different robotic platforms interact with the environment requires rich, semantic scene understanding. Despite this, existing approaches often assume homogeneous robot teams or focus on discrete task compatibility rather than continuous routing. Consequently, scene understanding is not fully integrated into routing decisions, limiting their ability to adapt to the environment and to leverage each robot's strengths. In this paper, we propose an integrated semantic-aware framework for coordinating heterogeneous robots. Starting from a reconnaissance flight, we build a metric-semantic map using open-vocabulary vision models and use it to identify regions requiring closer inspection and capability-aware paths for each platform to reach them. These are then incorporated into a heterogeneous vehicle routing formulation that jointly assigns inspection tasks and computes robot trajectories. Experiments in simulation and in a real inspection mission with three robotic platforms demonstrate the effectiveness of our approach in planning safer and more efficient routes by explicitly accounting for each platform's navigation capabilities. We release our framework, CHORAL, as open source to support reproducibility and deployment of diverse robot teams.

</details>


### [12] [FastStair: Learning to Run Up Stairs with Humanoid Robots](https://arxiv.org/abs/2601.10365)
*Yan Liu,Tao Yu,Haolin Song,Hongbo Zhu,Nianzong Hu,Yuzhi Hao,Xiuyong Yao,Xizhe Zang,Hua Chen,Jie Zhao*

Main category: cs.RO

TL;DR: 提出一种名为FastStair的多阶段学习框架，通过结合模型导向的足迹规划和无模型强化学习，成功实现快速稳定的楼梯攀爬。


<details>
  <summary>Details</summary>
Motivation: 解决人形机器人登楼梯时面临的高灵活性与稳定性要求的挑战，克服现有方法的不足。

Method: 结合模型导向的足迹规划器与强化学习训练环，偏向于动态可行接触并预训练安全政策。通过专注于速度的专家细化基础政策，并使用低秩适应技术实现不同速度范围的平滑操作。

Result: 在命令速度高达1.65 m/s的情况下，Oli人形机器人成功穿越33步螺旋楼梯，完成时间为12秒。

Conclusion: FastStair成功地在Oli人形机器人上实现了稳定的楼梯攀爬，展示了快速而可靠的性能。

Abstract: Running up stairs is effortless for humans but remains extremely challenging for humanoid robots due to the simultaneous requirements of high agility and strict stability. Model-free reinforcement learning (RL) can generate dynamic locomotion, yet implicit stability rewards and heavy reliance on task-specific reward shaping tend to result in unsafe behaviors, especially on stairs; conversely, model-based foothold planners encode contact feasibility and stability structure, but enforcing their hard constraints often induces conservative motion that limits speed. We present FastStair, a planner-guided, multi-stage learning framework that reconciles these complementary strengths to achieve fast and stable stair ascent. FastStair integrates a parallel model-based foothold planner into the RL training loop to bias exploration toward dynamically feasible contacts and to pretrain a safety-focused base policy. To mitigate planner-induced conservatism and the discrepancy between low- and high-speed action distributions, the base policy was fine-tuned into speed-specialized experts and then integrated via Low-Rank Adaptation (LoRA) to enable smooth operation across the full commanded-speed range. We deploy the resulting controller on the Oli humanoid robot, achieving stable stair ascent at commanded speeds up to 1.65 m/s and traversing a 33-step spiral staircase (17 cm rise per step) in 12 s, demonstrating robust high-speed performance on long staircases. Notably, the proposed approach served as the champion solution in the Canton Tower Robot Run Up Competition.

</details>


### [13] [Online identification of nonlinear time-varying systems with uncertain information](https://arxiv.org/abs/2601.10379)
*He Ren,Gaowei Yan,Hang Liu,Lifeng Cao,Zhijun Zhao,Gang Dang*

Main category: cs.RO

TL;DR: 本文提出了一种名为BRSL的新框架，通过贝叶斯回归实现高预测精度和在线适应的符号学习，克服了现有算法的局限性，展现了良好的性能。


<details>
  <summary>Details</summary>
Motivation: 由于现有技术无法同时满足高预测精度、强可解释性和在线适应能力的需求，提出一种新方法以解决这一问题。

Method: 提出一种基于贝叶斯回归的符号学习框架(BRSL)，将在线符号发现表述为统一的概率状态空间模型。

Result: 提出的BRSL框架实现了系统识别和不确定性量化的同时进行，增强了算法的鲁棒性，并在案例研究中验证了其有效性。

Conclusion: 研究表明，BRSL框架在真实应用中具备可解释性、有效的概率预测和在线学习能力。

Abstract: Digital twins (DTs), serving as the core enablers for real-time monitoring and predictive maintenance of complex cyber-physical systems, impose critical requirements on their virtual models: high predictive accuracy, strong interpretability, and online adaptive capability. However, existing techniques struggle to meet these demands simultaneously: Bayesian methods excel in uncertainty quantification but lack model interpretability, while interpretable symbolic identification methods (e.g., SINDy) are constrained by their offline, batch-processing nature, which make real-time updates challenging. To bridge this semantic and computational gap, this paper proposes a novel Bayesian Regression-based Symbolic Learning (BRSL) framework. The framework formulates online symbolic discovery as a unified probabilistic state-space model. By incorporating sparse horseshoe priors, model selection is transformed into a Bayesian inference task, enabling simultaneous system identification and uncertainty quantification. Furthermore, we derive an online recursive algorithm with a forgetting factor and establish precise recursive conditions that guarantee the well-posedness of the posterior distribution. These conditions also function as real-time monitors for data utility, enhancing algorithmic robustness. Additionally, a rigorous convergence analysis is provided, demonstrating the convergence of parameter estimates under persistent excitation conditions. Case studies validate the effectiveness of the proposed framework in achieving interpretable, probabilistic prediction and online learning.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [14] [Who Owns My AI Twin? Data Ownership in a New World of Simulated Identities](https://arxiv.org/abs/2601.09877)
*Paulius Jurcys,Ashley Greenwald,Mark Fenwick,Valto Loikkanen,Sebastian Porsdam Mann,Brian D. Earp*

Main category: cs.HC

TL;DR: 本文论证自然人应被视为其人工智能双胞胎的道德和法律所有者，并提出了以人为本的数据治理模型。


<details>
  <summary>Details</summary>
Motivation: 探讨数字复制体对个体数据主权和个人自主性提出的挑战，强调在人工智能中保护个人身份的必要性。

Method: 采用法律与伦理的批判分析，审视现行法律框架对个人数据控制权的局限性，并提出新的以人为中心的数据治理模型。

Result: 本论文探讨了人工智能双胞胎的出现对数据治理和个人身份所带来的法律和道德新挑战。

Conclusion: 文章呼吁重构社会契约，以加强个人能力，促进公平的数据管理，更好地将法律规范与人工智能双胞胎的社会技术现实对接。

Abstract: The emergence of AI twins, digital replicas that encapsulate an individual's knowledge, memories, psychological traits, and behavioral patterns, raises novel legal and ethical challenges for data governance and personal identity. Built from personal data, these systems require a rethinking of what it means to exercise dominion over one's data and to maintain personal autonomy in an AI-mediated environment. This article argues that natural persons should be recognized as the moral and legal owners of their AI twins, which function as intimate extensions of the self rather than as proprietary technological artifacts. It critiques prevailing legal frameworks that prioritize technological infrastructure and platform control over data and individual autonomy, exposing their structural limitations. In response, the article advances a human-centric model of data governance grounded in individual dominion and a private-by-default principle. This approach proposes a reimagined social contract for AI-driven identities that strengthens personal agency, promotes equitable data stewardship, and better aligns legal norms with the socio-technical realities of AI twins.

</details>


### [15] [LAMDA: Aiding Visual Exploration of Atomic Displacements in Molecular Dynamics Simulations](https://arxiv.org/abs/2601.09887)
*Rostyslav Hnatyshyn,Danny Perez,Gerik Scheuermann,Ross Maciejewski,Baldwin Nsonga*

Main category: cs.HC

TL;DR: 本文介绍了一种名为LAMDA的可视化分析系统，帮助材料科学家快速系统地探索原子状态之间的转变，解决了现有分析方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 在材料科学研究中，随着计算模拟技术的发展，数据量急剧增加，如何有效分析原子位移模式以理解材料的物理属性演化变得极具挑战性。

Method: LAMDA系统通过层次结构来分类转变，允许科学家根据局部原子环境的特征进行可视化，支持注释捕获用户输入。

Result: 提出了LAMDA，一个可视化分析系统，可以系统化地探索状态之间的转变，从而简化这种分析过程。

Conclusion: LAMDA系统通过层级分类转变，支持不同分辨率的模拟分析，并简化了用户输入，最终实现了有效的模拟数据探索。

Abstract: Contemporary materials science research is heavily conducted in silico, involving massive simulations of the atomic-scale evolution of materials. Cataloging basic patterns in the atomic displacements is key to understanding and predicting the evolution of physical properties. However, the combinatorial complexity of the space of possible transitions coupled with the overwhelming amount of data being produced by high-throughput simulations make such an analysis extremely challenging and time-consuming for domain experts. The development of visual analytics systems that facilitate the exploration of simulation data is an active field of research. While these systems excel in identifying temporal regions of interest, they treat each timestep of a simulation as an independent event without considering the behavior of the atomic displacements between timesteps. We address this gap by introducing LAMDA, a visual analytics system that allows domain experts to quickly and systematically explore state-to-state transitions. In LAMDA, transitions are hierarchically categorized, providing a basis for cataloging displacement behavior, as well as enabling the analysis of simulations at different resolutions, ranging from very broad qualitative classes of transitions to very narrow definitions of unit processes. LAMDA supports navigating the hierarchy of transitions, enabling scientists to visualize the commonalities between different transitions in each class in terms of invariant features characterizing local atomic environments, and LAMDA simplifies the analysis by capturing user inputs through annotations. We evaluate our system through a case study and report on findings from our domain experts.

</details>


### [16] [The Algorithmic Gaze: An Audit and Ethnography of the LAION-Aesthetics Predictor Model](https://arxiv.org/abs/2601.09896)
*Jordan Taylor,William Agnew,Maarten Sap,Sarah E. Fox,Haiyi Zhu*

Main category: cs.HC

TL;DR: 本研究分析了LAION Aesthetic Predictor在审美筛选中的偏见，呼吁向多元化的审美评估转变。


<details>
  <summary>Details</summary>
Motivation: 研究视觉生成AI模型的美学评估，探索其中涉及的个人品味和文化价值观，理解谁的品味在生成模型中得到了体现。

Method: 审计LAION Aesthetic Predictor模型，通过对三个数据集的分析及对开发资料的数字人类学研究，识别其存在的偏见。

Result: 发现LAION Aesthetic Predictor在筛选数据集时存在性别和文化偏见，强化了西方艺术历史中的帝国主义和男性视角。

Conclusion: 美学评估可能加剧代表性伤害，建议AI开发者采用更具包容性的评估方法。

Abstract: Visual generative AI models are trained using a one-size-fits-all measure of aesthetic appeal. However, what is deemed "aesthetic" is inextricably linked to personal taste and cultural values, raising the question of whose taste is represented in visual generative AI models. In this work, we study an aesthetic evaluation model--LAION Aesthetic Predictor (LAP)--that is widely used to curate datasets to train visual generative image models, like Stable Diffusion, and evaluate the quality of AI-generated images. To understand what LAP measures, we audited the model across three datasets. First, we examined the impact of aesthetic filtering on the LAION-Aesthetics Dataset (approximately 1.2B images), which was curated from LAION-5B using LAP. We find that the LAP disproportionally filters in images with captions mentioning women, while filtering out images with captions mentioning men or LGBTQ+ people. Then, we used LAP to score approximately 330k images across two art datasets, finding the model rates realistic images of landscapes, cityscapes, and portraits from western and Japanese artists most highly. In doing so, the algorithmic gaze of this aesthetic evaluation model reinforces the imperial and male gazes found within western art history. In order to understand where these biases may have originated, we performed a digital ethnography of public materials related to the creation of LAP. We find that the development of LAP reflects the biases we found in our audits, such as the aesthetic scores used to train LAP primarily coming from English-speaking photographers and western AI-enthusiasts. In response, we discuss how aesthetic evaluation can perpetuate representational harms and call on AI developers to shift away from prescriptive measures of "aesthetics" toward more pluralistic evaluation.

</details>


### [17] [Cooking Up Politeness in Human-AI Information Seeking Dialogue](https://arxiv.org/abs/2601.09898)
*David Elsweiler,Christine Elsweiler,Anna Ziegner*

Main category: cs.HC

TL;DR: 本研究探讨了用户礼貌行为如何影响人机对话结果，特别是在烹饪助手场景中。通过对30个对话进行标注，并模拟18000个对话，研究发现礼貌行为对响应长度、信息获取和效率都有显著影响。


<details>
  <summary>Details</summary>
Motivation: 探讨人机对话中礼貌行为对信息获取效果的影响，填补现有研究的空白。

Method: 对30个用户对话进行标注，识别出四种用户群体，并模拟18000个对话以研究不同礼貌表现的影响。

Result: 礼貌行为系统性地影响对话的响应长度和信息量；不礼貌输入导致的回答冗长但低效，且有显著的能量成本。

Conclusion: 礼貌不仅影响对话的公平性，还存在能源成本问题，因此需关注信息代理的包容性和资源意识设计。

Abstract: Politeness is a core dimension of human communication, yet its role in human-AI information seeking remains underexplored. We investigate how user politeness behaviour shapes conversational outcomes in a cooking-assistance setting. First, we annotated 30 dialogues, identifying four distinct user clusters ranging from Hyperpolite to Hyperefficient. We then scaled up to 18,000 simulated conversations across five politeness profiles (including impolite) and three open-weight models. Results show that politeness is not only cosmetic: it systematically affects response length, informational gain, and efficiency. Engagement-seeking prompts produced up to 90% longer replies and 38% more information nuggets than hyper-efficient prompts, but at markedly lower density. Impolite inputs yielded verbose but less efficient answers, with up to 48% fewer nuggets per watt-hour compared to polite input. These findings highlight politeness as both a fairness and sustainability issue: conversational styles can advantage or disadvantage users, and "polite" requests may carry hidden energy costs. We discuss implications for inclusive and resource-aware design of information agents.

</details>


### [18] [In-Browser Agents for Search Assistance](https://arxiv.org/abs/2601.09928)
*Saber Zerhoudi,Michael Granitzer*

Main category: cs.HC

TL;DR: 本文提出一种浏览器扩展，利用客户端的混合架构提供隐私保护的AI搜索辅助，效果显著。


<details>
  <summary>Details</summary>
Motivation: 应对对AI助手不断增长的需求与保护用户数据隐私之间的矛盾。

Method: 提出了一种在浏览器中运行的混合架构，包括自适应概率模型和小型语言模型，完全在客户端工作。

Result: 该隐私保护方法有效适应用户行为，提高了搜索效率。

Conclusion: 在不妥协用户隐私和数据控制的情况下，实现了先进的AI辅助。

Abstract: A fundamental tension exists between the demand for sophisticated AI assistance in web search and the need for user data privacy. Current centralized models require users to transmit sensitive browsing data to external services, which limits user control. In this paper, we present a browser extension that provides a viable in-browser alternative. We introduce a hybrid architecture that functions entirely on the client side, combining two components: (1) an adaptive probabilistic model that learns a user's behavioral policy from direct feedback, and (2) a Small Language Model (SLM), running in the browser, which is grounded by the probabilistic model to generate context-aware suggestions. To evaluate this approach, we conducted a three-week longitudinal user study with 18 participants. Our results show that this privacy-preserving approach is highly effective at adapting to individual user behavior, leading to measurably improved search efficiency. This work demonstrates that sophisticated AI assistance is achievable without compromising user privacy or data control.

</details>


### [19] [From SERPs to Agents: A Platform for Comparative Studies of Information Interaction](https://arxiv.org/abs/2601.09937)
*Saber Zerhoudi,Michael Granitzer*

Main category: cs.HC

TL;DR: UXLab是一个开源工具，简化了用户研究的设计和分析过程，支持研究人员进行不同信息获取系统的比较。


<details>
  <summary>Details</summary>
Motivation: 随着信息获取系统的多样化，进行比较性用户研究的需求日益增强，但现有系统的技术复杂性成为了一个主要障碍。

Method: 通过构建一个基于网络的仪表盘，允许研究人员直观管理用户研究的各个环节。

Result: UXLab通过微型案例研究展示了在RAG与自主代理之间比较用户行为的能力，以及其在管理复杂实验设计上的应用价值。

Conclusion: UXLab是一种将用户体验研究简化为无代码配置的开源系统，能有效支持多模态交互研究和实验设计。

Abstract: The diversification of information access systems, from RAG to autonomous agents, creates a critical need for comparative user studies. However, the technical overhead to deploy and manage these distinct systems is a major barrier. We present UXLab, an open-source system for web-based user studies that addresses this challenge. Its core is a web-based dashboard enabling the complete, no-code configuration of complex experimental designs. Researchers can visually manage the full study, from recruitment to comparing backends like traditional search, vector databases, and LLMs. We demonstrate UXLab's value via a micro case study comparing user behavior with RAG versus an autonomous agent. UXLab allows researchers to focus on experimental design and analysis, supporting future multi-modal interaction research.

</details>


### [20] [Empowering Older Adults in Digital Technology Use with Foundation Models](https://arxiv.org/abs/2601.10018)
*Hasti Sharifi,Homaira Huda Shomee,Sourav Medya,Debaleena Chattopadhyay*

Main category: cs.HC

TL;DR: 老年人因技术术语和认知变化而面临沟通困难，研究探讨了通过AI来改善这种情况，发现AI改写查询能提高解决方案的准确性和老年人对技术的理解。


<details>
  <summary>Details</summary>
Motivation: 为了解决老年人在寻求技术支持时的沟通障碍，研究旨在提升他们的参与感和理解能力。

Method: 研究分为日记研究和控制实验，采用反思性主题分析识别沟通障碍，使用大型语言模型生成合成数据集以支持AI改写。

Result: 此研究揭示了老年人在使用数字技术时面临的沟通障碍，并提出了基于AI的解决方案。通过日记研究和控制实验，研究发现AI改写查询显著提高了解决方案的准确性和老年人的理解能力。

Conclusion: 研究展示了基础模型如何通过解决与年龄相关的沟通障碍来增强老年人的技术支持能力，提出的OATS数据集为开发公平的AI系统提供了可扩展的资源。

Abstract: While high-quality technology support can assist older adults in using digital applications, many struggle to articulate their issues due to unfamiliarity with technical terminology and age-related cognitive changes. This study examines these communication challenges and explores AI-based approaches to mitigate them. We conducted a diary study with English-speaking, community-dwelling older adults to collect asynchronous, technology-related queries and used reflexive thematic analysis to identify communication barriers. To address these barriers, we evaluated how foundation models can paraphrase older adults' queries to improve solution accuracy. Two controlled experiments followed: one with younger adults evaluating AI-rephrased queries and another with older adults evaluating AI-generated solutions. We also developed a pipeline using large language models to generate the first synthetic dataset of how older adults request tech support (OATS). We identified four key communication challenges: verbosity, incompleteness, over-specification, and under-specification. Our prompt-chaining approach using the large language model, GPT-4o, elicited contextual details, paraphrased the original query, and generated a solution. AI-rephrased queries significantly improved solution accuracy (69% vs. 46%) and Google search results (69% vs. 35%). Younger adults better understood AI-rephrased queries (93.7% vs. 65.8%) and reported greater confidence and ease. Older adults reported high perceived ability to answer contextual questions (89.8%) and follow solutions (94.7%), with high confidence and ease. OATS demonstrated strong fidelity and face validity. This work shows how foundation models can enhance technology support for older adults by addressing age-related communication barriers. The OATS dataset offers a scalable resource for developing equitable AI systems that better serve aging populations.

</details>


### [21] [Tables or Sankey Diagrams? Investigating User Interaction with Different Representations of Simulation Parameters](https://arxiv.org/abs/2601.10232)
*Choro Ulan uulu,Mikhail Kulyabin,Katharina M Zeiner,Jan Joosten,Nuno Miguel Martins Pacheco,Filippos Petridis,Rebecca Johnson,Jan Bosch,Helena Holmström Olsson*

Main category: cs.HC

TL;DR: 通过使用交互式Sankey图，可显著提高对复杂软件系统中参数依赖关系的理解，改善配置和维护效率。


<details>
  <summary>Details</summary>
Motivation: 理解复杂参数依赖关系对于软件系统的配置和维护至关重要，然而传统表格界面导致的理解困难影响了工作效率和系统信任。

Method: 采用Sankey图进行参数依赖关系可视化，并与传统表格接口进行比较

Result: 使用Sankey图的可视化方法显著降低了认知负担（PURE得分降低51%）和交互复杂性（步骤减少56%），使参数依赖关系即时可见。

Conclusion: Sankey图作为依赖关系可视化工具，能够帮助用户理解复杂的系统配置，提高程序理解和软件可视化效果，对任何需要理解复杂参数关系的软件领域都有积极影响。

Abstract: Understanding complex parameter dependencies is critical for effective configuration and maintenance of software systems across diverse domains - from Computer-Aided Engineering (CAE) to cloud infrastructure and database management. However, legacy tabular interfaces create a major bottleneck: engineers cannot easily comprehend how parameters relate across the system, leading to inefficient workflows, costly configuration errors, and reduced system trust - a fundamental program comprehension challenge in configuration-intensive software. This research evaluates whether interactive Sankey diagrams can improve comprehension of parameter dependencies compared to traditional spreadsheet interfaces. We employed a heuristic evaluation using the PURE method with three expert evaluators (UX design, simulation, and software development specialists) to compare a Sankey-based prototype to traditional tabular representations for core engineering tasks. Our key contribution demonstrates that flow-based parameter visualizations significantly reduce cognitive load (51% lower PURE scores) and interaction complexity (56% fewer steps) compared to traditional tables, while making parameter dependencies immediately visible rather than requiring mental reconstruction. By explicitly visualizing parameter relationships, Sankey diagrams address a core software visualization challenge: helping users comprehend complex system configurations without requiring deep tool-specific knowledge. While demonstrated through CAE software, this research contributes to program comprehension and software visualization by showing that dependency-aware visualizations can significantly improve understanding of configuration-intensive systems. The findings have implications for any software domain where comprehending complex parameter relationships is essential for effective system use and maintenance.

</details>


### [22] [Who Owns the Text? Design Patterns for Preserving Authorship in AI-Assisted Writing](https://arxiv.org/abs/2601.10236)
*Bohan Zhang,Chengke Bu,Paramveer S. Dhillon*

Main category: cs.HC

TL;DR: 这项研究探讨了AI写作助手对作家所有权感的影响，发现个性化风格建议能部分恢复所有权感。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在探讨AI写作工具对作家归属感的影响，以及如何设计这些工具以增强作者的创作所有权。

Method: 参与者在没有AI帮助、使用普通AI建议和使用个性化指导的情况下完成三项写作任务，比较了心理所有权和认知负担的变化。

Result: 这项研究开发了一种具有所有权意识的协作编辑工具，探讨了AI写作助手对作家著作权感的影响。结果显示，尽管AI帮助减轻了认知负担，但作家的心理所有权感下降。个性化的风格建议能部分恢复所有权感，提供了五个设计模式，以指导未来的写作工具。

Conclusion: AI助手虽然提升了写作流畅度和减少了认知负担，但却降低了作家的所有权感。通过设计特定的功能，可以帮助作家保持对作品的控制感。

Abstract: AI writing assistants can reduce effort and improve fluency, but they may also weaken writers' sense of authorship. We study this tension with an ownership-aware co-writing editor that offers on-demand, sentence-level suggestions and tests two common design choices: persona-based coaching and style personalization. In an online study (N=176), participants completed three professional writing tasks: an email without AI help, a proposal with generic AI suggestions, and a cover letter with persona-based coaching, while half received suggestions tailored to a brief sample of their prior writing. Across the two AI-assisted tasks, psychological ownership dropped relative to unassisted writing (about 0.85-1.0 points on a 7-point scale), even as cognitive load decreased (about 0.9 points) and quality ratings stayed broadly similar overall. Persona coaching did not prevent the ownership decline. Style personalization partially restored ownership (about +0.43) and increased AI incorporation in text (+5 percentage points). We distill five design patterns: on-demand initiation, micro-suggestions, voice anchoring, audience scaffolds, and point-of-decision provenance, to guide authorship-preserving writing tools.

</details>


### [23] [Developer Interaction Patterns with Proactive AI: A Five-Day Field Study](https://arxiv.org/abs/2601.10253)
*Nadine Kuo,Agnia Sergeyuk,Valerie Chen,Maliheh Izadi*

Main category: cs.HC

TL;DR: 本研究通过研究开发者在工作流程中的反应，探讨了前瞻性AI建议的有效性，发现适时的建议能显著提高开发者的接受度。


<details>
  <summary>Details</summary>
Motivation: 当前的IDE内AI编码工具通常依赖耗时的手动提示和上下文管理，而少有前瞻性替代方案可以在不明确请求的情况下预见开发者需求。

Method: 通过观察229个AI干预事件在5732个交互点的效果，分析了开发者如何接受前瞻性建议，并测量了建议的时机对解释时间的影响。

Result: 通过对15名开发者进行为期五天的实地研究，评估了在生产级IDE中集成的AI助手的前瞻性功能对代码质量建议的影响。

Conclusion: 研究表明，设计前瞻性编码助手时，干预的时机、与开发者上下文的对齐以及AI代理与用户控制之间的平衡至关重要。

Abstract: Current in-IDE AI coding tools typically rely on time-consuming manual prompting and context management, whereas proactive alternatives that anticipate developer needs without explicit invocation remain underexplored. Understanding when humans are receptive to such proactive AI assistance during their daily work remains an open question in human-AI interaction research. We address this gap through a field study of proactive AI assistance in professional developer workflows. We present a five-day in-the-wild study with 15 developers who interacted with a proactive feature of an AI assistant integrated into a production-grade IDE that offers code quality suggestions based on in-IDE developer activity. We examined 229 AI interventions across 5,732 interaction points to understand how proactive suggestions are received across workflow stages, how developers experience them, and their perceived impact. Our findings reveal systematic patterns in human receptivity to proactive suggestions: interventions at workflow boundaries (e.g., post-commit) achieved 52% engagement rates, while mid-task interventions (e.g., on declined edit) were dismissed 62% of the time. Notably, well-timed proactive suggestions required significantly less interpretation time than reactive suggestions (45.4s versus 101.4s, W = 109.00, r = 0.533, p = 0.0016), indicating enhanced cognitive alignment. This study provides actionable implications for designing proactive coding assistants, including how to time interventions, align them with developer context, and strike a balance between AI agency and user control in production IDEs.

</details>


### [24] [Does Cognitive Load Affect Human Accuracy in Detecting Voice-Based Deepfakes?](https://arxiv.org/abs/2601.10383)
*Marcel Gohsen,Nicola Libera,Johannes Kiesel,Jan Ehlers,Benno Stein*

Main category: cs.HC

TL;DR: 这篇论文研究了认知负荷对检测深伪影像的影响，发现低认知负荷不损害检测能力，反而可能有所帮助。


<details>
  <summary>Details</summary>
Motivation: 了解社交媒体用户在认知负荷下的深伪影像检测能力

Method: 通过实证研究分析认知负荷对人类检测语音深伪影像的影响

Result: 低认知负荷并不会普遍损害检测能力，同时时接收次要刺激可能有助于提升检测任务的表现

Conclusion: 研究结果表明，环境因素如认知负荷对深伪检测能力的影响较为复杂，可能在特定条件下产生积极效果。

Abstract: Deepfake technologies are powerful tools that can be misused for malicious purposes such as spreading disinformation on social media. The effectiveness of such malicious applications depends on the ability of deepfakes to deceive their audience. Therefore, researchers have investigated human abilities to detect deepfakes in various studies. However, most of these studies were conducted with participants who focused exclusively on the detection task; hence the studies may not provide a complete picture of human abilities to detect deepfakes under realistic conditions: Social media users are exposed to cognitive load on the platform, which can impair their detection abilities. In this paper, we investigate the influence of cognitive load on human detection abilities of voice-based deepfakes in an empirical study with 30 participants. Our results suggest that low cognitive load does not generally impair detection abilities, and that the simultaneous exposure to a secondary stimulus can actually benefit people in the detection task.

</details>


### [25] [LangLasso: Interactive Cluster Descriptions through LLM Explanation](https://arxiv.org/abs/2601.10458)
*Raphael Buchmüller,Dennis Collaris,Linhao Meng,Angelos Chatzimparmpas*

Main category: cs.HC

TL;DR: LangLasso 是一种通过自然语言描述群集，促进非专家理解数据结构的工具


<details>
  <summary>Details</summary>
Motivation: 旨在提高群集解释的可及性，让非专家也能理解数据结构和潜在群集

Method: LangLasso，结合自然语言生成与交互式可视化分析方法

Result: LangLasso 生成易于理解的群集描述，并经过系统评估其可靠性

Conclusion: LangLasso 作为一种工具，为更广泛受众的群集解释提供了有效的初步步骤。

Abstract: Dimensionality reduction is a powerful technique for revealing structure and potential clusters in data. However, as the axes are complex, non-linear combinations of features, they often lack semantic interpretability. Existing visual analytics (VA) methods support cluster interpretation through feature comparison and interactive exploration, but they require technical expertise and intense human effort. We present \textit{LangLasso}, a novel method that complements VA approaches through interactive, natural language descriptions of clusters using large language models (LLMs). It produces human-readable descriptions that make cluster interpretation accessible to non-experts and allow integration of external contextual knowledge beyond the dataset. We systematically evaluate the reliability of these explanations and demonstrate that \langlasso provides an effective first step for engaging broader audiences in cluster interpretation. The tool is available at https://langlasso.vercel.app

</details>


### [26] [AI Sycophancy: How Users Flag and Respond](https://arxiv.org/abs/2601.10467)
*Kazi Noshin,Syed Ishtiaque Ahmed,Sharifa Sultana*

Main category: cs.HC

TL;DR: 本研究探讨了用户如何识别和应对生成式人工智能的阿谀行为，提出ODR框架，发现阿谀行为影响因情境不同而异。


<details>
  <summary>Details</summary>
Motivation: 尽管研究者对LMM阿谀行为的担忧加剧，但用户如何体验这些行为尚未被充分探讨。

Method: 通过分析Reddit讨论，研究用户在与AI互动中的经验和反应，提出ODR框架。

Result: 本研究分析了用户在使用生成式人工智能（LLM）时遇到的阿谀行为及其体验。我们开发了ODR框架，细分用户体验为三个阶段：观察阿谀行为、检测阿谀行为及应对这些行为。研究显示，用户使用多种检测技术与缓解策略，且阿谀行为的影响因上下文而异。在某些情况下，如焦虑、孤独的人群中，用户会积极寻求阿谀行为带来的情感支持。

Conclusion: 我们建议设计更具上下文感知的人工智能，以平衡阿谀行为的风险与益处，并讨论用户教育与透明度的重要性。

Abstract: While concerns about LLM sycophancy have grown among researchers and developers, how users themselves experience this behavior remains largely unexplored. We analyze Reddit discussions to investigate how users detect, mitigate, and perceive sycophantic AI. We develop the ODR Framework that maps user experiences across three stages: observing sycophantic behaviors, detecting sycophancy, and responding to these behaviors. Our findings reveal that users employ various detection techniques, including cross-platform comparison and inconsistency testing. We document diverse mitigation approaches, such as persona-based prompts to specific language patterns in prompt engineering. We find sycophancy's effects are context-dependent rather than universally harmful. Specifically, vulnerable populations experiencing trauma, mental health challenges, or isolation actively seek and value sycophantic behaviors as emotional support. Users develop both technical and folk explanations for why sycophancy occurs. These findings challenge the assumption that sycophancy should be eliminated universally. We conclude by proposing context-aware AI design that balances the risks with the benefits of affirmative interaction, while discussing implications for user education and transparency.

</details>


### [27] [Learning from Brain Topography: A Hierarchical Local-Global Graph-Transformer Network for EEG Emotion Recognition](https://arxiv.org/abs/2601.10525)
*Yijin Zhou,Fu Li,Yi Niu,Boxun Fu,Huaning Wang,Lijian Zhang*

Main category: cs.HC

TL;DR: 提出了一种新型神经网络Neuro-HGLN，结合空间图和动态图提升脑电图情绪识别性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有深度学习方法未能充分考虑大脑空间组织的问题，从而提高脑电图信号解码人类情绪的效果。

Method: 构建生物学基础的空间优先图及动态图，并利用多头自注意力机制形成区域级局部图，通过局部约束并行GCN层处理，以获得区域特征，最后用iTransformer编码器聚合特征以捕捉跨区域依赖。

Result: 经过大量实验，Neuro-HGLN在多个基准测试中实现了先进的性能，增强了解释能力，基于神经生理结构的表现。

Conclusion: Neuro-HGLN通过结合局部拓扑学习与跨区域依赖建模，有效提升了脑电图情绪识别的准确性与可解释性。

Abstract: Understanding how local neurophysiological patterns interact with global brain dynamics is essential for decoding human emotions from EEG signals. However, existing deep learning approaches often overlook the brain's intrinsic spatial organization, failing to simultaneously capture local topological relations and global dependencies. To address these challenges, we propose Neuro-HGLN, a Neurologically-informed Hierarchical Graph-Transformer Learning Network that integrates biologically grounded priors with hierarchical representation learning. Neuro-HGLN first constructs a spatial Euclidean prior graph based on physical electrode distances to serve as an anatomically grounded inductive bias. A learnable global dynamic graph is then introduced to model functional connectivity across the entire brain. In parallel, to capture fine-grained regional dependencies, Neuro-HGLN builds region-level local graphs using a multi-head self-attention mechanism. These graphs are processed synchronously through local-constrained parallel GCN layers to produce region-specific representations. Subsequently, an iTransformer encoder aggregates these features to capture cross-region dependencies under a dimension-as-token formulation. Extensive experiments demonstrate that Neuro-HGLN achieves state-of-the-art performance on multiple benchmarks, providing enhanced interpretability grounded in neurophysiological structure. These results highlight the efficacy of unifying local topological learning with cross-region dependency modeling for robust EEG emotion recognition.

</details>


### [28] [CoGen: Creation of Reusable UI Components in Figma via Textual Commands](https://arxiv.org/abs/2601.10536)
*Ishani Kanapathipillai,Obhasha Priyankara*

Main category: cs.HC

TL;DR: 本研究提出 CoGen 系统，利用机器学习在 Figma 中生成可重用 UI 组件，显著提升设计效率。


<details>
  <summary>Details</summary>
Motivation: 随着用户界面设计的发展，对高效、可重用和可编辑组件的需求日益增加。

Method: 通过机器学习技术，利用 Figma API 数据提取、Seq2Seq 模型和微调的 T5 转换器生成组件。

Result: T5 模型在提示生成中的效率达到 98% 的准确率，JSON 创建成功率高达100%。

Conclusion: CoGen 系统有效地生成可重用的 UI 组件，显著提高了设计效率。

Abstract: The evolution of User Interface design has emphasized the need for efficient, reusable, and editable components to ensure an efficient design process. This research introduces CoGen, a system that uses machine learning techniques to generate reusable UI components directly in Figma, one of the most popular UI design tools. Addressing gaps in current systems, CoGen focuses on creating atomic components such as buttons, labels, and input fields using structured JSON and natural language prompts.
  The project integrates Figma API data extraction, Seq2Seq models, and fine-tuned T5 transformers for component generation. The key results demonstrate the efficiency of the T5 model in prompt generation, with an accuracy of 98% and a BLEU score of 0.2668, which ensures the mapping of JSON to descriptive prompts. For JSON creation, CoGen achieves a success rate of up to 100% in generating simple JSON outputs for specified component types.

</details>


### [29] [An Extension-Based Accessibility Framework for Making Blockly Accessible to Blind and Low-Vision Users](https://arxiv.org/abs/2601.10688)
*Rubel Hassan Mollik,Vamsi Krishna Kosuri,Hans Djalali,Stephanie Ludi,Aboubakar Mountapmbeme*

Main category: cs.HC

TL;DR: 提出EAF框架，提升盲人和视力受损者在基于区块编程环境中的可访问性，采用模块化设计，可与现有环境整合，体验改善。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有可访问性解决方案在BBPE中难以应用的问题，从而使盲人或视力受损学习者能够更好地参与计算机科学课程。

Method: 使用模块化架构设计EAF框架，通过177个测试案例评估其在两个BBPE中的集成效果，并进行参与者访谈。

Result: 本文提出了一种基于扩展的可访问性框架（EAF），以增强盲人或视力受损学习者在基于区块的编程环境（BBPEs）中的可访问性。该框架采用模块化架构，便于与现有BBPEs的整合。通过在两个BBPE中集成EAF框架并进行 semi-structured interviews，参与者反馈了比默认Blockly键盘导航更清晰的空间定位和更容易的心理模型形成。

Conclusion: EAF框架通过模块化架构提供了全面的可访问性，确保与现有基于Blockly的编程环境的兼容性。

Abstract: Block-based programming environments (BBPEs) such as Scratch and Code.org are now widely used in K-12 computer science classes, but they remain mostly inaccessible to blind or visually impaired (BVI) learners. A major problem is that prior accessibility solutions have relied on modifications to the Blockly library, making them difficult to apply in existing BBPEs and thereby limiting adoption. We present an Extension-based Accessibility Framework (EAF) to make BBPEs accessible for BVI students. The framework uses a modular architecture that enables seamless integration with existing Blockly-based BBPEs. We present an innovative three-dimensional (3D) hierarchical navigation model featuring stack labeling and block numbering, mode-based editing to prevent accidental modifications, and WAI-ARIA implementation to ensure compatibility with external screen readers. We evaluated our approach by integrating the EAF framework into two BBPEs (covering 177 test cases) and conducting semi-structured interviews with four participants using VoiceOver, JAWS, and NVDA. Participants reported clearer spatial orientation and easier mental model formation compared to default Blockly keyboard navigation. EAF shows that modular architecture can provide comprehensive accessibility while ensuring compatibility with existing BBPEs.

</details>
