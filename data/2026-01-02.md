<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 35]
- [cs.HC](#cs.HC) [Total: 6]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Simultaneous Extrinsic Contact and In-Hand Pose Estimation via Distributed Tactile Sensing](https://arxiv.org/abs/2512.23856)
*Mark Van der Merwe,Kei Ota,Dmitry Berenson,Nima Fazeli,Devesh K. Jha*

Main category: cs.RO

TL;DR: 本文提出一种结合触觉传感和物理约束的局部观察方法，优化了物体姿态与接触情况的估计。


<details>
  <summary>Details</summary>
Motivation: 在自适应操控中，需要精确理解物体的姿态和接触，而仅依赖触觉传感可能导致不适定问题。

Method: 将局部观察与接触的物理约束相结合

Result: 提出了一种因子图的方法，能有效估计物体的姿态和接触情况

Conclusion: 所提出的方法在仅使用触觉信息时的表现优于现有的几何和接触信息估计流程

Abstract: Prehensile autonomous manipulation, such as peg insertion, tool use, or assembly, require precise in-hand understanding of the object pose and the extrinsic contacts made during interactions. Providing accurate estimation of pose and contacts is challenging. Tactile sensors can provide local geometry at the sensor and force information about the grasp, but the locality of sensing means resolving poses and contacts from tactile alone is often an ill-posed problem, as multiple configurations can be consistent with the observations. Adding visual feedback can help resolve ambiguities, but can suffer from noise and occlusions. In this work, we propose a method that pairs local observations from sensing with the physical constraints of contact. We propose a set of factors that ensure local consistency with tactile observations as well as enforcing physical plausibility, namely, that the estimated pose and contacts must respect the kinematic and force constraints of quasi-static rigid body interactions. We formalize our problem as a factor graph, allowing for efficient estimation. In our experiments, we demonstrate that our method outperforms existing geometric and contact-informed estimation pipelines, especially when only tactile information is available. Video results can be found at https://tacgraph.github.io/.

</details>


### [2] [Learning to Feel the Future: DreamTacVLA for Contact-Rich Manipulation](https://arxiv.org/abs/2512.23864)
*Guo Ye,Zexi Zhang,Xu Zhao,Shang Wu,Haoran Lu,Shihan Lu,Han Liu*

Main category: cs.RO

TL;DR: DreamTacVLA通过整合触觉信号与视觉信息，显著提升了机器人在接触丰富操作中的表现。


<details>
  <summary>Details</summary>
Motivation: 解决目前VLA模型在物理接触方面的盲点，提升其在需要判断力、纹理和滑移的操作任务中的表现。

Method: 通过分层感知方案，使用高分辨率触觉图像、手腕摄像机的局部视觉和第三人称宏观视觉进行统一策略训练，并采用触觉世界模型细化系统。

Result: DreamTacVLA通过预测未来触觉信号，获得丰富的接触物理模型，并在操作任务中显示出显著的成功率提升。

Conclusion: DreamTacVLA在接触丰富的操作任务中 outperform 现有的VLA基线模型，成功率高达95%。

Abstract: Vision-Language-Action (VLA) models have shown remarkable generalization by mapping web-scale knowledge to robotic control, yet they remain blind to physical contact. Consequently, they struggle with contact-rich manipulation tasks that require reasoning about force, texture, and slip. While some approaches incorporate low-dimensional tactile signals, they fail to capture the high-resolution dynamics essential for such interactions. To address this limitation, we introduce DreamTacVLA, a framework that grounds VLA models in contact physics by learning to feel the future. Our model adopts a hierarchical perception scheme in which high-resolution tactile images serve as micro-vision inputs coupled with wrist-camera local vision and third-person macro vision. To reconcile these multi-scale sensory streams, we first train a unified policy with a Hierarchical Spatial Alignment (HSA) loss that aligns tactile tokens with their spatial counterparts in the wrist and third-person views. To further deepen the model's understanding of fine-grained contact dynamics, we finetune the system with a tactile world model that predicts future tactile signals. To mitigate tactile data scarcity and the wear-prone nature of tactile sensors, we construct a hybrid large-scale dataset sourced from both high-fidelity digital twin and real-world experiments. By anticipating upcoming tactile states, DreamTacVLA acquires a rich model of contact physics and conditions its actions on both real observations and imagined consequences. Across contact-rich manipulation tasks, it outperforms state-of-the-art VLA baselines, achieving up to 95% success, highlighting the importance of understanding physical contact for robust, touch-aware robotic agents.

</details>


### [3] [SHIELD: Spherical-Projection Hybrid-Frontier Integration for Efficient LiDAR-based Drone Exploration](https://arxiv.org/abs/2512.23972)
*Liangtao Feng,Zhenchang Liu,Feng Zhang,Xuefeng Ren*

Main category: cs.RO

TL;DR: 本论文提出SHIELD，一种用于LiDAR无人机探索的方法，通过改善观察质量和降低计算负担，已通过实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决LiDAR在无人机探索中的观察质量、计算负担和空间分类等挑战。

Method: 使用混合前沿策略和球面投影射线投射方法，以提高LiDAR点云的观察质量和计算效率。

Result: 通过仿真和飞行实验验证了SHIELD方法的有效性。

Conclusion: SHIELD proves to be an effective method for LiDAR-based drone exploration, improving observation quality and computational efficiency.

Abstract: This paper introduces SHIELD, a Spherical-Projection Hybrid-Frontier Integration for Efficient LiDAR-based Drone exploration method. Although laser LiDAR offers the advantage of a wide field of view, its application in UAV exploration still faces several challenges. The observation quality of LiDAR point clouds is generally inferior to that of depth cameras. Traditional frontier methods based on known and unknown regions impose a heavy computational burden, especially when handling the wide field of view of LiDAR. In addition, regions without point cloud are also difficult to classify as free space through raycasting. To address these problems, the SHIELD is proposed. It maintains an observation-quality occupancy map and performs ray-casting on this map to address the issue of inconsistent point-cloud quality during exploration. A hybrid frontier method is used to tackle both the computational burden and the limitations of point-cloud quality exploration. In addition, an outward spherical-projection ray-casting strategy is proposed to jointly ensure flight safety and exploration efficiency in open areas. Simulations and flight experiments prove the effectiveness of SHIELD. This work will be open-sourced to contribute to the research community.

</details>


### [4] [Evaluation of Impression Difference of a Domestic Mobile Manipulator with Autonomous and/or Remote Control in Fetch-and-Carry Tasks](https://arxiv.org/abs/2512.24029)
*Takashi Yamamoto,Hiroaki Yaguchi,Shohei Kato,Hiroyuki Okada*

Main category: cs.RO

TL;DR: 研究探讨了服务机器人中自主与操作员介入的双重代理，并评估不同交互模式对用户体验的影响，结果表明混合代理能显著影响人类的印象。


<details>
  <summary>Details</summary>
Motivation: 研究服务机器人如何在其自主性与操作员介入之间平衡，提供更好的用户体验。

Method: 通过控制的取放任务在模拟测试场进行评估，比较三种模式（自主、远程和混合）的表现。

Result: 评估显示用户对不同模式的亲和力存在系统性差异，这影响了他们对安全感的感知。

Conclusion: 切换或混合机器人中的代理会显著影响人类的印象，为家庭物理任务中的人机协作设计提供了实证指导。

Abstract: A single service robot can present two distinct agencies: its onboard autonomy and an operator-mediated agency, yet users experience them through one physical body. We formalize this dual-agency structure as a User-Robot-Operator triad in an autonomous remote-control setting that combines autonomous execution with remote human support. Prior to the recent surge of language-based and multimodal interfaces, we developed and evaluated an early-stage prototype in 2020 that combined natural-language text chat with freehand sketch annotations over the robot's live camera view to support remote intervention. We evaluated three modes - autonomous, remote, and hybrid - in controlled fetch-and-carry tasks using a domestic mobile manipulator (HSR) on a World Robot Summit 2020 rule-compliant test field. The results show systematic mode-dependent differences in user-rated affinity and additional insights on perceived security, indicating that switching or blending agency within one robot measurably shapes human impressions. These findings provide empirical guidance for designing human-in-the-loop mobile manipulation in domestic physical tasks.

</details>


### [5] [RflyUT-Sim: A Simulation Platform for Development and Testing of Complex Low-Altitude Traffic Control](https://arxiv.org/abs/2512.24112)
*Zonghan Li,Tianwen Tao,Rao Fu,Liang Wang,Dongyuan Zhang,Quan Quan*

Main category: cs.RO

TL;DR: 本文提出一个高保真低空无人机交通仿真平台，集成多种功能并提供灵活定制，支持研究。


<details>
  <summary>Details</summary>
Motivation: 因低空无人机交通仿真与测试面临高成本和复杂场景建立的挑战，亟需一个高保真仿真平台来支持相关研究。

Method: 介绍一个集成的高保真仿真平台，模拟低空无人机交通的各个组成部分。

Result: 平台通过集成RflySim/AirSim和Unreal Engine 5，开发出完整状态的无人机模型和使用倾斜摄影测量技术建模的3D地图。

Conclusion: 该平台为低空交通研究提供了灵活的接口和可定制的模型和场景，并且源代码已发布，促进了相关研究的开展。

Abstract: Significant challenges are posed by simulation and testing in the field of low-altitude unmanned aerial vehicle (UAV) traffic due to the high costs associated with large-scale UAV testing and the complexity of establishing low-altitude traffic test scenarios. Stringent safety requirements make high fidelity one of the key metrics for simulation platforms. Despite advancements in simulation platforms for low-altitude UAVs, there is still a shortage of platforms that feature rich traffic scenarios, high-precision UAV and scenario simulators, and comprehensive testing capabilities for low-altitude traffic. Therefore, this paper introduces an integrated high-fidelity simulation platform for low-altitude UAV traffic. This platform simulates all components of the UAV traffic network, including the control system, the traffic management system, the UAV system, the communication network , the anomaly and fault modules, etc. Furthermore, it integrates RflySim/AirSim and Unreal Engine 5 to develop full-state models of UAVs and 3D maps that model the real world using the oblique photogrammetry technique. Additionally, the platform offers a wide range of interfaces, and all models and scenarios can be customized with a high degree of flexibility. The platform's source code has been released, making it easier to conduct research related to low-altitude traffic.

</details>


### [6] [Unified Embodied VLM Reasoning with Robotic Action via Autoregressive Discretized Pre-training](https://arxiv.org/abs/2512.24125)
*Yi Liu,Sukai Wang,Dafeng Wei,Xiaowei Cai,Linqing Zhong,Jiange Yang,Guanghui Ren,Jinyu Zhang,Maoqing Yao,Chuankang Li,Xindong He,Liliang Chen,Jianlan Luo*

Main category: cs.RO

TL;DR: 本文提出了ERIQ基准与FACT工具，旨在解决通用机器人在推理与精准执行之间的挑战，提升机器人的操作能力。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作（VLA）模型在开放世界环境中表现不足，无法有效整合广泛泛化与高精度行动执行。

Method: 引入ERIQ评估推理能力，并采用FACT将连续控制转化为离散序列，实现推理与行动的统一优化。

Result: GenieReasoner在实际任务中优于以往的动作基线，表明推理能力与执行精度之间存在显著正相关。

Conclusion: ERIQ与FACT为解决机器人精准控制与推理能力之间的矛盾提供了有效的框架，推动了通用机器人操作的进步。

Abstract: General-purpose robotic systems operating in open-world environments must achieve both broad generalization and high-precision action execution, a combination that remains challenging for existing Vision-Language-Action (VLA) models. While large Vision-Language Models (VLMs) improve semantic generalization, insufficient embodied reasoning leads to brittle behavior, and conversely, strong reasoning alone is inadequate without precise control. To provide a decoupled and quantitative assessment of this bottleneck, we introduce Embodied Reasoning Intelligence Quotient (ERIQ), a large-scale embodied reasoning benchmark in robotic manipulation, comprising 6K+ question-answer pairs across four reasoning dimensions. By decoupling reasoning from execution, ERIQ enables systematic evaluation and reveals a strong positive correlation between embodied reasoning capability and end-to-end VLA generalization. To bridge the gap from reasoning to precise execution, we propose FACT, a flow-matching-based action tokenizer that converts continuous control into discrete sequences while preserving high-fidelity trajectory reconstruction. The resulting GenieReasoner jointly optimizes reasoning and action in a unified space, outperforming both continuous-action and prior discrete-action baselines in real-world tasks. Together, ERIQ and FACT provide a principled framework for diagnosing and overcoming the reasoning-precision trade-off, advancing robust, general-purpose robotic manipulation.

</details>


### [7] [ROBOPOL: Social Robotics Meets Vehicular Communications for Cooperative Automated Driving](https://arxiv.org/abs/2512.24129)
*Manuel Bied,John Arockiasamy,Andy Comeca,Maximilian Schrapel,Victoria Yang,Alexey Rolich,Barbara Bruno,Maike Schwammberger,Dieter Fiems,Alexey Vinel*

Main category: cs.RO

TL;DR: 本论文探讨了社交机器人如何帮助自动驾驶车辆与行人互动，提出了实现这一目标的四个关键技术，并进行了初步的概念验证。


<details>
  <summary>Details</summary>
Motivation: 在实现完全自主驾驶的过程中，自动驾驶车辆与人类交通参与者共享道路是不可避免的，尤其是面对行人等脆弱道路用户的情况。

Method: 提出将社交机器人作为自动驾驶车辆与脆弱道路用户之间的调解者，识别出集成的四个关键因素。

Result: 概述了四个关键因素并报告了前期概念验证，集成了前三个关键因素，设想了社交机器人在与协作自动电动自行车的场景中指导行人。

Conclusion: 本研究为社交机器人在混合交通中与自动驾驶车辆的协作提供了初步的概念验证，显示了这种集成的潜力。

Abstract: On the way towards full autonomy, sharing roads between automated vehicles and human actors in so-called mixed traffic is unavoidable. Moreover, even if all vehicles on the road were autonomous, pedestrians would still be crossing the streets. We propose social robots as moderators between autonomous vehicles and vulnerable road users (VRU). To this end, we identify four enablers requiring integration: (1) advanced perception, allowing the robot to see the environment; (2) vehicular communications allowing connected vehicles to share intentions and the robot to send guiding commands; (3) social human-robot interaction allowing the robot to effectively communicate with VRUs and drivers; (4) formal specification allowing the robot to understand traffic and plan accordingly. This paper presents an overview of the key enablers and report on a first proof-of-concept integration of the first three enablers envisioning a social robot advising pedestrians in scenarios with a cooperative automated e-bike.

</details>


### [8] [GR-Dexter Technical Report](https://arxiv.org/abs/2512.24210)
*Ruoshi Wen,Guangzeng Chen,Zhongren Cui,Min Du,Yang Gou,Zhigang Han,Liqun Huang,Mingyu Lei,Yunfei Li,Zhuohang Li,Wenlei Liu,Yuxiao Liu,Xiao Ma,Hao Niu,Yutao Ouyang,Zeyu Ren,Haixin Shi,Wei Xu,Haoxiang Zhang,Jiajun Zhang,Xiao Zhang,Liwei Zheng,Weiheng Zhong,Yifei Zhou,Zhengming Zhu,Hang Li*

Main category: cs.RO

TL;DR: GR-Dexter框架结合了硬件、模型和数据，成功应对双手灵巧机器人的操作挑战，具有良好的性能与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决现有代理机构在双手灵巧操作中的局限性，特别是扩大行动空间和改进数据收集过程。

Method: 将紧凑的21自由度机械手设计、直观的双手遥操作系统以及训练方案相结合，利用遥操作机器人轨迹和大规模视觉语言数据集

Result: 在真实世界评估中，GR-Dexter在长时间日常操作和可推广的拾放任务中表现出强劲的领域内性能，并对未见物体和指令表现出更好的鲁棒性。

Conclusion: GR-Dexter作为朝向通用灵巧手机器人操作的实际步骤，简化了操作和提升了性能。

Abstract: Vision-language-action (VLA) models have enabled language-conditioned, long-horizon robot manipulation, but most existing systems are limited to grippers. Scaling VLA policies to bimanual robots with high degree-of-freedom (DoF) dexterous hands remains challenging due to the expanded action space, frequent hand-object occlusions, and the cost of collecting real-robot data. We present GR-Dexter, a holistic hardware-model-data framework for VLA-based generalist manipulation on a bimanual dexterous-hand robot. Our approach combines the design of a compact 21-DoF robotic hand, an intuitive bimanual teleoperation system for real-robot data collection, and a training recipe that leverages teleoperated robot trajectories together with large-scale vision-language and carefully curated cross-embodiment datasets. Across real-world evaluations spanning long-horizon everyday manipulation and generalizable pick-and-place, GR-Dexter achieves strong in-domain performance and improved robustness to unseen objects and unseen instructions. We hope GR-Dexter serves as a practical step toward generalist dexterous-hand robotic manipulation.

</details>


### [9] [RANGER: A Monocular Zero-Shot Semantic Navigation Framework through Contextual Adaptation](https://arxiv.org/abs/2512.24212)
*Ming-Ming Yu,Yi Chen,Börje F. Karlsson,Wenjun Wu*

Main category: cs.RO

TL;DR: RANGER是一种新颖的零-shot语义导航框架，利用单目相机高效导航，克服了对深度和姿态信息的依赖，并具备学习适应能力。


<details>
  <summary>Details</summary>
Motivation: 在复杂环境中有效寻找目标是现实世界应用的关键，但现有方法依赖于精确的深度和姿态信息，并且缺乏快速适应新环境的能力，因此需要新的方法。

Method: RANGER结合了多种关键组件，包括基于关键帧的3D重建、语义点云生成、基于视觉语言模型的探索价值估算、高级自适应航标选择和低级动作执行，从而实现零-shot导航。

Result: RANGER是一种新的零-shot开放词汇语义导航框架，能够在没有深度和姿态信息的情况下，仅依靠单目相机进行有效目标寻找，适用于复杂环境。

Conclusion: 通过强大的3D基础模型和高水平的自适应路径选择，RANGER在HM3D基准和真实环境中展示了竞争力的导航成功率和探索效率，同时在无先前3D映射的情况下表现出优越的ICL适应性。

Abstract: Efficiently finding targets in complex environments is fundamental to real-world embodied applications. While recent advances in multimodal foundation models have enabled zero-shot object goal navigation, allowing robots to search for arbitrary objects without fine-tuning, existing methods face two key limitations: (1) heavy reliance on precise depth and pose information provided by simulators, which restricts applicability in real-world scenarios; and (2) lack of in-context learning (ICL) capability, making it difficult to quickly adapt to new environments, as in leveraging short videos. To address these challenges, we propose RANGER, a novel zero-shot, open-vocabulary semantic navigation framework that operates using only a monocular camera. Leveraging powerful 3D foundation models, RANGER eliminates the dependency on depth and pose while exhibiting strong ICL capability. By simply observing a short video of a new environment, the system can also significantly improve task efficiency without requiring architectural modifications or fine-tuning. The framework integrates several key components: keyframe-based 3D reconstruction, semantic point cloud generation, vision-language model (VLM)-driven exploration value estimation, high-level adaptive waypoint selection, and low-level action execution. Experiments on the HM3D benchmark and real-world environments demonstrate that RANGER achieves competitive performance in terms of navigation success rate and exploration efficiency, while showing superior ICL adaptability, with no previous 3D mapping of the environment required.

</details>


### [10] [Heteroscedastic Bayesian Optimization-Based Dynamic PID Tuning for Accurate and Robust UAV Trajectory Tracking](https://arxiv.org/abs/2512.24249)
*Fuqiang Gu,Jiangshan Ai,Xu Lu,Xianlei Long,Yan Li,Tao Jiang,Chao Chen,Huidong Liu*

Main category: cs.RO

TL;DR: 提出的HBO-PID控制算法结合异方差贝叶斯优化和PID控制器，显著提升了无人机的轨迹跟踪精度。


<details>
  <summary>Details</summary>
Motivation: 无人机在多种应用中扮演重要角色，但传统轨迹跟踪控制算法因四旋翼系统的欠驱动、非线性及高度耦合动态而表现有限。

Method: 提出了一种名为HBO-PID的新型控制算法，结合了异方差贝叶斯优化框架与经典PID控制器，通过建模输入相关噪声方差以提高跟踪准确性和鲁棒性。

Result: 通过模拟和实际场景实验，HBO-PID方法在位置精度上比先进技术提高了24.7%至42.9%，在角度精度上提高了40.9%至78.4%。

Conclusion: 该方法明显优于现有的先进技术，提高了位置和角度的跟踪精度。

Abstract: Unmanned Aerial Vehicles (UAVs) play an important role in various applications, where precise trajectory tracking is crucial. However, conventional control algorithms for trajectory tracking often exhibit limited performance due to the underactuated, nonlinear, and highly coupled dynamics of quadrotor systems. To address these challenges, we propose HBO-PID, a novel control algorithm that integrates the Heteroscedastic Bayesian Optimization (HBO) framework with the classical PID controller to achieve accurate and robust trajectory tracking. By explicitly modeling input-dependent noise variance, the proposed method can better adapt to dynamic and complex environments, and therefore improve the accuracy and robustness of trajectory tracking. To accelerate the convergence of optimization, we adopt a two-stage optimization strategy that allow us to more efficiently find the optimal controller parameters. Through experiments in both simulation and real-world scenarios, we demonstrate that the proposed method significantly outperforms state-of-the-art (SOTA) methods. Compared to SOTA methods, it improves the position accuracy by 24.7% to 42.9%, and the angular accuracy by 40.9% to 78.4%.

</details>


### [11] [Local Path Optimization in The Latent Space Using Learned Distance Gradient](https://arxiv.org/abs/2512.24272)
*Jiawei Zhang,Chengchao Bai,Wei Pan,Tianhang Liu,Jifeng Guo*

Main category: cs.RO

TL;DR: 提出了一种基于神经网络的最小距离预测方法，结合局部路径优化，显著提高了受限运动规划速度。


<details>
  <summary>Details</summary>
Motivation: 传统的受限运动规划面临路径有效性检查和重规划耗时的问题，尤其是由于流形近似误差和碰撞冲突识别困难。

Method: 使用神经网络预测机器人与障碍物之间的最小距离，并在潜在空间中进行局部路径优化。

Result: 与最先进的算法相比，在多个规划场景中展示了最快的规划速度。

Conclusion: 本文提出的方法能够有效减少路径重规划的时间，提高运动规划速度。

Abstract: Constrained motion planning is a common but challenging problem in robotic manipulation. In recent years, data-driven constrained motion planning algorithms have shown impressive planning speed and success rate. Among them, the latent motion method based on manifold approximation is the most efficient planning algorithm. Due to errors in manifold approximation and the difficulty in accurately identifying collision conflicts within the latent space, time-consuming path validity checks and path replanning are required. In this paper, we propose a method that trains a neural network to predict the minimum distance between the robot and obstacles using latent vectors as inputs. The learned distance gradient is then used to calculate the direction of movement in the latent space to move the robot away from obstacles. Based on this, a local path optimization algorithm in the latent space is proposed, and it is integrated with the path validity checking process to reduce the time of replanning. The proposed method is compared with state-of-the-art algorithms in multiple planning scenarios, demonstrating the fastest planning speed

</details>


### [12] [DRL-TH: Jointly Utilizing Temporal Graph Attention and Hierarchical Fusion for UGV Navigation in Crowded Environments](https://arxiv.org/abs/2512.24284)
*Ruitong Li,Lin Zhang,Yuenan Zhao,Chengxin Liu,Ran Song,Wei Zhang*

Main category: cs.RO

TL;DR: 提出了一种基于深度强化学习的新型导航框架DRL-TH，通过时间图注意力和分层图池化提高了无人地面车辆在拥挤环境中的导航和障碍物规避能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖单帧观察并采用简单的多模态融合方式，这限制了捕捉时序上下文的能力，影响了动态适应性。

Method: 提出了一种基于DRL的导航框架DRL-TH，利用时间图注意力和分层图池化来整合历史观察和适应性融合多模态信息。

Result: DRL-TH通过引入时间加权的图注意力网络和图分层抽象模块，实现了对RGB和激光雷达特征的动态集成，并在各种拥挤环境中表现优越。

Conclusion: 实验表明，DRL-TH在各种拥挤环境中优于现有方法，并在真实环境中表现良好。

Abstract: Deep reinforcement learning (DRL) methods have demonstrated potential for autonomous navigation and obstacle avoidance of unmanned ground vehicles (UGVs) in crowded environments. Most existing approaches rely on single-frame observation and employ simple concatenation for multi-modal fusion, which limits their ability to capture temporal context and hinders dynamic adaptability. To address these challenges, we propose a DRL-based navigation framework, DRL-TH, which leverages temporal graph attention and hierarchical graph pooling to integrate historical observations and adaptively fuse multi-modal information. Specifically, we introduce a temporal-guided graph attention network (TG-GAT) that incorporates temporal weights into attention scores to capture correlations between consecutive frames, thereby enabling the implicit estimation of scene evolution. In addition, we design a graph hierarchical abstraction module (GHAM) that applies hierarchical pooling and learnable weighted fusion to dynamically integrate RGB and LiDAR features, achieving balanced representation across multiple scales. Extensive experiments demonstrate that our DRL-TH outperforms existing methods in various crowded environments. We also implemented DRL-TH control policy on a real UGV and showed that it performed well in real world scenarios.

</details>


### [13] [Real-world Reinforcement Learning from Suboptimal Interventions](https://arxiv.org/abs/2512.24288)
*Yinuo Zhao,Huiqian Jin,Lechun Jiang,Xinyi Zhang,Kun Wu,Pei Ren,Zhiyuan Xu,Zhengping Che,Lei Sun,Dapeng Wu,Chi Harold Liu,Jian Tang*

Main category: cs.RO

TL;DR: SiLRI是一种新型的强化学习算法，能够有效利用人类的次优干预来加速机器人操控任务的学习，显著提高成功率。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习方法往往假设人类的干预是最佳的，但实际上即便是专家在所有状态下也无法提供最佳的动作，此研究旨在探索如何从潜在次优并带有噪声的人类干预中加速学习。

Method: 通过将在线操控问题公式化为一个约束强化学习优化问题，使用状态相关的拉格朗日乘子进行联合优化，最终达到鞍点。

Result: 提出的SiLRI算法通过考虑人类干预的不确定性，在各种操控任务中有效利用潜在的次优干预，缩短了达到高成功率所需的时间。

Conclusion: SiLRI算法在真实环境中的实验表明，它对人类的次优干预进行有效利用，使得在长时间操作任务中成功率达到了100%，而其他强化学习方法则难以达到这样的效果。

Abstract: Real-world reinforcement learning (RL) offers a promising approach to training precise and dexterous robotic manipulation policies in an online manner, enabling robots to learn from their own experience while gradually reducing human labor. However, prior real-world RL methods often assume that human interventions are optimal across the entire state space, overlooking the fact that even expert operators cannot consistently provide optimal actions in all states or completely avoid mistakes. Indiscriminately mixing intervention data with robot-collected data inherits the sample inefficiency of RL, while purely imitating intervention data can ultimately degrade the final performance achievable by RL. The question of how to leverage potentially suboptimal and noisy human interventions to accelerate learning without being constrained by them thus remains open. To address this challenge, we propose SiLRI, a state-wise Lagrangian reinforcement learning algorithm for real-world robot manipulation tasks. Specifically, we formulate the online manipulation problem as a constrained RL optimization, where the constraint bound at each state is determined by the uncertainty of human interventions. We then introduce a state-wise Lagrange multiplier and solve the problem via a min-max optimization, jointly optimizing the policy and the Lagrange multiplier to reach a saddle point. Built upon a human-as-copilot teleoperation system, our algorithm is evaluated through real-world experiments on diverse manipulation tasks. Experimental results show that SiLRI effectively exploits human suboptimal interventions, reducing the time required to reach a 90% success rate by at least 50% compared with the state-of-the-art RL method HIL-SERL, and achieving a 100% success rate on long-horizon manipulation tasks where other RL methods struggle to succeed. Project website: https://silri-rl.github.io/.

</details>


### [14] [World In Your Hands: A Large-Scale and Open-source Ecosystem for Learning Human-centric Manipulation in the Wild](https://arxiv.org/abs/2512.24310)
*TARS Robotics,Yuhang Zheng,Jichao Peng,Weize Li,Yupeng Zheng,Xiang Li,Yujie Jin,Julong Wei,Guanhua Zhang,Ruiling Zheng,Ming Cao,Songen Gu,Zhenhong Zou,Kaige Li,Ke Wu,Mingmin Yang,Jiahao Liu,Pengfei Li,Hengjie Si,Feiyu Zhu,Wang Fu,Likun Wang,Ruiwen Yao,Jieru Zhao,Yilun Chen,Wenchao Din*

Main category: cs.RO

TL;DR: WiYH是一个大型开源生态系统，旨在通过多模态的数据和标注集来提升人类操控学习，特别是在桌面操控任务中的应用效果显著提高。


<details>
  <summary>Details</summary>
Motivation: 当前的人类操控数据集在规模和多样性上存在不足，这限制了策略的泛化能力。

Method: 通过开发Oracle Suite可穿戴数据采集工具及WiYH数据集，收集超过1000小时的多模态操控数据，并提供广泛的注释和基准测试。

Result: 实验表明，利用WiYH的人类中心数据显著增强了灵巧手政策在桌面操控任务中的泛化能力和鲁棒性。

Conclusion: World In Your Hands (WiYH) improves dexterous hand manipulation policy learning through extensive and diverse datasets, enhancing generalization and robustness.

Abstract: Large-scale pre-training is fundamental for generalization in language and vision models, but data for dexterous hand manipulation remains limited in scale and diversity, hindering policy generalization. Limited scenario diversity, misaligned modalities, and insufficient benchmarking constrain current human manipulation datasets. To address these gaps, we introduce World In Your Hands (WiYH), a large-scale open-source ecosystem for human-centric manipulation learning. WiYH includes (1) the Oracle Suite, a wearable data collection kit with an auto-labeling pipeline for accurate motion capture; (2) the WiYH Dataset, featuring over 1,000 hours of multi-modal manipulation data across hundreds of skills in diverse real-world scenarios; and (3) extensive annotations and benchmarks supporting tasks from perception to action. Furthermore, experiments based on the WiYH ecosystem show that integrating WiYH's human-centric data significantly enhances the generalization and robustness of dexterous hand policies in tabletop manipulation tasks. We believe that World In Your Hands will bring new insights into human-centric data collection and policy learning to the community.

</details>


### [15] [3D Path-Following Guidance via Nonlinear Model Predictive Control for Fixed-Wing Small UAS](https://arxiv.org/abs/2512.24326)
*Camron Alexander Hirst,Chris Reale,Eric Frew*

Main category: cs.RO

TL;DR: 该论文展示了基于非线性模型预测控制的3D路径跟随引导算法，强调了其在小型无人机应用中的优越性。


<details>
  <summary>Details</summary>
Motivation: 设计和实现两种新型的3D路径跟随引导算法，以提高小型无源飞行器在复杂路径上的表现。

Method: 基于非线性模型预测控制(MPC)的方法，采用控制增强建模和系统识别技术，对小型无人机进行优化。

Result: 在高曲率测试路径上飞行并与基线前视引导法进行比较，结果显示非线性MPC在3D路径跟随引导上具备更优越的性能。

Conclusion: 该研究表明，非线性MPC算法在以高达36米每秒的速度进行3D路径跟随时，在真实世界中具有可行性和卓越性能。

Abstract: This paper presents the design, implementation, and flight test results of two novel 3D path-following guidance algorithms based on nonlinear model predictive control (MPC), with specific application to fixed-wing small uncrewed aircraft systems. To enable MPC, control-augmented modelling and system identification of the RAAVEN small uncrewed aircraft is presented. Two formulations of MPC are then showcased. The first schedules a static reference path rate over the MPC horizon, incentivizing a constant inertial speed. The second, with inspiration from model predictive contouring control, dynamically optimizes for the reference path rate over the controller horizon as the system operates. This allows for a weighted tradeoff between path progression and distance from path, two competing objectives in path-following guidance. Both controllers are formulated to operate over general smooth 3D arc-length parameterized curves. The MPC guidance algorithms are flown over several high-curvature test paths, with comparison to a baseline lookahead guidance law. The results showcase the real-world feasibility and superior performance of nonlinear MPC for 3D path-following guidance at ground speeds up to 36 meters per second.

</details>


### [16] [Geometric Multi-Session Map Merging with Learned Local Descriptors](https://arxiv.org/abs/2512.24384)
*Yanlong Ma,Nakul S. Joshi,Christa S. Robison,Philip R. Osteen,Brett T. Lopez*

Main category: cs.RO

TL;DR: 本文提出GMLD框架，针对大规模多会话点云地图合并，通过学习方法实现精准对齐和优化，显著提升地图合并的准确性和一致性。


<details>
  <summary>Details</summary>
Motivation: 为了解决在大规模环境中扩展自主操作时多会话地图合并的挑战，确保不同会话收集的地图在重叠区域进行系统对齐。

Method: 采用基于学习的本地描述子框架，通过关键点感知编码器和基于平面的几何变换器来提取特征，并在因子图优化阶段包含跨会话扫描匹配成本因子，以提高全局一致性。

Result: 在公开数据集和自收集的数据上进行评估，结果显示出低误差的准确和鲁棒的地图合并效果。

Conclusion: 通过在多种环境中测试，GMLD展示了在地图合并方面的准确性和鲁棒性，同时在环闭合检测和相对位姿估计中表现出色。

Abstract: Multi-session map merging is crucial for extended autonomous operations in large-scale environments. In this paper, we present GMLD, a learning-based local descriptor framework for large-scale multi-session point cloud map merging that systematically aligns maps collected across different sessions with overlapping regions. The proposed framework employs a keypoint-aware encoder and a plane-based geometric transformer to extract discriminative features for loop closure detection and relative pose estimation. To further improve global consistency, we include inter-session scan matching cost factors in the factor-graph optimization stage. We evaluate our framework on the public datasets, as well as self-collected data from diverse environments. The results show accurate and robust map merging with low error, and the learned features deliver strong performance in both loop closure detection and relative pose estimation.

</details>


### [17] [Fast and Realistic Automated Scenario Simulations and Reporting for an Autonomous Racing Stack](https://arxiv.org/abs/2512.24402)
*Giovanni Lambertini,Matteo Pini,Eugenio Mascaro,Francesco Moretti,Ayoub Raji,Marko Bertogna*

Main category: cs.RO

TL;DR: 本文提出了一种自动化仿真和报告流水线，旨在提高自主赛车技术的验证效率，通过高保真模型和故障注入，支持关键模块的有效验证。


<details>
  <summary>Details</summary>
Motivation: 开发一个自动化的仿真和报告流水线，以提高自主赛车技术的验证和分析效率。

Method: 基于高保真车辆模型构建的流水线，支持软件堆栈的实时仿真，并通过运行不同场景初始化自我车辆及堆栈配置，结合故障注入模块和自动报告流程。

Result: 该流水线能够以比实时快三倍的速度执行仿真和软件堆栈，能够有效验证关键模块，如高速超车和定位。

Conclusion: 通过该自动化流水线，可以更高效地验证和分析自主赛车系统，从而提高其可靠性和性能。

Abstract: In this paper, we describe the automated simulation and reporting pipeline implemented for our autonomous racing stack, ur.autopilot. The backbone of the simulation is based on a high-fidelity model of the vehicle interfaced as a Functional Mockup Unit (FMU). The pipeline can execute the software stack and the simulation up to three times faster than real-time, locally or on GitHub for Continuous Integration/- Continuous Delivery (CI/CD). As the most important input of the pipeline, there is a set of running scenarios. Each scenario allows the initialization of the ego vehicle in different initial conditions (position and speed), as well as the initialization of any other configuration of the stack. This functionality is essential to validate efficiently critical modules, like the one responsible for high-speed overtaking maneuvers or localization, which are among the most challenging aspects of autonomous racing. Moreover, we describe how we implemented a fault injection module, capable of introducing sensor delays and perturbations as well as modifying outputs of any node of the stack. Finally, we describe the design of our automated reporting process, aimed at maximizing the effectiveness of the simulation analysis.

</details>


### [18] [Counterfactual VLA: Self-Reflective Vision-Language-Action Model with Adaptive Reasoning](https://arxiv.org/abs/2512.24426)
*Zhenghao "Mark" Peng,Wenhao Ding,Yurong You,Yuxiao Chen,Wenjie Luo,Thomas Tian,Yulong Cao,Apoorva Sharma,Danfei Xu,Boris Ivanovic,Boyi Li,Bolei Zhou,Yan Wang,Marco Pavone*

Main category: cs.RO

TL;DR: CF-VLA是一种自我反思的VLA框架，通过反事实推理修正驾驶计划，显著提高轨迹精度和安全性。


<details>
  <summary>Details</summary>
Motivation: 尽管现有的VLA模型优化了解释性，但缺乏对计划行动安全性的反思和修正。 CF-VLA旨在填补这一空白。

Method: 提出了一种自我反思的VLA框架CF-VLA，生成数据驱动的时间分段元动作并进行反事实推理，以修正驱动意图。

Result: 在大规模驾驶数据集上的实验显示，CF-VLA的轨迹精确度提高了17.6%，安全性指标提升20.5%。

Conclusion: CF-VLA促进了自我反思的自主驾驶代理的发展，使其在行动前进行思考，从而提升了驾驶安全性和决策能力。

Abstract: Recent reasoning-augmented Vision-Language-Action (VLA) models have improved the interpretability of end-to-end autonomous driving by generating intermediate reasoning traces. Yet these models primarily describe what they perceive and intend to do, rarely questioning whether their planned actions are safe or appropriate. This work introduces Counterfactual VLA (CF-VLA), a self-reflective VLA framework that enables the model to reason about and revise its planned actions before execution. CF-VLA first generates time-segmented meta-actions that summarize driving intent, and then performs counterfactual reasoning conditioned on both the meta-actions and the visual context. This step simulates potential outcomes, identifies unsafe behaviors, and outputs corrected meta-actions that guide the final trajectory generation. To efficiently obtain such self-reflective capabilities, we propose a rollout-filter-label pipeline that mines high-value scenes from a base (non-counterfactual) VLA's rollouts and labels counterfactual reasoning traces for subsequent training rounds. Experiments on large-scale driving datasets show that CF-VLA improves trajectory accuracy by up to 17.6%, enhances safety metrics by 20.5%, and exhibits adaptive thinking: it only enables counterfactual reasoning in challenging scenarios. By transforming reasoning traces from one-shot descriptions to causal self-correction signals, CF-VLA takes a step toward self-reflective autonomous driving agents that learn to think before they act.

</details>


### [19] [Subsecond 3D Mesh Generation for Robot Manipulation](https://arxiv.org/abs/2512.24428)
*Qian Wang,Omar Abdellall,Tony Gao,Xiatao Sun,Daniel Rakita*

Main category: cs.RO

TL;DR: 本文提出了一种端到端的系统，从单个RGB-D图像中在不到一秒的时间内生成高质量的上下文相关3D网格，以解决自动3D网格生成的效率和上下文问题。


<details>
  <summary>Details</summary>
Motivation: 尽管近年来自动3D网格生成方法取得了进展，但生成高保真网格仍然缓慢，并且需要与场景上下文相结合。

Method: 采用端到端系统集成开放词汇物体分割、加速的基于扩散的网格生成和稳健的点云注册，优化速度和准确性。

Result: 该系统能够在一秒内从单个RGB-D图像生成高质量、上下文相关的3D网格。

Conclusion: 该系统显著提高了3D网格生成效率，使其在机器人感知和规划中具备了实用性，特别是在真实环境操作中展现了有效性。

Abstract: 3D meshes are a fundamental representation widely used in computer science and engineering. In robotics, they are particularly valuable because they capture objects in a form that aligns directly with how robots interact with the physical world, enabling core capabilities such as predicting stable grasps, detecting collisions, and simulating dynamics. Although automatic 3D mesh generation methods have shown promising progress in recent years, potentially offering a path toward real-time robot perception, two critical challenges remain. First, generating high-fidelity meshes is prohibitively slow for real-time use, often requiring tens of seconds per object. Second, mesh generation by itself is insufficient. In robotics, a mesh must be contextually grounded, i.e., correctly segmented from the scene and registered with the proper scale and pose. Additionally, unless these contextual grounding steps remain efficient, they simply introduce new bottlenecks. In this work, we introduce an end-to-end system that addresses these challenges, producing a high-quality, contextually grounded 3D mesh from a single RGB-D image in under one second. Our pipeline integrates open-vocabulary object segmentation, accelerated diffusion-based mesh generation, and robust point cloud registration, each optimized for both speed and accuracy. We demonstrate its effectiveness in a real-world manipulation task, showing that it enables meshes to be used as a practical, on-demand representation for robotics perception and planning.

</details>


### [20] [Foundation models on the bridge: Semantic hazard detection and safety maneuvers for maritime autonomy with vision-language models](https://arxiv.org/abs/2512.24470)
*Kim Alexander Christensen,Andreas Gudahl Tufte,Alexey Gusev,Rohan Sinha,Milan Ganai,Ole Andreas Alsos,Marco Pavoned,Martin Steinert*

Main category: cs.RO

TL;DR: 本研究提出的Semantic Lookout模型利用视觉-语言模型为自主航运提供语义意识，从而增强短期决策能力，符合IMO MASS代码的要求，并有效支持人类操作干预。


<details>
  <summary>Details</summary>
Motivation: 满足国际海事组织(IMO) MASS代码对自主和远程监督航运船只的要求，特别是在操作设计域内检测偏离情况并及时采取应对措施。

Method: 引入语义 lookout，一个基于相机的候选约束视觉-语言模型(VLM)后备机动选择器，通过短期人类可覆盖的机动来选择从水域有效、世界锚定轨迹中选择一种谨慎的动作或静止保持。

Result: 在40个港口场景中测量每次调用的场景理解和延迟，模型在火灾危险场景中的短期风险缓解及与人类共识的一致性等表现良好。结果表明，该后备机动选择器优于几何模型基准，并在火灾场景中提升了安全距离。

Conclusion: 这项研究支持 VLM 作为与 IMO MASS 代码兼容的语义后备机动选择器，具有实用延迟预算，并推动了未来的多传感器鸟瞰感觉与短期重新规划的混合自主研究。

Abstract: The draft IMO MASS Code requires autonomous and remotely supervised maritime vessels to detect departures from their operational design domain, enter a predefined fallback that notifies the operator, permit immediate human override, and avoid changing the voyage plan without approval. Meeting these obligations in the alert-to-takeover gap calls for a short-horizon, human-overridable fallback maneuver. Classical maritime autonomy stacks struggle when the correct action depends on meaning (e.g., diver-down flag means people in the water, fire close by means hazard). We argue (i) that vision-language models (VLMs) provide semantic awareness for such out-of-distribution situations, and (ii) that a fast-slow anomaly pipeline with a short-horizon, human-overridable fallback maneuver makes this practical in the handover window. We introduce Semantic Lookout, a camera-only, candidate-constrained vision-language model (VLM) fallback maneuver selector that selects one cautious action (or station-keeping) from water-valid, world-anchored trajectories under continuous human authority. On 40 harbor scenes we measure per-call scene understanding and latency, alignment with human consensus (model majority-of-three voting), short-horizon risk-relief on fire hazard scenes, and an on-water alert->fallback maneuver->operator handover. Sub-10 s models retain most of the awareness of slower state-of-the-art models. The fallback maneuver selector outperforms geometry-only baselines and increases standoff distance on fire scenes. A field run verifies end-to-end operation. These results support VLMs as semantic fallback maneuver selectors compatible with the draft IMO MASS Code, within practical latency budgets, and motivate future work on domain-adapted, hybrid autonomy that pairs foundation-model semantics with multi-sensor bird's-eye-view perception and short-horizon replanning.

</details>


### [21] [DISF: Disentangled Iterative Surface Fitting for Contact-stable Grasp Planning with Grasp Pose Alignment to the Object Center of Mass](https://arxiv.org/abs/2512.24550)
*Tomoya Yamanokuchi,Alberto Bacchin,Emilio Olivastri,Ryotaro Arifuku,Takamitsu Matsubara,Emanuele Menegatti*

Main category: cs.RO

TL;DR: 提出了一种新算法，通过优化抓取姿态的不同步骤，提高了接触点的稳定性和抓取成功率。


<details>
  <summary>Details</summary>
Motivation: 解决基于表面拟合的抓取规划算法在接触点分布稳定性方面的不足。

Method: 提出一种新的表面拟合算法，集成接触稳定性与几何兼容性，分解抓取姿态优化为旋转优化、平移细化和夹爪开口调整三个步骤。

Result: 在15个物体上进行仿真验证，包括已知形状和观察到的形状数据集，并在UR3e机器人上进行实物抓取实验。

Conclusion: DISF在保持几何兼容性的同时减少了质心误对齐，提高了仿真和现实世界执行中的抓取成功率。

Abstract: In this work, we address the limitation of surface fitting-based grasp planning algorithm, which primarily focuses on geometric alignment between the gripper and object surface while overlooking the stability of contact point distribution, often resulting in unstable grasps due to inadequate contact configurations. To overcome this limitation, we propose a novel surface fitting algorithm that integrates contact stability while preserving geometric compatibility. Inspired by human grasping behavior, our method disentangles the grasp pose optimization into three sequential steps: (1) rotation optimization to align contact normals, (2) translation refinement to improve the alignment between the gripper frame origin and the object Center of Mass (CoM), and (3) gripper aperture adjustment to optimize contact point distribution. We validate our approach in simulation across 15 objects under both Known-shape (with clean CAD-derived dataset) and Observed-shape (with YCB object dataset) settings, including cross-platform grasp execution on three robot--gripper platforms. We further validate the method in real-world grasp experiments on a UR3e robot. Overall, DISF reduces CoM misalignment while maintaining geometric compatibility, translating into higher grasp success in both simulation and real-world execution compared to baselines. Additional videos and supplementary results are available on our project page: https://tomoya-yamanokuchi.github.io/disf-ras-project-page/

</details>


### [22] [Resolving State Ambiguity in Robot Manipulation via Adaptive Working Memory Recoding](https://arxiv.org/abs/2512.24638)
*Qingda Hu,Ziheng Qiu,Zijun Xu,Kaizhao Zhang,Xizhou Bu,Zuolei Sun,Bo Zhang,Jieru Zhao,Zhongxue Gan,Wenchao Ding*

Main category: cs.RO

TL;DR: 本文提出了一种新型的视觉运动策略PAM，通过自适应工作记忆和分层框架特征提取，解决了机器人操作中的状态模糊性问题。


<details>
  <summary>Details</summary>
Motivation: 机器人操作中常见的状态模糊性使得相同的观察结果可能对应多个有效的行为轨迹，现有方法存在计算成本高和过拟合的问题。

Method: 采用两阶段的训练方式，设计了分层框架特征提取器和上下文路由器，以支持300帧的历史窗口同时维持高推理速度。

Result: 引入了PAM，一个具有自适应工作记忆的视觉运动策略，能够在机器人操作中有效处理状态模糊性。

Conclusion: PAM通过设计上下文路由器和辅助目标，有效地提取信息，实现了稳定的训练和高效的推理速度。

Abstract: State ambiguity is common in robotic manipulation. Identical observations may correspond to multiple valid behavior trajectories. The visuomotor policy must correctly extract the appropriate types and levels of information from the history to identify the current task phase. However, naively extending the history window is computationally expensive and may cause severe overfitting. Inspired by the continuous nature of human reasoning and the recoding of working memory, we introduce PAM, a novel visuomotor Policy equipped with Adaptive working Memory. With minimal additional training cost in a two-stage manner, PAM supports a 300-frame history window while maintaining high inference speed. Specifically, a hierarchical frame feature extractor yields two distinct representations for motion primitives and temporal disambiguation. For compact representation, a context router with range-specific queries is employed to produce compact context features across multiple history lengths. And an auxiliary objective of reconstructing historical information is introduced to ensure that the context router acts as an effective bottleneck. We meticulously design 7 tasks and verify that PAM can handle multiple scenarios of state ambiguity simultaneously. With a history window of approximately 10 seconds, PAM still supports stable training and maintains inference speeds above 20Hz. Project website: https://tinda24.github.io/pam/

</details>


### [23] [Hybrid Motion Planning with Deep Reinforcement Learning for Mobile Robot Navigation](https://arxiv.org/abs/2512.24651)
*Yury Kolomeytsev,Dmitry Golembiovsky*

Main category: cs.RO

TL;DR: 提出了一种混合运动规划方法HMP-DRL，通过图形算法与深度强化学习结合，能够在复杂环境中优化机器人导航。


<details>
  <summary>Details</summary>
Motivation: 面对复杂、动态环境中的自主移动机器人需同时应对大型多样化空间的导航与与移动体的安全交互。

Method: HMP-DRL方法利用图形算法的全局规划生成路径，并通过编码状态空间和奖励函数的检查点将其集成入局部DRL策略。

Result: 实验证明HMP-DRL在成功率、碰撞率和到达目标时间等关键指标上优于其他现有方法。

Conclusion: HMP-DRL在自主导航的安全性和可靠性方面显著提升，结合了长远路径指导与语义感知的局部控制。

Abstract: Autonomous mobile robots operating in complex, dynamic environments face the dual challenge of navigating large-scale, structurally diverse spaces with static obstacles while safely interacting with various moving agents. Traditional graph-based planners excel at long-range pathfinding but lack reactivity, while Deep Reinforcement Learning (DRL) methods demonstrate strong collision avoidance but often fail to reach distant goals due to a lack of global context. We propose Hybrid Motion Planning with Deep Reinforcement Learning (HMP-DRL), a hybrid framework that bridges this gap. Our approach utilizes a graph-based global planner to generate a path, which is integrated into a local DRL policy via a sequence of checkpoints encoded in both the state space and reward function. To ensure social compliance, the local planner employs an entity-aware reward structure that dynamically adjusts safety margins and penalties based on the semantic type of surrounding agents. We validate the proposed method through extensive testing in a realistic simulation environment derived from real-world map data. Comprehensive experiments demonstrate that HMP-DRL consistently outperforms other methods, including state-of-the-art approaches, in terms of key metrics of robot navigation: success rate, collision rate, and time to reach the goal. Overall, these findings confirm that integrating long-term path guidance with semantically-aware local control significantly enhances both the safety and reliability of autonomous navigation in complex human-centric settings.

</details>


### [24] [RoboMIND 2.0: A Multimodal, Bimanual Mobile Manipulation Dataset for Generalizable Embodied Intelligence](https://arxiv.org/abs/2512.24653)
*Chengkai Hou,Kun Wu,Jiaming Liu,Zhengping Che,Di Wu,Fei Liao,Guangrun Li,Jingyang He,Qiuxuan Feng,Zhao Jin,Chenyang Gu,Zhuoyang Liu,Nuowei Han,Xiangju Mi,Yaoxu Lv,Yankai Fu,Gaole Dai,Langzhe Gu,Tao Li,Yuheng Zhang,Yixue Zhang,Xinhua Wang,Shichao Fan,Meng Li,Zhen Zhao,Ning Liu,Zhiyuan Xu,Pei Ren,Junjie Ji,Haonan Liu,Kuan Cheng,Shanghang Zhang,Jian Tang*

Main category: cs.RO

TL;DR: RoboMIND 2.0是一个大型数据集，旨在提高机器人双臂操作和移动操作的泛化能力，并提出了MIND-2系统以优化这一过程。


<details>
  <summary>Details</summary>
Motivation: 当前数据驱动的模仿学习在机器人操作方面受到实际演示匮乏的限制，模型的泛化能力不足。

Method: 推出RoboMIND 2.0数据集，包含310K个双臂操作轨迹和高保真数字双胞胎环境，结合MIND-2系统进行优化。

Result: RoboMIND 2.0数据集包括多种操作轨迹，具有较强的应用潜力，同时MIND-2系统高效地将指令转化为实际动作。

Conclusion: RoboMIND 2.0及MIND-2系统为机器人在复杂环境中的操作提供了新的研究基础，促进了机器人学习的进一步发展。

Abstract: While data-driven imitation learning has revolutionized robotic manipulation, current approaches remain constrained by the scarcity of large-scale, diverse real-world demonstrations. Consequently, the ability of existing models to generalize across long-horizon bimanual tasks and mobile manipulation in unstructured environments remains limited. To bridge this gap, we present RoboMIND 2.0, a comprehensive real-world dataset comprising over 310K dual-arm manipulation trajectories collected across six distinct robot embodiments and 739 complex tasks. Crucially, to support research in contact-rich and spatially extended tasks, the dataset incorporates 12K tactile-enhanced episodes and 20K mobile manipulation trajectories. Complementing this physical data, we construct high-fidelity digital twins of our real-world environments, releasing an additional 20K-trajectory simulated dataset to facilitate robust sim-to-real transfer. To fully exploit the potential of RoboMIND 2.0, we propose MIND-2 system, a hierarchical dual-system frame-work optimized via offline reinforcement learning. MIND-2 integrates a high-level semantic planner (MIND-2-VLM) to decompose abstract natural language instructions into grounded subgoals, coupled with a low-level Vision-Language-Action executor (MIND-2-VLA), which generates precise, proprioception-aware motor actions.

</details>


### [25] [Antagonistic Bowden-Cable Actuation of a Lightweight Robotic Hand: Toward Dexterous Manipulation for Payload Constrained Humanoids](https://arxiv.org/abs/2512.24657)
*Sungjae Min,Hyungjoo Kim,David Hyunchul Shim*

Main category: cs.RO

TL;DR: 本研究提出了一种轻量级的Bowden电缆驱动人形手，通过优化设计实现了高效的抓取能力，满足了人形机器人的多重性能需求。


<details>
  <summary>Details</summary>
Motivation: 实现与人类手相似的灵活性与力量，对于人形机器人在各种环境中的应用至关重要。

Method: 采用Bowden电缆驱动的轻量型人形手，结合滚动接触关节优化与对抗性电缆驱动，实现单电机控制，减少了系统的整体质量。

Result: 手部组件在不使用远程驱动器和Bowden外套的情况下达到了236克的质量，能够完成超过18N的指尖力量，提升的载荷超过自身质量的百倍，显示出极高的任务执行能力和鲁棒性。

Conclusion: 该轻量级人形手成功实现了高抓握力与高灵活度，并能够在不增加整体质量的情况下，执行复杂的抓取任务。

Abstract: Humanoid robots toward human-level dexterity require robotic hands capable of simultaneously providing high grasping force, rapid actuation speeds, multiple degrees of freedom, and lightweight structures within human-like size constraints. Meeting these conflicting requirements remains challenging, as satisfying this combination typically necessitates heavier actuators and bulkier transmission systems, significantly restricting the payload capacity of robot arms. In this letter, we present a lightweight anthropomorphic hand actuated by Bowden cables, which uniquely combines rolling-contact joint optimization with antagonistic cable actuation, enabling single-motor-per-joint control with negligible cable-length deviation. By relocating the actuator module to the torso, the design substantially reduces distal mass while maintaining anthropomorphic scale and dexterity. Additionally, this antagonistic cable actuation eliminates the need for synchronization between motors. Using the proposed methods, the hand assembly with a distal mass of 236g (excluding remote actuators and Bowden sheaths) demonstrated reliable execution of dexterous tasks, exceeding 18N fingertip force and lifting payloads over one hundred times its own mass. Furthermore, robustness was validated through Cutkosky taxonomy grasps and trajectory consistency under perturbed actuator-hand transformations.

</details>


### [26] [VLA-RAIL: A Real-Time Asynchronous Inference Linker for VLA Models and Robots](https://arxiv.org/abs/2512.24673)
*Yongsheng Zhao,Lei Zhao,Baoping Cheng,Gongxin Yao,Xuanzhang Wen,Han Gao*

Main category: cs.RO

TL;DR: 本论文提出VLA-RAIL，一个新框架，通过异步推理和运动控制解决运动抖动和速度问题，提升VLA模型的整体性能。


<details>
  <summary>Details</summary>
Motivation: 在机器人运动控制中，已有方法存在抖动、停顿等问题，影响执行速度和任务成功率。

Method: 提出了VLA-RAIL框架，其中包含一个采用多项式拟合的轨迹平滑器和一个对齐当前执行轨迹与新到达动作块的块融合器。

Result: VLA-RAIL在动态仿真任务和实际操作任务中验证了其有效性，证明其能够实现平滑、连续和高速的动作执行。

Conclusion: VLA-RAIL显著减少了运动抖动，提高了执行速度，改善了任务成功率，为VLA模型的大规模应用奠定了关键基础。

Abstract: Vision-Language-Action (VLA) models have achieved remarkable breakthroughs in robotics, with the action chunk playing a dominant role in these advances. Given the real-time and continuous nature of robotic motion control, the strategies for fusing a queue of successive action chunks have a profound impact on the overall performance of VLA models. Existing methods suffer from jitter, stalling, or even pauses in robotic action execution, which not only limits the achievable execution speed but also reduces the overall success rate of task completion. This paper introduces VLA-RAIL (A Real-Time Asynchronous Inference Linker), a novel framework designed to address these issues by conducting model inference and robot motion control asynchronously and guaranteeing smooth, continuous, and high-speed action execution. The core contributions of the paper are two fold: a Trajectory Smoother that effectively filters out the noise and jitter in the trajectory of one action chunk using polynomial fitting and a Chunk Fuser that seamlessly align the current executing trajectory and the newly arrived chunk, ensuring position, velocity, and acceleration continuity between two successive action chunks. We validate the effectiveness of VLA-RAIL on a benchmark of dynamic simulation tasks and several real-world manipulation tasks. Experimental results demonstrate that VLA-RAIL significantly reduces motion jitter, enhances execution speed, and improves task success rates, which will become a key infrastructure for the large-scale deployment of VLA models.

</details>


### [27] [ReSPIRe: Informative and Reusable Belief Tree Search for Robot Probabilistic Search and Tracking in Unknown Environments](https://arxiv.org/abs/2512.24680)
*Kangjie Zhou,Zhaoyang Li,Han Gao,Yao Su,Hangxin Liu,Junzhi Yu,Chang Liu*

Main category: cs.RO

TL;DR: 本研究提出ReSPIRe，一种针对不确定性下的目标搜索与跟踪的新颖轨迹规划方法，具有更高的搜索效率和稳定性。


<details>
  <summary>Details</summary>
Motivation: 目标搜索与跟踪在机器人应用中至关重要，但现有方法在不准确先验信息和限制感知视野的情况下表现欠佳。

Method: 该方法使用了基于sigma点的近似技术、分层粒子结构和可重用信念树搜索来提高规划效率和降低计算复杂度。

Result: ReSPIRe方法在未知杂乱环境中进行目标搜索和跟踪，能够有效处理不准确的先验目标信息和有限的感知视野。

Conclusion: 通过创新的方法，ReSPIRe在目标搜索和跟踪中实现了更高的效率和更稳定的表现，优于传统方法。

Abstract: Target search and tracking (SAT) is a fundamental problem for various robotic applications such as search and rescue and environmental exploration. This paper proposes an informative trajectory planning approach, namely ReSPIRe, for SAT in unknown cluttered environments under considerably inaccurate prior target information and limited sensing field of view. We first develop a novel sigma point-based approximation approach to fast and accurately estimate mutual information reward under non-Gaussian belief distributions, utilizing informative sampling in state and observation spaces to mitigate the computational intractability of integral calculation. To tackle significant uncertainty associated with inadequate prior target information, we propose the hierarchical particle structure in ReSPIRe, which not only extracts critical particles for global route guidance, but also adjusts the particle number adaptively for planning efficiency. Building upon the hierarchical structure, we develop the reusable belief tree search approach to build a policy tree for online trajectory planning under uncertainty, which reuses rollout evaluation to improve planning efficiency. Extensive simulations and real-world experiments demonstrate that ReSPIRe outperforms representative benchmark methods with smaller MI approximation error, higher search efficiency, and more stable tracking performance, while maintaining outstanding computational efficiency.

</details>


### [28] [CREPES-X: Hierarchical Bearing-Distance-Inertial Direct Cooperative Relative Pose Estimation System](https://arxiv.org/abs/2512.24688)
*Zhehan Li,Zheng Wang,Jiadong Lu,Qi Liu,Zhiren Xun,Yue Wang,Fei Gao,Chao Xu,Yanjun Cao*

Main category: cs.RO

TL;DR: CREPES-X是一种新型的层次化相对定位框架，旨在提升多机器人系统在复杂环境中的速度、准确性和鲁棒性，且不依赖于全局信息。


<details>
  <summary>Details</summary>
Motivation: 在自主多机器人系统中，相对定位对于合作至关重要，但现有方法面临共享环境特征、惯性假设以及在复杂环境中遭遇的非视距衰减和异常值等挑战。

Method: CREPES-X采用紧凑的硬件设计和两阶段的层次估计器，首先通过单帧相对估计器提供即时位置，其次通过多帧相对估计器结合IMU预积分来优化准确性和鲁棒性。

Result: CREPES-X经过广泛的仿真和实地实验验证，在高达90%的异常值下仍能保持鲁棒性，实现了真实数据集中的均方根误差为0.073m和角度误差为1.817°的结果。

Conclusion: CREPES-X在没有全局信息的复杂条件下，展示了卓越的定位性能，适用于多机器人系统的合作任务。

Abstract: Relative localization is critical for cooperation in autonomous multi-robot systems. Existing approaches either rely on shared environmental features or inertial assumptions or suffer from non-line-of-sight degradation and outliers in complex environments. Robust and efficient fusion of inter-robot measurements such as bearings, distances, and inertials for tens of robots remains challenging. We present CREPES-X (Cooperative RElative Pose Estimation System with multiple eXtended features), a hierarchical relative localization framework that enhances speed, accuracy, and robustness under challenging conditions, without requiring any global information. CREPES-X starts with a compact hardware design: InfraRed (IR) LEDs, an IR camera, an ultra-wideband module, and an IMU housed in a cube no larger than 6cm on each side. Then CREPES-X implements a two-stage hierarchical estimator to meet different requirements, considering speed, accuracy, and robustness. First, we propose a single-frame relative estimator that provides instant relative poses for multi-robot setups through a closed-form solution and robust bearing outlier rejection. Then a multi-frame relative estimator is designed to offer accurate and robust relative states by exploring IMU pre-integration via robocentric relative kinematics with loosely- and tightly-coupled optimization. Extensive simulations and real-world experiments validate the effectiveness of CREPES-X, showing robustness to up to 90% bearing outliers, proving resilience in challenging conditions, and achieving RMSE of 0.073m and 1.817° in real-world datasets.

</details>


### [29] [Dynamic Policy Learning for Legged Robot with Simplified Model Pretraining and Model Homotopy Transfer](https://arxiv.org/abs/2512.24698)
*Dongyun Kang,Min-Gyu Kim,Tae-Gyu Song,Hajun Kim,Sehoon Ha,Hae-Won Park*

Main category: cs.RO

TL;DR: 本研究提出了一种结合预训练和模型同伦转移的持续学习框架，旨在高效生成四足机器人的动态动作，经过验证显示出优秀的性能和稳定性。


<details>
  <summary>Details</summary>
Motivation: 生成动态动作对于四足机器人来说是一个具有挑战性的问题，强化学习在腿部运动任务中取得了显著成功，但生成高度动态的行为通常需要广泛的奖励调整或高质量的演示。

Method: 提出了一种基于持续学习的框架，结合简化模型的预训练和模型同伦转移，以有效生成和精炼复杂的动态行为。首先，用单一刚体模型对策略进行预训练，以捕捉简化环境中的核心运动模式。然后，采用持续策略逐步将策略转移到全身环境，最小化性能损失。

Result: 提出的方法在动态任务（如翻转和墙辅助操作）中验证，且在转移过程中相比基线方法展现出更快的收敛性和更好的稳定性。

Conclusion: 该框架成功地在实际的四足机器人上部署，实现了高效的动态行为生成。

Abstract: Generating dynamic motions for legged robots remains a challenging problem. While reinforcement learning has achieved notable success in various legged locomotion tasks, producing highly dynamic behaviors often requires extensive reward tuning or high-quality demonstrations. Leveraging reduced-order models can help mitigate these challenges. However, the model discrepancy poses a significant challenge when transferring policies to full-body dynamics environments. In this work, we introduce a continuation-based learning framework that combines simplified model pretraining and model homotopy transfer to efficiently generate and refine complex dynamic behaviors. First, we pretrain the policy using a single rigid body model to capture core motion patterns in a simplified environment. Next, we employ a continuation strategy to progressively transfer the policy to the full-body environment, minimizing performance loss. To define the continuation path, we introduce a model homotopy from the single rigid body model to the full-body model by gradually redistributing mass and inertia between the trunk and legs. The proposed method not only achieves faster convergence but also demonstrates superior stability during the transfer process compared to baseline methods. Our framework is validated on a range of dynamic tasks, including flips and wall-assisted maneuvers, and is successfully deployed on a real quadrupedal robot.

</details>


### [30] [LSRE: Latent Semantic Rule Encoding for Real-Time Semantic Risk Detection in Autonomous Driving](https://arxiv.org/abs/2512.24712)
*Qian Cheng,Weitao Zhou,Cheng Jing,Nanshan Deng,Junze Wen,Zhaoyang Liu,Kun Jiang,Diange Yang*

Main category: cs.RO

TL;DR: 本研究提出了一种名为LSRE的框架，能够在自主驾驶中实时进行语义风险评估，同时保持低延迟和高准确性。


<details>
  <summary>Details</summary>
Motivation: 自主驾驶需要遵循复杂的人类社会规则，这些规则超越了法律法规，传统的方法难以明确编码这些语义约束。

Method: LSRE框架将稀疏采样的视觉-语言模型（VLM）判断转换为递归世界模型的潜在空间中的决策边界，利用轻量级的潜在分类器进行实时风险评估。

Result: 在CARLA环境下进行的实验显示，LSRE在六种语义故障场景中实现了与大型VLM基线相当的语义风险检测准确性，并提前预测危险，同时保持低计算延迟。

Conclusion: LSRE为自主驾驶中的语义安全监测提供了一种有效和可部署的机制，能够很好地推广到罕见的语义相似测试案例。

Abstract: Real-world autonomous driving must adhere to complex human social rules that extend beyond legally codified traffic regulations. Many of these semantic constraints, such as yielding to emergency vehicles, complying with traffic officers' gestures, or stopping for school buses, are intuitive for humans yet difficult to encode explicitly. Although large vision-language models (VLMs) can interpret such semantics, their inference cost makes them impractical for real-time deployment.This work proposes LSRE, a Latent Semantic Rule Encoding framework that converts sparsely sampled VLM judgments into decision boundaries within the latent space of a recurrent world model. By encoding language-defined safety semantics into a lightweight latent classifier, LSRE enables real-time semantic risk assessment at 10 Hz without per-frame VLM queries. Experiments on six semantic-failure scenarios in CARLA demonstrate that LSRE attains semantic risk detection accuracy comparable to a large VLM baseline, while providing substantially earlier hazard anticipation and maintaining low computational latency. LSRE further generalizes to rarely seen semantic-similar test cases, indicating that language-guided latent classification offers an effective and deployable mechanism for semantic safety monitoring in autonomous driving.

</details>


### [31] [Control of Microrobots with Reinforcement Learning under On-Device Compute Constraints](https://arxiv.org/abs/2512.24740)
*Yichen Liu,Kesava Viswanadha,Zhongyu Li,Nelson Lojo,Kristofer S. J. Pister*

Main category: cs.RO

TL;DR: 本研究探讨了如何在硬件资源受限条件下，通过强化学习和控制算法优化微型四足机器人的运动，提升其在现实环境中的稳定性。


<details>
  <summary>Details</summary>
Motivation: 研究如何在硬件限制下，提高微型机器人的运动控制能力，满足低延迟和低能耗的需求。

Method: 采用强化学习训练紧凑的多层感知器控制策略，并通过硬件量化和领域随机化提高其在资源有限的硬件上的推理能力。

Result: 成功在资源受限的ARM Cortex-M0微控制器上实现了优化的MLP控制策略，并在不平坦地形上验证了其稳定性。

Conclusion: 通过对称运动调度，能在有限的硬件资源下有效控制微型四足机器人，在真实环境中实现更稳定的转移学习。

Abstract: An important function of autonomous microrobots is the ability to perform robust movement over terrain. This paper explores an edge ML approach to microrobot locomotion, allowing for on-device, lower latency control under compute, memory, and power constraints. This paper explores the locomotion of a sub-centimeter quadrupedal microrobot via reinforcement learning (RL) and deploys the resulting controller on an ultra-small system-on-chip (SoC), SC$μ$M-3C, featuring an ARM Cortex-M0 microcontroller running at 5 MHz. We train a compact FP32 multilayer perceptron (MLP) policy with two hidden layers ($[128, 64]$) in a massively parallel GPU simulation and enhance robustness by utilizing domain randomization over simulation parameters. We then study integer (Int8) quantization (per-tensor and per-feature) to allow for higher inference update rates on our resource-limited hardware, and we connect hardware power budgets to achievable update frequency via a cycles-per-update model for inference on our Cortex-M0. We propose a resource-aware gait scheduling viewpoint: given a device power budget, we can select the gait mode (trot/intermediate/gallop) that maximizes expected RL reward at a corresponding feasible update frequency. Finally, we deploy our MLP policy on a real-world large-scale robot on uneven terrain, qualitatively noting that domain-randomized training can improve out-of-distribution stability. We do not claim real-world large-robot empirical zero-shot transfer in this work.

</details>


### [32] [Dream2Flow: Bridging Video Generation and Open-World Manipulation with 3D Object Flow](https://arxiv.org/abs/2512.24766)
*Karthik Dharmarajan,Wenlong Huang,Jiajun Wu,Li Fei-Fei,Ruohan Zhang*

Main category: cs.RO

TL;DR: Dream2Flow是一个将视频生成和机器人控制连接的框架，通过3D物体流实现低级动作的生成，支持多种物体的操控。


<details>
  <summary>Details</summary>
Motivation: 解决生成性视频模型与机器人的低级动作之间的转换难题，以实现更高效的开放世界操作。

Method: 通过3D物体流重构物体运动，并将操作表述为物体轨迹跟踪，从而实现从生成视频到可执行低级命令的转化。

Result: 提出了一种新的框架Dream2Flow，该框架能够将生成性视频模型与机器人控制连接起来，通过3D物体流的中介表示，实现开放世界下的物体操作。

Conclusion: Dream2Flow成功地将人类引导的动作与机器人系统的低级动作进行了有效转换，展现了在没有任务特定演示的情况下进行开放世界操作的潜力。

Abstract: Generative video modeling has emerged as a compelling tool to zero-shot reason about plausible physical interactions for open-world manipulation. Yet, it remains a challenge to translate such human-led motions into the low-level actions demanded by robotic systems. We observe that given an initial image and task instruction, these models excel at synthesizing sensible object motions. Thus, we introduce Dream2Flow, a framework that bridges video generation and robotic control through 3D object flow as an intermediate representation. Our method reconstructs 3D object motions from generated videos and formulates manipulation as object trajectory tracking. By separating the state changes from the actuators that realize those changes, Dream2Flow overcomes the embodiment gap and enables zero-shot guidance from pre-trained video models to manipulate objects of diverse categories-including rigid, articulated, deformable, and granular. Through trajectory optimization or reinforcement learning, Dream2Flow converts reconstructed 3D object flow into executable low-level commands without task-specific demonstrations. Simulation and real-world experiments highlight 3D object flow as a general and scalable interface for adapting video generation models to open-world robotic manipulation. Videos and visualizations are available at https://dream2flow.github.io/.

</details>


### [33] [ArtiSG: Functional 3D Scene Graph Construction via Human-demonstrated Articulated Objects Manipulation](https://arxiv.org/abs/2512.24845)
*Qiuyi Gu,Yuze Sheng,Jincheng Yu,Jiahao Tang,Xiaolong Shan,Zhaoyang Shen,Tinghao Yi,Xiaodan Liang,Xinlei Chen,Yu Wang*

Main category: cs.RO

TL;DR: 本研究提出了ArtiSG框架，通过将人类示范编码为结构化的机器人记忆，构建功能性3D场景图，以提升机器人对关节物体的操作能力。


<details>
  <summary>Details</summary>
Motivation: 现有的3D场景图缺乏对物理操作所需的功能信息，尤其是关节物体的处理。

Method: 我们提出ArtiSG框架，利用便携设置的强大关节数据收集管道，准确估计关节轨迹和轴心，并将运动学先验整合到分层开口词汇图中，同时利用交互数据发现被视觉感知遗漏的功能元素。

Result: 大量真实世界实验表明，ArtiSG在功能元素召回和关节估计精度上显著优于基线。

Conclusion: 构建的图作为可靠的功能记忆，有效指导机器人在包含多样化关节物体的现实环境中执行语言指令的操作任务。

Abstract: 3D scene graphs have empowered robots with semantic understanding for navigation and planning, yet they often lack the functional information required for physical manipulation, particularly regarding articulated objects. Existing approaches for inferring articulation mechanisms from static observations are prone to visual ambiguity, while methods that estimate parameters from state changes typically rely on constrained settings such as fixed cameras and unobstructed views. Furthermore, fine-grained functional elements like small handles are frequently missed by general object detectors. To bridge this gap, we present ArtiSG, a framework that constructs functional 3D scene graphs by encoding human demonstrations into structured robotic memory. Our approach leverages a robust articulation data collection pipeline utilizing a portable setup to accurately estimate 6-DoF articulation trajectories and axes even under camera ego-motion. We integrate these kinematic priors into a hierarchical and open-vocabulary graph while utilizing interaction data to discover inconspicuous functional elements missed by visual perception. Extensive real-world experiments demonstrate that ArtiSG significantly outperforms baselines in functional element recall and articulation estimation precision. Moreover, we show that the constructed graph serves as a reliable functional memory that effectively guides robots to perform language-directed manipulation tasks in real-world environments containing diverse articulated objects.

</details>


### [34] [Hierarchical Deformation Planning and Neural Tracking for DLOs in Constrained Environments](https://arxiv.org/abs/2512.24974)
*Yunxi Tang,Tianqi Yang,Jing Huang,Xiangyu Chu,Kwok Wai Samuel Au*

Main category: cs.RO

TL;DR: 提出了一种新颖的框架用于受限环境中的变形线性物体(GLO)操作，结合了层次化变形规划与神经跟踪，解决了高维状态空间和复杂变形动态带来的挑战。


<details>
  <summary>Details</summary>
Motivation: 变形线性物体的操作面临高维状态空间和复杂变形动态的挑战，尤其是在障碍物密集的现实工作环境中，迫切需要高效的变形规划和稳健的变形跟踪方法。

Method: 框架结合了层次化变形规划和神经跟踪。变形规划器生成满足同伦约束的空间路径集，并应用路径集引导的优化方法合成最佳时序变形序列。使用基于数据驱动的变形模型的神经模型预测控制方法来准确跟踪计划的DLO变形序列。

Result: 通过在多种受限DLO操作任务中的验证，展示了所提框架在变形合成和跟踪方面的有效性。

Conclusion: 该框架在多种受限DLO操作任务中得到了有效验证，显示出其在全局形变合成和局部形变跟踪方面的可靠性能。

Abstract: Deformable linear objects (DLOs) manipulation presents significant challenges due to DLOs' inherent high-dimensional state space and complex deformation dynamics. The wide-populated obstacles in realistic workspaces further complicate DLO manipulation, necessitating efficient deformation planning and robust deformation tracking. In this work, we propose a novel framework for DLO manipulation in constrained environments. This framework combines hierarchical deformation planning with neural tracking, ensuring reliable performance in both global deformation synthesis and local deformation tracking. Specifically, the deformation planner begins by generating a spatial path set that inherently satisfies the homotopic constraints associated with DLO keypoint paths. Next, a path-set-guided optimization method is applied to synthesize an optimal temporal deformation sequence for the DLO. In manipulation execution, a neural model predictive control approach, leveraging a data-driven deformation model, is designed to accurately track the planned DLO deformation sequence. The effectiveness of the proposed framework is validated in extensive constrained DLO manipulation tasks.

</details>


### [35] [Coordinated Humanoid Manipulation with Choice Policies](https://arxiv.org/abs/2512.25072)
*Haozhi Qi,Yen-Jen Wang,Toru Lin,Brent Yi,Yi Ma,Koushil Sreenath,Jitendra Malik*

Main category: cs.RO

TL;DR: 本研究提出了一种模块化遥操作和模仿学习结合的方法，显著提升类人机器人的整体协调能力。


<details>
  <summary>Details</summary>
Motivation: 在以人为中心的环境中，类人机器人操作的潜力巨大，但实现头部、手和腿之间的整体协调仍然是一个主要挑战。

Method: 我们提出了一种将模块化遥操作接口与可扩展学习框架结合的系统，利用模块化设计分解类人控制为直观的子模块，包括手眼协调、抓取原语、臂末端执行器跟踪和 locomotion。引入了Choice Policy，一种模仿学习方法，生成多个候选动作并对其进行评分。

Result: Choice Policy显著优于扩散策略和标准行为克隆，且手眼协调对成功完成长时间任务至关重要。

Conclusion: 我们的工作展示了在非结构化环境中，面向协调类人操作的数据收集和学习的可行路径。

Abstract: Humanoid robots hold great promise for operating in human-centric environments, yet achieving robust whole-body coordination across the head, hands, and legs remains a major challenge. We present a system that combines a modular teleoperation interface with a scalable learning framework to address this problem. Our teleoperation design decomposes humanoid control into intuitive submodules, which include hand-eye coordination, grasp primitives, arm end-effector tracking, and locomotion. This modularity allows us to collect high-quality demonstrations efficiently. Building on this, we introduce Choice Policy, an imitation learning approach that generates multiple candidate actions and learns to score them. This architecture enables both fast inference and effective modeling of multimodal behaviors. We validate our approach on two real-world tasks: dishwasher loading and whole-body loco-manipulation for whiteboard wiping. Experiments show that Choice Policy significantly outperforms diffusion policies and standard behavior cloning. Furthermore, our results indicate that hand-eye coordination is critical for success in long-horizon tasks. Our work demonstrates a practical path toward scalable data collection and learning for coordinated humanoid manipulation in unstructured environments.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [36] [Seeking Late Night Life Lines: Experiences of Conversational AI Use in Mental Health Crisis](https://arxiv.org/abs/2512.23859)
*Leah Hope Ajmani,Arka Ghosh,Benjamin Kaveladze,Eugenia Kim,Keertana Namuduri,Theresa Nguyen,Ebele Okoli,Jessica Schleider,Denae Ford,Jina Suh*

Main category: cs.HC

TL;DR: 研究探讨了人们在心理健康危机中如何使用AI代理，强调了人际支持的重要性，建议设计AI时要促进人际连接而非替代。


<details>
  <summary>Details</summary>
Motivation: 探索AI代理在极端心理健康危机中的潜力，并寻找促进人际支持的设计方向。

Method: 通过第一人称经验的调查和专家访谈

Result: 调查发现人们在心理健康危机中使用AI代理进行支持，主要是因为缺乏心理健康专业人士或担忧给他人带来负担；专家意见指出人际连接在心理健康危机管理中的重要性。

Conclusion: 设计会话AI代理应作为人际连接的桥梁，而非单独的解决方案，以提升用户采取积极行动的准备程度。

Abstract: Online, people often recount their experiences turning to conversational AI agents (e.g., ChatGPT, Claude, Copilot) for mental health support -- going so far as to replace their therapists. These anecdotes suggest that AI agents have great potential to offer accessible mental health support. However, it's unclear how to meet this potential in extreme mental health crisis use cases. In this work, we explore the first-person experience of turning to a conversational AI agent in a mental health crisis. From a testimonial survey (n = 53) of lived experiences, we find that people use AI agents to fill the in-between spaces of human support; they turn to AI due to lack of access to mental health professionals or fears of burdening others. At the same time, our interviews with mental health experts (n = 16) suggest that human-human connection is an essential positive action when managing a mental health crisis. Using the stages of change model, our results suggest that a responsible AI crisis intervention is one that increases the user's preparedness to take a positive action while de-escalating any intended negative action. We discuss the implications of designing conversational AI agents as bridges towards human-human connection rather than ends in themselves.

</details>


### [37] [Deletion Considered Harmful](https://arxiv.org/abs/2512.23907)
*Paul Englefield,Russell Beale*

Main category: cs.HC

TL;DR: 本研究调查了删除在信息管理中的效果，发现其实际使用率低且对检索产生负面影响，强调了需要重新评估删除策略的必要性。


<details>
  <summary>Details</summary>
Motivation: 在信息泛滥的世界中，理解如何有效管理信息对成功至关重要。

Method: 通过问卷和访谈对51名知识工作者的行为进行研究，评估他们在组织、归档和检索数字资源时使用的策略。

Result: 研究发现，相比于其他策略如归档、覆盖、Ontology和时效性，删除策略被低估，并且其对检索成功与满意度有负面影响。

Conclusion: 删除在信息管理中被低估，且对检索成功和满意度有负面影响。

Abstract: In a world of information overload, understanding how we can most effectively manage information is crucial to success. We set out to understand how people view deletion, the removal of material no longer needed: does it help by reducing clutter and improving the signal to noise ratio, or does the effort required to decide to delete something make it not worthwhile? How does deletion relate to other strategies like filing; do people who spend extensive time in filing also prune their materials too? We studied the behaviour of 51 knowledge workers though a series of questionnaires and interviews to evaluate a range of tactics they used aimed at organizing, filing, and retrieving digital resources. Our study reveals that deletion is consistently under-adopted compared to other tactics such as Filing, Coverage, Ontology, and Timeliness. Moreover, the empirical data indicate that deletion is actually detrimental to retrieval success and satisfaction. In this paper, we examine the practice of deletion, review the related literature, and present detailed statistical results and clustering outcomes that underscore its adverse effects.

</details>


### [38] [External Human-Machine Interface based on Intent Recognition: Framework Design and Experimental Validation](https://arxiv.org/abs/2512.24166)
*Boya Sun,Haotian Shi,Ying Ni,Shaocheng Jia,Haoyang Liang*

Main category: cs.HC

TL;DR: 本文提出了一种基于行人意图识别的自适应外部人机界面IR-eHMI，显著改善了自主车辆与行人之间的互动效率和安全性。


<details>
  <summary>Details</summary>
Motivation: 随着自主车辆（AVs）在交通系统中的增加，加强AV与行人之间的有效互动变得至关重要。

Method: 本研究将自适应互动机制纳入eHMI（外部人机界面），根据行人意图识别来实现称为IR-eHMI的系统。IR-eHMI动态检测并推断行人和AV的行为意图，通过识别它们的合作状态。

Result: 实验结果表明，与传统的固定距离eHMI相比，IR-eHMI显著提高了过马路的效率，减少了目光分散，同时保持了互动安全。

Conclusion: 这种自适应和明确的互动模式为AV与行人之间的合作引入了一种创新的程序范式。

Abstract: Increasing autonomous vehicles (AVs) in transportation systems makes effective interactions between AVs and pedestrians indispensable. External human--machine interface (eHMI), which employs visual or auditory cues to explicitly convey vehicle behaviors can compensate for the loss of human-like interactions and enhance AV--pedestrian cooperation. To facilitate faster intent convergence between pedestrian and AVs, this study incorporates an adaptive interaction mechanism into eHMI based on pedestrian intent recognition, namely IR-eHMI. IR-eHMI dynamically detects and infers the behavioral intentions of both pedestrians and AVs through identifying their cooperation states. The proposed interaction framework is implemented and evaluated on a virtual reality (VR) experimental platform to demonstrate its effectiveness through statistical analysis. Experimental results show that IR-eHMI significantly improves crossing efficiency, reduces gaze distraction while maintaining interaction safety compared to traditional fixed-distance eHMI. This adaptive and explicit interaction mode introduces an innovative procedural paradigm for AV--pedestrian cooperation.

</details>


### [39] [A Framing and Analysis of Applicative Tangible Interfaces](https://arxiv.org/abs/2512.24237)
*Guillaume Riviere*

Main category: cs.HC

TL;DR: 本文探讨有形用户界面的组件化，提出商业潜力并定义未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着有形用户界面的逐步成熟，探索其商业潜力变得更加重要。

Method: 研究将159个物理项分配到四个角色，并与有形用户界面领域的研究阶段进行对比。

Result: 文中成功地将35个应用中的159个物理项分配到新的互动模型中定义的四个角色，并指出未来研究的三条主要路径。

Conclusion: 本文识别出适用的有形用户界面的四个组件角色，并提出了未来研究的主要方向。

Abstract: The investigation of tangible user interfaces commenced approximately thirty years ago. Questions on its commercial potential become more pressing as the field becomes mature. To take the field one step further -- as the emergence of components contributed to the commercial development of graphical user interfaces -- this article suggests that applicative tangible user interfaces could also be split into components. These components are composed of the aggregation, combination, or coupling of physical items and fulfil four roles that are described through a new interaction model. This article successfully distributed among these four components' roles all of the 159 physical items from a representative collection of 35 applications. Further examination of these applicative tangible interfaces coincides with four research phases in the field and identifies three main paths for future research to fully realize the potential of tangible user interfaces.

</details>


### [40] [ReflecToMeet: An AI-Assisted Reflection Based System to Enhance Collaborative Preparedness](https://arxiv.org/abs/2512.24632)
*Md Nazmus Sakib,Naga Manogna Rayasam,Ishika Tarin,Sanorita Dey*

Main category: cs.HC

TL;DR: 本研究开发了ReflecToMeet，一个AI辅助系统，旨在通过反思提示和分享机制解决协作环境中任务偏离的问题。


<details>
  <summary>Details</summary>
Motivation: 在协作环境中，难以保持一致的节奏和投入会导致任务偏离，降低会议间的准备性和整体效能。

Method: 进行了一个形成性研究，并开展了混合方法研究，对三种条件下的系统进行了评估：深入反思、定期反思和不结构化反思的对照组。

Result: 对照组表现出较少的深思熟虑和较弱的协作，导致会议期间的压力和不对齐，而结构化反思支持了更好的组织和稳定的进展。

Conclusion: 我们讨论了AI代理促进反思以增强协作的设计启示，以及支持协作目标的AI辅助系统的更广泛考虑。

Abstract: In collaborative settings, difficulties in sustaining a consistent pace and engagement often lead to task drift, reducing preparedness and overall effectiveness between meetings. To address this challenge, we conducted a formative study and developed ReflecToMeet, an AI assisted system that integrates theory driven reflective prompts with mechanisms for sharing teammates reflections. Informed by ten formative interviews, the system was evaluated in a mixed method study across three conditions: deeper reflection, regular reflection, and a control condition with unstructured reflection. Participants in the control condition demonstrated less deliberate thought and weaker collaboration, which led to stress and misalignment during team meetings. In contrast, structured reflection supported greater organization and steadier progress. The deeper reflection condition further facilitated confidence, teamwork, and idea generation, although it imposed a higher cognitive load. We conclude by discussing design implications for AI agents that facilitate reflection to enhance collaboration and broader considerations for AI assisted systems aimed at sustaining collaborative goals.

</details>


### [41] [Vibe Coding, Interface Flattening](https://arxiv.org/abs/2512.24939)
*Hongrui Jin*

Main category: cs.HC

TL;DR: 大语言模型通过自然语言交互重塑了编程，产生了'vibe coding'，即新型的软件开发模式，尽管技术能力表面上被民主化，但实际上却依赖于模型和协议提供者，导致新形式的依赖与素养。


<details>
  <summary>Details</summary>
Motivation: 探讨'vibe coding'作为界面扁平化的重构，揭示其对编程的影响及其背后的控制与意义创造的权力转移。

Method: 通过重新构建当代'vibe coding'堆栈，分析远程计算基础设施、延迟与连接性、结构化输出、功能/工具调用及互操作性标准的影响。

Result: 该研究指出，'vibe coding'的表面民主化依赖于对模型和协议提供者的新依赖，同时也揭示了技术能力和负责权的动态变化。

Conclusion: LLM介导的开发重新分配了符号劳动和权力，模糊了责任，并使先前分散在编程社区的能力私有化，从而提供了对AI介导的人机交互的政治经济的重要视角。

Abstract: Large language models are reshaping programming by enabling 'vibe coding': the development of softwares through natural-language interaction with model-driven toolchains. This article argues that vibe coding is best understood as interface flattening, a reconfiguration in which previously distinct modalities (GUI, CLI, and API) appear to converge into a single conversational surface, even as the underlying chain of translation from intention to machinic effect lengthens and thickens. Drawing on Friedrich Kittler's materialist media theory and Alexander Galloway's account of interfaces as sites of protocol control, the paper situates programming as a historically localised interface arrangement rather than an essential relation to computation. Through a materialist reconstruction of the contemporary vibe-coding stack, it shows how remote compute infrastructures, latency and connectivity, structured outputs, function/tool calling, and interoperability standards such as the Model Context Protocol relocate control and meaning-making power to model and protocol providers. The apparent democratisation of technical capability therefore depends on new dependencies and new literacies. By foregrounding the tension between experiential flattening and infrastructural thickening, I demonstrate how LLM-mediated development redistributes symbolic labour/power, obscures responsibility, and privatises competencies previously dispersed across programming communities, contributing a critical lens on the political economy of AI-mediated human-computer interaction.

</details>
