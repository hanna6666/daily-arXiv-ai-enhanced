{"id": "2601.05401", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.05401", "abs": "https://arxiv.org/abs/2601.05401", "authors": ["Alicia Guo", "David Ledo", "George Fitzmaurice", "Fraser Anderson"], "title": "Protosampling: Enabling Free-Form Convergence of Sampling and Prototyping through Canvas-Driven Visual AI Generation", "comment": "27 pages", "summary": "As an emergent process, creativity relies on explorations via sampling and prototyping for problem construction. These activities compile knowledge, provide a context enveloping the solution, and answer questions. With Generative AI, practitioners can go beyond sampling existing media towards instantly generating and remixing new ones. We refer to this convergence as 'protosampling'. Using existing literature we ground a definition for protosampling and operationalize it through Atelier, a canvas-like system that leverages a variety of generative image and video models for visual creation. Atelier: (1) blends the spaces for thinking and creation, where both references and generated assets co-exist in one space, (2) provides various encapsulated technical workflows that focus on the activity at hand, and (3) enables navigating emergence through interactive visualizations, smart search, and collections. Protosampling as a lens reframes creative work to emphasize the process itself and how seemingly disjointed thoughts can tightly interweave into a final solution.", "AI": {"tldr": "\u672c\u8bba\u6587\u5b9a\u4e49\u4e86 '\u539f\u578b\u91c7\u6837'\uff0c\u5e76\u63d0\u51fa\u4e86 Atelie \u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u878d\u5408\u4e86\u751f\u6210\u5a92\u4f53\u7684\u521b\u9020\u8fc7\u7a0b\uff0c\u5f3a\u8c03\u4e86\u521b\u9020\u6027\u8fc7\u7a0b\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u521b\u9020\u529b\u4f5c\u4e3a\u4e00\u79cd\u65b0\u5174\u8fc7\u7a0b\uff0c\u4f9d\u8d56\u4e8e\u91c7\u6837\u548c\u539f\u578b\u5236\u4f5c\u7684\u63a2\u7d22\uff0c\u4ee5\u6784\u5efa\u95ee\u9898\u5e76\u56de\u7b54\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u6587\u732e\u57fa\u7840\u5efa\u7acb\u4e86\u539f\u578b\u91c7\u6837\u7684\u5b9a\u4e49\uff0c\u5e76\u901a\u8fc7 Atelie \u8fdb\u884c\u64cd\u4f5c\uff0cAtelie \u662f\u4e00\u4e2a\u7c7b\u4f3c\u753b\u5e03\u7684\u7cfb\u7edf\uff0c\u5229\u7528\u591a\u79cd\u751f\u6210\u56fe\u50cf\u548c\u89c6\u9891\u6a21\u578b\u8fdb\u884c\u89c6\u89c9\u521b\u4f5c\u3002", "result": "Atelie \u63d0\u4f9b\u4e86\u601d\u8003\u4e0e\u521b\u4f5c\u7a7a\u95f4\u7684\u878d\u5408\u3001\u5c01\u88c5\u7684\u6280\u672f\u5de5\u4f5c\u6d41\u7a0b\u4ee5\u53ca\u4ea4\u4e92\u5f0f\u53ef\u89c6\u5316\u548c\u667a\u80fd\u641c\u7d22\uff0c\u4fc3\u4f7f\u7528\u6237\u5728\u521b\u4f5c\u8fc7\u7a0b\u4e2d\u5bfc\u822a\u4e0e\u63a2\u7d22\u3002", "conclusion": "\u539f\u578b\u91c7\u6837\u91cd\u65b0\u6846\u5b9a\u4e86\u521b\u9020\u6027\u5de5\u4f5c\uff0c\u5f3a\u8c03\u8fc7\u7a0b\u672c\u8eab\u4ee5\u53ca\u770b\u4f3c\u65e0\u5173\u7684\u60f3\u6cd5\u5982\u4f55\u7d27\u5bc6\u4ea4\u7ec7\u6210\u6700\u7ec8\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.05450", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.05450", "abs": "https://arxiv.org/abs/2601.05450", "authors": ["Behdokht Kiafar", "Mohammad Fahim Abrar", "Roghayeh Leila Barmaki"], "title": "Feedback Effects on Cognitive Dynamics: Network-Based Insights from EEG Patterns and Behavioral Performance", "comment": null, "summary": "This study examines the impact of feedback on Electroencephalography (EEG) activity and performance during the Reading the Mind in the Eyes Test. In a within-subject design, eleven participants completed the test under Feedback and No-Feedback conditions. Using the principles of Epistemic Network Analysis (ENA) and Ordered Network Analysis (ONA), we extend these network-based models to explore the link between neural dynamics and task outcomes. ENA results showed that feedback is associated with stronger connections between higher frequency EEG bands (Beta and Gamma) and correct responses, while the absence of feedback activated lower frequency bands (Theta and Alpha). ONA further disclosed directional shifts toward higher frequency activity preceding correct answers in the Feedback condition, whereas the No-Feedback condition showed more self-connections in lower bands and a higher occurrence of wrong answers, suggesting less effective reasoning strategies without feedback. Both ENA and ONA revealed statistically significant differences between conditions (p = 0.01, Cohen's d > 2). This study highlights the methodological benefits of integrating EEG with ENA and ONA for network analysis, capturing both temporal and relational dynamics, as well as the practical insight that feedback can foster more effective reasoning processes and improve task performance.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u53cd\u9988\u5bf9\u8111\u7535\u56fe(EEG)\u6d3b\u52a8\u53ca\u9605\u8bfb\u773c\u775b\u4e2d\u7684\u601d\u60f3\u6d4b\u8bd5\u8868\u73b0\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u53cd\u9988\u6761\u4ef6\u4e0b\u9ad8\u9891EEG\u6ce2\u6bb5\u4e0e\u6b63\u786e\u53cd\u5e94\u4e4b\u95f4\u5b58\u5728\u66f4\u5f3a\u8fde\u63a5\uff0c\u663e\u793a\u53cd\u9988\u53ef\u4ee5\u63d0\u5347\u63a8\u7406\u6548\u679c\u548c\u4efb\u52a1\u8868\u73b0\u3002", "motivation": "\u7406\u89e3\u53cd\u9988\u5728\u63d0\u9ad8\u8ba4\u77e5\u8868\u73b0\u4e2d\u7684\u4f5c\u7528\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u5f71\u54cd\u673a\u5236\u3002", "method": "\u901a\u8fc7\u5728\u53cd\u9988\u548c\u65e0\u53cd\u9988\u6761\u4ef6\u4e0b\u8fdb\u884c\u5b9e\u9a8c\uff0c\u4f7f\u7528\u77e5\u8bc6\u7f51\u7edc\u5206\u6790(ENA)\u548c\u6709\u5e8f\u7f51\u7edc\u5206\u6790(ONA)\u6765\u7814\u7a76EEG\u6d3b\u52a8\u4e0e\u4efb\u52a1\u7ed3\u679c\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "result": "\u53cd\u9988\u6761\u4ef6\u4e0b\uff0cENA\u663e\u793a\u9ad8\u9891EEG\u6ce2\u6bb5\uff08Beta\u548cGamma\uff09\u4e0e\u6b63\u786e\u53cd\u5e94\u4e4b\u95f4\u8fde\u63a5\u66f4\u5f3a\uff0c\u800c\u65e0\u53cd\u9988\u6761\u4ef6\u5219\u6fc0\u6d3b\u4f4e\u9891\u6ce2\u6bb5\uff08Theta\u548cAlpha\uff09\u3002ONA\u663e\u793a\u53cd\u9988\u6761\u4ef6\u4e0b\u5728\u6b63\u786e\u7b54\u6848\u524d\u7684\u9ad8\u9891\u6d3b\u52a8\u589e\u52a0\uff0c\u800c\u65e0\u53cd\u9988\u6761\u4ef6\u66f4\u591a\u4f4e\u9891\u81ea\u8fde\u63a5\u4e14\u9519\u8bef\u56de\u7b54\u589e\u591a\u3002", "conclusion": "\u6574\u5408EEG\u4e0eENA\u548cONA\u7684\u65b9\u6cd5\u5b66\u4f18\u52bf\u663e\u8457\uff0c\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u8bc1\u636e\u8868\u660e\u53cd\u9988\u673a\u5236\u80fd\u4fc3\u8fdb\u66f4\u6709\u6548\u7684\u63a8\u7406\u8fc7\u7a0b\u548c\u6539\u5584\u4efb\u52a1\u8868\u73b0\u3002"}}
{"id": "2601.05516", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.05516", "abs": "https://arxiv.org/abs/2601.05516", "authors": ["Yuxuan Huang", "Qiao Jin", "Tongyu Nie", "Victoria Interrante", "Evan Suma Rosenberg"], "title": "Secure Text Entry using a Virtual Radial Keyboard with Dynamically Resized Keys and Non-Intrusive Randomization", "comment": null, "summary": "As virtual reality (VR) becomes more widely adopted, secure and efficient text entry is an increasingly critical need. In this paper, we identify a vulnerability in a state-of-the-art secure VR text entry method and introduce a novel virtual radial keyboard designed to achieve a balance between security with usability. Keys are arranged alphabetically in a circular layout, with each key selected by controller rotation and dynamically expanding to facilitate precise selection. A randomized rotation mechanism shifts the keyboard after each keystroke, preserving relative key positions while disrupting absolute spatial mappings to protect against inference attacks. We conducted a within-subject study (N=30) comparing our method with the prior secure technique and a standard QWERTY keyboard. Results showed that the radial keyboard significantly improves resistance to keystroke prediction attacks while incurring a tradeoff in entry speed and subjective workload due to the unfamiliar non-QWERTY layout. However, both quantitative trends and qualitative feedback indicate strong potential for performance improvements with practice. We also discuss design implications, possible interface refinements, and directions for future work, including layout variations and visual enhancements.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u865a\u62df\u5f84\u5411\u952e\u76d8\uff0c\u65e8\u5728\u63d0\u9ad8VR\u4e2d\u7684\u6587\u672c\u8f93\u5165\u5b89\u5168\u6027\uff0c\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u6bd4\u63d0\u9ad8\u4e86\u62b5\u6297\u653b\u51fb\u7684\u80fd\u529b\uff0c\u4f46\u901f\u5ea6\u548c\u4e60\u60ef\u4e0a\u6709\u6240\u59a5\u534f\u3002", "motivation": "\u968f\u7740\u865a\u62df\u73b0\u5b9e\u7684\u666e\u53ca\uff0c\u5b89\u5168\u548c\u9ad8\u6548\u7684\u6587\u672c\u8f93\u5165\u6210\u4e3a\u8feb\u5207\u9700\u6c42\u3002", "method": "\u901a\u8fc7\u8bbe\u8ba1\u4e00\u4e2a\u5b57\u6bcd\u6309\u952e\u6309\u5706\u5f62\u5e03\u5c40\u7684\u5f84\u5411\u952e\u76d8\uff0c\u5e76\u8fdb\u884c\u4e86\u4e00\u9879\u5305\u542b30\u540d\u53d7\u8bd5\u8005\u7684\u7814\u7a76\uff0c\u4e0e\u4f20\u7edf\u65b9\u6cd5\u548c\u6807\u51c6QWERTY\u952e\u76d8\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u865a\u62df\u5f84\u5411\u952e\u76d8\uff0c\u65e8\u5728\u63d0\u9ad8VR\u6587\u672c\u8f93\u5165\u7684\u5b89\u5168\u6027\u548c\u53ef\u7528\u6027\u3002", "conclusion": "\u5f84\u5411\u952e\u76d8\u5728\u62b5\u6297\u6309\u952e\u9884\u6d4b\u653b\u51fb\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u5b89\u5168\u65b9\u6cd5\uff0c\u4f46\u5728\u8f93\u5165\u901f\u5ea6\u548c\u4e3b\u89c2\u5de5\u4f5c\u8d1f\u8377\u4e0a\u5b58\u5728\u6743\u8861\u3002"}}
{"id": "2601.05651", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.05651", "abs": "https://arxiv.org/abs/2601.05651", "authors": ["Kyuwon Kim", "Jeanhee Lee", "Sung-Eun Kim", "Hyo-Jeong So"], "title": "Productive Discussion Moves in Groups Addressing Controversial Issues", "comment": null, "summary": "Engaging learners in dialogue around controversial issues is essential for examining diverse values and perspectives in pluralistic societies. While prior research has identified productive discussion moves mainly in STEM-oriented contexts, less is known about what constitutes productive discussion in ethical and value-laden discussions. This study investigates productive discussion in AI ethics dilemmas using a dialogue-centric learning analytics approach. We analyze small-group discussions among undergraduate students through a hybrid method that integrates expert-informed coding with data-driven topic modeling. This process identifies 14 discussion moves across five categories, including Elaborating Ideas, Position Taking, Reasoning & Justifications, Emotional Expression, and Discussion Management. We then examine how these moves relate to discussion quality and analyze sequential interaction patterns using Ordered Network Analysis. Results indicate that emotive and experiential arguments and explicit acknowledgment of ambiguity are strong positive predictors of discussion quality, whereas building on ideas is negatively associated. Ordered Network Analysis further reveals that productive discussions are characterized by interactional patterns that connect emotional expressions to evidence-based reasoning. These findings suggest that productive ethical discussion is grounded not only in reasoning and justification but also in the constructive integration of emotional expression.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8AI\u4f26\u7406\u8ba8\u8bba\u4e2d\u7684\u6709\u6548\u8ba8\u8bba\u884c\u4e3a\uff0c\u53d1\u73b0\u60c5\u611f\u8868\u8fbe\u4e0e\u8bc1\u636e\u57fa\u7840\u7684\u63a8\u7406\u4e4b\u95f4\u7684\u4e92\u52a8\u6a21\u5f0f\u5bf9\u4e8e\u8ba8\u8bba\u8d28\u91cf\u81f3\u5173\u91cd\u8981\u3002", "motivation": "\u5728\u591a\u5143\u5316\u793e\u4f1a\u4e2d\uff0c\u56f4\u7ed5\u4e89\u8bae\u6027\u95ee\u9898\u4e0e\u5b66\u4e60\u8005\u8fdb\u884c\u5bf9\u8bdd\u5bf9\u4e8e\u5ba1\u89c6\u591a\u6837\u7684\u4ef7\u503c\u89c2\u548c\u89c2\u70b9\u81f3\u5173\u91cd\u8981\u3002", "method": "\u672c\u7814\u7a76\u4f7f\u7528\u5bf9\u8bdd\u4e2d\u5fc3\u5b66\u4e60\u5206\u6790\u65b9\u6cd5\uff0c\u8c03\u67e5AI\u4f26\u7406\u56f0\u5883\u4e2d\u7684\u6709\u6548\u8ba8\u8bba\uff0c\u5206\u6790\u672c\u79d1\u751f\u7684\u5c0f\u7ec4\u8ba8\u8bba\uff0c\u91c7\u7528\u4e13\u5bb6\u77e5\u60c5\u7f16\u7801\u4e0e\u6570\u636e\u9a71\u52a8\u4e3b\u9898\u5efa\u6a21\u7684\u6df7\u5408\u65b9\u6cd5\u3002", "result": "\u7814\u7a76\u8bc6\u522b\u4e86\u5305\u62ec\u9610\u8ff0\u89c2\u70b9\u3001\u7acb\u573a\u8868\u8ff0\u3001\u63a8\u7406\u4e0e\u7406\u7531\u3001\u60c5\u611f\u8868\u8fbe\u548c\u8ba8\u8bba\u7ba1\u7406\u5728\u5185\u7684\u4e94\u4e2a\u7c7b\u522b\u4e2d\u768414\u79cd\u8ba8\u8bba\u884c\u4e3a\uff0c\u5e76\u53d1\u73b0\u60c5\u611f\u548c\u7ecf\u9a8c\u6027\u8bba\u636e\u4ee5\u53ca\u5bf9\u6a21\u7cca\u6027\u7684\u660e\u786e\u627f\u8ba4\u662f\u8ba8\u8bba\u8d28\u91cf\u7684\u5f3a\u6b63\u5411\u9884\u6d4b\u56e0\u5b50\u3002", "conclusion": "\u6709\u6548\u7684\u4f26\u7406\u8ba8\u8bba\u4e0d\u4ec5\u57fa\u4e8e\u63a8\u7406\u4e0e\u7406\u7531\uff0c\u8fd8\u5728\u4e8e\u60c5\u611f\u8868\u8fbe\u7684\u5efa\u8bbe\u6027\u6574\u5408\u3002"}}
{"id": "2601.05336", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.05336", "abs": "https://arxiv.org/abs/2601.05336", "authors": ["Tracey Yee Hsin Tay", "Xu Yan", "Jonathan Ouyang", "Daniel Wu", "William Jiang", "Jonathan Kao", "Yuchen Cui"], "title": "Intent at a Glance: Gaze-Guided Robotic Manipulation via Foundation Models", "comment": "Accepted to 2025 RSS Robot Planning in the Era of Foundation Models (FM4RoboPlan) Workshop", "summary": "Designing intuitive interfaces for robotic control remains a central challenge in enabling effective human-robot interaction, particularly in assistive care settings. Eye gaze offers a fast, non-intrusive, and intent-rich input modality, making it an attractive channel for conveying user goals. In this work, we present GAMMA (Gaze Assisted Manipulation for Modular Autonomy), a system that leverages ego-centric gaze tracking and a vision-language model to infer user intent and autonomously execute robotic manipulation tasks. By contextualizing gaze fixations within the scene, the system maps visual attention to high-level semantic understanding, enabling skill selection and parameterization without task-specific training. We evaluate GAMMA on a range of table-top manipulation tasks and compare it against baseline gaze-based control without reasoning. Results demonstrate that GAMMA provides robust, intuitive, and generalizable control, highlighting the potential of combining foundation models and gaze for natural and scalable robot autonomy. Project website: https://gamma0.vercel.app/", "AI": {"tldr": "GAMMA\u662f\u4e00\u79cd\u7ed3\u5408\u76ee\u5149\u8ffd\u8e2a\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u7cfb\u7edf\uff0c\u80fd\u6709\u6548\u63a8\u65ad\u7528\u6237\u610f\u56fe\u5e76\u81ea\u4e3b\u64cd\u63a7\u673a\u5668\u4eba\uff0c\u5728\u8f85\u52a9\u62a4\u7406\u73af\u5883\u4e2d\u63d0\u5347\u4e86\u4eba\u673a\u4ea4\u4e92\u7684\u76f4\u89c2\u6027\u4e0e\u6548\u7387\u3002", "motivation": "\u8bbe\u8ba1\u76f4\u89c2\u7684\u673a\u5668\u4eba\u63a7\u5236\u754c\u9762\uff0c\u4ee5\u63d0\u5347\u4eba\u673a\u4ea4\u4e92\u7684\u6709\u6548\u6027\uff0c\u7279\u522b\u662f\u5728\u8f85\u52a9\u62a4\u7406\u73af\u5883\u4e2d\u3002", "method": "\u901a\u8fc7\u81ea\u6211\u4e2d\u5fc3\u7684\u76ee\u5149\u8ffd\u8e2a\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u63a8\u65ad\u7528\u6237\u610f\u56fe\uff0c\u5e76\u81ea\u4e3b\u6267\u884c\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u3002", "result": "\u5728\u4e00\u7cfb\u5217\u684c\u9762\u64cd\u4f5c\u4efb\u52a1\u4e2d\uff0cGAMMA\u7684\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u76ee\u5149\u63a7\u5236\uff0c\u5c55\u793a\u51fa\u5176\u7a33\u5065\u3001\u76f4\u89c2\u53ca\u53ef\u63a8\u5e7f\u7684\u63a7\u5236\u80fd\u529b\u3002", "conclusion": "GAMMA\u7cfb\u7edf\u5c55\u793a\u4e86\u7ed3\u5408\u57fa\u7840\u6a21\u578b\u548c\u76ee\u5149\u8ffd\u8e2a\u6280\u672f\u7684\u6709\u6548\u6027\uff0c\u4e3a\u673a\u5668\u4eba\u81ea\u4e3b\u63a7\u5236\u63d0\u4f9b\u4e86\u76f4\u89c2\u548c\u53ef\u63a8\u5e7f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.05666", "categories": ["cs.HC", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.05666", "abs": "https://arxiv.org/abs/2601.05666", "authors": ["Yerin Kwak", "Siddharth Adelkar", "Zachary A. Pardos"], "title": "Advancing credit mobility through stakeholder-informed AI design and adoption", "comment": "17 pages, 8 figures", "summary": "Transferring from a 2-year to a 4-year college is crucial for socioeconomic mobility, yet students often face challenges ensuring their credits are fully recognized, leading to delays in their academic progress and unexpected costs. Determining whether courses at different institutions are equivalent (i.e., articulation) is essential for successful credit transfer, as it minimizes unused credits and increases the likelihood of bachelor's degree completion. However, establishing articulation agreements remains time- and resource-intensive, as all candidate articulations are reviewed manually. Although recent efforts have explored the use of artificial intelligence to support this work, its use in articulation practice remains limited. Given these challenges and the need for scalable support, this study applies artificial intelligence to suggest articulations between institutions in collaboration with the State University of New York system, one of the largest systems of higher education in the US. To develop our methodology, we first surveyed articulation staff and faculty to assess adoption rates of baseline algorithmic recommendations and gather feedback on perceptions and concerns about these recommendations. Building on these insights, we developed a supervised alignment method that addresses superficial matching and institutional biases in catalog descriptions, achieving a 5.5-fold improvement in accuracy over previous methods. Based on articulation predictions of this method and a 61% average surveyed adoption rate among faculty and staff, these findings project a 12-fold increase in valid credit mobility opportunities that would otherwise remain unrealized. This study suggests that stakeholder-informed design of AI in higher education administration can expand student credit mobility and help reshape current institutional decision-making in course articulation.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u4f7f\u7528\u4eba\u5de5\u667a\u80fd\u4f18\u5316\u9ad8\u7b49\u6559\u80b2\u8bfe\u7a0b\u8ba4\u8bc1\u7684\u8fc7\u7a0b\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8ba4\u8bc1\u51c6\u786e\u6027\uff0c\u4ece\u800c\u4fc3\u8fdb\u4e86\u5b66\u751f\u7684\u5b66\u5206\u6d41\u52a8\u6027\u3002", "motivation": "\u4fc3\u8fdb\u5b66\u751f\u4ece2\u5e74\u5236\u8f6c\u54114\u5e74\u5236\u5927\u5b66\u5bf9\u4e8e\u793e\u4f1a\u7ecf\u6d4e\u6d41\u52a8\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5b66\u751f\u5728\u786e\u4fdd\u5b66\u5206\u88ab\u6709\u6548\u8ba4\u53ef\u65f6\u5e38\u9762\u4e34\u6311\u6218\uff0c\u5bfc\u81f4\u5b66\u4e1a\u8fdb\u5ea6\u5ef6\u8fdf\u548c\u989d\u5916\u8d39\u7528\u3002", "method": "\u672c\u7814\u7a76\u4e0e\u7ebd\u7ea6\u5dde\u5927\u5b66\u7cfb\u7edf\u5408\u4f5c\uff0c\u901a\u8fc7\u8c03\u67e5\u8ba4\u8bc1\u5de5\u4f5c\u4eba\u5458\u548c\u6559\u5e08\uff0c\u4ee5\u8bc4\u4f30\u7b97\u6cd5\u63a8\u8350\u7684\u91c7\u7528\u7387\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u79cd\u76d1\u7763\u5bf9\u9f50\u65b9\u6cd5\uff0c\u89e3\u51b3\u76ee\u5f55\u63cf\u8ff0\u4e2d\u7684\u8868\u9762\u5339\u914d\u548c\u673a\u6784\u504f\u89c1\u95ee\u9898\u3002", "result": "\u901a\u8fc7\u8be5\u65b9\u6cd5\u7684\u8ba4\u8bc1\u9884\u6d4b\u548c61%\u7684\u6559\u5e08\u4e0e\u5de5\u4f5c\u4eba\u5458\u7684\u8c03\u67e5\u91c7\u7528\u7387\uff0c\u9884\u6d4b\u5c06\u5b9e\u73b012\u500d\u7684\u6709\u6548\u5b66\u5206\u6d41\u52a8\u6027\u673a\u4f1a\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5728\u9ad8\u7b49\u6559\u80b2\u7ba1\u7406\u4e2d\u4ee5\u5229\u76ca\u76f8\u5173\u8005\u4e3a\u5bfc\u5411\u8bbe\u8ba1\u7684\u4eba\u5de5\u667a\u80fd\u53ef\u4ee5\u6269\u5927\u5b66\u751f\u7684\u5b66\u5206\u6d41\u52a8\u6027\uff0c\u540c\u65f6\u5e2e\u52a9\u91cd\u5851\u5f53\u524d\u8bfe\u7a0b\u8ba4\u8bc1\u7684\u51b3\u7b56\u8fc7\u7a0b\u3002"}}
{"id": "2601.05356", "categories": ["cs.RO", "cs.AI", "cs.MA", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2601.05356", "abs": "https://arxiv.org/abs/2601.05356", "authors": ["Brian Hsu", "Priyanka V Setty", "Rory M Butler", "Ryan Lewis", "Casey Stone", "Rebecca Weinberg", "Thomas Brettin", "Rick Stevens", "Ian Foster", "Arvind Ramanathan"], "title": "PRISM: Protocol Refinement through Intelligent Simulation Modeling", "comment": "43 pages, 8 figures, submitted to RSC Digital Discovery. Equal contribution: B. Hsu, P.V. Setty, R.M. Butler. Corresponding author: A. Ramanathan", "summary": "Automating experimental protocol design and execution remains as a fundamental bottleneck in realizing self-driving laboratories. We introduce PRISM (Protocol Refinement through Intelligent Simulation Modeling), a framework that automates the design, validation, and execution of experimental protocols on a laboratory platform composed of off-the-shelf robotic instruments. PRISM uses a set of language-model-based agents that work together to generate and refine experimental steps. The process begins with automatically gathering relevant procedures from web-based sources describing experimental workflows. These are converted into structured experimental steps (e.g., liquid handling steps, deck layout and other related operations) through a planning, critique, and validation loop. The finalized steps are translated into the Argonne MADSci protocol format, which provides a unified interface for coordinating multiple robotic instruments (Opentrons OT-2 liquid handler, PF400 arm, Azenta plate sealer and peeler) without requiring human intervention between steps. To evaluate protocol-generation performance, we benchmarked both single reasoning models and multi-agent workflow across constrained and open-ended prompting paradigms. The resulting protocols were validated in a digital-twin environment built in NVIDIA Omniverse to detect physical or sequencing errors before execution. Using Luna qPCR amplification and Cell Painting as case studies, we demonstrate PRISM as a practical end-to-end workflow that bridges language-based protocol generation, simulation-based validation, and automated robotic execution.", "AI": {"tldr": "PRISM\u662f\u4e00\u4e2a\u81ea\u52a8\u5316\u5b9e\u9a8c\u534f\u8bae\u8bbe\u8ba1\u548c\u6267\u884c\u7684\u6846\u67b6\uff0c\u5229\u7528\u8bed\u8a00\u6a21\u578b\u548c\u4eff\u771f\u6765\u63d0\u9ad8\u5b9e\u9a8c\u5ba4\u81ea\u52a8\u5316\u7684\u6548\u7387\u548c\u53ef\u9760\u6027\u3002", "motivation": "\u9488\u5bf9\u81ea\u9a71\u52a8\u5b9e\u9a8c\u5ba4\u7684\u5b9e\u9a8c\u534f\u8bae\u8bbe\u8ba1\u548c\u6267\u884c\u7684\u81ea\u52a8\u5316\u95ee\u9898\uff0c\u63d0\u51faPRISM\u6846\u67b6\u4ee5\u63d0\u9ad8\u5b9e\u9a8c\u6548\u7387\u3002", "method": "\u901a\u8fc7\u8bed\u8a00\u6a21\u578b\u57fa\u7840\u7684\u4ee3\u7406\u751f\u6210\u548c\u7ec6\u5316\u5b9e\u9a8c\u6b65\u9aa4\uff0c\u5e76\u7ed3\u5408\u6570\u5b57\u53cc\u80de\u80ce\u73af\u5883\u8fdb\u884c\u534f\u8bae\u751f\u6210\u6027\u80fd\u8bc4\u4f30\uff0c\u9a8c\u8bc1\u6700\u7ec8\u534f\u8bae\u7684\u6709\u6548\u6027\u3002", "result": "PRISM\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\uff08\u5982Luna qPCR\u653e\u5927\u548c\u7ec6\u80de\u7ed8\u5236\uff09\u5c55\u793a\u4e86\u8bed\u8a00\u9a71\u52a8\u7684\u534f\u8bae\u751f\u6210\u4e0e\u57fa\u4e8e\u4eff\u771f\u7684\u9a8c\u8bc1\u76f8\u7ed3\u5408\u7684\u6709\u6548\u6027\uff0c\u4ece\u800c\u5b9e\u73b0\u4e86\u5168\u81ea\u52a8\u7684\u673a\u5668\u4eba\u6267\u884c\u3002", "conclusion": "PRISM\u5c55\u793a\u4e86\u81ea\u52a8\u5316\u5b9e\u9a8c\u534f\u8bae\u8bbe\u8ba1\u548c\u6267\u884c\u7684\u6709\u6548\u6027\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u65e0\u987b\u4eba\u5de5\u5e72\u9884\u7684\u5168\u6d41\u7a0b\u5b9e\u9a8c\u5ba4\u81ea\u52a8\u5316\u3002"}}
{"id": "2601.05789", "categories": ["cs.HC", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05789", "abs": "https://arxiv.org/abs/2601.05789", "authors": ["Tianwang Jia", "Xiaoqing Chen", "Dongrui Wu"], "title": "SAFE: Secure and Accurate Federated Learning for Privacy-Preserving Brain-Computer Interfaces", "comment": "12 pages, 9 figures", "summary": "Electroencephalogram (EEG)-based brain-computer interfaces (BCIs) are widely adopted due to their efficiency and portability; however, their decoding algorithms still face multiple challenges, including inadequate generalization, adversarial vulnerability, and privacy leakage. This paper proposes Secure and Accurate FEderated learning (SAFE), a federated learning-based approach that protects user privacy by keeping data local during model training. SAFE employs local batch-specific normalization to mitigate cross-subject feature distribution shifts and hence improves model generalization. It further enhances adversarial robustness by introducing perturbations in both the input space and the parameter space through federated adversarial training and adversarial weight perturbation. Experiments on five EEG datasets from motor imagery (MI) and event-related potential (ERP) BCI paradigms demonstrated that SAFE consistently outperformed 14 state-of-the-art approaches in both decoding accuracy and adversarial robustness, while ensuring privacy protection. Notably, it even outperformed centralized training approaches that do not consider privacy protection at all. To our knowledge, SAFE is the first algorithm to simultaneously achieve high decoding accuracy, strong adversarial robustness, and reliable privacy protection without using any calibration data from the target subject, making it highly desirable for real-world BCIs.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u5b89\u5168\u51c6\u786e\u7684\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5SAFE\uff0c\u901a\u8fc7\u5bf9\u7528\u6237\u6570\u636e\u7684\u672c\u5730\u5316\u5904\u7406\uff0c\u63d0\u5347\u4e86EEG\u8111\u673a\u63a5\u53e3\u7684\u89e3\u7801\u51c6\u786e\u6027\u548c\u5bf9\u6297\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u4fdd\u969c\u4e86\u9690\u79c1\u3002", "motivation": "EEG\u8111\u673a\u63a5\u53e3\u88ab\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u89e3\u7801\u7b97\u6cd5\u9762\u4e34\u901a\u7528\u6027\u4e0d\u8db3\u3001\u654c\u5bf9\u653b\u51fb\u8106\u5f31\u6027\u548c\u9690\u79c1\u6cc4\u9732\u7b49\u95ee\u9898\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u57fa\u4e8e\u8054\u90a6\u5b66\u4e60\u7684\u65b9\u6cd5SAFE\uff0c\u5728\u6a21\u578b\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4fdd\u6301\u6570\u636e\u672c\u5730\u5316\uff0c\u4f7f\u7528\u5c40\u90e8\u6279\u6b21\u7279\u5b9a\u5f52\u4e00\u5316\u6280\u672f\u4ee5\u51cf\u5c11\u8de8\u53d7\u8bd5\u8005\u7279\u5f81\u5206\u5e03\u504f\u5dee\uff0c\u540c\u65f6\u901a\u8fc7\u8054\u90a6\u5bf9\u6297\u8bad\u7ec3\u548c\u5bf9\u6297\u6743\u91cd\u6270\u52a8\u589e\u5f3a\u5bf9\u6297\u9c81\u68d2\u6027\u3002", "result": "\u5728\u4e94\u4e2a\u6765\u81ea\u8fd0\u52a8\u60f3\u8c61\u548c\u4e8b\u4ef6\u76f8\u5173\u7535\u4f4dBCI\u8303\u5f0f\u7684EEG\u6570\u636e\u96c6\u4e0a\uff0cSAFE\u5728\u89e3\u7801\u51c6\u786e\u6027\u548c\u5bf9\u6297\u9c81\u68d2\u6027\u65b9\u9762\u8868\u73b0\u4f18\u4e8e14\u79cd\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\uff0c\u540c\u65f6\u786e\u4fdd\u4e86\u9690\u79c1\u4fdd\u62a4\u3002", "conclusion": "SAFE\u662f\u7b2c\u4e00\u4e2a\u5728\u4e0d\u4f7f\u7528\u76ee\u6807\u7528\u6237\u7684\u6821\u51c6\u6570\u636e\u7684\u60c5\u51b5\u4e0b\uff0c\u540c\u65f6\u5b9e\u73b0\u9ad8\u89e3\u7801\u51c6\u786e\u6027\u3001\u5f3a\u654c\u5bf9\u9c81\u68d2\u6027\u548c\u53ef\u9760\u9690\u79c1\u4fdd\u62a4\u7684\u7b97\u6cd5\uff0c\u6781\u5177\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2601.05491", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.05491", "abs": "https://arxiv.org/abs/2601.05491", "authors": ["Luca Nunziante", "Kentaro Uno", "Gustavo H. Diaz", "Shreya Santra", "Alessandro De Luca", "Kazuya Yoshida"], "title": "Assembling Solar Panels by Dual Robot Arms Towards Full Autonomous Lunar Base Construction", "comment": "This is the authors' version of a paper accepted for publication in IEEE/SICE International Symposium on System Integration (SII), 2025, (c) IEEE", "summary": "Since the successful Apollo program, humanity is once again aiming to return to the Moon for scientific discovery, resource mining, and inhabitation. Upcoming decades focus on building a lunar outpost, with robotic systems playing a crucial role to safely and efficiently establish essential infrastructure such as solar power generating towers. Similar to the construction of the International Space Station (ISS), shipping necessary components via modules and assembling them in situ should be a practical scenario. In this context, this paper focuses on the integration of vision, control, and hardware systems within an autonomous sequence for a dual-arm robot system. We explore a perception and control pipeline specifically designed for assembling solar panel modules, one of the benchmark tasks. Ad hoc hardware was designed and tested in real-world experiments. A mock-up of modular solar panels and active-passive connectors are employed, with the control of this grappling fixture integrated into the proposed pipeline. The successful implementation of our method demonstrates that the two robot manipulators can effectively connect arbitrarily placed panels, highlighting the seamless integration of vision, control, and hardware systems in complex space applications.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u4e00\u4e2a\u53cc\u81c2\u673a\u5668\u4eba\u7cfb\u7edf\u5728\u6708\u7403\u51fa\u5efa\u8bbe\u65bd\u4e2d\u7684\u5e94\u7528\uff0c\u805a\u7126\u4e8e\u592a\u9633\u80fd\u677f\u6a21\u5757\u7684\u88c5\u914d\u3002", "motivation": "\u968f\u7740\u4eba\u7c7b\u91cd\u8fd4\u6708\u7403\u7684\u8ba1\u5212\uff0c\u6784\u5efa\u6708\u7403\u524d\u54e8\u57fa\u5730\uff0c\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u4f5c\u7528\u6108\u53d1\u91cd\u8981\u3002", "method": "\u8bbe\u8ba1\u5e76\u6d4b\u8bd5\u4e86\u4e00\u79cd\u96c6\u6210\u89c6\u89c9\u3001\u63a7\u5236\u548c\u786c\u4ef6\u7684\u7ba1\u9053\uff0c\u7528\u4e8e\u53cc\u81c2\u673a\u5668\u4eba\u8fdb\u884c\u592a\u9633\u80fd\u677f\u6a21\u5757\u7684\u88c5\u914d\u3002", "result": "\u5b9e\u9a8c\u6210\u529f\u6f14\u793a\u4e86\u4e24\u4e2a\u673a\u68b0\u624b\u53ef\u4ee5\u6709\u6548\u8fde\u63a5\u4efb\u610f\u653e\u7f6e\u7684\u592a\u9633\u80fd\u677f\uff0c\u663e\u793a\u51fa\u7cfb\u7edf\u7684\u9ad8\u6548\u6027\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u89c6\u89c9\u3001\u63a7\u5236\u548c\u786c\u4ef6\u7cfb\u7edf\u7684\u65e0\u7f1d\u96c6\u6210\u80fd\u591f\u63a8\u52a8\u590d\u6742\u592a\u7a7a\u5e94\u7528\u7684\u5b9e\u73b0\u3002"}}
{"id": "2601.05822", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.05822", "abs": "https://arxiv.org/abs/2601.05822", "authors": ["Adarsh Pawar", "Yuqiao Meng", "Luoxi Tang", "Zhaohan Xi"], "title": "Improving Clinical Data Accessibility Through Automated FHIR Data Transformation Tools", "comment": null, "summary": "The Fast Healthcare Interoperability Resources (FHIR) standard has emerged as a widely adopted specification for exchanging structured clinical data across healthcare systems. However, raw FHIR resources are often complex, verbose, and difficult for clinicians and analysts to interpret without specialized tooling. This paper presents a lightweight, browser-based system that improves the accessibility of FHIR data by automatically transforming raw JSON resources into human-readable PDF and Excel reports, along with interactive data visualizations. The system supports both remote retrieval of FHIR resources from server endpoints and the upload of local FHIR JSON files, enabling both online and offline analysis. Using a modular React architecture with jsPDF, xlsx, and Recharts, the tool parses, normalizes, visualizes, and exports FHIR data in an intuitive format. Evaluation results demonstrate that the system enhances interpretability and usability while preserving the semantic integrity of FHIR structures. Limitations and future extensions, including expanded FHIR profile support and clinical validation, are discussed.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7cfb\u7edf\uff0c\u901a\u8fc7\u81ea\u52a8\u8f6c\u6362FHIR\u6570\u636e\uff0c\u63d0\u5347\u4e86\u4e34\u5e8a\u6570\u636e\u7684\u53ef\u8bfb\u6027\u548c\u53ef\u7528\u6027\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3FHIR\u8d44\u6e90\u590d\u6742\u4e14\u96be\u4ee5\u7406\u89e3\u7684\u95ee\u9898\uff0c\u5f00\u53d1\u4e00\u4e2a\u9ad8\u6548\u7684\u5de5\u5177\uff0c\u63d0\u9ad8\u6570\u636e\u7684\u53ef\u83b7\u53d6\u6027\u548c\u53ef\u89e3\u8bfb\u6027\u3002", "method": "\u4f7f\u7528\u6a21\u5757\u5316\u7684React\u67b6\u6784\uff0c\u7ed3\u5408jsPDF\u3001xlsx\u548cRecharts\uff0c\u5b9e\u73b0\u5bf9FHIR\u6570\u636e\u7684\u89e3\u6790\u3001\u89c4\u8303\u5316\u3001\u53ef\u89c6\u5316\u548c\u5bfc\u51fa\u3002", "result": "\u521b\u5efa\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u57fa\u4e8e\u6d4f\u89c8\u5668\u7684\u7cfb\u7edf\uff0c\u53ef\u5c06\u539f\u59cbJSON\u8d44\u6e90\u81ea\u52a8\u8f6c\u5316\u4e3a\u6613\u4e8e\u7406\u89e3\u7684PDF\u548cExcel\u62a5\u544a\uff0c\u5e76\u63d0\u4f9b\u4ea4\u4e92\u5f0f\u6570\u636e\u53ef\u89c6\u5316\u3002", "conclusion": "\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u7cfb\u7edf\u63d0\u9ad8\u4e86FHIR\u6570\u636e\u7684\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u7528\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4e86FHIR\u7ed3\u6784\u7684\u8bed\u4e49\u5b8c\u6574\u6027\u3002"}}
{"id": "2601.05499", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.05499", "abs": "https://arxiv.org/abs/2601.05499", "authors": ["Weishang Wu", "Yifei Shi", "Zhiping Cai"], "title": "TOSC: Task-Oriented Shape Completion for Open-World Dexterous Grasp Generation from Partial Point Clouds", "comment": "Accepted to AAAI 2026", "summary": "Task-oriented dexterous grasping remains challenging in robotic manipulations of open-world objects under severe partial observation, where significant missing data invalidates generic shape completion. In this paper, to overcome this limitation, we study Task-Oriented Shape Completion, a new task that focuses on completing the potential contact regions rather than the entire shape. We argue that shape completion for grasping should be explicitly guided by the downstream manipulation task. To achieve this, we first generate multiple task-oriented shape completion candidates by leveraging the zero-shot capabilities of object functional understanding from several pre-trained foundation models. A 3D discriminative autoencoder is then proposed to evaluate the plausibility of each generated candidate and optimize the most plausible one from a global perspective. A conditional flow-matching model named FlowGrasp is developed to generate task-oriented dexterous grasps from the optimized shape. Our method achieves state-of-the-art performance in task-oriented dexterous grasping and task-oriented shape completion, improving the Grasp Displacement and the Chamfer Distance over the state-of-the-art by 16.17\\% and 55.26%, respectively. In particular, it shows good capabilities in grasping objects with severe missing data. It also demonstrates good generality in handling open-set categories and tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4efb\u52a1\u5bfc\u5411\u5f62\u72b6\u8865\u5168\u65b9\u6cd5\uff0c\u4ee5\u5e94\u5bf9\u673a\u5668\u4eba\u64cd\u63a7\u4e2d\u4e25\u91cd\u7684\u90e8\u5206\u89c2\u5bdf\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6293\u63e1\u548c\u5f62\u72b6\u8865\u5168\u7684\u6027\u80fd\u3002", "motivation": "\u5728\u5f00\u653e\u4e16\u754c\u7269\u4f53\u7684\u673a\u5668\u4eba\u64cd\u63a7\u4e2d\uff0c\u4efb\u52a1\u5bfc\u5411\u7684\u7075\u5de7\u6293\u63e1\u9762\u4e34\u4e25\u91cd\u7684\u90e8\u5206\u89c2\u5bdf\u95ee\u9898\uff0c\u5bfc\u81f4\u91cd\u8981\u6570\u636e\u7f3a\u5931\u4f7f\u5f97\u901a\u7528\u5f62\u72b6\u8865\u5168\u5931\u6548\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4efb\u52a1\uff1a\u4efb\u52a1\u5bfc\u5411\u5f62\u72b6\u8865\u5168\uff0c\u4e13\u6ce8\u4e8e\u8865\u5168\u6f5c\u5728\u63a5\u89e6\u533a\u57df\uff0c\u800c\u975e\u6574\u4e2a\u5f62\u72b6\u3002\u901a\u8fc7\u5229\u7528\u591a\u4e2a\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u96f6-shot\u80fd\u529b\u751f\u6210\u591a\u4e2a\u4efb\u52a1\u5bfc\u5411\u7684\u5f62\u72b6\u8865\u5168\u5019\u9009\uff0c\u63a5\u7740\u4f7f\u75283D\u5224\u522b\u81ea\u7f16\u7801\u5668\u8bc4\u4f30\u6bcf\u4e2a\u5019\u9009\u7684\u53ef\u884c\u6027\u5e76\u4f18\u5316\u6700\u53ef\u884c\u7684\u5f62\u72b6\u3002\u540c\u65f6\uff0c\u5f00\u53d1\u4e86\u6761\u4ef6\u6d41\u5339\u914d\u6a21\u578bFlowGrasp\uff0c\u4ece\u4f18\u5316\u540e\u7684\u5f62\u72b6\u751f\u6210\u4efb\u52a1\u5bfc\u5411\u7684\u7075\u5de7\u6293\u63e1\u3002", "result": "\u6211\u4eec\u7684\u7b97\u6cd5\u5728\u4efb\u52a1\u5bfc\u5411\u7684\u7075\u5de7\u6293\u63e1\u548c\u5f62\u72b6\u8865\u5168\u65b9\u9762\u8fbe\u5230\u4e86\u6700\u65b0\u7684\u6027\u80fd\u6307\u6807\uff0c\u5206\u522b\u5c06\u6293\u63e1\u4f4d\u79fb\u548cChamfer\u8ddd\u79bb\u63d0\u5347\u4e8616.17%\u548c55.26%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u5904\u7406\u4e25\u91cd\u7f3a\u5931\u6570\u636e\u7684\u7269\u4f53\u6293\u63e1\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u540c\u65f6\u5728\u5f00\u653e\u7c7b\u522b\u548c\u4efb\u52a1\u5904\u7406\u4e0a\u5c55\u73b0\u51fa\u5f88\u597d\u7684\u901a\u7528\u6027\u3002"}}
{"id": "2601.05825", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05825", "abs": "https://arxiv.org/abs/2601.05825", "authors": ["Lucija Mihi\u0107 Zidar", "Philipp Wicke", "Praneel Bhatia", "Rosa Lutz", "Marius Klug", "Thorsten O. Zander"], "title": "Decoding Workload and Agreement From EEG During Spoken Dialogue With Conversational AI", "comment": "Accepted at the 14th International Winter Conference on Brain-Computer Interface", "summary": "Passive brain-computer interfaces offer a potential source of implicit feedback for alignment of large language models, but most mental state decoding has been done in controlled tasks. This paper investigates whether established EEG classifiers for mental workload and implicit agreement can be transferred to spoken human-AI dialogue. We introduce two conversational paradigms - a Spelling Bee task and a sentence completion task- and an end-to-end pipeline for transcribing, annotating, and aligning word-level conversational events with continuous EEG classifier output. In a pilot study, workload decoding showed interpretable trends during spoken interaction, supporting cross-paradigm transfer. For implicit agreement, we demonstrate continuous application and precise temporal alignment to conversational events, while identifying limitations related to construct transfer and asynchronous application of event-based classifiers. Overall, the results establish feasibility and constraints for integrating passive BCI signals into conversational AI systems.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u5982\u4f55\u5728\u53e3\u8bed\u5bf9\u8bdd\u4e2d\u5229\u7528\u88ab\u52a8\u8111\u673a\u63a5\u53e3\u4fe1\u53f7\uff0c\u9a8c\u8bc1\u4e86EEG\u5206\u7c7b\u5668\u7684\u53ef\u79fb\u8f6c\u6027\uff0c\u5e76\u8bc6\u522b\u4e86\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u9650\u5236\u3002", "motivation": "\u5e0c\u671b\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u5229\u7528\u5927\u8111\u4fe1\u53f7\u63d0\u4f9b\u9690\u5f0f\u53cd\u9988\uff0c\u63d0\u9ad8\u4eba\u673a\u4ea4\u4e92\u7684\u667a\u80fd\u4e0e\u6548\u7387\u3002", "method": "\u6784\u5efa\u4e86\u4e24\u79cd\u5bf9\u8bdd\u4efb\u52a1\uff08\u62fc\u5199\u8702\u548c\u53e5\u5b50\u5b8c\u6210\uff09\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u6d41\u7a0b\u7528\u4e8e\u8f6c\u5f55\u3001\u6ce8\u91ca\u548c\u5c06\u5bf9\u8bdd\u4e8b\u4ef6\u4e0e\u8fde\u7eedEEG\u5206\u7c7b\u5668\u8f93\u51fa\u5bf9\u9f50\u3002", "result": "\u901a\u8fc7\u5f15\u5165\u88ab\u52a8\u8111\u673a\u63a5\u53e3\uff08BCI\uff09\u4fe1\u53f7\uff0c\u7814\u7a76\u4e86\u5176\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u9690\u5f0f\u53cd\u9988\u5e94\u7528\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0cEEG\u5206\u7c7b\u5668\u5728\u53e3\u8bed\u4eba\u673a\u5bf9\u8bdd\u4e2d\u7684\u6709\u6548\u6027\u53ca\u5176\u5c40\u9650\u6027\uff1b\u5c24\u5176\u662f\u5de5\u4f5c\u8d1f\u8377\u89e3\u7801\u5c55\u793a\u4e86\u7406\u89e3\u8d8b\u52bf\uff0c\u800c\u9690\u5f0f\u540c\u610f\u5219\u6210\u529f\u4e0e\u5bf9\u8bdd\u4e8b\u4ef6\u7cbe\u786e\u5bf9\u9f50\u3002"}}
{"id": "2601.05533", "categories": ["cs.RO", "cs.FL"], "pdf": "https://arxiv.org/pdf/2601.05533", "abs": "https://arxiv.org/abs/2601.05533", "authors": ["Kandai Watanabe", "Nicholas Renninger", "Sriram Sankaranarayanan", "Morteza Lahijanian"], "title": "Learning specifications for reactive synthesis with safety constraints", "comment": null, "summary": "This paper presents a novel approach to learning from demonstration that enables robots to autonomously execute complex tasks in dynamic environments. We model latent tasks as probabilistic formal languages and introduce a tailored reactive synthesis framework that balances robot costs with user task preferences. Our methodology focuses on safety-constrained learning and inferring formal task specifications as Probabilistic Deterministic Finite Automata (PDFA). We adapt existing evidence-driven state merging algorithms and incorporate safety requirements throughout the learning process to ensure that the learned PDFA always complies with safety constraints. Furthermore, we introduce a multi-objective reactive synthesis algorithm that generates deterministic strategies that are guaranteed to satisfy the PDFA task while optimizing the trade-offs between user preferences and robot costs, resulting in a Pareto front of optimal solutions. Our approach models the interaction as a two-player game between the robot and the environment, accounting for dynamic changes. We present a computationally-tractable value iteration algorithm to generate the Pareto front and the corresponding deterministic strategies. Comprehensive experimental results demonstrate the effectiveness of our algorithms across various robots and tasks, showing that the learned PDFA never includes unsafe behaviors and that synthesized strategies consistently achieve the task while meeting both the robot cost and user-preference requirements.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u4ece\u793a\u4f8b\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u4f7f\u673a\u5668\u4eba\u80fd\u591f\u5728\u52a8\u6001\u73af\u5883\u4e2d\u81ea\u4e3b\u6267\u884c\u590d\u6742\u4efb\u52a1\uff0c\u4fa7\u91cd\u5b89\u5168\u7ea6\u675f\u548c\u7528\u6237\u504f\u597d\u7684\u5e73\u8861\u3002", "motivation": "\u7814\u7a76\u7684\u52a8\u673a\u5728\u4e8e\u63d0\u9ad8\u673a\u5668\u4eba\u5728\u52a8\u6001\u73af\u5883\u4e2d\u81ea\u4e3b\u6267\u884c\u590d\u6742\u4efb\u52a1\u7684\u80fd\u529b\uff0c\u540c\u65f6\u786e\u4fdd\u5b89\u5168\u6027\u548c\u7528\u6237\u7684\u5177\u4f53\u4efb\u52a1\u504f\u597d\u3002", "method": "\u91c7\u7528\u5c06\u6f5c\u5728\u4efb\u52a1\u5efa\u6a21\u4e3a\u6982\u7387\u5f62\u5f0f\u8bed\u8a00\u7684\u65b9\u5f0f\uff0c\u7ed3\u5408\u5b9a\u5236\u7684\u53cd\u5e94\u5408\u6210\u6846\u67b6\uff0c\u4f7f\u7528\u6982\u7387\u786e\u5b9a\u6027\u6709\u9650\u81ea\u52a8\u673a (PDFA) \u5b66\u4e60\u4efb\u52a1\u89c4\u8303\uff0c\u5e76\u5f15\u5165\u591a\u76ee\u6807\u53cd\u5e94\u5408\u6210\u7b97\u6cd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5730\u5b66\u4e60\u6ee1\u8db3\u5b89\u5168\u7ea6\u675f\u7684PDFA\uff0c\u5e76\u4f18\u5316\u7528\u6237\u504f\u597d\u4e0e\u673a\u5668\u4eba\u6210\u672c\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u6700\u7ec8\u5f62\u6210\u6709\u6548\u7684Pareto\u524d\u6cbf\u89e3\u3002", "conclusion": "\u603b\u7ed3\u8868\u660e\u6240\u63d0\u7b97\u6cd5\u5728\u591a\u4e2a\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u4f18\u79c0\uff0c\u4fdd\u8bc1\u4e86\u751f\u6210\u7684\u7b56\u7565\u4e0d\u4ec5\u6ee1\u8db3\u4efb\u52a1\u8981\u6c42\uff0c\u540c\u65f6\u907f\u514d\u4e86\u4e0d\u5b89\u5168\u884c\u4e3a\u7684\u51fa\u73b0\u3002"}}
{"id": "2601.05871", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.05871", "abs": "https://arxiv.org/abs/2601.05871", "authors": ["Andy Crabtree"], "title": "How to Analyse Interviews: A Documentary Method of Interpretation", "comment": null, "summary": "Interviews are commonplace in HCI. This paper presents a novel documentary method of interpretation that supports analysis of the topics contained within a collection of transcripts, topics that are endogenous to it and which elaborate participants collective reasoning about issues of relevance to research. We contrast endogenous topic analysis with established qualitative approaches, including content analysis, grounded theory, interpretative phenomenological analysis, and thematic analysis, to draw out the distinctive character of the documentary method of interpretation. Unlike established methods, the DMI does not require that the analyst be proficient in qualitative analysis, or have sound knowledge of underlying theories and methods. The DMI is a members method, not a social science method, that relies on mastery of natural language; a competence most people possess.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\u2014\u2014\u6587\u6863\u89e3\u91ca\u6cd5\uff08DMI\uff09\uff0c\u7528\u4e8e\u5206\u6790\u8bbf\u8c08\u8f6c\u5f55\u4e2d\u7684\u4e3b\u9898\uff0c\u5f3a\u8c03\u4e86\u5176\u4e0e\u4f20\u7edf\u5b9a\u6027\u5206\u6790\u65b9\u6cd5\u7684\u4e0d\u540c\u4e4b\u5904\uff0cDMI\u4e0d\u9700\u8981\u5206\u6790\u5e08\u5177\u5907\u5b9a\u6027\u5206\u6790\u7684\u4e13\u4e1a\u77e5\u8bc6\u3002", "motivation": "\u968f\u7740\u4eba\u673a\u4ea4\u4e92\u4e2d\u7684\u8bbf\u8c08\u53d8\u5f97\u8d8a\u6765\u8d8a\u666e\u904d\uff0c\u8feb\u5207\u9700\u8981\u4e00\u79cd\u65b0\u65b9\u6cd5\u6765\u5206\u6790\u8bbf\u8c08\u5185\u5bb9\uff0c\u8fd9\u79cd\u65b9\u6cd5\u5e94\u5f53\u66f4\u52a0\u6613\u7528\u4e14\u4e0d\u9700\u8981\u7279\u6b8a\u7684\u5b66\u672f\u80cc\u666f\u3002", "method": "\u672c\u6587\u63d0\u51fa\u7684\u6587\u6863\u89e3\u91ca\u6cd5\uff08DMI\uff09\u662f\u4e00\u79cd\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u80fd\u529b\u7684\u5206\u6790\u65b9\u6cd5\uff0c\u4e0d\u8981\u6c42\u5206\u6790\u5e08\u638c\u63e1\u590d\u6742\u7684\u5b9a\u6027\u5206\u6790\u6280\u672f\u6216\u7406\u8bba\u3002", "result": "\u901a\u8fc7\u4e0e\u4f20\u7edf\u7684\u5b9a\u6027\u5206\u6790\u65b9\u6cd5\u8fdb\u884c\u6bd4\u8f83\uff0cDMI\u663e\u793a\u51fa\u72ec\u7279\u7684\u4f18\u52bf\uff0c\u4f7f\u5f97\u4e00\u822c\u516c\u4f17\u4e5f\u80fd\u53c2\u4e0e\u5230\u8bbf\u8c08\u5185\u5bb9\u7684\u5206\u6790\u4e2d\u6765\u3002", "conclusion": "\u8fd9\u7bc7\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6587\u6863\u89e3\u91ca\u65b9\u6cd5\uff0c\u7279\u522b\u9002\u5408\u5904\u7406\u4eba\u673a\u4ea4\u4e92\uff08HCI\uff09\u4e2d\u7684\u8bbf\u8c08\u8f6c\u5f55\u5185\u5bb9\u5206\u6790\u3002"}}
{"id": "2601.05653", "categories": ["cs.RO", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.05653", "abs": "https://arxiv.org/abs/2601.05653", "authors": ["Phu-Hoa Pham", "Chi-Nguyen Tran", "Duy-Minh Dao-Sy", "Phu-Quy Nguyen-Lam", "Trung-Kiet Huynh"], "title": "EvoQRE: Modeling Bounded Rationality in Safety-Critical Traffic Simulation via Evolutionary Quantal Response Equilibrium", "comment": "11 pages, 5 figures", "summary": "Existing traffic simulation frameworks for autonomous vehicles typically rely on imitation learning or game-theoretic approaches that solve for Nash or coarse correlated equilibria, implicitly assuming perfectly rational agents. However, human drivers exhibit bounded rationality, making approximately optimal decisions under cognitive and perceptual constraints. We propose EvoQRE, a principled framework for modeling safety-critical traffic interactions as general-sum Markov games solved via Quantal Response Equilibrium (QRE) and evolutionary game dynamics. EvoQRE integrates a pre-trained generative world model with entropy-regularized replicator dynamics, capturing stochastic human behavior while maintaining equilibrium structure. We provide rigorous theoretical results, proving that the proposed dynamics converge to Logit-QRE under a two-timescale stochastic approximation with an explicit convergence rate of O(log k / k^{1/3}) under weak monotonicity assumptions. We further extend QRE to continuous action spaces using mixture-based and energy-based policy representations. Experiments on the Waymo Open Motion Dataset and nuPlan benchmark demonstrate that EvoQRE achieves state-of-the-art realism, improved safety metrics, and controllable generation of diverse safety-critical scenarios through interpretable rationality parameters.", "AI": {"tldr": "EvoQRE\u662f\u4e00\u79cd\u65b0\u7684\u4ea4\u901a\u6a21\u62df\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408QRE\u548c\u8fdb\u5316\u535a\u5f08\u52a8\u6001\uff0c\u66f4\u597d\u5730\u6a21\u62df\u4eba\u7c7b\u53f8\u673a\u7684\u6709\u9650\u7406\u6027\u884c\u4e3a\u3002", "motivation": "\u73b0\u6709\u7684\u4ea4\u901a\u6a21\u62df\u6846\u67b6\u901a\u5e38\u5047\u8bbe\u667a\u80fd\u4f53\u662f\u5b8c\u5168\u7406\u6027\u7684\uff0c\u800c\u4eba\u7c7b\u53f8\u673a\u5219\u8868\u73b0\u51fa\u6709\u9650\u7406\u6027\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u66f4\u7b26\u5408\u4eba\u7c7b\u9a7e\u9a76\u884c\u4e3a\u7684\u6a21\u578b\u3002", "method": "\u63d0\u51faEvoQRE\u6846\u67b6\uff0c\u5229\u7528Quantal Response Equilibrium (QRE)\u548c\u8fdb\u5316\u535a\u5f08\u52a8\u6001\uff0c\u5c06\u4ea4\u901a\u4e92\u52a8\u5efa\u6a21\u4e3a\u4e00\u822c\u548c\u535a\u5f08\uff0c\u5e76\u7ed3\u5408\u9884\u8bad\u7ec3\u7684\u751f\u6210\u4e16\u754c\u6a21\u578b\u4e0e\u71b5\u6b63\u5219\u5316\u7684\u590d\u5236\u5668\u52a8\u6001\u3002", "result": "EvoQRE\u5728Waymo Open Motion Dataset\u548cnuPlan\u57fa\u51c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u8be5\u6846\u67b6\u5728\u73b0\u5b9e\u4e3b\u4e49\u548c\u5b89\u5168\u6027\u6307\u6807\u4e0a\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6c34\u5e73\uff0c\u5e76\u80fd\u901a\u8fc7\u53ef\u89e3\u91ca\u7684\u7406\u6027\u53c2\u6570\u53ef\u63a7\u5730\u4ea7\u751f\u591a\u6837\u7684\u5b89\u5168\u5173\u952e\u573a\u666f\u3002", "conclusion": "EvoQRE\u6210\u529f\u5730\u6355\u83b7\u4e86\u968f\u673a\u4eba\u7c7b\u884c\u4e3a\u5e76\u4fdd\u6301\u4e86\u5747\u8861\u7ed3\u6784\uff0c\u663e\u793a\u51fa\u66f4\u7b26\u5408\u4eba\u7c7b\u884c\u4e3a\u7684\u4ea4\u901a\u6a21\u62df\u80fd\u529b\u3002"}}
{"id": "2601.05974", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.05974", "abs": "https://arxiv.org/abs/2601.05974", "authors": ["Goran Muric", "Steven Minton"], "title": "A Framework for Optimizing Human-Machine Interaction in Classification Systems", "comment": null, "summary": "Automated decision systems increasingly rely on human oversight to ensure accuracy in uncertain cases. This paper presents a practical framework for optimizing such human-in-the-loop classification systems using a double-threshold policy. Instead of relying on a single decision cutoff, the system defines two thresholds (a lower and an upper) to automatically accept or reject confident cases while routing ambiguous ones for human review. We formalize this problem as an optimization task that balances system accuracy against human review workload and demonstrate its behavior through extensive Monte Carlo simulations. Our results quantify how different probability score distributions affect the efficiency of human intervention and identify the regions of diminishing returns where additional review yields minimal benefit. The framework provides a general, reproducible method for improving reliability in any decision pipeline requiring selective human validation, including applications in entity resolution, fraud detection, medical triage, and content moderation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u9608\u503c\u7b56\u7565\u4e0b\u7684\u4f18\u5316\u6846\u67b6\uff0c\u4ee5\u63d0\u5347\u4eba\u7c7b\u53c2\u4e0e\u7684\u5206\u7c7b\u7cfb\u7edf\u5728\u4e0d\u786e\u5b9a\u60c5\u51b5\u4e0b\u7684\u51c6\u786e\u6027\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u6a21\u7cca\u6848\u4f8b\u65f6\uff0c\u7ed3\u5408\u4eba\u5de5\u5ba1\u6838\u4ee5\u63d0\u9ad8\u51b3\u7b56\u6548\u7387\u3002", "motivation": "\u968f\u7740\u81ea\u52a8\u51b3\u7b56\u7cfb\u7edf\u7684\u666e\u53ca\uff0c\u786e\u4fdd\u7cfb\u7edf\u5728\u4e0d\u786e\u5b9a\u60c5\u51b5\u4e0b\u7684\u51c6\u786e\u6027\u53d8\u5f97\u81f3\u5173\u91cd\u8981\uff0c\u7279\u522b\u662f\u9700\u8981\u4eba\u7c7b\u76d1\u7763\u7684\u60c5\u51b5\u4e0b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u9608\u503c\u653f\u7b56\u6765\u81ea\u52a8\u63a5\u53d7\u6216\u62d2\u7edd\u660e\u786e\u6848\u4f8b\uff0c\u540c\u65f6\u5c06\u6a21\u7cca\u6848\u4f8b\u8f6c\u4ea4\u4eba\u7c7b\u5ba1\u6838\uff0c\u5e76\u5c06\u8fd9\u4e00\u95ee\u9898\u5f62\u5f0f\u5316\u4e3a\u4e00\u4e2a\u4f18\u5316\u4efb\u52a1\uff0c\u4ee5\u5e73\u8861\u7cfb\u7edf\u7684\u51c6\u786e\u6027\u4e0e\u4eba\u7c7b\u5ba1\u6838\u7684\u5de5\u4f5c\u8d1f\u8377\u3002", "result": "\u901a\u8fc7\u5e7f\u6cdb\u7684\u8499\u7279\u5361\u6d1b\u4eff\u771f\uff0c\u91cf\u5316\u4e86\u4e0d\u540c\u6982\u7387\u5206\u5e03\u5728\u63d0\u5347\u4eba\u7c7b\u5e72\u9884\u6548\u7387\u65b9\u9762\u7684\u5f71\u54cd\uff0c\u5e76\u8bc6\u522b\u51fa\u4e86\u989d\u5916\u5ba1\u6838\u6536\u76ca\u9012\u51cf\u7684\u533a\u57df\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u9700\u8981\u9009\u62e9\u6027\u4eba\u7c7b\u9a8c\u8bc1\u7684\u4efb\u4f55\u51b3\u7b56\u6d41\u7a0b\u63d0\u4f9b\u4e86\u4e00\u79cd\u901a\u7528\u3001\u53ef\u91cd\u590d\u7684\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u591a\u4e2a\u9886\u57df\uff0c\u5982\u5b9e\u4f53\u89e3\u6790\u3001\u6b3a\u8bc8\u68c0\u6d4b\u3001\u533b\u7597\u5206\u8bca\u548c\u5185\u5bb9\u5ba1\u6838\u3002"}}
{"id": "2601.05661", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.05661", "abs": "https://arxiv.org/abs/2601.05661", "authors": ["Matija Markulin", "Luka Matijevi\u0107", "Luka Siktar", "Janko Jurdana", "Branimir Caran", "Marko \u0160vaco", "Filip \u0160uligoj", "Bojan \u0160ekoranja"], "title": "Motion Compensation for Real Time Ultrasound Scanning in Robotically Assisted Prostate Biopsy Procedures", "comment": "Submitted for ICRA 2026", "summary": "Prostate cancer is one of the most common types of cancer in men. Its diagnosis by biopsy requires a high level of expertise and precision from the surgeon, so the results are highly operator-dependent. The aim of this work is to develop a robotic system for assisted ultrasound (US) examination of the prostate, a prebiopsy step that could reduce the dexterity requirements and enable faster, more accurate and more available prostate biopsy. We developed and validated a laboratory setup with a collaborative robotic arm that can autonomously scan a prostate phantom and attached the phantom to a medical robotic arm that mimics the patient's movements. The scanning robot keeps the relative position of the US probe and the prostate constant, ensuring a consistent and robust approach to reconstructing the prostate. To reconstruct the prostate, each slice is segmented to generate a series of prostate contours converted into a 3D point cloud used for biopsy planning. The average scan time of the prostate was 30 s, and the average 3D reconstruction of the prostate took 3 s. We performed four motion scenarios: the phantom was scanned in a stationary state (S), with horizontal motion (H), with vertical motion (V), and with a combination of the two (C). System validation is performed by registering the prostate point cloud reconstructions acquired during different motions (H, V, C) with those obtained in the stationary state. ICP registration with a threshold of 0.8 mm yields mean 83.2\\% fitness and 0.35 mm RMSE for S-H registration, 84.1\\% fitness and 0.37 mm RMSE for S-V registration and 79.4\\% fitness and 0.37 mm RMSE for S-C registration. Due to the elastic and soft material properties of the prostate phantom, the maximum robot tracking error was 3 mm, which can be sufficient for prostate biopsy according to medical literature. The maximum delay in motion compensation was 0.5 s.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u79cd\u534f\u4f5c\u673a\u5668\u4eba\u7cfb\u7edf\u7528\u4e8e\u524d\u5217\u817a\u8d85\u58f0\u68c0\u67e5\uff0c\u63d0\u5347\u4e86\u6d3b\u68c0\u7684\u51c6\u786e\u6027\u4e0e\u53ef\u7528\u6027\u3002", "motivation": "\u7531\u4e8e\u524d\u5217\u817a\u764c\u7684\u6d3b\u68c0\u7ed3\u679c\u4f9d\u8d56\u4e8e\u5916\u79d1\u533b\u751f\u7684\u4e13\u4e1a\u6c34\u5e73\uff0c\u672c\u7814\u7a76\u65e8\u5728\u51cf\u5c11\u5bf9\u64cd\u4f5c\u8005\u7075\u5de7\u6027\u7684\u8981\u6c42\uff0c\u5b9e\u73b0\u66f4\u5feb\u3001\u66f4\u51c6\u786e\u7684\u524d\u5217\u817a\u6d3b\u68c0\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u534f\u4f5c\u673a\u5668\u4eba\u7cfb\u7edf\uff0c\u7528\u4e8e\u524d\u5217\u817a\u7684\u8f85\u52a9\u8d85\u58f0\u68c0\u67e5\uff0c\u8fdb\u884c\u524d\u671f\u6d3b\u68c0\u6b65\u9aa4\u3002", "result": "\u901a\u8fc7\u673a\u5668\u4eba\u626b\u63cf\u5047\u4f53\u5e76\u8fdb\u884c\u4e09\u7ef4\u91cd\u5efa\uff0c\u5e73\u5747\u626b\u63cf\u65f6\u95f4\u4e3a30\u79d2\uff0c\u4e09\u7ef4\u91cd\u5efa\u65f6\u95f4\u4e3a3\u79d2\u3002\u7cfb\u7edf\u9a8c\u8bc1\u901a\u8fc7\u4e0d\u540c\u8fd0\u52a8\u72b6\u6001\u4e0b\u7684\u70b9\u4e91\u914d\u51c6\uff0c\u8fbe\u5230\u5e73\u574783.2%-84.1%\u7684\u543b\u5408\u5ea6\u3002", "conclusion": "\u8be5\u673a\u5668\u4eba\u7cfb\u7edf\u80fd\u591f\u63d0\u9ad8\u524d\u5217\u817a\u6d3b\u68c0\u7684\u51c6\u786e\u6027\u548c\u53ef\u7528\u6027\uff0c\u6700\u5927\u8ffd\u8e2a\u8bef\u5dee\u4e3a3\u6beb\u7c73\uff0c\u7b26\u5408\u533b\u5b66\u6587\u732e\u4e2d\u5bf9\u6d3b\u68c0\u7684\u8981\u6c42\u3002"}}
{"id": "2601.05805", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.05805", "abs": "https://arxiv.org/abs/2601.05805", "authors": ["Simon Archieri", "Ahmet Cinar", "Shu Pan", "Jonatan Scharff Willners", "Michele Grimald", "Ignacio Carlucho", "Yvan Petillot"], "title": "InsSo3D: Inertial Navigation System and 3D Sonar SLAM for turbid environment inspection", "comment": null, "summary": "This paper presents InsSo3D, an accurate and efficient method for large-scale 3D Simultaneous Localisation and Mapping (SLAM) using a 3D Sonar and an Inertial Navigation System (INS). Unlike traditional sonar, which produces 2D images containing range and azimuth information but lacks elevation information, 3D Sonar produces a 3D point cloud, which therefore does not suffer from elevation ambiguity. We introduce a robust and modern SLAM framework adapted to the 3D Sonar data using INS as prior, detecting loop closure and performing pose graph optimisation. We evaluated InsSo3D performance inside a test tank with access to ground truth data and in an outdoor flooded quarry. Comparisons to reference trajectories and maps obtained from an underwater motion tracking system and visual Structure From Motion (SFM) demonstrate that InsSo3D efficiently corrects odometry drift. The average trajectory error is below 21cm during a 50-minute-long mission, producing a map of 10m by 20m with a 9cm average reconstruction error, enabling safe inspection of natural or artificial underwater structures even in murky water conditions.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u75283D\u58f0\u7eb3\u548c\u60ef\u6027\u5bfc\u822a\u7cfb\u7edf\u7684\u4e09\u7ef4\u540c\u65f6\u5b9a\u4f4d\u4e0e\u5efa\u56fe\u65b9\u6cd5InsSo3D\uff0c\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u5728\u6c34\u4e0b\u6761\u4ef6\u4e0b\u5177\u6709\u4f4e\u8bef\u5dee\u548c\u826f\u597d\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u58f0\u7eb3\u65e0\u6cd5\u63d0\u4f9b\u9ad8\u5ea6\u4fe1\u606f\uff0c\u800c3D\u58f0\u7eb3\u80fd\u591f\u4ea7\u751f\u4e09\u7ef4\u70b9\u4e91\uff0c\u4ee5\u514b\u670d\u8fd9\u4e00\u9650\u5236\uff0c\u4ece\u800c\u63d0\u5347\u6c34\u4e0bSLAM\u7684\u7cbe\u5ea6\u548c\u53ef\u9760\u6027\u3002", "method": "\u91c7\u7528\u4e00\u79cd\u73b0\u4ee3\u5316\u7684SLAM\u6846\u67b6\uff0c\u7ed3\u54083D\u58f0\u7eb3\u6570\u636e\u548c\u60ef\u6027\u5bfc\u822a\u7cfb\u7edf\uff0c\u6267\u884c\u56de\u73af\u68c0\u6d4b\u548c\u4f4d\u59ff\u56fe\u4f18\u5316\u3002", "result": "\u5728\u6d4b\u8bd5\u8fc7\u7a0b\u4e2d\uff0cInsSo3D\u7684\u5e73\u5747\u8f68\u8ff9\u8bef\u5dee\u4f4e\u4e8e21\u5398\u7c73\uff0c\u5e76\u4e14\u5728\u4e00\u4e2a50\u5206\u949f\u7684\u4efb\u52a1\u4e2d\uff0c\u4ea7\u751f\u7684\u5730\u56fe\u5e73\u5747\u91cd\u5efa\u8bef\u5dee\u4e3a9\u5398\u7c73\u3002", "conclusion": "InsSo3D\u662f\u4e00\u79cd\u9ad8\u6548\u51c6\u786e\u7684\u4e09\u7ef4\u540c\u65f6\u5b9a\u4f4d\u4e0e\u5efa\u56fe\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u590d\u6742\u6c34\u4e0b\u73af\u5883\u4e2d\u5b9e\u73b0\u53ef\u9760\u7684\u5b9a\u4f4d\u548c\u5730\u56fe\u6784\u5efa\u3002"}}
{"id": "2601.05806", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.05806", "abs": "https://arxiv.org/abs/2601.05806", "authors": ["Marvin Seegert", "Korbinian Moller", "Johannes Betz"], "title": "Modular Autonomy with Conversational Interaction: An LLM-driven Framework for Decision Making in Autonomous Driving", "comment": "Submitted to the IEEE Intelligent Vehicles Symposium (IV 2026), Detroit, MI, United States", "summary": "Recent advancements in Large Language Models (LLMs) offer new opportunities to create natural language interfaces for Autonomous Driving Systems (ADSs), moving beyond rigid inputs. This paper addresses the challenge of mapping the complexity of human language to the structured action space of modular ADS software. We propose a framework that integrates an LLM-based interaction layer with Autoware, a widely used open-source software. This system enables passengers to issue high-level commands, from querying status information to modifying driving behavior. Our methodology is grounded in three key components: a taxonomization of interaction categories, an application-centric Domain Specific Language (DSL) for command translation, and a safety-preserving validation layer. A two-stage LLM architecture ensures high transparency by providing feedback based on the definitive execution status. Evaluation confirms the system's timing efficiency and translation robustness. Simulation successfully validated command execution across all five interaction categories. This work provides a foundation for extensible, DSL-assisted interaction in modular and safety-conscious autonomy stacks.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6574\u5408LLM\u7684\u6846\u67b6\uff0c\u4e3aADS\u521b\u5efa\u81ea\u7136\u8bed\u8a00\u63a5\u53e3\uff0c\u652f\u6301\u591a\u79cd\u9ad8\u5c42\u547d\u4ee4\u7684\u6267\u884c\uff0c\u5e76\u786e\u4fdd\u5b89\u5168\u548c\u9ad8\u6548\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8fdb\u6b65\uff0c\u4e3a\u81ea\u4e3b\u9a7e\u9a76\u7cfb\u7edf\u521b\u9020\u81ea\u7136\u8bed\u8a00\u63a5\u53e3\u7684\u673a\u4f1a\u589e\u591a\uff0c\u4f46\u4eba\u7c7b\u8bed\u8a00\u7684\u590d\u6742\u6027\u4e0e\u7ed3\u6784\u5316\u64cd\u4f5c\u7a7a\u95f4\u4e4b\u95f4\u5b58\u5728\u5de8\u5927\u6311\u6218\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u7684\u6846\u67b6\u5305\u62ec\u4e09\u4e2a\u5173\u952e\u7ec4\u6210\u90e8\u5206\uff1a\u4ea4\u4e92\u7c7b\u522b\u7684\u5206\u7c7b\u3001\u7528\u4e8e\u547d\u4ee4\u7ffb\u8bd1\u7684\u5e94\u7528\u4e2d\u5fc3\u9886\u57df\u7279\u5b9a\u8bed\u8a00\uff08DSL\uff09\u3001\u4ee5\u53ca\u4fdd\u62a4\u5b89\u5168\u7684\u9a8c\u8bc1\u5c42\u3002\u91c7\u7528\u4e24\u9636\u6bb5LLM\u67b6\u6784\uff0c\u786e\u4fdd\u901a\u8fc7\u53cd\u9988\u63d0\u4f9b\u9ad8\u900f\u660e\u6027\u3002", "result": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e0e\u5f00\u6e90\u8f6f\u4ef6Autoware\u96c6\u6210\u7684\u6846\u67b6\uff0c\u65e8\u5728\u4e3a\u81ea\u4e3b\u9a7e\u9a76\u7cfb\u7edf\uff08ADS\uff09\u521b\u5efa\u81ea\u7136\u8bed\u8a00\u63a5\u53e3\u3002\u8be5\u7cfb\u7edf\u53ef\u4ee5\u5904\u7406\u4eba\u7c7b\u8bed\u8a00\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u64cd\u4f5c\u7a7a\u95f4\u7684\u590d\u6742\u6027\uff0c\u4f7f\u4e58\u5ba2\u80fd\u591f\u9ad8\u5c42\u6b21\u53d1\u51fa\u547d\u4ee4\uff0c\u5982\u67e5\u8be2\u72b6\u6001\u4fe1\u606f\u6216\u4fee\u6539\u9a7e\u9a76\u884c\u4e3a\u3002", "conclusion": "\u6211\u4eec\u7684\u8bc4\u4f30\u786e\u8ba4\u4e86\u8be5\u7cfb\u7edf\u7684\u65f6\u6548\u6027\u548c\u7ffb\u8bd1\u7684\u7a33\u5065\u6027\u3002\u901a\u8fc7\u4eff\u771f\u9a8c\u8bc1\u4e86\u547d\u4ee4\u5728\u4e94\u79cd\u4ea4\u4e92\u7c7b\u522b\u4e0b\u7684\u6267\u884c\u3002\u8fd9\u9879\u5de5\u4f5c\u4e3a\u6a21\u5757\u5316\u548c\u5b89\u5168\u610f\u8bc6\u5f3a\u7684\u81ea\u4e3b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u3001\u57fa\u4e8e\u9886\u57df\u4e13\u7528\u8bed\u8a00\uff08DSL\uff09\u8f85\u52a9\u7684\u4ea4\u4e92\u57fa\u7840\u3002"}}
{"id": "2601.05836", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05836", "abs": "https://arxiv.org/abs/2601.05836", "authors": ["Sheng-Kai Chen", "Jyh-Horng Wu"], "title": "Intelligent Singularity Avoidance in UR10 Robotic Arm Path Planning Using Hybrid Fuzzy Logic and Reinforcement Learning", "comment": "Published in TANET 2025 (Paper No. T0404)", "summary": "This paper presents a comprehensive approach to singularity detection and avoidance in UR10 robotic arm path planning through the integration of fuzzy logic safety systems and reinforcement learning algorithms. The proposed system addresses critical challenges in robotic manipulation where singularities can cause loss of control and potential equipment damage. Our hybrid approach combines real-time singularity detection using manipulability measures, condition number analysis, and fuzzy logic decision-making with a stable reinforcement learning framework for adaptive path planning. Experimental results demonstrate a 90% success rate in reaching target positions while maintaining safe distances from singular configurations. The system integrates PyBullet simulation for training data collection and URSim connectivity for real-world deployment.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6a21\u7cca\u903b\u8f91\u548c\u5f3a\u5316\u5b66\u4e60\u7684\u6df7\u5408\u65b9\u6cd5\uff0c\u4ee5\u76d1\u6d4b\u548c\u907f\u514dUR10\u673a\u68b0\u81c2\u7684\u5947\u5f02\u6027\u95ee\u9898\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5177\u6709\u9ad8\u6210\u529f\u7387\u548c\u5b89\u5168\u6027\u3002", "motivation": "\u672c\u7814\u7a76\u7684\u52a8\u529b\u5728\u4e8e\u89e3\u51b3\u673a\u5668\u4eba\u64cd\u4f5c\u4e2d\u7684\u5947\u5f02\u6027\u95ee\u9898\uff0c\u8fd9\u5bfc\u81f4\u4e86\u63a7\u5236\u4e27\u5931\u548c\u8bbe\u5907\u635f\u574f\u7684\u98ce\u9669\u3002", "method": "\u4f7f\u7528\u53ef\u64cd\u63a7\u6027\u5ea6\u91cf\u3001\u6761\u4ef6\u6570\u5206\u6790\u548c\u6a21\u7cca\u903b\u8f91\u51b3\u7b56\u5236\u5b9a\u8fdb\u884c\u5b9e\u65f6\u5947\u5f02\u6027\u68c0\u6d4b\uff0c\u5e76\u7ed3\u5408\u7a33\u5b9a\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u8fdb\u884c\u81ea\u9002\u5e94\u8def\u5f84\u89c4\u5212\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7efc\u5408\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728UR10\u673a\u68b0\u81c2\u8def\u5f84\u89c4\u5212\u4e2d\u68c0\u6d4b\u548c\u907f\u514d\u5947\u5f02\u6027\uff0c\u7ed3\u5408\u4e86\u6a21\u7cca\u903b\u8f91\u5b89\u5168\u7cfb\u7edf\u548c\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u3002\u8be5\u7cfb\u7edf\u6210\u529f\u89e3\u51b3\u4e86\u673a\u5668\u4eba\u64cd\u63a7\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u907f\u514d\u4e86\u56e0\u5947\u5f02\u6027\u9020\u6210\u7684\u5931\u63a7\u548c\u8bbe\u5907\u635f\u574f\u3002", "conclusion": "\u901a\u8fc7\u5b9e\u9a8c\u7ed3\u679c\uff0c\u8be5\u7cfb\u7edf\u5728\u5230\u8fbe\u76ee\u6807\u4f4d\u7f6e\u65f6\u6210\u529f\u7387\u4e3a90%\uff0c\u5e76\u6709\u6548\u4fdd\u6301\u4e86\u4e0e\u5947\u5f02\u914d\u7f6e\u7684\u5b89\u5168\u8ddd\u79bb\u3002"}}
