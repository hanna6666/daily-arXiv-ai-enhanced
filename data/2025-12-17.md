<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 22]
- [cs.HC](#cs.HC) [Total: 6]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [PrediFlow: A Flow-Based Prediction-Refinement Framework for Real-Time Human Motion Prediction in Human-Robot Collaboration](https://arxiv.org/abs/2512.13903)
*Sibo Tian,Minghui Zheng,Xiao Liang*

Main category: cs.RO

TL;DR: 本研究提出一种新框架，通过结合人体与机器人运动，提高了人类运动预测的质量与实时性，同时保留运动的多样性和不确定性。


<details>
  <summary>Details</summary>
Motivation: 人机协作中的运动预测存在现实性和准确性的问题，需同时考虑机器人运动对人的影响。

Method: 采用预测-细化框架，并利用Flow Matching结构对不确定性进行处理，以提高预测质量。

Result: 提出了一种新颖的预测-细化框架，通过整合人类和机器人观察到的运动，显著提高了运动预测的准确性，同时保持了人类运动的不确定性和多模态特性。

Conclusion: 实验表明，该方法在保持时间预算的同时，提升了预测精度，强调了人机协作中的实时性和现实性。

Abstract: Stochastic human motion prediction is critical for safe and effective human-robot collaboration (HRC) in industrial remanufacturing, as it captures human motion uncertainties and multi-modal behaviors that deterministic methods cannot handle. While earlier works emphasize highly diverse predictions, they often generate unrealistic human motions. More recent methods focus on accuracy and real-time performance, yet there remains potential to improve prediction quality further without exceeding time budgets. Additionally, current research on stochastic human motion prediction in HRC typically considers human motion in isolation, neglecting the influence of robot motion on human behavior. To address these research gaps and enable real-time, realistic, and interaction-aware human motion prediction, we propose a novel prediction-refinement framework that integrates both human and robot observed motion to refine the initial predictions produced by a pretrained state-of-the-art predictor. The refinement module employs a Flow Matching structure to account for uncertainty. Experimental studies on the HRC desktop disassembly dataset demonstrate that our method significantly improves prediction accuracy while preserving the uncertainties and multi-modalities of human motion. Moreover, the total inference time of the proposed framework remains within the time budget, highlighting the effectiveness and practicality of our approach.

</details>


### [2] [Autonomous Construction-Site Safety Inspection Using Mobile Robots: A Multilayer VLM-LLM Pipeline](https://arxiv.org/abs/2512.13974)
*Hossein Naderi,Alireza Shojaei,Philip Agee,Kereshmeh Afsari,Abiola Akanmu*

Main category: cs.RO

TL;DR: 本文提出了一种自动化建筑安全检查框架，结合机器人技术和人工智能，生成安全报告，验证结果显示高效能和透明度。


<details>
  <summary>Details</summary>
Motivation: 目前建筑安全检查仍然依赖人工，现有自动化方法困难于快速变化的环境，亟需开发一种可持续、自动的检查解决方案。

Method: 提出了一种多层框架，包括机器人和人工智能模块，使用SLAM和自主导航进行场景识别和安全报告生成，结合视觉语言模型和大型语言模型处理安全规则和报告。

Result: 在模拟环境中验证了所提框架，结果显示高召回率和有竞争力的精确度。

Conclusion: 该框架提供了一个透明、可推广的安全检查解决方案，能够与人工协作并为未来扩展提供基础。

Abstract: Construction safety inspection remains mostly manual, and automated approaches still rely on task-specific datasets that are hard to maintain in fast-changing construction environments due to frequent retraining. Meanwhile, field inspection with robots still depends on human teleoperation and manual reporting, which are labor-intensive. This paper aims to connect what a robot sees during autonomous navigation to the safety rules that are common in construction sites, automatically generating a safety inspection report. To this end, we proposed a multi-layer framework with two main modules: robotics and AI. On the robotics side, SLAM and autonomous navigation provide repeatable coverage and targeted revisits via waypoints. On AI side, a Vision Language Model (VLM)-based layer produces scene descriptions; a retrieval component powered grounds those descriptions in OSHA and site policies; Another VLM-based layer assesses the safety situation based on rules; and finally Large Language Model (LLM) layer generates safety reports based on previous outputs. The framework is validated with a proof-of-concept implementation and evaluated in a lab environment that simulates common hazards across three scenarios. Results show high recall with competitive precision compared to state-of-the-art closed-source models. This paper contributes a transparent, generalizable pipeline that moves beyond black-box models by exposing intermediate artifacts from each layer and keeping the human in the loop. This work provides a foundation for future extensions to additional tasks and settings within and beyond construction context.

</details>


### [3] [Impact of Robot Facial-Audio Expressions on Human Robot Trust Dynamics and Trust Repair](https://arxiv.org/abs/2512.13981)
*Hossein Naderi,Alireza Shojaei,Philip Agee,Kereshmeh Afsari,Abiola Akanmu*

Main category: cs.RO

TL;DR: 本研究探索了机器人在AEC行业中如何通过任务表现及表达反应影响人类信任的动态变化，研究显示成功提升信任，失败则显著降低，歉意表达能够部分恢复信任。


<details>
  <summary>Details</summary>
Motivation: 尽管机器人技术在建筑行业取得进展，但对信任动态变化的研究较少，亟需深入理解人机协作中的信任因素。

Method: 设计了一个控制实验，涉及两个建筑相关任务，并多次测量参与者的信任感，使用了14项信任感知量表及再委托选择。

Result: 结果表明，机器人成功会可靠地提高信任，但失败会造成显著下降。基于歉意的表达在一定程度上恢复了信任，尤其通过互动和沟通因素驱动恢复。

Conclusion: 本研究为未来根据任务需求和用户特征调整恢复策略提供了基础，有助于在建筑现场安全有效地采用机器人。

Abstract: Despite recent advances in robotics and human-robot collaboration in the AEC industry, trust has mostly been treated as a static factor, with little guidance on how it changes across events during collaboration. This paper investigates how a robot's task performance and its expressive responses after outcomes shape the dynamics of human trust over time. To this end, we designed a controlled within-subjects study with two construction-inspired tasks, Material Delivery (physical assistance) and Information Gathering (perceptual assistance), and measured trust repeatedly (four times per task) using the 14-item Trust Perception Scale for HRI plus a redelegation choice. The robot produced two multimodal expressions, a "glad" display with a brief confirmation after success, and a "sad" display with an apology and a request for a second chance after failure. The study was conducted in a lab environment with 30 participants and a quadruped platform, and we evaluated trust dynamics and repair across both tasks. Results show that robot success reliably increases trust, failure causes sharp drops, and apology-based expressions partially restores trust (44% recovery in Material Delivery; 38% in Information Gathering). Item-level analysis indicates that recovered trust was driven mostly by interaction and communication factors, with competence recovering partially and autonomy aspects changing least. Additionally, age group and prior attitudes moderated trust dynamics with younger participants showed larger but shorter-lived changes, mid-20s participants exhibited the most durable repair, and older participants showed most conservative dynamics. This work provides a foundation for future efforts that adapt repair strategies to task demands and user profiles to support safe, productive adoption of robots on construction sites.

</details>


### [4] [CLAIM: Camera-LiDAR Alignment with Intensity and Monodepth](https://arxiv.org/abs/2512.14001)
*Zhuo Zhang,Yonghui Liu,Meijie Zhang,Feiyang Tan,Yikang Ding*

Main category: cs.RO

TL;DR: 提出一种新方法CLAIM，用于相机与LiDAR数据的校准，简化了过程并提高了性能。


<details>
  <summary>Details</summary>
Motivation: 当前相机与LiDAR校准方法复杂且需多步骤处理，存在适应性不足的问题。

Method: CLAIM利用粗到细的搜索方法，结合基于皮尔森相关性的结构损失和基于互信息的纹理损失来优化变换。

Result: CLAIM在KITTI、Waymo和MIAS-LCEC数据集上表现优越，超越了现有最先进方法。

Conclusion: CLAIM方法简单且适应性强，能有效提升相机与LiDAR的校准效果。

Abstract: In this paper, we unleash the potential of the powerful monodepth model in camera-LiDAR calibration and propose CLAIM, a novel method of aligning data from the camera and LiDAR. Given the initial guess and pairs of images and LiDAR point clouds, CLAIM utilizes a coarse-to-fine searching method to find the optimal transformation minimizing a patched Pearson correlation-based structure loss and a mutual information-based texture loss. These two losses serve as good metrics for camera-LiDAR alignment results and require no complicated steps of data processing, feature extraction, or feature matching like most methods, rendering our method simple and adaptive to most scenes. We validate CLAIM on public KITTI, Waymo, and MIAS-LCEC datasets, and the experimental results demonstrate its superior performance compared with the state-of-the-art methods. The code is available at https://github.com/Tompson11/claim.

</details>


### [5] [Sample-Efficient Robot Skill Learning for Construction Tasks: Benchmarking Hierarchical Reinforcement Learning and Vision-Language-Action VLA Model](https://arxiv.org/abs/2512.14031)
*Zhaofeng Hu,Hongrui Yu,Vaidhyanathan Chandramouli,Ci-Jyun Liang*

Main category: cs.RO

TL;DR: 这项研究评估了VLA和RL在建筑机器人技能教学上的实用性，发现VLA在减轻编程工作和增强任务适应性方面表现更佳。


<details>
  <summary>Details</summary>
Motivation: 评估两种主要方法在建筑自动化中教导机器人新技能的适用性。

Method: 对比视觉语言行动（VLA）模型和强化学习（RL）方法，通过开发遥操作界面收集演示，并进行三阶段评估。

Result: VLA模型在拾取阶段取得60%和100%的成功率，展现出强大的泛化能力和少量学习能力；相比之下，DQN虽可增强稳定性，但需要额外的噪声调优，增加工作量。

Conclusion: VLA在任务变化上提供了实用优势，减少编程工作，且可以在最小数据下实现有用的性能，而DQN在需要足够调优工作时也能作为可行基准。

Abstract: This study evaluates two leading approaches for teaching construction robots new skills to understand their applicability for construction automation: a Vision-Language-Action (VLA) model and Reinforcement Learning (RL) methods. The goal is to understand both task performance and the practical effort needed to deploy each approach on real jobs. The authors developed two teleoperation interfaces to control the robots and collect the demonstrations needed, both of which proved effective for training robots for long-horizon and dexterous tasks. In addition, the authors conduct a three-stage evaluation. First, the authors compare a Multi-Layer Perceptron (MLP) policy with a Deep Q-network (DQN) imitation model to identify the stronger RL baseline, focusing on model performance, generalization, and a pick-up experiment. Second, three different VLA models are trained in two different scenarios and compared with each other. Third, the authors benchmark the selected RL baseline against the VLA model using computational and sample-efficiency measures and then a robot experiment on a multi-stage panel installation task that includes transport and installation. The VLA model demonstrates strong generalization and few-shot capability, achieving 60% and 100% success in the pickup phase. In comparison, DQN can be made robust but needs additional noise during tuning, which increases the workload. Overall, the findings indicate that VLA offers practical advantages for changing tasks by reducing programming effort and enabling useful performance with minimal data, while DQN provides a viable baseline when sufficient tuning effort is acceptable.

</details>


### [6] [E-Navi: Environmental Adaptive Navigation for UAVs on Resource Constrained Platforms](https://arxiv.org/abs/2512.14046)
*Boyang Li,Zhongpeng Jin,Shuai Zhao,Jiahui Liao,Tian Liu,Han Liu,Yuanhai Zhang,Kai Huang*

Main category: cs.RO

TL;DR: E-Navi是一种新型环境自适应导航系统，能根据环境变化动态调整任务执行，大幅提升无人机的导航效率和稳定性。


<details>
  <summary>Details</summary>
Motivation: 无人机的自主导航系统必须适应变化的环境，但现有系统未考虑环境动态，导致飞行策略僵化和计算过载，影响性能。

Method: 提出了一种名为E-Navi的环境自适应导航系统，通过动态调整任务执行来适应环境变化，重设计了感知-规划管道，实时评估环境复杂性。

Result: E-Navi在不同硬件平台上进行了大量实验，显示出比基线方法显著优越，最高可减少53.9%的导航任务工作负载，63.8%的飞行时间，同时提供更稳定的速度控制。

Conclusion: E-Navi有效地提升了无人机在动态环境中的适应性和性能，支持不同计算能力硬件的灵活部署。

Abstract: The ability to adapt to changing environments is crucial for the autonomous navigation systems of Unmanned Aerial Vehicles (UAVs). However, existing navigation systems adopt fixed execution configurations without considering environmental dynamics based on available computing resources, e.g., with a high execution frequency and task workload. This static approach causes rigid flight strategies and excessive computations, ultimately degrading flight performance or even leading to failures in UAVs. Despite the necessity for an adaptive system, dynamically adjusting workloads remains challenging, due to difficulties in quantifying environmental complexity and modeling the relationship between environment and system configuration. Aiming at adapting to dynamic environments, this paper proposes E-Navi, an environmental-adaptive navigation system for UAVs that dynamically adjusts task executions on the CPUs in response to environmental changes based on available computational resources. Specifically, the perception-planning pipeline of UAVs navigation system is redesigned through dynamic adaptation of mapping resolution and execution frequency, driven by the quantitative environmental complexity evaluations. In addition, E-Navi supports flexible deployment across hardware platforms with varying levels of computing capability. Extensive Hardware-In-the-Loop and real-world experiments demonstrate that the proposed system significantly outperforms the baseline method across various hardware platforms, achieving up to 53.9% navigation task workload reduction, up to 63.8% flight time savings, and delivering more stable velocity control.

</details>


### [7] [Expert Switching for Robust AAV Landing: A Dual-Detector Framework in Simulation](https://arxiv.org/abs/2512.14054)
*Humaira Tasnim,Ashik E Rasul,Bruce Jo,Hyung-Jin Yoon*

Main category: cs.RO

TL;DR: 提出了一种双专家框架，通过两个YOLOv8专家分别处理远近不同规模的直升机降落检测任务，显著改善了无人机的降落精度和稳定性。


<details>
  <summary>Details</summary>
Motivation: 在GPS失效或视觉条件不佳的情况下，实现可靠的直升机停机坪检测是自动驾驶航空飞行器成功着陆的关键。

Method: 采用双专家感知框架，将目标检测任务分解为远程和近程两个领域，训练两个针对不同尺度的YOLOv8专家模型。

Result: 该方法在与NASA的GUAM飞行动力学引擎结合的闭环降落环境中取得了更好的对齐稳定性、降落精度和整体鲁棒性，相较于单模型基准具有显著改进。

Conclusion: 本研究提出的双专家感知框架显著提高了自主降落的视觉感知能力，能够更好地应对复杂的起降环境。

Abstract: Reliable helipad detection is essential for Autonomous Aerial Vehicle (AAV) landing, especially under GPS-denied or visually degraded conditions. While modern detectors such as YOLOv8 offer strong baseline performance, single-model pipelines struggle to remain robust across the extreme scale transitions that occur during descent, where helipads appear small at high altitude and large near touchdown. To address this limitation, we propose a scale-adaptive dual-expert perception framework that decomposes the detection task into far-range and close-range regimes. Two YOLOv8 experts are trained on scale-specialized versions of the HelipadCat dataset, enabling one model to excel at detecting small, low-resolution helipads and the other to provide high-precision localization when the target dominates the field of view. During inference, both experts operate in parallel, and a geometric gating mechanism selects the expert whose prediction is most consistent with the AAV's viewpoint. This adaptive routing prevents the degradation commonly observed in single-detector systems when operating across wide altitude ranges. The dual-expert perception module is evaluated in a closed-loop landing environment that integrates CARLA's photorealistic rendering with NASA's GUAM flight-dynamics engine. Results show substantial improvements in alignment stability, landing accuracy, and overall robustness compared to single-detector baselines. By introducing a scale-aware expert routing strategy tailored to the landing problem, this work advances resilient vision-based perception for autonomous descent and provides a foundation for future multi-expert AAV frameworks.

</details>


### [8] [Context Representation via Action-Free Transformer encoder-decoder for Meta Reinforcement Learning](https://arxiv.org/abs/2512.14057)
*Amir M. Soufi Enayati,Homayoun Honari,Homayoun Najjaran*

Main category: cs.RO

TL;DR: CRAFT模型通过仅依赖状态和奖励序列进行任务推断，克服了传统上下文自适应元强化学习在未见任务中的适应性不足问题。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习模型在面对未知任务时，普遍存在泛化能力不足的缺陷。

Method: CRAFT采用了Action Free Transformer编码器-解码器结构，通过状态和奖励序列推断任务表征，消除了对动作的依赖。

Result: 在MetaWorld ML-10机器人操作基准上的实验显示，CRAFT在适应速度、泛化能力和探索效率方面均优于现有的上下文自适应元强化学习基线。

Conclusion: CRAFT模型通过去除对动作的依赖，实现了更快的适应性和更好的泛化性能，为机器人控制中的可扩展强化学习奠定了基础。

Abstract: Reinforcement learning (RL) enables robots to operate in uncertain environments, but standard approaches often struggle with poor generalization to unseen tasks. Context-adaptive meta reinforcement learning addresses these limitations by conditioning on the task representation, yet they mostly rely on complete action information in the experience making task inference tightly coupled to a specific policy. This paper introduces Context Representation via Action Free Transformer encoder decoder (CRAFT), a belief model that infers task representations solely from sequences of states and rewards. By removing the dependence on actions, CRAFT decouples task inference from policy optimization, supports modular training, and leverages amortized variational inference for scalable belief updates. Built on a transformer encoder decoder with rotary positional embeddings, the model captures long range temporal dependencies and robustly encodes both parametric and non-parametric task variations. Experiments on the MetaWorld ML-10 robotic manipulation benchmark show that CRAFT achieves faster adaptation, improved generalization, and more effective exploration compared to context adaptive meta--RL baselines. These findings highlight the potential of action-free inference as a foundation for scalable RL in robotic control.

</details>


### [9] [Interactive Motion Planning for Human-Robot Collaboration Based on Human-Centric Configuration Space Ergonomic Field](https://arxiv.org/abs/2512.14111)
*Chenzui Li,Yiming Chen,Xi Wu,Tao Teng,Sylvain Calinon,Darwin Caldwell,Fei Chen*

Main category: cs.RO

TL;DR: 提出一种新的配置空间人体工学场 (CSEF)，提升工业人机协作中的运动规划效率与安全性。


<details>
  <summary>Details</summary>
Motivation: 工业人机协作中的运动规划需要避免碰撞、反应迅速且确保人体工学安全，以减少疲劳和肌肉骨骼风险。

Method: 提出CSEF作为一种连续可微的字段，用于量化人体工学质量，并结合基于梯度的规划器集成，使其适用于阻抗控制的机器人。

Result: 与任务空间人体工学规划器相比，CSEF基础的规划在成功率、人体工学成本和计算速度上均表现更佳，在各种硬件实验中显示出显著的好处。

Conclusion: CSEF基础的规划在协作钻孔和双手共同搬运任务中，减少平均人体工学评分和关键肌肉群的激活，表明其在实际应用中的有效性。

Abstract: Industrial human-robot collaboration requires motion planning that is collision-free, responsive, and ergonomically safe to reduce fatigue and musculoskeletal risk. We propose the Configuration Space Ergonomic Field (CSEF), a continuous and differentiable field over the human joint space that quantifies ergonomic quality and provides gradients for real-time ergonomics-aware planning. An efficient algorithm constructs CSEF from established metrics with joint-wise weighting and task conditioning, and we integrate it into a gradient-based planner compatible with impedance-controlled robots. In a 2-DoF benchmark, CSEF-based planning achieves higher success rates, lower ergonomic cost, and faster computation than a task-space ergonomic planner. Hardware experiments with a dual-arm robot in unimanual guidance, collaborative drilling, and bimanual cocarrying show faster ergonomic cost reduction, closer tracking to optimized joint targets, and lower muscle activation than a point-to-point baseline. CSEF-based planning method reduces average ergonomic scores by up to 10.31% for collaborative drilling tasks and 5.60% for bimanual co-carrying tasks while decreasing activation in key muscle groups, indicating practical benefits for real-world deployment.

</details>


### [10] [SUPER -- A Framework for Sensitivity-based Uncertainty-aware Performance and Risk Assessment in Visual Inertial Odometry](https://arxiv.org/abs/2512.14189)
*Johannes A. Gaus,Daniel Häufle,Woo-Jeong Baek*

Main category: cs.RO

TL;DR: 本文提出了SUPER框架，用于在视觉惯性里程计中实现实时风险评估，展示了其在准确性和效率上的优势。


<details>
  <summary>Details</summary>
Motivation: 现有视觉里程计和SLAM系统在运行时缺乏风险评估，本文旨在填补这一空白。

Method: 通过施尔余子矩阵传播不确定性，利用残差大小、几何条件和短时间趋势来估计风险。

Result: 提出了SUPER框架，该框架基于敏感性传播不确定性，在视觉惯性里程计中进行实时风险评估。

Conclusion: SUPER框架有效地进行实时风险评估，并且在低成本下提供一致的不确定性估计。

Abstract: While many visual odometry (VO), visual-inertial odometry (VIO), and SLAM systems achieve high accuracy, the majority of existing methods miss to assess risks at runtime. This paper presents SUPER (Sensitivity-based Uncertainty-aware PErformance and Risk assessment) that is a generic and explainable framework that propagates uncertainties via sensitivities for real-time risk assessment in VIO. The scientific novelty lies in the derivation of a real-time risk indicator that is backend-agnostic and exploits the Schur complement blocks of the Gauss-Newton normal matrix to propagate uncertainties. Practically, the Schur complement captures the sensitivity that reflects the influence of the uncertainty on the risk occurrence. Our framework estimates risks on the basis of the residual magnitudes, geometric conditioning, and short horizon temporal trends without requiring ground truth knowledge. Our framework enables to reliably predict trajectory degradation 50 frames ahead with an improvement of 20% to the baseline. In addition, SUPER initiates a stop or relocalization policy with 89.1% recall. The framework is backend agnostic and operates in real time with less than 0.2% additional CPU cost. Experiments show that SUPER provides consistent uncertainty estimates. A SLAM evaluation highlights the applicability to long horizon mapping.

</details>


### [11] [Trajectory Tracking for Multi-Manipulator Systems in Constrained Environments](https://arxiv.org/abs/2512.14206)
*Mayank Sewlia,Christos K. Verginis,Dimos V. Dimarogonas*

Main category: cs.RO

TL;DR: 本文提出了一种多率规划控制框架，用于在复杂环境下多移动操控器协作运输物体，且保证碰撞安全与动态约束。


<details>
  <summary>Details</summary>
Motivation: 在障碍物密集的环境中，多操控器系统需要有效地移动抓取物体，同时遵循动态与几何约束。

Method: 结合离线生成 STL 满足的物体轨迹和无碰撞基础足印，以及在线约束逆向运动学和连续时间反馈控制的多率规划与控制框架。

Result: 提出了一种多率规划与控制框架，以解决移动多操控器系统在复杂环境中协作操作的问题，保证运输抓取物体时满足机器人动力学和几何约束。

Conclusion: 该方法在高保真物理仿真中进行了评估，展示了其在多个 manipulator 协同重构同时跟踪期望物体运动方面的有效性。

Abstract: We consider the problem of cooperative manipulation by a mobile multi-manipulator system operating in obstacle-cluttered and highly constrained environments under spatio-temporal task specifications. The task requires transporting a grasped object while respecting both continuous robot dynamics and discrete geometric constraints arising from obstacles and narrow passages. To address this hybrid structure, we propose a multi-rate planning and control framework that combines offline generation of an STL-satisfying object trajectory and collision-free base footprints with online constrained inverse kinematics and continuous-time feedback control. The resulting closed-loop system enables coordinated reconfiguration of multiple manipulators while tracking the desired object motion. The approach is evaluated in high-fidelity physics simulations using three Franka Emika Panda mobile manipulators rigidly grasping an object.

</details>


### [12] [CaFe-TeleVision: A Coarse-to-Fine Teleoperation System with Immersive Situated Visualization for Enhanced Ergonomics](https://arxiv.org/abs/2512.14270)
*Zixin Tang,Yiming Chen,Quentin Rouxel,Dianxi Li,Shuang Wu,Fei Chen*

Main category: cs.RO

TL;DR: 本文提出的CaFe-TeleVision系统通过粗到细的控制机制和沉浸式可视化技术，显著改善遥操作的效率和人体工程学。


<details>
  <summary>Details</summary>
Motivation: 当前遥操作系统在效率和人体工程学方面仍存在不足，尤其是在复杂场景中。

Method: 提出了一种粗到细的遥操作系统CaFe-TeleVision，结合沉浸式现场可视化技术。

Result: 在六个艰巨的双手操作任务中进行验证，用户研究表明该系统显著提高了人体工程学性能，并在成功率和完成时间方面超过了对比方法。

Conclusion: CaFe-TeleVision系统通过优化控制机制和可视化技术，有效降低了任务负担，提高了用户接受度和操作效率。

Abstract: Teleoperation presents a promising paradigm for remote control and robot proprioceptive data collection. Despite recent progress, current teleoperation systems still suffer from limitations in efficiency and ergonomics, particularly in challenging scenarios. In this paper, we propose CaFe-TeleVision, a coarse-to-fine teleoperation system with immersive situated visualization for enhanced ergonomics. At its core, a coarse-to-fine control mechanism is proposed in the retargeting module to bridge workspace disparities, jointly optimizing efficiency and physical ergonomics. To stream immersive feedback with adequate visual cues for human vision systems, an on-demand situated visualization technique is integrated in the perception module, which reduces the cognitive load for multi-view processing. The system is built on a humanoid collaborative robot and validated with six challenging bimanual manipulation tasks. User study among 24 participants confirms that CaFe-TeleVision enhances ergonomics with statistical significance, indicating a lower task load and a higher user acceptance during teleoperation. Quantitative results also validate the superior performance of our system across six tasks, surpassing comparative methods by up to 28.89% in success rate and accelerating by 26.81% in completion time. Project webpage: https://clover-cuhk.github.io/cafe_television/

</details>


### [13] [ARCADE: Adaptive Robot Control with Online Changepoint-Aware Bayesian Dynamics Learning](https://arxiv.org/abs/2512.14331)
*Rishabh Dev Yadav,Avirup Das,Hongyu Song,Samuel Kaski,Wei Pan*

Main category: cs.RO

TL;DR: 提出了一种适应性的框架，通过流数据实时更新机器人动态模型，能有效处理变化条件。


<details>
  <summary>Details</summary>
Motivation: 机器人在真实世界中必须应对动态变化的操作条件和外部干扰，因此需要一种实时适应的模型来维持性能。

Method: 该方法将表示学习与在线适应解耦，利用离线学习的潜在表示支持在线的贝叶斯更新，同时引入了一个能够识别变化点的机制。

Result: 在模拟和实际飞行测试中，改善了预测准确性、加快了恢复速度以及提升了闭环跟踪的精度。

Conclusion: 该框架在处理动态变化时的适应性优于现有的基准，证明了其有效性。

Abstract: Real-world robots must operate under evolving dynamics caused by changing operating conditions, external disturbances, and unmodeled effects. These may appear as gradual drifts, transient fluctuations, or abrupt shifts, demanding real-time adaptation that is robust to short-term variation yet responsive to lasting change. We propose a framework for modeling the nonlinear dynamics of robotic systems that can be updated in real time from streaming data. The method decouples representation learning from online adaptation, using latent representations learned offline to support online closed-form Bayesian updates. To handle evolving conditions, we introduce a changepoint-aware mechanism with a latent variable inferred from data likelihoods that indicates continuity or shift. When continuity is likely, evidence accumulates to refine predictions; when a shift is detected, past information is tempered to enable rapid re-learning. This maintains calibrated uncertainty and supports probabilistic reasoning about transient, gradual, or structural change. We prove that the adaptive regret of the framework grows only logarithmically in time and linearly with the number of shifts, competitive with an oracle that knows timings of shift. We validate on cartpole simulations and real quadrotor flights with swinging payloads and mid-flight drops, showing improved predictive accuracy, faster recovery, and more accurate closed-loop tracking than relevant baselines.

</details>


### [14] [Field evaluation and optimization of a lightweight lidar-based UAV navigation system for dense boreal forest environments](https://arxiv.org/abs/2512.14340)
*Aleksi Karhunen,Teemu Hakala,Väinö Karjalainen,Eija Honkavaara*

Main category: cs.RO

TL;DR: 本研究开发了一种基于轻量级激光雷达的自主飞行四旋翼，并在实际森林环境中进行了多次严格实验，优化了系统，提高了在不同森林密度环境下的成功率，并提出了标准化测试设置和评估标准。


<details>
  <summary>Details</summary>
Motivation: 随着无人机在森林领域应用的兴趣增加，特别是在新华无人机下飞行的自主控制能力提升，促进了并需要对自主飞行技术的探索与标准化。

Method: 采用轻量级激光雷达和开放算法，实施了一种自主飞行四旋翼，通过IPC路径规划器和LTA-OM SLAM算法进行 rigorous experiments。

Result: 在93次测试飞行中，优化后的系统在中密度森林和高密度森林中的成功率分别为12/15和15/15，显示出自主系统的可靠性和飞行任务完成时间有显著改善。

Conclusion: 本研究提出了一种在森林环境中有效工作的自主飞行四旋翼系统，并建立了规范的测试设置与评估标准，有助于今后的森林机器人研究。

Abstract: The interest in the usage of uncrewed aerial vehicles (UAVs) for forest applications has increased in recent years. While above-canopy flight has reached a high level of autonomy, navigating under-canopy remains a significant challenge. The use of autonomous UAVs could reduce the burden of data collection, which has motivated the development of numerous solutions for under-canopy autonomous flight. However, the experiments conducted in the literature and their reporting lack rigor. Very rarely, the density and the difficulty of the test forests are reported, or multiple flights are flown, and the success rate of those flights is reported. The aim of this study was to implement an autonomously flying quadrotor based on a lightweight lidar using openly available algorithms and test its behavior in real forest environments. A set of rigorous experiments was conducted with a quadrotor prototype utilizing the IPC path planner and LTA-OM SLAM algorithm. Based on the results of the first 33 flights, the original system was further enhanced. With the optimized system, 60 flights were performed, resulting in a total of 93 test flights. The optimized system performed significantly better in terms of reliability and flight mission completion times, achieving success rates of 12/15 in a medium-density forest and 15/15 in a dense forest, at a target flight velocity of 1 m/s. At a target flight velocity of 2 m/s, it had a success rate of 12/15 and 5/15, respectively. Furthermore, a standardized testing setup and evaluation criteria were proposed, enabling consistent performance comparisons of autonomous under-canopy UAV systems, enhancing reproducibility, guiding system improvements, and accelerating progress in forest robotics.

</details>


### [15] [Fine-Tuning of Neural Network Approximate MPC without Retraining via Bayesian Optimization](https://arxiv.org/abs/2512.14350)
*Henrik Hose,Paul Brunzema,Alexander von Rohr,Alexander Gräfe,Angela P. Schoellig,Sebastian Trimpe*

Main category: cs.RO

TL;DR: 提出了一种基于贝叶斯优化的AMPC参数调节方法，以提高AMPC在复杂控制任务中的性能，减少了微调过程的劳动强度与数据需求。


<details>
  <summary>Details</summary>
Motivation: 在实际应用中，近似模型预测控制（AMPC）需要对底层模型进行微调，而这种过程通常需要生成新数据集并重新训练神经网络，导致AMPC的实用性下降。

Method: 采用贝叶斯优化的方法，通过实验数据来调节AMPC策略的参数，结合模型基础控制与直接局部学习。

Result: 在硬件实验中，该方法在倒立摆的摆动与单轮车的偏航控制等挑战性控制问题上，表现出优于标准AMPC的卓越性能，且实验量最小。

Conclusion: 该方法实现了对AMPC在新系统实例及难以直接在MPC中实现的成本函数上的自动适应与高效调整。

Abstract: Approximate model-predictive control (AMPC) aims to imitate an MPC's behavior with a neural network, removing the need to solve an expensive optimization problem at runtime. However, during deployment, the parameters of the underlying MPC must usually be fine-tuned. This often renders AMPC impractical as it requires repeatedly generating a new dataset and retraining the neural network. Recent work addresses this problem by adapting AMPC without retraining using approximated sensitivities of the MPC's optimization problem. Currently, this adaption must be done by hand, which is labor-intensive and can be unintuitive for high-dimensional systems. To solve this issue, we propose using Bayesian optimization to tune the parameters of AMPC policies based on experimental data. By combining model-based control with direct and local learning, our approach achieves superior performance to nominal AMPC on hardware, with minimal experimentation. This allows automatic and data-efficient adaptation of AMPC to new system instances and fine-tuning to cost functions that are difficult to directly implement in MPC. We demonstrate the proposed method in hardware experiments for the swing-up maneuver on an inverted cartpole and yaw control of an under-actuated balancing unicycle robot, a challenging control problem.

</details>


### [16] [CoLD Fusion: A Real-time Capable Spline-based Fusion Algorithm for Collective Lane Detection](https://arxiv.org/abs/2512.14355)
*Jörg Gamerdinger,Sven Teufel,Georg Volk,Oliver Bringmann*

Main category: cs.RO

TL;DR: 本文提出了一种基于车对车的集体感知方法，以提高自动驾驶车辆在道路检测中的感知范围和实时能力。


<details>
  <summary>Details</summary>
Motivation: 在自动驾驶中，全面的环境感知对于保障安全至关重要，尤其是在缺乏高清地图或准确定位时，车辆必须依赖自身感知。

Method: 我们提出了一种实时的集体感知方法，通过样条基估计未检测的路段，实现车辆之间的信息共享。

Result: 我们的融合算法在多种情况下进行了评估，并成功提高了感知范围并实现实时处理。

Conclusion: 通过使用基于样条的估计方法进行车对车的集体感知，我们成功扩展了高速公路的感知范围，并实现了实时能力，最高可扩展200%。

Abstract: Comprehensive environment perception is essential for autonomous vehicles to operate safely. It is crucial to detect both dynamic road users and static objects like traffic signs or lanes as these are required for safe motion planning. However, in many circumstances a complete perception of other objects or lanes is not achievable due to limited sensor ranges, occlusions, and curves. In scenarios where an accurate localization is not possible or for roads where no HD maps are available, an autonomous vehicle must rely solely on its perceived road information. Thus, extending local sensing capabilities through collective perception using vehicle-to-vehicle communication is a promising strategy that has not yet been explored for lane detection. Therefore, we propose a real-time capable approach for collective perception of lanes using a spline-based estimation of undetected road sections. We evaluate our proposed fusion algorithm in various situations and road types. We were able to achieve real-time capability and extend the perception range by up to 200%.

</details>


### [17] [A Comprehensive Safety Metric to Evaluate Perception in Autonomous Systems](https://arxiv.org/abs/2512.14367)
*Georg Volk,Jörg Gamerdinger,Alexander von Bernuth,Oliver Bringmann*

Main category: cs.RO

TL;DR: 本文提出了一种新的安全评估指标，考虑了物体感知中的多种参数，为自动驾驶安全性提供更全面的评估。


<details>
  <summary>Details</summary>
Motivation: 为了提高自动驾驶车辆对环境的感知能力，必须不仅考虑物体的存在，还要根据其速度、方向、距离、大小和潜在危险性进行综合评估。

Method: 提出一种新的安全度量标准，整合了物体速度、方向、距离、大小及碰撞带来的潜在损害等参数。

Result: 新度量标准在现实世界和虚拟数据集上进行了评估，并与现有的最佳评估标准进行了比较。

Conclusion: 提出了一种新的安全度量标准，能够综合考虑多种参数，从而为自动驾驶车辆的物体感知提供一个易于解释的安全评估分数。

Abstract: Complete perception of the environment and its correct interpretation is crucial for autonomous vehicles. Object perception is the main component of automotive surround sensing. Various metrics already exist for the evaluation of object perception. However, objects can be of different importance depending on their velocity, orientation, distance, size, or the potential damage that could be caused by a collision due to a missed detection. Thus, these additional parameters have to be considered for safety evaluation. We propose a new safety metric that incorporates all these parameters and returns a single easily interpretable safety assessment score for object perception. This new metric is evaluated with both real world and virtual data sets and compared to state of the art metrics.

</details>


### [18] [Synthetic Data Pipelines for Adaptive, Mission-Ready Militarized Humanoids](https://arxiv.org/abs/2512.14411)
*Mohammed Ayman Habib,Aldo Petruzzelli*

Main category: cs.RO

TL;DR: 通过合成数据驱动的管道，Omnia 提高 militarized humanoids 的训练效率与适应性。


<details>
  <summary>Details</summary>
Motivation: 希望在复杂的环境中加快开发周期并提高系统的鲁棒性。

Method: 构建合成数据驱动管道

Result: 加速 militarized humanoids 的训练、验证与部署准备

Conclusion: 该管道支持快速迭代感知、导航和决策能力，降低试验成本与风险，适应新环境与威胁条件。

Abstract: Omnia presents a synthetic data driven pipeline to accelerate the training, validation, and deployment readiness of militarized humanoids. The approach converts first-person spatial observations captured from point-of-view recordings, smart glasses, augmented reality headsets, and spatial browsing workflows into scalable, mission-specific synthetic datasets for humanoid autonomy. By generating large volumes of high-fidelity simulated scenarios and pairing them with automated labeling and model training, the pipeline enables rapid iteration on perception, navigation, and decision-making capabilities without the cost, risk, or time constraints of extensive field trials. The resulting datasets can be tuned quickly for new operational environments and threat conditions, supporting both baseline humanoid performance and advanced subsystems such as multimodal sensing, counter-detection survivability, and CBRNE-relevant reconnaissance behaviors. This work targets faster development cycles and improved robustness in complex, contested settings by exposing humanoid systems to broad scenario diversity early in the development process.

</details>


### [19] [Odyssey: An Automotive Lidar-Inertial Odometry Dataset for GNSS-denied situations](https://arxiv.org/abs/2512.14428)
*Aaron Kurda,Simon Steuernagel,Lukas Jung,Marcus Baum*

Main category: cs.RO

TL;DR: Odyssey数据集专注于GNSS信号受限环境，提供高精度的LIO和SLAM基准，支持多种任务，首次公开基于RLG的INS数据集。


<details>
  <summary>Details</summary>
Motivation: 提升GNSS信号在阻塞环境中的可靠性，为LIO和SLAM系统的发展提供高质量的地面真值数据。

Method: 开发了一个以环形激光陀螺仪为基础的高精度惯性导航系统，创建了Odyssey数据集，专注于GNSS信号丧失环境。

Result: Odyssey数据集提供高质量的Lidar-Inertial Odometry (LIO)和SLAM系统的基准，尤其在隧道、停车场等GNSS信号受限的环境中。

Conclusion: Odyssey是第一个公开的基于环形激光陀螺仪的INS数据集，为城市环境中的LIO等应用提供了数据支持。

Abstract: The development and evaluation of Lidar-Inertial Odometry (LIO) and Simultaneous Localization and Mapping (SLAM) systems requires a precise ground truth. The Global Navigation Satellite System (GNSS) is often used as a foundation for this, but its signals can be unreliable in obstructed environments due to multi-path effects or loss-of-signal. While existing datasets compensate for the sporadic loss of GNSS signals by incorporating Inertial Measurement Unit (IMU) measurements, the commonly used Micro-Electro-Mechanical Systems (MEMS) or Fiber Optic Gyroscope (FOG)-based systems do not permit the prolonged study of GNSS-denied environments. To close this gap, we present Odyssey, a LIO dataset with a focus on GNSS-denied environments such as tunnels and parking garages as well as other underrepresented, yet ubiquitous situations such as stop-and-go-traffic, bumpy roads and wide open fields. Our ground truth is derived from a navigation-grade Inertial Navigation System (INS) equipped with a Ring Laser Gyroscope (RLG), offering exceptional bias stability characteristics compared to IMUs used in existing datasets and enabling the prolonged and accurate study of GNSS-denied environments. This makes Odyssey the first publicly available dataset featuring a RLG-based INS. Besides providing data for LIO, we also support other tasks, such as place recognition, through the threefold repetition of all trajectories as well as the integration of external mapping data by providing precise geodetic coordinates. All data, dataloader and other material is available online at https://odyssey.uni-goettingen.de/ .

</details>


### [20] [Geometric Parameter Optimization of a Novel 3-(PP(2-(UPS))) Redundant Parallel Mechanism based on Workspace Determination](https://arxiv.org/abs/2512.14434)
*Quan Yuan,Daqian Cao,Weibang Bai*

Main category: cs.RO

TL;DR: 本文提出了一种新型的3-(PP(2-(UPS)))冗余并行机制，并优化其运动学性能。


<details>
  <summary>Details</summary>
Motivation: 探讨冗余并行机器人在高精度、大负载和大工作空间应用中的挑战，尤其是几何参数优化问题。

Method: 通过分析关键几何参数对工作空间体积、形状、边界完整性及定向能力的影响，定义扭转能力指数TI_1和倾斜能力指数TI_2以评估机制的定向性能，并进行数值仿真研究。

Result: 通过数值仿真，分析了3-(PP(2-(UPS)))冗余并行机制的几何参数优化，提供了合理的参考。

Conclusion: 该研究为3-(PP(2-(UPS)))及类似冗余并行机制的参数优化提供了必要的参考。

Abstract: Redundant parallel robots are normally employed in scenarios requiring good precision, high load capability, and large workspace compared to traditional parallel mechanisms. However, the elementary robotic configuration and geometric parameter optimization are still quite challenging. This paper proposes a novel 3-(PP(2-(UPS))) redundant parallel mechanism, with good generalizability first, and further investigates the kinematic optimization issue by analyzing and investigating how its key geometric parameters influence the volume, shape, boundary completeness, and orientation capabilities of its workspace. The torsional capability index TI_1 and tilting capability index TI_2 are defined to evaluate the orientation performance of the mechanism. Numerical simulation studies are completed to indicate the analysis, providing reasonable but essential references for the parameter optimization of 3-(PP(2-(UPS))) and other similar redundant parallel mechanisms.

</details>


### [21] [EVOLVE-VLA: Test-Time Training from Environment Feedback for Vision-Language-Action Models](https://arxiv.org/abs/2512.14666)
*Zechen Bai,Chen Gao,Mike Zheng Shou*

Main category: cs.RO

TL;DR: EVOLVE-VLA框架使得VLA能够在缺乏演示的情况下自适应，显著提高了学习效果和泛化能力，表现出了新的能力


<details>
  <summary>Details</summary>
Motivation: 实现真正的自适应智能体，使之像人类一样通过实践而非静态演示不断提高。

Method: 引入EVOLVE-VLA测试时训练框架，使VLA通过环境互动持续自适应，最小化或零任务特定演示的需求

Result: 在长时间任务上提高了8.6%，在一次性学习中提高了22.0%，在无任务特定演示训练的情况下实现了20.8%的成功率

Conclusion: 通过替换不可用的神谕奖励信号，利用自主反馈与学习进度估计器，成功提升了VLA的适应能力和任务间泛化能力

Abstract: Achieving truly adaptive embodied intelligence requires agents that learn not just by imitating static demonstrations, but by continuously improving through environmental interaction, which is akin to how humans master skills through practice. Vision-Language-Action (VLA) models have advanced robotic manipulation by leveraging large language models, yet remain fundamentally limited by Supervised Finetuning (SFT): requiring hundreds of demonstrations per task, rigidly memorizing trajectories, and failing to adapt when deployment conditions deviate from training. We introduce EVOLVE-VLA, a test-time training framework enabling VLAs to continuously adapt through environment interaction with minimal or zero task-specific demonstrations. The key technical challenge is replacing oracle reward signals (unavailable at test time) with autonomous feedback. We address this through a learned progress estimator providing dense feedback, and critically, we design our framework to ``tame'' this inherently noisy signal via two mechanisms: (1) an accumulative progress estimation mechanism smoothing noisy point-wise estimates, and (2) a progressive horizon extension strategy enabling gradual policy evolution. EVOLVE-VLA achieves substantial gains: +8.6\% on long-horizon tasks, +22.0\% in 1-shot learning, and enables cross-task generalization -- achieving 20.8\% success on unseen tasks without task-specific demonstrations training (vs. 0\% for pure SFT). Qualitative analysis reveals emergent capabilities absent in demonstrations, including error recovery and novel strategies. This work represents a critical step toward VLAs that truly learn and adapt, moving beyond static imitation toward continuous self-improvements.

</details>


### [22] [CHIP: Adaptive Compliance for Humanoid Control through Hindsight Perturbation](https://arxiv.org/abs/2512.14689)
*Sirui Chen,Zi-ang Cao,Zhengyi Luo,Fernando Castañeda,Chenran Li,Tingwu Wang,Ye Yuan,Linxi "Jim" Fan,C. Karen Liu,Yuke Zhu*

Main category: cs.RO

TL;DR: 本文提出了CHIP模块，增强了类人机器人的操作能力，支持多种强制操作任务，且易于实现。


<details>
  <summary>Details</summary>
Motivation: 尽管类人机器人在敏捷运动技能上取得了进展，但在执行强制操作任务方面仍面临挑战。

Method: 提出了一种适应性合规类人控制模块（CHIP），该模块可以在保持敏捷跟踪动态参考运动的同时，实现可控的末端执行器刚度。

Result: 使用CHIP训练的通用运动跟踪控制器能够执行多种强制操作任务，展示了不同末端执行器合规性下的应用能力。

Conclusion: CHIP模块易于实现，无需数据增强或额外的奖励调整，证明其在多机器人协作、擦拭、箱包运输和开门等任务中的有效性。

Abstract: Recent progress in humanoid robots has unlocked agile locomotion skills, including backflipping, running, and crawling. Yet it remains challenging for a humanoid robot to perform forceful manipulation tasks such as moving objects, wiping, and pushing a cart. We propose adaptive Compliance Humanoid control through hIsight Perturbation (CHIP), a plug-and-play module that enables controllable end-effector stiffness while preserving agile tracking of dynamic reference motions. CHIP is easy to implement and requires neither data augmentation nor additional reward tuning. We show that a generalist motion-tracking controller trained with CHIP can perform a diverse set of forceful manipulation tasks that require different end-effector compliance, such as multi-robot collaboration, wiping, box delivery, and door opening.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [23] [From Framework to Practice: Designing a Real-World Telehealth Application for Palliative Care](https://arxiv.org/abs/2512.13693)
*Wei Zhou,Rashina Hoda,Andy Li,Chris Bain,Laura Bird,Emmy Trinh,Peter Poon,Teresa O Brien,Mahima Kalla,Olivia Metcalf,Wendy Chapman,Joycelyn Ling,Sam Georgy,David Bevan*

Main category: cs.HC

TL;DR: 本论文分析了为姑息护理设计一种增强远程医疗能力的软件应用，重点关注质量、人体价值和现实世界三个社会技术维度的整合。


<details>
  <summary>Details</summary>
Motivation: 随着数字健康解决方案不断重塑医疗保健交付，远程医疗软件应用在改善可及性、护理的连续性和患者结果方面变得至关重要。

Method: 采用多学科、基于经验的共同设计方法，结合临床医生、患者和护理人员的反馈，通过原型设计、可用性测试和现实世界评估的迭代循环进行设计。

Result: 结果显示，该远程医疗软件解决方案在技术稳健性、伦理适应性和与临床实践的连续对齐方面取得成功。

Conclusion: 我们的设计方法能够为健康及其他领域的软件设计提供帮助。

Abstract: As digital health solutions continue to reshape healthcare delivery, telehealth software applications have become vital for improving accessibility, continuity of care, and patient outcomes. This paper presents an analysis of designing a software application focused on Enhanced Telehealth Capabilities (ETHC) for palliative care, integrating across three socio-technical dimensions: quality, human values, and real-world. Designing for quality attributes -- such as performance, maintainability, safety, and security -- ensured that the system is technically robust and compliant with clinical standards. Designing for human values -- empathy, inclusivity, accessibility, and transparency -- helped enhance patient experience, trust, and ethical alignment. Designing for real-world -- through a multidisciplinary, experience-based co-design approach involving clinicians, patients, and carers that guided iterative cycles of prototyping, usability testing, and real-world evaluation -- ensured continuous refinement of features and alignment with clinical practice. The resulting telehealth software solution demonstrated that our socio-technical design framework was successful in producing a secure, equitable, and resilient digital health application. Our design approach can assist others designing software in health and other domains.

</details>


### [24] [Learning to Car-Follow Using an Inertia-Oriented Driving Technique: A Before-and-After Study on a Closed Circuit](https://arxiv.org/abs/2512.13694)
*Kostantinos Mattas,Antonio Lucas-Alba,Tomer Toledo,Oscar M. Melchor,Shlomo Bekhor,Biagio Ciuffo*

Main category: cs.HC

TL;DR: 研究表明，司机可以通过DI课程改变跟车策略，提升驾驶稳定性。


<details>
  <summary>Details</summary>
Motivation: 研究驾驶者在保持安全距离方面的默认策略是否合适，以探索替代的跟车策略。

Method: 通过邀请12名司机在真实赛道上跟随领车，并进行DI课程培训，观察其在跟车情境下的表现。

Result: 经过DI课程培训后，司机的加速度、减速度及速度波动显著减少，表明采用了DI策略。

Conclusion: 这是首次在真实赛道上展示采用DI策略的潜力。

Abstract: For decades, car following and traffic flow models have assumed that drivers default driving strategy is to maintain a safe distance. Several previous studies have questioned whether the Driving to Keep Distance is a traffic invariant. Therefore, the acceleration deceleration torque asymmetry of drivers must necessarily determine the observed patterns of traffic oscillations. Those studies indicate that drivers can adopt alternative CF strategies, such as Driving to Keep Inertia, by following basic instructions. The present work extends the evidence from previous research by showing the effectiveness of a DI course that immediately translates into practice on a closed circuit. Twelve drivers were invited to follow a lead car that varied its speed on a real circuit. Then, the driver took a DI course and returned to the same real car following scenario. Drivers generally adopted DD as the default CF mode in the pretest, both in field and simulated PC conditions, yielding very similar results. After taking the full DI course, drivers showed significantly less acceleration, deceleration, and speed variability than did the pretest, both in the field and in the simulated conditions, which indicates that drivers adopted the DI strategy. This study is the first to show the potential of adopting a DI strategy in a real circuit.

</details>


### [25] [Juicy Text: Onomatopoeia and Semantic Text Effects for Juicy Player Experiences](https://arxiv.org/abs/2512.13695)
*Émilie Fabre,Katie Seaborn,Adrien Alexandre Verhulst,Yuta Itoh,Jun Rekimoto*

Main category: cs.HC

TL;DR: 本研究探讨了文本效果的“多汁感”，发现文本效果在用户体验上的表现与粒子效果相似，且结合两者可能提升体验。


<details>
  <summary>Details</summary>
Motivation: 研究游戏中的视觉效果，特别是文本效果如何提升玩家体验和参与感。

Method: 进行多阶段的被试内实验，比较文本效果和粒子效果的评估和性能。

Result: 用户对文本效果的评分与粒子效果相似，并且在性能上可比，并提供更可靠的反馈。

Conclusion: 文本刺激与其他视觉效果的感知可能存在差异，同时结合文本与粒子效果可能改善用户体验。

Abstract: Juiciness is visual pizzazz used to improve player experience and engagement in games. Most research has focused on juicy particle effects. However, text effects are also commonly used in games, albeit not always juiced up. One type is onomatopoeia, a well-defined element of human language that has been translated to visual media, such as comic books and games. Another is semantic text, often used to provide performance feedback in games. In this work, we explored the relationship between juiciness and text effects, aiming to replicate juicy user experiences with text-based juice and combining particle and text juice. We show in a multi-phase within-subjects experiment that users rate juicy text effects similarly to particles effects, with comparable performance, and more reliable feedback. We also hint at potential improvement in user experience when both are combined, and how text stimuli may be perceived differently than other visual ones. We contribute empirical findings on the juicy-text connection in the context of visual effects for interactive media.

</details>


### [26] [LAPPI: Interactive Optimization with LLM-Assisted Preference-Based Problem Instantiation](https://arxiv.org/abs/2512.14138)
*So Kuroki,Manami Nakagawa,Shigeo Yoshida,Yuki Koyama,Kozuno Tadashi*

Main category: cs.HC

TL;DR: 提出了一种名为LAPPI的互动方法，通过大语言模型帮助用户将模糊的偏好转化为明确的组合优化问题，并成功应用于行程规划。


<details>
  <summary>Details</summary>
Motivation: 许多真实世界的任务可以被表述为组合优化问题，但用户在使用优化求解器时面临问题实例化的困难。

Method: LAPPI利用大语言模型和自然语言对话，支持用户将模糊的偏好转换为明确的优化问题，再将这些问题传递给现有的优化求解器。

Result: 在行程规划的用户研究中，LAPPI方法成功捕捉用户偏好，生成的可行计划优于传统和提示工程的方法。

Conclusion: LAPPI展示了其在多个用例中的灵活性，除了行程规划外，还可以扩展到其他应用领域。

Abstract: Many real-world tasks, such as trip planning or meal planning, can be formulated as combinatorial optimization problems. However, using optimization solvers is difficult for end users because it requires problem instantiation: defining candidate items, assigning preference scores, and specifying constraints. We introduce LAPPI (LLM-Assisted Preference-based Problem Instantiation), an interactive approach that uses large language models (LLMs) to support users in this instantiation process. Through natural language conversations, the system helps users transform vague preferences into well-defined optimization problems. These instantiated problems are then passed to existing optimization solvers to generate solutions. In a user study on trip planning, our method successfully captured user preferences and generated feasible plans that outperformed both conventional and prompt-engineering approaches. We further demonstrate LAPPI's versatility by adapting it to an additional use case.

</details>


### [27] [The Trust in AI-Generated Health Advice (TAIGHA) Scale and Short Version (TAIGHA-S): Development and Validation Study](https://arxiv.org/abs/2512.14278)
*Marvin Kopka,Azeem Majeed,Gabriella Spinelli,Austen El-Osta,Markus Feufel*

Main category: cs.HC

TL;DR: 本研究开发了TAIGHA量表，并进行验证，旨在评估用户对AI健康建议的信任与不信任，结果表明该量表具有良好的心理测量特性。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能技术在健康领域的广泛应用，用户对AI生成健康建议的信任度逐渐成为重要研究课题，但目前缺乏专门的信任评估工具。

Method: 通过生成式AI方法开发量表项目，并经过多个阶段的内容验证、认知验证和心理测量验证，最终确定了TAIGHA和TAIGHA-S的结构和可靠性。

Result: 本研究开发并验证了信任人工智能生成医疗建议量表（TAIGHA）及其四项短表（TAIGHA-S），旨在测量用户对AI生成的健康建议的信任和不信任，具有良好的内容有效性和心理测量特性。

Conclusion: TAIGHA和TAIGHA-S是有效的工具，可以用于评估用户对AI生成健康建议的信任情况，能有效区分信任和不信任的维度，适合快速评估的环境。

Abstract: Artificial Intelligence tools such as large language models are increasingly used by the public to obtain health information and guidance. In health-related contexts, following or rejecting AI-generated advice can have direct clinical implications. Existing instruments like the Trust in Automated Systems Survey assess trustworthiness of generic technology, and no validated instrument measures users' trust in AI-generated health advice specifically. This study developed and validated the Trust in AI-Generated Health Advice (TAIGHA) scale and its four-item short form (TAIGHA-S) as theory-based instruments measuring trust and distrust, each with cognitive and affective components. The items were developed using a generative AI approach, followed by content validation with 10 domain experts, face validation with 30 lay participants, and psychometric validation with 385 UK participants who received AI-generated advice in a symptom-assessment scenario. After automated item reduction, 28 items were retained and reduced to 10 based on expert ratings. TAIGHA showed excellent content validity (S-CVI/Ave=0.99) and CFA confirmed a two-factor model with excellent fit (CFI=0.98, TLI=0.98, RMSEA=0.07, SRMR=0.03). Internal consistency was high (α=0.95). Convergent validity was supported by correlations with the Trust in Automated Systems Survey (r=0.67/-0.66) and users' reliance on the AI's advice (r=0.37 for trust), while divergent validity was supported by low correlations with reading flow and mental load (all |r|<0.25). TAIGHA-S correlated highly with the full scale (r=0.96) and showed good reliability (α=0.88). TAIGHA and TAIGHA-S are validated instruments for assessing user trust and distrust in AI-generated health advice. Reporting trust and distrust separately permits a more complete evaluation of AI interventions, and the short scale is well-suited for time-constrained settings.

</details>


### [28] [Creating Opportunities: Co-designing an mHealth App with Older Adults](https://arxiv.org/abs/2512.14641)
*Abhinav Choudhry,Bashab Mazumder,Lauren Alyssa Marks,Roqaya Elmenshawy,Devorah Kletenik,Sean Mullen,Rachel F. Adler*

Main category: cs.HC

TL;DR: 本研究通过定性共同设计，获取了对老年人身体活动支持应用程序及其聊天机器人的设计反馈，为未来工作提供了指导。


<details>
  <summary>Details</summary>
Motivation: 为了获取有关支持老年人身体活动的AI教练应用程序的设计见解。

Method: 通过与四位60岁以上的成人进行定性共同设计研究，收集关于Figma原型和生成型AI聊天机器人的反馈。

Result: 研究提供了关于改进应用程序的用户体验以及聊天机器人的对话流程的反馈。

Conclusion: 这项研究将为未来实施面向老年人的生成型AI健康教练提供支持。

Abstract: We conducted a qualitative co-design study with four adults aged 60+ to gather design insights on a Figma prototype and a generative AI (GenAI) chatbot for an app aimed at providing an AI coach to support older adults' physical activity. The initial design for both incorporates several novel aspects: a curated health knowledge base, personalised responses based on goals and health history, privacy considerations, integration with wearables for physical activity context, as well as dynamic context injection. The study yielded feedback on improving both the proposed user experience in the app and the conversation flow with the chatbot, and it will aid future work aimed at implementing a GenAI-powered health coach for older adults.

</details>
