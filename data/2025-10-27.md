<div id=toc></div>

# Table of Contents

- [cs.HC](#cs.HC) [Total: 6]
- [cs.RO](#cs.RO) [Total: 18]


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [1] [NeuroPilot: A Realtime Brain-Computer Interface system to enhance concentration of students in online learning](https://arxiv.org/abs/2510.20958)
*Asif Islam,Farhan Ishtiaque,Md. Muhyminul Haque,Kaled Masukur Rahman,Ravi Vaidyanathan,Khondaker A. Mamun*

Main category: cs.HC

TL;DR: 本研究开发了一种基于BCI的系统，通过EEG监测学生的注意力状态，并实现了有效的注意力反馈，显示出显著的改善效果。


<details>
  <summary>Details</summary>
Motivation: 在线学习的普及使得实时监测学生注意力变得至关重要，但传统方法的准确性不足，缺乏有效验证及评估程序。

Method: 利用非侵入性脑电图（EEG）头戴设备FocusCalm收集参与者的脑电活动，并运用支持向量机（SVM）对注意力和非注意力状态进行分类。

Result: 通过实验，该系统在注意力分类任务中取得了88.77%的准确率，并且实时反馈显著改善了参与者的注意力。

Conclusion: 该BCI系统在实时监测和反馈学生注意力方面表现出色，提供了有效的关注状态评估方法。

Abstract: Prevalence of online learning poses a vital challenge in real-time monitoring
of students' concentration. Traditional methods such as questionnaire
assessments require manual interventions and webcam-based monitoring fails to
provide accurate insights into learners' mental focus as they are deceived by
mere screen fixation without cognitive engagement. Existing BCI-based
approaches lack real-time validation and evaluation procedures. To address
these limitations, a Brain-Computer Interface (BCI) system is developed using a
non-invasive Electroencephalogram (EEG) headband, FocusCalm, to record
brainwave activity under attentive and non-attentive states. 20 minutes of data
were collected from each of 20 participants watching a pre-recorded educational
video. The data validation employed a novel intra-video questionnaire
assessment. Subsequently, collected signals were segmented (sliding window),
filtered (butterworth bandpass), and cleaned (removal of high-amplitude and EOG
artifacts such as eye blinks). Time, frequency, wavelet and statistical
features have been extracted, followed by recursive feature elimination (RFE)
with Support vector machines (SVMs) to classify attention and non-attention
states. The leave-one-subject-out (LOSO) cross-validation accuracy has been
tested to be 88.77%. The system provides feedback alerts upon non-attention
state detection and keeps focus profile logs. A pilot study was conducted to
evaluate the effectiveness of real-time feedback. Five participants completed a
10-minute session consisting of a 5-minute baseline phase without feedback
followed by a 5-minute feedback phase, during which alerts were issued if
participants remained non-attentive for approximately 8 consecutive seconds. A
paired t-test (t = 5.73, p = 0.007) indicated a statistically significant
improvement in concentration during the feedback phase.

</details>


### [2] [Race and Gender in LLM-Generated Personas: A Large-Scale Audit of 41 Occupations](https://arxiv.org/abs/2510.21011)
*Ilona van der Linden,Sahana Kumar,Arnav Dixit,Aadi Sudan,Smruthi Danda,David C. Anastasiu,Kai Lukoff*

Main category: cs.HC

TL;DR: 本研究分析生成性人工智能在职场表现中的种族和性别偏差，结果显示白人与黑人工作者被低估，而西班牙裔与亚裔工作者被高估，揭示了显著的偏差和刻板印象的加剧。


<details>
  <summary>Details</summary>
Motivation: 研究生成性人工智能工具在创建职业人群的表现中，种族和性别的表示问题，尤其是如何影响不同群体的代表性。

Method: 对来自美国、中国和法国的四种大型语言模型生成的职业人群数据进行比较分析，并与劳工统计局的数据进行对比，进行大规模审计。

Result: 在对41种美国职业的150万种职业人群进行审计后发现，存在系统性偏差和刻板印象夸大现象。

Conclusion: 不同的人工智能模型在职业人群的表现中展示了明显的种族和性别偏差，建议进行模型特定的审计和设计实践的责任。

Abstract: Generative AI tools are increasingly used to create portrayals of people in
occupations, raising concerns about how race and gender are represented. We
conducted a large-scale audit of over 1.5 million occupational personas across
41 U.S. occupations, generated by four large language models with different AI
safety commitments and countries of origin (U.S., China, France). Compared with
Bureau of Labor Statistics data, we find two recurring patterns: systematic
shifts, where some groups are consistently under- or overrepresented, and
stereotype exaggeration, where existing demographic skews are amplified. On
average, White (--31pp) and Black (--9pp) workers are underrepresented, while
Hispanic (+17pp) and Asian (+12pp) workers are overrepresented. These
distortions can be extreme: for example, across all four models, Housekeepers
are portrayed as nearly 100\% Hispanic, while Black workers are erased from
many occupations. For HCI, these findings show provider choice materially
changes who is visible, motivating model-specific audits and accountable design
practices.

</details>


### [3] [Designing and Evaluating Hint Generation Systems for Science Education](https://arxiv.org/abs/2510.21087)
*Anubhav Jangra,Smaranda Muresan*

Main category: cs.HC

TL;DR: 大型语言模型在教育中的应用可以通过自动提示生成提升学习者的参与度，但还需考虑不同的提示策略和评估指标。


<details>
  <summary>Details</summary>
Motivation: 为了提升学生的概念理解和批判性思维能力，探索一种新的教学策略——自动提示生成。

Method: 通过对比静态提示和动态提示策略，并进行定量研究，分析41名参与者对提示策略的偏好。

Result: 研究发现学习者对提示策略有不同的偏好，并识别出自动评估指标的局限性。

Conclusion: 自动提示生成可以促进学习者的积极参与，同时避免直接给出答案，这是未来教育技术设计的重要考虑点。

Abstract: Large language models are influencing the education landscape, with students
relying on them in their learning process. Often implemented using
general-purpose models, these systems are likely to give away the answers,
which could hinder conceptual understanding and critical thinking. We study the
role of automatic hint generation as a pedagogical strategy to promote active
engagement with the learning content, while guiding learners toward the
answers. Focusing on scientific topics at the secondary education level, we
explore the potential of large language models to generate chains of hints that
scaffold learners without revealing answers. We compare two distinct hinting
strategies: static hints, pre-generated for each problem, and dynamic hints,
adapted to learners' progress. Through a quantitative study with 41
participants, we uncover different preferences among learners with respect to
hinting strategies, and identify the limitations of automatic evaluation
metrics to capture them. Our findings highlight key design considerations for
future research on hint generation and intelligent tutoring systems that seek
to develop learner-centered educational technologies.

</details>


### [4] [Co-Designing with Multiple Stakeholders and Datasets: A Community-Centered Process to Understand Youth Deviance in the Italian City of Turin](https://arxiv.org/abs/2510.21467)
*Ravinithesh Annapureddy,Alessandro Fornaroli,Massimo Fattori,Valeria Lacovara,Eleonora Fiori,Sarah Vollmer,Moritz Konradi,Britta Elena Hecking,Gianfranco Todesco,Daniel Gatica-Perez*

Main category: cs.HC

TL;DR: 该论文展示了一个共同设计的公民工具的开发过程，旨在解决意大利都灵的青少年偏差问题，通过多方协作和数据分析实现社区参与。


<details>
  <summary>Details</summary>
Motivation: 应对意大利都灵青少年偏差问题，通过多方协作和数据分析，提升社区理解和行动能力

Method: 通过设计研究和参与式设计方法开展共同设计和设计评估

Result: 开发了一个包含数据仪表板、利益相关者委员会和结构化共同设计会议的公民工具，评估了利益相关者信任、合作和决策的影响

Conclusion: 研究表明，政治和机构支持对公民工具的成功至关重要，同时揭示了沟通、数据素养和运营协调的障碍，强调了参与式设计在解决复杂社会问题中的重要性。

Abstract: This paper presents the co-design and design evaluation of Sbocciamo Torino
civic tool, which helps understand and act upon the issues of youth deviance in
the Italian city of Turin through multi-stakeholder collaboration and
collaborative data analysis. Rooted in research through design and
participatory design methodologies, the civic tool integrates a data dashboard,
stakeholder committee, and structured co-design sessions to facilitate
collaborative analysis and intervention planning. The civic tool was developed
in partnership with municipal authorities, law enforcement, NGOs, and social
services, and reflects their institutional priorities while centering community
knowledge. We describe the iterative co-design process, including stakeholder
workshops for design, validation, training, and evaluation. The civic tool's
impact on stakeholder trust, collaboration, and decision-making was assessed
through surveys and open-ended questionnaires. Our findings show that
stakeholders valued the inclusive design approach and data-driven collaboration
while revealing barriers in communication, data literacy, and operational
coordination. Furthermore, political and institutional support was identified
as critical to the civic tool's success. This paper contributes to research on
community technologies by demonstrating how civic tools can be collaboratively
developed to navigate wicked social problems through participatory design.

</details>


### [5] [Actionable Cybersecurity Notifications for Smart Homes: A User Study on the Role of Length and Complexity](https://arxiv.org/abs/2510.21508)
*Victor Jüttner,Charlotte S. Löffler,Erik Buchmann*

Main category: cs.HC

TL;DR: 本研究探讨了大语言模型生成的安全通知的复杂度对用户理解和反应的影响，中等复杂度的通知最有效。


<details>
  <summary>Details</summary>
Motivation: 智能家居设备的普及带来了便利，但也引发了网络安全风险，许多设备缺乏强有力的安全特性。

Method: 进行了一项包含130名参与者的在线实验研究，考察了LLM生成的通知的长度和复杂度对用户的影响。

Result: 通过实验研究发现，适中的复杂度的安全通知在不同用户群体中都最有效。

Conclusion: 研究结果为设计兼具可操作性和广泛可接触性的安全通知提供了重要见解。

Abstract: The proliferation of smart home devices has increased convenience but also
introduced cybersecurity risks for everyday users, as many devices lack robust
security features. Intrusion Detection Systems are a prominent approach to
detecting cybersecurity threats. However, their alerts often use technical
terms and require users to interpret them correctly, which is challenging for a
typical smart home user. Large Language Models can bridge this gap by
translating IDS alerts into actionable security notifications. However, it has
not yet been clear what an actionable cybersecurity notification should look
like. In this paper, we conduct an experimental online user study with 130
participants to examine how the length and complexity of LLM-generated
notifications affect user likability, understandability, and motivation to act.
Our results show that intermediate-complexity notifications are the most
effective across all user groups, regardless of their technological
proficiency. Across the board, users rated beginner-level messages as more
effective when they were longer, while expert-level messages were rated
marginally more effective when they were shorter. These findings provide
insights for designing security notifications that are both actionable and
broadly accessible to smart home users.

</details>


### [6] [Human and AI Trust: Trust Attitude Measurement Instrument](https://arxiv.org/abs/2510.21535)
*Retno Larasati*

Main category: cs.HC

TL;DR: 本文开发了一款16项信任量表，用于评估非专家对人工智能医疗支持系统的信任，经过六个阶段验证其可靠性和有效性。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能技术的发展，信任成为使用、接受和部署AI的关键标准，需要一个人本视角的信任测量工具来进行评估。

Method: 本文采用了心理测量学原则，经过项目开发、评估、问卷管理、维度测试、可靠性测试和有效性测试等六个研究阶段，来开发和验证信任测量工具。

Result: 本文提出了一种信任测量工具，旨在评估普通人对人工智能系统的信任态度，特别是在医疗支持系统的背景下。

Conclusion: 所提出的信任测量工具在评估非专家对AI医疗支持系统的信任方面， empirically可靠且有效。

Abstract: With the current progress of Artificial Intelligence (AI) technology and its
increasingly broader applications, trust is seen as a required criterion for AI
usage, acceptance, and deployment. A robust measurement instrument is essential
to correctly evaluate trust from a human-centered perspective. This paper
describes the development and validation process of a trust measure instrument,
which follows psychometric principles, and consists of a 16-items trust scale.
The instrument was built explicitly for research in human-AI interaction to
measure trust attitudes towards AI systems from layperson (non-expert)
perspective. The use-case we used to develop the scale was in the context of AI
medical support systems (specifically cancer/health prediction). The scale
development (Measurement Item Development) and validation (Measurement Item
Evaluation) involved six research stages: item development, item evaluation,
survey administration, test of dimensionality, test of reliability, and test of
validity. The results of the six-stages evaluation show that the proposed trust
measurement instrument is empirically reliable and valid for systematically
measuring and comparing non-experts' trust in AI Medical Support Systems.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [7] [ROPES: Robotic Pose Estimation via Score-Based Causal Representation Learning](https://arxiv.org/abs/2510.20884)
*Pranamya Kulkarni,Puranjay Datta,Burak Varıcı,Emre Acartürk,Karthikeyan Shanmugam,Ali Tajer*

Main category: cs.RO

TL;DR: 本研究通过ROPES框架，成功实现在无标签数据的情况下进行机器人姿态估计，填补了因果表示学习与实际应用之间的差距。


<details>
  <summary>Details</summary>
Motivation: 将因果表示学习（CRL）应用于机器人领域，填补理论与实际应用之间的差距。

Method: ROPES通过识别可操控的潜在变量并利用干预因果理论，进行无监督的姿态估计。

Result: 提出了一种新的无监督框架ROPES，用于机器人姿态估计，能够高保真地解耦潜在生成因素。

Conclusion: 将机器人姿态估计视为因果表示学习的近乎实用的测试平台。

Abstract: Causal representation learning (CRL) has emerged as a powerful unsupervised
framework that (i) disentangles the latent generative factors underlying
high-dimensional data, and (ii) learns the cause-and-effect interactions among
the disentangled variables. Despite extensive recent advances in
identifiability and some practical progress, a substantial gap remains between
theory and real-world practice. This paper takes a step toward closing that gap
by bringing CRL to robotics, a domain that has motivated CRL. Specifically,
this paper addresses the well-defined robot pose estimation -- the recovery of
position and orientation from raw images -- by introducing Robotic Pose
Estimation via Score-Based CRL (ROPES). Being an unsupervised framework, ROPES
embodies the essence of interventional CRL by identifying those generative
factors that are actuated: images are generated by intrinsic and extrinsic
latent factors (e.g., joint angles, arm/limb geometry, lighting, background,
and camera configuration) and the objective is to disentangle and recover the
controllable latent variables, i.e., those that can be directly manipulated
(intervened upon) through actuation. Interventional CRL theory shows that
variables that undergo variations via interventions can be identified. In
robotics, such interventions arise naturally by commanding actuators of various
joints and recording images under varied controls. Empirical evaluations in
semi-synthetic manipulator experiments demonstrate that ROPES successfully
disentangles latent generative factors with high fidelity with respect to the
ground truth. Crucially, this is achieved by leveraging only distributional
changes, without using any labeled data. The paper also includes a comparison
with a baseline based on a recently proposed semi-supervised framework. This
paper concludes by positioning robot pose estimation as a near-practical
testbed for CRL.

</details>


### [8] [Aircraft Collision Avoidance Systems: Technological Challenges and Solutions on the Path to Regulatory Acceptance](https://arxiv.org/abs/2510.20916)
*Sydney M. Katz,Robert J. Moss,Dylan M. Asmar,Wesley A. Olson,James K. Kuchar,Mykel J. Kochenderfer*

Main category: cs.RO

TL;DR: 飞机防撞系统在现代航空中至关重要，但其面临各种技术挑战；本文章回顾了这些挑战及其解决方案，特别关注经过严格验证并被监管机构接受的情况。


<details>
  <summary>Details</summary>
Motivation: 确保航空安全，避免潜在的飞机碰撞，促进技术进步。

Method: 综述现有研究与开发成果，强调已通过严格验证的解决方案。

Result: 各种解决方案的回顾与分析，有助于推动飞机防撞技术的发展和应用。

Conclusion: 飞机防撞系统的研究不仅为航空安全提供了重要解决方案，也为其他安全关键系统提供了有价值的见解。

Abstract: Aircraft collision avoidance systems is critical to modern aviation. These
systems are designed to predict potential collisions between aircraft and
recommend appropriate avoidance actions. Creating effective collision avoidance
systems requires solutions to a variety of technical challenges related to
surveillance, decision making, and validation. These challenges have sparked
significant research and development efforts over the past several decades that
have resulted in a variety of proposed solutions. This article provides an
overview of these challenges and solutions with an emphasis on those that have
been put through a rigorous validation process and accepted by regulatory
bodies. The challenges posed by the collision avoidance problem are often
present in other domains, and aircraft collision avoidance systems can serve as
case studies that provide valuable insights for a wide range of safety-critical
systems.

</details>


### [9] [SutureBot: A Precision Framework & Benchmark For Autonomous End-to-End Suturing](https://arxiv.org/abs/2510.20965)
*Jesse Haworth,Juo-Tung Chen,Nigel Nelson,Ji Woong Kim,Masoud Moghani,Chelsea Finn,Axel Krieger*

Main category: cs.RO

TL;DR: 本研究介绍了SutureBot，一个用于自主缝合的基准和数据集，提升了插入精度，并评估了多种最先进的视觉-语言-行动模型。


<details>
  <summary>Details</summary>
Motivation: 实现完全自主的缝合流程，以支持手术机器人的自主性。

Method: 提出SutureBot，定义自主缝合基准，使用da Vinci Research Kit，涉及针头拾取、组织插入和打结。

Result: 发布1890个缝合示例的高保真数据集，提高了插入点精度，目标准确性提高了59%-74%。

Conclusion: 自主缝合是手术机器人自主性的重要里程碑，促进了精密且长时间操作政策的发展。

Abstract: Robotic suturing is a prototypical long-horizon dexterous manipulation task,
requiring coordinated needle grasping, precise tissue penetration, and secure
knot tying. Despite numerous efforts toward end-to-end autonomy, a fully
autonomous suturing pipeline has yet to be demonstrated on physical hardware.
We introduce SutureBot: an autonomous suturing benchmark on the da Vinci
Research Kit (dVRK), spanning needle pickup, tissue insertion, and knot tying.
To ensure repeatability, we release a high-fidelity dataset comprising 1,890
suturing demonstrations. Furthermore, we propose a goal-conditioned framework
that explicitly optimizes insertion-point precision, improving targeting
accuracy by 59\%-74\% over a task-only baseline. To establish this task as a
benchmark for dexterous imitation learning, we evaluate state-of-the-art
vision-language-action (VLA) models, including $\pi_0$, GR00T N1, OpenVLA-OFT,
and multitask ACT, each augmented with a high-level task-prediction policy.
Autonomous suturing is a key milestone toward achieving robotic autonomy in
surgery. These contributions support reproducible evaluation and development of
precision-focused, long-horizon dexterous manipulation policies necessary for
end-to-end suturing. Dataset is available at:
https://huggingface.co/datasets/jchen396/suturebot

</details>


### [10] [Robust Point Cloud Reinforcement Learning via PCA-Based Canonicalization](https://arxiv.org/abs/2510.20974)
*Michael Bezick,Vittorio Giammarino,Ahmed H. Qureshi*

Main category: cs.RO

TL;DR: 本研究提出了一种PCA点云框架，通过将点云统一映射到标准姿态，显著增强了机器人控制中强化学习的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习在处理原始视觉输入时对外部变化仍显脆弱，特别是在相机姿态不匹配的情况下，亟需一种更稳健的方法。

Method: 提出了一种PCA点云（PPC）框架，旨在将点云映射到独特的标准姿态，以减少由视角变化引起的不一致性。

Result: 实验表明，PPC在各种具有挑战性的机器人任务中提高了对未见相机姿态的鲁棒性。

Conclusion: PCA Point Cloud (PPC)显著提高了机器人任务在未见相机姿态下的鲁棒性，是领域随机化的合理替代方案。

Abstract: Reinforcement Learning (RL) from raw visual input has achieved impressive
successes in recent years, yet it remains fragile to out-of-distribution
variations such as changes in lighting, color, and viewpoint. Point Cloud
Reinforcement Learning (PC-RL) offers a promising alternative by mitigating
appearance-based brittleness, but its sensitivity to camera pose mismatches
continues to undermine reliability in realistic settings. To address this
challenge, we propose PCA Point Cloud (PPC), a canonicalization framework
specifically tailored for downstream robotic control. PPC maps point clouds
under arbitrary rigid-body transformations to a unique canonical pose, aligning
observations to a consistent frame, thereby substantially decreasing
viewpoint-induced inconsistencies. In our experiments, we show that PPC
improves robustness to unseen camera poses across challenging robotic tasks,
providing a principled alternative to domain randomization.

</details>


### [11] [HRT1: One-Shot Human-to-Robot Trajectory Transfer for Mobile Manipulation](https://arxiv.org/abs/2510.21026)
*Sai Haneesh Allu,Jishnu Jaykumar P,Ninad Khargonkar,Tyler Summers,Jian Yao,Yu Xiang*

Main category: cs.RO

TL;DR: 本研究提出了一种机器人通过人类视频学习操控的系统，包含数据收集、视频理解、轨迹转移及优化等模块，能够有效完成操控任务。


<details>
  <summary>Details</summary>
Motivation: 研究如何让机器人通过观察人类的示范视频学习操控物体，以实现更灵活、高效的任务完成方式。

Method: 该系统由四个模块组成：数据收集模块、视频理解模块、轨迹转移模块和轨迹优化模块。

Result: 本系统可以让机器人在观看了一次人类示范视频后，在不同环境中重复相同的移动操控任务。

Conclusion: 通过实验验证了该系统在多种操控任务中的有效性，表明其具备在不同环境中执行任务的能力。

Abstract: We introduce a novel system for human-to-robot trajectory transfer that
enables robots to manipulate objects by learning from human demonstration
videos. The system consists of four modules. The first module is a data
collection module that is designed to collect human demonstration videos from
the point of view of a robot using an AR headset. The second module is a video
understanding module that detects objects and extracts 3D human-hand
trajectories from demonstration videos. The third module transfers a human-hand
trajectory into a reference trajectory of a robot end-effector in 3D space. The
last module utilizes a trajectory optimization algorithm to solve a trajectory
in the robot configuration space that can follow the end-effector trajectory
transferred from the human demonstration. Consequently, these modules enable a
robot to watch a human demonstration video once and then repeat the same mobile
manipulation task in different environments, even when objects are placed
differently from the demonstrations. Experiments of different manipulation
tasks are conducted on a mobile manipulator to verify the effectiveness of our
system

</details>


### [12] [Sequentially Teaching Sequential Tasks $(ST)^2$: Teaching Robots Long-horizon Manipulation Skills](https://arxiv.org/abs/2510.21046)
*Zlatan Ajanović,Ravi Prakash,Leandro de Souza Rosa,Jens Kober*

Main category: cs.RO

TL;DR: 该研究探讨了两种机器人教学方法，结果表明用户在偏好上有差异，但整体效果相似。


<details>
  <summary>Details</summary>
Motivation: 研究如何高效地教机器人完成复杂的长期任务，以减少累积误差和提高学习效率。

Method: 对比传统单一方法和分段方法，在真实零售环境中进行用户研究，评估教学效果和用户偏好。

Result: 用户研究显示，参与者对两种教学框架有不同的偏好，分别倾向于分段控制和简单性。

Conclusion: 两种教学方法在轨迹质量和成功率上表现相似，但用户偏好有所不同。

Abstract: Learning from demonstration is effective for teaching robots complex skills
with high sample efficiency. However, teaching long-horizon tasks with multiple
skills is difficult, as deviations accumulate, distributional shift increases,
and human teachers become fatigued, raising the chance of failure. In this
work, we study user responses to two teaching frameworks: (i) a traditional
monolithic approach, where users demonstrate the entire trajectory of a
long-horizon task; and (ii) a sequential approach, where the task is segmented
by the user and demonstrations are provided step by step. To support this
study, we introduce $(ST)^2$, a sequential method for learning long-horizon
manipulation tasks that allows users to control the teaching flow by defining
key points, enabling incremental and structured demonstrations. We conducted a
user study on a restocking task with 16 participants in a realistic retail
environment to evaluate both user preference and method effectiveness. Our
objective and subjective results show that both methods achieve similar
trajectory quality and success rates. Some participants preferred the
sequential approach for its iterative control, while others favored the
monolithic approach for its simplicity.

</details>


### [13] [Revisiting Replanning from Scratch: Real-Time Incremental Planning with Fast Almost-Surely Asymptotically Optimal Planners](https://arxiv.org/abs/2510.21074)
*Mitchell E. C. Sabbadini,Andrew H. Liu,Joseph Ruan,Tyler S. Wilson,Zachary Kingston,Jonathan D. Gammell*

Main category: cs.RO

TL;DR: 本研究探讨了一种新的反应性规划方法，通过快速的ASAO算法，在动态环境中有效获取一致的全球路径，无需更新现有计划，且在实验中表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 研究旨在改善在动态环境中机器人的路径规划效率，尤其是在不必更新已有计划的情况下。

Method: 通过模拟实验和真实世界的机器人臂规划问题，使用Effort Informed Trees (EIT*)和Asymptotically Optimal RRT-Connect (AORRTC)进行验证。

Result: EIT*算法相较于测试的反应性规划算法，找到的中位解决路径更短，证明了该方法的有效性。

Conclusion: 该研究表明，通过使用快速的几乎肯定渐近最优(ASAO)规划算法，可以更有效地解决增量规划问题，而不需要更新现有计划。

Abstract: Robots operating in changing environments either predict obstacle changes
and/or plan quickly enough to react to them. Predictive approaches require a
strong prior about the position and motion of obstacles. Reactive approaches
require no assumptions about their environment but must replan quickly and find
high-quality paths to navigate effectively.
  Reactive approaches often reuse information between queries to reduce
planning cost. These techniques are conceptually sound but updating dense
planning graphs when information changes can be computationally prohibitive. It
can also require significant effort to detect the changes in some applications.
  This paper revisits the long-held assumption that reactive replanning
requires updating existing plans. It shows that the incremental planning
problem can alternatively be solved more efficiently as a series of independent
problems using fast almost-surely asymptotically optimal (ASAO) planning
algorithms. These ASAO algorithms quickly find an initial solution and converge
towards an optimal solution which allows them to find consistent global plans
in the presence of changing obstacles without requiring explicit plan reuse.
This is demonstrated with simulated experiments where Effort Informed Trees
(EIT*) finds shorter median solution paths than the tested reactive planning
algorithms and is further validated using Asymptotically Optimal RRT-Connect
(AORRTC) on a real-world planning problem on a robot arm.

</details>


### [14] [Generalizable Hierarchical Skill Learning via Object-Centric Representation](https://arxiv.org/abs/2510.21121)
*Haibo Zhao,Yu Qi,Boce Hu,Yizhe Zhu,Ziyan Chen,Heng Tian,Xupeng Zhu,Owen Howell,Haojie Huang,Robin Walters,Dian Wang,Robert Platt*

Main category: cs.RO

TL;DR: GSL是一种优化机器人操作学习的框架，通过对象中心技能实现政策泛化和样本效率的显著提升。


<details>
  <summary>Details</summary>
Motivation: 提高机器人在操作时的政策泛化能力和样本效率，克服传统学习方法依赖大量示例的问题。

Method: 使用对象中心的技能作为高层视觉-语言模型与低层视觉-运动策略之间的接口，分解演示为可转移的对象规范化技能原语。

Result: GSL在模拟中以每个任务仅3个演示进行训练，表现超越基线（训练30倍数据）的性能，且在真实实验中也优于训练10倍数据的基线。

Conclusion: GSL框架在机器人操作中的样本效率和政策泛化方面表现优异，能够以较少的示例实现更好的性能。

Abstract: We present Generalizable Hierarchical Skill Learning (GSL), a novel framework
for hierarchical policy learning that significantly improves policy
generalization and sample efficiency in robot manipulation. One core idea of
GSL is to use object-centric skills as an interface that bridges the high-level
vision-language model and the low-level visual-motor policy. Specifically, GSL
decomposes demonstrations into transferable and object-canonicalized skill
primitives using foundation models, ensuring efficient low-level skill learning
in the object frame. At test time, the skill-object pairs predicted by the
high-level agent are fed to the low-level module, where the inferred canonical
actions are mapped back to the world frame for execution. This structured yet
flexible design leads to substantial improvements in sample efficiency and
generalization of our method across unseen spatial arrangements, object
appearances, and task compositions. In simulation, GSL trained with only 3
demonstrations per task outperforms baselines trained with 30 times more data
by 15.5 percent on unseen tasks. In real-world experiments, GSL also surpasses
the baseline trained with 10 times more data.

</details>


### [15] [An Agnostic End-Effector Alignment Controller for Robust Assembly of Modular Space Robots](https://arxiv.org/abs/2510.21164)
*Shamistan Karimov,Elian Neppel,Shreya Santra,Kentaro Uno,Kazuya Yoshida*

Main category: cs.RO

TL;DR: 模组机器人通过新的自适应控制器在月球环境中实现了良好的运动控制，展现出灵活性与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 模块化机器人在月球任务中需要具备可重配置性和容错性，同时需要适应现实世界扰动的控制器。

Method: 开发了一个新的控制器，通过动态超球体夹具强制执行自适应速度限制，基于实时末端执行器和目标姿态测量进行调整。

Result: 实验证明，离散步骤法提供了高度可预测、低摆动的运动，而连续速度法则在收敛更快的同时保持了毫米级的定位精度。

Conclusion: 结果强调了我们机器人无关框架在严酷条件下自主自组装和重配置的能力。

Abstract: Modular robots offer reconfigurability and fault tolerance essential for
lunar missions, but require controllers that adapt safely to real-world
disturbances. We build on our previous hardware-agnostic actuator
synchronization in Motion Stack to develop a new controller enforcing adaptive
velocity bounds via a dynamic hypersphere clamp. Using only real-time
end-effector and target pose measurements, the controller adjusts its
translational and rotational speed limits to ensure smooth, stable alignment
without abrupt motions. We implemented two variants, a discrete, step-based
version and a continuous, velocity-based version, and tested them on two
MoonBot limbs in JAXA's lunar environment simulator. Field trials demonstrate
that the step-based variant produces highly predictable, low-wobble motions,
while the continuous variant converges more quickly and maintains
millimeter-level positional accuracy, and both remain robust across limbs with
differing mechanical imperfections and sensing noise (e.g., backlash and flex).
These results highlight the flexibility and robustness of our robot-agnostic
framework for autonomous self-assembly and reconfiguration under harsh
conditions.

</details>


### [16] [Underwater Visual-Inertial-Acoustic-Depth SLAM with DVL Preintegration for Degraded Environments](https://arxiv.org/abs/2510.21215)
*Shuoshuo Ding,Tiedong Zhang,Dapeng Jiang,Ming Lei*

Main category: cs.RO

TL;DR: 提出了一种图基于视觉-惯性-声学-深度SLAM系统，利用多种传感器提高水下环境中的定位和映射能力。


<details>
  <summary>Details</summary>
Motivation: 水下环境中的有限可见性和特征稀缺对SLAM系统构成挑战。

Method: 结合立体相机、惯性测量单元、DVL和压力传感器，通过四种传感器的紧密集成应对水下视觉退化问题。

Result: 在仿真和现实世界水下场景中进行的广泛分析显示，该系统在稳定性和定位准确性方面优于当前先进的视觉-惯性SLAM系统。

Conclusion: 该系统在水下挑战性环境中表现出卓越的鲁棒性和定位准确性，超越了现有的视觉-惯性SLAM技术。

Abstract: Visual degradation caused by limited visibility, insufficient lighting, and
feature scarcity in underwater environments presents significant challenges to
visual-inertial simultaneous localization and mapping (SLAM) systems. To
address these challenges, this paper proposes a graph-based
visual-inertial-acoustic-depth SLAM system that integrates a stereo camera, an
inertial measurement unit (IMU), the Doppler velocity log (DVL), and a pressure
sensor. The key innovation lies in the tight integration of four distinct
sensor modalities to ensure reliable operation, even under degraded visual
conditions. To mitigate DVL drift and improve measurement efficiency, we
propose a novel velocity-bias-based DVL preintegration strategy. At the
frontend, hybrid tracking strategies and acoustic-inertial-depth joint
optimization enhance system stability. Additionally, multi-source hybrid
residuals are incorporated into a graph optimization framework. Extensive
quantitative and qualitative analyses of the proposed system are conducted in
both simulated and real-world underwater scenarios. The results demonstrate
that our approach outperforms current state-of-the-art stereo visual-inertial
SLAM systems in both stability and localization accuracy, exhibiting
exceptional robustness, particularly in visually challenging environments.

</details>


### [17] [Remote Autonomy for Multiple Small Lowcost UAVs in GNSS-denied Search and Rescue Operations](https://arxiv.org/abs/2510.21357)
*Daniel Schleich,Jan Quenzel,Sven Behnke*

Main category: cs.RO

TL;DR: 本研究提出了一种轻量级消费级无人机的自主飞行系统，通过Android应用简化操作并提升多机协调能力，增强现场可视化。


<details>
  <summary>Details</summary>
Motivation: 提高消费级无人机在复杂环境中的自主飞行能力，降低无人机操作员的负担。

Method: 通过Android应用程序实现状态估计和障碍物避免，直接在无人机的遥控器上运行。

Result: 该系统支持单个操作员对多架异构无人机的配置与监控，并将所有无人机的观测整合为一个联合的3D环境模型。

Conclusion: 该系统实现了轻量级消费级无人机的自主飞行，简化了操作流程并提升了多个无人机的协同工作能力。

Abstract: In recent years, consumer-grade UAVs have been widely adopted by first
responders. In general, they are operated manually, which requires trained
pilots, especially in unknown GNSS-denied environments and in the vicinity of
structures. Autonomous flight can facilitate the application of UAVs and reduce
operator strain. However, autonomous systems usually require special
programming interfaces, custom sensor setups, and strong onboard computers,
which limits a broader deployment.
  We present a system for autonomous flight using lightweight consumer-grade
DJI drones. They are controlled by an Android app for state estimation and
obstacle avoidance directly running on the UAV's remote control. Our ground
control station enables a single operator to configure and supervise multiple
heterogeneous UAVs at once. Furthermore, it combines the observations of all
UAVs into a joint 3D environment model for improved situational awareness.

</details>


### [18] [Load-bearing Assessment for Safe Locomotion of Quadruped Robots on Collapsing Terrain](https://arxiv.org/abs/2510.21369)
*Vivian S. Medeiros,Giovanni B. Dessy,Thiago Boaventura,Marcelo Becker,Claudio Semini,Victor Barasuol*

Main category: cs.RO

TL;DR: 本文提出了一种新的运动框架，使四足机器人能够在崩塌地形中安全导航，通过联合测量评估地形稳定性，而无需硬件修改。使用模型预测控制优化运动并协调地形探测。


<details>
  <summary>Details</summary>
Motivation: 研究四足机器人在崩塌地形中的导航能力，以应对搜索与救援任务或行星探索中的挑战。

Method: 采用模型预测控制系统优化机器人的运动，同时使用状态机协调地形探测行为，以动态调整机器人的落脚点。

Result: 提出了一种集成了地形探测、承载分析、运动规划和控制策略的鲁棒运动框架，提高了在不稳定表面上的安全导航能力。

Conclusion: 实验结果表明，该框架能够在保持稳定性和关注安全的前提下成功穿越崩塌地形，证明了其实用性。

Abstract: Collapsing terrains, often present in search and rescue missions or planetary
exploration, pose significant challenges for quadruped robots. This paper
introduces a robust locomotion framework for safe navigation over unstable
surfaces by integrating terrain probing, load-bearing analysis, motion
planning, and control strategies. Unlike traditional methods that rely on
specialized sensors or external terrain mapping alone, our approach leverages
joint measurements to assess terrain stability without hardware modifications.
A Model Predictive Control (MPC) system optimizes robot motion, balancing
stability and probing constraints, while a state machine coordinates terrain
probing actions, enabling the robot to detect collapsible regions and
dynamically adjust its footholds. Experimental results on custom-made
collapsing platforms and rocky terrains demonstrate the framework's ability to
traverse collapsing terrain while maintaining stability and prioritizing
safety.

</details>


### [19] [PREVENT: Proactive Risk Evaluation and Vigilant Execution of Tasks for Mobile Robotic Chemists using Multi-Modal Behavior Trees](https://arxiv.org/abs/2510.21438)
*Satheeshkumar Veeramani,Zhengxue Zhou,Francisco Munguia-Galeano,Hatem Fakhruldeen,Thomas Roddelkopf,Mohammed Faeik Ruzaij Al-Okby,Kerstin Thurow,Andrew Ian Cooper*

Main category: cs.RO

TL;DR: 移动机器人化学家在化学和材料研究中快速发展，但缺乏工作流程意识技能，可能导致小异常干扰整个工作流程。为解决这一问题，提出了PREVENT系统，运用多模态行为树方法，提高了工作流程的效率并避免了错误警报。


<details>
  <summary>Details</summary>
Motivation: 解决移动机器人在化学工作流程中因小异常而导致的时间、资源浪费及潜在风险问题，提升其自动化操作的效益。

Method: 采用基于多模态行为树的方法，并结合人工智能技术和传感器反馈，实现导航和操作技能的层次化感知机制。

Result: 该系统在模拟实验中无虚假阳性和阴性，且多模态技能的准确性高于单模态技能，显示出优越的性能。

Conclusion: PREVENT系统在模拟风险场景中表现出较高的效率和准确性，成功避免了虚假警报，并且其多模态感知技能的部署准确性超出了单模态技能的平均水平。

Abstract: Mobile robotic chemists are a fast growing trend in the field of chemistry
and materials research. However, so far these mobile robots lack workflow
awareness skills. This poses the risk that even a small anomaly, such as an
improperly capped sample vial could disrupt the entire workflow. This wastes
time, and resources, and could pose risks to human researchers, such as
exposure to toxic materials. Existing perception mechanisms can be used to
predict anomalies but they often generate excessive false positives. This may
halt workflow execution unnecessarily, requiring researchers to intervene and
to resume the workflow when no problem actually exists, negating the benefits
of autonomous operation. To address this problem, we propose PREVENT a system
comprising navigation and manipulation skills based on a multimodal Behavior
Tree (BT) approach that can be integrated into existing software architectures
with minimal modifications. Our approach involves a hierarchical perception
mechanism that exploits AI techniques and sensory feedback through Dexterous
Vision and Navigational Vision cameras and an IoT gas sensor module for
execution-related decision-making. Experimental evaluations show that the
proposed approach is comparatively efficient and completely avoids both false
negatives and false positives when tested in simulated risk scenarios within
our robotic chemistry workflow. The results also show that the proposed
multi-modal perception skills achieved deployment accuracies that were higher
than the average of the corresponding uni-modal skills, both for navigation and
for manipulation.

</details>


### [20] [Enhancing Social Robots through Resilient AI](https://arxiv.org/abs/2510.21469)
*Domenico Palmisano,Giuseppe Palestra,Berardina Nadja De Carolis*

Main category: cs.RO

TL;DR: 随着AI的进步，社交机器人需要具备韧性，以在逆境中保持信任和基本操作能力。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能在医疗、教育和日常生活中的应用日益加深，确保系统的韧性和稳健性变得至关重要。

Method: 

Result: 

Conclusion: 社交机器人应具备韧性，以确保用户信任，尤其是在老年人中。

Abstract: As artificial intelligence continues to advance and becomes more integrated
into sensitive areas like healthcare, education, and everyday life, it's
crucial for these systems to be both resilient and robust. This paper shows how
resilience is a fundamental characteristic of social robots, which, through it,
ensure trust in the robot itself-an essential element especially when operating
in contexts with elderly people, who often have low trust in these systems.
Resilience is therefore the ability to operate under adverse or stressful
conditions, even when degraded or weakened, while maintaining essential
operational capabilities.

</details>


### [21] [AURASeg: Attention Guided Upsampling with Residual Boundary-Assistive Refinement for Drivable-Area Segmentation](https://arxiv.org/abs/2510.21536)
*Narendhiran Vijayakumar,Sridevi. M*

Main category: cs.RO

TL;DR: 提出了一种新的地面平面语义分割模型AURASeg，能在保持高分割精度的同时改善边界精度，适用于自主感知。


<details>
  <summary>Details</summary>
Motivation: 提高现有分割模型在室内和结构化环境中对于细粒度特征的处理能力，克服多尺度处理、边界精细化和特征表示的局限性。

Method: Attention-Guided Upsampling with Residual Boundary-Assistive Refinement (AURASeg)模型

Result: 在Ground Mobile Robot Perception (GMRP) 数据集和自定义的Gazebo室内数据集测试中，该模型在mIoU和F1指标上优于基准分割架构，mIoU提高了1.26%，分割精度提高了1.65%。

Conclusion: 该技术适用于室内和室外环境的自主感知，实现了精确的边界细化，且对推断速度的影响最小。

Abstract: Free space ground segmentation is essential to navigate robots and autonomous
vehicles, recognize drivable zones, and traverse efficiently. Fine-grained
features remain challenging for existing segmentation models, particularly for
robots in indoor and structured environments. These difficulties arise from
ineffective multi-scale processing, suboptimal boundary refinement, and limited
feature representation. In order to overcome these limitations, we propose
Attention-Guided Upsampling with Residual Boundary-Assistive Refinement
(AURASeg), a ground-plane semantic segmentation model that maintains high
segmentation accuracy while improving border precision. Our method uses
CSP-Darknet backbone by adding a Residual Border Refinement Module (RBRM) for
accurate edge delineation and an Attention Progressive Upsampling Decoder
(APUD) for strong feature integration. We also incorporate a lightweight Atrous
Spatial Pyramid Pooling (ASPP-Lite) module to ensure multi-scale context
extraction without compromising real-time performance. The proposed model beats
benchmark segmentation architectures in mIoU and F1 metrics when tested on the
Ground Mobile Robot Perception (GMRP) Dataset and a custom Gazebo indoor
dataset. Our approach achieves an improvement in mean Intersection-over-Union
(mIoU) of +1.26% and segmentation precision of +1.65% compared to
state-of-the-art models. These results show that our technique is feasible for
autonomous perception in both indoor and outdoor environments, enabling precise
border refinement with minimal effect on inference speed.

</details>


### [22] [Scalable Vision-Language-Action Model Pretraining for Robotic Manipulation with Real-Life Human Activity Videos](https://arxiv.org/abs/2510.21571)
*Qixiu Li,Yu Deng,Yaobo Liang,Lin Luo,Lei Zhou,Chengtang Yao,Lingqi Zeng,Zhiyuan Feng,Huizhi Liang,Sicheng Xu,Yizhong Zhang,Xi Chen,Hao Chen,Lily Sun,Dong Chen,Jiaolong Yang,Baining Guo*

Main category: cs.RO

TL;DR: 本研究提出了一种通过大量非脚本化视频预训练机器人视觉-语言-动作(VLA)模型的新方法，并展示了模型在真实环境中的强大表现和良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 旨在利用大量非脚本化的真实视频记录来预训练机器人操作的VLA模型。

Method: 采用全自动的整体人类活动分析方法，将无注释的人类手活动视频转换为机器人训练数据格式。

Result: 创建了一个包含100万集和2600万帧的手-VLA训练数据集，模型在完全未见的真实世界观察中的零-shot能力表现良好，并通过对少量真实机器人动作数据的微调，显著提高了任务成功率和对新物体的泛化能力。

Conclusion: 该研究为可扩展的视觉-语言-动作(VLA)预训练奠定了基础，推动机器人向真正的可泛化的具身智能发展。

Abstract: This paper presents a novel approach for pretraining robotic manipulation
Vision-Language-Action (VLA) models using a large corpus of unscripted
real-life video recordings of human hand activities. Treating human hand as
dexterous robot end-effector, we show that "in-the-wild" egocentric human
videos without any annotations can be transformed into data formats fully
aligned with existing robotic V-L-A training data in terms of task granularity
and labels. This is achieved by the development of a fully-automated holistic
human activity analysis approach for arbitrary human hand videos. This approach
can generate atomic-level hand activity segments and their language
descriptions, each accompanied with framewise 3D hand motion and camera motion.
We process a large volume of egocentric videos and create a hand-VLA training
dataset containing 1M episodes and 26M frames. This training data covers a wide
range of objects and concepts, dexterous manipulation tasks, and environment
variations in real life, vastly exceeding the coverage of existing robot data.
We design a dexterous hand VLA model architecture and pretrain the model on
this dataset. The model exhibits strong zero-shot capabilities on completely
unseen real-world observations. Additionally, fine-tuning it on a small amount
of real robot action data significantly improves task success rates and
generalization to novel objects in real robotic experiments. We also
demonstrate the appealing scaling behavior of the model's task performance with
respect to pretraining data scale. We believe this work lays a solid foundation
for scalable VLA pretraining, advancing robots toward truly generalizable
embodied intelligence.

</details>


### [23] [Enhancing Tactile-based Reinforcement Learning for Robotic Control](https://arxiv.org/abs/2510.21609)
*Elle Miller,Trevor McInroe,David Abel,Oisin Mac Aodha,Sethu Vijayakumar*

Main category: cs.RO

TL;DR: 本文开发了自监督学习方法，以提高机器人使用触觉传感器的能力，展示了稀疏二元信号在复杂接触任务中的重要性，并发布了触觉操控的标准化基准。


<details>
  <summary>Details</summary>
Motivation: 为了实现安全可靠的机器人操作，需要超越视觉，整合触觉感知，以克服感知不足和对理想状态信息的依赖。

Method: 通过自监督学习的方法来处理稀疏的二元触觉信号，强调了其在本体感知控制误差无法注册的任务中的重要性。

Result: 本文提出了自监督学习方法，以提高机器人在现实世界中进行安全、可靠的操作能力，特别是在触觉传感的有效利用上。通过对稀疏二元触觉信号的研究，揭示了其在灵巧性方面的重要性，尤其是在一些本体感知控制错误无法感知的情况下。实验中，提出的方法在复杂接触任务中展现了超人类的灵巧性，并通过解耦自监督学习记忆与策略记忆提升了性能。

Conclusion: 自监督学习可以显著提升机器人在复杂触觉操控任务中的表现，稀疏二元触觉信号在提升灵巧性方面极为关键。同时，解耦记忆的方法能进一步优化性能。

Abstract: Achieving safe, reliable real-world robotic manipulation requires agents to
evolve beyond vision and incorporate tactile sensing to overcome sensory
deficits and reliance on idealised state information. Despite its potential,
the efficacy of tactile sensing in reinforcement learning (RL) remains
inconsistent. We address this by developing self-supervised learning (SSL)
methodologies to more effectively harness tactile observations, focusing on a
scalable setup of proprioception and sparse binary contacts. We empirically
demonstrate that sparse binary tactile signals are critical for dexterity,
particularly for interactions that proprioceptive control errors do not
register, such as decoupled robot-object motions. Our agents achieve superhuman
dexterity in complex contact tasks (ball bouncing and Baoding ball rotation).
Furthermore, we find that decoupling the SSL memory from the on-policy memory
can improve performance. We release the Robot Tactile Olympiad (RoTO) benchmark
to standardise and promote future research in tactile-based manipulation.
Project page: https://elle-miller.github.io/tactile_rl

</details>


### [24] [Design and Structural Validation of a Micro-UAV with On-Board Dynamic Route Planning](https://arxiv.org/abs/2510.21648)
*Inbazhagan Ravikumar,Ram Sundhar,Narendhiran Vijayakumar*

Main category: cs.RO

TL;DR: 本研究开发了一种轻便且具有适应性的小型无人机，适合搜索和救援，解决了结构耐久性和路径动态重规划的不足。


<details>
  <summary>Details</summary>
Motivation: 提高无人机在搜索和救援任务中的性能，解决现有低成本无人机在复杂环境下的局限性。

Method: 通过使用常见组件和材料，自主设计并制造无人机，框架采用轻质耐用材料增强，以承受冲击，同时控制系统使用开源软件。

Result: 提出了一种定制的小型无人机，专门用于搜索和救援操作，以克服低成本无人机在动态路径重规划和飞行耐久性方面的限制。

Conclusion: 该无人机系统在动态环境中能够实时感知，并具备适应性导航功能，是一种经济实用的搜索和救援解决方案。

Abstract: Micro aerial vehicles are becoming increasingly important in search and
rescue operations due to their agility, speed, and ability to access confined
spaces or hazardous areas. However, designing lightweight aerial systems
presents significant structural, aerodynamic, and computational challenges.
This work addresses two key limitations in many low-cost aerial systems under
two kilograms: their lack of structural durability during flight through rough
terrains and inability to replan paths dynamically when new victims or
obstacles are detected. We present a fully customised drone built from scratch
using only commonly available components and materials, emphasising modularity,
low cost, and ease of assembly. The structural frame is reinforced with
lightweight yet durable materials to withstand impact, while the onboard
control system is powered entirely by free, open-source software solutions. The
proposed system demonstrates real-time perception and adaptive navigation
capabilities without relying on expensive hardware accelerators, offering an
affordable and practical solution for real-world search and rescue missions.

</details>
