<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 27]
- [cs.HC](#cs.HC) [Total: 23]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Signal or 'Noise': Human Reactions to Robot Errors in the Wild](https://arxiv.org/abs/2602.05010)
*Maia Stiber,Sameer Khan,Russell Taylor,Chien-Ming Huang*

Main category: cs.RO

TL;DR: 本研究探讨了人类在真实环境中对机器人错误的社交反应，发现社交信号丰富但呈现噪声，强调了社交信号在现实机器人-人类互动中的潜力与挑战。


<details>
  <summary>Details</summary>
Motivation: 研究人类在真实环境中对机器人错误的社会反应，以了解社交信号在错误管理中的作用。

Method: 通过构建一个咖啡机器人并在公共场所进行部署（样本量为49），观察参与者对错误的社会反应。

Result: 参与者在群体互动中对错误表现出各种社交信号，并自愿提供有关互动的信息。

Conclusion: 社交信号在真实环境中的表现丰富但噪声较大，为机器人与人类的互动提出了可行性和挑战。

Abstract: In the real world, robots frequently make errors, yet little is known about people's social responses to errors outside of lab settings. Prior work has shown that social signals are reliable and useful for error management in constrained interactions, but it is unclear if this holds in the real world - especially with a non-social robot in repeated and group interactions with successive or propagated errors. To explore this, we built a coffee robot and conducted a public field deployment ($N = 49$). We found that participants consistently expressed varied social signals in response to errors and other stimuli, particularly during group interactions. Our findings suggest that social signals in the wild are rich (with participants volunteering information about the interaction), but "noisy." We discuss lessons, benefits, and challenges for using social signals in real-world HRI.

</details>


### [2] [Differentiable Inverse Graphics for Zero-shot Scene Reconstruction and Robot Grasping](https://arxiv.org/abs/2602.05029)
*Octavio Arriaga,Proneet Sharma,Jichen Guo,Marc Otto,Siddhant Kadwe,Rebecca Adam*

Main category: cs.RO

TL;DR: 该研究提出了一种新的可微分神经图形模型，实现了在新环境中进行零-shot场景重建和抓取，且不依赖于大规模数据集，展现了优越性。


<details>
  <summary>Details</summary>
Motivation: 为了实现机器人在新环境中估计和交互以前未见过的物体的能力，现有的主流模型依赖于大量的训练数据和测试样本。

Method: 提出了一个可微分的神经图形模型，该模型结合了神经基础模型与基于物理的可微分渲染，解决了一系列约束优化问题，以从单个RGBD图像和边界框中估计场景参数。

Result: 该模型在标准的无模型少样本基准测试中表现优于现有算法，并在零-shot抓取任务中验证了场景重建的准确性。

Conclusion: 该方法能够实现无须大量数据或测试样本的零-shot场景重建和抓取，为新环境中的机器人自主性提供了更有效的路径。

Abstract: Operating effectively in novel real-world environments requires robotic systems to estimate and interact with previously unseen objects. Current state-of-the-art models address this challenge by using large amounts of training data and test-time samples to build black-box scene representations. In this work, we introduce a differentiable neuro-graphics model that combines neural foundation models with physics-based differentiable rendering to perform zero-shot scene reconstruction and robot grasping without relying on any additional 3D data or test-time samples. Our model solves a series of constrained optimization problems to estimate physically consistent scene parameters, such as meshes, lighting conditions, material properties, and 6D poses of previously unseen objects from a single RGBD image and bounding boxes. We evaluated our approach on standard model-free few-shot benchmarks and demonstrated that it outperforms existing algorithms for model-free few-shot pose estimation. Furthermore, we validated the accuracy of our scene reconstructions by applying our algorithm to a zero-shot grasping task. By enabling zero-shot, physically-consistent scene reconstruction and grasping without reliance on extensive datasets or test-time sampling, our approach offers a pathway towards more data efficient, interpretable and generalizable robot autonomy in novel environments.

</details>


### [3] [Reinforcement Learning Enhancement Using Vector Semantic Representation and Symbolic Reasoning for Human-Centered Autonomous Emergency Braking](https://arxiv.org/abs/2602.05079)
*Vinal Asodia,Iman Sharifi,Saber Fallah*

Main category: cs.RO

TL;DR: 该论文提出了一种新颖的神经符号特征表示和软一阶逻辑奖励函数，以解决现有深度强化学习在自主驾驶中存在的问题，结果显示提升了政策稳健性和安全性。


<details>
  <summary>Details</summary>
Motivation: 现有基于相机的深度强化学习方法在特征表示中很少整合高层场景上下文，并依赖于固定的奖励函数。

Method: 提出了一种神经符号特征表示和软一阶逻辑奖励函数.

Result: 实验证明，所提出的神经符号表示和SFOL奖励函数在政策稳健性和安全相关性能指标上超过了基线表示和奖励公式。

Conclusion: 通过整合整体表示和软推理，增强了自主驾驶的上下文感知和价值对齐的决策能力。

Abstract: The problem with existing camera-based Deep Reinforcement Learning approaches is twofold: they rarely integrate high-level scene context into the feature representation, and they rely on rigid, fixed reward functions. To address these challenges, this paper proposes a novel pipeline that produces a neuro-symbolic feature representation that encompasses semantic, spatial, and shape information, as well as spatially boosted features of dynamic entities in the scene, with an emphasis on safety-critical road users. It also proposes a Soft First-Order Logic (SFOL) reward function that balances human values via a symbolic reasoning module. Here, semantic and spatial predicates are extracted from segmentation maps and applied to linguistic rules to obtain reward weights. Quantitative experiments in the CARLA simulation environment show that the proposed neuro-symbolic representation and SFOL reward function improved policy robustness and safety-related performance metrics compared to baseline representations and reward formulations across varying traffic densities and occlusion levels. The findings demonstrate that integrating holistic representations and soft reasoning into Reinforcement Learning can support more context-aware and value-aligned decision-making for autonomous driving.

</details>


### [4] [A Framework for Combining Optimization-Based and Analytic Inverse Kinematics](https://arxiv.org/abs/2602.05092)
*Thomas Cohn,Lihan Tang,Alexandre Amice,Russ Tedrake*

Main category: cs.RO

TL;DR: 本文提出了一种新的优化逆运动学方法，通过将解析解作为变量变换，提高了在复杂约束下的成功率。


<details>
  <summary>Details</summary>
Motivation: 开发统一的方法以同时利用解析和优化逆运动学方法的优势，解决高失败率的问题。

Method: 使用解析逆运动学解作为变量变换来简化优化过程。

Result: 新方法在解决碰撞避免、抓取选择和人形稳定性等多个逆运动学问题中，表现出比旧方法更高的成功率。

Conclusion: 新提出的优化逆运动学方法在处理多种挑战的逆运动学问题时表现出更高的成功率。

Abstract: Analytic and optimization methods for solving inverse kinematics (IK) problems have been deeply studied throughout the history of robotics. The two strategies have complementary strengths and weaknesses, but developing a unified approach to take advantage of both methods has proved challenging. A key challenge faced by optimization approaches is the complicated nonlinear relationship between the joint angles and the end-effector pose. When this must be handled concurrently with additional nonconvex constraints like collision avoidance, optimization IK algorithms may suffer high failure rates. We present a new formulation for optimization IK that uses an analytic IK solution as a change of variables, and is fundamentally easier for optimizers to solve. We test our methodology on three popular solvers, representing three different paradigms for constrained nonlinear optimization. Extensive experimental comparisons demonstrate that our new formulation achieves higher success rates than the old formulation and baseline methods across various challenging IK problems, including collision avoidance, grasp selection, and humanoid stability.

</details>


### [5] [PLATO Hand: Shaping Contact Behavior with Fingernails for Precise Manipulation](https://arxiv.org/abs/2602.05156)
*Dong Ho Kang,Aaron Kim,Mingyo Seo,Kazuto Yokoyama,Tetsuya Narita,Luis Sentis*

Main category: cs.RO

TL;DR: PLATO手通过将刚性指甲与柔性指柄结合，实现了提高夹持稳定性和力可观测性的灵巧操控，适用于多种物体操作。


<details>
  <summary>Details</summary>
Motivation: 设计一种能够在各种物体几何形状上实现多种交互模式的灵巧机器人手。

Method: 开发了一种基于应变能的弯曲-压入模型，以指导手指尖设计并解释如何保持局部压入同时抑制整体弯曲。

Result: 实验结果表明，所提出的机器人手设计在夹持稳定性、力可观测性和边缘敏感操作任务（如纸张分离、卡片拾取和橙子剥皮）的执行上均有所改善。

Conclusion: 将结构化接触几何与力-运动透明机制相结合提供了一种原则性、物理体现的方法，以实现精确操作。

Abstract: We present the PLATO Hand, a dexterous robotic hand with a hybrid fingertip that embeds a rigid fingernail within a compliant pulp. This design shapes contact behavior to enable diverse interaction modes across a range of object geometries. We develop a strain-energy-based bending-indentation model to guide the fingertip design and to explain how guided contact preserves local indentation while suppressing global bending. Experimental results show that the proposed robotic hand design demonstrates improved pinching stability, enhanced force observability, and successful execution of edge-sensitive manipulation tasks, including paper singulation, card picking, and orange peeling. Together, these results show that coupling structured contact geometry with a force-motion transparent mechanism provides a principled, physically embodied approach to precise manipulation.

</details>


### [6] [Informative Path Planning with Guaranteed Estimation Uncertainty](https://arxiv.org/abs/2602.05198)
*Kalvik Jakkala,Saurav Agarwal,Jason O'Kane,Srinivas Akella*

Main category: cs.RO

TL;DR: 本研究提出了一种新方法，结合信息路径规划和不确定性保证，优化了环境监测机器人的路径规划，实验证明其在实际应用中具有有效性。


<details>
  <summary>Details</summary>
Motivation: 随着环境监测机器人在空间场重构中的应用需求增加，减少测量重采样并提高重建质量成为迫切需求。

Method: 本文提出了一个三阶段方法，包括学习高斯过程模型、生成覆盖图以及规划近最优路径以满足全球不确定性约束。

Result: 实验结果表明，与最近的基准相比，我们的方法在满足不确定性目标的情况下，使用更少的测量位置和更短的旅行距离。

Conclusion: 本研究提出了一种新颖的方法，通过融合信息路径规划与重建质量保证，优化了环境监测机器人的测量路径。

Abstract: Environmental monitoring robots often need to reconstruct spatial fields (e.g., salinity, temperature, bathymetry) under tight distance and energy constraints. Classical boustrophedon lawnmower surveys provide geometric coverage guarantees but can waste effort by oversampling predictable regions. In contrast, informative path planning (IPP) methods leverage spatial correlations to reduce oversampling, yet typically offer no guarantees on reconstruction quality. This paper bridges these approaches by addressing informative path planning with guaranteed estimation uncertainty: computing the shortest path whose measurements ensure that the Gaussian-process (GP) posterior variance -- an intrinsic uncertainty measure that lower-bounds the mean-squared prediction error under the GP model -- falls below a user-specified threshold over the monitoring region.
  We propose a three-stage approach: (i) learn a GP model from available prior information; (ii) transform the learned GP kernel into binary coverage maps for each candidate sensing location, indicating which locations' uncertainty can be reduced below a specified target; and (iii) plan a near-shortest route whose combined coverage satisfies the global uncertainty constraint. To address heterogeneous phenomena, we incorporate a nonstationary kernel that captures spatially varying correlation structure, and we accommodate non-convex environments with obstacles. Algorithmically, we present methods with provable approximation guarantees for sensing-location selection and for the joint selection-and-routing problem under a travel budget. Experiments on real-world topographic data show that our planners meet the uncertainty target using fewer sensing locations and shorter travel distances than a recent baseline, and field experiments with bathymetry-mapping autonomous surface and underwater vehicles demonstrate real-world feasibility.

</details>


### [7] [MobileManiBench: Simplifying Model Verification for Mobile Manipulation](https://arxiv.org/abs/2602.05233)
*Wenbo Wang,Fangyun Wei,QiXiu Li,Xi Chen,Yaobo Liang,Chang Xu,Jiaolong Yang,Baining Guo*

Main category: cs.RO

TL;DR: 我们提出了MobileManiBench，一个大型基准测试，用于验证视觉-语言-动作模型在移动机器人操作中的表现，支持多样化的操作研究。


<details>
  <summary>Details</summary>
Motivation: 当前视觉-语言-动作模型在机器人操作中表现良好，但受限于静态桌面场景的数据集，因此需要更具挑战性的基准测试。

Method: 通过在NVIDIA Isaac Sim上使用强化学习，自动生成多样化的操作轨迹并进行丰富的注释。

Result: MobileManiBench包含630种物体和100种现实场景，提供300K个操作轨迹，支持对不同机器人形态和感知方式的研究。

Conclusion: 本研究提出的MobileManiBench基准测试，加速了机器人操作中的数据效率和泛化能力研究，验证了不同VLA模型在复杂模拟环境中的表现。

Abstract: Vision-language-action models have advanced robotic manipulation but remain constrained by reliance on the large, teleoperation-collected datasets dominated by the static, tabletop scenes. We propose a simulation-first framework to verify VLA architectures before real-world deployment and introduce MobileManiBench, a large-scale benchmark for mobile-based robotic manipulation. Built on NVIDIA Isaac Sim and powered by reinforcement learning, our pipeline autonomously generates diverse manipulation trajectories with rich annotations (language instructions, multi-view RGB-depth-segmentation images, synchronized object/robot states and actions). MobileManiBench features 2 mobile platforms (parallel-gripper and dexterous-hand robots), 2 synchronized cameras (head and right wrist), 630 objects in 20 categories, 5 skills (open, close, pull, push, pick) with over 100 tasks performed in 100 realistic scenes, yielding 300K trajectories. This design enables controlled, scalable studies of robot embodiments, sensing modalities, and policy architectures, accelerating research on data efficiency and generalization. We benchmark representative VLA models and report insights into perception, reasoning, and control in complex simulated environments.

</details>


### [8] [Low-Cost Underwater In-Pipe Centering and Inspection Using a Minimal-Sensing Robot](https://arxiv.org/abs/2602.05265)
*Kalvik Jakkala,Jason O'Kane*

Main category: cs.RO

TL;DR: 提出了一种新颖的水下机器人导航策略，实现了沉没管道的自动检查，展示了该系统在复杂环境中可靠运行的能力。


<details>
  <summary>Details</summary>
Motivation: 自主水下检验沉没管道面临很大挑战，因此需要发展一种新策略来提高在复杂环境中的导航能力。

Method: 采用最小感知策略，通过IMU、压力传感器以及单束声呐和360度声呐进行管道中心定位和巡航。

Result: 在46厘米直径的沉没管道中进行实验，展示了稳定的中心定位和成功的整管巡航能力，尽管存在环境流动和结构变形。

Conclusion: 可靠的管道内导航与检测可以通过轻量级和计算高效的传感与处理架构实现，从而提升自主水下检查在有限环境中的实用性。

Abstract: Autonomous underwater inspection of submerged pipelines is challenging due to confined geometries, turbidity, and the scarcity of reliable localization cues. This paper presents a minimal-sensing strategy that enables a free-swimming underwater robot to center itself and traverse a flooded pipe of known radius using only an IMU, a pressure sensor, and two sonars: a downward-facing single-beam sonar and a rotating 360 degree sonar. We introduce a computationally efficient method for extracting range estimates from single-beam sonar intensity data, enabling reliable wall detection in noisy and reverberant conditions. A closed-form geometric model leverages the two sonar ranges to estimate the pipe center, and an adaptive, confidence-weighted proportional-derivative (PD) controller maintains alignment during traversal. The system requires no Doppler velocity log, external tracking, or complex multi-sensor arrays. Experiments in a submerged 46 cm-diameter pipe using a Blue Robotics BlueROV2 heavy remotely operated vehicle demonstrate stable centering and successful full-pipe traversal despite ambient flow and structural deformations. These results show that reliable in-pipe navigation and inspection can be achieved with a lightweight, computationally efficient sensing and processing architecture, advancing the practicality of autonomous underwater inspection in confined environments.

</details>


### [9] [Affordance-Aware Interactive Decision-Making and Execution for Ambiguous Instructions](https://arxiv.org/abs/2602.05273)
*Hengxuan Xu,Fengbo Lan,Zhixin Zhao,Shengjie Wang,Mengqiao Liu,Jieqian Sun,Yu Cheng,Tao Zhang*

Main category: cs.RO

TL;DR: 提出AIDE框架解决模糊指令下机器人探索和执行中的挑战，取得优秀的任务规划和执行结果。


<details>
  <summary>Details</summary>
Motivation: 解决现有基于VLM的方法在处理模糊人类指令时面临的推理效率低下及缺乏环境交互的问题。

Method: 提出了双流框架AIDE，包括多阶段推理（MSI）作为决策流，快速决策（ADM）作为执行流，结合了交互探索和视觉-语言推理。

Result: AIDE在模拟和现实环境中经过广泛实验验证，展示了其在任务规划和执行中的优越性能。

Conclusion: AIDE在多种开放世界场景中超过80%的任务规划成功率和95%以上的闭环持续执行准确率，优于现有的基于VLM的方法。

Abstract: Enabling robots to explore and act in unfamiliar environments under ambiguous human instructions by interactively identifying task-relevant objects (e.g., identifying cups or beverages for "I'm thirsty") remains challenging for existing vision-language model (VLM)-based methods. This challenge stems from inefficient reasoning and the lack of environmental interaction, which hinder real-time task planning and execution. To address this, We propose Affordance-Aware Interactive Decision-Making and Execution for Ambiguous Instructions (AIDE), a dual-stream framework that integrates interactive exploration with vision-language reasoning, where Multi-Stage Inference (MSI) serves as the decision-making stream and Accelerated Decision-Making (ADM) as the execution stream, enabling zero-shot affordance analysis and interpretation of ambiguous instructions. Extensive experiments in simulation and real-world environments show that AIDE achieves the task planning success rate of over 80\% and more than 95\% accuracy in closed-loop continuous execution at 10 Hz, outperforming existing VLM-based methods in diverse open-world scenarios.

</details>


### [10] [Learning Soccer Skills for Humanoid Robots: A Progressive Perception-Action Framework](https://arxiv.org/abs/2602.05310)
*Jipeng Kong,Xinzhe Liu,Yuhang Lin,Jinrui Han,Sören Schwertfeger,Chenjia Bai,Xuelong Li*

Main category: cs.RO

TL;DR: 本研究提出PAiD架构，通过分阶段的技能获取，增强了人形机器人在复杂足球任务中的感知-行动能力，实验显示其在多种环境下均能高效表现。


<details>
  <summary>Details</summary>
Motivation: 旨在解决现有模块化管道的不稳定性和端到端框架中的训练目标冲突，以提升人形机器人在足球等复杂任务中的感知-行动能力。

Method: 采用了分阶段的技能获取，即通过人类运动跟踪获取运动技能，通过轻量化的感知-行动集成实现位置泛化，最后实现基于物理的模拟到现实转移。

Result: 在Unitree G1机器人上的实验表明，PAiD架构在静态和滚动球、不同位置和干扰下实现了高保真度的人类踢球表现，并在室内和室外场景中持续稳定执行。

Conclusion: 本研究提出的PAiD架构通过分阶段的技能获取和集成方法，成功提高了人形机器人在足球领域的表现，展现了强大的适应能力和稳定性的优势。

Abstract: Soccer presents a significant challenge for humanoid robots, demanding tightly integrated perception-action capabilities for tasks like perception-guided kicking and whole-body balance control. Existing approaches suffer from inter-module instability in modular pipelines or conflicting training objectives in end-to-end frameworks. We propose Perception-Action integrated Decision-making (PAiD), a progressive architecture that decomposes soccer skill acquisition into three stages: motion-skill acquisition via human motion tracking, lightweight perception-action integration for positional generalization, and physics-aware sim-to-real transfer. This staged decomposition establishes stable foundational skills, avoids reward conflicts during perception integration, and minimizes sim-to-real gaps. Experiments on the Unitree G1 demonstrate high-fidelity human-like kicking with robust performance under diverse conditions-including static or rolling balls, various positions, and disturbances-while maintaining consistent execution across indoor and outdoor scenarios. Our divide-and-conquer strategy advances robust humanoid soccer capabilities and offers a scalable framework for complex embodied skill acquisition. The project page is available at https://soccer-humanoid.github.io/.

</details>


### [11] [RoboPaint: From Human Demonstration to Any Robot and Any View](https://arxiv.org/abs/2602.05325)
*Jiacheng Fan,Zhiyue Zhao,Yiqian Zhang,Chao Chen,Peide Wang,Hengdi Zhang,Zhengxue Cheng*

Main category: cs.RO

TL;DR: 我们提出了一种有效的数据管道，将人类演示转化为机器人训练数据，显著提升了在灵巧操作任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 解决灵巧操作中大规模高保真机器人演示数据获取的关键瓶颈，以提升视觉-语言-动作（VLA）模型的性能。

Method: 提出一种实境-仿真-实境的数据收集和编辑管道，将人类演示转换为机器人可执行和环境特定的训练数据，采用触觉感知重定向方法，基于几何和力引导优化将人类手的状态映射到机器人灵巧手的状态。

Result: 通过真实世界实验表明，重定向的灵巧手轨迹在10个不同物体操作任务中取得了84%的成功率；基于生成数据训练的VLA策略在三项代表性任务上平均成功率达到80%。

Conclusion: 我们的实境-仿真-实境数据管道能够有效地从人类演示中生成机器人训练数据，提供了一种可扩展且成本效益高的替代方案来进行复杂的灵巧操作训练，性能损失最小。

Abstract: Acquiring large-scale, high-fidelity robot demonstration data remains a critical bottleneck for scaling Vision-Language-Action (VLA) models in dexterous manipulation. We propose a Real-Sim-Real data collection and data editing pipeline that transforms human demonstrations into robot-executable, environment-specific training data without direct robot teleoperation. Standardized data collection rooms are built to capture multimodal human demonstrations (synchronized 3 RGB-D videos, 11 RGB videos, 29-DoF glove joint angles, and 14-channel tactile signals). Based on these human demonstrations, we introduce a tactile-aware retargeting method that maps human hand states to robot dex-hand states via geometry and force-guided optimization. Then the retargeted robot trajectories are rendered in a photorealistic Isaac Sim environment to build robot training data. Real world experiments have demonstrated: (1) The retargeted dex-hand trajectories achieve an 84\% success rate across 10 diverse object manipulation tasks. (2) VLA policies (Pi0.5) trained exclusively on our generated data achieve 80\% average success rate on three representative tasks, i.e., pick-and-place, pushing and pouring. To conclude, robot training data can be efficiently "painted" from human demonstrations using our real-sim-real data pipeline. We offer a scalable, cost-effective alternative to teleoperation with minimal performance loss for complex dexterous manipulation.

</details>


### [12] [Benchmarking Affordance Generalization with BusyBox](https://arxiv.org/abs/2602.05441)
*Dean Fortier,Timothy Adamson,Tess Hellebrekers,Teresa LaScala,Kofi Ennin,Michael Murray,Andrey Kolobov,Galen Mullins*

Main category: cs.RO

TL;DR: BusyBox 是一个新的物理基准，用于评估视觉语言行动模型在易操作性泛化方面的能力，提供了方便的构建方法和相关数据集。


<details>
  <summary>Details</summary>
Motivation: 随着研究人员对 VLA 模型的关注增加，需要一种系统性的工具来评估它们在处理未知对象时的能力，特别是可操作性的泛化能力。

Method: 通过构建可交换和旋转的模块，生成不同的 BusyBox 变体，评估 VLAs 的传达能力。

Result: 即使对于强大的开放权重 VLA 模型，如 $π_{0.5}$ 和 GR00T-N1.6，跨 BusyBox 变体的泛化仍然非常具有挑战性。

Conclusion: BusyBox 是一个实用的基准，旨在促进研究人员对 VLA 能力的评估和新实验的提出。

Abstract: Vision-Language-Action (VLA) models have been attracting the attention of researchers and practitioners thanks to their promise of generalization. Although single-task policies still offer competitive performance, VLAs are increasingly able to handle commands and environments unseen in their training set. While generalization in vision and language space is undoubtedly important for robust versatile behaviors, a key meta-skill VLAs need to possess is affordance generalization -- the ability to manipulate new objects with familiar physical features.
  In this work, we present BusyBox, a physical benchmark for systematic semi-automatic evaluation of VLAs' affordance generalization. BusyBox consists of 6 modules with switches, sliders, wires, buttons, a display, and a dial. The modules can be swapped and rotated to create a multitude of BusyBox variations with different visual appearances but the same set of affordances. We empirically demonstrate that generalization across BusyBox variants is highly challenging even for strong open-weights VLAs such as $π_{0.5}$ and GR00T-N1.6. To encourage the research community to evaluate their own VLAs on BusyBox and to propose new affordance generalization experiments, we have designed BusyBox to be easy to build in most robotics labs. We release the full set of CAD files for 3D-printing its parts as well as a bill of materials for (optionally) assembling its electronics. We also publish a dataset of language-annotated demonstrations that we collected using the common bimanual Mobile Aloha robot on the canonical BusyBox configuration. All of the released materials are available at https://microsoft.github.io/BusyBox.

</details>


### [13] [Ontology-Driven Robotic Specification Synthesis](https://arxiv.org/abs/2602.05456)
*Maksym Figat,Ryan M. Mackey,Michel D. Ingham*

Main category: cs.RO

TL;DR: 本文提出了一种名为RSTM2的方法，用于优化机器人系统工程，特别是在多机器人系统中，提升任务执行和资源管理的安全性与效果。


<details>
  <summary>Details</summary>
Motivation: 旨在填补高层目标和形式化可执行规范之间的鸿沟，提升机器人系统工程在安全和关键任务应用中的有效性。

Method: 采用分层的本体驱动方法，通过随机时序Petri网与资源结合，实现任务到模型的转换，并进行Monte Carlo模拟。

Result: 通过假设案例研究展示了RSTM2方法在不确定性下支持架构权衡、资源分配和性能分析的能力，并促进了解释性AI助手的应用。

Conclusion: 本方法对复杂多机器人系统（如NASA CADRE任务）具有重要应用价值，通过自适应资源管理实现更好的安全性和任务执行效果。

Abstract: This paper addresses robotic system engineering for safety- and mission-critical applications by bridging the gap between high-level objectives and formal, executable specifications. The proposed method, Robotic System Task to Model Transformation Methodology (RSTM2) is an ontology-driven, hierarchical approach using stochastic timed Petri nets with resources, enabling Monte Carlo simulations at mission, system, and subsystem levels. A hypothetical case study demonstrates how the RSTM2 method supports architectural trades, resource allocation, and performance analysis under uncertainty. Ontological concepts further enable explainable AI-based assistants, facilitating fully autonomous specification synthesis. The methodology offers particular benefits to complex multi-robot systems, such as the NASA CADRE mission, representing decentralized, resource-aware, and adaptive autonomous systems of the future.

</details>


### [14] [TaSA: Two-Phased Deep Predictive Learning of Tactile Sensory Attenuation for Improving In-Grasp Manipulation](https://arxiv.org/abs/2602.05468)
*Pranav Ponnivalavan,Satoshi Funabashi,Alexander Schmitz,Tetsuya Ogata,Shigeki Sugano*

Main category: cs.RO

TL;DR: 本研究提出了TaSA框架，通过学习自触动态，改进机器人对复杂操控任务的处理，提高了任务成功率。


<details>
  <summary>Details</summary>
Motivation: 人类能够进行复杂的手部操作，通过预测机制克服自我接触与外部接触的区分问题，而大多数现有方法忽略自接触，限制了机器人在现实场景下的适应性。

Method: 介绍了一种名为TaSA的两阶段深度预测学习框架，第一阶段学习自触动态，第二阶段将这一模型纳入运动学习，强调物体接触信号。

Result: 在一系列插入任务中，使用TaSA训练的策略比基线方法显著提高了成功率，显示出结构化触觉感知的重要性。

Conclusion: 通过引入TaSA框架，研究表明，自触知觉基于感官抑制的结构化触觉感知对灵巧的机器人操控至关重要。

Abstract: Humans can achieve diverse in-hand manipulations, such as object pinching and tool use, which often involve simultaneous contact between the object and multiple fingers. This is still an open issue for robotic hands because such dexterous manipulation requires distinguishing between tactile sensations generated by their self-contact and those arising from external contact. Otherwise, object/robot breakage happens due to contacts/collisions. Indeed, most approaches ignore self-contact altogether, by constraining motion to avoid/ignore self-tactile information during contact. While this reduces complexity, it also limits generalization to real-world scenarios where self-contact is inevitable. Humans overcome this challenge through self-touch perception, using predictive mechanisms that anticipate the tactile consequences of their own motion, through a principle called sensory attenuation, where the nervous system differentiates predictable self-touch signals, allowing novel object stimuli to stand out as relevant. Deriving from this, we introduce TaSA, a two-phased deep predictive learning framework. In the first phase, TaSA explicitly learns self-touch dynamics, modeling how a robot's own actions generate tactile feedback. In the second phase, this learned model is incorporated into the motion learning phase, to emphasize object contact signals during manipulation. We evaluate TaSA on a set of insertion tasks, which demand fine tactile discrimination: inserting a pencil lead into a mechanical pencil, inserting coins into a slot, and fixing a paper clip onto a sheet of paper, with various orientations, positions, and sizes. Across all tasks, policies trained with TaSA achieve significantly higher success rates than baseline methods, demonstrating that structured tactile perception with self-touch based on sensory attenuation is critical for dexterous robotic manipulation.

</details>


### [15] [DECO: Decoupled Multimodal Diffusion Transformer for Bimanual Dexterous Manipulation with a Plugin Tactile Adapter](https://arxiv.org/abs/2602.05513)
*Xukun Li,Yu Sun,Lei Zhang,Bosheng Huang,Yibo Peng,Yuan Meng,Haojun Jiang,Shaoxuan Xie,Guacai Yao,Alois Knoll,Zhenshan Bing,Xinlong Wang,Zhenguo Sun*

Main category: cs.RO

TL;DR: DECO是一个多模态解耦框架，通过自注意力机制和数据集DECO-50改善了机器人操作能力。


<details>
  <summary>Details</summary>
Motivation: 为了提高机器人在复杂环境中的操作能力，DECO框架旨在有效集成不同的输入模态（图像、动作、触觉信号等），并改善其自适应能力。

Method: DECO框架采用了基于DiT的策略，结合了多模态条件和自注意力机制，同时利用轻量化LoRA适配器进行调优。

Result: DECO及其配套的数据集DECO-50，为机器人操作提供了丰富的训练和评估数据，确保了政策的有效性和灵活性。

Conclusion: DECO框架通过多模态条件解耦和创新的自注意力机制改善了机器人操控性能，并生成了丰富的数据集以支持该政策的测试和改进。

Abstract: Overview of the Proposed DECO Framework.} DECO is a DiT-based policy that decouples multimodal conditioning. Image and action tokens interact via joint self attention, while proprioceptive states and optional conditions are injected through adaptive layer normalization. Tactile signals are injected via cross attention, while a lightweight LoRA-based adapter is used to efficiently fine-tune the pretrained policy. DECO is also accompanied by DECO-50, a bimanual dexterous manipulation dataset with tactile sensing, consisting of 4 scenarios and 28 sub-tasks, covering more than 50 hours of data, approximately 5 million frames, and 8,000 successful trajectories.

</details>


### [16] [Virtual-Tube-Based Cooperative Transport Control for Multi-UAV Systems in Constrained Environments](https://arxiv.org/abs/2602.05516)
*Runxiao Liu,Pengda Mao,Xiangli Le,Shuang Gu,Yapeng Chen,Quan Quan*

Main category: cs.RO

TL;DR: 本研究提出了一种新控制框架，利用虚拟管和耗散系统理论，实现了多无人机在复杂环境中的高效合作运输，具有良好的实用性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为了解决多无人机在障碍物丰富的环境中进行载重运输的挑战，以实现高效的协作和导航。

Method: 利用虚拟管理论和耗散系统理论，提出了一种新的控制框架，适用于多无人机在受限环境中的合作运输

Result: 通过仿真和户外实验验证了框架的有效性，并展示了其在大规模多无人机系统中的可扩展性。

Conclusion: 该框架在复杂环境中实现了高效的多无人机合作运输，并在实际应用中表现出强大的可行性和鲁棒性。

Abstract: This paper proposes a novel control framework for cooperative transportation of cable-suspended loads by multiple unmanned aerial vehicles (UAVs) operating in constrained environments. Leveraging virtual tube theory and principles from dissipative systems theory, the framework facilitates efficient multi-UAV collaboration for navigating obstacle-rich areas. The proposed framework offers several key advantages. (1) It achieves tension distribution and coordinated transportation within the UAV-cable-load system with low computational overhead, dynamically adapting UAV configurations based on obstacle layouts to facilitate efficient navigation. (2) By integrating dissipative systems theory, the framework ensures high stability and robustness, essential for complex multi-UAV operations. The effectiveness of the proposed approach is validated through extensive simulations, demonstrating its scalability for large-scale multi-UAV systems. Furthermore, the method is experimentally validated in outdoor scenarios, showcasing its practical feasibility and robustness under real-world conditions.

</details>


### [17] [VLN-Pilot: Large Vision-Language Model as an Autonomous Indoor Drone Operator](https://arxiv.org/abs/2602.05552)
*Bessie Dominguez-Dager,Sergio Suescun-Ferrandiz,Felix Escalona,Francisco Gomez-Donoso,Miguel Cazorla*

Main category: cs.RO

TL;DR: 本文介绍了VLN-Pilot，一个利用大规模视觉语言模型进行室内无人机导航的新框架，具有语言驱动的语义理解和视觉感知，验证了在复杂任务中的高成功率。


<details>
  <summary>Details</summary>
Motivation: 利用多模态推理能力，自动化无人机的室内导航任务，特别是在缺乏GPS的环境中。

Method: 通过将语言驱动的语义理解与视觉感知相结合，支持无人机在室内环境中的自主导航。

Result: 在复杂的指令跟随任务中展现出较高的成功率，包括多语义目标的长时间导航。

Conclusion: VLLM驱动的无人机飞行员可以大幅减少操作员工作负担，同时提高安全性和任务灵活性。

Abstract: This paper introduces VLN-Pilot, a novel framework in which a large Vision-and-Language Model (VLLM) assumes the role of a human pilot for indoor drone navigation. By leveraging the multimodal reasoning abilities of VLLMs, VLN-Pilot interprets free-form natural language instructions and grounds them in visual observations to plan and execute drone trajectories in GPS-denied indoor environments. Unlike traditional rule-based or geometric path-planning approaches, our framework integrates language-driven semantic understanding with visual perception, enabling context-aware, high-level flight behaviors with minimal task-specific engineering. VLN-Pilot supports fully autonomous instruction-following for drones by reasoning about spatial relationships, obstacle avoidance, and dynamic reactivity to unforeseen events. We validate our framework on a custom photorealistic indoor simulation benchmark and demonstrate the ability of the VLLM-driven agent to achieve high success rates on complex instruction-following tasks, including long-horizon navigation with multiple semantic targets. Experimental results highlight the promise of replacing remote drone pilots with a language-guided autonomous agent, opening avenues for scalable, human-friendly control of indoor UAVs in tasks such as inspection, search-and-rescue, and facility monitoring. Our results suggest that VLLM-based pilots may dramatically reduce operator workload while improving safety and mission flexibility in constrained indoor environments.

</details>


### [18] [TOLEBI: Learning Fault-Tolerant Bipedal Locomotion via Online Status Estimation and Fallibility Rewards](https://arxiv.org/abs/2602.05596)
*Hokyun Lee,Woo-Jeong Baek,Junhyeok Cha,Jaeheung Park*

Main category: cs.RO

TL;DR: TOLEBI是一个针对双足运动的故障容忍学习框架，能够处理在运动过程中出现的硬件故障，支持在线状态监测，并通过一系列实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 尽管近年来在双足运动任务中取得了高成功率的成果，但对处理运动过程中的硬件故障的方法研究较少，实际环境中的干扰或硬件故障可能导致严重后果，因此需要开发相应的方法。

Method: 通过在仿真中注入关节锁定、电力损失和外部干扰，TOLEBI学习故障容忍的运动策略，并将学习到的策略通过仿真到现实的转移到实际机器人上，同时集成了在线关节状态模块以实时监测关节状态。

Result: 通过实验证明了TOLEBI在现实和仿真环境中的有效性，特别是在处理运动中的故障时表现出色。

Conclusion: 本论文提出的TOLEBI框架是首个基于学习的行走故障容忍框架，推动了双足运动领域高效学习方法的发展。

Abstract: With the growing employment of learning algorithms in robotic applications, research on reinforcement learning for bipedal locomotion has become a central topic for humanoid robotics. While recently published contributions achieve high success rates in locomotion tasks, scarce attention has been devoted to the development of methods that enable to handle hardware faults that may occur during the locomotion process. However, in real-world settings, environmental disturbances or sudden occurrences of hardware faults might yield severe consequences. To address these issues, this paper presents TOLEBI (A faulT-tOlerant Learning framEwork for Bipedal locomotIon) that handles faults on the robot during operation. Specifically, joint locking, power loss and external disturbances are injected in simulation to learn fault-tolerant locomotion strategies. In addition to transferring the learned policy to the real robot via sim-to-real transfer, an online joint status module incorporated. This module enables to classify joint conditions by referring to the actual observations at runtime under real-world conditions. The validation experiments conducted both in real-world and simulation with the humanoid robot TOCABI highlight the applicability of the proposed approach. To our knowledge, this manuscript provides the first learning-based fault-tolerant framework for bipedal locomotion, thereby fostering the development of efficient learning methods in this field.

</details>


### [19] [HiCrowd: Hierarchical Crowd Flow Alignment for Dense Human Environments](https://arxiv.org/abs/2602.05608)
*Yufei Zhu,Shih-Min Yang,Martin Magnusson,Allan Wang*

Main category: cs.RO

TL;DR: HiCrowd是一种新框架，通过强化学习和模型预测控制提升机器人在拥挤人群中的导航能力，显著提高效率和安全性，减少卡壳现象。


<details>
  <summary>Details</summary>
Motivation: 解决移动机器人在密集人群中导航的挑战，特别是机器人卡壳问题。

Method: 提出了一种层次化框架HiCrowd，结合了强化学习（RL）与模型预测控制（MPC），通过周围行人的运动数据提供指导。

Result: HiCrowd在离线和在线实验设置中均显示出出色的性能，尤其是在导航效率和安全性方面。

Conclusion: HiCrowd框架在导航效率和安全性方面优于其他基线方法，同时减少了机器人在拥挤人群中的卡壳行为。

Abstract: Navigating through dense human crowds remains a significant challenge for mobile robots. A key issue is the freezing robot problem, where the robot struggles to find safe motions and becomes stuck within the crowd. To address this, we propose HiCrowd, a hierarchical framework that integrates reinforcement learning (RL) with model predictive control (MPC). HiCrowd leverages surrounding pedestrian motion as guidance, enabling the robot to align with compatible crowd flows. A high-level RL policy generates a follow point to align the robot with a suitable pedestrian group, while a low-level MPC safely tracks this guidance with short horizon planning. The method combines long-term crowd aware decision making with safe short-term execution. We evaluate HiCrowd against reactive and learning-based baselines in offline setting (replaying recorded human trajectories) and online setting (human trajectories are updated to react to the robot in simulation). Experiments on a real-world dataset and a synthetic crowd dataset show that our method outperforms in navigation efficiency and safety, while reducing freezing behaviors. Our results suggest that leveraging human motion as guidance, rather than treating humans solely as dynamic obstacles, provides a powerful principle for safe and efficient robot navigation in crowds.

</details>


### [20] [From Vision to Decision: Neuromorphic Control for Autonomous Navigation and Tracking](https://arxiv.org/abs/2602.05683)
*Chuwei Wang,Eduardo Sebastián,Amanda Prorok,Anastasia Bizyaeva*

Main category: cs.RO

TL;DR: 提出了一种神经形态控制框架，解决了机器人导航中的决策不确定性问题，实现了实时自主控制与简单参数设置。


<details>
  <summary>Details</summary>
Motivation: 解决反应性控制与模型规划能力之间的矛盾，特别是在目标不明显时造成的决策困难。

Method: 采用简约的神经形态控制框架，利用环境几何动态分岔机制来延迟决策，直接将视觉目标激励转化为自我中心运动指令。

Result: 通过来自机载摄像头的图像像素编码，成功实现了决策延迟机制，并在模拟环境和实验四旋翼平台上验证了方法。

Conclusion: 提出的神经形态控制框架在视觉引导导航与跟踪中有效解决了反应性系统与基于模型的规划之间的矛盾，具备实时自主决策能力，并且计算负担小。

Abstract: Robotic navigation has historically struggled to reconcile reactive, sensor-based control with the decisive capabilities of model-based planners. This duality becomes critical when the absence of a predominant option among goals leads to indecision, challenging reactive systems to break symmetries without computationally-intense planners. We propose a parsimonious neuromorphic control framework that bridges this gap for vision-guided navigation and tracking. Image pixels from an onboard camera are encoded as inputs to dynamic neuronal populations that directly transform visual target excitation into egocentric motion commands. A dynamic bifurcation mechanism resolves indecision by delaying commitment until a critical point induced by the environmental geometry. Inspired by recently proposed mechanistic models of animal cognition and opinion dynamics, the neuromorphic controller provides real-time autonomy with a minimal computational burden, a small number of interpretable parameters, and can be seamlessly integrated with application-specific image processing pipelines. We validate our approach in simulation environments as well as on an experimental quadrotor platform.

</details>


### [21] [Task-Oriented Robot-Human Handovers on Legged Manipulators](https://arxiv.org/abs/2602.05760)
*Andreea Tulbure,Carmen Scheidemann,Elias Steiner,Marco Hutter*

Main category: cs.RO

TL;DR: 本研究提出了AFT-Handover框架，通过结合LLM驱动的推理和纹理转移，实现了更高效的人机交接，显著提高了泛化能力和成功率。


<details>
  <summary>Details</summary>
Motivation: 现有的交接方法通常局限于特定的对象或任务，而其在新场景中的泛化能力有限，因此需要一种新的方法来提升人机协作中的交接效率。

Method: 通过大型语言模型（LLM）驱动的可供性推理和基于纹理的高效可供性转移，AFT-Handover实现了零样本的可泛化任务导向交接。

Result: AFT-Handover在多样化的任务-对象组合上进行了评估，展示出比基线方法更高的交接成功率和更强的泛化能力。

Conclusion: AFT-Handover框架显著提升了任务导向交接的成功率和泛化能力，并且在用户研究中表现优于现有最先进的方法。

Abstract: Task-oriented handovers (TOH) are fundamental to effective human-robot collaboration, requiring robots to present objects in a way that supports the human's intended post-handover use. Existing approaches are typically based on object- or task-specific affordances, but their ability to generalize to novel scenarios is limited. To address this gap, we present AFT-Handover, a framework that integrates large language model (LLM)-driven affordance reasoning with efficient texture-based affordance transfer to achieve zero-shot, generalizable TOH. Given a novel object-task pair, the method retrieves a proxy exemplar from a database, establishes part-level correspondences via LLM reasoning, and texturizes affordances for feature-based point cloud transfer. We evaluate AFT-Handover across diverse task-object pairs, showing improved handover success rates and stronger generalization compared to baselines. In a comparative user study, our framework is significantly preferred over the current state-of-the-art, effectively reducing human regrasping before tool use. Finally, we demonstrate TOH on legged manipulators, highlighting the potential of our framework for real-world robot-human handovers.

</details>


### [22] [Scalable and General Whole-Body Control for Cross-Humanoid Locomotion](https://arxiv.org/abs/2602.05791)
*Yufei Xue,YunFeng Lin,Wentao Dong,Yang Tang,Jingbo Wang,Jiangmiao Pang,Ming Zhou,Minghuan Liu,Weinan Zhang*

Main category: cs.RO

TL;DR: 该论文研究了跨形体人形控制的问题，提出了XHugWBC框架，使得单一控制策略能够在多种人形机器人上进行有效控制，无需特定机器人训练。


<details>
  <summary>Details</summary>
Motivation: 解决现有学习型全身控制器需要特定机器人的训练问题，研究跨形体的通用控制能力。

Method: 提出了XHugWBC框架，通过物理一致的形态随机化、语义对齐的观察和动作空间及有效的策略架构来实现跨形体控制。

Result: 在12个模拟人类机器人和7个真实世界机器人上进行的实验表明，该通用控制器具有良好的泛化和鲁棒性。

Conclusion: XHugWBC能够在多种人形机器人上实现强大的泛化能力和鲁棒性，并且能够在未见过的机器人上也能有效控制。

Abstract: Learning-based whole-body controllers have become a key driver for humanoid robots, yet most existing approaches require robot-specific training. In this paper, we study the problem of cross-embodiment humanoid control and show that a single policy can robustly generalize across a wide range of humanoid robot designs with one-time training. We introduce XHugWBC, a novel cross-embodiment training framework that enables generalist humanoid control through: (1) physics-consistent morphological randomization, (2) semantically aligned observation and action spaces across diverse humanoid robots, and (3) effective policy architectures modeling morphological and dynamical properties. XHugWBC is not tied to any specific robot. Instead, it internalizes a broad distribution of morphological and dynamical characteristics during training. By learning motion priors from diverse randomized embodiments, the policy acquires a strong structural bias that supports zero-shot transfer to previously unseen robots. Experiments on twelve simulated humanoids and seven real-world robots demonstrate the strong generalization and robustness of the resulting universal controller.

</details>


### [23] [A Hybrid Autoencoder for Robust Heightmap Generation from Fused Lidar and Depth Data for Humanoid Robot Locomotion](https://arxiv.org/abs/2602.05855)
*Dennis Bank,Joost Cordes,Thomas Seel,Simon F. G. Ehlers*

Main category: cs.RO

TL;DR: 本文提出一种基于学习的框架，通过多模态融合提高人形机器人在非结构化环境中的地形感知能力，显著提升了重建精度并降低地图漂移。


<details>
  <summary>Details</summary>
Motivation: 提高人形机器人在非结构化人类环境中的地形感知能力，克服传统系统的局限性。

Method: 提出了一个混合编码-解码结构（EDS），使用卷积神经网络（CNN）进行空间特征提取，并结合门控递归单元（GRU）核心以保持时间一致性。

Result: 多模态融合在重建精度上分别比仅深度和仅激光雷达配置提高了7.2%和9.9%。

Conclusion: 多模态融合提高了重建精度，并且通过整合时间上下文降低了地图漂移现象。

Abstract: Reliable terrain perception is a critical prerequisite for the deployment of humanoid robots in unstructured, human-centric environments. While traditional systems often rely on manually engineered, single-sensor pipelines, this paper presents a learning-based framework that uses an intermediate, robot-centric heightmap representation. A hybrid Encoder-Decoder Structure (EDS) is introduced, utilizing a Convolutional Neural Network (CNN) for spatial feature extraction fused with a Gated Recurrent Unit (GRU) core for temporal consistency. The architecture integrates multimodal data from an Intel RealSense depth camera, a LIVOX MID-360 LiDAR processed via efficient spherical projection, and an onboard IMU. Quantitative results demonstrate that multimodal fusion improves reconstruction accuracy by 7.2% over depth-only and 9.9% over LiDAR-only configurations. Furthermore, the integration of a 3.2 s temporal context reduces mapping drift.

</details>


### [24] [Residual Reinforcement Learning for Waste-Container Lifting Using Large-Scale Cranes with Underactuated Tools](https://arxiv.org/abs/2602.05895)
*Qi Li,Karsten Berns*

Main category: cs.RO

TL;DR: 本论文提出了一种结合名义控制器和学习的残余策略的残余强化学习方法，提高了废物容器回收任务的轨迹跟踪精度和提升成功率。


<details>
  <summary>Details</summary>
Motivation: 在城市环境中进行废物容器回收任务时，提升容器阶段具有严格的几何公差，因此精确的轨迹跟踪和摆动抑制至关重要。

Method: 提出了一种残余强化学习（RRL）方法，结合了名义笛卡尔控制器和学习的残余策略，并使用拟合控制、阻尼最小二乘逆运动学等技术。

Result: 通过使用PPO训练的残余策略，通过补偿未建模的动态和参数变化，改进了精度和鲁棒性，同时增强了通用性。

Conclusion: 仿真结果表明该方法比单独使用名义控制器具有更好的轨迹跟踪精度、减少了摆动，并提高了提升成功率。

Abstract: This paper studies the container lifting phase of a waste-container recycling task in urban environments, performed by a hydraulic loader crane equipped with an underactuated discharge unit, and proposes a residual reinforcement learning (RRL) approach that combines a nominal Cartesian controller with a learned residual policy. All experiments are conducted in simulation, where the task is characterized by tight geometric tolerances between the discharge-unit hooks and the container rings relative to the overall crane scale, making precise trajectory tracking and swing suppression essential. The nominal controller uses admittance control for trajectory tracking and pendulum-aware swing damping, followed by damped least-squares inverse kinematics with a nullspace posture term to generate joint velocity commands. A PPO-trained residual policy in Isaac Lab compensates for unmodeled dynamics and parameter variations, improving precision and robustness without requiring end-to-end learning from scratch. We further employ randomized episode initialization and domain randomization over payload properties, actuator gains, and passive joint parameters to enhance generalization. Simulation results demonstrate improved tracking accuracy, reduced oscillations, and higher lifting success rates compared to the nominal controller alone.

</details>


### [25] [From Bench to Flight: Translating Drone Impact Tests into Operational Safety Limits](https://arxiv.org/abs/2602.05922)
*Aziz Mohamed Mili,Louis Catar,Paul Gérard,Ilyass Tabiai,David St-Onge*

Main category: cs.RO

TL;DR: 提出一种工具链，将冲击测试结果转化为无人机的安全限制，确保室内微型飞行器在靠近人类时的安全性。


<details>
  <summary>Details</summary>
Motivation: 室内微型飞行器用于接近人类的任务，但缺乏基于实际影响风险调节运动限制的方法。

Method: 通过构建一个压缩且可复制的冲击设备，结合数据驱动模型，计算速度限制，并提供在线实施的脚本和ROS2节点。

Result: 研究验证了该工作流程在多款商业四旋翼无人机和典型室内资产上的有效性，确保任务通过率的同时满足安全约束。

Conclusion: 我们的方法提供了一种从测量到实时限制的实用桥梁，使得室内微型飞行器能够安全地在人类附近操作。

Abstract: Indoor micro-aerial vehicles (MAVs) are increasingly used for tasks that require close proximity to people, yet practitioners lack practical methods to tune motion limits based on measured impact risk. We present an end-to-end, open toolchain that converts benchtop impact tests into deployable safety governors for drones. First, we describe a compact and replicable impact rig and protocol for capturing force-time profiles across drone classes and contact surfaces. Second, we provide data-driven models that map pre-impact speed to impulse and contact duration, enabling direct computation of speed bounds for a target force limit. Third, we release scripts and a ROS2 node that enforce these bounds online and log compliance, with support for facility-specific policies. We validate the workflow on multiple commercial off-the-shelf quadrotors and representative indoor assets, demonstrating that the derived governors preserve task throughput while meeting force constraints specified by safety stakeholders. Our contribution is a practical bridge from measured impacts to runtime limits, with shareable datasets, code, and a repeatable process that teams can adopt to certify indoor MAV operations near humans.

</details>


### [26] [Visuo-Tactile World Models](https://arxiv.org/abs/2602.06001)
*Carolina Higuera,Sergio Arnaud,Byron Boots,Mustafa Mukadam,Francois Robert Hogan,Franziska Meier*

Main category: cs.RO

TL;DR: 引入多任务视觉-触觉世界模型(VT-WM)，提高机器人在接触任务中的性能，并在零-shot实验中展示了显著的成功率和适应能力。


<details>
  <summary>Details</summary>
Motivation: 为了更好地理解机器人与物体之间的接触互动，避免视觉模型在遮挡或模糊接触状态下的常见失败模式。

Method: 通过多任务学习的方式，引入了多模态的视觉-触觉世界模型(VT-WM)，并在一系列接触丰富的操控任务中进行训练。

Result: VT-WM在物理真实性的想象能力上提高了33%，在遵守运动定律方面提高了29%。实验表明触觉动态的基础能够转化为有效的规划能力。

Conclusion: VT-WM在零-shot真实机器人实验中实现了最高35%的成功率，并且在多步骤、接触丰富的任务中取得了显著提升，同时展示了其在新的任务中的适应能力和可靠的规划成功率。

Abstract: We introduce multi-task Visuo-Tactile World Models (VT-WM), which capture the physics of contact through touch reasoning. By complementing vision with tactile sensing, VT-WM better understands robot-object interactions in contact-rich tasks, avoiding common failure modes of vision-only models under occlusion or ambiguous contact states, such as objects disappearing, teleporting, or moving in ways that violate basic physics. Trained across a set of contact-rich manipulation tasks, VT-WM improves physical fidelity in imagination, achieving 33% better performance at maintaining object permanence and 29% better compliance with the laws of motion in autoregressive rollouts. Moreover, experiments show that grounding in contact dynamics also translates to planning. In zero-shot real-robot experiments, VT-WM achieves up to 35% higher success rates, with the largest gains in multi-step, contact-rich tasks. Finally, VT-WM demonstrates significant downstream versatility, effectively adapting its learned contact dynamics to a novel task and achieving reliable planning success with only a limited set of demonstrations.

</details>


### [27] [CommCP: Efficient Multi-Agent Coordination via LLM-Based Communication with Conformal Prediction](https://arxiv.org/abs/2602.06038)
*Xiaopan Zhang,Zejin Wang,Zhixu Li,Jianpeng Yao,Jiachen Li*

Main category: cs.RO

TL;DR: 本研究提出了一种新的去中心化通信框架CommCP，针对多机器人任务下的信息收集问题，显著提高了任务成功率与探索效率。


<details>
  <summary>Details</summary>
Motivation: 为了在自然语言指令下执行任务，机器人需要有效的信息收集与协调，尤其是在多机器人环境中。

Method: 提出了一种基于大型语言模型的去中心化通信框架CommCP，采用保形预测来校准生成消息。

Result: CommCP在多代理多任务的环境下，通过减少接收者分心，增强通信可靠性，从而提高了任务执行效率。

Conclusion: CommCP显著提高了任务成功率和探索效率，证明了其在多机器人多任务环境中的有效性。

Abstract: To complete assignments provided by humans in natural language, robots must interpret commands, generate and answer relevant questions for scene understanding, and manipulate target objects. Real-world deployments often require multiple heterogeneous robots with different manipulation capabilities to handle different assignments cooperatively. Beyond the need for specialized manipulation skills, effective information gathering is important in completing these assignments. To address this component of the problem, we formalize the information-gathering process in a fully cooperative setting as an underexplored multi-agent multi-task Embodied Question Answering (MM-EQA) problem, which is a novel extension of canonical Embodied Question Answering (EQA), where effective communication is crucial for coordinating efforts without redundancy. To address this problem, we propose CommCP, a novel LLM-based decentralized communication framework designed for MM-EQA. Our framework employs conformal prediction to calibrate the generated messages, thereby minimizing receiver distractions and enhancing communication reliability. To evaluate our framework, we introduce an MM-EQA benchmark featuring diverse, photo-realistic household scenarios with embodied questions. Experimental results demonstrate that CommCP significantly enhances the task success rate and exploration efficiency over baselines. The experiment videos, code, and dataset are available on our project website: https://comm-cp.github.io.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [28] [Applying Ground Robot Fleets in Urban Search: Understanding Professionals' Operational Challenges and Design Opportunities](https://arxiv.org/abs/2602.04992)
*Puqi Zhou,Charles R. Twardy,Cynthia Lum,Myeong Lee,David J. Porfirio,Michael R. Hieb,Chris Thomas,Xuesu Xiao,Sungsoo Ray Hong*

Main category: cs.HC

TL;DR: 本文探讨地面机器人在城市搜索中的潜在应用，通过与警察的焦点小组讨论，提出了机器人集成的设计机会和需求。


<details>
  <summary>Details</summary>
Motivation: 随着科技的进步，地面机器人与计算机视觉及LLM驱动的接口可以减轻城市搜索中公共安全专业人士的操作负担，但缺乏对这些技术的接受度和整合的研究。

Method: 通过与来自维吉尼亚州五个地方部门的八名警察进行焦点小组讨论，获取数据和见解。

Result: 研究发现，地面机器人能降低专业人士对纸质参考材料和临时协调的依赖，减轻在四个关键挑战领域的认知和身体负担。

Conclusion: 本文探讨了未来公共安全操作中地面机器人队伍整合的设计启示，强调了需求可扩展的多机器人规划接口，以及增强行动信任和减少认知负担的设计要求。

Abstract: Urban searches demand rapid, defensible decisions and sustained physical effort under high cognitive and situational load. Incident commanders must plan, coordinate, and document time-critical operations, while field searchers execute evolving tasks in uncertain environments. With recent advances in technology, ground-robot fleets paired with computer-vision-based situational awareness and LLM-powered interfaces offer the potential to ease these operational burdens. However, no dedicated studies have examined how public safety professionals perceive such technologies or envision their integration into existing practices, risking building technically sophisticated yet impractical solutions. To address this gap, we conducted focus-group sessions with eight police officers across five local departments in Virginia. Our findings show that ground robots could reduce professionals' reliance on paper references, mental calculations, and ad-hoc coordination, alleviating cognitive and physical strain in four key challenge areas: (1) partitioning the workforce across multiple search hypotheses, (2) retaining group awareness and situational awareness, (3) building route planning that fits the lost-person profile, and (4) managing cognitive and physical fatigue under uncertainty. We further identify four design opportunities and requirements for future ground-robot fleet integration in public-safety operations: (1) scalable multi-robot planning and control interfaces, (2) agency-specific route optimization, (3) real-time replanning informed by debrief updates, and (4) vision-assisted cueing that preserves operational trust while reducing cognitive workload. We conclude with design implications for deployable, accountable, and human-centered urban-search support systems

</details>


### [29] [From Fragmentation to Integration: Exploring the Design Space of AI Agents for Human-as-the-Unit Privacy Management](https://arxiv.org/abs/2602.05016)
*Eryue Xu,Tianshi Li*

Main category: cs.HC

TL;DR: 本研究探讨了用户在数字足迹管理中的隐私挑战，提出AI代理作为解决方案以提高隐私管理的效率和有效性。


<details>
  <summary>Details</summary>
Motivation: 面对数字足迹管理的复杂性及用户在多平台上面临的隐私挑战，探索利用AI提供上下文敏感的隐私增强解决方案。

Method: 通过12次半结构访谈探索用户的跨上下文隐私挑战，并通过速度约会调查评估了九个AI代理概念。

Result: 研究确定了九个隐私管理挑战，并提出了九个AI代理概念，特别是后分享管理工具受到了用户的高度认可。

Conclusion: 研究结果表明，用户对AI的准确性表现出更大的信任，期望AI代理能够自动、全面地修复数字足迹，改善隐私管理体验。

Abstract: Managing one's digital footprint is overwhelming, as it spans multiple platforms and involves countless context-dependent decisions. Recent advances in agentic AI offer ways forward by enabling holistic, contextual privacy-enhancing solutions. Building on this potential, we adopted a ''human-as-the-unit'' perspective and investigated users' cross-context privacy challenges through 12 semi-structured interviews. Results reveal that people rely on ad hoc manual strategies while lacking comprehensive privacy controls, highlighting nine privacy-management challenges across applications, temporal contexts, and relationships. To explore solutions, we generated nine AI agent concepts and evaluated them via a speed-dating survey with 116 US participants. The three highest-ranked concepts were all post-sharing management tools with half or full agent autonomy, with users expressing greater trust in AI accuracy than in their own efforts. Our findings highlight a promising design space where users see AI agents bridging the fragments in privacy management, particularly through automated, comprehensive post-sharing remediation of users' digital footprints.

</details>


### [30] [A Design Space for Live Music Agents](https://arxiv.org/abs/2602.05064)
*Yewon Kim,Stephen Brade,Alexander Wang,David Zhou,Haven Kim,Bill Wang,Sung-Ju Lee,Hugo F Flores Garcia,Cheng-Zhi Anna Huang,Chris Donahue*

Main category: cs.HC

TL;DR: 本研究分析了184个现场音乐代理系统，建立了一个综合设计空间，以促进研究者、设计师和音乐家之间的有效沟通和协作。


<details>
  <summary>Details</summary>
Motivation: 现场音乐因其自发性为研究创造力和互动提供了独特的环境，研究实时音乐代理的智能系统支持这一过程，然而，跨学科的特性导致了研究社区的发展碎片化。

Method: 我们分析了184个系统，结合不同领域的观点，建立了一个综合设计空间，分类维度涵盖使用情境、交互、技术和生态系统。

Result: 通过我们的设计空间，我们突出了现场音乐代理的趋势和缺口，进而促进各领域之间的有效沟通和协作进展。

Conclusion: 我们的设计空间为研究者、设计师和音乐家提供了一个结构化的视角，以理解现有系统并塑造未来的实时人机音乐共创方向。

Abstract: Live music provides a uniquely rich setting for studying creativity and interaction due to its spontaneous nature. The pursuit of live music agents--intelligent systems supporting real-time music performance and interaction--has captivated researchers across HCI, AI, and computer music for decades, and recent advancements in AI suggest unprecedented opportunities to evolve their design. However, the interdisciplinary nature of music has led to fragmented development across research communities, hindering effective communication and collaborative progress. In this work, we bring together perspectives from these diverse fields to map the current landscape of live music agents. Based on our analysis of 184 systems across both academic literature and video, we develop a comprehensive design space that categorizes dimensions spanning usage contexts, interactions, technologies, and ecosystems. By highlighting trends and gaps in live music agents, our design space offers researchers, designers, and musicians a structured lens to understand existing systems and shape future directions in real-time human-AI music co-creation. We release our annotated systems as a living artifact at https://live-music-agents.github.io.

</details>


### [31] [VR Calm Plus: Coupling a Squeezable Tangible Interaction with Immersive VR for Stress Regulation](https://arxiv.org/abs/2602.05093)
*He Zhang,Xinyang Li,Xingyu Zhou,Xinyi Fu*

Main category: cs.HC

TL;DR: 本研究提出VR Calm Plus，通过结合触觉输入提升VR在压力管理中的应用，初步结果显示其能增强放松与积极情感。


<details>
  <summary>Details</summary>
Motivation: 大多数虚拟现实应用依赖于音频和视觉刺激，但忽视了挤压参与的治疗潜力，因此我们提出了VR Calm Plus，集成压力敏感毛绒玩具和互动VR环境。

Method: 本研究利用PANAS-X问卷、主观问卷、生理指标（心率、皮肤电导、脉率变异性）及半结构化访谈评估系统的有效性。

Result: 与仅视觉的基线相比，基于挤压的交互显著增强了积极情感和感知的放松，同时生理数据揭示了更大的心率减少和保持自主灵活性的'主动放松'状态。

Conclusion: 通过将可触摸的输入与沉浸式环境相结合，我们的研究强调了该方法对情感幸福感的支持价值，并为未来基于VR的心理健康工具提供了设计见解。

Abstract: While Virtual Reality (VR) is increasingly employed for stress management, most applications rely heavily on audio-visual stimuli and overlook the therapeutic potential of squeezing engagement. To address this gap, we introduce VR Calm Plus, a multimodal system that integrates a pressure-sensitive plush toy into an interactive VR environment. This interface allows users to dynamically modulate the virtual atmosphere through physical squeezing actions, fostering a deeper sense of embodied relaxation. We evaluated the system with 40 participants using PANAS-X surveys, subjective questionnaires, physiological measures (heart rate, skin conductance, pulse rate variability), and semi-structured interviews. Results demonstrate that, compared to a visual-only baseline, squeeze-based interaction significantly enhances positive affect and perceived relaxation. Physiological data further revealed a state of "active relaxation", characterized by greater reductions in heart rate and preserved autonomic flexibility (PRV), alongside sustained emotional engagement (GSR). Our findings highlight the value of coupling tangible input with immersive environments to support emotional well-being and offer design insights for future VR-based mental health tools.

</details>


### [32] [Metacognitive Demands and Strategies While Using Off-The-Shelf AI Conversational Agents for Health Information](https://arxiv.org/abs/2602.05111)
*Shri Harini Ramesh,Foroozan Daneshzand,Babak Rashidi,Shriti Raj,Hariharan Subramonyam,Fateme Rajabiyazdi*

Main category: cs.HC

TL;DR: 本研究探讨了AI对话代理在健康信息检索中的元认知负担，识别应对策略，并提出了设计改进建议。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能对话代理的普及，人们越来越多地使用它们搜索健康信息，但可能会增加个体的元认知负担。

Method: 进行了一项思维大声实验，邀请15名参与者使用我们的AI对话代理进行健康信息检索。

Result: 识别了使用此类系统时产生的元认知需求和人们应对这些需求的策略。

Conclusion: 提出了设计能减少认知负担并改善用户体验的建议。

Abstract: As Artificial Intelligence (AI) conversational agents become widespread, people are increasingly using them for health information seeking. The use of off-the-shelf conversational agents for health information seeking could place high metacognitive demands (the need for extensive monitoring and control of one's own thought process) on individuals, which could compromise their experience of seeking health information. However, currently, the specific demands that arise while using conversational agents for health information seeking, and the strategies people use to cope with those demands, remain unknown. To address these gaps, we conducted a think-aloud study with 15 participants as they sought health information using our off-the-shelf AI conversational agent. We identified the metacognitive demands such systems impose, the strategies people adopt in response, and propose considerations for designing beyond off-the-shelf interfaces to reduce these demands and support better user experiences and affordances in health information seeking.

</details>


### [33] [Reporting and Reviewing LLM-Integrated Systems in HCI: Challenges and Considerations](https://arxiv.org/abs/2602.05128)
*Karla Felix Navarro,Eugene Syriani,Ian Arawjo*

Main category: cs.HC

TL;DR: HCI学者在报告和审查涉及LLM集成系统的论文时，需关注信任缺失、技术评估的重要性及HCI与ML/NLP社区的价值观差异，研究提供了一系列指导方针.


<details>
  <summary>Details</summary>
Motivation: 研究目的是分析HCI学者在报告和审查涉及大型语言模型（LLM）集成系统的论文时需考虑的因素，以及当前审查过程中所面临的挑战与矛盾。

Method: 通过对18位关于LLM集成系统论文的作者进行访谈，探讨他们在写作和审审中的经验与看法。

Result: 发现作者和审稿人之间的信任建立规范由于LLM行为的不确定性与围绕AI的夸大修辞而受到侵蚀，同时论文对LLM集成系统的审查标准存在怀疑和不一致性；提出建议包括技术评估、使用理由的阐明及对LLM存在感的降低。

Conclusion: 本研究提出了一套关于报告和审查与LLM集成系统相关论文的指导方针，帮助作者、审稿人及HCI社区更好地理解并应对相关挑战。

Abstract: What should HCI scholars consider when reporting and reviewing papers that involve LLM-integrated systems? We interview 18 authors of LLM-integrated system papers on their authoring and reviewing experiences. We find that norms of trust-building between authors and reviewers appear to be eroded by the uncertainty of LLM behavior and hyperbolic rhetoric surrounding AI. Authors perceive that reviewers apply uniquely skeptical and inconsistent standards towards papers that report LLM-integrated systems, and mitigate mistrust by adding technical evaluations, justifying usage, and de-emphasizing LLM presence. Authors' views challenge blanket directives to report all prompts and use open models, arguing that prompt reporting is context-dependent and justifying proprietary model usage despite ethical concerns. Finally, some tensions in peer review appear to stem from clashes between the norms and values of HCI and ML/NLP communities, particularly around what constitutes a contribution and an appropriate level of technical rigor. Based on our findings and additional feedback from six expert HCI researchers, we present a set of guidelines and considerations for authors, reviewers, and HCI communities around reporting and reviewing papers that involve LLM-integrated systems.

</details>


### [34] [Varifocal Displays Reduce the Impact of the Vergence-Accommodation Conflict on 3D Pointing Performance in Augmented Reality Systems](https://arxiv.org/abs/2602.05129)
*Xiaodan Hu,Monica Perusquía-Hernández,Mayra Donaji Barrera Machuca,Anil Ufuk Batmaz,Yan Zhang,Wolfgang Stuerzlinger,Kiyoshi Kiyokawa*

Main category: cs.HC

TL;DR: 本研究探讨了可变焦显示器在增强现实中对3D指向性能的影响，发现其整体表现优于固定焦点，且个体差异显著。


<details>
  <summary>Details</summary>
Motivation: 调查定制的可变焦显示器是否能改善增强现实中的3D指向性能，并缓解已知的凝视-调节冲突（VAC）对交互的影响。

Method: 进行了一项在被试内的实验研究，涉及24名参与者在可变焦和固定焦点视图下完成ISO 9241-411指向任务。

Result: 整体而言，可变焦视图的表现显著优于固定焦点基线。在不同个体中的收益幅度和方向有所不同，且在基线表现较好的参与者中观察到改善幅度较小或偶尔退步。

Conclusion: 可变焦技术相较于固定焦点视图，能够提高增强现实中的指向性能，但个体差异显著，设计和评估时需考虑这些差异。

Abstract: This paper investigates whether a custom varifocal display can improve 3D pointing performance in augmented reality (AR), where the vergence-accommodation conflict (VAC) is known to impair interaction. Varifocal displays have been hypothesized to alleviate the VAC by dynamically matching the focal distance to the user's gaze-defined target depth. Following prior work, we conducted a within-subject study with 24 participants performing an ISO 9241-411 pointing task under varifocal and fixed-focal viewing. Overall, varifocal viewing yielded significantly higher performance than the fixed-focal baseline across key interaction metrics, although the magnitude and even the direction of the benefit varied across individuals. In particular, participants' responses exhibited a baseline-dependent pattern, with smaller improvements (or occasional degradation) observed for those with better baseline performance. Our findings suggest that varifocal technology can improve AR pointing performance relative to fixed-focal viewing, while highlighting substantial individual differences that should be considered in design and evaluation.

</details>


### [35] [Co-Designing Collaborative Generative AI Tools for Freelancers](https://arxiv.org/abs/2602.05299)
*Kashif Imteyaz,Michael Muller,Claudia Flores-Saviaga,Saiph Savage*

Main category: cs.HC

TL;DR: 该论文探讨了设计生成AI工具以支持自由职业者的协作，强调要保护其创造代理和工作身份，提出了相关的设计建议。


<details>
  <summary>Details</summary>
Motivation: 现有的生成AI工具由于侧重个人生产力和个性化，未能有效支持自由职业者的协作，可能加剧其孤立感和不稳定性。

Method: 通过与27名自由职业者进行共创会议，探讨如何设计生成AI工具以支持自由职业者的协作。

Result: 发现自由职业者担心AI工具可能会侵犯其创造代理和工作身份，并提出支持创造性的“辅助AI”系统设计建议。

Conclusion: 本文提出了针对自由职业者的协作生成AI工具设计建议，以保护其创造代理和工作身份，并支持自由职业者主导的灵活合作。

Abstract: Most generative AI tools prioritize individual productivity and personalization, with limited support for collaboration. Designed for traditional workplaces, these tools do not fit freelancers' short-term teams or lack of shared institutional support, which can worsen their isolation and overlook freelancing platform dynamics. This mismatch means that, instead of empowering freelancers, current generative AI tools could reinforce existing precarity and make freelancer collaboration harder. To investigate how to design generative AI tools to support freelancer collaboration, we conducted co-design sessions with 27 freelancers. A key concern that emerged was the risk of AI systems compromising their creative agency and work identities when collaborating, especially when AI tools could reproduce content without attribution, threatening the authenticity and distinctiveness of their collaborative work. Freelancers proposed "auxiliary AI" systems, human-guided tools that support their creative agencies and identities, allowing for flexible freelancer-led collaborations that promote "productive friction". Drawing on Marcuse's concept of technological rationality, we argue that freelancers are resisting one-dimensional, efficiency-driven AI, and instead envisioning technologies that preserve their collective creative agencies. We conclude with design recommendations for collaborative generative AI tools for freelancers.

</details>


### [36] [DiLLS: Interactive Diagnosis of LLM-based Multi-agent Systems via Layered Summary of Agent Behaviors](https://arxiv.org/abs/2602.05446)
*Rui Sheng,Yukun Yang,Chuhan Shi,Yanna Lin,Zixin Chen,Huamin Qu,Furui Cheng*

Main category: cs.HC

TL;DR: 提出DiLLS框架，通过自然语言查询组织多智能体系统的信息，帮助开发者更高效地识别和理解故障。


<details>
  <summary>Details</summary>
Motivation: 为了应对多智能体系统中复杂的代理行为，帮助开发者更有效地识别故障的根本原因及改善路径。

Method: 通过构建一个交互式系统DiLLS，组织多代理系统的行为信息，分为活动、行动和操作三个层次，利用自然语言进行查询。

Result: 用户研究表明，DiLLS显著提升了开发者在处理故障时的效能与效率。

Conclusion: DiLLS显著提高了开发者在识别、诊断和理解基于大型语言模型的多智能体系统中的故障的效率和效果。

Abstract: Large language model (LLM)-based multi-agent systems have demonstrated impressive capabilities in handling complex tasks. However, the complexity of agentic behaviors makes these systems difficult to understand. When failures occur, developers often struggle to identify root causes and to determine actionable paths for improvement. Traditional methods that rely on inspecting raw log records are inefficient, given both the large volume and complexity of data. To address this challenge, we propose a framework and an interactive system, DiLLS, designed to reveal and structure the behaviors of multi-agent systems. The key idea is to organize information across three levels of query completion: activities, actions, and operations. By probing the multi-agent system through natural language, DiLLS derives and organizes information about planning and execution into a structured, multi-layered summary. Through a user study, we show that DiLLS significantly improves developers' effectiveness and efficiency in identifying, diagnosing, and understanding failures in LLM-based multi-agent systems.

</details>


### [37] [Relying on LLMs: Student Practices and Instructor Norms are Changing in Computer Science Education](https://arxiv.org/abs/2602.05506)
*Xinrui Lin,Heyan Huang,Shumin Shi,John Vines*

Main category: cs.HC

TL;DR: 研究分析了计算机科学学生与 LLM 的互动，指出了学生与教师之间的冲突和共识，并提出了 LLM 设计指南以减少依赖和促进学习。


<details>
  <summary>Details</summary>
Motivation: 探讨学生在高等教育中过度依赖大型语言模型 (LLM) 的问题。

Method: 通过对 16 名学生和 6 名教师的用户研究，分析了计算机科学学生和教师在五种情境下与 LLM 的互动。

Result: 发现学生实践与教师规范之间存在不同程度的冲突，以及教师对 LLM 使用的态度正逐渐从禁止转向认可。

Conclusion: 建议设计 LLM 以促进学生学习并减少过度依赖，尤其是在写作生成领域。

Abstract: Prior research has raised concerns about students' over-reliance on large language models (LLMs) in higher education. This paper examines how Computer Science students and instructors engage with LLMs across five scenarios: "Writing", "Quiz", "Programming", "Project-based learning", and "Information retrieval". Through user studies with 16 students and 6 instructors, we identify 7 key intents, including increasingly complex student practices. Findings reveal varying levels of conflict between student practices and instructor norms, ranging from clear conflict in "Writing-generation" and "(Programming) quiz-solving", through partial conflict in "Programming project-implementation" and "Project-based learning", to broad agreement in "Writing-revision & ideation", "(Programming) quiz-correction" and "Info-query & summary". We document instructors are shifting from prohibiting to recognizing students' use of LLMs for high-quality work, integrating usage records into assessment grading. Finally, we propose LLM design guidelines: deploying default guardrails with game-like and empathetic interaction to prevent students from "deserting" LLMs, especially for "Writing-generation", while utilizing comprehension checks in low-conflict intents to promote learning.

</details>


### [38] [Assessing Problem-Solving in HR Contexts: A Comparison Between Game-Based and Self-Report Measures](https://arxiv.org/abs/2602.05525)
*Fabrizio Fornari,Eleonora Cova,Niccolò Vito Vacca,Francesco Bocci,Luigi Caputo*

Main category: cs.HC

TL;DR: 本研究探索了自我报告和基于行为的问题解决能力之间的关系，发现两者缺乏一致性，强调多方法评估的重要性。


<details>
  <summary>Details</summary>
Motivation: 在招聘环境中，游戏化评估作为评估跨行技能的工具日益受到关注，但关于游戏化行为指标与传统自我报告测量之间的实证证据仍然有限。

Method: 采用方法比较的方法，比较了自我感知与行为表现的问题解决能力，使用了问题解决清单（PSI-B）和五分钟的游戏化问题解决任务。

Result: 结果显示自我报告得分与基于行为的问题解决得分之间没有显著的一致性，表明两种测量方式之间缺乏收敛性。

Conclusion: 自我报告与行为表现之间的测量方式缺乏一致性，但这并不意味着游戏化评估的有效性不足。这些发现支持自我报告和行为测量在问题解决能力评估中互为补充的观点，强调了在人员选择中依赖单一评估方式的风险。

Abstract: Game-based assessments (GBAs) are increasingly adopted in recruitment contexts as tools to assess transversal skills through observable behavior. However, empirical evidence directly comparing game-based behavioral indicators with traditional self-report measures remains limited. This study adopts a method-comparison approach to explore the convergence between self-perceived and behaviorally enacted problem-solving competence, comparing a game-based assessment with the Problem Solving Inventory (PSI-B).
  Seventy-eight participants completed both the PSI-B and a five-minute game-based problem-solving task, which classified performance into four behavioral proficiency levels. Results revealed no significant convergence between self-reported and behavior-based problem-solving scores, indicating a lack of convergence between the two measurement modalities.
  Rather than indicating a lack of validity of the game-based assessment, these findings support the view that self-report and behavioral measures provide complementary information about problem-solving competence. The study highlights the risks of relying on a single assessment modality in personnel selection and underscores the value of integrating game-based tools within multi-method assessment frameworks.

</details>


### [39] [AI chatbots versus human healthcare professionals: a systematic review and meta-analysis of empathy in patient care](https://arxiv.org/abs/2602.05628)
*Alastair Howcroft,Amber Bennett-Weston,Ahmad Khan,Joseff Griffiths,Simon Gay,Jeremy Howick*

Main category: cs.HC

TL;DR: 本研究发现，在文本场景中，AI聊天机器人被普遍认为具有更高的同理心，未来需要通过直接患者评估验证这些结果，并研究语音互动AI系统的同理心表现。


<details>
  <summary>Details</summary>
Motivation: 同理心对改善患者结果至关重要，而AI聊天机器人在医疗中的应用迅速增长，有研究表明其在同理心方面可能优于人类医疗专业人员。

Method: 对多个数据库中的研究进行了系统性检索，比较使用大型语言模型的AI聊天机器人与人类医疗专业人员在同理心测量上的表现，并使用随机效应元分析法进行数据合成。

Result: 从15项研究中获得的数据表明，13项研究显示AI的同理心评分显著高于人类，元分析结果显示标准化均值差异为0.87，表明AI在同理心上表现出色。

Conclusion: 在文本场景中，AI聊天机器人通常被认为比人类医疗专业人员更具同理心。

Abstract: Background: Empathy is widely recognized for improving patient outcomes, including reduced pain and anxiety and improved satisfaction, and its absence can cause harm. Meanwhile, use of artificial intelligence (AI)-based chatbots in healthcare is rapidly expanding, with one in five general practitioners using generative AI to assist with tasks such as writing letters. Some studies suggest AI chatbots can outperform human healthcare professionals (HCPs) in empathy, though findings are mixed and lack synthesis.
  Sources of data: We searched multiple databases for studies comparing AI chatbots using large language models with human HCPs on empathy measures. We assessed risk of bias with ROBINS-I and synthesized findings using random-effects meta-analysis where feasible, whilst avoiding double counting.
  Areas of agreement: We identified 15 studies (2023-2024). Thirteen studies reported statistically significantly higher empathy ratings for AI, with only two studies situated in dermatology favouring human responses. Of the 15 studies, 13 provided extractable data and were suitable for pooling. Meta-analysis of those 13 studies, all utilising ChatGPT-3.5/4, showed a standardized mean difference of 0.87 (95% CI, 0.54-1.20) favouring AI (P < .00001), roughly equivalent to a two-point increase on a 10-point scale.
  Areas of controversy: Studies relied on text-based assessments that overlook non-verbal cues and evaluated empathy through proxy raters.
  Growing points: Our findings indicate that, in text-only scenarios, AI chatbots are frequently perceived as more empathic than human HCPs.
  Areas timely for developing research: Future research should validate these findings with direct patient evaluations and assess whether emerging voice-enabled AI systems can deliver similar empathic advantages.

</details>


### [40] [Making AI Agents Evaluate Misleading Charts without Nudging](https://arxiv.org/abs/2602.05662)
*Swaroop Panda*

Main category: cs.HC

TL;DR: AI代理在评估图表时，即使存在缺陷也可能高估其美观性和可读性，除非明确要求其检查完整性问题。


<details>
  <summary>Details</summary>
Motivation: 探讨AI代理在早期可视化评估中的可靠性，特别是在面对有意设计缺陷的图表时的表现。

Method: 使用已确立的美学评价尺度（BeauVis和PREVis）评估包含图表杂乱、操控轴线和扭曲比例线索的可视化图表。

Result: 尽管图形完整性受到损害，AI代理对美学吸引力和可读性的评分通常仍保持较高，这表明缺乏明确引导时，代理可能不会关注完整性缺陷。

Conclusion: AI代理在没有提示的情况下，可能会低估与图表完整性相关的缺陷。

Abstract: AI agents are increasingly used as low-cost proxies for early visualization evaluation. In an initial study of deliberately flawed charts, we test whether agents spontaneously penalise chart junk and misleading encodings without being prompted to look for errors. Using established scales (BeauVis and PREVis), the agent evaluated visualizations containing decorative clutter, manipulated axes, and distorted proportional cues. The ratings of aesthetic appeal and perceived readability often remained relatively high even when graphical integrity was compromised. These results suggest that un-nudged AI agent evaluation may underweight integrity-related defects unless such checks are explicitly elicited.

</details>


### [41] [(Computer) Vision in Action: Comparing Remote Sighted Assistance and a Multimodal Voice Agent in Inspection Sequences](https://arxiv.org/abs/2602.05671)
*Damien Rudaz,Barbara Nino Carreras,Sara Merlino,Brian L. Due,Barry Brown*

Main category: cs.HC

TL;DR: 本研究比较了人类助手与多模态语音助手在执行任务时的表现，指出后者缺乏环境引发的视觉行为，影响其主动性。


<details>
  <summary>Details</summary>
Motivation: 从盲人和视力正常志愿者的专业知识中汲取经验，以指导多模态语音助手的设计，并解决主动性方面的挑战。

Method: 分析两个代表性片段，通过与经验丰富的人类远程视力助手和盲人参与者的合作进行比较。

Result: 通过比较人类助手与多模态语音助手在相同任务中的表现，明确指出了代理在积极主动的基本实践中未能实现的方面。

Conclusion: 多模态语音助手无法产生环境引发的基于视觉的行为，从而缺乏人类远程视力助手所依赖的重要资源。

Abstract: Does human-AI assistance unfold in the same way as human-human assistance? This research explores what can be learned from the expertise of blind individuals and sighted volunteers to inform the design of multimodal voice agents and address the enduring challenge of proactivity. Drawing on granular analysis of two representative fragments from a larger corpus, we contrast the practices co-produced by an experienced human remote sighted assistant and a blind participant-as they collaborate to find a stain on a blanket over the phone-with those achieved when the same participant worked with a multimodal voice agent on the same task, a few moments earlier. This comparison enables us to specify precisely which fundamental proactive practices the agent did not enact in situ. We conclude that, so long as multimodal voice agents cannot produce environmentally occasioned vision-based actions, they will lack a key resource relied upon by human remote sighted assistants.

</details>


### [42] [Exploring AI-Augmented Sensemaking of Patient-Generated Health Data: A Mixed-Method Study with Healthcare Professionals in Cardiac Risk Reduction](https://arxiv.org/abs/2602.05687)
*Pavithren V S Pakianathan,Rania Islambouli,Diogo Branco,Albrecht Schmidt,Tiago Guerreiro,Jan David Smeddinck*

Main category: cs.HC

TL;DR: 本研究探讨了大型语言模型如何支持患者生成健康数据的理解，提出了将AI驱动的摘要和对话整合到临床工作流程中的建议。


<details>
  <summary>Details</summary>
Motivation: 随着个人健康和生活方式数据的生成增加，如何有效整合这些数据以改善预防保健变得越来越重要。

Method: 通过混合方法研究，16名医疗保健专业人员评估了一个原型，该原型整合了常见图表、LLM生成的摘要和对话界面。

Result: AI生成的摘要提供了快速的概述，促进了灵活的分析，并帮助解决数据素养差距。

Conclusion: 人工智能生成的摘要和对话界面在支持患者生成健康数据的理解中展示了有效性，但也引发了对透明度和隐私的担忧。

Abstract: Individuals are increasingly generating substantial personal health and lifestyle data, e.g. through wearables and smartphones. While such data could transform preventative care, its integration into clinical practice is hindered by its scale, heterogeneity and the time pressure and data literacy of healthcare professionals (HCPs). We explore how large language models (LLMs) can support sensemaking of patient-generated health data (PGHD) with automated summaries and natural language data exploration. Using cardiovascular disease (CVD) risk reduction as a use case, 16 HCPs reviewed multimodal PGHD in a mixed-methods study with a prototype that integrated common charts, LLM-generated summaries, and a conversational interface. Findings show that AI summaries provided quick overviews that anchored exploration, while conversational interaction supported flexible analysis and bridged data-literacy gaps. However, HCPs raised concerns about transparency, privacy, and overreliance. We contribute empirical insights and sociotechnical design implications for integrating AI-driven summarization and conversation into clinical workflows to support PGHD sensemaking.

</details>


### [43] [Authorship Drift: How Self-Efficacy and Trust Evolve During LLM-Assisted Writing](https://arxiv.org/abs/2602.05819)
*Yeon Su Park,Nadia Azzahra Putri Arvi,Seoyoung Kim,Juho Kim*

Main category: cs.HC

TL;DR: 本研究探讨了在大型语言模型辅助写作中，用户自我效能感和信任的变化及其对作者身份的影响，发现需要关注如何支持自我效能感的维持，以促进人类与LLM的有效合作。


<details>
  <summary>Details</summary>
Motivation: 在大型语言模型的协作写作环境中探讨用户的自我效能感和信任的动态变化，以了解其对作者身份的影响。

Method: 通过对302名参与者的LLM辅助写作进行研究，收集互动日志和逐步的自我效能感及信任评级。

Result: 合作过程通常会降低用户的自我效能感，但提高信任度。失去自我效能感的参与者更倾向于请求LLM直接编辑他们的作品，而自我效能感恢复的参与者则请求更多的审阅和反馈。

Conclusion: 稳定的自我效能感与最终文本的实际和感知作者身份较高相关，因此在促进人类与大型语言模型（LLM）的合作过程中，需要关注用户自我效能感的变化。

Abstract: Large language models (LLMs) are increasingly used as collaborative partners in writing. However, this raises a critical challenge of authorship, as users and models jointly shape text across interaction turns. Understanding authorship in this context requires examining users' evolving internal states during collaboration, particularly self-efficacy and trust. Yet, the dynamics of these states and their associations with users' prompting strategies and authorship outcomes remain underexplored. We examined these dynamics through a study of 302 participants in LLM-assisted writing, capturing interaction logs and turn-by-turn self-efficacy and trust ratings. Our analysis showed that collaboration generally decreased users' self-efficacy while increasing trust. Participants who lost self-efficacy were more likely to ask the LLM to edit their work directly, whereas those who recovered self-efficacy requested more review and feedback. Furthermore, participants with stable self-efficacy showed higher actual and perceived authorship of the final text. Based on these findings, we propose design implications for understanding and supporting authorship in human-LLM collaboration.

</details>


### [44] [ToMigo: Interpretable Design Concept Graphs for Aligning Generative AI with Creative Intent](https://arxiv.org/abs/2602.05825)
*Lena Hegemann,Xinyi Wen,Michael A. Hedderich,Tarmo Nurmi,Hariharan Subramonyam*

Main category: cs.HC

TL;DR: ToMigo通过设计概念图帮助用户更好地表达和控制生成式人工智能的设计意图。


<details>
  <summary>Details</summary>
Motivation: 为了克服生成式人工智能与用户意图之间的错位，通过简单直接的输入理解和影响AI对用户意图的解释。

Method: 基于图形设计的用户研究，用于验证ToMigo的有效性，重点关注用户意图的捕捉和交互特性。

Result: ToMigo有效地推断用户意图，并提供了高等级的对齐评分，用户觉得控制感增强，且其互动功能对设计思路的演变和实现有帮助。

Conclusion: 用户对ToMigo的互动特性表示满意，认为可以更好地控制设计过程，并有效地表达设计意图。

Abstract: Generative AI often produces results misaligned with user intentions, for example, resolving ambiguous prompts in unexpected ways. Despite existing approaches to clarify intent, a major challenge remains: understanding and influencing AI's interpretation of user intent through simple, direct inputs requiring no expertise or rigid procedures. We present ToMigo, representing intent as design concept graphs: nodes represent choices of purpose, content, or style, while edges link them with interpretable explanations. Applied to graphic design, ToMigo infers intent from reference images and text. We derived a schema of node types and edges from pre-study data, informing a multimodal large language model to generate graphs aligning nodes externally with user intent and internally toward a unified design goal. This structure enables users to explore AI reasoning and directly manipulate the design concept. In our user studies, ToMigo received high alignment ratings and captured most user intentions well. Users reported greater control and found interactive features-editable graphs, reflective chats, concept-design realignment-useful for evolving and realizing their design ideas.

</details>


### [45] [Whispers of the Butterfly: A Research-through-Design Exploration of In-Situ Conversational AI Guidance in Large-Scale Outdoor MR Exhibitions](https://arxiv.org/abs/2602.05826)
*Dongyijie Primo Pan,Shuyue Li,Yawei Zhao,Junkun Long,Hao Li,Pan Hui*

Main category: cs.HC

TL;DR: 本研究探索了在大型户外MR艺术展览中引入AI导览员的效果与设计启示，发现AI导览可改善访客体验。


<details>
  <summary>Details</summary>
Motivation: 大型户外混合现实艺术展览中，传统导览方式无法有效扩展，探索体验往往变成了脚本化的导览，因此需要寻找创新的解决方案。

Method: 通过Research-through-Design方法，设计并部署了一个AI导览员，并进行了一项有24名参与者的田野实验，比较人类导览与AI导览的体验。

Result: 实验结果显示，AI导览提升了对于解释信息的获取、反应灵敏度和沉浸感，同时减少参与者的工作负担；并揭示了访客在导览过程中如何进行角色责任的交接。

Conclusion: 本文提出了一种新型的AI导览员Dream-Butterfly，通过对比人类导览与AI导览，展现了AI在大型户外混合现实展览中的独特优势和设计启示。

Abstract: Large-scale outdoor mixed reality (MR) art exhibitions distribute curated virtual works across open public spaces, but interpretation rarely scales without turning exploration into a scripted tour. Through Research-through-Design, we created Dream-Butterfly, an in-situ conversational AI docent embodied as a small non-human companion that visitors summon for multilingual, exhibition-grounded explanations. We deployed Dream-Butterfly in a large-scale outdoor MR exhibition at a public university campus in southern China, and conducted an in-the-wild between-subject study (N=24) comparing a primarily human-led tour with an AI-led tour while keeping staff for safety in both conditions. Combining questionnaires and semi-structured interviews, we characterize how shifting the primary explanation channel reshapes explanation access, perceived responsiveness, immersion, and workload, and how visitors negotiate responsibility handoffs among staff, the AI guide, and themselves. We distill transferable design implications for configuring mixed human-AI guiding roles and embodying conversational agents in mobile, safety-constrained outdoor MR exhibitions.

</details>


### [46] [Large Data Acquisition and Analytics at Synchrotron Radiation Facilities](https://arxiv.org/abs/2602.05837)
*Aashish Panta,Giorgio Scorzelli,Amy A. Gooch,Werner Sun,Katherine S. Shanks,Suchismita Sarker,Devin Bougie,Keara Soloway,Rolf Verberg,Tracy Berman,Glenn Tarcea,John Allison,Michela Taufer,Valerio Pascucci*

Main category: cs.HC

TL;DR: 本文介绍了一个新框架的设计和评估，该框架改善了CHESS的同步辐射数据采集和管理，提升了操作效率，支持远程监测和数据质量评估。


<details>
  <summary>Details</summary>
Motivation: 面对数据获取和管理挑战，包括有限的访问时间和数据管理需求，开发框架以提高操作效率。

Method: 设计、部署和评估了一个新的框架，用于同步辐射数据采集和管理，提供实时的远程实验监测与数据质量评估工具。

Result: 该框架在2024年底在三条光束线成功部署，管理了50-100 TB数据和超过1000万个文件，测试显示降低了开销，提高了可访问性。

Conclusion: 该框架显著提高了同步辐射数据采集的效率和可访问性，并成功管理了大量数据。

Abstract: Synchrotron facilities like the Cornell High Energy Synchrotron Source (CHESS) generate massive data volumes from complex beamline experiments, but face challenges such as limited access time, the need for on-site experiment monitoring, and managing terabytes of data per user group. We present the design, deployment, and evaluation of a framework that addresses CHESS's data acquisition and management issues. Deployed on a secure CHESS server, our system provides real time, web-based tools for remote experiment monitoring and data quality assessment, improving operational efficiency. Implemented across three beamlines (ID3A, ID3B, ID4B), the framework managed 50-100 TB of data and over 10 million files in late 2024. Testing with 43 research groups and 86 dashboards showed reduced overhead, improved accessibility, and streamlined data workflows. Our paper highlights the development, deployment, and evaluation of our framework and its transformative impact on synchrotron data acquisition.

</details>


### [47] [DuoDrama: Supporting Screenplay Refinement Through LLM-Assisted Human Reflection](https://arxiv.org/abs/2602.05854)
*Yuying Tang,Xinyi Chen,Haotian Li,Xing Xie,Xiaojuan Ma,Huamin Qu*

Main category: cs.HC

TL;DR: DuoDrama是一个AI系统，可以通过Experience-Grounded Feedback Generation Workflow（ExReflect）为编剧提供反思支持，研究显示其有效提升了反馈质量与反思深度。


<details>
  <summary>Details</summary>
Motivation: 现有AI工具无法协调角色内部视角和整个故事的外部视角，无法满足编剧的需求。

Method: 基于表演理论和对九位专业编剧的形成性研究，设计了体验为基础的反馈生成工作流程（ExReflect）。

Result: 一项针对十四位专业编剧的研究表明，DuoDrama改善了反馈质量和一致性，并增强了反思的有效性、深度和丰富性。

Conclusion: DuoDrama提升了反馈质量和一致性，增强了反思的有效性、深度和丰富性。

Abstract: AI has been increasingly integrated into screenwriting practice. In refinement, screenwriters expect AI to provide feedback that supports reflection across the internal perspective of characters and the external perspective of the overall story. However, existing AI tools cannot sufficiently coordinate the two perspectives to meet screenwriters' needs. To address this gap, we present DuoDrama, an AI system that generates feedback to assist screenwriters' reflection in refinement. To enable DuoDrama, based on performance theories and a formative study with nine professional screenwriters, we design the Experience-Grounded Feedback Generation Workflow for Human Reflection (ExReflect). In ExReflect, an AI agent adopts an experience role to generate experience and then shifts to an evaluation role to generate feedback based on the experience. A study with fourteen professional screenwriters shows that DuoDrama improves feedback quality and alignment and enhances the effectiveness, depth, and richness of reflection. We conclude by discussing broader implications and future directions.

</details>


### [48] ["It Talks Like a Patient, But Feels Different": Co-Designing AI Standardized Patients with Medical Learners](https://arxiv.org/abs/2602.05856)
*Zhiqi Gao,Guo Zhu,Huarui Luo,Dongyijie Primo Pan,Haoming Tang,Bingquan Zhang,Jiahuan Pei,Jie Li,Benyou Wang*

Main category: cs.HC

TL;DR: 研究发现，AI-SP可以作为有目的的练习工具，通过关注教学可用性而非单纯的对话真实性，提高学习者的信任度和参与感。


<details>
  <summary>Details</summary>
Motivation: 探讨传统标准化患者的高成本和不一致性，以及学习者对AI标准化患者的不同感受。

Method: 通过对12名临床年的医学学生进行访谈和三次共同设计研讨会，探讨学生对标准化患者(SP)遭遇中的限制以及他们对AI-SP的期望。

Result: 识别出六个以学习者为中心的需求，并将其转化为AI-SP设计要求，最终形成一个概念工作流程。

Conclusion: AI-SPs作为工具可以增强有目的的练习，关注教学可用性比单纯的对话真实性更能提高学习者的信任度、参与感和教育价值。

Abstract: Standardized patients (SPs) play a central role in clinical communication training but are costly, difficult to scale, and inconsistent. Large language model (LLM) based AI standardized patients (AI-SPs) promise flexible, on-demand practice, yet learners often report that they talk like a patient but feel different. We interviewed 12 clinical-year medical students and conducted three co-design workshops to examine how learners experience constraints of SP encounters and what they expect from AI-SPs. We identified six learner-centered needs, translated them into AI-SP design requirements, and synthesized a conceptual workflow. Our findings position AI-SPs as tools for deliberate practice and show that instructional usability, rather than conversational realism alone, drives learner trust, engagement, and educational value.

</details>


### [49] [Prompting Destiny: Negotiating Socialization and Growth in an LLM-Mediated Speculative Gameworld](https://arxiv.org/abs/2602.05864)
*Mandi Yang,Zhiqi Gao,Yibo Meng,Dongyijie Primo Pan*

Main category: cs.HC

TL;DR: 本研究展示了一种支持社交化和道德责任反思的角色扮演游戏，通过用户研究揭示了玩家在游戏中的责任感和角色定位的谈判。


<details>
  <summary>Details</summary>
Motivation: 旨在通过角色扮演游戏支持对社交化、道德责任感和教育角色定位的反思。

Method: 通过用户研究（N=12），结合游戏记录和赛后访谈，采用反思性主题分析进行分析。

Result: 游戏帮助玩家思考教育指导如何随着社交化而变化，并提供了关于将社会学模型转化为反思性AI介导游戏系统的设计知识。

Conclusion: 玩家在游戏中探讨责任感和角色定位，发现了开放表达与持续参与之间的紧张关系。

Abstract: We present an LLM-mediated role-playing game that supports reflection on socialization, moral responsibility, and educational role positioning. Grounded in socialization theory, the game follows a four-season structure in which players guide a child prince through morally charged situations and compare the LLM-mediated NPC's differentiated responses across stages, helping them reason about how educational guidance shifts with socialization. To approximate real educational contexts and reduce score-chasing, the system hides real-time evaluative scores and provides delayed, end-of-stage growth feedback as reflective prompts. We conducted a user study (N=12) with gameplay logs and post-game interviews, analyzed via reflexive thematic analysis. Findings show how players negotiated responsibility and role positioning, and reveal an entry-load tension between open-ended expression and sustained engagement. We contribute design knowledge on translating sociological models of socialization into reflective AI-mediated game systems.

</details>


### [50] [From Human-Human Collaboration to Human-Agent Collaboration: A Vision, Design Philosophy, and an Empirical Framework for Achieving Successful Partnerships Between Humans and LLM Agents](https://arxiv.org/abs/2602.05987)
*Bingsheng Yao,Chaoran Chen,April Yi Wang,Sherry Tongshuang Wu,Toby Jia-jun Li,Dakuo Wang*

Main category: cs.HC

TL;DR: 大型语言模型促进人机协作发展，研讨会探讨如何借鉴远程人类协作的研究为人机合作设计提供启示。


<details>
  <summary>Details</summary>
Motivation: 希望大型语言模型代理能够成为人类真正的合作伙伴，从而推动人机合作的新范式。

Method: 将举办180分钟的互动研讨会，包含主题演讲、闪电演讲和小组设计会话。

Result: 邀请来自HCI、CSCW和AI领域的跨学科团队，共同探讨人机合作设计及其未来挑战与机遇。

Conclusion: 本研讨会旨在通过建立共同的词汇和研究议程，为协作代理的未来描绘蓝图。

Abstract: The emergence of Large Language Model (LLM) agents enables us to build agent-based intelligent systems that move beyond the role of a "tool" to become genuine collaborators with humans, thereby realizing a novel human-agent collaboration paradigm. Our vision is that LLM agents should resemble remote human collaborators, which allows HCI researchers to ground the future exploration in decades of research on trust, awareness, and common ground in remote human collaboration, while also revealing the unique opportunities and challenges that emerge when one or more partners are AI agents. This workshop establishes a foundational research agenda for the new era by posing the question: How can the rich understanding of remote human collaboration inspire and inform the design and study of human-agent collaboration? We will bring together an interdisciplinary group from HCI, CSCW, and AI to explore this critical transition. The 180-minute workshop will be highly interactive, featuring a keynote speaker, a series of invited lightning talks, and an exploratory group design session where participants will storyboard novel paradigms of human-agent partnership. Our goal is to enlighten the research community by cultivating a shared vocabulary and producing a research agenda that charts the future of collaborative agents.

</details>
