<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 30]
- [cs.HC](#cs.HC) [Total: 11]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [SCOUT: A Lightweight Framework for Scenario Coverage Assessment in Autonomous Driving](https://arxiv.org/abs/2510.24949)
*Anil Yildiz,Sarah M. Thornton,Carl Hildebrandt,Sreeja Roy-Singh,Mykel J. Kochenderfer*

Main category: cs.RO

TL;DR: 我们提出了一种轻量级模型 SCOUT，能够高效预测自主代理的场景覆盖率，减少对人类标注和大型语言模型的依赖。


<details>
  <summary>Details</summary>
Motivation: 评估场景覆盖率对于评估自主代理的鲁棒性至关重要，目前的方法依赖于昂贵的人类标注或计算密集型的大型视觉语言模型，这些方法在大规模部署中不现实。

Method: 通过蒸馏过程训练，学习近似 LVLM 生成的覆盖标签，利用预计算的感知特征避免冗余计算，快速、可扩展地估计场景覆盖率。

Result: 提出了一种名为 SCOUT 的轻量级替代模型，能够直接从代理的潜在传感器表示中预测场景覆盖标签，显著降低了计算成本。

Conclusion: SCOUT 是自主系统中高效场景覆盖监督的重要一步，尽管其性能依赖于 LVLM 生成的训练标签质量。

Abstract: Assessing scenario coverage is crucial for evaluating the robustness of
autonomous agents, yet existing methods rely on expensive human annotations or
computationally intensive Large Vision-Language Models (LVLMs). These
approaches are impractical for large-scale deployment due to cost and
efficiency constraints. To address these shortcomings, we propose SCOUT
(Scenario Coverage Oversight and Understanding Tool), a lightweight surrogate
model designed to predict scenario coverage labels directly from an agent's
latent sensor representations. SCOUT is trained through a distillation process,
learning to approximate LVLM-generated coverage labels while eliminating the
need for continuous LVLM inference or human annotation. By leveraging
precomputed perception features, SCOUT avoids redundant computations and
enables fast, scalable scenario coverage estimation. We evaluate our method
across a large dataset of real-life autonomous navigation scenarios,
demonstrating that it maintains high accuracy while significantly reducing
computational cost. Our results show that SCOUT provides an effective and
practical alternative for large-scale coverage analysis. While its performance
depends on the quality of LVLM-generated training labels, SCOUT represents a
major step toward efficient scenario coverage oversight in autonomous systems.

</details>


### [2] [Smooth path planning with safety margins using Piece-Wise Bezier curves](https://arxiv.org/abs/2510.24972)
*Iancu Andrei,Marius Kloetzer,Cristian Mahulea,Catalin Dosoftei*

Main category: cs.RO

TL;DR: 本文提出了一种使用分段二次Bezier曲线的高效二次规划方法，能够为移动机器人生成平滑的导航路径，并在安全性和实时性能上表现出色。


<details>
  <summary>Details</summary>
Motivation: 本论文旨在通过结构化优化框架，在轨迹平滑性、鲁棒性和可管理的数值复杂性之间取得平衡，以适应实时和嵌入式应用。

Method: 提出了一种计算效率高的二次规划方法，利用分段二次Bezier曲线生成光滑的$C^1$连续路径。

Result: 与传统的分段线性路径规划方法相比，仿真显示出轨迹偏差减少、鲁棒性增强以及整体路径质量改善等明显优势。

Conclusion: 本方法在实现安全导航方面展现了优越的实际有效性和可扩展性。

Abstract: In this paper, we propose a computationally efficient quadratic programming
(QP) approach for generating smooth, $C^1$ continuous paths for mobile robots
using piece-wise quadratic Bezier (PWB) curves. Our method explicitly
incorporates safety margins within a structured optimization framework,
balancing trajectory smoothness and robustness with manageable numerical
complexity suitable for real-time and embedded applications. Comparative
simulations demonstrate clear advantages over traditional piece-wise linear
(PWL) path planning methods, showing reduced trajectory deviations, enhanced
robustness, and improved overall path quality. These benefits are validated
through simulations using a Pure-Pursuit controller in representative
scenarios, highlighting the practical effectiveness and scalability of our
approach for safe navigation.

</details>


### [3] [Defect Mitigation for Robot Arm-based Additive Manufacturing Utilizing Intelligent Control and IOT](https://arxiv.org/abs/2510.24994)
*Matsive Ali,Blake Gassen,Sen Liu*

Main category: cs.RO

TL;DR: 本文提出了一种集成的机器人增材制造系统，结合实时热控制和智能缺陷检测，能够有效改善打印质量，适用于多个领域。


<details>
  <summary>Details</summary>
Motivation: 开发一个集成的机器人熔融沉积建模增材制造系统，以提高打印质量和效率，解决传统技术中存在的缺陷管理问题。

Method: 使用6自由度机器人臂、IoT微控制器进行温度控制和ROS2协调运动，结合OpenCV进行缺陷检测和自动修正。

Result: 提出了一种能够实现实时热控制和智能缺陷修正的集成系统，成功验证了在打印过程中减轻缺陷的能力。

Conclusion: 该系统通过实时热调控、运动控制和智能缺陷检测与修正的结合，建立了一个可扩展的增材制造框架，为航空航天、生物医疗和工业应用提供了解决方案。

Abstract: This paper presents an integrated robotic fused deposition modeling additive
manufacturing system featuring closed-loop thermal control and intelligent
in-situ defect correction using a 6-degree of freedom robotic arm and an Oak-D
camera. The robot arm end effector was modified to mount an E3D hotend
thermally regulated by an IoT microcontroller, enabling precise temperature
control through real-time feedback. Filament extrusion system was synchronized
with robotic motion, coordinated via ROS2, ensuring consistent deposition along
complex trajectories. A vision system based on OpenCV detects layer-wise
defects position, commanding autonomous re-extrusion at identified sites.
Experimental validation demonstrated successful defect mitigation in printing
operations. The integrated system effectively addresses challenges real-time
quality assurance. Inverse kinematics were used for motion planning, while
homography transformations corrected camera perspectives for accurate defect
localization. The intelligent system successfully mitigated surface anomalies
without interrupting the print process. By combining real-time thermal
regulation, motion control, and intelligent defect detection & correction, this
architecture establishes a scalable and adaptive robotic additive manufacturing
framework suitable for aerospace, biomedical, and industrial applications.

</details>


### [4] [Scalable predictive processing framework for multitask caregiving robots](https://arxiv.org/abs/2510.25053)
*Hayato Idei,Tamon Miyake,Tetsuya Ogata,Yuichi Yamashita*

Main category: cs.RO

TL;DR: 本论文提出了一种基于预测处理的分层多模态递归神经网络，能够有效整合多种感官输入，学习灵活的护理任务，展示出良好的自我组织和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 应对社会老龄化的快速发展，现有任务特定的护理机器人无法有效适应多样化场景，急需一种灵活的解决方案。

Method: 构建了一种分层多模态递归神经网络，能够直接整合30,000维的视觉-本体输入，学习护理任务而无需特定特征工程。

Result: 该模型成功学习了两个护理任务，展现出任务转移自我组织能力、对视觉下降的鲁棒性以及在多任务学习中的不对称干扰特性。

Conclusion: 预测处理作为一种通用的计算原理，为开发稳健、灵活和自主的护理机器人提供了理论基础。

Abstract: The rapid aging of societies is intensifying demand for autonomous care
robots; however, most existing systems are task-specific and rely on
handcrafted preprocessing, limiting their ability to generalize across diverse
scenarios. A prevailing theory in cognitive neuroscience proposes that the
human brain operates through hierarchical predictive processing, which
underlies flexible cognition and behavior by integrating multimodal sensory
signals. Inspired by this principle, we introduce a hierarchical multimodal
recurrent neural network grounded in predictive processing under the
free-energy principle, capable of directly integrating over 30,000-dimensional
visuo-proprioceptive inputs without dimensionality reduction. The model was
able to learn two representative caregiving tasks, rigid-body repositioning and
flexible-towel wiping, without task-specific feature engineering. We
demonstrate three key properties: (i) self-organization of hierarchical latent
dynamics that regulate task transitions, capture variability in uncertainty,
and infer occluded states; (ii) robustness to degraded vision through
visuo-proprioceptive integration; and (iii) asymmetric interference in
multitask learning, where the more variable wiping task had little influence on
repositioning, whereas learning the repositioning task led to a modest
reduction in wiping performance, while the model maintained overall robustness.
Although the evaluation was limited to simulation, these results establish
predictive processing as a universal and scalable computational principle,
pointing toward robust, flexible, and autonomous caregiving robots while
offering theoretical insight into the human brain's ability to achieve flexible
adaptation in uncertain real-world environments.

</details>


### [5] [Non-Invasive Calibration Of A Stewart Platform By Photogrammetry](https://arxiv.org/abs/2510.25072)
*Sourabh Karmakar,Cameron J. Turner*

Main category: cs.RO

TL;DR: 本研究开发了一种新的基于前向运动学的Stewart平台光测量校准方法，采用最小二乘法进行了错误补偿，显著提高了系统精度。


<details>
  <summary>Details</summary>
Motivation: 针对Stewart平台校准过程中，由于前向运动学产生的多解性问题，研究者们面临的挑战，旨在开发一种有效的校准方法以提高操作精度。

Method: 采用Denavit-Hartenberg公理建立前向运动学模型，并结合光测量技术，通过高分辨率相机捕捉平台位姿进行校准。

Result: 作者提出了一种基于前向运动学的新校准方法，成功改善了Stewart平台的精度。通过光测量和最小二乘法，提出并应用了三种补偿策略，体现出良好的错误补偿效果。

Conclusion: 研究表明，通过光测量与最小二乘法相结合的校准方法能有效提高Stewart平台的操作精度，但仍有进一步提升的空间。

Abstract: Accurate calibration of a Stewart platform is important for their precise and
efficient operation. However, the calibration of these platforms using forward
kinematics is a challenge for researchers because forward kinematics normally
generates multiple feasible and unfeasible solutions for any pose of the moving
platform. The complex kinematic relations among the six actuator paths
connecting the fixed base to the moving platform further compound the
difficulty in establishing a straightforward and efficient calibration method.
The authors developed a new forward kinematics-based calibration method using
Denavit-Hartenberg convention and used the Stewart platform Tiger 66.1
developed in their lab for experimenting with the photogrammetry-based
calibration strategies described in this paper. This system became operational
upon completion of construction, marking its inaugural use. The authors used
their calibration model for estimating the errors in the system and adopted
three compensation options or strategies as per Least Square method to improve
the accuracy of the system. These strategies leveraged a high-resolution
digital camera and off-the-shelf software to capture the poses of the moving
platform's center. This process is non-invasive and does not need any
additional equipment to be attached to the hexapod or any alteration of the
hexapod hardware. This photogrammetry-based calibration process involves
multiple high-resolution images from different angles to measure the position
and orientation of the platform center in the three-dimensional space. The
Target poses and Actual poses are then compared, and the error compensations
are estimated using the Least-Squared methods to calculate the Predicted poses.
Results from each of the three compensation approaches demonstrated noticeable
enhancements in platform pose accuracies, suggesting room for further
improvements.

</details>


### [6] [Mean-Shift Theory and Its Applications in Swarm Robotics: A New Way to Enhance the Efficiency of Multi-Robot Collaboration](https://arxiv.org/abs/2510.25086)
*Guibin Sun,Jinhu Lü,Kexin Liu,Zhenqian Wang,Guanrong Chen*

Main category: cs.RO

TL;DR: 本文回顾了无分配机器人群体协作的最新进展，强调了平均迁移策略在形状形成问题上的应用，提升了大规模协作的效率。


<details>
  <summary>Details</summary>
Motivation: 自然界中群体行为的集体效应使生物系统能够实现更高效和更强大的协作，研究如何在工程机器人中实现类似的群体智能是个挑战。

Method: 介绍了平均迁移探索策略作为一种理论基础，聚焦于大规模机器人群体的协作形状形成问题。

Result: 提出了一种新颖的无分配协作方法，显著提高了大规模机器人群的协作效率。

Conclusion: 平均迁移探索策略在多种工业应用中展示了其卓越的性能，尤其是在形状形成、区域覆盖和机动编队方面。

Abstract: Swarms evolving from collective behaviors among multiple individuals are
commonly seen in nature, which enables biological systems to exhibit more
efficient and robust collaboration. Creating similar swarm intelligence in
engineered robots poses challenges to the design of collaborative algorithms
that can be programmed at large scales. The assignment-based method has played
an eminent role for a very long time in solving collaboration problems of robot
swarms. However, it faces fundamental limitations in terms of efficiency and
robustness due to its unscalability to swarm variants. This article presents a
tutorial review on recent advances in assignment-free collaboration of robot
swarms, focusing on the problem of shape formation. A key theoretical component
is the recently developed \emph{mean-shift exploration} strategy, which
improves the collaboration efficiency of large-scale swarms by dozens of times.
Further, the efficiency improvement is more significant as the swarm scale
increases. Finally, this article discusses three important applications of the
mean-shift exploration strategy, including precise shape formation, area
coverage formation, and maneuvering formation, as well as their corresponding
industrial scenarios in smart warehousing, area exploration, and cargo
transportation.

</details>


### [7] [NanoVLA: Routing Decoupled Vision-Language Understanding for Nano-sized Generalist Robotic Policies](https://arxiv.org/abs/2510.25122)
*Jiahong Chen,Jing Wang,Long Chen,Chuwei Cai,Jinghui Lu*

Main category: cs.RO

TL;DR: 本文提出NanoVLA模型，旨在解决在资源受限设备上实施现有视语言动作模型的挑战，通过轻量级架构在保持高性能的同时，显著降低计算资源需求。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的边缘设备上，实施现有的视语言动作模型面临高计算需求的挑战，影响了移动机器人和嵌入式系统的实际应用。

Method: 提出的NanoVLA采用了视觉语言解耦、长短动作块化以及动态路由等策略，优化了推断效率与实时响应能力。

Result: NanoVLA在边缘设备上的推断速度比现有的最先进VLA模型快52倍，参数少98%，同时保持或超越了任务精度和泛化能力。

Conclusion: NanoVLA通过创新的设计策略，为在资源受限硬件上实现高精度的机器人操作提供了实际可行的解决方案。

Abstract: Vision-language-action (VLA) models have significantly advanced robotic
manipulation by integrating vision-language models (VLMs), and action decoders
into a unified architecture. However, their deployment on resource-constrained
edge devices, such as mobile robots or embedded systems (e.g., Jetson Orin
Nano), remains challenging due to high computational demands, especially in
real-world scenarios where power, latency, and computational resources are
critical. To close this gap, we introduce Nano-scale Vision-Language Action
(NanoVLA), a family of lightweight VLA architectures that achieve high
performance with minimal resources. Our core innovations include: (1)
vision-language decoupling that moves conventional early vision and language
inputs fusion in VLM to late stage, achieving better performance while enabling
caching and reduce inference overhead and latency; (2) long-short action
chunking to ensure smooth, coherent multi-step planning without sacrificing
real-time responsiveness; (3) dynamic routing that adaptively assigns
lightweight or heavy backbones based on task complexity, further optimizing
inference efficiency. Experimental results on several benchmarks, as well as
real-world deployments, demonstrate that NanoVLA achieves up to 52x faster
inference on edge devices compared to previous state-of-the-art VLA models,
with 98% less parameters while maintaining or surpassing their task accuracy
and generalization. Ablation studies confirm that our decoupling strategy
preserves cross-task transferability, and the routing module enhances
cost-performance trade-offs, enabling practical, high-precision robotic
manipulation on resource-constrained hardware.

</details>


### [8] [Learning Spatial-Aware Manipulation Ordering](https://arxiv.org/abs/2510.25138)
*Yuxiang Yan,Zhiyuan Zhou,Xin Gao,Guanghao Li,Shenglin Li,Jiaqi Chen,Qunyan Pu,Jian Pu*

Main category: cs.RO

TL;DR: 提出OrderMind框架，通过学习空间上下文来优化杂乱环境中的物体操控顺序，显著提高效果与效率。


<details>
  <summary>Details</summary>
Motivation: 当前方法常常忽视物体之间的空间关系，限制了其灵活性和可扩展性。

Method: 提出OrderMind，一个统一的空间感知操控顺序框架，通过空间上下文直接学习物体操控优先级。

Result: 通过在操控排序基准上进行评估，OrderMind在有效性和效率上显著优于现有方法。

Conclusion: OrderMind能够在杂乱场景中实现稳健的操控，为物体操控提供了新的思路。

Abstract: Manipulation in cluttered environments is challenging due to spatial
dependencies among objects, where an improper manipulation order can cause
collisions or blocked access. Existing approaches often overlook these spatial
relationships, limiting their flexibility and scalability. To address these
limitations, we propose OrderMind, a unified spatial-aware manipulation
ordering framework that directly learns object manipulation priorities based on
spatial context. Our architecture integrates a spatial context encoder with a
temporal priority structuring module. We construct a spatial graph using
k-Nearest Neighbors to aggregate geometric information from the local layout
and encode both object-object and object-manipulator interactions to support
accurate manipulation ordering in real-time. To generate physically and
semantically plausible supervision signals, we introduce a spatial prior
labeling method that guides a vision-language model to produce reasonable
manipulation orders for distillation. We evaluate OrderMind on our Manipulation
Ordering Benchmark, comprising 163,222 samples of varying difficulty. Extensive
experiments in both simulation and real-world environments demonstrate that our
method significantly outperforms prior approaches in effectiveness and
efficiency, enabling robust manipulation in cluttered scenes.

</details>


### [9] [SoraNav: Adaptive UAV Task-Centric Navigation via Zeroshot VLM Reasoning](https://arxiv.org/abs/2510.25191)
*Hongyu Song,Rishabh Dev Yadav,Cheng Guo,Wei Pan*

Main category: cs.RO

TL;DR: 本文提出了SoraNav框架，通过结合几何信息与零-shot视觉-语言模型，有效提高了无人机在3D环境中的导航成功率。


<details>
  <summary>Details</summary>
Motivation: 理解视觉观察和自然语言指令以执行复杂任务是机器人和人工智能中的一个关键挑战，尤其是在小规模3D环境中。

Method: 通过将几何先验纳入图像注释，约束视觉-语言模型的动作空间，并利用混合切换策略利用导航历史在基于VLM的推理和几何探索之间进行切换。

Result: SoraNav是一个自适应的无人机导航框架，通过将零-shot视觉-语言模型推理与几何感知决策结合起来，提高了导航性能。

Conclusion: 实验结果显示，SoraNav在2.5D和3D场景中显著提高了成功率和成功路径长度的加权。

Abstract: Interpreting visual observations and natural language instructions for
complex task execution remains a key challenge in robotics and AI. Despite
recent advances, language-driven navigation is still difficult, particularly
for UAVs in small-scale 3D environments. Existing Vision-Language Navigation
(VLN) approaches are mostly designed for ground robots and struggle to
generalize to aerial tasks that require full 3D spatial reasoning. The
emergence of large Vision-Language Models (VLMs), such as GPT and Claude,
enables zero-shot semantic reasoning from visual and textual inputs. However,
these models lack spatial grounding and are not directly applicable to
navigation. To address these limitations, SoraNav is introduced, an adaptive
UAV navigation framework that integrates zero-shot VLM reasoning with
geometry-aware decision-making. Geometric priors are incorporated into image
annotations to constrain the VLM action space and improve decision quality. A
hybrid switching strategy leverages navigation history to alternate between VLM
reasoning and geometry-based exploration, mitigating dead-ends and redundant
revisits. A PX4-based hardware-software platform, comprising both a digital
twin and a physical micro-UAV, enables reproducible evaluation. Experimental
results show that in 2.5D scenarios, our method improves Success Rate (SR) by
25.7% and Success weighted by Path Length (SPL) by 17%. In 3D scenarios, it
improves SR by 29.5% and SPL by 18.5% relative to the baseline.

</details>


### [10] [RoadSens-4M: A Multimodal Smartphone & Camera Dataset for Holistic Road-way Analysis](https://arxiv.org/abs/2510.25211)
*Amith Khandakar,David Michelson,Shaikh Golam Rabbani,Fariya Bintay Shafi,Md. Faysal Ahamed,Khondokar Radwanur Rahman,Md Abidur Rahman,Md. Fahmidun Nabi,Mohamed Arselene Ayari,Khaled Khan,Ponnuthurai Nagaratnam Suganthan*

Main category: cs.RO

TL;DR: 本研究创建了一个新数据集，旨在通过整合多个传感器数据和地理信息，提高道路监测的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 改善道路安全和条件，通过监测路面问题如坑洼和颠簸来实现

Method: 使用手机应用程序收集设备传感器数据并创建数据集

Result: 提出一种综合性的高质量数据集，结合了传感器数据、GIS、天气信息和视频素材，以全面分析道路问题

Conclusion: 该数据集不仅有助于道路状况的明晰分析，还支持交通管理和基础设施发展等多项举措，并将向公众开放，以促进智能交通系统的研究与创新。

Abstract: It's important to monitor road issues such as bumps and potholes to enhance
safety and improve road conditions. Smartphones are equipped with various
built-in sensors that offer a cost-effective and straightforward way to assess
road quality. However, progress in this area has been slow due to the lack of
high-quality, standardized datasets. This paper discusses a new dataset created
by a mobile app that collects sensor data from devices like GPS,
accelerometers, gyroscopes, magnetometers, gravity sensors, and orientation
sensors. This dataset is one of the few that integrates Geographic Information
System (GIS) data with weather information and video footage of road
conditions, providing a comprehensive understanding of road issues with
geographic context. The dataset allows for a clearer analysis of road
conditions by compiling essential data, including vehicle speed, acceleration,
rotation rates, and magnetic field intensity, along with the visual and spatial
context provided by GIS, weather, and video data. Its goal is to provide
funding for initiatives that enhance traffic management, infrastructure
development, road safety, and urban planning. Additionally, the dataset will be
publicly accessible to promote further research and innovation in smart
transportation systems.

</details>


### [11] [Hybrid Vision Servoing with Depp Alignment and GRU-Based Occlusion Recovery](https://arxiv.org/abs/2510.25233)
*Jee Won Lee,Hansol Lim,Sooyeun Yang,Jongseong Brad Choi*

Main category: cs.RO

TL;DR: 本研究提出一种新的混合视觉追踪框架，旨在提高机器人在部分遮挡情况下的目标追踪精度与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为解决在部分或完全遮挡下的目标追踪问题，改进图像基础视觉伺服控制系统的精度和鲁棒性。

Method: 采用快速全局模板匹配约束pose搜索区域，再结合深度特征Lucas-Kanade模块和轻量级残差回归器处理局部对齐问题，最后通过GRU预测器处理视觉信号的低置信度情况。

Result: 提出了一种混合视觉追踪框架，能够实现高效且精确的实时控制。

Conclusion: 该系统在高达90%遮挡情况下仍能保持2px以内的追踪误差，证明了其实时性和精确性适用于实际机器人视觉应用。

Abstract: Vision-based control systems, such as image-based visual servoing (IBVS),
have been extensively explored for precise robot manipulation. A persistent
challenge, however, is maintaining robust target tracking under partial or full
occlusions. Classical methods like Lucas-Kanade (LK) offer lightweight tracking
but are fragile to occlusion and drift, while deep learning-based approaches
often require continuous visibility and intensive computation. To address these
gaps, we propose a hybrid visual tracking framework that bridges advanced
perception with real-time servo control. First, a fast global template matcher
constrains the pose search region; next, a deep-feature Lucas-Kanade module
operating on early VGG layers refines alignment to sub-pixel accuracy (<2px);
then, a lightweight residual regressor corrects local misalignments caused by
texture degradation or partial occlusion. When visual confidence falls below a
threshold, a GRU-based predictor seamlessly extrapolates pose updates from
recent motion history. Crucially, the pipeline's final outputs-translation,
rotation, and scale deltas-are packaged as direct control signals for 30Hz
image-based servo loops. Evaluated on handheld video sequences with up to 90%
occlusion, our system sustains under 2px tracking error, demonstrating the
robustness and low-latency precision essential for reliable real-world robot
vision applications.

</details>


### [12] [One-shot Humanoid Whole-body Motion Learning](https://arxiv.org/abs/2510.25241)
*Hao Huang,Geeta Chandra Raju Bethala,Shuaihang Yuan,Congcong Wen,Anthony Tzes,Yi Fang*

Main category: cs.RO

TL;DR: 本研究提出了一种新方法，利用单个非步态样本和现成的步态样本，通过最优传输和几何插值生成中间姿态，从而有效训练类人运动策略，在多项评估中超越了基线。


<details>
  <summary>Details</summary>
Motivation: 当前方法需大量训练样本来建立高质量的人类运动数据集，耗时耗力，因此开发一种使用单一目标运动样本的有效策略显得尤为重要。

Method: 通过利用有序保持的最优传输计算步态和非步态序列之间的距离，利用几何插值生成新的中间姿态骨架，并进行冲突优化配置，最后通过强化学习在模拟环境中进行策略训练。

Result: 在CMU MoCap数据集上的实验评估表明，该方法在多项指标上始终优于基线，体现了其在类人运动模拟中的优势。

Conclusion: 该方法在多个指标上表现优于基线方法，展示了单一目标运动样本训练全身类人运动策略的有效性。

Abstract: Whole-body humanoid motion represents a cornerstone challenge in robotics,
integrating balance, coordination, and adaptability to enable human-like
behaviors. However, existing methods typically require multiple training
samples per motion category, rendering the collection of high-quality human
motion datasets both labor-intensive and costly. To address this, we propose a
novel approach that trains effective humanoid motion policies using only a
single non-walking target motion sample alongside readily available walking
motions. The core idea lies in leveraging order-preserving optimal transport to
compute distances between walking and non-walking sequences, followed by
interpolation along geodesics to generate new intermediate pose skeletons,
which are then optimized for collision-free configurations and retargeted to
the humanoid before integration into a simulated environment for policy
training via reinforcement learning. Experimental evaluations on the CMU MoCap
dataset demonstrate that our method consistently outperforms baselines,
achieving superior performance across metrics. Code will be released upon
acceptance.

</details>


### [13] [Time-Optimal Transport of Loosely Placed Liquid Filled Cups along Prescribed Paths](https://arxiv.org/abs/2510.25255)
*Klaus Zauner,Hubert Gattringer,Andreas Mueller*

Main category: cs.RO

TL;DR: 本文提出了一种通过最优控制实现液体杯快速运输的方法，解决了轨迹规划中的晃动问题。


<details>
  <summary>Details</summary>
Motivation: 处理装有液体的松散物体的轨迹规划和控制难度较大，特别是在运输过程中避免液体溢出是一个挑战。

Method: 采用直接多重发射方法解决优化问题，并将液体动态纳入动态模型中。

Result: 成功优化了液体杯的运输路径，实现了在最短时间内的运输，同时减少了液体的晃动和溢出。

Conclusion: 提出了一种优化控制方法，能够有效地在最短时间内运输装有液体的杯子，减少液体溢出。

Abstract: Handling loosely placed objects with robotic manipulators is a difficult task
from the point of view of trajectory planning and control. This becomes even
more challenging when the object to be handled is a container filled with
liquid. This paper addresses the task of transporting a liquid-filled cup
placed on a tray along a prescribed path in shortest time. The objective is to
minimize swapping, thus avoiding spillage of the fluid. To this end, the
sloshing dynamics is incorporated into the dynamic model used within the
optimal control problem formulation. The optimization problem is solved using a
direct multiple shooting approach.

</details>


### [14] [SynHLMA:Synthesizing Hand Language Manipulation for Articulated Object with Discrete Human Object Interaction Representation](https://arxiv.org/abs/2510.25268)
*Wang zhi,Yuyan Liu,Liu Liu,Li Zhang,Ruixuan Lu,Dan Guo*

Main category: cs.RO

TL;DR: 本论文提出了一种新颖的手部操控序列生成框架SynHLMA，旨在通过自然语言指导生成手部抓取，对于关节物体的长时间操控序列至关重要。


<details>
  <summary>Details</summary>
Motivation: 将语言指令与手部操作结合，能够提升虚拟与增强现实（VR/AR）应用中的机器人与物体交互能力。

Method: 利用离散的手部与物体交互表示以及自然语言嵌入，通过HAOI操控语言模型对抓取过程与语言描述进行对齐，并使用共同感知损失确保手部抓取符合物体关节的动态变化。

Result: 在自建的HAOI-lang数据集上进行评估，证明了SynHLMA在手部操控任务中表现的优越性，并展示了该框架在模仿学习中的机器人抓取应用。

Conclusion: 实验结果表明，SynHLMA在手部抓取序列生成方面表现优于现有技术，证明了该框架的有效性。

Abstract: Generating hand grasps with language instructions is a widely studied topic
that benefits from embodied AI and VR/AR applications. While transferring into
hand articulatied object interaction (HAOI), the hand grasps synthesis requires
not only object functionality but also long-term manipulation sequence along
the object deformation. This paper proposes a novel HAOI sequence generation
framework SynHLMA, to synthesize hand language manipulation for articulated
objects. Given a complete point cloud of an articulated object, we utilize a
discrete HAOI representation to model each hand object interaction frame. Along
with the natural language embeddings, the representations are trained by an
HAOI manipulation language model to align the grasping process with its
language description in a shared representation space. A joint-aware loss is
employed to ensure hand grasps follow the dynamic variations of articulated
object joints. In this way, our SynHLMA achieves three typical hand
manipulation tasks for articulated objects of HAOI generation, HAOI prediction
and HAOI interpolation. We evaluate SynHLMA on our built HAOI-lang dataset and
experimental results demonstrate the superior hand grasp sequence generation
performance comparing with state-of-the-art. We also show a robotics grasp
application that enables dexterous grasps execution from imitation learning
using the manipulation sequence provided by our SynHLMA. Our codes and datasets
will be made publicly available.

</details>


### [15] [Development of Implicit-Explicit Control Based Amphibious Centipede-Type Robot and Evaluation of its Mobile Performance](https://arxiv.org/abs/2510.25280)
*Yusuke Tsunoda,Seiya Yamamoto,Kazuki Ito,Runze Xiao,Keisuke Naniwa,Koichi Osuka*

Main category: cs.RO

TL;DR: 本研究开发了一种蜈蚣型移动机器人，能够在水陆环境中进行导航，采用统一控制方案，简化了不同环境下的行走方式设计。


<details>
  <summary>Details</summary>
Motivation: 旨在解决为不同复杂环境设计适当行走方式和控制器切换的困难。

Method: 通过设计具有灵活关节和两侧腿部的蜈蚣型机器人，并采用隐式-显式控制哲学进行统一控制。

Result: 通过实验评估了机器人在陆地和水中运动性能，验证了新开发的腿部结构的有效性。

Conclusion: 研究结果表明，存在一种适合在水陆环境中导航的腿部结构，并且可以在相同的控制条件下实现有效的活动。

Abstract: Multi-legged mobile robots possess high mobility performance in rough terrain
environments, stemming from their high postural stability, joint flexibility,
and the redundancy provided by multiple legs. In prior research on navigating
between different environments such as land and water, the primary strategy
employed involves switching to a controller that generates an appropriate gait
for the new environment upon entering it. However, designing appropriate gaits
for each complex and diverse environment and accurately determining controller
switching for each environment is challenging. Therefore, this research
develops a centipede-type mobile robot that navigates both aquatic and
terrestrial environments with a simple, unified control scheme, based on the
implicit-explicit control philosophy and by ingeniously designing the robot's
body structure. In this research, we developed the robot featuring flexible
joints and left and right legs on each body segment and focused on the leg
structure which has extensive contact with the environment. This paper
evaluates the locomotion performance on land and water using the three
developed leg structures, using the robot's leg slip rate and actuator energy
consumption as evaluation metrics. The experimental results confirmed the
existence of an appropriate leg structure capable of navigating both aquatic
and terrestrial environments under identical control.

</details>


### [16] [An approach for combining transparency and motion assistance of a lower body exoskeleton](https://arxiv.org/abs/2510.25335)
*Jakob Ziegler,Bernhard Rameder,Hubert Gattringer,Andreas Mueller*

Main category: cs.RO

TL;DR: 本论文提出了一种使用下肢外骨骼的步态辅助方法，结合透明模式和运动辅助模式，以最小的交互力跟随用户的自如动作，同时在行走时引入额外的扭矩来引导腿部运动。


<details>
  <summary>Details</summary>
Motivation: 旨在提高下肢外骨骼在步态辅助中的透明度和有效性，以提升用户的步态体验。

Method: 采用透明模式和运动辅助模式的组合，通过利用驱动单元的齿轮间隙和适应性振荡器来实现步态学习。

Result: 实验表明该方法能够有效指导腿部运动，初步结果良好。

Conclusion: 初步实验结果显示该方法有良好的效果，表明适应性振荡器在步态辅助中的可行性。

Abstract: In this paper, an approach for gait assistance with a lower body exoskeleton
is described. Two concepts, transparency and motion assistance, are combined.
The transparent mode, where the system is following the user's free motion with
a minimum of perceived interaction forces, is realized by exploiting the gear
backlash of the actuation units. During walking a superimposed assistance mode
applies an additional torque guiding the legs to their estimated future
position. The concept of adaptive oscillators is utilized to learn the
quasi-periodic signals typical for locomotion. First experiments showed
promising results.

</details>


### [17] [Geometric Robot Calibration Using a Calibration Plate](https://arxiv.org/abs/2510.25338)
*Bernhard Rameder,Hubert Gattringer,Andreas Mueller*

Main category: cs.RO

TL;DR: 本文提出了一种基于校准板的机器人几何校准新方法，具有更高的机械稳定性和经济性。


<details>
  <summary>Details</summary>
Motivation: 提出一种新方法，以解决现有几何机器人校准中的高成本和复杂性问题。

Method: 使用具有已知测量点距离的校准板，通过相对测量确定误差参数，并结合最小二乘法和约束优化问题进行参数识别。

Result: 该方法通过使用校准板识别系统的误差参数，取得了良好的实验结果。

Conclusion: 所提出的方法在实验中表现出良好的效果，并且可以推广到其他类型的机器人。

Abstract: In this paper a new method for geometric robot calibration is introduced,
which uses a calibration plate with precisely known distances between its
measuring points. The relative measurement between two points on the
calibration plate is used to determine predefined error parameters of the
system. In comparison to conventional measurement methods, like laser tracker
or motion capture systems, the calibration plate provides a more mechanically
robust and cheaper alternative, which is furthermore easier to transport due to
its small size. The calibration method, the plate design, the mathematical
description of the error system as well as the identification of the parameters
are described in detail. For identifying the error parameters, the least
squares method and a constrained optimization problem are used. The
functionality of this method was demonstrated in experiments that led to
promising results, correlated with one of a laser tracker calibration. The
modeling and identification of the error parameters is done for a gantry
machine, but is not restricted to that type of robot.

</details>


### [18] [Integrating Legal and Logical Specifications in Perception, Prediction, and Planning for Automated Driving: A Survey of Methods](https://arxiv.org/abs/2510.25386)
*Kumar Manas,Mert Keser,Alois Knoll*

Main category: cs.RO

TL;DR: 本文审查当前自动驾驶系统集成法律和逻辑规范的方法，揭示了相关技术中的挑战，并提出分类法以促进未来发展。


<details>
  <summary>Details</summary>
Motivation: 分析当前将法律和逻辑规范集成到自动驾驶系统的感知、预测和规划模块的方法论，以确保合规性与可解释性。

Method: 系统探讨了基于逻辑的框架和计算法律推理方法，特别关注应对感知不确定性和明确法律规范的方法。

Result: 提出了一种分类法，对现有方法进行系统分析，强调了在感知可靠性、法律合规性和决策合理性交汇处的挑战。

Conclusion: 研究强调了跨学科的见解，指出了解决自动驾驶系统法律合规问题所需面对的开放问题和实践权衡。

Abstract: This survey provides an analysis of current methodologies integrating legal
and logical specifications into the perception, prediction, and planning
modules of automated driving systems. We systematically explore techniques
ranging from logic-based frameworks to computational legal reasoning
approaches, emphasizing their capability to ensure regulatory compliance and
interpretability in dynamic and uncertain driving environments. A central
finding is that significant challenges arise at the intersection of perceptual
reliability, legal compliance, and decision-making justifiability. To
systematically analyze these challenges, we introduce a taxonomy categorizing
existing approaches by their theoretical foundations, architectural
implementations, and validation strategies. We particularly focus on methods
that address perceptual uncertainty and incorporate explicit legal norms,
facilitating decisions that are both technically robust and legally defensible.
The review covers neural-symbolic integration methods for perception,
logic-driven rule representation, and norm-aware prediction strategies, all
contributing toward transparent and accountable autonomous vehicle operation.
We highlight critical open questions and practical trade-offs that must be
addressed, offering multidisciplinary insights from engineering, logic, and law
to guide future developments in legally compliant autonomous driving systems.

</details>


### [19] [Sim-to-Real Gentle Manipulation of Deformable and Fragile Objects with Stress-Guided Reinforcement Learning](https://arxiv.org/abs/2510.25405)
*Kei Ikemura,Yifei Dong,David Blanco-Mulero,Alberta Longhini,Li Chen,Florian T. Pokorny*

Main category: cs.RO

TL;DR: 提出一种视觉基础的强化学习方法，减少操作过程中的物体损伤。


<details>
  <summary>Details</summary>
Motivation: 解决机器人操作中由于物体损伤所带来的挑战，现有方法过于依赖准确物体模型和复杂传感器。

Method: 通过引入应力度惩罚奖励，加上离线示范和循序渐进的设置，来引导强化学习过程。

Result: 本文提出了一种基于视觉的强化学习方法，以应对脆弱和可变形物体的机器人操作问题。

Conclusion: 所提出的方法在仿真和现实场景中证明了其有效性，在完成任务时显著减少对脆弱物体施加的压力。

Abstract: Robotic manipulation of deformable and fragile objects presents significant
challenges, as excessive stress can lead to irreversible damage to the object.
While existing solutions rely on accurate object models or specialized sensors
and grippers, this adds complexity and often lacks generalization. To address
this problem, we present a vision-based reinforcement learning approach that
incorporates a stress-penalized reward to discourage damage to the object
explicitly. In addition, to bootstrap learning, we incorporate offline
demonstrations as well as a designed curriculum progressing from rigid proxies
to deformables. We evaluate the proposed method in both simulated and
real-world scenarios, showing that the policy learned in simulation can be
transferred to the real world in a zero-shot manner, performing tasks such as
picking up and pushing tofu. Our results show that the learned policies exhibit
a damage-aware, gentle manipulation behavior, demonstrating their effectiveness
by decreasing the stress applied to fragile objects by 36.5% while achieving
the task goals, compared to vanilla RL policies.

</details>


### [20] [Solving the Right Problem with Multi-Robot Formations](https://arxiv.org/abs/2510.25422)
*Chaz Cornwall,Jeremy P. Bos*

Main category: cs.RO

TL;DR: 本文提出了一种形成规划器，通过优化相对机器人位置来减少多机器人编队与原始成本函数之间的不匹配，从而提供更好的性能。


<details>
  <summary>Details</summary>
Motivation: 在形成控制中，机器人维护的形状与原始成本函数之间存在不匹配的问题，现有的静态形状可能不再最小化保护成本，因此需要一种新的形成规划方法。

Method: 形成规划器采用两步优化问题，首先解决约束问题来估计非线性和不可微的成本，然后使用相对位置最小化加权代替成本函数。

Result: 在仿真中，形成规划器能够将单一成本降低超过75%，并在同时最小化多种成本函数时，将成本降低20-40%。

Conclusion: 形成规划提供了通过最小化接近原始成本函数的代替成本函数来优化机器人编队的更好性能。

Abstract: Formation control simplifies minimizing multi-robot cost functions by
encoding a cost function as a shape the robots maintain. However, by reducing
complex cost functions to formations, discrepancies arise between maintaining
the shape and minimizing the original cost function. For example, a Diamond or
Box formation shape is often used for protecting all members of the formation.
When more information about the surrounding environment becomes available, a
static shape often no longer minimizes the original protection cost. We propose
a formation planner to reduce mismatch between a formation and the cost
function while still leveraging efficient formation controllers. Our formation
planner is a two-step optimization problem that identifies desired relative
robot positions. We first solve a constrained problem to estimate non-linear
and non-differentiable costs with a weighted sum of surrogate cost functions.
We theoretically analyze this problem and identify situations where weights do
not need to be updated. The weighted, surrogate cost function is then minimized
using relative positions between robots. The desired relative positions are
realized using a non-cooperative formation controller derived from Lyapunov's
direct approach. We then demonstrate the efficacy of this approach for
military-like costs such as protection and obstacle avoidance. In simulations,
we show a formation planner can reduce a single cost by over 75%. When
minimizing a variety of cost functions simultaneously, using a formation
planner with adaptive weights can reduce the cost by 20-40%. Formation planning
provides better performance by minimizing a surrogate cost function that
closely approximates the original cost function instead of relying on a shape
abstraction.

</details>


### [21] [Combining Moving Mass Actuators and Manoeuvring Models for Underwater Vehicles: A Lagrangian Approach](https://arxiv.org/abs/2510.25479)
*Alexander B. Rambech,Ivar B. Saksvik,Vahid Hassani*

Main category: cs.RO

TL;DR: 本研究提出了一种改进的水下车辆动力学模型，考虑内部移动质量的影响，并通过仿真验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 研究内部移动质量对水下车辆运动的影响，以改进其动力学模型。

Method: 提出了一种Newton-Euler公式来描述带有内部移动质量驱动器的水下车辆的运动方程，并扩展了Fossen提出的机动模型。

Result: 该研究表明，移动质量影响可以作为状态包括在额外的运动方程和耦合的刚体动力学中。

Conclusion: 所提出的Newton-Euler模型通过仿真验证，并与传统的Hamiltonian内部移动质量驱动器模型进行了比较。

Abstract: In this paper, we present a Newton-Euler formulation of the equations of
motion for underwater vehicles with an interntal moving mass actuator.
Furthermore, the moving mass dynamics are expressed as an extension to the
manoeuvring model for underwater vehicles, originally introduced by Fossen
(1991). The influence of the moving mass is described in body-frame and
included as states in both an additional kinematic equation and as part of the
coupled rigid-body kinetics of the underwater vehicle. The Coriolis-centripetal
effects are derived from Kirchhoff's equations and the hydrostatics are derived
using first principals. The proposed Newton-Euler model is validated through
simulation and compared with the traditional Hamiltonian internal moving mass
actuator formulation.

</details>


### [22] [Octopus-like Reaching Motion: A Perspective Inspired by Whipping](https://arxiv.org/abs/2510.25520)
*Shengyao Zhang,Yiyuan Zhang,Chenrui Zhang,Yiming Li,Wenci Xin,Yuliang Liufu,Hong Wei Ng,Cecilia Laschi*

Main category: cs.RO

TL;DR: 本研究通过对水中被动动态的调查，揭示了章鱼臂的伸展运动与鞭子的动力学之间的关系，发现其运动并不是单纯的被动行为。


<details>
  <summary>Details</summary>
Motivation: 研究章鱼臂的特定伸展动作，因为其对可高度变形的身体的有效控制引起了广泛关注。

Method: 通过在水和空气中进行平台测试，系统性地变化材料的硬度和驱动速度，使用基于图像的量化技术来分析形成的曲率传播。

Result: 通过实验验证了塑料手臂在水中模拟章鱼伸展运动的关键特征，得出了与生物行为的相似与不同之处。

Conclusion: 研究表明，章鱼的伸展运动不仅是被动的鞭打行为，周围介质在形成这种运动中起着至关重要的作用，并为未来的水动力研究提供了潜在的平台。

Abstract: The stereotypical reaching motion of the octopus arm has drawn growing
attention for its efficient control of a highly deformable body. Previous
studies suggest that its characteristic bend propagation may share underlying
principles with the dynamics of a whip. This work investigates whether
whip-like passive dynamics in water can reproduce the kinematic features
observed in biological reaching and their similarities and differences.
Platform-based whipping tests were performed in water and air while
systematically varying material stiffness and driving speed. Image-based
quantification revealed that the Ecoflex Gel 2 arm driven at 150 rpm (motor
speed) reproduced curvature propagation similar to that observed in octopus
reaching. However, its bend-point velocity decreased monotonically rather than
exhibiting the biological bell-shaped profile, confirming that the octopus
reaching movement is not merely a passive whipping behavior. The absence of
propagation in air further highlights the critical role of the surrounding
medium in forming octopus-like reaching motion. This study provides a new
perspective for understand biological reaching movement, and offers a potential
platform for future hydrodynamic research.

</details>


### [23] [Using VLM Reasoning to Constrain Task and Motion Planning](https://arxiv.org/abs/2510.25548)
*Muyang Yan,Miras Mengdibayev,Ardon Floros,Weihang Guo,Lydia E. Kavraki,Zachary Kingston*

Main category: cs.RO

TL;DR: VIZ-COAST 利用预训练模型的空间推理能力，提前识别细化问题，优化了任务规划的效率，减少了失败情况。


<details>
  <summary>Details</summary>
Motivation: 任务与运动规划中的抽象计划可能因细化问题而导致失败，因此需要提前识别潜在的细化问题以提高效率。

Method: VIZ-COAST 方法利用视觉语言模型提取图像和领域描述中的合理约束，从而识别下行细化的问题。

Result: 在两个具有挑战性的 TAMP 领域中的实验表明，该方法能有效提取可信约束，减少规划时间，并能够广泛适用于不同实例。

Conclusion: VIZ-COAST 方法通过利用大型预训练视觉语言模型的空间推理能力，显著减少了规划时间，并在某些情况下消除了下行细化失败。

Abstract: In task and motion planning, high-level task planning is done over an
abstraction of the world to enable efficient search in long-horizon robotics
problems. However, the feasibility of these task-level plans relies on the
downward refinability of the abstraction into continuous motion. When a
domain's refinability is poor, task-level plans that appear valid may
ultimately fail during motion planning, requiring replanning and resulting in
slower overall performance. Prior works mitigate this by encoding refinement
issues as constraints to prune infeasible task plans. However, these approaches
only add constraints upon refinement failure, expending significant search
effort on infeasible branches. We propose VIZ-COAST, a method of leveraging the
common-sense spatial reasoning of large pretrained Vision-Language Models to
identify issues with downward refinement a priori, bypassing the need to fix
these failures during planning. Experiments on two challenging TAMP domains
show that our approach is able to extract plausible constraints from images and
domain descriptions, drastically reducing planning times and, in some cases,
eliminating downward refinement failures altogether, generalizing to a diverse
range of instances from the broader domain.

</details>


### [24] [Learning to Plan & Schedule with Reinforcement-Learned Bimanual Robot Skills](https://arxiv.org/abs/2510.25634)
*Weikang Wan,Fabio Ramos,Xuning Yang,Caelan Garrett*

Main category: cs.RO

TL;DR: 开发了一种新框架以提高双手协同操控的效率，利用强化学习训练技能，并通过变压器模型预测技能调度。


<details>
  <summary>Details</summary>
Motivation: 探讨双手长时间接触操作的高复杂性，要求复杂的协调机制。

Method: 基于强化学习训练的单臂和双臂基本技能库，使用变压器作为高层调度器，预测技能的离散调度和连续参数。

Result: 提出了一种层次框架，将双手操作转化为一个集成的技能规划与调度问题。

Conclusion: 该方法在复杂接触任务中表现出更高的成功率和更高的协调效率。

Abstract: Long-horizon contact-rich bimanual manipulation presents a significant
challenge, requiring complex coordination involving a mixture of parallel
execution and sequential collaboration between arms. In this paper, we
introduce a hierarchical framework that frames this challenge as an integrated
skill planning & scheduling problem, going beyond purely sequential
decision-making to support simultaneous skill invocation. Our approach is built
upon a library of single-arm and bimanual primitive skills, each trained using
Reinforcement Learning (RL) in GPU-accelerated simulation. We then train a
Transformer-based planner on a dataset of skill compositions to act as a
high-level scheduler, simultaneously predicting the discrete schedule of skills
as well as their continuous parameters. We demonstrate that our method achieves
higher success rates on complex, contact-rich tasks than end-to-end RL
approaches and produces more efficient, coordinated behaviors than traditional
sequential-only planners.

</details>


### [25] [Collision avoidance and path finding in a robotic mobile fulfillment system using multi-objective meta-heuristics](https://arxiv.org/abs/2510.25650)
*Ahmad Kokhahi,Mary Kurz*

Main category: cs.RO

TL;DR: 本文提出了一种新的AGV路径规划方法，考虑了能源消耗，同时在避免碰撞和任务分配方面取得了更好的效果。


<details>
  <summary>Details</summary>
Motivation: 在自动引导车（AGV）的路径规划中，除了考虑碰撞和行驶时间外，还需要考虑能源消耗。

Method: 提出了一种新的碰撞避免策略，并使用非支配排序遗传算法（NSGA）和自适应大邻域搜索（ALNS）进行任务分配。

Result: 比较评估显示，所提出的方法在碰撞避免和任务分配方面的表现优于现有方法。

Conclusion: 所提出的方法在避免碰撞和任务分配方面优于现有方法。

Abstract: Multi-Agent Path Finding (MAPF) has gained significant attention, with most
research focusing on minimizing collisions and travel time. This paper also
considers energy consumption in the path planning of automated guided vehicles
(AGVs). It addresses two main challenges: i) resolving collisions between AGVs
and ii) assigning tasks to AGVs. We propose a new collision avoidance strategy
that takes both energy use and travel time into account. For task assignment,
we present two multi-objective algorithms: Non-Dominated Sorting Genetic
Algorithm (NSGA) and Adaptive Large Neighborhood Search (ALNS). Comparative
evaluations show that these proposed methods perform better than existing
approaches in both collision avoidance and task assignment.

</details>


### [26] [Robotic Assistant: Completing Collaborative Tasks with Dexterous Vision-Language-Action Models](https://arxiv.org/abs/2510.25713)
*Boshi An,Chenyu Yang,Robert Katzschmann*

Main category: cs.RO

TL;DR: 本文改进了VLA模型以提高人机协作，展示了有效的动作预测和关键限制。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过最小化语言提示，改善灵巧的人机协作能力。

Method: 本文采用预训练的视觉-语言-动作（VLA）模型Open-VLA，结合FiLM调节、辅助意图头和动作空间后处理等方法，进行人机协作。

Result: 通过对多视角的Franka和Mimic手数据集进行实验证明缓慢动作（delta actions）的表现良好，四个主成分能解释约96%的手指关节方差，动作后处理是性能提升的主要驱动因素。

Conclusion: 训练者过拟合特定示范者是本文的主要限制，未来需要解决此问题。

Abstract: We adapt a pre-trained Vision-Language-Action (VLA) model (Open-VLA) for
dexterous human-robot collaboration with minimal language prompting. Our
approach adds (i) FiLM conditioning to visual backbones for task-aware
perception, (ii) an auxiliary intent head that predicts collaborator hand pose
and target cues, and (iii) action-space post-processing that predicts compact
deltas (position/rotation) and PCA-reduced finger joints before mapping to full
commands. Using a multi-view, teleoperated Franka and Mimic-hand dataset
augmented with MediaPipe hand poses, we demonstrate that delta actions are
well-behaved and that four principal components explain ~96% of hand-joint
variance. Ablations identify action post-processing as the primary performance
driver; auxiliary intent helps, FiLM is mixed, and a directional motion loss is
detrimental. A real-time stack (~0.3 s latency on one RTX 4090) composes
"pick-up" and "pass" into a long-horizon behavior. We surface "trainer
overfitting" to specific demonstrators as the key limitation.

</details>


### [27] [A Humanoid Visual-Tactile-Action Dataset for Contact-Rich Manipulation](https://arxiv.org/abs/2510.25725)
*Eunju Kwon,Seungwon Oh,In-Chang Baek,Yucheon Park,Gyungbo Kim,JaeYoung Moon,Yunho Choi,Kyung-Joong Kim*

Main category: cs.RO

TL;DR: 本研究开发了一种针对可变形软物体的类人视觉-触觉动作数据集，以填补现有数据集中对压力条件多样性的缺失，并为理解复杂触觉信号的学习模型奠定基础。


<details>
  <summary>Details</summary>
Motivation: 当前的机器人学习数据集主要集中于刚性物体，未能充分代表真实世界操控中的压力条件多样性，这激励了本研究的开展。

Method: 通过遥操作技术，使用配备灵巧手的类人机器人收集多模态交互数据，涵盖不同的压力条件。

Result: 构建了一个新的数据集，能够支持对可变形软物体的操控学习，同时促进了对高级优化策略模型的未来研究。

Conclusion: 该研究提出了一种适用于操控可变形软物体的视觉-触觉-动作数据集，为机器人的学习提供了丰富的数据源，并推动了针对复杂触觉信号的研究。

Abstract: Contact-rich manipulation has become increasingly important in robot
learning. However, previous studies on robot learning datasets have focused on
rigid objects and underrepresented the diversity of pressure conditions for
real-world manipulation. To address this gap, we present a humanoid
visual-tactile-action dataset designed for manipulating deformable soft
objects. The dataset was collected via teleoperation using a humanoid robot
equipped with dexterous hands, capturing multi-modal interactions under varying
pressure conditions. This work also motivates future research on models with
advanced optimization strategies capable of effectively leveraging the
complexity and diversity of tactile signals.

</details>


### [28] [Modeling Collapse of Steered Vine Robots Under Their Own Weight](https://arxiv.org/abs/2510.25727)
*Ciera McFarland,Margaret McGuinness*

Main category: cs.RO

TL;DR: 本文提出了一种全面的坍塌模型，用于预测软性生长机器人在面临环境间隙时的坍塌行为。


<details>
  <summary>Details</summary>
Motivation: 解决在有限空间内移动的软性机器人在面对环境间隙时坍塌的问题，以提升其导航能力。

Method: 通过真形状信息和尾部张力来预测机器人在不同环境中的坍塌长度，并对无真形状信息的机器人的坍塌进行了验证。

Result: 模型准确预测了不同机器人的坍塌趋势，尤其是在缺乏支撑的情况下。

Conclusion: 该模型能够为不同形状和材料的机器人提供坍塌预测，有助于其在3D导航任务中的成功。

Abstract: Soft, vine-inspired growing robots that move by eversion are highly mobile in
confined environments, but, when faced with gaps in the environment, they may
collapse under their own weight while navigating a desired path. In this work,
we present a comprehensive collapse model that can predict the collapse length
of steered robots in any shape using true shape information and tail tension.
We validate this model by collapsing several unsteered robots without true
shape information. The model accurately predicts the trends of those
experiments. We then attempt to collapse a robot steered with a single actuator
at different orientations. Our models accurately predict collapse when it
occurs. Finally, we demonstrate how this could be used in the field by having a
robot attempt a gap-crossing task with and without inflating its actuators. The
robot needs its actuators inflated to cross the gap without collapsing, which
our model supports. Our model has been specifically tested on straight and
series pouch motor-actuated robots made of non-stretchable material, but it
could be applied to other robot variations. This work enables us to model the
robot's collapse behavior in any open environment and understand the parameters
it needs to succeed in 3D navigation tasks.

</details>


### [29] [GET-USE: Learning Generalized Tool Usage for Bimanual Mobile Manipulation via Simulated Embodiment Extensions](https://arxiv.org/abs/2510.25754)
*Bohan Wu,Paul de La Sayette,Li Fei-Fei,Roberto Martín-Martín*

Main category: cs.RO

TL;DR: 本研究提出了GeT-USE，通过扩展机器人的体现方式，以更好地选择和使用工具。


<details>
  <summary>Details</summary>
Motivation: 提高机器人使用随机物体作为工具的能力，以增强其通用性和解决问题的能力

Method: 提出GeT-USE，一个两步程序

Result: GeT-USE在三个基于视觉的双手移动操控工具使用任务中，成功率提高了30-60%

Conclusion: 通过探索机器人的体现扩展，能够识别最有利于任务的通用工具几何形状，从而实现更加通用的工具使用。

Abstract: The ability to use random objects as tools in a generalizable manner is a
missing piece in robots' intelligence today to boost their versatility and
problem-solving capabilities. State-of-the-art robotic tool usage methods
focused on procedurally generating or crowd-sourcing datasets of tools for a
task to learn how to grasp and manipulate them for that task. However, these
methods assume that only one object is provided and that it is possible, with
the correct grasp, to perform the task; they are not capable of identifying,
grasping, and using the best object for a task when many are available,
especially when the optimal tool is absent. In this work, we propose GeT-USE, a
two-step procedure that learns to perform real-robot generalized tool usage by
learning first to extend the robot's embodiment in simulation and then
transferring the learned strategies to real-robot visuomotor policies. Our key
insight is that by exploring a robot's embodiment extensions (i.e., building
new end-effectors) in simulation, the robot can identify the general tool
geometries most beneficial for a task. This learned geometric knowledge can
then be distilled to perform generalized tool usage tasks by selecting and
using the best available real-world object as tool. On a real robot with 22
degrees of freedom (DOFs), GeT-USE outperforms state-of-the-art methods by
30-60% success rates across three vision-based bimanual mobile manipulation
tool-usage tasks.

</details>


### [30] [STITCH 2.0: Extending Augmented Suturing with EKF Needle Estimation and Thread Management](https://arxiv.org/abs/2510.25768)
*Kush Hari,Ziyang Chen,Hansoul Kim,Ken Goldberg*

Main category: cs.RO

TL;DR: STITCH 2.0是一个改进的手术缝合机器人，具有更好的缝合性能和效率。


<details>
  <summary>Details</summary>
Motivation: 由于外科医生缝合技能的差异以及现有机器人缝合技术的局限性，亟需开发更高效的缝合机器人。

Method: 引入了七项改进，包括改进的EKF针头姿态估计、新的线绳解缠方法和自动化的3D缝合对齐算法。

Result: STITCH 2.0在15次试验中平均实现74.4%的伤口闭合率，与前一个基线相比，缝合次数增加了66%，所需时间减少了38%。当允许两次人类干预时，达到100%的伤口闭合率。

Conclusion: STITCH 2.0在许多方面超越了STITCH 1.0，提供了更高的缝合闭合率和更快的操作速度。

Abstract: Surgical suturing is a high-precision task that impacts patient healing and
scarring. Suturing skill varies widely between surgeons, highlighting the need
for robot assistance. Previous robot suturing works, such as STITCH 1.0 [1],
struggle to fully close wounds due to inaccurate needle tracking and poor
thread management. To address these challenges, we present STITCH 2.0, an
elevated augmented dexterity pipeline with seven improvements including:
improved EKF needle pose estimation, new thread untangling methods, and an
automated 3D suture alignment algorithm. Experimental results over 15 trials
find that STITCH 2.0 on average achieves 74.4% wound closure with 4.87 sutures
per trial, representing 66% more sutures in 38% less time compared to the
previous baseline. When two human interventions are allowed, STITCH 2.0
averages six sutures with 100% wound closure rate. Project website:
https://stitch-2.github.io/

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [31] [Modelling the Interplay of Eye-Tracking Temporal Dynamics and Personality for Emotion Detection in Face-to-Face Settings](https://arxiv.org/abs/2510.24720)
*Meisam J. Seikavandi,Jostein Fimland,Fabricio Batista Narcizo,Maria Barrett,Ted Vucurevich,Jesper Bünsow Boldt,Andrew Burke Dittberner,Paolo Burelli*

Main category: cs.HC

TL;DR: 本研究提出了一种基于个性特征的多模态框架，通过整合眼动追踪、五大人格特征和上下文刺激线索来预测人类情感。


<details>
  <summary>Details</summary>
Motivation: 人机交互中对人类情感的准确识别对于提高互动质量至关重要。

Method: 通过眼动追踪、个性评估和情感评分，对73名参与者在观看视频时的数据进行神经网络模型分析。

Result: 使用该模型能够显著提升情感识别的准确性，尤其在感知情感和感受情感的分类中有显著增益。

Conclusion: 结合生理、性格和上下文信息有助于提高情感识别的准确性，推动情感计算的发展。

Abstract: Accurate recognition of human emotions is critical for adaptive
human-computer interaction, yet remains challenging in dynamic,
conversation-like settings. This work presents a personality-aware multimodal
framework that integrates eye-tracking sequences, Big Five personality traits,
and contextual stimulus cues to predict both perceived and felt emotions.
Seventy-three participants viewed speech-containing clips from the CREMA-D
dataset while providing eye-tracking signals, personality assessments, and
emotion ratings. Our neural models captured temporal gaze dynamics and fused
them with trait and stimulus information, yielding consistent gains over SVM
and literature baselines. Results show that (i) stimulus cues strongly enhance
perceived-emotion predictions (macro F1 up to 0.77), while (ii) personality
traits provide the largest improvements for felt emotion recognition (macro F1
up to 0.58). These findings highlight the benefit of combining physiological,
trait-level, and contextual information to address the inherent subjectivity of
emotion. By distinguishing between perceived and felt responses, our approach
advances multimodal affective computing and points toward more personalized and
ecologically valid emotion-aware systems.

</details>


### [32] [AmarDoctor: An AI-Driven, Multilingual, Voice-Interactive Digital Health Application for Primary Care Triage and Patient Management to Bridge the Digital Health Divide for Bengali Speakers](https://arxiv.org/abs/2510.24724)
*Nazmun Nahar,Ritesh Harshad Ruparel,Shariar Kabir,Sumaiya Tasnia Khan,Shyamasree Saha,Mamunur Rashid*

Main category: cs.HC

TL;DR: AmarDoctor是一款专为孟加拉语用户设计的多语言数字健康应用，利用AI支持提升医疗服务效率，临床表现超越多位医生。


<details>
  <summary>Details</summary>
Motivation: 为应对讲孟加拉语人群在数字医疗服务中的不足，设计一款能提供全面患者分诊和临床决策支持的数字健康应用。

Method: 通过自适应问答算法和语音交互AI助手为患者提供评估指导，同时为临床医生提供AI驱动的决策支持，基于临床小案例进行验证。

Result: AmarDoctor在诊断精度和专业推荐准确性方面显著优于传统医生。

Conclusion: AmarDoctor在临床准确性及工作效率上表现优异，能够有效填补数字医疗服务的空白。

Abstract: This study presents AmarDoctor, a multilingual voice-interactive digital
health app designed to provide comprehensive patient triage and AI-driven
clinical decision support for Bengali speakers, a population largely
underserved in access to digital healthcare. AmarDoctor adopts a data-driven
approach to strengthen primary care delivery and enable personalized health
management. While platforms such as AdaHealth, WebMD, Symptomate, and K-Health
have become popular in recent years, they mainly serve European demographics
and languages. AmarDoctor addresses this gap with a dual-interface system for
both patients and healthcare providers, supporting three major Bengali
dialects. At its core, the patient module uses an adaptive questioning
algorithm to assess symptoms and guide users toward the appropriate specialist.
To overcome digital literacy barriers, it integrates a voice-interactive AI
assistant that navigates users through the app services. Complementing this,
the clinician-facing interface incorporates AI-powered decision support that
enhances workflow efficiency by generating structured provisional diagnoses and
treatment recommendations. These outputs inform key services such as
e-prescriptions, video consultations, and medical record management. To
validate clinical accuracy, the system was evaluated against a gold-standard
set of 185 clinical vignettes developed by experienced physicians.
Effectiveness was further assessed by comparing AmarDoctor performance with
five independent physicians using the same vignette set. Results showed
AmarDoctor achieved a top-1 diagnostic precision of 81.08 percent (versus
physicians average of 50.27 percent) and a top specialty recommendation
precision of 91.35 percent (versus physicians average of 62.6 percent).

</details>


### [33] [Beyond Models: A Framework for Contextual and Cultural Intelligence in African AI Deployment](https://arxiv.org/abs/2510.24729)
*Qness Ndlovu*

Main category: cs.HC

TL;DR: 本论文提出了一种新的CCI框架，使AI系统能够理解文化背景，从而更好地服务于资源有限市场，特别是在非洲的应用。


<details>
  <summary>Details</summary>
Motivation: 非洲市场的有效部署需要不同的架构决策，特别是在全球AI开发侧重于模型性能和计算规模的背景下。

Method: 采用设计科学方法，通过一个服务侨民社区的跨境购物平台验证CCI框架的有效性，收集了用户的交互数据。

Result: 提出了上下文化和文化智能（CCI）框架，通过本地相关、情感智能和经济包容性的设计，使AI系统能够处理文化意义，而不只是数据模式。

Conclusion: CCI框架挑战了硅谷的设计惯例，同时为资源有限市场的公平AI部署提供了可操作的框架。

Abstract: While global AI development prioritizes model performance and computational
scale, meaningful deployment in African markets requires fundamentally
different architectural decisions. This paper introduces Contextual and
Cultural Intelligence (CCI) -- a systematic framework enabling AI systems to
process cultural meaning, not just data patterns, through locally relevant,
emotionally intelligent, and economically inclusive design. Using design
science methodology, we validate CCI through a production AI-native
cross-border shopping platform serving diaspora communities. Key empirical
findings: 89% of users prefer WhatsApp-based AI interaction over traditional
web interfaces (n=602, chi-square=365.8, p<0.001), achieving 536 WhatsApp users
and 3,938 total conversations across 602 unique users in just 6 weeks, and
culturally informed prompt engineering demonstrates sophisticated understanding
of culturally contextualized queries, with 89% family-focused commerce patterns
and natural code-switching acceptance. The CCI framework operationalizes three
technical pillars: Infrastructure Intelligence (mobile-first, resilient
architectures), Cultural Intelligence (multilingual NLP with social context
awareness), and Commercial Intelligence (trust-based conversational commerce).
This work contributes both theoretical innovation and reproducible
implementation patterns, challenging Silicon Valley design orthodoxies while
providing actionable frameworks for equitable AI deployment across
resource-constrained markets.

</details>


### [34] [Human- vs. AI-generated tests: dimensionality and information accuracy in latent trait evaluation](https://arxiv.org/abs/2510.24739)
*Mario Angelelli,Morena Oliva,Serena Arima,Enrico Ciavolino*

Main category: cs.HC

TL;DR: 研究比较了AI生成的问卷与人类开发的问卷在心理测量中的应用，发现AI生成问卷存在维度和信息分布的差异。


<details>
  <summary>Details</summary>
Motivation: 探讨AI和大型语言模型在社会与心理研究中的应用潜力，尤其是生成和定制测量工具。

Method: 采用贝叶斯分级响应模型评估AI生成的问卷的心理测量特性。

Result: AI生成问卷表面 wording 相似，但在维度和信息分布上存在显著差异。

Conclusion: AI生成的测量工具在效度和可解释性上存在问题，需应用统计准确性测度加以验证。

Abstract: Artificial Intelligence (AI) and large language models (LLMs) are
increasingly used in social and psychological research. Among potential
applications, LLMs can be used to generate, customise, or adapt measurement
instruments. This study presents a preliminary investigation of AI-generated
questionnaires by comparing two ChatGPT-based adaptations of the Body Awareness
Questionnaire (BAQ) with the validated human-developed version. The AI
instruments were designed with different levels of explicitness in content and
instructions on construct facets, and their psychometric properties were
assessed using a Bayesian Graded Response Model. Results show that although
surface wording between AI and original items was similar, differences emerged
in dimensionality and in the distribution of item and test information across
latent traits. These findings illustrate the importance of applying statistical
measures of accuracy to ensure the validity and interpretability of AI-driven
tools.

</details>


### [35] [Efficiency Without Cognitive Change: Evidence from Human Interaction with Narrow AI Systems](https://arxiv.org/abs/2510.24893)
*María Angélica Benítez,Rocío Candela Ceballos,Karina Del Valle Molina,Sofía Mundo Araujo,Sofía Evangelina Victorio Villaroel,Nadia Justel*

Main category: cs.HC

TL;DR: 短期接触狭义AI工具提升了任务效率，但未改变认知能力。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探讨人工智能与人类认知的整合是否仅仅是提升效率，还是会改变思维方式。

Method: 研究采用实验设计，30名年轻成人参与为期七周的研究，其中包括四周的在线干预，涉及有和没有AI支持的认知任务。

Result: 本研究发现，短期使用狭义的人工智能工具提高了任务的完成效率，但并未显著提升核心认知能力。

Conclusion: 目前的狭义AI系统作为认知支架，通过提高效率而非重新塑造思维能力，强调了需要促进批判性和自主思维的道德和教育框架。

Abstract: The growing integration of artificial intelligence (AI) into human cognition
raises a fundamental question: does AI merely improve efficiency, or does it
alter how we think? This study experimentally tested whether short-term
exposure to narrow AI tools enhances core cognitive abilities or simply
optimizes task performance. Thirty young adults completed standardized
neuropsychological assessments embedded in a seven-week protocol with a
four-week online intervention involving problem-solving and verbal
comprehension tasks, either with or without AI support (ChatGPT). While
AI-assisted participants completed several tasks faster and more accurately, no
significant pre-post differences emerged in standardized measures of problem
solving or verbal comprehension. These results demonstrate efficiency gains
without cognitive change, suggesting that current narrow AI systems serve as
cognitive scaffolds extending performance without transforming underlying
mental capacities. The findings highlight the need for ethical and educational
frameworks that promote critical and autonomous thinking in an increasingly
AI-augmented cognitive ecology.

</details>


### [36] [OrchVis: Hierarchical Multi-Agent Orchestration for Human Oversight](https://arxiv.org/abs/2510.24937)
*Jieyu Zhou*

Main category: cs.HC

TL;DR: OrchVis是一个多智能体编排框架，通过视觉化和自动验证简化人类对智能体协作的监督。


<details>
  <summary>Details</summary>
Motivation: 研究复杂的多智能体协作系统，使人类能够更好地监督和管理工作流。

Method: 通过分层目标对齐、任务分配和冲突解决来实现智能体间的有效协作。

Result: 提出了OrchVis框架，能够可视化、验证和协调LLM基础的多智能体协作。

Conclusion: OrchVis框架通过透明可视化与自适应自主性，推动了以人为中心的多智能体系统设计。

Abstract: We introduce OrchVis, a multi-agent orchestration framework that visualizes,
verifies, and coordinates goal-driven collaboration among LLM-based agents.
Through hierarchical goal alignment, task assignment, and conflict resolution,
OrchVis enables humans to supervise complex multi-agent workflows without
micromanaging each step. The system parses user intent into structured goals,
monitors execution via automated verification, and exposes inter-agent
dependencies through an interactive planning panel. When conflicts arise, users
can explore system-proposed alternatives and selectively replan. OrchVis
advances human-centered design for multi-agent systems by combining transparent
visualization with adaptive autonomy.

</details>


### [37] [CGM-Led Multimodal Tracking with Chatbot Support: An Autoethnography in Sub-Health](https://arxiv.org/abs/2510.25381)
*Dongyijie Primo Pan,Lan Luo,Yike Wang,Pan Hui*

Main category: cs.HC

TL;DR: 本研究探讨了连续血糖监测如何与多种数字设备指标结合，利用聊天机器人提供个性化支持，从而改善亚健康人群的生活方式。


<details>
  <summary>Details</summary>
Motivation: 代谢障碍是全球健康面临的紧迫挑战，中国负担最重。虽然连续血糖监测（CGM）在糖尿病护理中发挥了重大作用，但其对亚健康人群（如超重、前糖尿病或焦虑人群）的支持潜力尚未被充分探讨。

Method: 通过六周的自我民族志研究，结合CGM和数字设备的数据，以及提供个性化反思和解释的聊天机器人。

Result: 研究表明，CGM引导的数据优先多模式跟踪和对话支持结合，改变了人们在饮食、活动、压力和健康等方面的日常实践。

Conclusion: 本研究扩展了CGM在临床糖尿病之外的研究，表明基于LLM的代理如何支持亚健康人群的预防健康和反思。

Abstract: Metabolic disorders present a pressing global health challenge, with China
carrying the world's largest burden. While continuous glucose monitoring (CGM)
has transformed diabetes care, its potential for supporting sub-health
populations -- such as individuals who are overweight, prediabetic, or anxious
-- remains underexplored. At the same time, large language models (LLMs) are
increasingly used in health coaching, yet CGM is rarely incorporated as a
first-class signal. To address this gap, we conducted a six-week
autoethnography, combining CGM with multimodal indicators captured via common
digital devices and a chatbot that offered personalized reflections and
explanations of glucose fluctuations. Our findings show how CGM-led, data-first
multimodal tracking, coupled with conversational support, shaped everyday
practices of diet, activity, stress, and wellbeing. This work contributes to
HCI by extending CGM research beyond clinical diabetes and demonstrating how
LLM-driven agents can support preventive health and reflection in at-risk
populations.

</details>


### [38] [Small Talk, Big Impact? LLM-based Conversational Agents to Mitigate Passive Fatigue in Conditional Automated Driving](https://arxiv.org/abs/2510.25421)
*Lewis Cockram,Yueteng Yu,Jorge Pardo,Xiaomeng Li,Andry Rakotonirainy,Jonny Kuo,Sebastien Demmel,Mike Lenné,Ronald Schroeter*

Main category: cs.HC

TL;DR: 本研究探讨了在条件自动驾驶中，基于大型语言模型的对话代理对驾驶员疲劳的影响，发现其促进了警觉性并提高了用户对未来使用此类系统的意图。


<details>
  <summary>Details</summary>
Motivation: 被动疲劳在条件自动驾驶中可能危害驾驶员的准备性和安全性，因此需要有效的干预措施来维持驾驶员警觉性。

Method: 通过实车测试、视频录像分析、睡意评估和访谈，研究了驾驶员与对话代理的交互及其对警觉性的影响。

Result: 研究结果表明，基于大型语言模型的对话代理可以有效支持驾驶员的警觉性，对减少被动疲劳的影响起到积极作用。

Conclusion: 该研究强调了对话代理作为主动人机接口干预的潜力，并揭示了不同用户群体对其接受度的差异，为未来的适应性设计提供了依据。

Abstract: Passive fatigue during conditional automated driving can compromise driver
readiness and safety. This paper presents findings from a test-track study with
40 participants in a real-world rural automated driving scenario. In this
scenario, a Large Language Model (LLM) based conversational agent (CA) was
designed to check in with drivers and re-engage them with their surroundings.
Drawing on in-car video recordings, sleepiness ratings and interviews, we
analysed how drivers interacted with the agent and how these interactions
shaped alertness. Users found the CA helpful for supporting vigilance during
passive fatigue. Thematic analysis of acceptability further revealed three user
preference profiles that implicate future intention to use CAs. Positioning
empirically observed profiles within existing CA archetype frameworks
highlights the need for adaptive design sensitive to diverse user groups. This
work underscores the potential of CAs as proactive Human-Machine Interface
(HMI) interventions, demonstrating how natural language can support
context-aware interaction during automated driving.

</details>


### [39] [Psychoacoustic assessment of synthetic sounds for electric vehicles in a virtual reality experiment](https://arxiv.org/abs/2510.25593)
*Pavlo Bazilinskyy,Md Shadab Alam,Roberto Merino-Martınez*

Main category: cs.HC

TL;DR: 该研究旨在优化电动车的外部声音设计，以提高可注意性而减少噪音干扰。


<details>
  <summary>Details</summary>
Motivation: 研究电动车的外部声音信号，以提高事故易发路用户的可检测性

Method: 通过虚拟现实场景的听觉实验

Result: 心理声学声质量指标比传统声学指标更有效地预测烦扰评分

Conclusion: 本研究支持电动车外部声音标准的有效开发，旨在提升行人安全并减少噪音污染。

Abstract: The growing adoption of electric vehicles, known for their quieter operation
compared to internal combustion engine vehicles, raises concerns about their
detectability, particularly for vulnerable road users. To address this,
regulations mandate the inclusion of exterior sound signals for electric
vehicles, specifying minimum sound pressure levels at low speeds. These
synthetic exterior sounds are often used in noisy urban environments, creating
the challenge of enhancing detectability without introducing excessive noise
annoyance. This study investigates the design of synthetic exterior sound
signals that balance high noticeability with low annoyance. An audiovisual
experiment with 14 participants was conducted using 15 virtual reality
scenarios featuring a passing car. The scenarios included various sound
signals, such as pure, intermittent, and complex tones at different
frequencies. Two baseline cases, a diesel engine and only tyre noise, were also
tested. Participants rated sounds for annoyance, noticeability, and
informativeness using 11-point ICBEN scales. The findings highlight how
psychoacoustic sound quality metrics predict annoyance ratings better than
conventional sound metrics, providing insight into optimising sound design for
electric vehicles. By improving pedestrian safety while minimising noise
pollution, this research supports the development of effective and
user-friendly exterior sound standards for electric vehicles.

</details>


### [40] [ggtime: A Grammar of Temporal Graphics](https://arxiv.org/abs/2510.25656)
*Cynthia A. Huang,Mitchell O'Hara-Wild,Rob J. Hyndman,Matthew Kay*

Main category: cs.HC

TL;DR: 本文提出了一种新的时间图形语法及其软件实现，以更好地处理时间数据的复杂性。


<details>
  <summary>Details</summary>
Motivation: 可视化时间变化对从过去学习和预测未来至关重要，但现有工具在准确表示时间语义时常常存在困难。

Method: 开发了一种声明性语法，通过组成元素支持线性、循环、准循环等不同的可视化需求，并实现不规则持续时间的标准化以及跨不同粒度和时区的时间点对齐。

Result: 提出了一种时间图形的语法和相应的软件实现'ggtime'，可用于视觉化时间数据。

Conclusion: 该语法支持不同时间粒度的可视化，便于跨时间维度的导航，同时保持时间语义的准确性。

Abstract: Visualizing changes over time is fundamental to learning from the past and
anticipating the future. However, temporal semantics can be complicated, and
existing visualization tools often struggle to accurately represent these
complexities. It is common to use bespoke plot helper functions designed to
produce specific graphics, due to the absence of flexible general tools that
respect temporal semantics. We address this problem by proposing a grammar of
temporal graphics, and an associated software implementation, 'ggtime', that
encodes temporal semantics into a declarative grammar for visualizing temporal
data. The grammar introduces new composable elements that support visualization
across linear, cyclical, quasi-cyclical, and other granularities;
standardization of irregular durations; and alignment of time points across
different granularities and time zones. It is designed for interoperability
with other semantic variables, allowing navigation across the space of
visualizations while preserving temporal semantics.

</details>


### [41] [User Misconceptions of LLM-Based Conversational Programming Assistants](https://arxiv.org/abs/2510.25662)
*Gabrielle O'Brien,Antonio Pedro Santos Alves,Sebastian Baltes,Grischa Liebel,Mircea Lungu,Marcos Kalinowski*

Main category: cs.HC

TL;DR: 本研究探讨了用户对LLM编程助手的误解，强调需要更清晰的能力沟通，以优化编程实践。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）作为编程助手的普及，用户对其功能的误解可能导致不利的编程实践和质量控制不足。

Method: 采用两阶段的方法，首先列举用户的误解，然后通过定性分析检验这些问题在真实Python编程对话中的表现。

Result: 证据显示用户对LLM助手功能的期望存在偏差，尤其是在网络访问、代码执行和非文本输出生成方面，并且显示出在调试和优化程序时存在更深层次的概念问题。

Conclusion: LLM工具需更明确地沟通其编程能力，以减少用户的误解和过度依赖。

Abstract: Programming assistants powered by large language models (LLMs) have become
widely available, with conversational assistants like ChatGPT proving
particularly accessible to less experienced programmers. However, the varied
capabilities of these tools across model versions and the mixed availability of
extensions that enable web search, code execution, or retrieval-augmented
generation create opportunities for user misconceptions about what systems can
and cannot do. Such misconceptions may lead to over-reliance, unproductive
practices, or insufficient quality control in LLM-assisted programming. Here,
we aim to characterize misconceptions that users of conversational LLM-based
assistants may have in programming contexts. Using a two-phase approach, we
first brainstorm and catalog user misconceptions that may occur, and then
conduct a qualitative analysis to examine whether these conceptual issues
surface in naturalistic Python-programming conversations with an LLM-based
chatbot drawn from an openly available dataset. Indeed, we see evidence that
some users have misplaced expectations about the availability of LLM-based
chatbot features like web access, code execution, or non-text output
generation. We also see potential evidence for deeper conceptual issues around
the scope of information required to debug, validate, and optimize programs.
Our findings reinforce the need for designing LLM-based tools that more clearly
communicate their programming capabilities to users.

</details>
