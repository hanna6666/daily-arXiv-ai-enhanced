<div id=toc></div>

# Table of Contents

- [cs.HC](#cs.HC) [Total: 5]
- [cs.RO](#cs.RO) [Total: 28]


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [1] [Can You Keep Calm?: Adaptive Gameplay using Heart Rate as a Controller](https://arxiv.org/abs/2511.19934)
*Md Mosharaf Hossan,Rifat Ara Tasnim,Farjana Z Eishita*

Main category: cs.HC

TL;DR: 本研究开发了一款心率控制的游戏，旨在通过生物反馈帮助玩家管理压力，并发现其有效性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索如何利用生物反馈技术提高游戏在心理健康干预中的有效性。

Method: 通过受控实验，测试心率控制游戏对玩家体验以及压力管理的影响。

Result: 实验结果表明，心率控制的游戏能减轻负面情绪，增加积极情绪，并降低心脏反应。

Conclusion: 心率控制的游戏能够有效降低负面情绪并提升积极情绪，同时减少玩家的心脏反应，显示出生物反馈游戏在心理健康支持中的潜力。

Abstract: Serious games for health are designed with specific health objectives and are increasingly being used in mental health interventions. Leveraging sensor equipped handheld devices such as smartphones and smartwatches, these games can provide accessible and engaging therapeutic environments. This study introduces a heart rate (HR) controlled game to aid players manage stress by adjusting gameplay according to their biometric feedback. We aimed to determine how HR-based controls influence their experience and if it can be used to reduce stress. Findings from a controlled experiment revealed that HR controlled gameplay reduced negative and increased positive emotions. Also, players exhibited relatively less cardiac reactivity in HR adaptive target based gameplay. This highlights the promise of biometric feedback based gamified digital environments in supporting accessible mental health support.

</details>


### [2] [Editing with AI: How Doctors Refine LLM-Generated Answers to Patient Queries](https://arxiv.org/abs/2511.19940)
*Rahul Sharma,Pragnya Ramjee,Kaushik Murali,Mohit Jain*

Main category: cs.HC

TL;DR: 大语言模型在医疗领域生成草稿回复的有效性经历了多个编辑方式的测试，显示出人工干预的重要性和不同编辑方式的权衡。


<details>
  <summary>Details</summary>
Motivation: 随着患者信息需求增加，数字患者消息的激增对医疗系统造成压力，大语言模型提供了帮助医生生成回复的潜力。

Method: 通过混合方法研究，九名眼科医生在三种条件下回答了144个白内障手术问题，包括自写、直接编辑LLM草稿和基于指令的间接编辑。

Result: LLM输出通常准确，但存在偶尔错误和自动化偏见，编辑方式展示了不同的工作负荷和潜在错误。

Conclusion: 需要关注人类监督的重要性，并考虑开发安全、可扩展的医疗沟通系统。

Abstract: Patients frequently seek information during their medical journeys, but the rising volume of digital patient messages has strained healthcare systems. Large language models (LLMs) offer promise in generating draft responses for clinicians, yet how physicians refine these drafts remains underexplored. We present a mixed-methods study with nine ophthalmologists answering 144 cataract surgery questions across three conditions: writing from scratch, directly editing LLM drafts, and instruction-based indirect editing. Our quantitative and qualitative analyses reveal that while LLM outputs were generally accurate, occasional errors and automation bias revealed the need for human oversight. Contextualization--adapting generic answers to local practices and patient expectations--emerged as a dominant form of editing. Editing workflows revealed trade-offs: indirect editing reduced effort but introduced errors, while direct editing ensured precision but with higher workload. We conclude with design and policy implications for building safe, scalable LLM-assisted clinical communication systems.

</details>


### [3] [Adaptive LLM Agents: Toward Personalized Empathetic Care](https://arxiv.org/abs/2511.20080)
*Priyanka Singh,Sebastian Von Mammen*

Main category: cs.HC

TL;DR: 文章探讨了一种新的对话系统框架，该框架能够根据用户的心理状况调整互动方式。


<details>
  <summary>Details</summary>
Motivation: 目前的心理健康对话系统通常基于固定的对话模式，缺乏个性化。

Method: 采用设计虚构的方法，通过情节场景嵌入架构，探索智能体对护理获取和治疗关系的影响。

Result: 本文提出了一个基于大型语言模型的自适应框架，旨在根据用户的心理状态个性化治疗交互。

Conclusion: 该框架展示了如何结合临床个性化、技术可行性与情景分析来设计负责的心理健康支持伙伴。

Abstract: Current mental-health conversational systems are usually based on fixed, generic dialogue patterns. This paper proposes an adaptive framework based on large language models that aims to personalize therapeutic interaction according to a user's psychological state, quantified with the Acceptance of Illness Scale (AIS). The framework defines three specialized agents, L, M, and H, each linked to a different level of illness acceptance, and adjusts conversational behavior over time using continuous feedback signals. The AIS-stratified architecture is treated as a diegetic prototype placed in a plausible near-future setting and examined through the method of design fiction. By embedding the architecture in narrative scenarios, the study explores how such agents might influence access to care and therapeutic relationship. The goal is to show how clinically informed personalization, technical feasibility, and speculative scenario analysis can together inform the responsible design of LLM-based companions for mental-health support.

</details>


### [4] [GUIDAETA -- A Versatile Interactions Dataset with extensive Context Information and Metadata](https://arxiv.org/abs/2511.20328)
*Stefan Lengauer,Sarah Annabelle Von Götz,Marie-Therese Hoesch,Florian Dieter Steinwidder,Mariia Tytarenko,Michael Bedek,Tobias Schreck*

Main category: cs.HC

TL;DR: 提出了一个新数据集GUIDAETA，包含丰富的用户交互数据，适用于多个研究领域。


<details>
  <summary>Details</summary>
Motivation: 研究领域对结构化交互数据的需求日益增长，但可用的数据集有限，尤其是在需要特定上下文信息的情况下。

Method: 通过大规模指导用户研究收集数据，涉及250名用户和716个完成的任务，涵盖2.39百万鼠标和键盘事件。

Result: 本文介绍了一个新的数据集GUIDAETA，旨在解决多领域研究对交互数据的需求。该数据集来自于一项大规模的指导用户研究，超过250名用户完成了三项预定义的信息检索任务，提供了丰富的结构化数据，适用于各种应用场景。

Conclusion: GUIDAETA是一个多用途的数据集，能够为不同领域的研究提供支持，尤其是在需要结构化和上下文数据的场景中。

Abstract: Interaction data is widely used in multiple domains such as cognitive science, visualization, human computer interaction, and cybersecurity, among others. Applications range from cognitive analyses over user/behavior modeling, adaptation, recommendations, to (user/bot) identification/verification. That is, research on these applications - in particular those relying on learned models - require copious amounts of structured data for both training and evaluation. Different application domains thereby impose different requirements. I.e., for some purposes it is vital that the data is based on a guided interaction process, meaning that monitored subjects pursued a given task, while other purposes require additional context information, such as widget interactions or metadata. Unfortunately, the amount of publicly available datasets is small and their respective applicability for specific purposes limited. We present GUIDEd Interaction DATA (GUIDAETA) - a new dataset, collected from a large-scale guided user study with more than 250 users, each working on three pre-defined information retrieval tasks using a custom-built consumer information system. Besides being larger than most comparable datasets - with 716 completed tasks, 2.39 million mouse and keyboard events (2.35 million and 40 thousand, respectively) and a total observation period of almost 50 hours - its interactions exhibit encompassing context information in the form of widget information, triggered (system) events and associated displayed content. Combined with extensive metadata such as sociodemographic user data and answers to explicit feedback questionnaires (regarding perceived usability, experienced cognitive load, pre-knowledge on the information system's topic), GUIDAETA constitutes a versatile dataset, applicable for various research domains and purposes.

</details>


### [5] [A User-customized and Untethered Electro-haptic Device for Immersive Human-Machine Interaction](https://arxiv.org/abs/2511.20578)
*Ziang Cui,Shanyong Wang,Yining Zhao,Yiran Wang,Xingming Wen,Siyuan Chen,Ze Xiong*

Main category: cs.HC

TL;DR: 新开发的电触觉设备通过15个电极提供多维度触觉反馈，提升人机交互的沉浸感和真实感。


<details>
  <summary>Details</summary>
Motivation: 当前的触觉反馈设备普遍存在连线限制、便携性不足和反馈能力有限等问题，影响了人机交互的沉浸感和灵活性。

Method: 采用柔性材料和可打印液态金属墨水制造设备，通过控制电刺激来产生精细的触觉反馈。

Result: 提出了一种灵活、超薄且用户自定义的电触觉设备，能够提供精准的触觉反馈。

Conclusion: 该设备舒适易用，能煽动广泛的触觉感受，显著提高了人机交互的沉浸体验。

Abstract: Haptic feedback is essential for human-machine interaction, as it bridges physical and digital experiences and enables immersive engagement with virtual environments. However, current haptic devices are frequently tethered, lack portability and flexibility. They also have limited ability to deliver fine-grained, multi-dimensional feedback. To address these challenges, we present a flexible, ultra-thin, and user-customized electro-haptic device fabricated with soft materials and printable liquid metal ink. Its highly integrated and lightweight design minimizes interference with natural hand movements while maintaining reliable skin contact. By delivering finely controlled electrical stimulation through 15 electrodes, it can evoke a wide range of tactile sensations that cover diverse interaction scenarios. Our user study demonstrates that the device is comfortable to wear and capable of generating tunable, precise electro-haptic feedback, thereby significantly enhancing immersion and realism in human-machine interactions.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [6] [Discover, Learn, and Reinforce: Scaling Vision-Language-Action Pretraining with Diverse RL-Generated Trajectories](https://arxiv.org/abs/2511.19528)
*Rushuai Yang,Zhiyuan Feng,Tianxiang Zhang,Kaixin Wang,Chuheng Zhang,Li Zhao,Xiu Su,Yi Chen,Jiang Bian*

Main category: cs.RO

TL;DR: 提出了一种信息论模式发现框架DLR，可以生成多种高成功率的行为模式，用于视觉-语言-动作模型的预训练。


<details>
  <summary>Details</summary>
Motivation: 当前的视觉-语言-动作模型预训练需要大量高质量操作轨迹，而人类遥控获取这些数据成本高且难以扩展。

Method: 提出DLR框架，通过信息论方法发现并生成多样化的高成功率行为模式，克服了传统强化学习的局限。

Result: DLR生成的轨迹在多样性和覆盖状态-动作空间方面显著优于标准RL，且在下游任务上效果更佳。

Conclusion: 多模式强化学习作为可扩展的数据引擎，优于单一模式的强化学习，在未见任务上取得更好的预训练效果。

Abstract: Scaling vision-language-action (VLA) model pre-training requires large volumes of diverse, high-quality manipulation trajectories. Most current data is obtained via human teleoperation, which is expensive and difficult to scale. Reinforcement learning (RL) methods learn useful skills through autonomous exploration, making them a viable approach for generating data. However, standard RL training collapses to a narrow execution pattern, limiting its utility for large-scale pre-training. We propose Discover, Lea rn and Reinforce (DLR), an information-theoretic pattern discovery framework that generates multiple distinct, high-success behavioral patterns for VLA pretraining. Empirically, DLR generates a markedly more diverse trajectory corpus on LIBERO. Specifically, it learns multiple distinct, high-success strategies for the same task where standard RL discovers only one, and hence it covers substantially broader regions of the state-action space. When adapted to unseen downstream task suites, VLA models pretrained on our diverse RL data surpass counterparts trained on equal-sized standard RL datasets. Moreover, DLR exhibits positive data-scaling behavior that single-pattern RL lacks. These results position multi-pattern RL as a practical, scalable data engine for embodied foundation models.

</details>


### [7] [A Virtual Mechanical Interaction Layer Enables Resilient Human-to-Robot Object Handovers](https://arxiv.org/abs/2511.19543)
*Omar Faris,Sławomir Tadeja,Fulvio Forni*

Main category: cs.RO

TL;DR: 本文研究了人机物体传递中的机器人动作适应性，提出了虚拟模型控制与增强现实的结合，实验表明该方法在复杂情况下表现良好且获得用户偏好。


<details>
  <summary>Details</summary>
Motivation: 高效的人机物体传递在协作任务中普遍存在，然而实现这一点的过程仍然面临挑战，尤其是物体姿态的复杂变化。

Method: 采用虚拟模型控制和增强现实技术，建立人机交互层强化机器人手动传递的适应能力。

Result: 我们的控制器能够有效应对传递过程中多种不确定性，在用户研究中显示出对所提方法的普遍偏好。

Conclusion: 我们的方法在物体传递过程中展示了良好的适应性和用户偏好，提供了未来机器人控制与人机交互发展的指导。

Abstract: Object handover is a common form of interaction that is widely present in collaborative tasks. However, achieving it efficiently remains a challenge. We address the problem of ensuring resilient robotic actions that can adapt to complex changes in object pose during human-to-robot object handovers. We propose the use of Virtual Model Control to create an interaction layer that controls the robot and adapts to the dynamic changes in the handover process. Additionally, we propose the use of augmented reality to facilitate bidirectional communication between humans and robots during handovers. We assess the performance of our controller in a set of experiments that demonstrate its resilience to various sources of uncertainties, including complex changes to the object's pose during the handover. Finally, we performed a user study with 16 participants to understand human preferences for different robot control profiles and augmented reality visuals in object handovers. Our results showed a general preference for the proposed approach and revealed insights that can guide further development in adapting the interaction with the user.

</details>


### [8] [How Robot Kinematics Influence Human Performance in Virtual Robot-to-Human Handover Tasks](https://arxiv.org/abs/2511.20299)
*Róisín Keenan,Joost C. Dessing*

Main category: cs.RO

TL;DR: 本研究利用虚拟现实探讨了人机交互在任务动态和机器人运动学下的差异，结果表明适当的机器人设计能改善人类沟通的预测准确性和同步性。


<details>
  <summary>Details</summary>
Motivation: 研究机器人与人类的协调合作在现代工作环境中的重要性和变化需求。

Method: 采用VR模拟进行实验，分析任务启动控制、合作伙伴外观、机器人速度模型和对象运动定时等因素对人类表现的影响。

Result: 通过VR实验发现，机器人提供提前和明确的视觉信息与人类自然感知能力之间的最佳结合显著提升了人类的互动表现。

Conclusion: 人机交互设计应考虑人类对生物运动的自然检测能力，以减少机器计算成本和人类的认知负担。

Abstract: Recent advancements in robotics have increased the possibilities for integrating robotic systems into human-involved workplaces, highlighting the need to examine and optimize human-robot coordination in collaborative settings. This study explores human-robot interactions during handover tasks using Virtual Reality (VR) to investigate differences in human motor performance across various task dynamics and robot kinematics. A VR-based robot handover simulation afforded safe and controlled assessments of human-robot interactions. In separate experiments, four potential influences on human performance were examined (1) control over task initiation and robot movement synchrony (temporal and spatiotemporal); (2) partner appearance (human versus robotic); (3) robot velocity profiles (minimum jerk, constant velocity, constant acceleration, and biphasic); and (4) the timing of rotational object motion. Findings across experiments emphasize humans benefit from robots providing early and salient visual information about task-relevant object motion, and advantages of human-like smooth robot trajectories. To varying degrees, these manipulations improved predictive accuracy and synchronization during interaction. This suggests that human-robot interactions should be designed to allow humans to leverage their natural capabilities for detecting biological motion, which conversely may reduce the need for costly robotic computations or added cognitive adaptation on the human side.

</details>


### [9] [Robot-Powered Data Flywheels: Deploying Robots in the Wild for Continual Data Collection and Foundation Model Adaptation](https://arxiv.org/abs/2511.19647)
*Jennifer Grannen,Michelle Pan,Kenneth Llontop,Cherie Ho,Mark Zolotas,Jeannette Bohg,Dorsa Sadigh*

Main category: cs.RO

TL;DR: 本研究提出机器人驱动的数据飞轮，将机器人从基础模型的使用者转变为数据生成者，解决现实世界中的数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 解决基础模型在处理复杂、真实世界数据时的脆弱性，利用机器人收集丰富的数据以改善模型训练。

Method: 将配备基础模型的机器人部署到实际环境中，收集真实世界的数据，同时执行有用任务。

Result: Scanford通过收集来自2103个书架的数据，实现了图书识别性能从32.0%提高到71.8%，并在多语言OCR任务上也显著提升。

Conclusion: 机器人驱动的数据飞轮不仅减轻了人类的工作量，还为基础模型适应现实环境提供了新的途径。

Abstract: Foundation models (FM) have unlocked powerful zero-shot capabilities in vision and language, yet their reliance on internet pretraining data leaves them brittle in unstructured, real-world settings. The messy, real-world data encountered during deployment (e.g. occluded or multilingual text) remains massively underrepresented in existing corpora. Robots, as embodied agents, are uniquely positioned to close this gap: they can act in physical environments to collect large-scale, real-world data that enriches FM training with precisely the examples current models lack. We introduce the Robot-Powered Data Flywheel, a framework that transforms robots from FM consumers into data generators. By deploying robots equipped with FMs in the wild, we enable a virtuous cycle: robots perform useful tasks while collecting real-world data that improves both domain-specific adaptation and domain-adjacent generalization. We instantiate this framework with Scanford, a mobile manipulator deployed in the East Asia Library for 2 weeks. Scanford autonomously scans shelves, identifies books using a vision-language model (VLM), and leverages the library catalog to label images without human annotation. This deployment both aids librarians and produces a dataset to finetune the underlying VLM, improving performance on the domain-specific in-the-wild library setting and on domain-adjacent multilingual OCR benchmarks. Using data collected from 2103 shelves, Scanford improves VLM performance on book identification from 32.0% to 71.8% and boosts domain-adjacent multilingual OCR from 24.8% to 46.6% (English) and 30.8% to 38.0% (Chinese), while saving an ~18.7 hrs of human time. These results highlight how robot-powered data flywheels can both reduce human effort in real deployments and unlock new pathways for continually adapting FMs to the messiness of reality. More details are at: https://scanford-robot.github.io

</details>


### [10] [Gated Uncertainty-Aware Runtime Dual Invariants for Neural Signal-Controlled Robotics](https://arxiv.org/abs/2511.20570)
*Tasha Kim,Oiwi Parker Jones*

Main category: cs.RO

TL;DR: 提出GUARDIAN框架，旨在提高神经信号控制机器人系统的安全性和可靠性，实现高效低延迟的检测和干预。


<details>
  <summary>Details</summary>
Motivation: 确保安全关键辅助系统在用户意图解码中具有可靠性和信任度

Method: GUARDIAN framework for neuro-symbolic verification of neural signal-controlled robotics

Result: 在BNCI2014脑电图数据集上，GUARDIAN实现了94-97%的高安全率，尽管解码器架构轻量且测试准确率低，监测器以100Hz运行并具有亚毫秒决策延迟

Conclusion: GUARDIAN通过合格的响应和可审计的痕迹，有助于将神经证据与可验证的机器人行为联系起来。

Abstract: Safety-critical assistive systems that directly decode user intent from neural signals require rigorous guarantees of reliability and trust. We present GUARDIAN (Gated Uncertainty-Aware Runtime Dual Invariants), a framework for real-time neuro-symbolic verification for neural signal-controlled robotics. GUARDIAN enforces both logical safety and physiological trust by coupling confidence-calibrated brain signal decoding with symbolic goal grounding and dual-layer runtime monitoring. On the BNCI2014 motor imagery electroencephalogram (EEG) dataset with 9 subjects and 5,184 trials, the system performs at a high safety rate of 94-97% even with lightweight decoder architectures with low test accuracies (27-46%) and high ECE confidence miscalibration (0.22-0.41). We demonstrate 1.7x correct interventions in simulated noise testing versus at baseline. The monitor operates at 100Hz and sub-millisecond decision latency, making it practically viable for closed-loop neural signal-based systems. Across 21 ablation results, GUARDIAN exhibits a graduated response to signal degradation, and produces auditable traces from intent, plan to action, helping to link neural evidence to verifiable robot action.

</details>


### [11] [Online Learning-Enhanced High Order Adaptive Safety Control](https://arxiv.org/abs/2511.19651)
*Lishuo Pan,Mattia Catellani,Thales C. Silva,Lorenzo Sabattini,Nora Ayanian*

Main category: cs.RO

TL;DR: 本研究提出了一种利用神经常微分方程的在线学习增强高阶自适应控制屏障函数，以提高条件复杂时的安全性，并在38克微型四旋翼上进行验证。


<details>
  <summary>Details</summary>
Motivation: 随着现代控制问题的复杂性增加，控制屏障函数（CBFs）在优化和学习控制领域作为安全过滤器受到越来越多关注，但模型准确性对于保证其在现实系统中有效至关重要。

Method: 在线学习增强的高阶自适应控制屏障函数

Result: 提出了一种高效且灵活的在线学习增强的高阶自适应控制屏障函数，能够在复杂的时间变化模型扰动下，提高CBF认证系统的安全性。

Conclusion: 通过在38克的微型四旋翼上部署我们的混合自适应CBF控制器，能够在18公里/小时的风速下安全避障，验证了方法的有效性。

Abstract: Control barrier functions (CBFs) are an effective model-based tool to formally certify the safety of a system. With the growing complexity of modern control problems, CBFs have received increasing attention in both optimization-based and learning-based control communities as a safety filter, owing to their provable guarantees. However, success in transferring these guarantees to real-world systems is critically tied to model accuracy. For example, payloads or wind disturbances can significantly influence the dynamics of an aerial vehicle and invalidate the safety guarantee. In this work, we propose an efficient yet flexible online learning-enhanced high-order adaptive control barrier function using Neural ODEs. Our approach improves the safety of a CBF-certified system on the fly, even under complex time-varying model perturbations. In particular, we deploy our hybrid adaptive CBF controller on a 38g nano quadrotor, keeping a safe distance from the obstacle, against 18km/h wind.

</details>


### [12] [Flow-Based Path Planning for Multiple Homogenous UAVs for Outdoor Formation-Flying](https://arxiv.org/abs/2511.19653)
*Mahmud Suhaimi Ibrahim,Shantanu Rahman,Muhammad Samin Hasan,Minhaj Uddin Ahmad,Abdullah Abrar*

Main category: cs.RO

TL;DR: 本文提出了一种流网络方法，能够为多无人机编队生成安全的无碰撞路径。


<details>
  <summary>Details</summary>
Motivation: 多无人机编队飞行中的无碰撞路径规划是最关键的部分。

Method: 构建流网络图、使用图形路径寻找算法找到最小成本路径、实施Ford-Fulkerson方法找到最大流路径。

Result: 在进行最多64架无人机的模拟及3架四旋翼的实际实验后，展示了该方法的有效性。

Conclusion: 该方法能够有效生成安全、无碰撞的路径。

Abstract: Collision-free path planning is the most crucial component in multi-UAV formation-flying (MFF). We use unlabeled homogenous quadcopters (UAVs) to demonstrate the use of a flow network to create complete (inter-UAV) collision-free paths. This procedure has three main parts: 1) Creating a flow network graph from physical GPS coordinates, 2) Finding a path of minimum cost (least distance) using any graph-based path-finding algorithm, and 3) Implementing the Ford-Fulkerson Method to find the paths with the maximum flow (no collision). Simulations of up to 64 UAVs were conducted for various formations, followed by a practical experiment with 3 quadcopters for testing physical plausibility and feasibility. The results of these tests show the efficacy of this method's ability to produce safe, collision-free paths.

</details>


### [13] [Development of a Testbed for Autonomous Vehicles: Integrating MPC Control with Monocular Camera Lane Detection](https://arxiv.org/abs/2511.19655)
*Shantanu Rahman,Nayeb Hasin,Mainul Islam*

Main category: cs.RO

TL;DR: 本文提出一种结合车道识别与模型预测控制的新方法，以提高自主车辆的轨迹跟踪精度与稳定性，仿真结果显示控制器的优越性。


<details>
  <summary>Details</summary>
Motivation: 提高自主车辆在道路上的轨迹跟踪精度和稳定性

Method: 结合车道识别与模型预测控制（MPC）的方法

Result: 在仿真中，最优跟踪轨迹与目标轨迹的均方根误差减少了27.65%

Conclusion: 所开发的控制器展现出高强度的鲁棒性和灵活性，适用于装备摄像头的自主车辆。

Abstract: Autonomous vehicles are becoming popular day by day not only for autonomous road traversal but also for industrial automation, farming and military. Most of the standard vehicles follow the Ackermann style steering mechanism. This has become to de facto standard for large and long faring vehicles. The local planner of an autonomous vehicle controls the low-level vehicle movement upon which the vehicle will perform its motor actuation. In our work, we focus on autonomous vehicles in road and perform experiments to analyze the effect of low-level controllers in the simulation and a real environment. To increase the precision and stability of trajectory tracking in autonomous cars, a novel method that combines lane identification with Model Predictive Control (MPC) is presented. The research focuses on camera-equipped autonomous vehicles and uses methods like edge recognition, sliding window-based straight-line identification for lane line extraction, and dynamic region of interest (ROI) extraction. Next, to follow the identified lane line, an MPC built on a bicycle vehicle dynamics model is created. A single-lane road simulation model is built using ROS Gazebo and tested in order to verify the controller's performance. The root mean square error between the optimal tracking trajectory and the target trajectory was reduced by 27.65% in the simulation results, demonstrating the high robustness and flexibility of the developed controller.

</details>


### [14] [Multi-Agent gatekeeper: Safe Flight Planning and Formation Control for Urban Air Mobility](https://arxiv.org/abs/2511.19691)
*Thomas Marshall Vielmetti,Devansh R Agrawal,Dimitra Panagou*

Main category: cs.RO

TL;DR: 提出了一种新的多代理框架，提供领导-跟随者控制的安全保障，能在复杂的3D环境中有效避免碰撞。


<details>
  <summary>Details</summary>
Motivation: Existing methods lack formal safety guarantees for online planners and adaptability for offline planners in dynamic environments.

Method: Multi-Agent gatekeeper framework for leader-follower formation control

Result: Achieved a 100% collision-avoidance success rate in simulated 3D environments and demonstrated physical feasibility on quadcopters.

Conclusion: 该框架在多代理系统中证明了其有效性，并在现实情况下取得了安全的轨迹控制。

Abstract: We present Multi-Agent gatekeeper, a framework that provides provable safety guarantees for leader-follower formation control in cluttered 3D environments. Existing methods face a trad-off: online planners and controllers lack formal safety guarantees, while offline planners lack adaptability to changes in the number of agents or desired formation. To address this gap, we propose a hybrid architecture where a single leader tracks a pre-computed, safe trajectory, which serves as a shared trajectory backup set for all follower agents. Followers execute a nominal formation-keeping tracking controller, and are guaranteed to remain safe by always possessing a known-safe backup maneuver along the leader's path. We formally prove this method ensures collision avoidance with both static obstacles and other agents. The primary contributions are: (1) the multi-agent gatekeeper algorithm, which extends our single-agent gatekeeper framework to multi-agent systems; (2) the trajectory backup set for provably safe inter-agent coordination for leader-follower formation control; and (3) the first application of the gatekeeper framework in a 3D environment. We demonstrate our approach in a simulated 3D urban environment, where it achieved a 100% collision-avoidance success rate across 100 randomized trials, significantly outperforming baseline CBF and NMPC methods. Finally, we demonstrate the physical feasibility of the resulting trajectories on a team of quadcopters.

</details>


### [15] [Whole-Body Inverse Dynamics MPC for Legged Loco-Manipulation](https://arxiv.org/abs/2511.19709)
*Lukas Molnar,Jin Cheng,Gabriele Fadini,Dongho Kang,Fatemeh Zargarbashi,Stelian Coros*

Main category: cs.RO

TL;DR: 提出了一种基于完整逆动力学的全身模型预测控制框架，用于在动态稳定的情况下实现协调 locomotion 和物体操作。


<details>
  <summary>Details</summary>
Motivation: 解决在操控物体的同时维持 locomotion 稳定性所面临的计划和控制挑战。

Method: 通过全阶逆动力学直接优化关节扭矩的模型预测控制(MPC)方法。

Result: 在Unitree B2四足机器人实验中实现了实时性能，能够完成精细控制的loco-manipulation任务。

Conclusion: 该研究开发的控制框架有效实现了精细的末端执行器控制，并在现实世界的场景中展示了其应用潜力。

Abstract: Loco-manipulation demands coordinated whole-body motion to manipulate objects effectively while maintaining locomotion stability, presenting significant challenges for both planning and control. In this work, we propose a whole-body model predictive control (MPC) framework that directly optimizes joint torques through full-order inverse dynamics, enabling unified motion and force planning and execution within a single predictive layer. This approach allows emergent, physically consistent whole-body behaviors that account for the system's dynamics and physical constraints. We implement our MPC formulation using open software frameworks (Pinocchio and CasADi), along with the state-of-the-art interior-point solver Fatrop. In real-world experiments on a Unitree B2 quadruped equipped with a Unitree Z1 manipulator arm, our MPC formulation achieves real-time performance at 80 Hz. We demonstrate loco-manipulation tasks that demand fine control over the end-effector's position and force to perform real-world interactions like pulling heavy loads, pushing boxes, and wiping whiteboards.

</details>


### [16] [Unifying Perception and Action: A Hybrid-Modality Pipeline with Implicit Visual Chain-of-Thought for Robotic Action Generation](https://arxiv.org/abs/2511.19859)
*Xiangkai Ma,Lekai Xing,Han Zhang,Wenzhong Li,Sanglu Lu*

Main category: cs.RO

TL;DR: VITA框架通过学习视觉和动作的共享离散潜在空间，解决了视觉观察与低级动作之间的模态差距和训练不稳定性问题，从而提升了机器人的感知与运动控制能力。


<details>
  <summary>Details</summary>
Motivation: 传统文本链式思维无法有效捕捉复杂空间环境的场景细节，因此引入视觉先验以指导机器人动作生成。

Method: 提出VITA框架，学习视觉与动作的共享离散潜在空间，通过隐式视觉链式思维生成未来帧预测和机器人动作，内化视觉动态作为运动规划的归纳偏置。

Result: VITA在CALVIN、LIBERO和SimplerEnv上分别提高了14.5%、9.6%和12.1%的性能，并且在六个真实世界任务中平均成功率达到80.5%。

Conclusion: VITA在多个仿真和真实世界环境中展现了最佳性能，证明其作为通用机器人操作模型的潜力。

Abstract: Vision-Language-Action (VLA) models built upon Chain-of-Thought (CoT) have achieved remarkable success in advancing general-purpose robotic agents, owing to its significant perceptual comprehension. Recently, since text-only CoT struggles to adequately capture scene details in complex spatial environments, a highly promising strategy involves leveraging visual priors to guide robotic action generation. Nevertheless, these strategies face two inherent challenges: (i) a modality gap between visual observations and low-level actions, and (ii) unstable training due to competing objectives between visual prediction and action generation. To address these challenges, we propose a Vision-Integrated Trajectory Alignment (VITA) framework that learns a shared discrete latent space for vision and action, enabling joint modeling of perception and motor control. VITA introduces a implicit visual CoT: autoregressively generated tokens is simultaneously decoded into future frames predictions and robot actions, thereby internalizing visual dynamics as an inductive bias for motion planning. Extensive experiments on simulated and real-world environments demonstrate state-of-the-art performance. VITA improves 14.5\%, 9.6\% and 12.1\% over existing baselines on CALVIN, LIBERO and SimplerEnv. Furthermore, VITA attains an average success rate of 80.5\% across six real-world tasks, demonstrating its potential as a generalist robotic manipulation model.

</details>


### [17] [Human-Centered Cooperative Control Coupling Autonomous and Haptic Shared Control via Control Barrier Function](https://arxiv.org/abs/2511.19869)
*Eito Sato,Takahiro Wada*

Main category: cs.RO

TL;DR: 提出了一种结合自主控制器和触觉共享控制的合作框架，有效提升了水下机器人在遥控任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 在有限的自主控制性能下，如何提高遥控操作的效率和准确性。

Method: 通过结合一个独立于操纵杆的自主控制器与触觉共享控制(HSC)，在安全区域内忽略操纵杆输入。

Result: 在与操纵杆的动态及人手臂影响的情况下，提出的方法在模拟任务中显著提高准确性，减少时间。

Conclusion: 提出的合作框架在虚拟环境中对水下机器人进行的实验中，表现出比传统的HSC更高的准确性和更短的所需时间。

Abstract: Haptic shared control (HSC) is effective in teleoperation when full autonomy is limited by uncertainty or sensing constraints. However, autonomous control performance achieved by maximizing HSC strength is limited because the dynamics of the joystick and human arm affect the robot's behavior. We propose a cooperative framework coupling a joystick-independent autonomous controller with HSC. A control barrier function ignores joystick inputs within a safe region determined by the human operator in real-time, while HSC is engaged otherwise. A pilot experiment on simulated tasks with tele-operated underwater robot in virtual environment demonstrated improved accuracy and reduced required time over conventional HSC.

</details>


### [18] [CoC-VLA: Delving into Adversarial Domain Transfer for Explainable Autonomous Driving via Chain-of-Causality Visual-Language-Action Model](https://arxiv.org/abs/2511.19914)
*Dapeng Zhang,Fei Shen,Rui Zhao,Yinda Chen,Peng Zhi,Chenyang Li,Rui Zhou,Qingguo Zhou*

Main category: cs.RO

TL;DR: CoC-VLA框架通过整合模拟与真实数据，提升了自动驾驶系统在复杂情况下的推理与性能。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶领域的发展，需要解决复杂长尾情况的能力，包括微妙的人类行为、交通事故和不合规的驾驶模式，因此需要更好地将真实世界数据与模拟数据结合。

Method: 该方法由教师VLM模型、学生VLM模型和对抗鉴别器组成，使用一种名为链式因果视觉语言模型（CoC VLM）的共享基础架构，支持链式思维推理以推断复杂的驾驶逻辑。

Result: 通过创新的反向传播策略，学生VLM模型能够在真实环境中有效应用其从模拟环境中学习到的长尾处理能力。

Conclusion: 提出了一种新的VLM指导的端到端对抗转移框架CoC-VLA，能够有效地将长尾处理能力从模拟环境转移到真实世界的自动驾驶应用中。

Abstract: Autonomous driving represents a prominent application of artificial intelligence. Recent approaches have shifted from focusing solely on common scenarios to addressing complex, long-tail situations such as subtle human behaviors, traffic accidents, and non-compliant driving patterns. Given the demonstrated capabilities of large language models (LLMs) in understanding visual and natural language inputs and following instructions, recent methods have integrated LLMs into autonomous driving systems to enhance reasoning, interpretability, and performance across diverse scenarios. However, existing methods typically rely either on real-world data, which is suitable for industrial deployment, or on simulation data tailored to rare or hard case scenarios. Few approaches effectively integrate the complementary advantages of both data sources. To address this limitation, we propose a novel VLM-guided, end-to-end adversarial transfer framework for autonomous driving that transfers long-tail handling capabilities from simulation to real-world deployment, named CoC-VLA. The framework comprises a teacher VLM model, a student VLM model, and a discriminator. Both the teacher and student VLM models utilize a shared base architecture, termed the Chain-of-Causality Visual-Language Model (CoC VLM), which integrates temporal information via an end-to-end text adapter. This architecture supports chain-of-thought reasoning to infer complex driving logic. The teacher and student VLM models are pre-trained separately on simulated and real-world datasets. The discriminator is trained adversarially to facilitate the transfer of long-tail handling capabilities from simulated to real-world environments by the student VLM model, using a novel backpropagation strategy.

</details>


### [19] [Collaborate sim and real: Robot Bin Packing Learning in Real-world and Physical Engine](https://arxiv.org/abs/2511.19932)
*Lidi Zhang,Han Wu,Liyu Zhang,Ruofeng Liu,Haotian Wang,Chao Li,Desheng Zhang,Yunhuai Liu,Tian He*

Main category: cs.RO

TL;DR: 本研究提出了一种混合强化学习框架，通过物理仿真和真实反馈，优化3D装箱问题的解决方案，显著降低了崩溃率。


<details>
  <summary>Details</summary>
Motivation: 研究3D装箱问题在现实应用中的动态性质，解决现有静态模型导致的不稳定装载问题。

Method: 结合物理仿真与真实数据反馈，使用领域随机化增强智能体的泛化能力，以及通过真实部署反馈进行细致调整。

Result: 提出了一种混合强化学习框架，通过物理仿真和真实数据反馈，提高了装箱稳定性，并降低了崩溃率。

Conclusion: 该方法在模拟和现实场景中都显示出较低的崩溃率，并在物流系统中实现了35%的崩溃率降低，验证了其实际有效性。

Abstract: The 3D bin packing problem, with its diverse industrial applications, has garnered significant research attention in recent years. Existing approaches typically model it as a discrete and static process, while real-world applications involve continuous gravity-driven interactions. This idealized simplification leads to infeasible deployments (e.g., unstable packing) in practice. Simulations with physical engine offer an opportunity to emulate continuous gravity effects, enabling the training of reinforcement learning (RL) agents to address such limitations and improve packing stability. However, a simulation-to-reality gap persists due to dynamic variations in physical properties of real-world objects, such as various friction coefficients, elasticity, and non-uniform weight distributions. To bridge this gap, we propose a hybrid RL framework that collaborates with physical simulation with real-world data feedback. Firstly, domain randomization is applied during simulation to expose agents to a spectrum of physical parameters, enhancing their generalization capability. Secondly, the RL agent is fine-tuned with real-world deployment feedback, further reducing collapse rates. Extensive experiments demonstrate that our method achieves lower collapse rates in both simulated and real-world scenarios. Large-scale deployments in logistics systems validate the practical effectiveness, with a 35\% reduction in packing collapse compared to baseline methods.

</details>


### [20] [ShapeForce: Low-Cost Soft Robotic Wrist for Contact-Rich Manipulation](https://arxiv.org/abs/2511.19955)
*Jinxuan Zhu,Zihao Yan,Yangyu Xiao,Jingxiang Guo,Chenrui Tie,Xinyi Cao,Yuhang Zheng,Lin Shao*

Main category: cs.RO

TL;DR: 本文介绍了ShapeForce，这是一种低成本、无需校准的软手腕设备，用于提供接触反馈以改善机器人操作的效率。


<details>
  <summary>Details</summary>
Motivation: 现有的六轴力-扭矩传感器成本高且易碎，限制了其在接触丰富任务中的应用。

Method: 提出一种低成本、即插即用的软手腕ShapeForce，能够提供力量信号用于接触丰富的机器人操作。

Result: ShapeForce能够通过可测量的变形转换外部力和扭矩为类似力的信号，且性能可与高价传感器相媲美。

Conclusion: ShapeForce在多种接触丰富任务中表现出与昂贵的六轴传感器相当的性能，具有广泛的应用前景。

Abstract: Contact feedback is essential for contact-rich robotic manipulation, as it allows the robot to detect subtle interaction changes and adjust its actions accordingly. Six-axis force-torque sensors are commonly used to obtain contact feedback, but their high cost and fragility have discouraged many researchers from adopting them in contact-rich tasks. To offer a more cost-efficient and easy-accessible source of contact feedback, we present ShapeForce, a low-cost, plug-and-play soft wrist that provides force-like signals for contact-rich robotic manipulation. Inspired by how humans rely on relative force changes in contact rather than precise force magnitudes, ShapeForce converts external force and torque into measurable deformations of its compliant core, which are then estimated via marker-based pose tracking and converted into force-like signals. Our design eliminates the need for calibration or specialized electronics to obtain exact values, and instead focuses on capturing force and torque changes sufficient for enabling contact-rich manipulation. Extensive experiments across diverse contact-rich tasks and manipulation policies demonstrate that ShapeForce delivers performance comparable to six-axis force-torque sensors at an extremely low cost.

</details>


### [21] [Active3D: Active High-Fidelity 3D Reconstruction via Hierarchical Uncertainty Quantification](https://arxiv.org/abs/2511.20050)
*Yan Li,Yingzhao Li,Gim Hee Lee*

Main category: cs.RO

TL;DR: 该研究提出了一种新的3D重建方法，结合了不确定性评估和智能视角选择，显著提高了重建精度和效率。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在通过主动探索框架提升3D重建的准确性和效率，特别是在复杂和动态环境中的应用。

Method: 论文中采用了混合隐式-显式表示，结合神经场与高斯原语来捕捉全局结构先验和局部细节，同时 利用分层不确定性体积进行优化。

Result: 本论文提出了一种实现高保真3D重建的主动探索框架，该框架逐步构建了一个多层次的不确定性空间，并通过不确定性驱动的运动规划器选择下一个最佳视角。

Conclusion: 实验结果表明，该方法在准确性、完整性和渲染质量上均优于现有的最先进技术，证明了其在实际主动重建和机器人感知任务中的有效性。

Abstract: In this paper, we present an active exploration framework for high-fidelity 3D reconstruction that incrementally builds a multi-level uncertainty space and selects next-best-views through an uncertainty-driven motion planner. We introduce a hybrid implicit-explicit representation that fuses neural fields with Gaussian primitives to jointly capture global structural priors and locally observed details. Based on this hybrid state, we derive a hierarchical uncertainty volume that quantifies both implicit global structure quality and explicit local surface confidence. To focus optimization on the most informative regions, we propose an uncertainty-driven keyframe selection strategy that anchors high-entropy viewpoints as sparse attention nodes, coupled with a viewpoint-space sliding window for uncertainty-aware local refinement. The planning module formulates next-best-view selection as an Expected Hybrid Information Gain problem and incorporates a risk-sensitive path planner to ensure efficient and safe exploration. Extensive experiments on challenging benchmarks demonstrate that our approach consistently achieves state-of-the-art accuracy, completeness, and rendering quality, highlighting its effectiveness for real-world active reconstruction and robotic perception tasks.

</details>


### [22] [Hibikino-Musashi@Home 2025 Team Description Paper](https://arxiv.org/abs/2511.20180)
*Ryohei Kobayashi,Kosei Isomoto,Kosei Yamao,Soma Fumoto,Koshun Arimura,Naoki Yamaguchi,Akinobu Mizutani,Tomoya Shiba,Kouki Kimizuka,Yuta Ohno,Ryo Terashima,Hiromasa Yamaguchi,Tomoaki Fujino,Ryoga Maruno,Wataru Yoshimura,Kazuhito Mine,Tang Phu Thien Nhan,Yuga Yano,Yuichiro Tanaka,Takeshi Nishida,Takashi Morie,Hakaru Tamukoh*

Main category: cs.RO

TL;DR: 本文概述了Hibikino-Musashi@Home团队为开发家庭服务机器人所采用的技术，包括数据集生成器、开源开发环境、任务规划器以及脑启发的记忆模型。


<details>
  <summary>Details</summary>
Motivation: 为家庭提供直观及个性化的辅助服务，以及提升机器人在实际应用中的表现。

Method: 开发数据集生成器以训练机器人视觉系统，构建基于人类支持机器人的开源开发环境，利用大语言模型的任务规划器选择适当的技能，研究脑启发的记忆模型以适应不同家居环境。

Result: 完成了一个机器人视觉系统的训练数据集，建立了开源开发环境，开发了适应家庭环境的智能服务机器人，并实现了与RoboCup2024导航系统的可重用性。

Conclusion: 该团队旨在设计一款能够适应家庭环境的服务机器人，并通过不断参加比赛来评估和改进系统。

Abstract: This paper provides an overview of the techniques employed by Hibikino-Musashi@Home, which intends to participate in the domestic standard platform league. The team developed a dataset generator for training a robot vision system and an open-source development environment running on a Human Support Robot simulator. The large-language-model-powered task planner selects appropriate primitive skills to perform the task requested by the user. Moreover, the team has focused on research involving brain-inspired memory models for adaptation to individual home environments. This approach aims to provide intuitive and personalized assistance. Additionally, the team contributed to the reusability of the navigation system developed by Pumas in RoboCup2024. The team aimed to design a home service robot to assist humans in their homes and continuously attend competitions to evaluate and improve the developed system.

</details>


### [23] [Toward generic control for soft robotic systems](https://arxiv.org/abs/2511.20226)
*Yu Sun,Yaosheng Deng,Wenjie Mei,Xiaogang Xiong,Yang Bai,Masaki Ogura,Zeyu Zhou,Mir Feroskhan,Michael Yu Wang,Qiyang Zuo,Yao Li,Yunjiang Lou*

Main category: cs.RO

TL;DR: 本文提出了一种通用的软机器人控制框架，强调控制柔性的重要性，显示出在多种机器人上具有良好的适应性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 软机器人的控制方法仍然分散，需要任务特定的控制器，导致理论整合和大规模部署的障碍。

Method: 提出了一种基于控制柔性的通用控制框架，并在具有不同形态和驱动机制的机器人上进行验证。

Result: 结果表明，该框架实现了稳定、安全且跨平台可转移的行为。

Conclusion: 接受控制柔性原则而非抵抗它，为统一的软机器人控制提供了广泛适用的基础。

Abstract: Soft robotics has advanced rapidly, yet its control methods remain fragmented: different morphologies and actuation schemes still require task-specific controllers, hindering theoretical integration and large-scale deployment. A generic control framework is therefore essential, and a key obstacle lies in the persistent use of rigid-body control logic, which relies on precise models and strict low-level execution. Such a paradigm is effective for rigid robots but fails for soft robots, where the ability to tolerate and exploit approximate action representations, i.e., control compliance, is the basis of robustness and adaptability rather than a disturbance to be eliminated. Control should thus shift from suppressing compliance to explicitly exploiting it. Human motor control exemplifies this principle: instead of computing exact dynamics or issuing detailed muscle-level commands, it expresses intention through high-level movement tendencies, while reflexes and biomechanical mechanisms autonomously resolve local details. This architecture enables robustness, flexibility, and cross-task generalization. Motivated by this insight, we propose a generic soft-robot control framework grounded in control compliance and validate it across robots with diverse morphologies and actuation mechanisms. The results demonstrate stable, safe, and cross-platform transferable behavior, indicating that embracing control compliance, rather than resisting it, may provide a widely applicable foundation for unified soft-robot control.

</details>


### [24] [HAFO: Humanoid Force-Adaptive Control for Intense External Force Interaction Environments](https://arxiv.org/abs/2511.20275)
*Chenhui Dong,Haozhe Xu,Wenhao Feng,Zhipeng Wang,Yanmin Zhou,Yifei Zhao,Bin He*

Main category: cs.RO

TL;DR: HAFO框架通过双代理强化学习优化人形机器人在强力干扰下的运动与操作性能。


<details>
  <summary>Details</summary>
Motivation: 旨在解决现有强化学习控制在复杂力互动下运动精确性不足的问题。

Method: 提出HAFO，采用双代理强化学习控制框架，同时优化步态和上身操作策略，利用弹簧-阻尼系统模型外部干扰。

Result: 实验结果显示HAFO在强力干扰下保持稳定控制，优化加载任务表现。

Conclusion: HAFO框架在多种强力互动环境中展现出卓越的稳定性和鲁棒性，成功应对了加载任务和绳索张力干扰。

Abstract: Reinforcement learning controllers have made impressive progress in humanoid locomotion and light load manipulation. However, achieving robust and precise motion with strong force interaction remains a significant challenge. Based on the above limitations, this paper proposes HAFO, a dual-agent reinforcement learning control framework that simultaneously optimizes both a robust locomotion strategy and a precise upper-body manipulation strategy through coupled training under external force interaction environments. Simultaneously, we explicitly model the external pulling disturbances through a spring-damper system and achieve fine-grained force control by manipulating the virtual spring. During this process, the reinforcement-learning policy spontaneously generates disturbance-rejection response by exploiting environmental feedback. Moreover, HAFO employs an asymmetric Actor-Critic framework in which the Critic-network access to privileged spring-damping forces guides the actor-network to learn a generalizable, robust policy for resisting external disturbances. The experimental results demonstrate that HAFO achieves stable control of humanoid robot under various strong force interactions, showing remarkable performance in load tasks and ensuring stable robot operation under rope tension disturbances. Project website: hafo-robot.github.io.

</details>


### [25] [Dynamic-ICP: Doppler-Aware Iterative Closest Point Registration for Dynamic Scenes](https://arxiv.org/abs/2511.20292)
*Dong Wang,Daniel Casado Herraez,Stefan May,Andreas Nüchter*

Main category: cs.RO

TL;DR: Dynamic-ICP是一个基于多普勒感知的框架，可在高度动态环境中实现可靠的测程，显著提升旋转稳定性和位移精度。


<details>
  <summary>Details</summary>
Motivation: To address the challenges of reliable odometry in highly dynamic environments where traditional ICP-based methods fail.

Method: Dynamic-ICP, a Doppler-aware registration framework for odometry.

Result: Dynamic-ICP shows consistent improvements in rotational stability and translation accuracy over state-of-the-art methods in highly dynamic scenes.

Conclusion: Dynamic-ICP提供了一种轻量级的解决方案，适用于动态环境中的稳健配准，并且易于集成到现有 pipelines 中。

Abstract: Reliable odometry in highly dynamic environments remains challenging when it relies on ICP-based registration: ICP assumes near-static scenes and degrades in repetitive or low-texture geometry. We introduce Dynamic-ICP, a Doppler-aware registration framework. The method (i) estimates ego motion from per-point Doppler velocity via robust regression and builds a velocity filter, (ii) clusters dynamic objects and reconstructs object-wise translational velocities from ego-compensated radial measurements, (iii) predicts dynamic points with a constant-velocity model, and (iv) aligns scans using a compact objective that combines point-to-plane geometry residual with a translation-invariant, rotation-only Doppler residual. The approach requires no external sensors or sensor-vehicle calibration and operates directly on FMCW LiDAR range and Doppler velocities. We evaluate Dynamic-ICP on three datasets-HeRCULES, HeLiPR, AevaScenes-focusing on highly dynamic scenes. Dynamic-ICP consistently improves rotational stability and translation accuracy over the state-of-the-art methods. Our approach is also simple to integrate into existing pipelines, runs in real time, and provides a lightweight solution for robust registration in dynamic environments. To encourage further research, the code is available at: https://github.com/JMUWRobotics/Dynamic-ICP.

</details>


### [26] [ArtiBench and ArtiBrain: Benchmarking Generalizable Vision-Language Articulated Object Manipulation](https://arxiv.org/abs/2511.20330)
*Yuhan Wu,Tiantian Wei,Shuo Wang,ZhiChao Wang,Yanyong Zhang,Daniel Cremers,Yan Xia*

Main category: cs.RO

TL;DR: 本研究提出了一种名为ArtiBench的基准和ArtiBrain的框架，以应对交互式关节操作中的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言和扩散基于政策在跨部件、实例和类别的一致性上存在困难，亟需新的评估标准和框架。

Method: 使用VLM-based任务推理器分解和验证子目标，结合几何感知的关键帧执行和基于可供性引导的扩散进行精确操控。

Result: 在ArtiBench上的广泛实验表明，ArtiBrain在稳健性和泛化能力方面显著优于最先进的方法。

Conclusion: ArtiBrain在强化稳健性和泛化能力方面显著优于现有的多模态和扩散方法。

Abstract: Interactive articulated manipulation requires long-horizon, multi-step interactions with appliances while maintaining physical consistency. Existing vision-language and diffusion-based policies struggle to generalize across parts, instances, and categories. We first introduce ArtiBench, a five-level benchmark covering kitchen, storage, office, and tool environments. ArtiBench enables structured evaluation from cross-part and cross-instance variation to long-horizon multi-object tasks, revealing the core generalization challenges of articulated object manipulation. Building on this benchmark, we propose ArtiBrain, a modular framework that unifies high-level reasoning with adaptive low-level control. ArtiBrain uses a VLM-based Task Reasoner (GPT-4.1) to decompose and validate subgoals, and employs a Hybrid Controller that combines geometry-aware keyframe execution with affordance-guided diffusion for precise and interpretable manipulation. An Affordance Memory Bank continually accumulates successful execution episodes and propagates part-level actionable affordances to unseen articulated parts and configurations. Extensive experiments on ArtiBench show that our ArtiBrain significantly outperforms state-of-the-art multimodal and diffusion-based methods in robustness and generalization. Code and dataset will be released upon acceptance.

</details>


### [27] [Quality-guided UAV Surface Exploration for 3D Reconstruction](https://arxiv.org/abs/2511.20353)
*Benjamin Sportich,Kenza Boubakri,Olivier Simonin,Alessandro Renzaglia*

Main category: cs.RO

TL;DR: 本文提出了一种新颖的模块化NBV规划框架，优化了自主机器人的环境探索，通过TSDF表示方法提高了探索决策的有效性和效率。


<details>
  <summary>Details</summary>
Motivation: 开发有效的规划策略以支持自主机器人在未知环境中的探索和映射。

Method: 通过引入新方法生成和选择视点候选，基于用户定义的质量要求调整探索规划。

Result: 提出了一种新的模块化次优视图(NBV)规划框架，利用重建质量目标指导探索规划。

Conclusion: 该方法在覆盖范围、最终3D地图质量和路径效率等方面优于传统的NBV策略。

Abstract: Reasons for mapping an unknown environment with autonomous robots are wide-ranging, but in practice, they are often overlooked when developing planning strategies. Rapid information gathering and comprehensive structural assessment of buildings have different requirements and therefore necessitate distinct methodologies. In this paper, we propose a novel modular Next-Best-View (NBV) planning framework for aerial robots that explicitly uses a reconstruction quality objective to guide the exploration planning. In particular, our approach introduces new and efficient methods for view generation and selection of viewpoint candidates that are adaptive to the user-defined quality requirements, fully exploiting the uncertainty encoded in a Truncated Signed Distance field (TSDF) representation of the environment. This results in informed and efficient exploration decisions tailored towards the predetermined objective. Finally, we validate our method via extensive simulations in realistic environments. We demonstrate that it successfully adjusts its behavior to the user goal while consistently outperforming conventional NBV strategies in terms of coverage, quality of the final 3D map and path efficiency.

</details>


### [28] [Improved adaptive wind driven optimization algorithm for real-time path planning](https://arxiv.org/abs/2511.20394)
*Shiqian Liu,Azlan Mohd Zain,Le-le Mao*

Main category: cs.RO

TL;DR: 本研究提出多层次自适应风驱动优化（MAWDO）算法，改善动态路径规划中的自适应性和稳定性，显著提高优化精度与收敛稳定性。


<details>
  <summary>Details</summary>
Motivation: 应对动态环境中的实时适应性挑战，特别是在复杂约束下生成无碰撞、平滑且高效的轨迹。

Method: Multi-hierarchical adaptive wind driven optimization (MAWDO)

Result: MAWDO在动态路径规划中，相比其他算法（如MEWDO、AWDO和WDO），在路径长度、最优性差距和轨迹平滑度上表现优异。

Conclusion: MAWDO在复杂环境下实现了更平滑、更短和无碰撞的轨迹，证明了其在实时路径规划中的有效性。

Abstract: Recently, path planning has achieved remarkable progress in enhancing global search capability and convergence accuracy through heuristic and learning-inspired optimization frameworks. However, real-time adaptability in dynamic environments remains a critical challenge for autonomous navigation, particularly when robots must generate collision-free, smooth, and efficient trajectories under complex constraints. By analyzing the difficulties in dynamic path planning, the Wind Driven Optimization (WDO) algorithm emerges as a promising framework owing to its physically interpretable search dynamics. Motivated by these observations, this work revisits the WDO principle and proposes a variant formulation, Multi-hierarchical adaptive wind driven optimization(MAWDO), that improves adaptability and robustness in time-varying environments. To mitigate instability and premature convergence, a hierarchical-guidance mechanism divides the population into multiple groups guided by individual, regional, and global leaders to balance exploration and exploitation. Extensive evaluations on sixteen benchmark functions show that MAWDO achieves superior optimization accuracy, convergence stability, and adaptability over state-of-the art metaheuristics. In dynamic path planning, MAWDO shortens the path length to 469.28 pixels, improving over Multi-strategy ensemble wind driven optimization(MEWDO), Adaptive wind driven optimization(AWDO) and WDO by 3.51\%, 11.63\% and 14.93\%, and achieves the smallest optimality gap (1.01) with smoothness 0.71 versus 13.50 and 15.67 for AWDO and WDO, leading to smoother, shorter, and collision-free trajectories that confirm its effectiveness for real-time path planning in complex environments.

</details>


### [29] [Power-Efficient Autonomous Mobile Robots](https://arxiv.org/abs/2511.20467)
*Liangkai Liu,Weisong Shi,Kang G. Shin*

Main category: cs.RO

TL;DR: 该论文提出了一种名为pNav的新型电源管理系统，通过优化自主移动机器人(AMRs)的物理/机械子系统和网络子系统，显著提升其能效。


<details>
  <summary>Details</summary>
Motivation: 通过分析AMRs的功耗，我们识别出实现CPS能效的三大挑战，包括功耗分解的可变性、环境感知导航的局部性和C、P子系统的协调。

Method: pNav采用多方面的方法来提升AMRs的能效，整合了毫秒级功耗预测、实时空间和时间导航建模与监测，以及AMR软件和硬件配置的动态协同。

Result: pNav在真实机器人和Gazebo环境下的深入评估表明，能达到>96%的功耗预测精度和38.1%的功耗减少。

Conclusion: 通过与ROS导航栈、2D LiDAR和相机的原型制作，pNav实现了>96%的功耗预测精度以及38.1%的功耗减少，且未影响导航精度和安全性。

Abstract: This paper presents pNav, a novel power-management system that significantly enhances the power/energy-efficiency of Autonomous Mobile Robots (AMRs) by jointly optimizing their physical/mechanical and cyber subsystems. By profiling AMRs' power consumption, we identify three challenges in achieving CPS (cyber-physical system) power-efficiency that involve both cyber (C) and physical (P) subsystems: (1) variabilities of system power consumption breakdown, (2) environment-aware navigation locality, and (3) coordination of C and P subsystems. pNav takes a multi-faceted approach to achieve power-efficiency of AMRs. First, it integrates millisecond-level power consumption prediction for both C and P subsystems. Second, it includes novel real-time modeling and monitoring of spatial and temporal navigation localities for AMRs. Third, it supports dynamic coordination of AMR software (navigation, detection) and hardware (motors, DVFS driver) configurations. pNav is prototyped using the Robot Operating System (ROS) Navigation Stack, 2D LiDAR, and camera. Our in-depth evaluation with a real robot and Gazebo environments demonstrates a >96% accuracy in predicting power consumption and a 38.1% reduction in power consumption without compromising navigation accuracy and safety.

</details>


### [30] [Kleinkram: Open Robotic Data Management](https://arxiv.org/abs/2511.20492)
*Cyrill Püntener,Johann Schwabe,Dominique Garmier,Jonas Frey,Marco Hutter*

Main category: cs.RO

TL;DR: Kleinkram是一种开源系统，专为管理大量非结构化机器人数据集而设计，支持灵活的存储和自定义工作流程。


<details>
  <summary>Details</summary>
Motivation: 面对大型非结构化机器人数据集的管理挑战，Kleinkram旨在提供一个高效、可扩展的解决方案。

Method: Kleinkram使用模块化的本地云解决方案，并集成标准格式和S3兼容存储，同时提供Docker工作流执行功能。

Result: Kleinkram成功地优化了数据管理流程，通过现代Web界面和强大的命令行接口提升了用户体验。

Conclusion: Kleinkram有效地管理了超过30TB的多种机器人系统数据，改善了研究流程。

Abstract: We introduce Kleinkram, a free and open-source system designed to solve the challenge of managing massive, unstructured robotic datasets. Designed as a modular, on-premises cloud solution, Kleinkram enables scalable storage, indexing, and sharing of datasets, ranging from individual experiments to large-scale research collections. Kleinkram natively integrates with standard formats such as ROS bags and MCAP and utilises S3-compatible storage for flexibility. Beyond storage, Kleinkram features an integrated "Action Runner" that executes customizable Docker-based workflows for data validation, curation, and benchmarking. Kleinkram has successfully managed over 30 TB of data from diverse robotic systems, streamlining the research lifecycle through a modern web interface and a robust Command Line Interface (CLI).

</details>


### [31] [Metric, inertially aligned monocular state estimation via kinetodynamic priors](https://arxiv.org/abs/2511.20496)
*Jiaxin Liu,Min Li,Wanting Xu,Liang Li,Jiaqi Yang,Laurent Kneip*

Main category: cs.RO

TL;DR: 本论文提出了一种新方法，扩展了现有的刚体姿态估计方法至非刚性系统，通过借助多层感知机学习变形-力模型和使用连续时间B样条运动模型解决光滑运动，展示了提升姿态估计的可行性。


<details>
  <summary>Details</summary>
Motivation: 在动态变形结构的柔性机器人系统中，准确的状态估计面临重大挑战，尤其是当这些系统不符合刚体假设时。

Method: 利用多层感知机高效学习弹性属性，通过连续时间B样条运动模型解决平台的平滑运动，并通过持续应用牛顿第二定律建立视觉派生的轨迹加速度与预测的变形诱导加速度之间的物理联系。

Result: 提出了一种方法，不仅能够在非刚性平台上进行鲁棒和准确的姿态估计，还展示了合适建模的物理特性如何激发惯性传感特性。

Conclusion: 通过对简单的弹簧-相机系统的演示，论文验证了该方法能够有效解决单目视觉里程计中的度量尺度和重力恢复问题。

Abstract: Accurate state estimation for flexible robotic systems poses significant challenges, particular for platforms with dynamically deforming structures that invalidate rigid-body assumptions. This paper tackles this problem and allows to extend existing rigid-body pose estimation methods to non-rigid systems. Our approach hinges on two core assumptions: first, the elastic properties are captured by an injective deformation-force model, efficiently learned via a Multi-Layer Perceptron; second, we solve the platform's inherently smooth motion using continuous-time B-spline kinematic models. By continuously applying Newton's Second Law, our method establishes a physical link between visually-derived trajectory acceleration and predicted deformation-induced acceleration. We demonstrate that our approach not only enables robust and accurate pose estimation on non-rigid platforms, but that the properly modeled platform physics instigate inertial sensing properties. We demonstrate this feasibility on a simple spring-camera system, and show how it robustly resolves the typically ill-posed problem of metric scale and gravity recovery in monocular visual odometry.

</details>


### [32] [Safe and Stable Neural Network Dynamical Systems for Robot Motion Planning](https://arxiv.org/abs/2511.20593)
*Allen Emmanuel Binny,Mahathi Anand,Hugo T. M. Kussaba,Lingyun Chen,Shreenabh Agrawal,Fares J. Abu-Dakka,Abdalla Swikir*

Main category: cs.RO

TL;DR: 提出了一种新的学习框架S$^2$-NNDS，通过神经网络学习安全和稳定的机器人动作，同时确保运动的安全性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 在面对动态和复杂的环境时，安全和稳定的机器人运动学习仍然是一个挑战，现有方法存在限制，尤其是在非线性任务中的有效性不足。

Method: 该方法结合了神经网络和分离的符合预测，获取复杂机器人动作，同时学习Lyapunov稳定性和障碍物安全认证。

Result: 本论文提出了一种新的学习框架S$^2$-NNDS，用于从演示中学习安全和稳定的机器人运动，特别是在复杂和非线性任务中。该框架能够同时学习神经动力系统和Lyapunov稳定性及障碍物安全认证，确保在复杂环境中的运动稳定性和安全性。

Conclusion: S$^2$-NNDS能从潜在不安全的演示中高效学习到稳健、安全和稳定的机器人运动。

Abstract: Learning safe and stable robot motions from demonstrations remains a challenge, especially in complex, nonlinear tasks involving dynamic, obstacle-rich environments. In this paper, we propose Safe and Stable Neural Network Dynamical Systems S$^2$-NNDS, a learning-from-demonstration framework that simultaneously learns expressive neural dynamical systems alongside neural Lyapunov stability and barrier safety certificates. Unlike traditional approaches with restrictive polynomial parameterizations, S$^2$-NNDS leverages neural networks to capture complex robot motions providing probabilistic guarantees through split conformal prediction in learned certificates. Experimental results on various 2D and 3D datasets -- including LASA handwriting and demonstrations recorded kinesthetically from the Franka Emika Panda robot -- validate S$^2$-NNDS effectiveness in learning robust, safe, and stable motions from potentially unsafe demonstrations.

</details>


### [33] [Reinforcing Action Policies by Prophesying](https://arxiv.org/abs/2511.20633)
*Jiahui Zhang,Ze Huang,Chun Gu,Zipei Ma,Li Zhang*

Main category: cs.RO

TL;DR: 本文提出了ProphRL，一种通过学习世界模型和优化稳定性提高视觉-语言-动作(VLA)政策的后期训练方法，展示了在多种基准和实际机器人上显著提升成功率。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作(VLA)政策在语言、感知和机器人控制的对齐方面表现优越，但主要依赖模仿训练，导致过拟合和对变化环境的脆弱性。

Method: 提出了一种统一的动作到视频的机器人驱动方法Prophet，并结合Flow-action-GRPO和FlowScale进行后续强化学习训练，以实现有效的VLA后期训练。

Result: 提出了一种名为ProphRL的方法，该方法结合了学习世界模型和基于流的动作头的强化学习程序，使VLA在后期训练时有效。

Conclusion: 通过ProphRL框架，能有效提高视觉-语言-动作(VLA)策略的优化效率和数据使用效率，促进机器人在新环境中的适应能力。

Abstract: Vision-Language-Action (VLA) policies excel in aligning language, perception, and robot control. However, most VLAs are trained purely by imitation, which overfits to demonstrations, and is brittle under distribution shift. Reinforcement learning (RL) directly optimizes task reward and thus addresses this misalignment, but real-robot interaction is expensive and conventional simulators are hard to engineer and transfer. We address both data efficiency and optimization stability in VLA post-training via a learned world model and an RL procedure tailored to flow-based action heads. Specifically, we introduce Prophet, a unified action-to-video robot actuation pretrained across large-scale, heterogeneous robot data to learn reusable action-outcome dynamics. It is able to few-shot adapt to new robots, objects, and environments, yielding a rollout-ready simulator. Upon Prophet, we reinforce action policies with Flow-action-GRPO (FA-GRPO), which adapts Flow-GRPO to operate on VLA actions, and with FlowScale, a stepwise reweighting that rescales per-step gradients in the flow head. Together, Prophet, FA-GRPO, and FlowScale constitute ProphRL, a practical, data- and compute-efficient path to VLA post-training. Experiments show 5-17% success gains on public benchmarks and 24-30% gains on real robots across different VLA variants.

</details>
