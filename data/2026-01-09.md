<div id=toc></div>

# Table of Contents

- [cs.HC](#cs.HC) [Total: 9]
- [cs.RO](#cs.RO) [Total: 19]


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [1] [Human-in-the-Loop Testing of AI Agents for Air Traffic Control with a Regulated Assessment Framework](https://arxiv.org/abs/2601.04288)
*Ben Carvell,Marc Thomas,Andrew Pace,Christopher Dorney,George De Ath,Richard Everson,Nick Pepper,Adam Keane,Samuel Tomlinson,Richard Cannon*

Main category: cs.HC

TL;DR: 该研究提出了一种新的评估框架，用于在空中交通管制任务中评估AI表现，解决了现有文献中的表现错位问题。


<details>
  <summary>Details</summary>
Motivation: 解决学术界对空中交通管制的表现与实际操作环境之间的错位问题。

Method: 利用由监管机构认证的模拟器基础课程，结合专家人类讲师的评估参与。

Result: 建立了一个更真实和领域准确的AI表现测量框架，以支持未来的人机协作模式。

Conclusion: 提出了一种人机协同的评估框架，以更准确地评估AI在空中交通管制任务中的表现，并为人机协作奠定基础。

Abstract: We present a rigorous, human-in-the-loop evaluation framework for assessing the performance of AI agents on the task of Air Traffic Control, grounded in a regulator-certified simulator-based curriculum used for training and testing real-world trainee controllers. By leveraging legally regulated assessments and involving expert human instructors in the evaluation process, our framework enables a more authentic and domain-accurate measurement of AI performance. This work addresses a critical gap in the existing literature: the frequent misalignment between academic representations of Air Traffic Control and the complexities of the actual operational environment. It also lays the foundations for effective future human-machine teaming paradigms by aligning machine performance with human assessment targets.

</details>


### [2] [How Users Consider Web Tracking When Seeking Health Information Online](https://arxiv.org/abs/2601.04485)
*Martin P. Robillard,Lihn V. Nguyen,Deeksha Arya,Jin L. C. Guo*

Main category: cs.HC

TL;DR: 这项研究调查了加拿大居民对在线健康信息搜索中的隐私保护措施的理解与应用，发现用户对隐私保护的有限认知可能源于对隐蔽数据收集方式的误解。


<details>
  <summary>Details</summary>
Motivation: 研究在线健康信息搜索的隐私影响，以了解用户如何保护自己的隐私及其对网页追踪的理解。

Method: 对35名加拿大居民进行了访谈，了解他们在网上搜寻健康信息时采取的隐私保护措施。

Result: 研究结果显示，用户对隐私保护的主动性和有效性有限，这与对第三方隐蔽数据收集的理解不足有关。

Conclusion: 为了帮助互联网用户实现更好的自我数据保护，我们可能需要将隐私意识的努力从收集了哪些信息转向如何收集信息。

Abstract: Health information websites offer instantaneous access to information, but have important privacy implications as they can associate a visitor with specific medical conditions. We interviewed 35 residents of Canada to better understand whether and how online health information seekers exercise three potential means of protection against surveillance: website selection, privacy-enhancing technologies, and self-censorship, as well as their understanding of web tracking. Our findings reveal how users' limited initiative and effectiveness in protecting their privacy could be associated with a missing or inaccurate understanding of how implicit data collection by third parties takes place on the web, and who collects the data. We conclude that to help Internet users achieve better self-data protection, we may need to shift privacy awareness efforts from what information is collected to how it is collected.

</details>


### [3] [Feel the Presence: The Effects of Haptic Sensation on VR-Based Human-Robot Interaction](https://arxiv.org/abs/2601.04596)
*Xinyan Yu,Marius Hoggenmüller,Tram Thi Minh Tran,Martin Tomitsch*

Main category: cs.HC

TL;DR: 本研究探讨了触觉感知在虚拟现实（VR）中对人机交互(HRI)的影响。


<details>
  <summary>Details</summary>
Motivation: 随着虚拟现实技术在模拟人机交互中的日益普及，研究人员需要提高实验的有效性和真实性。

Method: 使用配备触觉手套的虚拟现实仿真，比较触觉感知与传统手柄控制器在增强参与者的存在感和机器人评价上的影响。

Result: 触觉感知显著增强了参与者的社交和自我存在感，并影响了他们对机器人的情感感知。

Conclusion: 研究为人机交互研究者提供了在构建基于VR的仿真时的指导以更好地满足研究背景和目标。

Abstract: Virtual reality (VR) has been increasingly utilised as a simulation tool for human-robot interaction (HRI) studies due to its ability to facilitate fast and flexible prototyping. Despite efforts to achieve high validity in VR studies, haptic sensation, an essential sensory modality for perception and a critical factor in enhancing VR realism, is often absent from these experiments. Studying an interactive robot help-seeking scenario, we used a VR simulation with haptic gloves that provide highly realistic tactile and force feedback to examine the effects of haptic sensation on VR-based HRI. We compared participants' sense of presence and their assessments of the robot to a traditional setup using hand controllers. Our results indicate that haptic sensation enhanced participants' social and self-presence in VR and fostered more diverse and natural bodily engagement. Additionally, haptic sensations significantly influenced participants' affective-related perceptions of the robot. Our study provides insights to guide HRI researchers in building VR-based simulations that better align with their study contexts and objectives.

</details>


### [4] [The UnScripted Trip: Fostering Policy Discussion on Future Human-Vehicle Collaboration in Autonomous Driving Through Design-Oriented Methods](https://arxiv.org/abs/2601.04601)
*Xinyan Yu,Julie Stephany Berrio Perez,Marius Hoggenmüller,Martin Tomitsch,Tram Thi Minh Tran,Stewart Worrall,Wendy Ju*

Main category: cs.HC

TL;DR: 本工作坊通过设计游戏探索自动驾驶技术带来的社会张力，旨在推动汽车领域的设计解决方案与政策制定。


<details>
  <summary>Details</summary>
Motivation: 应对自动驾驶技术迅猛发展带来的新的人-车协作挑战，促进HCI研究与政策制定的结合。

Method: 通过举办工作坊和设计游戏来探讨自动驾驶车辆的政策方向

Result: 通过参与式的卡牌游戏，激发参与者对未来自动驾驶场景的思考，探索人-车协作的张力及政策影响。

Conclusion: 通过集体探讨，促进人-车协作设计和政策的创新发展。

Abstract: The rapid advancement of autonomous vehicle (AV) technologies is fundamentally reshaping paradigms of human-vehicle collaboration, raising not only an urgent need for innovative design solutions but also for policies that address corresponding broader tensions in society. To bridge the gap between HCI research and policy making, this workshop will bring together researchers and practitioners in the automotive community to explore AV policy directions through collaborative speculation on the future of AVs. We designed The UnScripted Trip, a card game rooted in fictional narratives of autonomous mobility, to surface tensions around human-vehicle collaboration in future AV scenarios and to provoke critical reflections on design solutions and policy directions. Our goal is to provide an engaging, participatory space and method for automotive researchers, designers, and industry practitioners to collectively explore and shape the future of human-vehicle collaboration and its policy implications.

</details>


### [5] [RecruitScope: A Visual Analytics System for Multidimensional Recruitment Data Analysis](https://arxiv.org/abs/2601.04630)
*Xiyuan Zhu,Wenhan Lyu,Chaochao Fu,Yilin Wang,Jie Zheng,Qiyue Tan,Qianhe Chen,Yixin Yu,Ran Wang*

Main category: cs.HC

TL;DR: 本文介绍了RecruitScope，一个支持招聘数据多维分析的可视分析系统，克服了传统招聘平台功能的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前在线招聘平台仅提供基本的筛选功能，限制了对多属性关系和招聘市场模式的深入分析。

Method: 开发了RecruitScope可视分析系统，通过协调可视化支持对招聘数据的多维和跨层次探讨。

Result: 通过案例研究，展示了区域工资分布模式、行业增长轨迹和新兴角色的需求等发现。

Conclusion: RecruitScope有效支持求职者和HR专家对招聘数据的深入分析，揭示了行业动态和市场趋势。

Abstract: Online recruitment platforms have become the dominant channel for modern hiring, yet most platforms offer only basic filtering capabilities, such as job title, keyword, and salary range. This hinders comprehensive analysis of multi-attribute relationships and job market patterns across different scales. We present RecruitScope, a visual analytics system designed to support multidimensional and cross-level exploration of recruitment data for job seekers and employers, particularly HR specialists. Through coordinated visualizations, RecruitScope enables users to analyze job positions and salary patterns from multiple perspectives, interpret industry dynamics at the macro level, and identify emerging positions at the micro level. We demonstrate the effectiveness of RecruitScope through case studies that reveal regional salary distribution patterns, characterize industry growth trajectories, and discover high-demand emerging roles in the job market.

</details>


### [6] [Leveraging LLMs for Efficient and Personalized Smart Home Automation](https://arxiv.org/abs/2601.04680)
*Chaerin Yu,Chihun Choi,Sunjae Lee,Hyosu Kim,Steven Y. Ko,Young-Bae Ko,Sangeun Oh*

Main category: cs.HC

TL;DR: IoTGPT是一种基于大型语言模型的智能家居代理，旨在以可靠、高效和个性化的方式执行物联网命令，通过分解用户指令和记忆子任务来提高性能。


<details>
  <summary>Details</summary>
Motivation: 随着智能家居设备的增多，用户面临复杂的控制管理，导致疲劳。现有的基于大型语言模型的方法存在可靠性低、效率低和个性化不足的问题。

Method: IoTGPT通过将用户指令分解为子任务并进行记忆，以提高指令处理的效率，减少LLM调用，支持用户偏好的精细个性化。

Result: IoTGPT在准确性、延迟/成本和个性化方面超过了基准模型，同时减少了用户工作负担。

Conclusion: IoTGPT有效地解决了智能家居控制中的挑战，为用户提供了更优质的体验。

Abstract: The proliferation of smart home devices has increased the complexity of controlling and managing them, leading to user fatigue. In this context, large language models (LLMs) offer a promising solution by enabling natural-language interfaces for Internet of Things (IoT) control. However, existing LLM-based approaches suffer from unreliable and inefficient device control due to the non-deterministic nature of LLMs, high inference latency and cost, and limited personalization. To address these challenges, we present IoTGPT, an LLM-based smart home agent designed to execute IoT commands in a reliable, efficient, and personalized manner. Inspired by how humans manage complex tasks, IoTGPT decomposes user instructions into subtasks and memorizes them. By reusing learned subtasks, subsequent instructions can be processed more efficiently with fewer LLM calls, improving reliability and reducing both latency and cost. IoTGPT also supports fine-grained personalization by adapting individual subtasks to user preferences. Our evaluation demonstrates that IoTGPT outperforms baselines in accuracy, latency/cost, and personalization, while reducing user workload.

</details>


### [7] [Dynamic Thermal Feedback in Highly Immersive VR Scenarios: a Multimodal Analysis of User Experience](https://arxiv.org/abs/2601.04781)
*Sophie Villenave,Pierre Raimbaud,Guillaume Lavoué*

Main category: cs.HC

TL;DR: 该研究探讨了不同水平热反馈对虚拟现实中的用户体验的影响，发现热反馈能进一步提高用户的在场感，提出了热反馈的应用指导和研究设计建议。


<details>
  <summary>Details</summary>
Motivation: 为了填补现有研究缺乏对不同热反馈质量比较及沉浸式虚拟环境中热反馈影响的空白。

Method: 在两个沉浸式场景中进行参与者内的用户研究，比较三种反馈条件，并通过问卷、半结构化访谈和行为指标进行多模态分析。

Result: 加入热反馈后，用户在场感显著增强，但热反馈质量的不同在用户体验问卷中未显示显著差异。参与者特征和行为受情景顺序影响，相关建议已提出。

Conclusion: 研究表明，热反馈虽然在用户体验问卷中的效果无显著差异，但其影响因参与者特征和访谈而有所不同；参与者行为也受情景次序的影响。

Abstract: Thermal feedback is critical to a range of Virtual Reality (VR) applications, such as firefighting training or thermal comfort simulation. Previous studies showed that adding congruent thermal feedback positively influences User eXperience (UX). However, existing work did not compare different levels of thermal feedback quality and mostly used less immersive virtual environments. To investigate these gaps in the scientific literature, we conducted a within-participant user study in two highly-immersive scenarios, Desert Island (n=25) and Snowy Mountains (n=24). Participants explored the scenarios in three conditions (Audio-Visual only, Static-Thermal Feedback, and Dynamic-Thermal Feedback). To assess the complex and subtle effects of thermal feedback on UX, we performed a multimodal analysis by crossing data from questionnaires, semi-structured interviews, and behavioral indicators. Our results show that despite an already high level of presence in the Audio-Visual only condition, adding thermal feedback increased presence further. Comparison between levels of thermal feedback quality showed no significant difference in UX questionnaires, however this result is nuanced according to participant profiles and interviews. Furthermore, we show that although the order of passage did not influence UX directly, it influenced user behavior. We propose guidelines for the use of thermal feedback in VR, and the design of studies in complex multisensory scenarios.

</details>


### [8] [OnomaCompass: A Texture Exploration Interface that Shuttles between Words and Images](https://arxiv.org/abs/2601.04915)
*Miki Okamura,Shuhey Koyama,Li Jingjing,Yoichi Ochiai*

Main category: cs.HC

TL;DR: OnomaCompass是一个基于网络的探索系统，通过声音象征的拟声词和视觉纹理表示支持材料发现，显著降低用户工作负担并提升用户体验。


<details>
  <summary>Details</summary>
Motivation: 人类能够细致感知材料纹理，但将这些感觉用语言表达出来在设计构思中存在瓶颈。

Method: OnomaCompass提供两个协调的潜在空间地图，一个用于纹理图像，另一个用于拟声词，基于发明的拟声词和通过Stable Diffusion生成的相应纹理构建。用户可以在两个空间中导航，触发跨模态高亮，并使用图像编辑模型预览被应用于物体的纹理。

Result: 与基于提示的图像生成工作流程相比，OnomaCompass显著降低了工作负担，并增强了用户愉悦体验。

Conclusion: 利用声音象征作为轻量提示，为超越基于提示生成的材料构思提供了一种互补方法。

Abstract: Humans can finely perceive material textures, yet articulating such somatic impressions in words is a cognitive bottleneck in design ideation. We present OnomaCompass, a web-based exploration system that links sound-symbolic onomatopoeia and visual texture representations to support early-stage material discovery. Instead of requiring users to craft precise prompts for generative AI, OnomaCompass provides two coordinated latent-space maps--one for texture images and one for onomatopoeic term--built from an authored dataset of invented onomatopoeia and corresponding textures generated via Stable Diffusion. Users can navigate both spaces, trigger cross-modal highlighting, curate findings in a gallery, and preview textures applied to objects via an image-editing model. The system also supports video interpolation between selected textures and re-embedding of extracted frames to form an emergent exploration loop. We conducted a within-subjects study with 11 participants comparing OnomaCompass to a prompt-based image-generation workflow using Gemini 2.5 Flash Image ("Nano Banana"). OnomaCompass significantly reduced workload (NASA-TLX overall, mental demand, effort, and frustration; p < .05) and increased hedonic user experience (UEQ), while usability (SUS) favored the baseline. Qualitative findings indicate that OnomaCompass helps users externalize vague sensory expectations and promotes serendipitous discovery, but also reveals interaction challenges in spatial navigation. Overall, leveraging sound symbolism as a lightweight cue offers a complementary approach to Kansei-driven material ideation beyond prompt-centric generation.

</details>


### [9] [Driver-Intention Prediction with Deep Learning: Real-Time Brain-to-Vehicle Communication](https://arxiv.org/abs/2601.05084)
*Niloufar Alavi,Swati Shah,Rezvan Alamian,Stefan Goetz*

Main category: cs.HC

TL;DR: 该研究提出了一种通过EEG信号和深度学习预测驾驶者转向意图的方法，分类准确率为83.7%。


<details>
  <summary>Details</summary>
Motivation: BCI技术能够在没有语言或身体运动的情况下实现大脑与电子设备之间的直接通信，尤其在需要快速反应的应用中具有显著优势。

Method: 使用深度学习通过脑电图（EEG）信号预测驾驶者的转向意图，利用卷积神经网络（CNN）分类EEG数据

Result: 模型在区分三种转向意图时，达到了83.7%的准确率，尤其是在右转段的分类准确率最高，显示出大脑活动可能存在空间偏向。

Conclusion: 本研究为更直观的脑-车通信系统奠定了基础。

Abstract: Brain-computer interfaces (BCIs) allow direct communication between the brain and electronics without the need for speech or physical movement. Such interfaces can be particularly beneficial in applications requiring rapid response times, such as driving, where a vehicle's advanced driving assistance systems could benefit from immediate understanding of a driver's intentions. This study presents a novel method for predicting a driver's intention to steer using electroencephalography (EEG) signals through deep learning. A driving simulator created a controlled environment in which participants imagined controlling a vehicle during various driving scenarios, including left and right turns, as well as straight driving. A convolutional neural network (CNN) classified the detected EEG data with minimal pre-processing. Our model achieved an accuracy of 83.7% in distinguishing between the three steering intentions and demonstrated the ability of CNNs to process raw EEG data effectively. The classification accuracy was highest for right-turn segments, which suggests a potential spatial bias in brain activity. This study lays the foundation for more intuitive brain-to-vehicle communication systems.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [10] [Autonomous Reasoning for Spacecraft Control: A Large Language Model Framework with Group Relative Policy Optimization](https://arxiv.org/abs/2601.04334)
*Amit Jain,Richard Linares*

Main category: cs.RO

TL;DR: 本论文提出了一种基于学习的指导与控制方法，将具备推理能力的大型语言模型（LLM）与群体相对政策优化（GRPO）相结合，经过两阶段训练，在不同控制问题上展现出优越的控制能力。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探讨如何将大型语言模型的推理能力与控制策略优化结合，以提升自主控制系统的稳定性和可解释性。

Method: 采用两阶段方法：首先进行监督微调（SFT）以学习格式和控制原语，然后利用GRPO进行基于互动的策略改进。

Result: 研究展示，在保持一致的训练设置下，具备显式推理的LLM可以为线性和非线性系统合成可行的稳定政策。

Conclusion: 该工作为将GRPO与推理结合应用于自主控制系统奠定了基础，具有在航空航天及其他安全关键领域应用的潜力。

Abstract: This paper presents a learning-based guidance-and-control approach that couples a reasoning-enabled Large Language Model (LLM) with Group Relative Policy Optimization (GRPO). A two-stage procedure consisting of Supervised Fine-Tuning (SFT) to learn formatting and control primitives, followed by GRPO for interaction-driven policy improvement, trains controllers for each environment. The framework is demonstrated on four control problems spanning a gradient of dynamical complexity, from canonical linear systems through nonlinear oscillatory dynamics to three-dimensional spacecraft attitude control with gyroscopic coupling and thrust constraints. Results demonstrate that an LLM with explicit reasoning, optimized via GRPO, can synthesize feasible stabilizing policies under consistent training settings across both linear and nonlinear systems. The two-stage training methodology enables models to generate control sequences while providing human-readable explanations of their decision-making process. This work establishes a foundation for applying GRPO-based reasoning to autonomous control systems, with potential applications in aerospace and other safety-critical domains.

</details>


### [11] [UNIC: Learning Unified Multimodal Extrinsic Contact Estimation](https://arxiv.org/abs/2601.04356)
*Zhengtong Xu,Yuki Shirai*

Main category: cs.RO

TL;DR: UNIC是一个统一的多模态框架，能够在没有先验知识或相机校准的情况下进行外部接触估计，表现出高可靠性和适应性。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法对预定义接触类型、固定抓取配置或相机校准的依赖问题，从而提高对新物体的泛化能力和在非结构化环境中的应用。

Method: 提出了一种统一的多模态框架，通过直接编码视觉观察并与本体和触觉模态集成，采取完全数据驱动的方法。

Result: 在未见接触位置达到了9.6mm的平均Chamfer距离误差，能在缺失模态下稳定表现，对动态相机视角具有良好的适应性。

Conclusion: UNIC显著提高了外部接触估计的可靠性和适应性，能够处理未见物体和动态环境。

Abstract: Contact-rich manipulation requires reliable estimation of extrinsic contacts-the interactions between a grasped object and its environment which provide essential contextual information for planning, control, and policy learning. However, existing approaches often rely on restrictive assumptions, such as predefined contact types, fixed grasp configurations, or camera calibration, that hinder generalization to novel objects and deployment in unstructured environments. In this paper, we present UNIC, a unified multimodal framework for extrinsic contact estimation that operates without any prior knowledge or camera calibration. UNIC directly encodes visual observations in the camera frame and integrates them with proprioceptive and tactile modalities in a fully data-driven manner. It introduces a unified contact representation based on scene affordance maps that captures diverse contact formations and employs a multimodal fusion mechanism with random masking, enabling robust multimodal representation learning. Extensive experiments demonstrate that UNIC performs reliably. It achieves a 9.6 mm average Chamfer distance error on unseen contact locations, performs well on unseen objects, remains robust under missing modalities, and adapts to dynamic camera viewpoints. These results establish extrinsic contact estimation as a practical and versatile capability for contact-rich manipulation.

</details>


### [12] [Transformer-based Multi-agent Reinforcement Learning for Separation Assurance in Structured and Unstructured Airspaces](https://arxiv.org/abs/2601.04401)
*Arsyi Aziz,Peng Wei*

Main category: cs.RO

TL;DR: 传统优化依赖严格时间表，限制了AAM的灵活性；而多智能体强化学习提供去中心化，自适应框架。通过相对极坐标重新构造，测试不同深度的编码器，单层配置优于深层变体，提出了一种适应性强的飞机分离保障解决方案。


<details>
  <summary>Details</summary>
Motivation: 传统的基于优化的计量依赖于严格遵循预定义的时间表，限制了对先进空中移动的随机操作所需的灵活性。

Method: 将多智能体强化学习问题重新构造为相对极坐标状态空间，并在多样的交通模式和交叉角度上训练变压器编码器模型。

Result: 在结构化和非结构化空域中实验，发现单层编码器的配置在接近零的空中碰撞率和更短的分离违规时间方面优于更深的变体，并且优于纯粹基于注意力设计的基线模型。

Conclusion: 新提出的状态表示、神经网络架构设计和训练策略为结构化与非结构化空域中的飞机分离保障提供了一个具适应性和可扩展性的去中心化解决方案。

Abstract: Conventional optimization-based metering depends on strict adherence to precomputed schedules, which limits the flexibility required for the stochastic operations of Advanced Air Mobility (AAM). In contrast, multi-agent reinforcement learning (MARL) offers a decentralized, adaptive framework that can better handle uncertainty, required for safe aircraft separation assurance. Despite this advantage, current MARL approaches often overfit to specific airspace structures, limiting their adaptability to new configurations. To improve generalization, we recast the MARL problem in a relative polar state space and train a transformer encoder model across diverse traffic patterns and intersection angles. The learned model provides speed advisories to resolve conflicts while maintaining aircraft near their desired cruising speeds. In our experiments, we evaluated encoder depths of 1, 2, and 3 layers in both structured and unstructured airspaces, and found that a single encoder configuration outperformed deeper variants, yielding near-zero near mid-air collision rates and shorter loss-of-separation infringements than the deeper configurations. Additionally, we showed that the same configuration outperforms a baseline model designed purely with attention. Together, our results suggest that the newly formulated state representation, novel design of neural network architecture, and proposed training strategy provide an adaptable and scalable decentralized solution for aircraft separation assurance in both structured and unstructured airspaces.

</details>


### [13] [Fast Continuum Robot Shape and External Load State Estimation on SE(3)](https://arxiv.org/abs/2601.04493)
*James M. Ferguson,Alan Kuntz,Tucker Hermans*

Main category: cs.RO

TL;DR: 本文提出了一种新颖的框架，用于连续机器人状态估计，能够处理多种不确定性因素，并进行了实证验证。


<details>
  <summary>Details</summary>
Motivation: 先前的状态估计方法过于简化，无法有效考虑驱动输入和外部负荷，因此需要一个更全面的框架。

Method: 通过将时间先验引入模型，实现了在空间和时间域的联合估计，并采用离散化技术生成了因子图表示，以进行快速非线性优化。

Result: 提出了一种通用框架，能够进行连续机器人状态估计，包括驱动不确定性、外力与力矩、过程噪声、边界条件和任意主干测量。

Conclusion: 该框架适用于广泛的连续机器人，并在仿真和实验中验证了准确的运动学和力估计。

Abstract: Previous on-manifold approaches to continuum robot state estimation have typically adopted simplified Cosserat rod models, which cannot directly account for actuation inputs or external loads. We introduce a general framework that incorporates uncertainty models for actuation (e.g., tendon tensions), applied forces and moments, process noise, boundary conditions, and arbitrary backbone measurements. By adding temporal priors across time steps, our method additionally performs joint estimation in both the spatial (arclength) and temporal domains, enabling full \textit{spacetime} state estimation. Discretizing the arclength domain yields a factor graph representation of the continuum robot model, which can be exploited for fast batch sparse nonlinear optimization in the style of SLAM. The framework is general and applies to a broad class of continuum robots; as illustrative cases, we show (i) tendon-driven robots in simulation, where we demonstrate real-time kinematics with uncertainty, tip force sensing from position feedback, and distributed load estimation from backbone strain, and (ii) a surgical concentric tube robot in experiment, where we validate accurate kinematics and tip force estimation, highlighting potential for surgical palpation.

</details>


### [14] [Multiagent Reinforcement Learning with Neighbor Action Estimation](https://arxiv.org/abs/2601.04511)
*Zhenglong Luo,Zhiyong Chen,Aoxiang Liu*

Main category: cs.RO

TL;DR: 本研究提出了一种新框架，以改善多智能体系统在信息受限环境中的决策能力，增强实际应用的可行性。


<details>
  <summary>Details</summary>
Motivation: 现有方法对智能体之间的显式行动交换依赖过大，这在实际工程中存在通信限制和可靠性等问题。

Method: 通过集成轻量动作估计模块，智能体仅基于局部可观测信息推断邻居智能体的行为，支持协作策略学习。

Result: 提出了一种增强的多智能体强化学习框架，该框架使用动作估计神经网络推断智能体行为，无需显式行动交换。

Conclusion: 该框架在双臂机器人操作任务中的有效性得到了验证，显著提高了机器人系统的鲁棒性和可部署性。

Abstract: Multiagent reinforcement learning, as a prominent intelligent paradigm, enables collaborative decision-making within complex systems. However, existing approaches often rely on explicit action exchange between agents to evaluate action value functions, which is frequently impractical in real-world engineering environments due to communication constraints, latency, energy consumption, and reliability requirements. From an artificial intelligence perspective, this paper proposes an enhanced multiagent reinforcement learning framework that employs action estimation neural networks to infer agent behaviors. By integrating a lightweight action estimation module, each agent infers neighboring agents' behaviors using only locally observable information, enabling collaborative policy learning without explicit action sharing. This approach is fully compatible with standard TD3 algorithms and scalable to larger multiagent systems. At the engineering application level, this framework has been implemented and validated in dual-arm robotic manipulation tasks: two robotic arms collaboratively lift objects. Experimental results demonstrate that this approach significantly enhances the robustness and deployment feasibility of real-world robotic systems while reducing dependence on information infrastructure. Overall, this research advances the development of decentralized multiagent artificial intelligence systems while enabling AI to operate effectively in dynamic, information-constrained real-world environments.

</details>


### [15] [Design and Development of Modular Limbs for Reconfigurable Robots on the Moon](https://arxiv.org/abs/2601.04541)
*Gustavo H. Diaz,A. Sejal Jain,Matteo Brugnera,Elian Neppel,Shreya Santra,Kentaro Uno,Kazuya Yoshida*

Main category: cs.RO

TL;DR: 本文介绍了4自由度机器人肢体Moonbots的发展，能够以不同配置连接彼此和轮子模块，适应不同环境和任务，主要用于太空探索和月球建设。


<details>
  <summary>Details</summary>
Motivation: 开发灵活和多功能的模块化机器人，以应对资源有限的太空任务，并支持在月球上的探索和建设工作。

Method: 设计了基于统一驱动器的模块化组件，描述了硬件实现、机械设计和整体软件架构，用于控制和协调这些模块，并评估驱动器在不同负载条件下的控制性能。

Result: 提出了九种功能配置，包括4DOF肢体、8DOF肢体、车辆、龙形、最小、四足、货物、货物-最小和自行车，展示了系统的适应性。

Conclusion: 这些配置反映了不同的运动策略和任务特定行为，为可重构机器人系统的进一步研究提供了实际基础。

Abstract: In this paper, we present the development of 4-DOF robot limbs, which we call Moonbots, designed to connect in various configurations with each other and wheel modules, enabling adaptation to different environments and tasks. These modular components are intended primarily for robotic systems in space exploration and construction on the Moon in our Moonshot project. Such modular robots add flexibility and versatility for space missions where resources are constrained. Each module is driven by a common actuator characterized by a high torque-to-speed ratio, supporting both precise control and dynamic motion when required. This unified actuator design simplifies development and maintenance across the different module types. The paper describes the hardware implementation, the mechanical design of the modules, and the overall software architecture used to control and coordinate them. Additionally, we evaluate the control performance of the actuator under various load conditions to characterize its suitability for modular robot applications. To demonstrate the adaptability of the system, we introduce nine functional configurations assembled from the same set of modules: 4DOF-limb, 8DOF-limb, vehicle, dragon, minimal, quadruped, cargo, cargo-minimal, and bike. These configurations reflect different locomotion strategies and task-specific behaviors, offering a practical foundation for further research in reconfigurable robotic systems.

</details>


### [16] [Model of Spatial Human-Agent Interaction with Consideration for Others](https://arxiv.org/abs/2601.04657)
*Takafumi Sakamoto,Yugo Takeuchi*

Main category: cs.RO

TL;DR: 本研究构建了一个考虑他人的计算空间互动模型，并通过实验验证了该模型能够有效支持机器人在公共场所与人进行交互时，根据他人的行为来调节自身的沟通活动。


<details>
  <summary>Details</summary>
Motivation: 探讨如何使沟通机器人在公共场所根据他人的行为来调节自身的沟通活动，以满足不打扰行人的需求。

Method: 在虚拟现实环境中进行人类与机器人之间的互动实验。

Result: 实验结果表明，具有低考虑值的虚拟机器人会抑制参与者的移动，而具有高考虑值的机器人则不会抑制移动，且机器人在参与者接近时总是表现出逼近行为。

Conclusion: 提出的模型能够有效阐明考虑他人互动的机制。

Abstract: Communication robots often need to initiate conversations with people in public spaces. At the same time, such robots must not disturb pedestrians. To handle these two requirements, an agent needs to estimate the communication desires of others based on their behavior and then adjust its own communication activities accordingly. In this study, we construct a computational spatial interaction model that considers others. Consideration is expressed as a quantitative parameter: the amount of adjustment of one's internal state to the estimated internal state of the other. To validate the model, we experimented with a human and a virtual robot interacting in a VR environment. The results show that when the participant moves to the target, a virtual robot with a low consideration value inhibits the participant's movement, while a robot with a higher consideration value did not inhibit the participant's movement. When the participant approached the robot, the robot also exhibited approaching behavior, regardless of the consideration value, thus decreasing the participant's movement. These results appear to verify the proposed model's ability to clarify interactions with consideration for others.

</details>


### [17] [Data-Driven Terramechanics Approach Towards a Realistic Real-Time Simulator for Lunar Rovers](https://arxiv.org/abs/2601.04547)
*Jakob M. Kern,James M. Hurrell,Shreya Santra,Keisuke Takehana,Kentaro Uno,Kazuya Yoshida*

Main category: cs.RO

TL;DR: 本研究提出了一种结合高视觉真实感和真实地形交互的月球表面模拟器，克服了传统模拟器在真实感与物理精确度之间的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前月球表面模拟器在视觉真实感和物理准确性之间存在分歧，无法全面复制月球条件。

Method: 采用数据驱动的方法，通过回归模型进行轮子与土壤相互作用的模拟，模型根据全车和单轮实验及模拟数据进行构建。

Result: 回归基础的土工力学模型能准确再现平地和20度坡道上的稳态和动态滑移及沉降行为，验证结果与实地测试相符。

Conclusion: 该方法支持需要物理上合理的地形响应和高视觉真实感的实时应用。

Abstract: High-fidelity simulators for the lunar surface provide a digital environment for extensive testing of rover operations and mission planning. However, current simulators focus on either visual realism or physical accuracy, which limits their capability to replicate lunar conditions comprehensively. This work addresses that gap by combining high visual fidelity with realistic terrain interaction for a realistic representation of rovers on the lunar surface. Because direct simulation of wheel-soil interactions is computationally expensive, a data-driven approach was adopted, using regression models for slip and sinkage from data collected in both full-rover and single-wheel experiments and simulations. The resulting regression-based terramechanics model accurately reproduced steady-state and dynamic slip, as well as sinkage behavior, on flat terrain and slopes up to 20 degrees, with validation against field test results. Additionally, improvements were made to enhance the realism of terrain deformation and wheel trace visualization. This method supports real-time applications that require physically plausible terrain response alongside high visual fidelity.

</details>


### [18] [Discrete Fourier Transform-based Point Cloud Compression for Efficient SLAM in Featureless Terrain](https://arxiv.org/abs/2601.04551)
*Riku Suzuki,Ayumi Umemura,Shreya Santra,Kentaro Uno,Kazuya Yoshida*

Main category: cs.RO

TL;DR: 提出了一种新方法，通过离散傅里叶变换 (DFT) 压缩点云地图，以适应无人机探索任务中的计算和通信限制。


<details>
  <summary>Details</summary>
Motivation: 在机器人探索任务中，计算能力和通信带宽有限，点云数据庞大，因此需要有效的数据压缩方法。

Method: 使用离散傅里叶变换将数字高程模型（DEM）转换为频域2D图像，省略高频成分，专注于逐渐变化的地形。

Result: 通过对两种不同高程轮廓的地形的摄像头序列进行评估，验证了该方法在压缩率和精度方面的有效性。

Conclusion: 该方法在压缩数据大小的同时，保持了点云的表示精度，特别适用于逐渐变化的地形。

Abstract: Simultaneous Localization and Mapping (SLAM) is an essential technology for the efficiency and reliability of unmanned robotic exploration missions. While the onboard computational capability and communication bandwidth are critically limited, the point cloud data handled by SLAM is large in size, attracting attention to data compression methods. To address such a problem, in this paper, we propose a new method for compressing point cloud maps by exploiting the Discrete Fourier Transform (DFT). The proposed technique converts the Digital Elevation Model (DEM) to the frequency-domain 2D image and omits its high-frequency components, focusing on the exploration of gradual terrains such as planets and deserts. Unlike terrains with detailed structures such as artificial environments, high-frequency components contribute little to the representation of gradual terrains. Thus, this method is effective in compressing data size without significant degradation of the point cloud. We evaluated the method in terms of compression rate and accuracy using camera sequences of two terrains with different elevation profiles.

</details>


### [19] [UniBiDex: A Unified Teleoperation Framework for Robotic Bimanual Dexterous Manipulation](https://arxiv.org/abs/2601.04629)
*Zhongxuan Li,Zeliang Guo,Jun Hu,David Navarro-Alarcon,Jia Pan,Hongmin Wu,Peng Zhou*

Main category: cs.RO

TL;DR: UniBiDex是一个统一的遥操作框架，用于双手灵巧操作，通过集成多种输入方式实现高效和安全的操作，并在实际任务中表现出色，同时支持开源，促进机器人学习发展。


<details>
  <summary>Details</summary>
Motivation: 开发一个统一的遥操作框架，以支持双手灵巧操作，并能适应不同的输入方式，以提高机器人的操作效率和安全性。

Method: UniBiDex框架通过集成异构输入设备，实现对双臂的实时控制，采用null空间控制优化双手配置，以确保操作的平滑性、无碰撞和对奇异性的敏感性。

Result: 在长时间的厨房清理任务中，UniBiDex展示了更高的任务成功率、更平滑的运动轨迹和更好的鲁棒性，相较于强有力的基线方法。

Conclusion: 通过开放源代码发布所有硬件和软件组件，降低高质量人类示范数据集的收集门槛，推动机器人学习的进展。

Abstract: We present UniBiDex a unified teleoperation framework for robotic bimanual dexterous manipulation that supports both VRbased and leaderfollower input modalities UniBiDex enables realtime contactrich dualarm teleoperation by integrating heterogeneous input devices into a shared control stack with consistent kinematic treatment and safety guarantees The framework employs nullspace control to optimize bimanual configurations ensuring smooth collisionfree and singularityaware motion across tasks We validate UniBiDex on a longhorizon kitchentidying task involving five sequential manipulation subtasks demonstrating higher task success rates smoother trajectories and improved robustness compared to strong baselines By releasing all hardware and software components as opensource we aim to lower the barrier to collecting largescale highquality human demonstration datasets and accelerate progress in robot learning.

</details>


### [20] [Optimizing Path Planning using Deep Reinforcement Learning for UGVs in Precision Agriculture](https://arxiv.org/abs/2601.04668)
*Laukik Patade,Rohan Rane,Sandeep Pillai*

Main category: cs.RO

TL;DR: 本研究探讨了使用深度强化学习优化无人地面车辆在精准农业中的路径规划，重点是连续动作空间模型，实验结果表明该方法在动态环境中表现优越。


<details>
  <summary>Details</summary>
Motivation: 随着精准农业的发展，对无人地面车辆的路径规划提出了更高要求，传统的网格方法在动态环境中表现出局限，因此需要寻找自适应学习策略。

Method: 本研究使用深度强化学习方法，包括DQN、DDPG和TD3，在逐步复杂的三维环境中进行测试，并进行实验证明其效果。

Result: 在三维环境中进行的实验表明，连续深度强化学习算法在动态农业场景中表现有效，尤其是在处理移动障碍物时，预训练TD3代理达到了95%的成功率。

Conclusion: 预训练TD3代理在动态环境中实现了95%的成功率，证明了该方法在处理移动障碍物时的鲁棒性，同时确保了作物和机器人的安全。

Abstract: This study focuses on optimizing path planning for unmanned ground vehicles (UGVs) in precision agriculture using deep reinforcement learning (DRL) techniques in continuous action spaces. The research begins with a review of traditional grid-based methods, such as A* and Dijkstra's algorithms, and discusses their limitations in dynamic agricultural environments, highlighting the need for adaptive learning strategies. The study then explores DRL approaches, including Deep Q-Networks (DQN), which demonstrate improved adaptability and performance in two-dimensional simulations. Enhancements such as Double Q-Networks and Dueling Networks are evaluated to further improve decision-making. Building on these results, the focus shifts to continuous action space models, specifically Deep Deterministic Policy Gradient (DDPG) and Twin Delayed Deep Deterministic Policy Gradient (TD3), which are tested in increasingly complex environments. Experiments conducted in a three-dimensional environment using ROS and Gazebo demonstrate the effectiveness of continuous DRL algorithms in navigating dynamic agricultural scenarios. Notably, the pretrained TD3 agent achieves a 95 percent success rate in dynamic environments, demonstrating the robustness of the proposed approach in handling moving obstacles while ensuring safety for both crops and the robot.

</details>


### [21] [SeqWalker: Sequential-Horizon Vision-and-Language Navigation with Hierarchical Planning](https://arxiv.org/abs/2601.04699)
*Zebin Han,Xudong Wang,Baichen Liu,Qi Lyu,Zhenduo Shang,Jiahua Dong,Lianqing Liu,Zhi Han*

Main category: cs.RO

TL;DR: SeqWalker是一种在分层规划框架下的导航模型，旨在提升复杂长篇语言指令下的导航性能，通过动态选择相关子指令和利用探索验证策略来减少认知负担和纠正轨迹错误。


<details>
  <summary>Details</summary>
Motivation: 在多任务导航中，基于语言的模型因信息过载而性能下降，因此需要一种新模型来改善这种情况。

Method: SeqWalker采用分层规划框架，包含高层规划器和低层规划器，前者动态选择子指令，后者使用探索验证策略。

Result: 大量实验表明，SeqWalker在性能上优于现有的视觉-语言导航模型，且在扩展的IVLN数据集上设立了新基准。

Conclusion: SeqWalker模型在复杂长篇语言指令的引导下表现优越，能够有效提高多任务导航的执行效率，且在新的基准上验证了其优势。

Abstract: Sequential-Horizon Vision-and-Language Navigation (SH-VLN) presents a challenging scenario where agents should sequentially execute multi-task navigation guided by complex, long-horizon language instructions. Current vision-and-language navigation models exhibit significant performance degradation with such multi-task instructions, as information overload impairs the agent's ability to attend to observationally relevant details. To address this problem, we propose SeqWalker, a navigation model built on a hierarchical planning framework. Our SeqWalker features: i) A High-Level Planner that dynamically selects global instructions into contextually relevant sub-instructions based on the agent's current visual observations, thus reducing cognitive load; ii) A Low-Level Planner incorporating an Exploration-Verification strategy that leverages the inherent logical structure of instructions for trajectory error correction. To evaluate SH-VLN performance, we also extend the IVLN dataset and establish a new benchmark. Extensive experiments are performed to demonstrate the superiority of the proposed SeqWalker.

</details>


### [22] [Zero Wrench Control via Wrench Disturbance Observer for Learning-free Peg-in-hole Assembly](https://arxiv.org/abs/2601.04881)
*Kiyoung Choi,Juwon Jeong,Sehoon Oh*

Main category: cs.RO

TL;DR: 本文提出的动态扭矩扰动观测器(DW-DOB)在接触丰富的操作中，实现了高灵敏度的零扭矩控制，有效解决了传统方法的不足，并在实验中表现出优越性。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统观测器在补偿惯性效应时的不足，并在动态条件下保证稳定的交互。

Method: 通过将任务空间的惯性嵌入到观测器的名义模型中，DW-DOB实现了内在动态反应与真实外部扭矩的清晰分离。

Result: DW-DOB在工业公差下的Peg-in-hole实验中，显示出更深更顺应的插入效果，残余扭矩最小，超过了传统扭矩扰动观测器和PD基线。

Conclusion: DW-DOB提供了一种高灵敏度的零扭矩控制方案，适用于接触丰富的操作任务，且表现优于传统观测器及PD基线。

Abstract: This paper proposes a Dynamic Wrench Disturbance Observer (DW-DOB) designed to achieve highly sensitive zero-wrench control in contact-rich manipulation. By embedding task-space inertia into the observer nominal model, DW-DOB cleanly separates intrinsic dynamic reactions from true external wrenches. This preserves sensitivity to small forces and moments while ensuring robust regulation of contact wrenches. A passivity-based analysis further demonstrates that DW-DOB guarantees stable interactions under dynamic conditions, addressing the shortcomings of conventional observers that fail to compensate for inertial effects. Peg-in-hole experiments at industrial tolerances (H7/h6) validate the approach, yielding deeper and more compliant insertions with minimal residual wrenches and outperforming a conventional wrench disturbance observer and a PD baseline. These results highlight DW-DOB as a practical learning-free solution for high-precision zero-wrench control in contact-rich tasks.

</details>


### [23] [SKATER: Synthesized Kinematics for Advanced Traversing Efficiency on a Humanoid Robot via Roller Skate Swizzles](https://arxiv.org/abs/2601.04948)
*Junchi Gu,Feiyang Yuan,Weize Shi,Tianchen Huang,Haopeng Zhang,Xiaohu Zhang,Yu Wang,Wei Gao,Shiwu Zhang*

Main category: cs.RO

TL;DR: 提出一种新型的带被动轮的类人机器人，通过滑行运动优化能量效率，减少关节磨损。


<details>
  <summary>Details</summary>
Motivation: 类人机器人在行走和跑步中频繁的足部冲击导致高瞬时冲击力，增加关节磨损及降低能量利用率。

Method: 通过为每只脚配备四个被动轮，结合深度强化学习框架控制滑行步态，设计基于滑行特性的奖励函数。

Result: 在模拟中分析学习的策略，并在物理机器人上部署，结果显示滑行步态在冲击强度和运输成本上优于传统的双足行走。

Conclusion: 滑行作为一种运动模式，展示出显著提高能量效率和延长关节寿命的优势。

Abstract: Although recent years have seen significant progress of humanoid robots in walking and running, the frequent foot strikes with ground during these locomotion gaits inevitably generate high instantaneous impact forces, which leads to exacerbated joint wear and poor energy utilization. Roller skating, as a sport with substantial biomechanical value, can achieve fast and continuous sliding through rational utilization of body inertia, featuring minimal kinetic energy loss. Therefore, this study proposes a novel humanoid robot with each foot equipped with a row of four passive wheels for roller skating. A deep reinforcement learning control framework is also developed for the swizzle gait with the reward function design based on the intrinsic characteristics of roller skating. The learned policy is first analyzed in simulation and then deployed on the physical robot to demonstrate the smoothness and efficiency of the swizzle gait over traditional bipedal walking gait in terms of Impact Intensity and Cost of Transport during locomotion. A reduction of $75.86\%$ and $63.34\%$ of these two metrics indicate roller skating as a superior locomotion mode for enhanced energy efficiency and joint longevity.

</details>


### [24] [When to Act: Calibrated Confidence for Reliable Human Intention Prediction in Assistive Robotics](https://arxiv.org/abs/2601.04982)
*Johannes A. Gaus,Winfried Ilg,Daniel Haeufle*

Main category: cs.RO

TL;DR: 介绍了一种基于校准概率的框架，提升助理设备对用户意图的预测可靠性，降低安全风险。


<details>
  <summary>Details</summary>
Motivation: 助理设备需准确预测用户意图并评估预测的可靠性，确保提供安全支持。

Method: 基于校准概率的多模态下一步动作预测的安全触发框架

Result: 通过后置校准，将预测的置信度与实际可靠性对齐，显著减少误校准，未影响准确性。

Conclusion: 校准后的置信度驱动ACT/HOLD规则，仅在可靠性高时提供帮助，转化置信度阈值为定量安全参数，确保助理控制回路中的可验证行为。

Abstract: Assistive devices must determine both what a user intends to do and how reliable that prediction is before providing support. We introduce a safety-critical triggering framework based on calibrated probabilities for multimodal next-action prediction in Activities of Daily Living. Raw model confidence often fails to reflect true correctness, posing a safety risk. Post-hoc calibration aligns predicted confidence with empirical reliability and reduces miscalibration by about an order of magnitude without affecting accuracy. The calibrated confidence drives a simple ACT/HOLD rule that acts only when reliability is high and withholds assistance otherwise. This turns the confidence threshold into a quantitative safety parameter for assisted actions and enables verifiable behavior in an assistive control loop.

</details>


### [25] [The RoboSense Challenge: Sense Anything, Navigate Anywhere, Adapt Across Platforms](https://arxiv.org/abs/2601.05014)
*Lingdong Kong,Shaoyuan Xie,Zeying Gong,Ye Li,Meng Chu,Ao Liang,Yuhao Dong,Tianshuai Hu,Ronghe Qiu,Rong Li,Hanjiang Hu,Dongyue Lu,Wei Yin,Wenhao Ding,Linfeng Li,Hang Song,Wenwei Zhang,Yuexin Ma,Junwei Liang,Zhedong Zheng,Lai Xing Ng,Benoit R. Cottereau,Wei Tsang Ooi,Ziwei Liu,Zhanpeng Zhang,Weichao Qiu,Wei Zhang,Ji Ao,Jiangpeng Zheng,Siyu Wang,Guang Yang,Zihao Zhang,Yu Zhong,Enzhu Gao,Xinhan Zheng,Xueting Wang,Shouming Li,Yunkai Gao,Siming Lan,Mingfei Han,Xing Hu,Dusan Malic,Christian Fruhwirth-Reisinger,Alexander Prutsch,Wei Lin,Samuel Schulter,Horst Possegger,Linfeng Li,Jian Zhao,Zepeng Yang,Yuhang Song,Bojun Lin,Tianle Zhang,Yuchen Yuan,Chi Zhang,Xuelong Li,Youngseok Kim,Sihwan Hwang,Hyeonjun Jeong,Aodi Wu,Xubo Luo,Erjia Xiao,Lingfeng Zhang,Yingbo Tang,Hao Cheng,Renjing Xu,Wenbo Ding,Lei Zhou,Long Chen,Hangjun Ye,Xiaoshuai Hao,Shuangzhi Li,Junlong Shen,Xingyu Li,Hao Ruan,Jinliang Lin,Zhiming Luo,Yu Zang,Cheng Wang,Hanshi Wang,Xijie Gong,Yixiang Yang,Qianli Ma,Zhipeng Zhang,Wenxiang Shi,Jingmeng Zhou,Weijun Zeng,Kexin Xu,Yuchen Zhang,Haoxiang Fu,Ruibin Hu,Yanbiao Ma,Xiyan Feng,Wenbo Zhang,Lu Zhang,Yunzhi Zhuge,Huchuan Lu,You He,Seungjun Yu,Junsung Park,Youngsun Lim,Hyunjung Shim,Faduo Liang,Zihang Wang,Yiming Peng,Guanyu Zong,Xu Li,Binghao Wang,Hao Wei,Yongxin Ma,Yunke Shi,Shuaipeng Liu,Dong Kong,Yongchun Lin,Huitong Yang,Liang Lei,Haoang Li,Xinliang Zhang,Zhiyong Wang,Xiaofeng Wang,Yuxia Fu,Yadan Luo,Djamahl Etchegaray,Yang Li,Congfei Li,Yuxiang Sun,Wenkai Zhu,Wang Xu,Linru Li,Longjie Liao,Jun Yan,Benwu Wang,Xueliang Ren,Xiaoyu Yue,Jixian Zheng,Jinfeng Wu,Shurui Qin,Wei Cong,Yao He*

Main category: cs.RO

TL;DR: RoboSense 2025挑战旨在提升机器人感知的鲁棒性和适应性，通过多样化的研究轨道和标准化的数据集，实现各类感知场景的评估。


<details>
  <summary>Details</summary>
Motivation: 在多变和动态的环境中，现有的感知模型面临着可靠性下降的问题，因此亟需建立更鲁棒和可推广的机器人感知系统。

Method: RoboSense 2025挑战包含五个互补的研究轨道，提供标准化数据集、基准模型及统一的评估协议，以评估在不同环境下的感知能力。

Result: 该挑战吸引了来自16个国家的143个团队参与，通过23个获胜解决方案的总结，报告揭示了方法论趋势、设计原则和面临的挑战。

Conclusion: RoboSense 2025挑战为机器人感知领域的鲁棒性和适应性提供了一个全面的基准，通过整合来自参与团队的洞见，推动了未来机器人技术的发展。

Abstract: Autonomous systems are increasingly deployed in open and dynamic environments -- from city streets to aerial and indoor spaces -- where perception models must remain reliable under sensor noise, environmental variation, and platform shifts. However, even state-of-the-art methods often degrade under unseen conditions, highlighting the need for robust and generalizable robot sensing. The RoboSense 2025 Challenge is designed to advance robustness and adaptability in robot perception across diverse sensing scenarios. It unifies five complementary research tracks spanning language-grounded decision making, socially compliant navigation, sensor configuration generalization, cross-view and cross-modal correspondence, and cross-platform 3D perception. Together, these tasks form a comprehensive benchmark for evaluating real-world sensing reliability under domain shifts, sensor failures, and platform discrepancies. RoboSense 2025 provides standardized datasets, baseline models, and unified evaluation protocols, enabling large-scale and reproducible comparison of robust perception methods. The challenge attracted 143 teams from 85 institutions across 16 countries, reflecting broad community engagement. By consolidating insights from 23 winning solutions, this report highlights emerging methodological trends, shared design principles, and open challenges across all tracks, marking a step toward building robots that can sense reliably, act robustly, and adapt across platforms in real-world environments.

</details>


### [26] [Compensation Effect Amplification Control (CEAC): A movement-based approach for coordinated position and velocity control of the elbow of upper-limb prostheses](https://arxiv.org/abs/2601.05074)
*Julian Kulozik,Nathanaël Jarrassé*

Main category: cs.RO

TL;DR: 提出了一种新的控制策略CEAC，通过放大躯干运动来控制义肢肘部速度，提升了上肢义肢的直观控制能力。


<details>
  <summary>Details</summary>
Motivation: 尽管上肢义肢设计有所进步，但实现肘部和腕部控制的直观性仍存在挑战，尤其是在连续和速度调节的运动中。

Method: CEAC控制基于用户的躯干弯曲与伸展，放大躯干与义肢之间的自然耦合，并引入控制延迟以调节义肢关节的位置和速度。

Result: 在绘图任务中，CEAC的表现与自然手臂动作相当，且在不同的手势速度和绘图大小下也能保持良好的表现，维持了合理的躯干姿势。

Conclusion: CEAC为上肢义肢的中间关节提供了一种有前景的控制策略，特别适用于需要连续和精确协调的任务。

Abstract: Despite advances in upper-limb (UL) prosthetic design, achieving intuitive control of intermediate joints - such as the wrist and elbow - remains challenging, particularly for continuous and velocity-modulated movements. We introduce a novel movement-based control paradigm entitled Compensation Effect Amplification Control (CEAC) that leverages users' trunk flexion and extension as input for controlling prosthetic elbow velocity. Considering that the trunk can be both a functional and compensatory joint when performing upper-limb actions, CEAC amplifies the natural coupling between trunk and prosthesis while introducing a controlled delay that allows users to modulate both the position and velocity of the prosthetic joint. We evaluated CEAC in a generic drawing task performed by twelve able-bodied participants using a supernumerary prosthesis with an active elbow. Additionally a multiple-target-reaching task was performed by a subset of ten participants. Results demonstrate task performances comparable to those obtained with natural arm movements, even when gesture velocity or drawing size were varied, while maintaining ergonomic trunk postures. Analysis revealed that CEAC effectively restores joint coordinated action, distributes movement effort between trunk and elbow, enabling intuitive trajectory control without requiring extreme compensatory movements. Overall, CEAC offers a promising control strategy for intermediate joints of UL prostheses, particularly in tasks requiring continuous and precise coordination.

</details>


### [27] [Generate, Transfer, Adapt: Learning Functional Dexterous Grasping from a Single Human Demonstration](https://arxiv.org/abs/2601.05243)
*Xingyi He,Adhitya Polavaram,Yunhao Cao,Om Deshmukh,Tianrui Wang,Xiaowei Zhou,Kuan Fang*

Main category: cs.RO

TL;DR: 本文提出了CorDex，一个从合成数据中学习灵活抓取的框架，能够通过单一的人类演示生成多样化的训练数据，结合视觉与几何信息实现高效的抓取预测。


<details>
  <summary>Details</summary>
Motivation: 灵巧机器人手的功能性抓取是实现工具使用和复杂操作的关键能力，但受限于大规模数据集的稀缺和学习模型中缺乏集成语义与几何推理的现象。

Method: 提出了CorDex框架，核心是基于对应关系的数据引擎，能够从单个人类演示生成多样化高质量的合成训练数据，并通过局部-全局融合模块和重要性感知采样机制，整合视觉与几何信息进行抓取预测。

Result: 通过一系列广泛的实验，CorDex在多种物体类别上展示了其卓越的推广能力和显著的性能优势。

Conclusion: CorDex在多个物体类别的实验中表现出色，能够有效推广到未见过的物体实例，并显著优于现有的最佳方法。

Abstract: Functional grasping with dexterous robotic hands is a key capability for enabling tool use and complex manipulation, yet progress has been constrained by two persistent bottlenecks: the scarcity of large-scale datasets and the absence of integrated semantic and geometric reasoning in learned models. In this work, we present CorDex, a framework that robustly learns dexterous functional grasps of novel objects from synthetic data generated from just a single human demonstration. At the core of our approach is a correspondence-based data engine that generates diverse, high-quality training data in simulation. Based on the human demonstration, our data engine generates diverse object instances of the same category, transfers the expert grasp to the generated objects through correspondence estimation, and adapts the grasp through optimization. Building on the generated data, we introduce a multimodal prediction network that integrates visual and geometric information. By devising a local-global fusion module and an importance-aware sampling mechanism, we enable robust and computationally efficient prediction of functional dexterous grasps. Through extensive experiments across various object categories, we demonstrate that CorDex generalizes well to unseen object instances and significantly outperforms state-of-the-art baselines.

</details>


### [28] [LaST$_{0}$: Latent Spatio-Temporal Chain-of-Thought for Robotic Vision-Language-Action Model](https://arxiv.org/abs/2601.05248)
*Zhuoyang Liu,Jiaming Liu,Hao Chen,Ziyu Guo,Chengkai Hou,Chenyang Gu,Jiale Yu,Xiangju Mi,Renrui Zhang,Zhengping Che,Jian Tang,Pheng-Ann Heng,Shanghang Zhang*

Main category: cs.RO

TL;DR: LaST$_0$框架通过潜在时空思维链与双系统架构，显著提高了机器人操控的成功率和推理效率。


<details>
  <summary>Details</summary>
Motivation: 旨在克服现有VLA方法在推理延迟和语言空间限制下的不足，提升机器人操作的准确性与速度。

Method: 提出LaST$_0$框架，通过潜在时空思维链（CoT）进行高效推理，建模未来视觉动态和机器人本体状态，以实现自适应的推理和动作推断频率。

Result: 在十个模拟和六个真实世界的操作任务中，LaST$_0$的平均成功率比以前的VLA方法分别提高了8%和13%，同时推理速度显著更快。

Conclusion: LaST$_0$通过引入潜在的时空思维链，有效解决了现有VLA方法在推理延迟与表示瓶颈上的问题，从而提升了机器人操作的效率和成功率。

Abstract: Vision-Language-Action (VLA) models have recently demonstrated strong generalization capabilities in robotic manipulation. Some existing VLA approaches attempt to improve action accuracy by explicitly generating linguistic reasoning traces or future visual observations before action execution. However, explicit reasoning typically incurs non-negligible inference latency, which constrains the temporal resolution required for robotic manipulation. Moreover, such reasoning is confined to the linguistic space, imposing a representational bottleneck that struggles to faithfully capture ineffable physical attributes. To mitigate these limitations, we propose LaST$_0$, a framework that enables efficient reasoning before acting through a Latent Spatio-Temporal Chain-of-Thought (CoT), capturing fine-grained physical and robotic dynamics that are often difficult to verbalize. Specifically, we introduce a token-efficient latent CoT space that models future visual dynamics, 3D structural information, and robot proprioceptive states, and further extends these representations across time to enable temporally consistent implicit reasoning trajectories. Furthermore, LaST$_0$ adopts a dual-system architecture implemented via a Mixture-of-Transformers design, where a reasoning expert conducts low-frequency latent inference and an acting expert generates high-frequency actions conditioned on robotics-oriented latent representations. To facilitate coordination, LaST$_0$ is trained with heterogeneous operation frequencies, enabling adaptive switching between reasoning and action inference rates during deployment. Across ten simulated and six real-world manipulation tasks, LaST$_0$ improves mean success rates by 8% and 13% over prior VLA methods, respectively, while achieving substantially faster inference. Project website: https://sites.google.com/view/last0

</details>
