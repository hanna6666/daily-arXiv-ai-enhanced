<div id=toc></div>

# Table of Contents

- [cs.HC](#cs.HC) [Total: 18]
- [cs.RO](#cs.RO) [Total: 32]


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [1] [The Formation of Trust in Autonomous Vehicles after Interacting with Robotaxis on Public Roads](https://arxiv.org/abs/2510.00120)
*Xiang Chang,Zhijie Yi,Yichang Liu,Hongling Sheng,Dengbo He*

Main category: cs.HC

TL;DR: 本研究基于真实场景考察了行人与自动驾驶汽车之间的信任、接受度和行为，发现信任可以通过真实互动显著提高，且受多个变量影响。


<details>
  <summary>Details</summary>
Motivation: 公众对自动驾驶汽车的接受度对其推广至关重要，而以往的研究多基于简化模拟或实验室测试，缺乏对真实场景的探索。

Method: 本研究在商业Robotaxi运营区域进行真实实验，参与者在无控制的城市交叉口多次穿越，利用多种问卷评估参与者的行为、接受度和信任感。

Result: 实验结果显示，参与者对自动驾驶汽车的信任感在实验后显著增加，并且这种增加与参与者的接受度有正相关关系。

Conclusion: 该研究表明，行人与自动驾驶汽车（AV）互动中的信任是可以通过真实环境中的多次交互显著提升的，同时这一信任的形成受多个因素的影响。

Abstract: This study investigates how pedestrian trust, receptivity, and behavior
evolve during interactions with Level-4 autonomous vehicles (AVs) at
uncontrolled urban intersections in a naturalistic setting. While public
acceptance is critical for AV adoption, most prior studies relied on simplified
simulations or field tests. We conducted a real-world experiment in a
commercial Robotaxi operation zone, where 33 participants repeatedly crossed an
uncontrolled intersection with frequent Level-4 Robotaxi traffic. Participants
completed the Pedestrian Behavior Questionnaire (PBQ), Pedestrian Receptivity
Questionnaire for Fully AVs (PRQF), pre- and post-experiment Trust in AVs
Scale, and Personal Innovativeness Scale (PIS). Results showed that trust in
AVs significantly increased post-experiment, with the increase positively
associated with the Interaction component of PRQF. Additionally, both the
Positive and Error subscales of the PBQ significantly influenced trust change.
This study reveals how trust forms in real-world pedestrian-AV encounters,
offering insights beyond lab-based research by accounting for population
heterogeneity.

</details>


### [2] [Perceived Weight of Mediated Reality Sticks](https://arxiv.org/abs/2510.00191)
*Satoshi Hashiguchi,Yuta Kataoka,Asako Kimura,Shohei Mori*

Main category: cs.HC

TL;DR: 中介现实棒的长度和缺失对用户的重量和重心感知有显著影响，特别是在动态触摸情境下。


<details>
  <summary>Details</summary>
Motivation: 探讨中介现实（AR和DR结合）对物理物体视觉修改的影响，特别是用户对物体重量和重心的感知。

Method: 进行了两个用户研究（N=10），每个研究包含两个子研究，通过用户交互评估用户对中介现实棒的感知。

Result: 发现中介现实棒的长度影响用户对重量的感知，而缺失部分的棒被认为是连续的，其重量和重心保持不变。

Conclusion: 中介现实物体的特性影响用户对其重量和重心的感知，特别是在动态触摸的情境下。

Abstract: Mediated reality, where augmented reality (AR) and diminished reality (DR)
meet, enables visual modifications to real-world objects. A physical object
with a mediated reality visual change retains its original physical properties.
However, it is perceived differently from the original when interacted with. We
present such a mediated reality object, a stick with different lengths or a
stick with a missing portion in the middle, to investigate how users perceive
its weight and center of gravity. We conducted two user studies (N=10), each of
which consisted of two substudies. We found that the length of mediated reality
sticks influences the perceived weight. A longer stick is perceived as lighter,
and vice versa. The stick with a missing portion tends to be recognized as one
continuous stick. Thus, its weight and center of gravity (COG) remain the same.
We formulated the relationship between inertia based on the reported COG and
perceived weight in the context of dynamic touch.

</details>


### [3] [Data Melodification FM: Where Musical Rhetoric Meets Sonification](https://arxiv.org/abs/2510.00222)
*Ke Er Amy Zhang,David Grellscheid,Laura Garrison*

Main category: cs.HC

TL;DR: 本文提出通过音乐理论提升数据声化的美学，使数据更易接近且愉悦。


<details>
  <summary>Details</summary>
Motivation: 希望通过声化将数据的表达和感知提升，避免传统声化中常见的与语义不符的问题。

Method: 提出数据声化的设计空间，将可视化惯例和数据特征映射到音乐的修辞手法。

Result: 实现了一种新的数据声化方式，使数据的声化体验更加丰富和吸引人。

Conclusion: 通过运用经典音乐理论的美学，使数据的声化既可理解又愉悦。

Abstract: We propose a design space for data melodification, where standard
visualization idioms and fundamental data characteristics map to rhetorical
devices of music for a more affective experience of data. Traditional data
sonification transforms data into sound by mapping it to different parameters
such as pitch, volume, and duration. Often and regrettably, this mapping leaves
behind melody, harmony, rhythm and other musical devices that compose the
centuries-long persuasive and expressive power of music. What results is the
occasional, unintentional sense of tinnitus and horror film-like impending doom
caused by a disconnect between the semantics of data and sound. Through this
work we ask, can the aestheticization of sonification through (classical) music
theory make data simultaneously accessible, meaningful, and pleasing to one's
ears?

</details>


### [4] [Can AI agents understand spoken conversations about data visualizations in online meetings?](https://arxiv.org/abs/2510.00245)
*Rizul Sharma,Tianyu Jiang,Seokki Lee,Jillian Aurisano*

Main category: cs.HC

TL;DR: 本文评估了一种AI代理在在线会议中理解关于数据可视化的对话能力，采用双轴测试框架，测试发现文本输入模式的表现最佳。


<details>
  <summary>Details</summary>
Motivation: 随着对能够支持会议的AI助手的兴趣日益增长，尤其是在提供任务协助或总结讨论方面，理解会话对话的模型质量变得至关重要。

Method: 引入双轴测试框架，设计了一系列测试来评估AI代理对72段关于数据可视化的对话的理解。

Result: 我们研究了多种管道和模型架构（LLM与VLM），以及不同的可视化输入格式，发现文本输入模式表现最佳。

Conclusion: 通过我们的评估方法，发现仅文本输入模式在理解在线会议中对可视化的讨论方面表现最佳（达到96%的准确率）。

Abstract: In this short paper, we present work evaluating an AI agent's understanding
of spoken conversations about data visualizations in an online meeting
scenario. There is growing interest in the development of AI-assistants that
support meetings, such as by providing assistance with tasks or summarizing a
discussion. The quality of this support depends on a model that understands the
conversational dialogue. To evaluate this understanding, we introduce a
dual-axis testing framework for diagnosing the AI agent's comprehension of
spoken conversations about data. Using this framework, we designed a series of
tests to evaluate understanding of a novel corpus of 72 spoken conversational
dialogues about data visualizations. We examine diverse pipelines and model
architectures, LLM vs VLM, and diverse input formats for visualizations (the
chart image, its underlying source code, or a hybrid of both) to see how this
affects model performance on our tests. Using our evaluation methods, we found
that text-only input modalities achieved the best performance (96%) in
understanding discussions of visualizations in online meetings.

</details>


### [5] [Visualization Was Here: Reorienting Research When Visualizations Fade into the Background](https://arxiv.org/abs/2510.00266)
*Paul C. Parsons*

Main category: cs.HC

TL;DR: 这篇论文探讨了视觉化在真实世界中作为基础设施的隐性角色，强调在设计中理解和支持这种角色的重要性。


<details>
  <summary>Details</summary>
Motivation: 探讨在许多真实世界领域中，视觉化的默默角色如何影响工作实践，并将其视为一个重要方面，而不是一项设计或创新的失败。

Method: 通过结合联合认知系统、自然决策和基础设施研究的理论传统，研究视觉化如何融入专家实践的节奏。

Result: 通过对NASA任务控制操作的例子进行说明，展示了视觉化在专家实践中的深度整合与使用。

Conclusion: 视觉化的基础性存在需要新的概念、方法和批判性敏感性，以支持视觉化在使用中的角色，即使它在视野中淡化。

Abstract: Visualization research often centers on how visual representations generate
insight, guide interpretation, or support decision-making. But in many
real-world domains, visualizations do not stand out--they recede into the
background, stabilized and trusted as part of the everyday infrastructure of
work. This paper explores what it means to take such quiet roles seriously.
Drawing on theoretical traditions from joint cognitive systems, naturalistic
decision making, and infrastructure studies, I examine how visualization can
become embedded in the rhythms of expert practice--less a site of intervention
than a scaffold for attention, coordination, and judgment. I illustrate this
reorientation with examples from mission control operations at NASA, where
visualizations are deeply integrated but rarely interrogated. Rather than treat
invisibility as a failure of design or innovation, I argue that visualization's
infrastructural presence demands new concepts, methods, and critical
sensibilities. The goal is not to diminish visualization's importance, but to
broaden the field's theoretical repertoire--to recognize and support
visualization-in-use even when it fades from view.

</details>


### [6] [Navigating the Synchrony-Stability Frontier in Adaptive Chatbots](https://arxiv.org/abs/2510.00339)
*T. James Brandt*

Main category: cs.HC

TL;DR: 本文提出了一种计算评估框架，强调在语言同步与个性稳定性之间的权衡，通过一系列政策的比较分析，提出了可提高稳定性的有效适应策略。


<details>
  <summary>Details</summary>
Motivation: 适应性聊天机器人通过模仿用户的语言风格来建立关系和参与感，但无节制的模仿可能导致不稳定或谄媚的代理体验。

Method: 使用8维风格向量和封闭循环的“基础+增量”提示架构，模拟和比较不同的适应政策。

Result: 边界政策显著提高了稳定性，同时仅小幅降低了同步性，且新提倡的政策能够减少指令变化并降低明显语气变化的发生率。

Conclusion: 该框架提供了一种通用的风格适应评估工具，能够识别帕累托有效政策，并通过多样的数据集和模型进行稳健验证，同时引入新颖的可读性指标以连接政策选择与系统的维护性。

Abstract: Adaptive chatbots that mimic a user's linguistic style can build rapport and
engagement, yet unconstrained mimicry risks an agent that feels unstable or
sycophantic. We present a computational evaluation framework that makes the
core design tension explicit: balancing moment-to-moment linguistic synchrony
against long-term persona stability. Using an 8-dimensional style vector and a
closed-loop "base+delta" prompting architecture, we simulate and compare
explicit adaptation policies - Uncapped, Cap, Exponential Moving Average (EMA),
Dead-Band, and Hybrids - on a human-log dataset. Our analysis maps a clear
Pareto frontier: bounded policies achieve substantial gains in stability at a
modest cost to synchrony. For example, a Hybrid (EMA+Cap) raises stability from
0.542 to 0.878 (+62%) while reducing synchrony by only 17%. We confirm this
trade-off through large-scale replications on three public corpora
(DailyDialog, Persona-Chat, EmpatheticDialogues) and LLM-in-the-loop validation
across two model families. Furthermore, we quantify "prompt legibility,"
showing that frontier policies reduce instruction churn and cut jarring
register flips (major tone changes) from 0.254 to 0.092, yielding systems that
are easier to reason about and maintain. Taken together, our framework provides
a general evaluation harness for style adaptation; a systematic ablation that
identifies Pareto-efficient policies; robust validation across diverse datasets
and models; and novel legibility metrics linking policy choices to system
maintainability.

</details>


### [7] [The Feng Shui of Visualization: Design the Path to SUCCESS and GOOD FORTUNE](https://arxiv.org/abs/2510.00344)
*Chang Han,Andrew Mcnutt*

Main category: cs.HC

TL;DR: 本研究提出了一种基于风水的可视化设计框架，利用迷信叙事增强设计效果，减轻设计师压力并促进社区认同。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索迷信与宗教信仰在塑造人类行为中的影响，并将其应用于可视化设计，以提高设计的有效性与接受度。

Method: 构建了一种伪理论框架，将迷信心理与可视化设计原则结合，以提升设计实践。

Result: 通过将可视化设计原则与风水叙事结合，提出了一系列设计实践指南，减轻设计师焦虑，增强社区规范和记忆力。

Conclusion: 本研究提出了一种结合迷信与可视化设计的新框架，强调了文化叙事在设计中的心理影响力。

Abstract: Superstition and religious belief system have historically shaped human
behavior, offering powerful psychological motivations and persuasive frameworks
to guide actions. Inspired by Feng Shui -- an ancient Chinese superstition --
this paper proposes a pseudo-theoretical framework that integrates
superstition-like heuristics into visualization design. Rather than seeking
empirical truth, this framework leverages culturally resonant (superstitious)
narratives and symbolic metaphors as persuasive tools to encourage desirable
design practices, such as clarity, accessibility, and audience-centered
thinking. We articulate a set of visualization designs into a Feng Shui
compass, reframing empirical design principles and guidelines within an engaing
mythology. We present how visualization design principles can be intepreted in
Feng Shui narratives, discussing the potential of these metaphorical principles
in reducing designer anxiety, fostering community norms, and enhancing the
memorability and internalization of visualization design guidelines. Finally,
we discuss Feng Shui visualization theory as a set of cognitive shortcuts that
can exert persuasive power through playful, belief-like activities.

</details>


### [8] [Attribution Gradients: Incrementally Unfolding Citations for Critical Examination of Attributed AI Answers](https://arxiv.org/abs/2510.00361)
*Hita Kambhamettu,Alyssa Hwang,Philippe Laban,Andrew Head*

Main category: cs.HC

TL;DR: 本论文提出归因梯度作为解决AI问答系统源引证验证问题的方法，通过增进用户与来源内容间的互动，提高了修订任务的质量。


<details>
  <summary>Details</summary>
Motivation: 随着AI问答系统逐渐生成带有源引证的回答，验证这些引证的实际内容变得不切实际。

Method: 运用归因梯度技术，用户可分解AI答案中的句子，查看支持和反对的引文。

Result: 用户在使用归因梯度进行修订时，对源材料的参与度更高，修订任务的丰富性也更强。

Conclusion: 使用归因梯度可以提高用户对源材料的参与度和任务修订的丰富性。

Abstract: AI question answering systems increasingly generate responses with
attributions to sources. However, the task of verifying the actual content of
these attributions is in most cases impractical. In this paper, we present
attribution gradients as a solution. Attribution gradients provide integrated,
incremental affordances for diving into an attributed passage. A user can
decompose a sentence of an answer into its claims. For each claim, the user can
view supporting and contradictory excerpts mined from sources. Those excerpts
serve as clickable conduits into the source (in our application, scientific
papers). When evidence itself contains more citations, the UI unpacks the
evidence into excerpts from the cited sources. These features of attribution
gradients facilitate concurrent interconnections among answer, claim, excerpt,
and context. In a usability study, we observed greater engagement with sources
and richer revision in a task where participants revised an attributed AI
answer with attribution gradients and a baseline.

</details>


### [9] [Investigating Encoding and Perspective for Augmented Reality](https://arxiv.org/abs/2510.00407)
*Jade Kandel,Sriya Kasumarthi,Spiros Tsalikis,Chelsea Duppen,Daniel Szafir,Michael Lewek,Henry Fuchs,Danielle Szafir*

Main category: cs.HC

TL;DR: 本研究调查了增强现实中怎样的可视编码和视角能有效指导运动，提出了基于实证的设计指南，以提高增强现实系统的有效性。


<details>
  <summary>Details</summary>
Motivation: 虽然许多方法利用增强现实来指导运动，但现有的设计指南主要集中在用户视野内的简单上半身运动上，因此缺乏对多样化场景的证据基础设计建议。

Method: 通过实验研究不同的可视编码和视角如何影响运动引导的表现和用户体验，选取了三种可见性和运动平面各异的练习。

Result: 我们的研究发现，不同设计的偏好和表现存在显著差异；最佳视角因运动可见性而异，并且提供更多关于整体运动的信息并不一定改善运动执行。

Conclusion: 我们提供了基于实证的设计指南，以支持更有效的增强现实系统，专注于运动引导的沉浸式互动可视化设计。

Abstract: Augmented reality (AR) offers promising opportunities to support
movement-based activities, such as personal training or physical therapy, with
real-time, spatially-situated visual cues. While many approaches leverage AR to
guide motion, existing design guidelines focus on simple, upper-body movements
within the user's field of view. We lack evidence-based design recommendations
for guiding more diverse scenarios involving movements with varying levels of
visibility and direction. We conducted an experiment to investigate how
different visual encodings and perspectives affect motion guidance performance
and usability, using three exercises that varied in visibility and planes of
motion. Our findings reveal significant differences in preference and
performance across designs. Notably, the best perspective varied depending on
motion visibility and showing more information about the overall motion did not
necessarily improve motion execution. We provide empirically-grounded
guidelines for designing immersive, interactive visualizations for motion
guidance to support more effective AR systems.

</details>


### [10] [RELATE-Sim: Leveraging Turning Point Theory and LLM Agents to Predict and Understand Long-Term Relationship Dynamics through Interactive Narrative Simulations](https://arxiv.org/abs/2510.00414)
*Matthew Yue,Zhikun Xu,Vivek Gupta,Thao Ha,Liesal Sharabi,Ben Zhou*

Main category: cs.HC

TL;DR: RELATE-Sim是一个模拟器，重点研究长期情侣关系中的维护，而非仅仅是相聚。


<details>
  <summary>Details</summary>
Motivation: 大多数约会技术优化的是情侣相聚，而非维系关系，因此需要一种新的方法来理解情侣在关键时刻的动态行为。

Method: 通过理论驱动的模拟，RELATE-Sim建模情侣在关键转折点的行为，利用两个对齐的LLM代理人，在集中场景管理下互动。

Result: 在对71对情侣进行两年跟踪的纵向数据集上，模拟感知预测优于仅基于角色的基准，揭示了可操作的标记，解释了关系轨迹的偏离。

Conclusion: RELATE-Sim为理解和预测长期关系动态提供了一个透明、可扩展的平台，推动了关系研究从匹配转向维护。

Abstract: Most dating technologies optimize for getting together, not staying together.
We present RELATE-Sim, a theory-grounded simulator that models how couples
behave at consequential turning points-exclusivity talks, conflict-and-repair
episodes, relocations-rather than static traits. Two persona-aligned LLM agents
(one per partner) interact under a centralized Scene Master that frames each
turning point as a compact set of realistic options, advances the narrative,
and infers interpretable state changes and an auditable commitment estimate
after each scene. On a longitudinal dataset of 71 couples with two-year
follow-ups, simulation-aware predictions outperform a personas-only baseline
while surfacing actionable markers (e.g., repair attempts acknowledged, clarity
shifts) that explain why trajectories diverge. RELATE-Sim pushes the
relationship research's focus from matchmaking to maintenance, providing a
transparent, extensible platform for understanding and forecasting long-term
relationship dynamics.

</details>


### [11] [Face2Feel: Emotion-Aware Adaptive User Interface](https://arxiv.org/abs/2510.00489)
*Ismail Alihan Hadimlioglu,Siddharth Linga*

Main category: cs.HC

TL;DR: Face2Feel是一个基于用户情绪和偏好的动态自适应用户界面模型，通过计算机视觉技术分析用户表情，展示了情绪驱动界面在提升用户体验方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 解决传统静态界面的局限性，满足对情绪感知系统的需求。

Method: 利用计算机视觉技术进行用户情绪和偏好的动态适应。

Result: 用户调查显示85.7%的用户觉得这些系统非常吸引人和用户友好；案例研究展示了实用性。

Conclusion: 情绪驱动的用户界面适应性具有改善用户体验的潜力，特别是在推荐系统和反馈机制中。

Abstract: This paper presents Face2Feel, a novel user interface (UI) model that
dynamically adapts to user emotions and preferences captured through computer
vision. This adaptive UI framework addresses the limitations of traditional
static interfaces by integrating digital image processing, face recognition,
and emotion detection techniques. Face2Feel analyzes user expressions utilizing
a webcam or pre-installed camera as the primary data source to personalize the
UI in real-time. Although dynamically changing user interfaces based on
emotional states are not yet widely implemented, their advantages and the
demand for such systems are evident. This research contributes to the
development of emotion-aware applications, particularly in recommendation
systems and feedback mechanisms. A case study, "Shresta: Emotion-Based Book
Recommendation System," demonstrates the practical implementation of this
framework, the technologies employed, and the system's usefulness. Furthermore,
a user survey conducted after presenting the working model reveals a strong
demand for such adaptive interfaces, emphasizing the importance of user
satisfaction and comfort in human-computer interaction. The results showed that
nearly 85.7\% of the users found these systems to be very engaging and
user-friendly. This study underscores the potential for emotion-driven UI
adaptation to improve user experiences across various applications.

</details>


### [12] [PromptPilot: Improving Human-AI Collaboration Through LLM-Enhanced Prompt Engineering](https://arxiv.org/abs/2510.00555)
*Niklas Gutheil,Valentin Mayer,Leopold Müller,Jörg Rommelt,Niklas Kühl*

Main category: cs.HC

TL;DR: 本研究提出PromptPilot，一个交互式提示助手，旨在改善用户的提示工程能力，实验证明其在提升任务表现和用户体验方面有效。


<details>
  <summary>Details</summary>
Motivation: 许多用户在编写有效提示时面临困难，限制了大型语言模型的实际效益。

Method: 通过随机对照实验，评估参与者在使用PromptPilot时的表现。

Result: 使用PromptPilot的参与者表现显著提高，且反馈效率高、易于使用和自主性强。

Conclusion: 基于LLM的提示工程被确立为改善人类与AI合作的可行技术。

Abstract: Effective prompt engineering is critical to realizing the promised
productivity gains of large language models (LLMs) in knowledge-intensive
tasks. Yet, many users struggle to craft prompts that yield high-quality
outputs, limiting the practical benefits of LLMs. Existing approaches, such as
prompt handbooks or automated optimization pipelines, either require
substantial effort, expert knowledge, or lack interactive guidance. To address
this gap, we design and evaluate PromptPilot, an interactive prompting
assistant grounded in four empirically derived design objectives for
LLM-enhanced prompt engineering. We conducted a randomized controlled
experiment with 80 participants completing three realistic, work-related
writing tasks. Participants supported by PromptPilot achieved significantly
higher performance (median: 78.3 vs. 61.7; p = .045, d = 0.56), and reported
enhanced efficiency, ease-of-use, and autonomy during interaction. These
findings empirically validate the effectiveness of our proposed design
objectives, establishing LLM-enhanced prompt engineering as a viable technique
for improving human-AI collaboration.

</details>


### [13] [Rethinking Wine Tasting for Chinese Consumers: A Service Design Approach Enhanced by Multimodal Personalization](https://arxiv.org/abs/2510.00583)
*Xinyang Shan,Yuanyuan Xu,Tian Xia,Yinshan Lin*

Main category: cs.HC

TL;DR: 本研究探讨如何通过文化适应性的服务设计增强中国消费者的葡萄酒品尝体验，提出了新的交互系统与用户原型。


<details>
  <summary>Details</summary>
Motivation: 在非西方文化背景下，葡萄酒品尝面临独特挑战，需要重新构想体验以满足中国消费者的需求。

Method: 采用服务设计方法，基于上下文共同创造，进行26次现场访谈和后续验证。

Result: 确定了三种用户原型，揭示了传统葡萄酒描述的文化不适宜性，以及基于地方美食的交叉隐喻显著提升了认知与情感参与。

Conclusion: 本研究展示了如何通过文化适应的交互系统增强身临其境的消费体验，尤其是在非西方背景的葡萄酒品尝中。

Abstract: Wine tasting is a multimodal and culturally embedded activity that presents
unique challenges when adapted to non-Western contexts. This paper proposes a
service design approach rooted in contextual co-creation to reimagine wine
tasting experiences for Chinese consumers. Drawing on 26 in-situ interviews and
follow-up validation sessions, we identify three distinct user archetypes:
Curious Tasters, Experience Seekers, and Knowledge Builders, each exhibiting
different needs in vocabulary, interaction, and emotional pacing. Our findings
reveal that traditional wine descriptors lack cultural resonance and that
cross-modal metaphors grounded in local gastronomy (e.g., green mango for
acidity) significantly improve cognitive and emotional engagement. These
insights informed a partially implemented prototype, featuring AI-driven
metaphor-to-flavour mappings and real-time affective feedback visualisation. A
small-scale usability evaluation confirmed improvements in engagement and
comprehension. Our comparative analysis shows alignment with and
differentiation from prior multimodal and affect-aware tasting systems. This
research contributes to CBMI by demonstrating how culturally adaptive
interaction systems can enhance embodied consumption experiences in physical
tourism and beyond.

</details>


### [14] [Designing Wine Tasting Experiences for All: The role of Human Diversity and Personal food memory](https://arxiv.org/abs/2510.00607)
*Xinyang Shan,Yuanyuan Xu,Yuqing Wang,Tian Xia,Yinshan Lin*

Main category: cs.HC

TL;DR: 本研究探索如何通过人类多样性和个人食品记忆设计更具包容性的酒庄品酒体验，特别关注中国游客的文化交流与可持续发展。


<details>
  <summary>Details</summary>
Motivation: 探索人类多样性和个人食品记忆对酒庄品酒体验的影响，尤其关注中国游客的跨文化挑战。

Method: 通过在多个葡萄酒产区进行实地研究，调查中国游客在酒庄游览中的品酒体验。

Result: 研究发现体验者的能力、需求和愿望（ANAs）、酒庄游览中的品酒真实性，以及个人食品记忆作为品酒工具的价值都至关重要。

Conclusion: 本研究为中国的酒庄体验设计提供了更具包容性和参与性的视角，强调了人类多样性和个人食品记忆的重要性。

Abstract: This study investigates the design of inclusive wine-tasting experiences by
examining the roles of human diversity and personal food memory. Through field
studies conducted in various wine regions, we explored how Chinese visitors
engage with wine-tasting activities during winery tours, highlighting the
cross-cultural challenges they face. Our findings underscore the importance of
experiencers' abilities, necessities, and aspirations (ANAs), the authenticity
of wine tasting within the context of winery tours, and the use of personal
food memories as a wine-tasting tool accessible to all. These insights lay the
groundwork for developing more inclusive and engaging wine-tasting services,
offering new perspectives for cultural exchange and sustainable wine business
practices in China.

</details>


### [15] [Datasets for Valence and Arousal Inference: A Survey](https://arxiv.org/abs/2510.00738)
*Helen Schneider,Svetlana Pavlitska,Helen Gremmelmaier,J. Marius Zöllner*

Main category: cs.HC

TL;DR: 本研究概述了25个情感推断数据集的特征，并分析了情感检测的方法和技术进展。


<details>
  <summary>Details</summary>
Motivation: 理解人类情感可以在多个领域提升决策、个性化体验和改善情感健康。

Method: 对2008至2024年间发布的25个数据集进行了审查，分析了数据集大小、被试分布、传感器配置、注释规模和数据格式等关键因素。

Result: 我们总结了情感检测的主要方法，并探讨了传感器融合方法在情感推断上的进展。

Conclusion: 情感推断数据集的全面视角能够为情感检测领域的研究和应用提供有价值的指导。

Abstract: Understanding human affect can be used in robotics, marketing, education,
human-computer interaction, healthcare, entertainment, autonomous driving, and
psychology to enhance decision-making, personalize experiences, and improve
emotional well-being. This work presents a comprehensive overview of affect
inference datasets that utilize continuous valence and arousal labels. We
reviewed 25 datasets published between 2008 and 2024, examining key factors
such as dataset size, subject distribution, sensor configurations, annotation
scales, and data formats for valence and arousal values. While camera-based
datasets dominate the field, we also identified several widely used multimodal
combinations. Additionally, we explored the most common approaches to affect
detection applied to these datasets, providing insights into the prevailing
methodologies in the field. Our overview of sensor fusion approaches shows
promising advancements in model improvement for valence and arousal inference.

</details>


### [16] [Virtual Reality Alters Perceived Functional Body Size](https://arxiv.org/abs/2510.00824)
*Xiaoye Michael Wang,Ali Mazalek,Catherine M. Sabiston,Timothy N. Welsh*

Main category: cs.HC

TL;DR: 本研究揭示了虚拟现实如何通过深度压缩影响个体对功能身体大小的感知，导致感知和动作阈值的增加。


<details>
  <summary>Details</summary>
Motivation: 探讨沉浸式虚拟现实如何通过感觉干扰影响个体对于自己身体大小的认知。

Method: 采用传递孔径范式，通过头戴显示器(HMD)进行沉浸式虚拟现实体验，测试参与者在体育和虚拟现实中的动作任务和感知任务。

Result: 在虚拟现实中，参与者的动作和感知阈值显著高于物理现实，表明感知和动作之间存在不确定性和视觉失真。同时，在虚拟现实中，经过数学修正后，功能性比例与物理现实一致。

Conclusion: 研究结果表明，虚拟现实导致的深度压缩系统性地改变了感知的身体-环境关系，从而改变了个体的功能身体大小感知。

Abstract: Virtual reality (VR) introduces sensory perturbations that may impact
perception and action. The current study was designed to investigate how
immersive VR presented through a head-mounted display (HMD) affects perceived
functional body size using a passable aperture paradigm. Participants (n=60)
performed an action task (sidle through apertures) and a perception task
(adjust aperture width until passable without contact) in both physical,
unmediated reality (UR) and VR. Results revealed significantly higher action
and perceptual thresholds in VR compared to UR. Affordance ratios (perceptual
threshold over action threshold) were also higher in VR, indicating that the
increase in perceptual thresholds in VR was driven partly by sensorimotor
uncertainty, as reflected in the increase in the action thresholds, and partly
by perceptual distortions imposed by VR. This perceptual overestimation in VR
also persisted as an aftereffect in UR following VR exposure. Geometrical
modelling attributed the disproportionate increase in the perceptual threshold
in VR primarily to depth compression. This compression, stemming from the
vergence-accommodation conflict (VAC), caused the virtual aperture to be
perceived as narrower than depicted, thus requiring a wider adjusted aperture.
Critically, after mathematically correcting for the VAC's impact on perceived
aperture width, the affordance ratios in VR became equivalent to those in UR.
These outcomes demonstrate a recovered invariant geometrical scaling,
suggesting that perception remained functionally attuned to action capabilities
once VAC-induced distortions were accounted for. These findings highlight that
VR-induced depth compression systematically alters perceived body-environment
relationships, leading to an altered sense of one's functional body size.

</details>


### [17] ["We are not Future-ready": Understanding AI Privacy Risks and Existing Mitigation Strategies from the Perspective of AI Developers in Europe](https://arxiv.org/abs/2510.00909)
*Alexandra Klymenko,Stephen Meisenbacher,Patrick Gage Kelley,Sai Teja Peddinti,Kurt Thomas,Florian Matthes*

Main category: cs.HC

TL;DR: 研究显示AI开发者对隐私风险的认识不一致，且已有的减轻策略在实际应用中很少。


<details>
  <summary>Details</summary>
Motivation: 随着AI的发展，隐私问题日益突出，因此需要了解开发者对隐私威胁的看法及应对措施。

Method: 通过对25位欧洲AI开发者的访谈来研究隐私威胁及其应对策略。

Result: AI开发者对隐私风险的相对排名缺乏共识，且现实中很少采用已有的减轻策略。

Conclusion: AI开发者对隐私风险的认识不一致，并且尽管了解减轻策略，实际应用仍然很少。

Abstract: The proliferation of AI has sparked privacy concerns related to training
data, model interfaces, downstream applications, and more. We interviewed 25 AI
developers based in Europe to understand which privacy threats they believe
pose the greatest risk to users, developers, and businesses and what protective
strategies, if any, would help to mitigate them. We find that there is little
consensus among AI developers on the relative ranking of privacy risks. These
differences stem from salient reasoning patterns that often relate to human
rather than purely technical factors. Furthermore, while AI developers are
aware of proposed mitigation strategies for addressing these risks, they
reported minimal real-world adoption. Our findings highlight both gaps and
opportunities for empowering AI developers to better address privacy risks in
AI.

</details>


### [18] [Social Photo-Elicitation: The Use of Communal Production of Meaning to Hear a Vulnerable Population](https://arxiv.org/abs/2510.00964)
*Aakash Gautam,Chandani Shrestha,Deborah Tatar,Steve Harrison*

Main category: cs.HC

TL;DR: 本研究通过共 communal 照片引导法，探索尼泊尔性别贩运幸存者的处境与再融合，为相关文献提供新视角。


<details>
  <summary>Details</summary>
Motivation: 探索尼泊尔性别贩运幸存者的处境，促进他们在康复过程中发声及整合。

Method: 使用共 communal 的照片引导技术，以便更好地倾听幸存者的声音。

Result: 揭示了幸存者复杂的康复情况，强调了他们在社会中有限但重要的社会资本。

Conclusion: 研究提出了一种共 communal 方法的照片引导技术，以支持性别贩运幸存者的再融合。

Abstract: We report on an initial ethnographic exploration of the situation of
sex-trafficking survivors in Nepal. In the course of studying trafficking
survivors in a protected-living situation created by a non-governmental
organization in Nepal, we adapted photo-elicitation to hear the voices of the
survivors by making the technique more communal. Bringing sociality to the
forefront of the method reduced the pressure on survivors to assert voices as
individuals, allowing them to speak. We make three contributions to research.
First, we propose a communal form of photo-elicitation as a method to elicit
values in sensitive settings. Second, we present the complex circumstances of
the survivors as they undergo rehabilitation and move towards life with a ``new
normal''. Third, our work adds to HCI and CSCW literature on understanding
specific concerns of trafficking survivors and aims to inform designs that can
support reintegration of survivors in society. The values that the survivors
hold and their notion of future opportunities suggest possession of limited but
important social capital in some domains that could be leveraged to aid
reintegration.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [19] [RoboPilot: Generalizable Dynamic Robotic Manipulation with Dual-thinking Modes](https://arxiv.org/abs/2510.00154)
*Xinyi Liu,Mohammadreza Fani Sani,Zewei Zhou,Julius Wirbel,Bahram Zarrin,Roberto Galeazzi*

Main category: cs.RO

TL;DR: RoboPilot是一个新提出的闭环框架，解决复杂任务中的鲁棒性问题，并展示了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 解决当前自主机器人在处理复杂和长时任务时的开放式循环和反馈不足问题。

Method: 提出了双重思维闭环框架，结合反馈机制进行动态重规划，支持复杂任务的自适应推理。

Result: RoboPilot在21个任务中取得了25.9%的任务成功率提升，并在工业机器人上进行实际应用验证。

Conclusion: RoboPilot在复杂任务的执行中表现出优越性，并且在真实环境中显示出较强的鲁棒性。

Abstract: Despite rapid progress in autonomous robotics, executing complex or
long-horizon tasks remains a fundamental challenge. Most current approaches
follow an open-loop paradigm with limited reasoning and no feedback, resulting
in poor robustness to environmental changes and severe error accumulation. We
present RoboPilot, a dual-thinking closed-loop framework for robotic
manipulation that supports adaptive reasoning for complex tasks in real-world
dynamic environments. RoboPilot leverages primitive actions for structured task
planning and flexible action generation, while introducing feedback to enable
replanning from dynamic changes and execution errors. Chain-of-Thought
reasoning further enhances high-level task planning and guides low-level action
generation. The system dynamically switches between fast and slow thinking to
balance efficiency and accuracy. To systematically evaluate the robustness of
RoboPilot in diverse robot manipulation scenarios, we introduce
RoboPilot-Bench, a benchmark spanning 21 tasks across 10 categories, including
infeasible-task recognition and failure recovery. Experiments show that
RoboPilot outperforms state-of-the-art baselines by 25.9\% in task success
rate, and the real-world deployment on an industrial robot further demonstrates
its robustness in real-world settings.

</details>


### [20] [A Systematic Study of Large Language Models for Task and Motion Planning With PDDLStream](https://arxiv.org/abs/2510.00182)
*Jorge Mendez-Mendez*

Main category: cs.RO

TL;DR: 本研究开发了基于Gemini的规划器，发现其在成功率和效率上不如工程设计的规划器，同时指出非推理L语言模型的优势。


<details>
  <summary>Details</summary>
Motivation: 理解大型语言模型(LLMs)在复杂机器人问题中的规划能力，以及如何将其与任务和运动规划的正式推理相结合。

Method: 开发了16种算法，使用Gemini 2.5 Flash替换关键的任务和运动规划组件，并进行了零-shot实验。

Result: 在4950个问题和三个领域的实验中，Gemini-based规划器的成功率较低，规划时间较长，并且提供几何细节会增加任务规划错误。

Conclusion: Gemini-based规划器在成功率和规划时间上均逊色于工程设计的对手，非推理LLM变种在大多数情况下表现更好。

Abstract: Using large language models (LLMs) to solve complex robotics problems
requires understanding their planning capabilities. Yet while we know that LLMs
can plan on some problems, the extent to which these planning capabilities
cover the space of robotics tasks is unclear. One promising direction is to
integrate the semantic knowledge of LLMs with the formal reasoning of task and
motion planning (TAMP). However, the myriad of choices for how to integrate
LLMs within TAMP complicates the design of such systems. We develop 16
algorithms that use Gemini 2.5 Flash to substitute key TAMP components. Our
zero-shot experiments across 4,950 problems and three domains reveal that the
Gemini-based planners exhibit lower success rates and higher planning times
than their engineered counterparts. We show that providing geometric details
increases the number of task-planning errors compared to pure PDDL
descriptions, and that (faster) non-reasoning LLM variants outperform (slower)
reasoning variants in most cases, since the TAMP system can direct the LLM to
correct its mistakes.

</details>


### [21] [A Novel Robust Control Method Combining DNN-Based NMPC Approximation and PI Control: Application to Exoskeleton Squat Movements](https://arxiv.org/abs/2510.00188)
*Alireza Aliyari,Gholamreza Vossoughi*

Main category: cs.RO

TL;DR: 本研究提出了混合NMPC-DNN-PI控制器，以提高非线性模型预测控制的鲁棒性，结果表明其在外骨骼机器人应用中表现优越，显著降低了跟踪误差和关节扭矩，同时显著降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 提高NMPC在机器人系统中的应用效果，特别是在处理意外干扰和训练数据与实际情况不符时的鲁棒性。

Method: 将NMPC-DNN输出与PI控制器结合，形成混合控制器

Result: 混合NMPC-DNN-PI在复杂动态模型的外骨骼机器人上验证，跟踪误差降低，关节扭矩减少，计算成本显著降低。

Conclusion: 混合NMPC-DNN-PI控制器在未知条件下的跟踪误差显著低于NMPC-DNN，且降低了人类关节扭矩，同时计算成本大幅减少。

Abstract: Nonlinear Model Predictive Control (NMPC) is a precise controller, but its
heavy computational load often prevents application in robotic systems. Some
studies have attempted to approximate NMPC using deep neural networks
(NMPC-DNN). However, in the presence of unexpected disturbances or when
operating conditions differ from training data, this approach lacks robustness,
leading to large tracking errors. To address this issue, for the first time,
the NMPC-DNN output is combined with a PI controller (Hybrid NMPC-DNN-PI). The
proposed controller is validated by applying it to an exoskeleton robot during
squat movement, which has a complex dynamic model and has received limited
attention regarding robust nonlinear control design. A human-robot dynamic
model with three active joints (ankle, knee, hip) is developed, and more than
5.3 million training samples are used to train the DNN. The results show that,
under unseen conditions for the DNN, the tracking error in Hybrid NMPC-DNN-PI
is significantly lower compared to NMPC-DNN. Moreover, human joint torques are
greatly reduced with the use of the exoskeleton, with RMS values for the
studied case reduced by 30.9%, 41.8%, and 29.7% at the ankle, knee, and hip,
respectively. In addition, the computational cost of Hybrid NMPC-DNN-PI is
99.93% lower than that of NMPC.

</details>


### [22] [TGPO: Temporal Grounded Policy Optimization for Signal Temporal Logic Tasks](https://arxiv.org/abs/2510.00225)
*Yue Meng,Fei Chen,Chuchu Fan*

Main category: cs.RO

TL;DR: TGPO是为了解决复杂STL任务而提出的新方法，能有效改善策略学习并提升任务成功率。


<details>
  <summary>Details</summary>
Motivation: 为了克服STL的非马尔可夫性和稀疏奖励问题，提出一个新的方法来解决一般STL任务。

Method: 提出了TGPO，即时间引导策略优化，使用分层框架分解STL为时序子目标和不变约束，通过高层和低层组件来处理问题，并利用Metropolis-Hastings采样进行高效的策略学习。

Result: TGPO在五个不同环境中进行了实验，从低维导航到操作、无人机和四足行走，表现优异。

Conclusion: TGPO在各种STL任务中明显优于现有的最先进算法，尤其是在高维和长时间范围的任务中，任务成功率平均提高了31.6%。

Abstract: Learning control policies for complex, long-horizon tasks is a central
challenge in robotics and autonomous systems. Signal Temporal Logic (STL)
offers a powerful and expressive language for specifying such tasks, but its
non-Markovian nature and inherent sparse reward make it difficult to be solved
via standard Reinforcement Learning (RL) algorithms. Prior RL approaches focus
only on limited STL fragments or use STL robustness scores as sparse terminal
rewards. In this paper, we propose TGPO, Temporal Grounded Policy Optimization,
to solve general STL tasks. TGPO decomposes STL into timed subgoals and
invariant constraints and provides a hierarchical framework to tackle the
problem. The high-level component of TGPO proposes concrete time allocations
for these subgoals, and the low-level time-conditioned policy learns to achieve
the sequenced subgoals using a dense, stage-wise reward signal. During
inference, we sample various time allocations and select the most promising
assignment for the policy network to rollout the solution trajectory. To foster
efficient policy learning for complex STL with multiple subgoals, we leverage
the learned critic to guide the high-level temporal search via
Metropolis-Hastings sampling, focusing exploration on temporally feasible
solutions. We conduct experiments on five environments, ranging from
low-dimensional navigation to manipulation, drone, and quadrupedal locomotion.
Under a wide range of STL tasks, TGPO significantly outperforms
state-of-the-art baselines (especially for high-dimensional and long-horizon
cases), with an average of 31.6% improvement in task success rate compared to
the best baseline. The code will be available at
https://github.com/mengyuest/TGPO

</details>


### [23] [BC-MPPI: A Probabilistic Constraint Layer for Safe Model-Predictive Path-Integral Control](https://arxiv.org/abs/2510.00272)
*Odichimnma Ezeji,Michael Ziegltrum,Giulio Turrisi,Tommaso Belvedere,Valerio Modugno*

Main category: cs.RO

TL;DR: 提出BC-MPPI方法，通过贝叶斯约束提高MPPI的安全性，适用于复杂的机器人控制任务，能有效避免碰撞。


<details>
  <summary>Details</summary>
Motivation: MPPI控制方法在非线性机器人任务中快速且无梯度，但缺乏对约束满足的保证，因此需要引入一种安全机制。

Method: 采用贝叶斯约束为MPPI控制提供一种轻量级的安全层，通过每个状态和输入约束附加概率代理，调整候选轨迹的权重以降低碰撞风险。

Result: 在MuJoCo的四旋翼实验中，BC-MPPI能够在不需要手动调节惩罚成本或明确样本拒绝的情况下，通过对候选轨迹的概率评估，推动采样分布向安全子集倾斜。

Conclusion: BC-MPPI方法在保证安全边际方面表现良好，同时满足规定的违规概率，能够与验证和确认流程自然结合，适用于可认证的自动系统。

Abstract: Model Predictive Path Integral (MPPI) control has recently emerged as a fast,
gradient-free alternative to model-predictive control in highly non-linear
robotic tasks, yet it offers no hard guarantees on constraint satisfaction. We
introduce Bayesian-Constraints MPPI (BC-MPPI), a lightweight safety layer that
attaches a probabilistic surrogate to every state and input constraint. At each
re-planning step the surrogate returns the probability that a candidate
trajectory is feasible; this joint probability scales the weight given to a
candidate, automatically down-weighting rollouts likely to collide or exceed
limits and pushing the sampling distribution toward the safe subset; no
hand-tuned penalty costs or explicit sample rejection required. We train the
surrogate from 1000 offline simulations and deploy the controller on a
quadrotor in MuJoCo with both static and moving obstacles. Across K in
[100,1500] rollouts BC-MPPI preserves safety margins while satisfying the
prescribed probability of violation. Because the surrogate is a stand-alone,
version-controlled artefact and the runtime safety score is a single scalar,
the approach integrates naturally with verification-and-validation pipelines
for certifiable autonomous systems.

</details>


### [24] [Learning Human Reaching Optimality Principles from Minimal Observation Inverse Reinforcement Learning](https://arxiv.org/abs/2510.00329)
*Sarmad Mehrdad,Maxime Sabbah,Vincent Bonnet,Ludovic Righetti*

Main category: cs.RO

TL;DR: 这项研究展示了最小观察逆强化学习在建模和预测人类手臂运动中的应用，其成本结构不仅动态且不依赖于特定主体，具有促进人形机器人发展的潜力。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统逆强化学习方法所需演示次数多、收敛时间长的问题，研究最小观察逆强化学习(MO-IRL)在描述和预测人类手臂运动中的应用。

Method: 使用平面双链生物力学模型和高分辨率运动捕捉数据，通过分段每个轨迹学习特定阶段的成本函数组合，利用MO-IRL算法迭代优化成本权重。

Result: 在十个试验中，针对不同权重划分的关节角均方根误差(RMSE)分别为6.4度和5.6度，而使用单一静态权重时为10.4度。交叉验证和首次的跨主体验证表明，预测准确度约为8度RMSE，展示了良好的泛化能力。

Conclusion: MO-IRL能够高效揭示人类运动控制的动态、主体无关成本结构，具有对人形机器人潜在应用的价值。

Abstract: This paper investigates the application of Minimal Observation Inverse
Reinforcement Learning (MO-IRL) to model and predict human arm-reaching
movements with time-varying cost weights. Using a planar two-link biomechanical
model and high-resolution motion-capture data from subjects performing a
pointing task, we segment each trajectory into multiple phases and learn
phase-specific combinations of seven candidate cost functions. MO-IRL
iteratively refines cost weights by scaling observed and generated trajectories
in the maximum entropy IRL formulation, greatly reducing the number of required
demonstrations and convergence time compared to classical IRL approaches.
Training on ten trials per posture yields average joint-angle Root Mean Squared
Errors (RMSE) of 6.4 deg and 5.6 deg for six- and eight-segment weight
divisions, respectively, versus 10.4 deg using a single static weight.
Cross-validation on remaining trials and, for the first time, inter-subject
validation on an unseen subject's 20 trials, demonstrates comparable predictive
accuracy, around 8 deg RMSE, indicating robust generalization. Learned weights
emphasize joint acceleration minimization during movement onset and
termination, aligning with smoothness principles observed in biological motion.
These results suggest that MO-IRL can efficiently uncover dynamic,
subject-independent cost structures underlying human motor control, with
potential applications for humanoid robots.

</details>


### [25] [DiSA-IQL: Offline Reinforcement Learning for Robust Soft Robot Control under Distribution Shifts](https://arxiv.org/abs/2510.00358)
*Linjin He,Xinda Qi,Dong Chen,Zhaojian Li,Xiaobo Tan*

Main category: cs.RO

TL;DR: 本研究提出DiSA-IQL算法，通过惩罚不可靠的状态-动作对改善软蛇机器人控制中的离线强化学习，成功降低分布偏移，提升了任务成功率和轨迹平滑度。


<details>
  <summary>Details</summary>
Motivation: 由于现有控制方法在处理非线性动态时的性能限制，且在线训练往往不切实际，因此研究者寻找更安全有效的离线强化学习方法。

Method: 提出了一种名为DiSA-IQL的算法，该方法通过惩罚不可靠的状态-动作对来提升鲁棒性，旨在减轻分布偏移问题。

Result: 在两种环境下的目标到达任务中，DiSA-IQL表现优于行为克隆、保守Q学习及传统IQL模型。

Conclusion: DiSA-IQL在解决软蛇机器人控制中的分布偏移问题方面表现优异，超越了现有的基线模型，具有更高的成功率、平滑的轨迹和更强的鲁棒性。

Abstract: Soft snake robots offer remarkable flexibility and adaptability in complex
environments, yet their control remains challenging due to highly nonlinear
dynamics. Existing model-based and bio-inspired controllers rely on simplified
assumptions that limit performance. Deep reinforcement learning (DRL) has
recently emerged as a promising alternative, but online training is often
impractical because of costly and potentially damaging real-world interactions.
Offline RL provides a safer option by leveraging pre-collected datasets, but it
suffers from distribution shift, which degrades generalization to unseen
scenarios. To overcome this challenge, we propose DiSA-IQL
(Distribution-Shift-Aware Implicit Q-Learning), an extension of IQL that
incorporates robustness modulation by penalizing unreliable state-action pairs
to mitigate distribution shift. We evaluate DiSA-IQL on goal-reaching tasks
across two settings: in-distribution and out-of-distribution evaluation.
Simulation results show that DiSA-IQL consistently outperforms baseline models,
including Behavior Cloning (BC), Conservative Q-Learning (CQL), and vanilla
IQL, achieving higher success rates, smoother trajectories, and improved
robustness. The codes are open-sourced to support reproducibility and to
facilitate further research in offline RL for soft robot control.

</details>


### [26] [Physics-Informed Neural Controlled Differential Equations for Scalable Long Horizon Multi-Agent Motion Forecasting](https://arxiv.org/abs/2510.00401)
*Shounak Sural,Charles Kekeh,Wenliang Liu,Federico Pecora,Mouhacine Benosman*

Main category: cs.RO

TL;DR: PINCoDE是一个基于神经控制微分方程的运动预测模型，能在多目标条件下高效预测多机器人系统的运动，体现了物理约束的有效性。


<details>
  <summary>Details</summary>
Motivation: 解决多机器人长期运动预测中的非线性交互、预测误差累积和动态演变等挑战，提升旅行时间预测和规划等应用的准确性。

Method: 基于神经控制微分方程（CDEs）的模型，结合物理指导的深度学习方法，进行多机器人动态建模。

Result: 在1分钟的预测范围内，PINCoDE的平均绝对误差（ADE）低于0.5米，且通过逐步学习策略，预测位置误差降低了2.7倍，具有良好的扩展性。

Conclusion: PINCoDE模型在多机器人系统的长期运动预测中表现优越，能够在不增加模型参数的情况下扩展，且在未来目标的条件下有效地考虑物理约束，减少预测误差。

Abstract: Long-horizon motion forecasting for multiple autonomous robots is challenging
due to non-linear agent interactions, compounding prediction errors, and
continuous-time evolution of dynamics. Learned dynamics of such a system can be
useful in various applications such as travel time prediction,
prediction-guided planning and generative simulation. In this work, we aim to
develop an efficient trajectory forecasting model conditioned on multi-agent
goals. Motivated by the recent success of physics-guided deep learning for
partially known dynamical systems, we develop a model based on neural
Controlled Differential Equations (CDEs) for long-horizon motion forecasting.
Unlike discrete-time methods such as RNNs and transformers, neural CDEs operate
in continuous time, allowing us to combine physics-informed constraints and
biases to jointly model multi-robot dynamics. Our approach, named PINCoDE
(Physics-Informed Neural Controlled Differential Equations), learns
differential equation parameters that can be used to predict the trajectories
of a multi-agent system starting from an initial condition. PINCoDE is
conditioned on future goals and enforces physics constraints for robot motion
over extended periods of time. We adopt a strategy that scales our model from
10 robots to 100 robots without the need for additional model parameters, while
producing predictions with an average ADE below 0.5 m for a 1-minute horizon.
Furthermore, progressive training with curriculum learning for our PINCoDE
model results in a 2.7X reduction of forecasted pose error over 4 minute
horizons compared to analytical models.

</details>


### [27] [VLA-RFT: Vision-Language-Action Reinforcement Fine-tuning with Verified Rewards in World Simulators](https://arxiv.org/abs/2510.00406)
*Hengtao Li,Pengxiang Ding,Runze Suo,Yihao Wang,Zirui Ge,Dongyuan Zang,Kexian Yu,Mingyang Sun,Hongyin Zhang,Donglin Wang,Weihua Su*

Main category: cs.RO

TL;DR: VLA-RFT是一种基于世界模型的强化学习微调框架，显著提高了VLA模型在真实环境中的决策能力与鲁棒性，拥有高效的学习信号和较低的样本需求。


<details>
  <summary>Details</summary>
Motivation: 解决现有VLA模型在模仿学习中的不足，尤其是由于分布转变引起的错误累积及鲁棒性差的问题。

Method: 引入了基于世界模型的强化学习微调框架，利用实际交互数据训练模拟器，以预测未来视觉观测并提供密集的、基于轨迹的奖励。

Result: 在不到400次微调步骤中，VLA-RFT超越了强大的监督基线，并在扰动条件下表现出较强的鲁棒性，稳定执行任务。

Conclusion: VLA-RFT通过数据驱动的世界模型实现了可控的仿真，提高了VLA模型的泛化能力和鲁棒性。

Abstract: Vision-Language-Action (VLA) models enable embodied decision-making but rely
heavily on imitation learning, leading to compounding errors and poor
robustness under distribution shift. Reinforcement learning (RL) can mitigate
these issues yet typically demands costly real-world interactions or suffers
from sim-to-real gaps. We introduce VLA-RFT, a reinforcement fine-tuning
framework that leverages a data-driven world model as a controllable simulator.
Trained from real interaction data, the simulator predicts future visual
observations conditioned on actions, allowing policy rollouts with dense,
trajectory-level rewards derived from goal-achieving references. This design
delivers an efficient and action-aligned learning signal, drastically lowering
sample requirements. With fewer than 400 fine-tuning steps, VLA-RFT surpasses
strong supervised baselines and achieves greater efficiency than
simulator-based RL. Moreover, it exhibits strong robustness under perturbed
conditions, sustaining stable task execution. Our results establish
world-model-based RFT as a practical post-training paradigm to enhance the
generalization and robustness of VLA models. For more details, please refer to
https://vla-rft.github.io/.

</details>


### [28] [Seeing through Uncertainty: Robust Task-Oriented Optimization in Visual Navigation](https://arxiv.org/abs/2510.00441)
*Yiyuan Pan,Yunzhe Xu,Zhe Liu,Hesheng Wang*

Main category: cs.RO

TL;DR: 本文提出的NeuRO框架有效结合感知与优化，解决了多目标导航中的数据稀缺问题，实现了在新环境中的优异表现。


<details>
  <summary>Details</summary>
Motivation: 现有的基于神经网络的导航代理往往因数据稀缺而过拟合，难以泛化到新的环境，因此急需增强长时间规划和多目标任务的能力。

Method: 该论文介绍了一个名为NeuRO的综合学习优化框架，结合了感知网络与任务层次的鲁棒优化，通过部分输入凸神经网络（PICNNs）处理数据稀缺下的视觉预测，并将部分可观察性下的规划重构为鲁棒优化问题。

Result: 在无序和顺序多目标导航任务中，NeuRO的表现达到了最新的技术水平（SoTA），特别是在对未见环境的泛化能力上。

Conclusion: NeuRO在多目标导航任务中表现出色，尤其在新环境的泛化能力方面取得了重要进展，推动了鲁棒性和可泛化自治体的开发。

Abstract: Visual navigation is a fundamental problem in embodied AI, yet practical
deployments demand long-horizon planning capabilities to address
multi-objective tasks. A major bottleneck is data scarcity: policies learned
from limited data often overfit and fail to generalize OOD. Existing neural
network-based agents typically increase architectural complexity that
paradoxically become counterproductive in the small-sample regime. This paper
introduce NeuRO, a integrated learning-to-optimize framework that tightly
couples perception networks with downstream task-level robust optimization.
Specifically, NeuRO addresses core difficulties in this integration: (i) it
transforms noisy visual predictions under data scarcity into convex uncertainty
sets using Partially Input Convex Neural Networks (PICNNs) with conformal
calibration, which directly parameterize the optimization constraints; and (ii)
it reformulates planning under partial observability as a robust optimization
problem, enabling uncertainty-aware policies that transfer across environments.
Extensive experiments on both unordered and sequential multi-object navigation
tasks demonstrate that NeuRO establishes SoTA performance, particularly in
generalization to unseen environments. Our work thus presents a significant
advancement for developing robust, generalizable autonomous agents.

</details>


### [29] [Integrating Offline Pre-Training with Online Fine-Tuning: A Reinforcement Learning Approach for Robot Social Navigation](https://arxiv.org/abs/2510.00466)
*Run Su,Hao Fu,Shuai Zhou,Yingao Fu*

Main category: cs.RO

TL;DR: 本文提出了一种新的强化学习算法，通过回报预测集成在因果变换器中，解决机器人社交导航中的不确定性问题，取得了显著的成效。


<details>
  <summary>Details</summary>
Motivation: 应对机器人社交导航中的行人行为不确定性和有限环境交互导致的次优探索问题。

Method: 提出了一种新颖的离线到在线微调的强化学习算法，结合了回报预测和因果变换器架构。

Result: 在模拟社交导航环境中的实验表明，该方法成功率更高且碰撞率更低，超过了现有最先进的基线。

Conclusion: 本研究开发的算法能够有效提高机器人社交导航的成功率和适应性，适用于现实应用中的导航系统。

Abstract: Offline reinforcement learning (RL) has emerged as a promising framework for
addressing robot social navigation challenges. However, inherent uncertainties
in pedestrian behavior and limited environmental interaction during training
often lead to suboptimal exploration and distributional shifts between offline
training and online deployment. To overcome these limitations, this paper
proposes a novel offline-to-online fine-tuning RL algorithm for robot social
navigation by integrating Return-to-Go (RTG) prediction into a causal
Transformer architecture. Our algorithm features a spatiotem-poral fusion model
designed to precisely estimate RTG values in real-time by jointly encoding
temporal pedestrian motion patterns and spatial crowd dynamics. This RTG
prediction framework mitigates distribution shift by aligning offline policy
training with online environmental interactions. Furthermore, a hybrid
offline-online experience sampling mechanism is built to stabilize policy
updates during fine-tuning, ensuring balanced integration of pre-trained
knowledge and real-time adaptation. Extensive experiments in simulated social
navigation environments demonstrate that our method achieves a higher success
rate and lower collision rate compared to state-of-the-art baselines. These
results underscore the efficacy of our algorithm in enhancing navigation policy
robustness and adaptability. This work paves the way for more reliable and
adaptive robotic navigation systems in real-world applications.

</details>


### [30] [From Human Hands to Robot Arms: Manipulation Skills Transfer via Trajectory Alignment](https://arxiv.org/abs/2510.00491)
*Han Zhou,Jinjin Cao,Liyuan Ma,Xueji Fang,Guo-jun Qi*

Main category: cs.RO

TL;DR: Traj2Action是一个新的框架，用于通过3D轨迹促进人类与机器人之间的技能转移，从而在真实世界任务中显著提高机器人的操作表现。


<details>
  <summary>Details</summary>
Motivation: 解决通过无人机演示学习多样化操作技能时的成本和扩展性问题，以及人类和机器人形态之间的显著差距。

Method: 使用3D操作端点轨迹作为统一的中介表示，通过条件生成来实现人与机器人之间的知识转移。

Result: 在Franka机器人上进行的广泛实验表明，Traj2Action在短期和长期真实任务中，相较于$	ext{π}_0$基准，性能提升高达27%和22.25%。

Conclusion: Traj2Action框架显著提高了机器人的操作性能，使得机器人能更有效地从人类视频中学习多样化的操作技能。

Abstract: Learning diverse manipulation skills for real-world robots is severely
bottlenecked by the reliance on costly and hard-to-scale teleoperated
demonstrations. While human videos offer a scalable alternative, effectively
transferring manipulation knowledge is fundamentally hindered by the
significant morphological gap between human and robotic embodiments. To address
this challenge and facilitate skill transfer from human to robot, we introduce
Traj2Action,a novel framework that bridges this embodiment gap by using the 3D
trajectory of the operational endpoint as a unified intermediate
representation, and then transfers the manipulation knowledge embedded in this
trajectory to the robot's actions. Our policy first learns to generate a coarse
trajectory, which forms an high-level motion plan by leveraging both human and
robot data. This plan then conditions the synthesis of precise, robot-specific
actions (e.g., orientation and gripper state) within a co-denoising framework.
Extensive real-world experiments on a Franka robot demonstrate that Traj2Action
boosts the performance by up to 27% and 22.25% over $\pi_0$ baseline on short-
and long-horizon real-world tasks, and achieves significant gains as human data
scales in robot policy learning. Our project website, featuring code and video
demonstrations, is available at
https://anonymous.4open.science/w/Traj2Action-4A45/.

</details>


### [31] [Two stage GNSS outlier detection for factor graph optimization based GNSS-RTK/INS/odometer fusion](https://arxiv.org/abs/2510.00524)
*Baoshan Song,Penggao Yan,Xiao Xia,Yihan Zhong,Weisong Wen,Li-Ta Hsu*

Main category: cs.RO

TL;DR: 本文提出了一种两阶段的伪距异常值检测方法，有效缓解了GNSS在复杂环境中的定位问题，实验结果证明该方法能显著提高定位精度。


<details>
  <summary>Details</summary>
Motivation: 在复杂环境中，由于非视距传播、多路径效应和信号阻塞，GNSS定位面临着严重挑战，尤其是异常值对伪距测量的影响。

Method: 采用了两阶段的异常值检测方法，首先使用Doppler测量进行GNSS-only的伪距异常值检测，其次结合预积分的IMU和里程计约束生成预测的双差伪距测量进行进一步处理。

Result: 实验结果显示，该方法显著降低伪距异常值的影响，将GNSS-RTK/INS/里程计融合的均方根误差从0.52米降至0.30米，提升了42.3%的精度。

Conclusion: 提出的两阶段异常值检测方法显著提高了GNSS-RTK与INS及里程计融合的定位精度和一致性。

Abstract: Reliable GNSS positioning in complex environments remains a critical
challenge due to non-line-of-sight (NLOS) propagation, multipath effects, and
frequent signal blockages. These effects can easily introduce large outliers
into the raw pseudo-range measurements, which significantly degrade the
performance of global navigation satellite system (GNSS) real-time kinematic
(RTK) positioning and limit the effectiveness of tightly coupled GNSS-based
integrated navigation system. To address this issue, we propose a two-stage
outlier detection method and apply the method in a tightly coupled GNSS-RTK,
inertial navigation system (INS), and odometer integration based on factor
graph optimization (FGO). In the first stage, Doppler measurements are employed
to detect pseudo-range outliers in a GNSS-only manner, since Doppler is less
sensitive to multipath and NLOS effects compared with pseudo-range, making it a
more stable reference for detecting sudden inconsistencies. In the second
stage, pre-integrated inertial measurement units (IMU) and odometer constraints
are used to generate predicted double-difference pseudo-range measurements,
which enable a more refined identification and rejection of remaining outliers.
By combining these two complementary stages, the system achieves improved
robustness against both gross pseudo-range errors and degraded satellite
measuring quality. The experimental results demonstrate that the two-stage
detection framework significantly reduces the impact of pseudo-range outliers,
and leads to improved positioning accuracy and consistency compared with
representative baseline approaches. In the deep urban canyon test, the outlier
mitigation method has limits the RMSE of GNSS-RTK/INS/odometer fusion from 0.52
m to 0.30 m, with 42.3% improvement.

</details>


### [32] [GRITS: A Spillage-Aware Guided Diffusion Policy for Robot Food Scooping Tasks](https://arxiv.org/abs/2510.00573)
*Yen-Ling Tai,Yi-Ru Yang,Kuan-Ting Yu,Yu-Wei Chao,Yi-Ting Chen*

Main category: cs.RO

TL;DR: GRITS通过引导扩散策略和溢出预测器，显著提高了机器人食品铲取任务的成功率并降低了溢出率。


<details>
  <summary>Details</summary>
Motivation: 现有机器人学习算法在应对多样化和动态食品状态时存在困难，导致溢出和可靠性降低，因此需要开发更加有效的解决方案。

Method: 提出GRITS框架，利用引导扩散策略进行食品铲取任务，并设计了溢出预测器来估计溢出的概率，此预测器在模拟数据集上进行训练。

Result: GRITS在六种食品类别上进行训练，并在十种未见过的食品类别上进行评估，取得了82%的任务成功率和4%的溢出率。

Conclusion: GRITS在机器人食品铲取任务中表现出色，成功率达到82%，溢出率降低至4%，相比于无指导的基线减少了40%的溢出情况，证明了其有效性。

Abstract: Robotic food scooping is a critical manipulation skill for food preparation
and service robots. However, existing robot learning algorithms, especially
learn-from-demonstration methods, still struggle to handle diverse and dynamic
food states, which often results in spillage and reduced reliability. In this
work, we introduce GRITS: A Spillage-Aware Guided Diffusion Policy for Robot
Food Scooping Tasks. This framework leverages guided diffusion policy to
minimize food spillage during scooping and to ensure reliable transfer of food
items from the initial to the target location. Specifically, we design a
spillage predictor that estimates the probability of spillage given current
observation and action rollout. The predictor is trained on a simulated dataset
with food spillage scenarios, constructed from four primitive shapes (spheres,
cubes, cones, and cylinders) with varied physical properties such as mass,
friction, and particle size. At inference time, the predictor serves as a
differentiable guidance signal, steering the diffusion sampling process toward
safer trajectories while preserving task success. We validate GRITS on a
real-world robotic food scooping platform. GRITS is trained on six food
categories and evaluated on ten unseen categories with different shapes and
quantities. GRITS achieves an 82% task success rate and a 4% spillage rate,
reducing spillage by over 40% compared to baselines without guidance, thereby
demonstrating its effectiveness.

</details>


### [33] [Hybrid Training for Vision-Language-Action Models](https://arxiv.org/abs/2510.00600)
*Pietro Mazzaglia,Cansu Sancaktar,Markus Peschl,Daniel Dijkman*

Main category: cs.RO

TL;DR: 提出一种混合训练框架（HyT），用于提高视觉语言行动模型的性能，同时避免在推理时生成冗长的思维链，从而增强实际应用的可用性。


<details>
  <summary>Details</summary>
Motivation: 在复杂语言任务中，生成中间思维（思维链）被证明有助于提升性能，但在机器人设置中，生成冗长思维链可能会影响实际应用的可用性。

Method: 介绍了混合训练（HyT）框架，该框架允许视觉语言行动模型从思维中学习，以获得性能提升，同时在推理过程中可以选择不生成思维链。

Result: 在模拟基准测试和现实世界实验中验证了HyT方法的有效性，表明该方法能够提高性能并提供推理灵活性。

Conclusion: 提出的混合训练（HyT）框架能够改善视觉语言行动模型在复杂任务中的性能，同时在推理时避免生成冗长的思维链，从而提高实用性。

Abstract: Using Large Language Models to produce intermediate thoughts, a.k.a.
Chain-of-thought (CoT), before providing an answer has been a successful recipe
for solving complex language tasks. In robotics, similar embodied CoT
strategies, generating thoughts before actions, have also been shown to lead to
improved performance when using Vision-Language-Action models (VLAs). As these
techniques increase the length of the model's generated outputs to include the
thoughts, the inference time is negatively affected. Delaying an agent's
actions in real-world executions, as in robotic manipulation settings, strongly
affects the usability of a method, as tasks require long sequences of actions.
However, is the generation of long chains-of-thought a strong prerequisite for
achieving performance improvements? In this work, we explore the idea of Hybrid
Training (HyT), a framework that enables VLAs to learn from thoughts and
benefit from the associated performance gains, while enabling the possibility
to leave out CoT generation during inference. Furthermore, by learning to
conditionally predict a diverse set of outputs, HyT supports flexibility at
inference time, enabling the model to either predict actions directly, generate
thoughts or follow instructions. We evaluate the proposed method in a series of
simulated benchmarks and real-world experiments.

</details>


### [34] [What Did I Learn? Operational Competence Assessment for AI-Based Trajectory Planners](https://arxiv.org/abs/2510.00619)
*Michiel Braat,Maren Buermann,Marijke van Weperen,Jan-Pieter Paardekooper*

Main category: cs.RO

TL;DR: 本论文提出了一种通过知识图谱识别自动驾驶车辆未充分训练场景的方法，提高了机器学习的安全性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 确保自动驾驶机器学习算法的可靠性需要了解数据集中包含的内容，以评估训练模型的操作风险。

Method: 将驾驶数据建模为知识图谱，以实体及其关系表示驾驶场景，并查询特定子场景配置以检查其在数据集中的出现情况。

Result: 通过在NuPlan数据集上应用该方法，我们建模了知识图谱并分析了特定驾驶场景的覆盖情况，从而监控训练模型的能力。

Conclusion: 通过利用知识图谱建模驾驶数据，该方法有效提高了对自动驾驶车辆在未充分训练场景下的识别能力，从而增强了机器学习在自动驾驶中的安全性和可解释性。

Abstract: Automated driving functions increasingly rely on machine learning for tasks
like perception and trajectory planning, requiring large, relevant datasets.
The performance of these algorithms depends on how closely the training data
matches the task. To ensure reliable functioning, it is crucial to know what is
included in the dataset to assess the trained model's operational risk. We aim
to enhance the safe use of machine learning in automated driving by developing
a method to recognize situations that an automated vehicle has not been
sufficiently trained on. This method also improves explainability by describing
the dataset at a human-understandable level. We propose modeling driving data
as knowledge graphs, representing driving scenes with entities and their
relationships. These graphs are queried for specific sub-scene configurations
to check their occurrence in the dataset. We estimate a vehicle's competence in
a driving scene by considering the coverage and complexity of sub-scene
configurations in the training set. Higher complexity scenes require greater
coverage for high competence. We apply this method to the NuPlan dataset,
modeling it with knowledge graphs and analyzing the coverage of specific
driving scenes. This approach helps monitor the competence of machine learning
models trained on the dataset, which is essential for trustworthy AI to be
deployed in automated driving.

</details>


### [35] [Trajectory Based Observer Design: A Framework for Lightweight Sensor Fusion](https://arxiv.org/abs/2510.00630)
*Federico Oliva,Tom Shaked,Daniele Carnevale,Amir Degani*

Main category: cs.RO

TL;DR: 本文提出了一种新的基于优化的观察者设计方法TBOD，能够有效处理非线性系统和多传感器环境，性能在地面机器人定位上优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 提高状态估计中观察者设计的效率和传感器融合的准确性，尤其在复杂系统中。

Method: 通过优化设计的方法，利用预先记录的测量轨迹调整观察者参数，适用于非线性系统和多传感器设置。

Result: TBOD在结合IMU和超宽带天线传感器的地面机器人定位问题中验证了其性能，且在方向估计上有显著提升。

Conclusion: TBOD方法在地面机器人定位中的表现优于扩展卡尔曼滤波器，尤其在方向估计上显著提升。

Abstract: Efficient observer design and accurate sensor fusion are key in state
estimation. This work proposes an optimization-based methodology, termed
Trajectory Based Optimization Design (TBOD), allowing the user to easily design
observers for general nonlinear systems and multi-sensor setups. Starting from
parametrized observer dynamics, the proposed method considers a finite set of
pre-recorded measurement trajectories from the nominal plant and exploits them
to tune the observer parameters through numerical optimization. This research
hinges on the classic observer's theory and Moving Horizon Estimators
methodology. Optimization is exploited to ease the observer's design, providing
the user with a lightweight, general-purpose sensor fusion methodology. TBOD's
main characteristics are the capability to handle general sensors efficiently
and in a modular way and, most importantly, its straightforward tuning
procedure. The TBOD's performance is tested on a terrestrial rover localization
problem, combining IMU and ranging sensors provided by Ultra Wide Band
antennas, and validated through a motion-capture system. Comparison with an
Extended Kalman Filter is also provided, matching its position estimation
accuracy and significantly improving in the orientation.

</details>


### [36] [Enabling High-Frequency Cross-Modality Visual Positioning Service for Accurate Drone Landing](https://arxiv.org/abs/2510.00646)
*Haoyang Wang,Xinyu Luo,Wenhua Ding,Jingao Xu,Xuecheng Chen,Ruiyang Duan,Jialong Chen,Haitao Zhang,Yunhao Liu,Xinlei Chen*

Main category: cs.RO

TL;DR: 本研究提出EV-Pose，通过结合事件相机和新的姿态估计方法，提高了无人机在城市环境下的着陆精度和效率。


<details>
  <summary>Details</summary>
Motivation: 当前无人机在城市环境下的姿态跟踪传统系统不可靠，因此亟需一种新的方法来提高无人机着陆时的姿态跟踪精度和效率。

Method: 重设计视觉定位服务，结合事件相机，提出EV-Pose，包括时空特征指导的姿态估计模块和运动感知的分层融合优化方案。

Result: 通过采用EV-Pose的创新，提升了无人机在着陆阶段的姿态跟踪精度和效率。

Conclusion: EV-Pose显著提高了无人机着陆的准确性，旋转精度为1.34度，平移精度为6.9毫米，跟踪延迟为10.08毫秒，优于基线系统超过50%。

Abstract: After years of growth, drone-based delivery is transforming logistics. At its
core, real-time 6-DoF drone pose tracking enables precise flight control and
accurate drone landing. With the widespread availability of urban 3D maps, the
Visual Positioning Service (VPS), a mobile pose estimation system, has been
adapted to enhance drone pose tracking during the landing phase, as
conventional systems like GPS are unreliable in urban environments due to
signal attenuation and multi-path propagation. However, deploying the current
VPS on drones faces limitations in both estimation accuracy and efficiency. In
this work, we redesign drone-oriented VPS with the event camera and introduce
EV-Pose to enable accurate, high-frequency 6-DoF pose tracking for accurate
drone landing. EV-Pose introduces a spatio-temporal feature-instructed pose
estimation module that extracts a temporal distance field to enable 3D point
map matching for pose estimation; and a motion-aware hierarchical fusion and
optimization scheme to enhance the above estimation in accuracy and efficiency,
by utilizing drone motion in the \textit{early stage} of event filtering and
the \textit{later stage} of pose optimization. Evaluation shows that EV-Pose
achieves a rotation accuracy of 1.34$\degree$ and a translation accuracy of
6.9$mm$ with a tracking latency of 10.08$ms$, outperforming baselines by
$>$50\%, \tmcrevise{thus enabling accurate drone landings.} Demo:
https://ev-pose.github.io/

</details>


### [37] [Shared Object Manipulation with a Team of Collaborative Quadrupeds](https://arxiv.org/abs/2510.00682)
*Shengzhi Wang,Niels Dehio,Xuanqi Zeng,Xian Yang,Lingwei Zhang,Yun-Hui Liu,K. W. Samuel Au*

Main category: cs.RO

TL;DR: 本研究提出了一种新的控制方法，允许多足机器人团队高效、稳定地协作处理和运输硬物体，克服了现有多操纵系统的工作空间限制。


<details>
  <summary>Details</summary>
Motivation: 利用多个机器人的团队对大型物体进行处理，避免了多操纵系统在工作空间上的限制。

Method: 扩展经典的混合运动-力控制器至多足操纵系统，进行协作的活动-操控。

Result: 通过大量的仿真和实际实验，验证了机器人的协调运动能力。

Conclusion: 通过我们的新方法，多个机器人能够高效、稳定地共同操控和运输刚性物体。

Abstract: Utilizing teams of multiple robots is advantageous for handling bulky
objects. Many related works focus on multi-manipulator systems, which are
limited by workspace constraints. In this paper, we extend a classical hybrid
motion-force controller to a team of legged manipulator systems, enabling
collaborative loco-manipulation of rigid objects with a force-closed grasp. Our
novel approach allows the robots to flexibly coordinate their movements,
achieving efficient and stable object co-manipulation and transport, validated
through extensive simulations and real-world experiments.

</details>


### [38] [HAMLET: Switch your Vision-Language-Action Model into a History-Aware Policy](https://arxiv.org/abs/2510.00695)
*Myungkyu Koo,Daewon Choi,Taeyoung Kim,Kyungmin Lee,Changyeon Kim,Youngyo Seo,Jinwoo Shin*

Main category: cs.RO

TL;DR: 本文提出了HAMLET框架，成功提升了视觉-语言-动作模型对历史上下文的利用，在多项基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作模型未考虑历史上下文的依赖性，限制了其在复杂任务中的表现。

Method: 引入了时刻令牌和轻量级内存模块，通过时间对比学习及记忆特征整合历史上下文信息，以进行动作预测。

Result: HAMLET在历史依赖实用任务上成功实现76.4%的平均成功率，超越了基线性能47.2%。在RoboCasa Kitchen和LIBERO等基准测试上也表现出了显著提升。

Conclusion: HAMLET框架有效提升了现有视觉-语言-动作模型在历史依赖性任务中的表现，特别是在需要历史上下文的长时间跨度任务上，显著提高了成功率。

Abstract: Inherently, robotic manipulation tasks are history-dependent: leveraging past
context could be beneficial. However, most existing Vision-Language-Action
models (VLAs) have been designed without considering this aspect, i.e., they
rely solely on the current observation, ignoring preceding context. In this
paper, we propose HAMLET, a scalable framework to adapt VLAs to attend to the
historical context during action prediction. Specifically, we introduce moment
tokens that compactly encode perceptual information at each timestep. Their
representations are initialized with time-contrastive learning, allowing them
to better capture temporally distinctive aspects. Next, we employ a lightweight
memory module that integrates the moment tokens across past timesteps into
memory features, which are then leveraged for action prediction. Through
empirical evaluation, we show that HAMLET successfully transforms a
state-of-the-art VLA into a history-aware policy, especially demonstrating
significant improvements on long-horizon tasks that require historical context.
In particular, on top of GR00T N1.5, HAMLET achieves an average success rate of
76.4% on history-dependent real-world tasks, surpassing the baseline
performance by 47.2%. Furthermore, HAMLET pushes prior art performance from
64.1% to 66.4% on RoboCasa Kitchen (100-demo setup) and from 95.6% to 97.7% on
LIBERO, highlighting its effectiveness even under generic robot-manipulation
benchmarks.

</details>


### [39] [MultiPhysio-HRC: Multimodal Physiological Signals Dataset for industrial Human-Robot Collaboration](https://arxiv.org/abs/2510.00703)
*Andrea Bussolan,Stefano Baraldo,Oliver Avram,Pablo Urcola,Luis Montesano,Luca Maria Gambardella,Anna Valente*

Main category: cs.RO

TL;DR: 本研究推出了一个名为MultiPhysio-HRC的多模态数据集，旨在提高人机协调效率并关注人类福祉，适用于人机协作和智能机器人系统的研究。


<details>
  <summary>Details</summary>
Motivation: 提升人机协作中的工作效率和保障人类福祉。

Method: 通过收集在真实HRC场景中的生理、音频和面部数据，将数据集构建为多模态的形式。

Result: 该数据集展示了其在情感计算和人类感知机器人研究中的潜力，并通过基线模型评估了压力和认知负荷分类。

Conclusion: MultiPhysio-HRC数据集为研究人机交互和机器人智能提供了重要的支持。

Abstract: Human-robot collaboration (HRC) is a key focus of Industry 5.0, aiming to
enhance worker productivity while ensuring well-being. The ability to perceive
human psycho-physical states, such as stress and cognitive load, is crucial for
adaptive and human-aware robotics. This paper introduces MultiPhysio-HRC, a
multimodal dataset containing physiological, audio, and facial data collected
during real-world HRC scenarios. The dataset includes electroencephalography
(EEG), electrocardiography (ECG), electrodermal activity (EDA), respiration
(RESP), electromyography (EMG), voice recordings, and facial action units. The
dataset integrates controlled cognitive tasks, immersive virtual reality
experiences, and industrial disassembly activities performed manually and with
robotic assistance, to capture a holistic view of the participants' mental
states. Rich ground truth annotations were obtained using validated
psychological self-assessment questionnaires. Baseline models were evaluated
for stress and cognitive load classification, demonstrating the dataset's
potential for affective computing and human-aware robotics research.
MultiPhysio-HRC is publicly available to support research in human-centered
automation, workplace well-being, and intelligent robotic systems.

</details>


### [40] [CroSTAta: Cross-State Transition Attention Transformer for Robotic Manipulation](https://arxiv.org/abs/2510.00726)
*Giovanni Minelli,Giulio Turrisi,Victor Barasuol,Claudio Semini*

Main category: cs.RO

TL;DR: 本研究提出了一种新的注意力机制来增强机器人操作的适应性，方法在多项任务中显示出显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 机器人操作政策训练中，执行过程中未涵盖的变化使得标准的监督学习方法面临挑战，因此需要一种新的方法来建模执行历史中的时间结构。

Method: 采用了一种新的状态转移注意力机制（STA），结合结构化注意力和训练时的时间掩蔽技术，从而改善算法对历史上下文的推理能力。

Result: 在仿真评估中，STA在所有任务上均优于标准交叉注意力及采用时间建模的方法（如TCN和LSTM网络），在精确关键任务上表现出超过2倍的提升。

Conclusion: 提出的Cross-State Transition Attention Transformer通过引入状态转移注意力机制，显著提升了机器人操作政策对执行历史的适应能力，实现了在精确关键任务上的性能提升。

Abstract: Learning robotic manipulation policies through supervised learning from
demonstrations remains challenging when policies encounter execution variations
not explicitly covered during training. While incorporating historical context
through attention mechanisms can improve robustness, standard approaches
process all past states in a sequence without explicitly modeling the temporal
structure that demonstrations may include, such as failure and recovery
patterns. We propose a Cross-State Transition Attention Transformer that
employs a novel State Transition Attention (STA) mechanism to modulate standard
attention weights based on learned state evolution patterns, enabling policies
to better adapt their behavior based on execution history. Our approach
combines this structured attention with temporal masking during training, where
visual information is randomly removed from recent timesteps to encourage
temporal reasoning from historical context. Evaluation in simulation shows that
STA consistently outperforms standard cross-attention and temporal modeling
approaches like TCN and LSTM networks across all tasks, achieving more than 2x
improvement over cross-attention on precision-critical tasks.

</details>


### [41] [Tele-rehabilitation with online skill transfer and adaptation in $\mathbb{R}^3 \times \mathit{S}^3$](https://arxiv.org/abs/2510.00770)
*Tianle Ni,Xiao Chen,Hamid Sadeghian,Sami Haddadin*

Main category: cs.RO

TL;DR: 本研究提出了一种机器人辅助的远程康复教学框架，通过双向远程操作使治疗师能够远程指导患者，实验表明该框架在远程监督康复中具有良好适应性和个性化潜力。


<details>
  <summary>Details</summary>
Motivation: 提出一个机器人辅助的远程康复教学框架，以改善康复治疗的灵活性和有效性。

Method: 利用6自由度动态运动原语来编码运动轨迹，并实现双向远程操作。

Result: 通过7自由度机械手的实验证明了该方法的可行性。

Conclusion: 该框架在个性化和远程监督康复方面具有潜力。

Abstract: This paper proposes a tele-teaching framework for the domain of
robot-assisted tele-rehabilitation. The system connects two robotic
manipulators on therapist and patient side via bilateral teleoperation,
enabling a therapist to remotely demonstrate rehabilitation exercises that are
executed by the patient-side robot. A 6-DoF Dynamical Movement Primitives
formulation is employed to jointly encode translational and rotational motions
in $\mathbb{R}^3 \times \mathit{S}^3$ space, ensuring accurate trajectory
reproduction. The framework supports smooth transitions between therapist-led
guidance and patient passive training, while allowing adaptive adjustment of
motion. Experiments with 7-DoF manipulators demonstrate the feasibility of the
approach, highlighting its potential for personalized and remotely supervised
rehabilitation.

</details>


### [42] [Semantic Visual Simultaneous Localization and Mapping: A Survey on State of the Art, Challenges, and Future Directions](https://arxiv.org/abs/2510.00783)
*Thanh Nguyen Canh,Haolan Zhang,Xiem HoangVan,Nak Young Chong*

Main category: cs.RO

TL;DR: 本研究深入探讨了语义SLAM的现状，提出了系统化的解决方案和未来研究方向，以解决当前面临的挑战。


<details>
  <summary>Details</summary>
Motivation: 在语义SLAM领域，尽管其重要性不断增加，但缺乏全面的调查研究来涵盖近期的进展和持续的挑战。

Method: 提出了统一的问题表述和模块化解决方案框架，将SLAM问题分为多个离散阶段，包括视觉定位、语义特征提取、建图、数据关联和回环闭合优化。

Result: 综合考察了语义SLAM技术的最新发展，评估了视觉SLAM的演变、特点并对前述调查文献进行了批判性分析，同时探索了深度学习和大型语言模型等替代方法。

Conclusion: 本研究为研究人员提供了关于语义SLAM的最新进展和未来研究方向的全面资源。

Abstract: Semantic Simultaneous Localization and Mapping (SLAM) is a critical area of
research within robotics and computer vision, focusing on the simultaneous
localization of robotic systems and associating semantic information to
construct the most accurate and complete comprehensive model of the surrounding
environment. Since the first foundational work in Semantic SLAM appeared more
than two decades ago, this field has received increasing attention across
various scientific communities. Despite its significance, the field lacks
comprehensive surveys encompassing recent advances and persistent challenges.
In response, this study provides a thorough examination of the state-of-the-art
of Semantic SLAM techniques, with the aim of illuminating current trends and
key obstacles. Beginning with an in-depth exploration of the evolution of
visual SLAM, this study outlines its strengths and unique characteristics,
while also critically assessing previous survey literature. Subsequently, a
unified problem formulation and evaluation of the modular solution framework is
proposed, which divides the problem into discrete stages, including visual
localization, semantic feature extraction, mapping, data association, and loop
closure optimization. Moreover, this study investigates alternative
methodologies such as deep learning and the utilization of large language
models, alongside a review of relevant research about contemporary SLAM
datasets. Concluding with a discussion on potential future research directions,
this study serves as a comprehensive resource for researchers seeking to
navigate the complex landscape of Semantic SLAM.

</details>


### [43] [RTFF: Random-to-Target Fabric Flattening Policy using Dual-Arm Manipulator](https://arxiv.org/abs/2510.00814)
*Kai Tang,Dipankar Bhattacharya,Hang Xu,Fuyuki Tokuda,Norman C. Tien,Kazuhiro Kosuge*

Main category: cs.RO

TL;DR: 本论文提出了一种新的随机到目标面料平整策略（RTFF），通过混合模仿学习和视觉伺服技术，解决面料对齐中的挑战，展示了强大的适应性和准确性。


<details>
  <summary>Details</summary>
Motivation: 在服装生产中，机器人对面料的操作需要可靠的平整和对齐，但由于面料的可变形性和复杂度，这一过程充满挑战。

Method: 采用混合模仿学习-视觉伺服框架，通过模板基础网格提供目标状态表示，进行粗略与精确的面料对齐。

Result: RTFF政策在真实双臂遥操作系统上进行了验证，显示了在不同目标上的零样本对齐和高准确性。

Conclusion: 提出的RTFF策略在不同目标上实现了零样本对齐，展现了高准确性和强鲁棒性，能够适应多种面料和规模。

Abstract: Robotic fabric manipulation in garment production for sewing, cutting, and
ironing requires reliable flattening and alignment, yet remains challenging due
to fabric deformability, effectively infinite degrees of freedom, and frequent
occlusions from wrinkles, folds, and the manipulator's End-Effector (EE) and
arm. To address these issues, this paper proposes the first Random-to-Target
Fabric Flattening (RTFF) policy, which aligns a random wrinkled fabric state to
an arbitrary wrinkle-free target state. The proposed policy adopts a hybrid
Imitation Learning-Visual Servoing (IL-VS) framework, where IL learns with
explicit fabric models for coarse alignment of the wrinkled fabric toward a
wrinkle-free state near the target, and VS ensures fine alignment to the
target. Central to this framework is a template-based mesh that offers precise
target state representation, wrinkle-aware geometry prediction, and consistent
vertex correspondence across RTFF manipulation steps, enabling robust
manipulation and seamless IL-VS switching. Leveraging the power of mesh, a
novel IL solution for RTFF-Mesh Action Chunking Transformer (MACT)-is then
proposed by conditioning the mesh information into a Transformer-based policy.
The RTFF policy is validated on a real dual-arm tele-operation system, showing
zero-shot alignment to different targets, high accuracy, and strong
generalization across fabrics and scales. Project website:
https://kaitang98.github.io/RTFF_Policy/

</details>


### [44] [Product-oriented Product-Process-Resource Asset Network and its Representation in AutomationML for Asset Administration Shell](https://arxiv.org/abs/2510.00933)
*Sara Strakosova,Petr Novak,Petr Kadera*

Main category: cs.RO

TL;DR: 该论文提出了一种新模型PoPAN，以支持汽车等复杂产品在整个生命周期中的修复与再制造，特别聚焦电动汽车电池的应用。


<details>
  <summary>Details</summary>
Motivation: 希望通过将产品生命周期的末端影响纳入工程阶段，来改善当前产品工程和生产过程中存在的问题，特别是在汽车行业中的复杂技术系统。

Method: 通过产品-过程-资源（PPR）建模范式提出一种新的建模方法，并使用AutomationML数据格式进行序列化。

Result: 模型结合了产品结构和再制造等要求，能够在智能物理生产系统中应用，并推广至整个产品生命周期。

Conclusion: 提出的PoPAN模型能够在整个产品生命周期内伴随产品，助力修复、再制造和升级，尤其适用于电动汽车电池的拆解与再制造。

Abstract: Current products, especially in the automotive sector, pose complex technical
systems having a multi-disciplinary mechatronic nature. Industrial standards
supporting system engineering and production typically (i) address the
production phase only, but do not cover the complete product life cycle, and
(ii) focus on production processes and resources rather than the products
themselves. The presented approach is motivated by incorporating impacts of
end-of-life phase of the product life cycle into the engineering phase. This
paper proposes a modelling approach coming up from the Product-Process-Resource
(PPR) modeling paradigm. It combines requirements on (i) respecting the product
structure as a basis for the model, and (ii) it incorporates repairing,
remanufacturing, or upcycling within cyber-physical production systems. The
proposed model called PoPAN should accompany the product during the entire life
cycle as a digital shadow encapsulated within the Asset Administration Shell of
a product. To facilitate the adoption of the proposed paradigm, the paper also
proposes serialization of the model in the AutomationML data format. The model
is demonstrated on a use-case for disassembling electric vehicle batteries to
support their remanufacturing for stationary battery applications.

</details>


### [45] [Non-submodular Visual Attention for Robot Navigation](https://arxiv.org/abs/2510.00942)
*Reza Vafaee,Kian Behzad,Milad Siami,Luca Carlone,Ali Jadbabaie*

Main category: cs.RO

TL;DR: 本文提出了一种框架以增强机器人的视觉惯性导航，包含多种高效的特征选择算法，经过实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 针对视觉惯性导航中时间和能量资源有限的挑战，提出框架以优化视觉特征选择。

Method: 引入了四个多项式时间近似算法，包括经典贪婪法、低秩贪婪变体、随机贪婪采样器和基于线性化选择器，结合了子模性比率等分析方法。

Result: 在标准基准和自定义控制感知平台上进行了广泛实验，验证了理论结果的有效性与强近似保证。

Conclusion: 提出的任务导向计算框架有效提升了机器人的视觉惯性导航性能，并实现了实时部署。

Abstract: This paper presents a task-oriented computational framework to enhance
Visual-Inertial Navigation (VIN) in robots, addressing challenges such as
limited time and energy resources. The framework strategically selects visual
features using a Mean Squared Error (MSE)-based, non-submodular objective
function and a simplified dynamic anticipation model. To address the
NP-hardness of this problem, we introduce four polynomial-time approximation
algorithms: a classic greedy method with constant-factor guarantees; a low-rank
greedy variant that significantly reduces computational complexity; a
randomized greedy sampler that balances efficiency and solution quality; and a
linearization-based selector based on a first-order Taylor expansion for
near-constant-time execution. We establish rigorous performance bounds by
leveraging submodularity ratios, curvature, and element-wise curvature
analyses. Extensive experiments on both standardized benchmarks and a custom
control-aware platform validate our theoretical results, demonstrating that
these methods achieve strong approximation guarantees while enabling real-time
deployment.

</details>


### [46] [ROSflight 2.0: Lean ROS 2-Based Autopilot for Unmanned Aerial Vehicles](https://arxiv.org/abs/2510.00995)
*Jacob Moore,Phil Tokumaru,Ian Reid,Brandon Sutherland,Joseph Ritchie,Gabe Snow,Tim McLain*

Main category: cs.RO

TL;DR: ROSflight是一个开源无人机自主驾驶平台，通过提高模块化和可用性，促进无人机研究，支持高频控制。


<details>
  <summary>Details</summary>
Motivation: 旨在降低无人机研究的入门门槛，并加速从仿真到硬件实验的过渡。

Method: 在ROSflight架构中进行重要更新，包括从ROS 1迁移到ROS 2、支持的硬件、低级执行器混合和仿真环境的改进。

Result: 显示ROSflight能够通过串行连接在400 Hz下控制多旋翼，同时在伴随计算机上闭合所有控制回路。

Conclusion: ROSflight 通过改进模块化和可用性，加速了无人机研究，支持 400 Hz 的多旋翼控制。

Abstract: ROSflight is a lean, open-source autopilot ecosystem for unmanned aerial
vehicles (UAVs). Designed by researchers for researchers, it is built to lower
the barrier to entry to UAV research and accelerate the transition from
simulation to hardware experiments by maintaining a lean (not full-featured),
well-documented, and modular codebase. This publication builds on previous
treatments and describes significant additions to the architecture that improve
the modularity and usability of ROSflight, including the transition from ROS 1
to ROS 2, supported hardware, low-level actuator mixing, and the simulation
environment. We believe that these changes improve the usability of ROSflight
and enable ROSflight to accelerate research in areas like advanced-air
mobility. Hardware results are provided, showing that ROSflight is able to
control a multirotor over a serial connection at 400 Hz while closing all
control loops on the companion computer.

</details>


### [47] [Prometheus: Universal, Open-Source Mocap-Based Teleoperation System with Force Feedback for Dataset Collection in Robot Learning](https://arxiv.org/abs/2510.01023)
*S. Satsevich,A. Bazhenov,S. Egorov,A. Erkhov,M. Gromakov,A. Fedoseev,D. Tsetserukou*

Main category: cs.RO

TL;DR: 本论文提出了一种新颖的低成本远程操作系统，结合力反馈和定制设备，显著提高任务成功率。


<details>
  <summary>Details</summary>
Motivation: 研究动机是改善远程操作系统的反馈机制，允许操作者准确感知施加于物体的抓取力量。

Method: 该研究提出了一种集成HTC Vive Trackers 2.0的远程操作系统，结合定制控制器、UR3机械臂及Robotiq抓手。

Result: 实验结果表明，所提出的系统在任务成功率上有显著提升，且经济性较高。

Conclusion: 该系统提高了任务成功率，并提供了一种经济实惠的大规模模仿学习数据收集方案。

Abstract: This paper presents a novel teleoperation system with force feedback,
utilizing consumer-grade HTC Vive Trackers 2.0. The system integrates a
custom-built controller, a UR3 robotic arm, and a Robotiq gripper equipped with
custom-designed fingers to ensure uniform pressure distribution on an embedded
force sensor. Real-time compression force data is transmitted to the
controller, enabling operators to perceive the gripping force applied to
objects. Experimental results demonstrate that the system enhances task success
rates and provides a low-cost solution for large-scale imitation learning data
collection without compromising affordability.

</details>


### [48] [ROSplane 2.0: A Fixed-Wing Autopilot for Research](https://arxiv.org/abs/2510.01041)
*Ian Reid,Joseph Ritchie,Jacob Moore,Brandon Sutherland,Gabe Snow,Phillip Tokumaru,Tim McLain*

Main category: cs.RO

TL;DR: ROSplane 是一个开源的固定翼自主控制栈，旨在加速无人机研究，通过易于理解的代码和文档降低研究门槛，并简化新工具和方法的集成。


<details>
  <summary>Details</summary>
Motivation: 推动无人机研究的发展，降低研究人员在整合先进技术与现有自动驾驶系统时的资源与时间成本。

Method: 采用 ROS 2 平台，提供明确的接口和可修改的框架，以支持控制、路径规划和估计算法的快速集成。

Result: 最新的 ROSplane 版本显著提升了无人机研究的能力，包括从 ROS 1 迁移到 ROS 2、增强的估计与控制算法、更高的模块化以及改进的空气动力学建模流程。

Conclusion: ROSplane 的体系结构简化了新研究工具和方法的集成，促进了硬件实验的快速进行。

Abstract: Unmanned aerial vehicle (UAV) research requires the integration of
cutting-edge technology into existing autopilot frameworks. This process can be
arduous, requiring extensive resources, time, and detailed knowledge of the
existing system. ROSplane is a lean, open-source fixed-wing autonomy stack
built by researchers for researchers. It is designed to accelerate research by
providing clearly defined interfaces with an easily modifiable framework.
Powered by ROS 2, ROSplane allows for rapid integration of low or high-level
control, path planning, or estimation algorithms. A focus on lean, easily
understood code and extensive documentation lowers the barrier to entry for
researchers. Recent developments to ROSplane improve its capacity to accelerate
UAV research, including the transition from ROS 1 to ROS 2, enhanced estimation
and control algorithms, increased modularity, and an improved aerodynamic
modeling pipeline. This aerodynamic modeling pipeline significantly reduces the
effort of transitioning from simulation to real-world testing without requiring
expensive system identification or computational fluid dynamics tools.
ROSplane's architecture reduces the effort required to integrate new research
tools and methods, expediting hardware experimentation.

</details>


### [49] [Compose Your Policies! Improving Diffusion-based or Flow-based Robot Policies via Test-time Distribution-level Composition](https://arxiv.org/abs/2510.01068)
*Jiahang Cao,Yize Huang,Hanzhong Guo,Rui Zhang,Mu Nan,Weijian Mai,Jiaxu Wang,Hao Cheng,Jingkai Sun,Gang Han,Wen Zhao,Qiang Zhang,Yijie Guo,Qihao Zheng,Chunfeng Song,Xiao Li,Ping Luo,Andrew F. Luo*

Main category: cs.RO

TL;DR: 本文提出了一种新的政策组合方法，GPC，通过结合多个预训练政策的分布得分，无需额外训练，从而提高机器人控制性能。


<details>
  <summary>Details</summary>
Motivation: 传统的扩散模型在机器控制中取得了显著的成就，但由于获取大规模交互数据集的高成本，其发展受到了限制。

Method: 提出了一种无训练的方法——General Policy Composition (GPC)，通过对多个预训练政策的分布得分进行凸组合和测试时搜索来增强性能。

Result: 在Robomimic、PushT和RoboTwin基准测试以及真实机器人评估中，GPC一致性地提高了性能和适应性。

Conclusion: GPC是一种简单有效的方法，通过利用现有政策来改善控制性能。

Abstract: Diffusion-based models for robotic control, including vision-language-action
(VLA) and vision-action (VA) policies, have demonstrated significant
capabilities. Yet their advancement is constrained by the high cost of
acquiring large-scale interaction datasets. This work introduces an alternative
paradigm for enhancing policy performance without additional model training.
Perhaps surprisingly, we demonstrate that the composed policies can exceed the
performance of either parent policy. Our contribution is threefold. First, we
establish a theoretical foundation showing that the convex composition of
distributional scores from multiple diffusion models can yield a superior
one-step functional objective compared to any individual score. A
Gr\"onwall-type bound is then used to show that this single-step improvement
propagates through entire generation trajectories, leading to systemic
performance gains. Second, motivated by these results, we propose General
Policy Composition (GPC), a training-free method that enhances performance by
combining the distributional scores of multiple pre-trained policies via a
convex combination and test-time search. GPC is versatile, allowing for the
plug-and-play composition of heterogeneous policies, including VA and VLA
models, as well as those based on diffusion or flow-matching, irrespective of
their input visual modalities. Third, we provide extensive empirical
validation. Experiments on Robomimic, PushT, and RoboTwin benchmarks, alongside
real-world robotic evaluations, confirm that GPC consistently improves
performance and adaptability across a diverse set of tasks. Further analysis of
alternative composition operators and weighting strategies offers insights into
the mechanisms underlying the success of GPC. These results establish GPC as a
simple yet effective method for improving control performance by leveraging
existing policies.

</details>


### [50] [Real-Time Trajectory Generation and Hybrid Lyapunov-Based Control for Hopping Robots](https://arxiv.org/abs/2510.01138)
*Matthew Woodward*

Main category: cs.RO

TL;DR: 本论文介绍了一种新颖的方法，使跳跃机器人能够高效地生成并控制复杂的空中轨迹，提升了其在各种环境中的适用性。


<details>
  <summary>Details</summary>
Motivation: 应对当前跳跃机器人在空中轨迹控制和飞行动作转换方面的不足，提高其整体效率和性能。

Method: 采用非线性拖曳补偿的轨迹生成方法和李亚普诺夫控制器来进行实时控制。

Result: 结合的系统可以从起飞到着陆创建并遵循复杂的空中轨迹，并保持在接触时的姿态控制。

Conclusion: 提出了一种实时的轨迹生成方法与控制器，能够有效控制跳跃机器人在复杂空中轨迹中的表现，尤其在着陆时的姿态保持方面。

Abstract: The advent of rotor-based hopping robots has created very capable hopping
platforms with high agility and efficiency, and similar controllability, as
compared to their purely flying quadrotor counterparts. Advances in robot
performance have increased the hopping height to greater than 4 meters and
opened up the possibility for more complex aerial trajectories (i.e.,
behaviors). However, currently hopping robots do not directly control their
aerial trajectory or transition to flight, eliminating the efficiency benefits
of a hopping system. Here we show a real-time, computationally efficiency,
non-linear drag compensated, trajectory generation methodology and accompanying
Lyapunov-based controller. The combined system can create and follow complex
aerial trajectories from liftoff to touchdown on horizontal and vertical
surfaces, while maintaining strick control over the orientation at touchdown.
The computational efficiency provides broad applicability across all size
scales of hopping robots while maintaining applicability to quadrotors in
general.

</details>
