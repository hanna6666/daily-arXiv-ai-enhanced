<div id=toc></div>

# Table of Contents

- [cs.HC](#cs.HC) [Total: 7]
- [cs.RO](#cs.RO) [Total: 26]


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [1] [Surveillance and Disability in Online Proctored Exams: Student Perspectives and Design Implications](https://arxiv.org/abs/2511.10826)
*Monika Blue Kwapisz,Yoav Ackerman,Jennifer Nguyen,Prashanth Rajivan*

Main category: cs.HC

TL;DR: 在线监考系统对隐私的过度监控对残疾学生造成了不公平影响，增加了他们的焦虑和认知负担。


<details>
  <summary>Details</summary>
Motivation: 研究在线监考系统对学生隐私的影响，以及这些系统如何对残疾学生造成不公平的负担。

Method: 对有在线监考经历的残疾学生进行反思性主题分析的访谈。

Result: 通过对经历过在线监考的残疾学生进行访谈，揭示了监控与残疾之间的紧张关系及其对学生的心理负担。

Conclusion: 应重新设计在线监考系统，以保护残疾学生的隐私和公平考试。

Abstract: Online proctoring systems (OPS) are technologies and services that are used to monitor students during an online exam to deter cheating. However, OPS often violates student privacy by implementing overly intrusive surveillance to which students cannot consent meaningfully. The technologies used in OPS have been shown to unfairly flag students with disabilities. Our reflexive thematic analysis of interviews with students who have first-hand experience with online invigilated exams and who have disability accommodations points to their anxiety about the interaction between surveillance and their disabilities, leading to fears about misrepresentation and increased cognitive load on the exam. Students describe the compromises they need to make with their privacy and accommodations to take remote tests and share their privacy values. We present the implications for the design of OPS to mitigate the issues faced by disabled students.

</details>


### [2] [C2Views: Knowledge-based Colormap Design for Multiple-View Consistency](https://arxiv.org/abs/2511.11112)
*Yihan Hou,Yilin Ye,Liangwei Wang,Huamin Qu,Wei Zeng*

Main category: cs.HC

TL;DR: 我们提出C2Views框架，通过优化色图设计，增强多视图一致性，提升数据探索体验。


<details>
  <summary>Details</summary>
Motivation: 过往研究过于注重显式连接与交互，忽略了颜色在数据编码中的潜力。

Method: 提出C2Views框架，利用遗传算法优化色图设计，增强多视图一致性。

Result: C2Views生成的色图在简化数据探索过程中表现优于现有方法。

Conclusion: C2Views有效整合了颜色编码与多视图关系，提升了视觉传达效果，适用于多样化的数据关系。

Abstract: Multiple-view (MV) visualization provides a comprehensive and integrated perspective on complex data, establishing itself as an effective method for visual communication and exploratory data analysis. While existing studies have predominantly focused on designing explicit visual linkages and coordinated interactions to facilitate the exploration of MV visualizations, these approaches often demand extra graphical and interactive effort, overlooking the potential of color as an effective channel for encoding data and relationships. Addressing this oversight, we introduce C2Views, a new framework for colormap design that implicitly shows the relation across views. We begin by structuring the components and their relationships within MVs into a knowledge-based graph specification, wherein colormaps, data, and views are denoted as entities, and the interactions among them are illustrated as relations. Building on this representation, we formulate the design criteria as an optimization problem and employ a genetic algorithm enhanced by Pareto optimality, generating colormaps that balance single-view effectiveness and multiple-view consistency. Our approach is further complemented with an interactive interface for user-intended refinement. We demonstrate the feasibility of C2Views through various colormap design examples for MVs, underscoring its adaptability to diverse data relationships and view layouts. Comparative user studies indicate that our method outperforms the existing approach in facilitating color distinction and enhancing multiple-view consistency, thereby simplifying data exploration processes.

</details>


### [3] [ReTrace: Interactive Visualizations for Reasoning Traces of Large Reasoning Models](https://arxiv.org/abs/2511.11187)
*Ludwig Felder,Jacob Miller,Markus Wallinger,Stephen Kobourov,Chunyang Chen*

Main category: cs.HC

TL;DR: 本论文提出了ReTrace，一个交互式系统，通过结构化和可视化大型推理模型的推理过程，提升用户对模型思维方式的理解，减少认知负担。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的进步，用户需理解复杂的推理过程，因此需要一种方法来提升这些推理的可理解性和可解释性。

Method: 使用经过验证的推理分类法生成结构化推理数据，并调查两种类型的交互式可视化。在受控用户研究中，评估了这两种可视化的有效性。

Result: 通过用户研究，发现使用可视化的用户在理解模型推理时更准确且感知努力更少，相比于原始文本基线表现更佳。

Conclusion: 研究结果表明，ReTrace系统的可视化使用户能够更准确、轻松地理解模型的推理，具有重要的AI可解释性设计意义。

Abstract: Recent advances in Large Language Models have led to Large Reasoning Models, which produce step-by-step reasoning traces. These traces offer insight into how models think and their goals, improving explainability and helping users follow the logic, learn the process, and even debug errors. These traces, however, are often verbose and complex, making them cognitively demanding to comprehend. We address this challenge with ReTrace, an interactive system that structures and visualizes textual reasoning traces to support understanding. We use a validated reasoning taxonomy to produce structured reasoning data and investigate two types of interactive visualizations thereof. In a controlled user study, both visualizations enabled users to comprehend the model's reasoning more accurately and with less perceived effort than a raw text baseline. The results of this study could have design implications for making long and complex machine-generated reasoning processes more usable and transparent, an important step in AI explainability.

</details>


### [4] [Towards Usable Privacy Management for IoT TAPs: Deriving Privacy Clusters and Preference Profiles](https://arxiv.org/abs/2511.11209)
*Piero Romare,Farzaneh Karegar,Simone Fischer-Hübner*

Main category: cs.HC

TL;DR: 提出了一种可用的隐私管理方法，针对不同用户群体的隐私关切与需求进行聚类，形成三种隐私档案，为TAP提供更友好的隐私控制。


<details>
  <summary>Details</summary>
Motivation: 改善物联网触发-动作平台的隐私管理，特别是在用户需求与隐私偏好配置时，降低复杂性。

Method: 开发和验证了一份问卷，以用户对隐私的关注为基础，对用户进行聚类分析。

Result: 生成了三个不同的隐私档案（基础、中等和高隐私），为TAPs的可用隐私控制提供基础。

Conclusion: 研究结果揭示了用户隐私偏好的多样性，为TAP设计提供了实用的参考，以实现更好的隐私保护。

Abstract: IoT Trigger-Action Platforms (TAPs) typically offer coarse-grained permission controls. Even when fine-grained controls are available, users are likely overwhelmed by the complexity of setting privacy preferences. This paper contributes to usable privacy management for TAPs by deriving privacy clusters and profiles for different types of users that can be semi-automatically assigned or suggested to them. We developed and validated a questionnaire, based on users' privacy concerns regarding confidentiality and control and their requirements towards transparency in TAPs. In an online study (N=301), where participants were informed about potential privacy risks, we clustered users by their privacy concerns and requirements into Basic, Medium and High Privacy clusters. These clusters were then characterized by the users' data sharing preferences, based on a factorial vignette approach, considering the data categories, the data recipient types, and the purpose of data sharing. Our findings show three distinct privacy profiles, providing a foundation for more usable privacy controls in TAPs.

</details>


### [5] [Devising Experiments with Interactive Environments](https://arxiv.org/abs/2511.11229)
*Pavlos Panagiotidis,Jocelyn Spence,Nils Jager*

Main category: cs.HC

TL;DR: 本研究探索无编码的响应式光声创作，开发了模块化系统，经过工作坊实践，总结出三种集体策略。


<details>
  <summary>Details</summary>
Motivation: 这个研究旨在通过无编码的创作方式，提高表演者在沉浸式表演中对技术的操作能力，促进其创作自由。

Method: 通过六个工作坊的实践，以及分析录像、焦点小组讨论和指导者笔记，形成了一套有效的工作方法。

Result: 该论文报告了一个基于实践的研究，探讨了如何在沉浸式表演中无编码地创作响应式光和声音。作者开发了一个模块化系统，将实时手势、位置和语音输入与场景输出相结合，通过一个可视化逻辑层使表演者能够在排练中操作。经过六个工作坊的实践，最终呈现出一个包含互动元素的单观众沉浸式表演。论文详细叙述了系统的构建模块和工作坊的演变过程，以及通过分析工作坊录像、后期焦点小组讨论和指导者笔记，提出的三种使技术在混合创作/设计实践中可行的集体策略：角色轮换、接纳受控的不完美作为创造性资源，以及使用技术描述隐喻来支持创作实践。

Conclusion: 纸上总结的三种策略为技术与创作实践的结合提供了有效方法，推动了沉浸式表演的创新。

Abstract: This paper reports a practice-based investigation into authoring responsive light and sound in immersive performance without writing code. A modular system couples live gesture, position, and speech inputs to scenographic outputs through a visual logic layer that performers can operate in rehearsal. Across six workshops with eight professional performance-makers, we staged a progression from parallel ensemble and technical training to integrated dramaturgy, culminating in a single-spectator scratch immersive performance with interactive elements. This paper details the system's building blocks and the workshop arc. A reflexive reading of workshop video logs, post-workshop focus groups, and facilitator notes surfaced three ensemble-level strategies that made the technology workable in a hybrid devising/design practice: rotating roles between operator, performer, and mediator; embracing controlled imperfection as a creative resource; and using technology-describing metaphors to support creative practice.

</details>


### [6] [Building the Web for Agents: A Declarative Framework for Agent-Web Interaction](https://arxiv.org/abs/2511.11287)
*Sven Schultze,Meike Verena Kietzmann,Nils-Lucas Schönfeld,Ruth Stock-Homburg*

Main category: cs.HC

TL;DR: VOIX提供了一种通过简洁的HTML标签来定义AI代理可用功能的新框架，从而促进人机协作的安全性和效率。


<details>
  <summary>Details</summary>
Motivation: 当前自主AI代理在网络上的部署受到人机交互界面不匹配的制约，导致交互脆弱、效率低下和不安全。

Method: VOIX引入了<tool>和<context>标签，允许开发者明确地定义可用动作和相关状态，在开发者与用户之间建立清晰的机器可读合同。通过三天的黑客马拉松研究，评估了框架的实用性、学习能力和表现力，结果显示参与者能够快速构建多样化的功能性代理支持的Web应用。

Result: 我们提出了VOIX，一个网络原生框架，使网站能够通过简单的HTML元素向AI代理暴露可靠、可审计和保护隐私的功能。

Conclusion: 这一工作提供了实现代理网络的基础机制，使未来人类与AI在网络上的协作更加无缝和安全。

Abstract: The increasing deployment of autonomous AI agents on the web is hampered by a fundamental misalignment: agents must infer affordances from human-oriented user interfaces, leading to brittle, inefficient, and insecure interactions. To address this, we introduce VOIX, a web-native framework that enables websites to expose reliable, auditable, and privacy-preserving capabilities for AI agents through simple, declarative HTML elements. VOIX introduces <tool> and <context> tags, allowing developers to explicitly define available actions and relevant state, thereby creating a clear, machine-readable contract for agent behavior. This approach shifts control to the website developer while preserving user privacy by disconnecting the conversational interactions from the website. We evaluated the framework's practicality, learnability, and expressiveness in a three-day hackathon study with 16 developers. The results demonstrate that participants, regardless of prior experience, were able to rapidly build diverse and functional agent-enabled web applications. Ultimately, this work provides a foundational mechanism for realizing the Agentic Web, enabling a future of seamless and secure human-AI collaboration on the web.

</details>


### [7] [Context-aware Adaptive Visualizations for Critical Decision Making](https://arxiv.org/abs/2511.11476)
*Angela Lopez-Cardona,Mireia Masias Bruns,Nuwan T. Attygalle,Sebastian Idesis,Matteo Salvatori,Konstantinos Raftopoulos,Konstantinos Oikonomou,Saravanakumar Duraisamy,Parvin Emami,Nacera Latreche,Alaa Eddine Anis Sahraoui,Michalis Vakallelis,Jean Vanderdonckt,Ioannis Arapakis,Luis A. Leiva*

Main category: cs.HC

TL;DR: Symbiotik是一种智能的上下文感知适应可视化系统，能够根据心理负荷实时优化可视化仪表板，提高用户 performance和 engagement。


<details>
  <summary>Details</summary>
Motivation: 现有的信息可视化仪表板缺乏实时适应能力，不能根据用户的认知状态进行调整。

Method: 使用增强学习动态适应可视化仪表板，基于神经生理信号估计心理负荷。

Result: 通过对120名参与者和三种可视化类型的用户研究，证明了Symbiotik方案的有效性。

Conclusion: Symbiotik系统能提高用户任务表现与参与度，提供可扩展的实时适应架构及经过验证的方法论。

Abstract: Effective decision-making often relies on timely insights from complex visual data. While Information Visualization (InfoVis) dashboards can support this process, they rarely adapt to users' cognitive state, and less so in real time. We present Symbiotik, an intelligent, context-aware adaptive visualization system that leverages neurophysiological signals to estimate mental workload (MWL) and dynamically adapt visual dashboards using reinforcement learning (RL). Through a user study with 120 participants and three visualization types, we demonstrate that our approach improves task performance and engagement. Symbiotik offers a scalable, real-time adaptation architecture, and a validated methodology for neuroadaptive user interfaces.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [8] [Attentive Feature Aggregation or: How Policies Learn to Stop Worrying about Robustness and Attend to Task-Relevant Visual Cues](https://arxiv.org/abs/2511.10762)
*Nikolaos Tsagkas,Andreas Sochopoulos,Duolikun Danier,Sethu Vijayakumar,Alexandros Kouris,Oisin Mac Aodha,Chris Xiaoxuan Lu*

Main category: cs.RO

TL;DR: 本研究提出了一种新的特征池化方法，能够提高视觉运动策略在干扰环境下的鲁棒性，证明了精简视觉信息的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有的预训练视觉表示虽然有效，但在复杂场景中易受到不相关信息的影响，导致训练策略的脆弱性，需寻找解决方案以增强策略的鲁棒性。

Method: 通过引入注意特征聚合（AFA）机制，自动聚焦于与任务相关的视觉线索，忽略场景中的干扰信息。

Result: 本研究提出了一种轻量级的可训练特征池化机制（AFA），用于提升视觉运动策略的鲁棒性，解决了传统预训练视觉表示在面对扰动场景时的脆弱性问题。

Conclusion: 我们发现，忽视无关的视觉信息是部署鲁棒且可泛化的视觉运动策略的重要步骤。

Abstract: The adoption of pre-trained visual representations (PVRs), leveraging features from large-scale vision models, has become a popular paradigm for training visuomotor policies. However, these powerful representations can encode a broad range of task-irrelevant scene information, making the resulting trained policies vulnerable to out-of-domain visual changes and distractors. In this work we address visuomotor policy feature pooling as a solution to the observed lack of robustness in perturbed scenes. We achieve this via Attentive Feature Aggregation (AFA), a lightweight, trainable pooling mechanism that learns to naturally attend to task-relevant visual cues, ignoring even semantically rich scene distractors. Through extensive experiments in both simulation and the real world, we demonstrate that policies trained with AFA significantly outperform standard pooling approaches in the presence of visual perturbations, without requiring expensive dataset augmentation or fine-tuning of the PVR. Our findings show that ignoring extraneous visual information is a crucial step towards deploying robust and generalisable visuomotor policies. Project Page: tsagkas.github.io/afa

</details>


### [9] [From Framework to Reliable Practice: End-User Perspectives on Social Robots in Public Spaces](https://arxiv.org/abs/2511.10770)
*Samson Oruma,Ricardo Colomo-Palacios,Vasileios Gkioulos*

Main category: cs.RO

TL;DR: 本研究探讨了社交机器人的伦理及用户信任，展示了在大学环境中使用社交机器人并收集反馈的经验，旨在推动更为可信和包容的社交机器人开发。


<details>
  <summary>Details</summary>
Motivation: 随着社交机器人在公共环境中的应用增加，探讨其在技术可靠性之外的伦理完整性、可接受性和用户信任的必要性。

Method: 实施了针对社交机器人在大学环境中的使用的试点部署，收集了35名师生的反馈，评估机器人的安全性、隐私、可用性、可及性和透明度。

Result: 调查结果表明，用户对机器人的物理安全、数据保护和伦理行为持积极看法，但在可及性、包容性和动态交互方面仍面临挑战。

Conclusion: 该研究通过用户评估展示了理论框架在实际环境中的实施，为社会机器人设计提供了伦理与安全性的参考，同时支持可重复性和新研究者的进入。

Abstract: As social robots increasingly enter public environments, their acceptance depends not only on technical reliability but also on ethical integrity, accessibility, and user trust. This paper reports on a pilot deployment of an ARI social robot functioning as a university receptionist, designed in alignment with the SecuRoPS framework for secure and ethical social robot deployment. Thirty-five students and staff interacted with the robot and provided structured feedback on safety, privacy, usability, accessibility, and transparency. The results show generally positive perceptions of physical safety, data protection, and ethical behavior, while also highlighting challenges related to accessibility, inclusiveness, and dynamic interaction. Beyond the empirical findings, the study demonstrates how theoretical frameworks for ethical and secure design can be implemented in real-world contexts through end-user evaluation. It also provides a public GitHub repository containing reusable templates for ARI robot applications to support reproducibility and lower the entry barrier for new researchers. By combining user perspectives with practical technical resources, this work contributes to ongoing discussions in AI and society and supports the development of trustworthy, inclusive, and ethically responsible social robots for public spaces.

</details>


### [10] [$\rm{A}^{\rm{SAR}}$: $\varepsilon$-Optimal Graph Search for Minimum Expected-Detection-Time Paths with Path Budget Constraints for Search and Rescue](https://arxiv.org/abs/2511.10792)
*Eric Mugford,Jonathan D. Gammell*

Main category: cs.RO

TL;DR: 本文提出了一种新的SAR规划算法A^SAR，能够在保证解的质量保证的同时，加速搜索过程。


<details>
  <summary>Details</summary>
Motivation: 在搜救(SAR)中，面对不确定的信息、观察者的不完美以及庞大的搜索区域，优化搜索以提升成功概率的重要性。

Method: 提出了一种名为A^SAR的ε-最优搜索算法，利用启发式方法来限制搜索空间，并应用图搜索方法找到解。

Result: A^SAR算法能快速找到更好的解决方案，且在现实场景试验中表现优异，能在150秒内定位漂浮人偶。

Conclusion: A^SAR算法在优化SAR规划方面具有显著优势，可用于更有效的搜救行动。

Abstract: Searches are conducted to find missing persons and/or objects given uncertain information, imperfect observers and large search areas in Search and Rescue (SAR). In many scenarios, such as Maritime SAR, expected survival times are short and optimal search could increase the likelihood of success. This optimization problem is complex for nontrivial problems given its probabilistic nature.
  Stochastic optimization methods search large problems by nondeterministically sampling the space to reduce the effective size of the problem. This has been used in SAR planning to search otherwise intractably large problems but the stochastic nature provides no formal guarantees on the quality of solutions found in finite time.
  This paper instead presents $\rm{A}^{\rm{SAR}}$, an $\varepsilon$-optimal search algorithm for SAR planning. It calculates a heuristic to bound the search space and uses graph-search methods to find solutions that are formally guaranteed to be within a user-specified factor, $\varepsilon$, of the optimal solution. It finds better solutions faster than existing optimization approaches in operational simulations. It is also demonstrated with a real-world field trial on Lake Ontario, Canada, where it was used to locate a drifting manikin in only 150s.

</details>


### [11] [An Investigation into Dynamically Extensible and Retractable Robotic Leg Linkages for Multi-task Execution in Search and Rescue Scenarios](https://arxiv.org/abs/2511.10816)
*William Harris,Lucas Yager,Syler Sylvester,Elizabeth Peiros,Micheal C. Yip*

Main category: cs.RO

TL;DR: 本研究提出了一种新型的可变形腿部设计，旨在提升搜索与救援机器人的地形适应能力和高力输出，实验结果显示了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的搜索和救援平台在地形适应性和高力输出方面存在不足，迫切需要一种新型设计来满足这些需求。

Method: 通过动态可扩展和可收缩的五杆链设计，实现在高度优势和力优势配置之间的机械切换。对腿部性能进行了实证和分析评估，测试了不同链几何和操作模式的表现。

Result: 实验结果表明，所提出的变形腿部设计在行程长度、力输出和稳定性方面表现出色。

Conclusion: 形变腿部设计为搜索与救援机器人提供了一种有希望的方案，使其能够快速穿越地形并有效执行救援任务。

Abstract: Search and rescue (SAR) robots are required to quickly traverse terrain and perform high-force rescue tasks, necessitating both terrain adaptability and controlled high-force output. Few platforms exist today for SAR, and fewer still have the ability to cover both tasks of terrain adaptability and high-force output when performing extraction. While legged robots offer significant ability to traverse uneven terrain, they typically are unable to incorporate mechanisms that provide variable high-force outputs, unlike traditional wheel-based drive trains. This work introduces a novel concept for a dynamically extensible and retractable robot leg. Leveraging a dynamically extensible and retractable five-bar linkage design, it allows for mechanically switching between height-advantaged and force-advantaged configurations via a geometric transformation. A testbed evaluated leg performance across linkage geometries and operating modes, with empirical and analytical analyses conducted on stride length, force output, and stability. The results demonstrate that the morphing leg offers a promising path toward SAR robots that can both navigate terrain quickly and perform rescue tasks effectively.

</details>


### [12] [MIGHTY: Hermite Spline-based Efficient Trajectory Planning](https://arxiv.org/abs/2511.10822)
*Kota Kondo,Yuwei Wu,Vijay Kumar,Jonathan P. How*

Main category: cs.RO

TL;DR: MIGHTY采用Hermite样条进行时空优化，显著加快了计算速度和减少了旅行时间。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么在空间与时间的优化上相互 decouple，要么限制搜索空间，因此需要一种新的方法来实现综合优化。

Method: MIGHTY使用基于Hermite样条的规划方法，进行时空全局优化，完全利用样条的连续搜索空间。

Result: MIGHTY是一种基于Hermite样条的轨迹规划器，能够在不降低性能的情况下实现时空优化，解决了现有软约束方法的不足之处。

Conclusion: MIGHTY在模拟中表现出色，减少了计算时间和旅行时间，并在实际硬件上有效执行高速度飞行。

Abstract: Hard-constraint trajectory planners often rely on commercial solvers and demand substantial computational resources. Existing soft-constraint methods achieve faster computation, but either (1) decouple spatial and temporal optimization or (2) restrict the search space. To overcome these limitations, we introduce MIGHTY, a Hermite spline-based planner that performs spatiotemporal optimization while fully leveraging the continuous search space of a spline. In simulation, MIGHTY achieves a 9.3% reduction in computation time and a 13.1% reduction in travel time over state-of-the-art baselines, with a 100% success rate. In hardware, MIGHTY completes multiple high-speed flights up to 6.7 m/s in a cluttered static environment and long-duration flights with dynamically added obstacles.

</details>


### [13] [Decentralized Swarm Control via SO(3) Embeddings for 3D Trajectories](https://arxiv.org/abs/2511.10858)
*Dimitria Silveria,Kleber Cabral,Peter Jardine,Sidney Givigi*

Main category: cs.RO

TL;DR: 该论文提出了一种新颖的去中心化方法，通过最少的信息共享在多智能体系统中实现涌现行为。


<details>
  <summary>Details</summary>
Motivation: 通过减少信息共享，探索多智能体系统中涌现行为的实现。

Method: 使用基于Lie群的几何嵌入，特别是Lie群SO(3)，产生稳态周期轨迹，并提出了一种新颖的相位控制器来确保智能体间均匀分离。

Result: 模拟和实验验证了该方法的有效性和适应性。

Conclusion: 此方法在复杂低级动态和干扰情况下表现出良好的适应性。

Abstract: This paper presents a novel decentralized approach for achieving emergent behavior in multi-agent systems with minimal information sharing. Based on prior work in simple orbits, our method produces a broad class of stable, periodic trajectories by stabilizing the system around a Lie group-based geometric embedding. Employing the Lie group SO(3), we generate a wider range of periodic curves than existing quaternion-based methods. Furthermore, we exploit SO(3) properties to eliminate the need for velocity inputs, allowing agents to receive only position inputs. We also propose a novel phase controller that ensures uniform agent separation, along with a formal stability proof. Validation through simulations and experiments showcases the method's adaptability to complex low-level dynamics and disturbances.

</details>


### [14] [WetExplorer: Automating Wetland Greenhouse-Gas Surveys with an Autonomous Mobile Robot](https://arxiv.org/abs/2511.10864)
*Jose Vasquez,Xuping Zhang*

Main category: cs.RO

TL;DR: WetExplorer是一种自主机器人，通过高精度传感器和深度学习技术，自动化温室气体采样，解决了手动采样的时间和劳动问题。


<details>
  <summary>Details</summary>
Motivation: 湿地中的温室气体定量对于气候建模和恢复评估至关重要，但手动采样劳动强度大且耗时。

Method: 开发了一种名为WetExplorer的自主机器人，集成了多种传感器和深度学习算法，实现了温室气体(GHG)的采样工作流程自动化。

Result: WetExplorer通过集成低地压移动、厘米级提升定位、双RTK传感器融合、障碍物规避计划和深度学习感知，成功实现了高频、多地点的温室气体测量。户外试验表明，传感器融合系统维持了平均定位误差为1.71厘米，视觉模块在物体姿态估计中实现了7毫米的平移精度和3°的旋转精度。

Conclusion: WetExplorer的开发显著提高了湿地温室气体测量的效率和准确性，为长时间、大规模的数据采集提供了可能。

Abstract: Quantifying greenhouse-gases (GHG) in wetlands is critical for climate modeling and restoration assessment, yet manual sampling is labor-intensive, and time demanding. We present WetExplorer, an autonomous tracked robot that automates the full GHG-sampling workflow. The robot system integrates low-ground-pressure locomotion, centimeter-accurate lift placement, dual-RTK sensor fusion, obstacle avoidance planning, and deep-learning perception in a containerized ROS2 stack. Outdoor trials verified that the sensor-fusion stack maintains a mean localization error of 1.71 cm, the vision module estimates object pose with 7 mm translational and 3° rotational accuracy, while indoor trials demonstrated that the full motion-planning pipeline positions the sampling chamber within a global tolerance of 70 mm while avoiding obstacles, all without human intervention. By eliminating the manual bottleneck, WetExplorer enables high-frequency, multi-site GHG measurements and opens the door for dense, long-duration datasets in saturated wetland terrain.

</details>


### [15] [Collaborative Multi-Robot Non-Prehensile Manipulation via Flow-Matching Co-Generation](https://arxiv.org/abs/2511.10874)
*Yorai Shaoul,Zhe Chen,Mohamed Naveed Gul Mohamed,Federico Pecora,Maxim Likhachev,Jiaoyang Li*

Main category: cs.RO

TL;DR: 提出一个新框架，通过流匹配共同生成和运动规划，提升多机器人在复杂环境中操控多个物体的能力。


<details>
  <summary>Details</summary>
Motivation: 解决当前方法在处理多样化物体和长时间任务时的不足，尤其是学习任务和依赖特权信息的问题。

Method: 提出一个统一框架，结合流匹配共同生成和匿名多机器人运动规划，以实现协同多机器人、多物体的非抓取操控。

Result: 在复杂的模拟环境中，提出的方法在运动规划和操控任务上超越了基线，显示出生成共同设计和综合规划的优势。

Conclusion: 该算法框架统一了机器人和物体层面的推理，为在复杂多代理、多物体设置中扩展协同操控提供了有效解决方案。

Abstract: Coordinating a team of robots to reposition multiple objects in cluttered environments requires reasoning jointly about where robots should establish contact, how to manipulate objects once contact is made, and how to navigate safely and efficiently at scale. Prior approaches typically fall into two extremes -- either learning the entire task or relying on privileged information and hand-designed planners -- both of which struggle to handle diverse objects in long-horizon tasks. To address these challenges, we present a unified framework for collaborative multi-robot, multi-object non-prehensile manipulation that integrates flow-matching co-generation with anonymous multi-robot motion planning. Within this framework, a generative model co-generates contact formations and manipulation trajectories from visual observations, while a novel motion planner conveys robots at scale. Crucially, the same planner also supports coordination at the object level, assigning manipulated objects to larger target structures and thereby unifying robot- and object-level reasoning within a single algorithmic framework. Experiments in challenging simulated environments demonstrate that our approach outperforms baselines in both motion planning and manipulation tasks, highlighting the benefits of generative co-design and integrated planning for scaling collaborative manipulation to complex multi-agent, multi-object settings. Visit gco-paper.github.io for code and demonstrations.

</details>


### [16] [Terradynamics and design of tip-extending robotic anchors](https://arxiv.org/abs/2511.10901)
*Deniz Kerimoglu,Nicholas D. Naclerio,Sean Chu,Andrew Krohn,Vineet Kupunaram,Alexander Schepelmann,Daniel I. Goldman,Elliot W. Hawkes*

Main category: cs.RO

TL;DR: 该研究调查了类根机械手的插入与提取行为，提出了设计见解，并开发了一种可部署的轻量级软体机器人锚定装置。


<details>
  <summary>Details</summary>
Motivation: 传统锚固桩在外星等难以接近的地方需要更大的驱动力，而植物根系的插入机制相比之下要求的外力较小，提供了新的设计思路。

Method: 研究根部扩展锚与传统桩式入侵者的土体动力学，并基于此开发设计见解。

Result: 新开发的机器人装置在重300克的情况下，能够以120 N的力锚定并向下插入45厘米，表现出40:1的锚定与重力比。

Conclusion: 采用根部机制设计的机器人锚定装置在重量较轻的情况下表现出卓越的锚定能力，适合在外星环境中使用。

Abstract: Most engineered pilings require substantially more force to be driven into the ground than they can resist during extraction. This requires relatively heavy equipment for insertion, which is problematic for anchoring in hard-to-access sites, including in extraterrestrial locations. In contrast, for tree roots, the external reaction force required to extract is much greater than required to insert--little more than the weight of the seed initiates insertion. This is partly due to the mechanism by which roots insert into the ground: tip extension. Proof-of-concept robotic prototypes have shown the benefits of using this mechanism, but a rigorous understanding of the underlying granular mechanics and how they inform the design of a robotic anchor is lacking. Here, we study the terradynamics of tip-extending anchors compared to traditional piling-like intruders, develop a set of design insights, and apply these to create a deployable robotic anchor. Specifically, we identify that to increase an anchor's ratio of extraction force to insertion force, it should: (i) extend beyond a critical depth; (ii) include hair-like protrusions; (iii) extend near-vertically, and (iv) incorporate multiple smaller anchors rather than a single large anchor. Synthesizing these insights, we developed a lightweight, soft robotic, root-inspired anchoring device that inserts into the ground with a reaction force less than its weight. We demonstrate that the 300 g device can deploy a series of temperature sensors 45 cm deep into loose Martian regolith simulant while anchoring with an average of 120 N, resulting in an anchoring-to-weight ratio of 40:1.

</details>


### [17] [Dexterous Manipulation Transfer via Progressive Kinematic-Dynamic Alignment](https://arxiv.org/abs/2511.10987)
*Wenbin Bai,Qiyu Chen,Xiangbo Lin,Jianwen Li,Quancheng Li,Hejiang Pan,Yi Sun*

Main category: cs.RO

TL;DR: 提出了一种手无关的操控转移系统，能够从人手操控视频中自动生成灵巧操控轨迹，克服数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 解决多指机器人手硬件平台收集操控数据的困难与数据稀缺问题，以促进数据驱动的灵巧操控策略学习研究。

Method: 设计了一个渐进转移框架，包括基于运动学匹配的主要控制信号建立、带有动作空间重新缩放的残差策略训练，以及保留操作语义的腕部控制轨迹计算。

Result: 开发了一种手无关的操控转移系统，实现了高质量的灵巧操控轨迹生成，且无需大量训练数据。

Conclusion: 实验结果显示该框架能高效生成平滑且语义正确的灵巧手操控，具有强大的通用性和可扩展性。

Abstract: The inherent difficulty and limited scalability of collecting manipulation data using multi-fingered robot hand hardware platforms have resulted in severe data scarcity, impeding research on data-driven dexterous manipulation policy learning. To address this challenge, we present a hand-agnostic manipulation transfer system. It efficiently converts human hand manipulation sequences from demonstration videos into high-quality dexterous manipulation trajectories without requirements of massive training data. To tackle the multi-dimensional disparities between human hands and dexterous hands, as well as the challenges posed by high-degree-of-freedom coordinated control of dexterous hands, we design a progressive transfer framework: first, we establish primary control signals for dexterous hands based on kinematic matching; subsequently, we train residual policies with action space rescaling and thumb-guided initialization to dynamically optimize contact interactions under unified rewards; finally, we compute wrist control trajectories with the objective of preserving operational semantics. Using only human hand manipulation videos, our system automatically configures system parameters for different tasks, balancing kinematic matching and dynamic optimization across dexterous hands, object categories, and tasks. Extensive experimental results demonstrate that our framework can automatically generate smooth and semantically correct dexterous hand manipulation that faithfully reproduces human intentions, achieving high efficiency and strong generalizability with an average transfer success rate of 73%, providing an easily implementable and scalable method for collecting robot dexterous manipulation data.

</details>


### [18] [Dynamic Reconfiguration of Robotic Swarms: Coordination and Control for Precise Shape Formation](https://arxiv.org/abs/2511.10989)
*Prab Prasertying,Paulo Garcia,Warisa Sritriratanarak*

Main category: cs.RO

TL;DR: 本论文介绍了一种新算法以提高机器人群体的运动协调性和配置转换能力，利用几何构造和物理控制技术实现更复杂的分布式行为。


<details>
  <summary>Details</summary>
Motivation: 在机器人群体的运动协调中，如何高效确定每个机器人在移动到新配置时的最优路径是一个复杂的计算问题，物理系统的内在困难进一步增加了挑战。

Method: 使用几何构造方法，结合适当的控制、定位和映射技术，确保机器人从一种配置无缝过渡到另一种配置。

Result: 本文提出了一种算法，以协调机器人群体的运动和配置，解决了从一个配置平滑过渡到另一个配置的问题。

Conclusion: 研究表明，所提出的算法能够有效协调机器人群体的运动，提高其在物理环境中的应用潜能。

Abstract: Coordination of movement and configuration in robotic swarms is a challenging endeavor. Deciding when and where each individual robot must move is a computationally complex problem. The challenge is further exacerbated by difficulties inherent to physical systems, such as measurement error and control dynamics. Thus, how to best determine the optimal path for each robot, when moving from one configuration to another, and how to best perform such determination and effect corresponding motion remains an open problem. In this paper, we show an algorithm for such coordination of robotic swarms. Our methods allow seamless transition from one configuration to another, leveraging geometric formulations that are mapped to the physical domain through appropriate control, localization, and mapping techniques. This paves the way for novel applications of robotic swarms by enabling more sophisticated distributed behaviors.

</details>


### [19] [Latent-Space Autoregressive World Model for Efficient and Robust Image-Goal Navigation](https://arxiv.org/abs/2511.11011)
*Zhiwei Zhang,Hui Zhang,Xieyuanli Chen,Kaihong Huang,Chenghao Shi,Huimin Lu*

Main category: cs.RO

TL;DR: 提出了一种轻量级潜在空间导航世界模型LS-NWM，显著提高了导航性能同时降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 传统导航方法依赖于准确的定位和映射，而世界模型通过在潜在空间中捕捉环境动态，为导航任务提供了新视角。

Method: 开发了LS-NWM，一个轻量级的潜在空间导航世界模型，完全在潜在空间中进行训练和操作。

Result: 与最先进的基线相比，我们的方法在训练时间上减少了大约3.2倍，在规划时间上减少了约447倍，同时提高了导航性能，成功实现了35%更高的SR和11%更高的SPL。

Conclusion: 实验结果表明，我们的方法在保持效率优势的同时，达到了最先进的导航性能。

Abstract: Traditional navigation methods rely heavily on accurate localization and mapping. In contrast, world models that capture environmental dynamics in latent space have opened up new perspectives for navigation tasks, enabling systems to move beyond traditional multi-module pipelines. However, world model often suffers from high computational costs in both training and inference. To address this, we propose LS-NWM - a lightweight latent space navigation world model that is trained and operates entirely in latent space, compared to the state-of-the-art baseline, our method reduces training time by approximately 3.2x and planning time by about 447x,while further improving navigation performance with a 35% higher SR and an 11% higher SPL. The key idea is that accurate pixel-wise environmental prediction is unnecessary for navigation. Instead, the model predicts future latent states based on current observational features and action inputs, then performs path planning and decision-making within this compact representation, significantly improving computational efficiency. By incorporating an autoregressive multi-frame prediction strategy during training, the model effectively captures long-term spatiotemporal dependencies, thereby enhancing navigation performance in complex scenarios. Experimental results demonstrate that our method achieves state-of-the-art navigation performance while maintaining a substantial efficiency advantage over existing approaches.

</details>


### [20] [Miniature Testbed for Validating Multi-Agent Cooperative Autonomous Driving](https://arxiv.org/abs/2511.11022)
*Hyunchul Bae,Eunjae Lee,Jehyeop Han,Minhee Kang,Jaehyeon Kim,Junggeun Seo,Minkyun Noh,Heejin Ahn*

Main category: cs.RO

TL;DR: 本研究设计了一个名为CIVAT的1:15比例微型测试平台，用于验证合作自动驾驶，解决了现有测试平台缺乏智能基础设施的缺陷。


<details>
  <summary>Details</summary>
Motivation: 现有的测试平台未采用具备感知、边缘计算和通信能力的智能基础设施，限制了合作自动驾驶的研究和发展。

Method: 设计并实施了一个包含缩放城市地图、自主车辆和智能基础设施的微型测试平台，集成了车辆与车辆(V2V)及车辆与基础设施(V2I)通信。

Result: 通过基础设施感知和交叉口管理实验，验证了CIVAT系统的有效性。

Conclusion: CIVAT平台有效实现了车辆与基础设施之间的信息交换，为合作自动驾驶提供了验证工具。

Abstract: Cooperative autonomous driving, which extends vehicle autonomy by enabling real-time collaboration between vehicles and smart roadside infrastructure, remains a challenging yet essential problem. However, none of the existing testbeds employ smart infrastructure equipped with sensing, edge computing, and communication capabilities. To address this gap, we design and implement a 1:15-scale miniature testbed, CIVAT, for validating cooperative autonomous driving, consisting of a scaled urban map, autonomous vehicles with onboard sensors, and smart infrastructure. The proposed testbed integrates V2V and V2I communication with the publish-subscribe pattern through a shared Wi-Fi and ROS2 framework, enabling information exchange between vehicles and infrastructure to realize cooperative driving functionality. As a case study, we validate the system through infrastructure-based perception and intersection management experiments.

</details>


### [21] [AdaptPNP: Integrating Prehensile and Non-Prehensile Skills for Adaptive Robotic Manipulation](https://arxiv.org/abs/2511.11052)
*Jinxuan Zhu,Chenrui Tie,Xinyi Cao,Yuran Wang,Jingxiang Guo,Zixuan Chen,Haonan Chen,Junting Chen,Yangyu Xiao,Ruihai Wu,Lin Shao*

Main category: cs.RO

TL;DR: 提出了一种结合非抓握和抓握动作的任务和运动规划框架，旨在提升机器人在多样化操作任务中的灵活性和能力。


<details>
  <summary>Details</summary>
Motivation: 探索在抓握不可行的情况下，机器人如何有效进行非抓握操作，以提升机器人的操作能力。

Method: 通过视觉语言模型生成高层次规划，以解释视觉场景和文本任务描述，结合动态的对象中心中间层和控制模块优化执行。

Result: 在仿真和真实环境中评估ApaptPNP在代表性混合任务中的表现，结果表明其在多任务处理中的有效性。

Conclusion: ApaptPNP展示了混合非抓握与抓握操作在实现普适性人类水平操控能力方面的重要潜力。

Abstract: Non-prehensile (NP) manipulation, in which robots alter object states without forming stable grasps (for example, pushing, poking, or sliding), significantly broadens robotic manipulation capabilities when grasping is infeasible or insufficient. However, enabling a unified framework that generalizes across different tasks, objects, and environments while seamlessly integrating non-prehensile and prehensile (P) actions remains challenging: robots must determine when to invoke NP skills, select the appropriate primitive for each context, and compose P and NP strategies into robust, multi-step plans. We introduce ApaptPNP, a vision-language model (VLM)-empowered task and motion planning framework that systematically selects and combines P and NP skills to accomplish diverse manipulation objectives. Our approach leverages a VLM to interpret visual scene observations and textual task descriptions, generating a high-level plan skeleton that prescribes the sequence and coordination of P and NP actions. A digital-twin based object-centric intermediate layer predicts desired object poses, enabling proactive mental rehearsal of manipulation sequences. Finally, a control module synthesizes low-level robot commands, with continuous execution feedback enabling online task plan refinement and adaptive replanning through the VLM. We evaluate ApaptPNP across representative P&NP hybrid manipulation tasks in both simulation and real-world environments. These results underscore the potential of hybrid P&NP manipulation as a crucial step toward general-purpose, human-level robotic manipulation capabilities. Project Website: https://sites.google.com/view/adaptpnp/home

</details>


### [22] [Humanoid Whole-Body Badminton via Multi-Stage Reinforcement Learning](https://arxiv.org/abs/2511.11218)
*Chenhao Liu,Leyun Jiang,Yibo Wang,Kairan Yao,Jinchen Fu,Xiaoyu Ren*

Main category: cs.RO

TL;DR: 本论文提出了一种基于强化学习的训练方法，使人形机器人能够在动态羽毛球比赛中实现精确击球，并表现出高性能和适应性。


<details>
  <summary>Details</summary>
Motivation: 人形机器人在确定性场景中的交互能力强，但在动态环境中却面临挑战，因此本研究旨在提高人形机器人在复杂环境下的交互能力。

Method: 本研究采用基于强化学习的训练管道，分为三个阶段：首先获取脚步移动，然后生成精准的挥拍动作，最后进行任务导向的优化。

Result: 实验结果表明，仿真中两个机器人能够持续进行21次击球，而在真实世界测试中，击球速度达到10米/秒，返回落点平均距离为3.5米，表明机器人的击球精确度高。

Conclusion: 该论文展示了一个训练管道，使人形机器人能够在羽毛球运动中实现动态且精确的击球目标，并可适用于更动态的领域。

Abstract: Humanoid robots have demonstrated strong capability for interacting with deterministic scenes across locomotion, manipulation, and more challenging loco-manipulation tasks. Yet the real world is dynamic, quasi-static interactions are insufficient to cope with the various environmental conditions. As a step toward more dynamic interaction scenario, we present a reinforcement-learning-based training pipeline that produces a unified whole-body controller for humanoid badminton, enabling coordinated lower-body footwork and upper-body striking without any motion priors or expert demonstrations. Training follows a three-stage curriculum: first footwork acquisition, then precision-guided racket swing generation, and finally task-focused refinement, yielding motions in which both legs and arms serve the hitting objective. For deployment, we incorporate an Extended Kalman Filter (EKF) to estimate and predict shuttlecock trajectories for target striking. We also introduce a prediction-free variant that dispenses with EKF and explicit trajectory prediction. To validate the framework, we conduct five sets of experiment in both simulation and the real world. In simulation, two robots sustain a rally of 21 consecutive hits. Moreover, the prediction-free variant achieves successful hits with comparable performance relative to the target-known policy. In real-world tests, both the prediction and controller module exhibit high accuracy, and on-court hitting achieves an outgoing shuttle speed up to 10 m/s with a mean return landing distance of 3.5 m. These experiment results show that our humanoid robot can deliver highly dynamic while precise goal striking in badminton, and can be adapted to more dynamism critical domains.

</details>


### [23] [Sashimi-Bot: Autonomous Tri-manual Advanced Manipulation and Cutting of Deformable Objects](https://arxiv.org/abs/2511.11223)
*Sverre Herland,Amit Parag,Elling Ruud Øye,Fangyi Zhang,Fouad Makiyeh,Aleksander Lillienskiold,Abhaya Pal Singh,Edward H. Adelson,Francois Chaumette,Alexandre Krupa,Peter Corke,Ekrem Misimi*

Main category: cs.RO

TL;DR: 本文介绍了Sashimi-Bot，一个自主多机器人系统，能够高效操控和切割变形的三文鱼，结合深度强化学习和多种反馈机制，代表了该领域的重大进展。


<details>
  <summary>Details</summary>
Motivation: 面对变形体积物体操控的挑战，开发一个能够高效准确处理如三文鱼 loin 等自然物体的机器人系统。

Method: 该系统结合了深度强化学习、工具形状操控、刀具切割和视觉与触觉信息反馈，以应对任务中的各种不确定性。

Result: 三台机器人能够协作完成三文鱼的整理、切割和取走薄片，表现出在处理不规则和滑腻物体上的高度鲁棒性。

Conclusion: Sashimi-Bot是一种自主多机器人系统，能够高效地操控和切割变形的体积物体，代表了机器人操作的一个重要里程碑。

Abstract: Advanced robotic manipulation of deformable, volumetric objects remains one of the greatest challenges due to their pliancy, frailness, variability, and uncertainties during interaction. Motivated by these challenges, this article introduces Sashimi-Bot, an autonomous multi-robotic system for advanced manipulation and cutting, specifically the preparation of sashimi. The objects that we manipulate, salmon loins, are natural in origin and vary in size and shape, they are limp and deformable with poorly characterized elastoplastic parameters, while also being slippery and hard to hold. The three robots straighten the loin; grasp and hold the knife; cut with the knife in a slicing motion while cooperatively stabilizing the loin during cutting; and pick up the thin slices from the cutting board or knife blade. Our system combines deep reinforcement learning with in-hand tool shape manipulation, in-hand tool cutting, and feedback of visual and tactile information to achieve robustness to the variabilities inherent in this task. This work represents a milestone in robotic manipulation of deformable, volumetric objects that may inspire and enable a wide range of other real-world applications.

</details>


### [24] [Experiences from Benchmarking Vision-Language-Action Models for Robotic Manipulation](https://arxiv.org/abs/2511.11298)
*Yihao Zhang,Yuankai Qi,Xi Zheng*

Main category: cs.RO

TL;DR: 本论文评估了多种VLA模型在现实机器人操作中的表现，提供了一套标准化评估框架，并揭示了不同模型在适应性、稳定性和计算需求方面的差异，强调了在选择和部署VLA时的实用权衡。


<details>
  <summary>Details</summary>
Motivation: 推动VLA模型在机器人中的实际应用，评估不同模型的表现及其在实际操作中的适用性和可靠性。

Method: 建立了一套标准化的评估框架，从准确性和效率、适应性以及语言指令跟随准确性三个维度进行评测。

Result: 本研究对四种代表性视觉-语言-动作（VLA）模型进行了基准测试，包括ACT、OpenVLA-OFT、RDT-1B和π0，针对四个操作任务进行了系统评估。

Conclusion: 研究发现，模型π0在不在分布场景中表现出优越的适应性，而ACT在分布场景中提供最高的稳定性，强调了在选择和部署VLA模型时的权衡与实用指导。

Abstract: Foundation models applied in robotics, particularly \textbf{Vision--Language--Action (VLA)} models, hold great promise for achieving general-purpose manipulation. Yet, systematic real-world evaluations and cross-model comparisons remain scarce. This paper reports our \textbf{empirical experiences} from benchmarking four representative VLAs -- \textbf{ACT}, \textbf{OpenVLA--OFT}, \textbf{RDT-1B}, and \boldmath{$π_0$} -- across four manipulation tasks conducted in both simulation and on the \textbf{ALOHA Mobile} platform. We establish a \textbf{standardized evaluation framework} that measures performance along three key dimensions: (1) \textit{accuracy and efficiency} (success rate and time-to-success), (2) \textit{adaptability} across in-distribution, spatial out-of-distribution, and instance-plus-spatial out-of-distribution settings, and (3) \textit{language instruction-following accuracy}. Through this process, we observe that \boldmath{$π_0$} demonstrates superior adaptability in out-of-distribution scenarios, while \textbf{ACT} provides the highest stability in-distribution. Further analysis highlights differences in computational demands, data-scaling behavior, and recurring failure modes such as near-miss grasps, premature releases, and long-horizon state drift. These findings reveal practical trade-offs among VLA model architectures in balancing precision, generalization, and deployment cost, offering actionable insights for selecting and deploying VLAs in real-world robotic manipulation tasks.

</details>


### [25] [Simulating an Autonomous System in CARLA using ROS 2](https://arxiv.org/abs/2511.11310)
*Joseph Abdo,Aditya Shibu,Moaiz Saeed,Abdul Maajid Aga,Apsara Sivaprazad,Mohamed Al-Musleh*

Main category: cs.RO

TL;DR: 本文提出了一种自主赛车的软件堆栈设计方法，通过采集和处理多种传感器数据，成功验证了竞争驾驶性能，并移植至真实硬件。


<details>
  <summary>Details</summary>
Motivation: 自主赛车提供了一个测试感知、规划和控制的严格环境，具有高速度和不确定性的特征，为提升竞争驾驶性能提供了机会。

Method: 利用ROS 2实现一个完整的自主系统堆栈，使用LiDAR、立体相机、GNSS和IMU传感器进行数据采集和处理。

Result: 该系统能够在35米的距离内可靠检测赛道边界的圆锥，并优化车辆轨迹以高效穿越赛道。

Conclusion: 该研究成功设计并评估了一个适用于自主赛车的软件堆栈，经过大量验证后将其移植到实际硬件上。

Abstract: Autonomous racing offers a rigorous setting to stress test perception, planning, and control under high speed and uncertainty. This paper proposes an approach to design and evaluate a software stack for an autonomous race car in CARLA: Car Learning to Act simulator, targeting competitive driving performance in the Formula Student UK Driverless (FS-AI) 2025 competition. By utilizing a 360° light detection and ranging (LiDAR), stereo camera, global navigation satellite system (GNSS), and inertial measurement unit (IMU) sensor via ROS 2 (Robot Operating System), the system reliably detects the cones marking the track boundaries at distances of up to 35 m. Optimized trajectories are computed considering vehicle dynamics and simulated environmental factors such as visibility and lighting to navigate the track efficiently. The complete autonomous stack is implemented in ROS 2 and validated extensively in CARLA on a dedicated vehicle (ADS-DV) before being ported to the actual hardware, which includes the Jetson AGX Orin 64GB, ZED2i Stereo Camera, Robosense Helios 16P LiDAR, and CHCNAV Inertial Navigation System (INS).

</details>


### [26] [SimTac: A Physics-Based Simulator for Vision-Based Tactile Sensing with Biomorphic Structures](https://arxiv.org/abs/2511.11456)
*Xuyang Zhang,Jiaqi Jiang,Zhuo Chen,Yongqiang Zhao,Tianqi Yang,Daniel Fernandes Gomes,Jianan Wang,Shan Luo*

Main category: cs.RO

TL;DR: SimTac是一个新颖的物理模拟框架，用于设计和验证生物形态触觉传感器，具有多样的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 生物体中的触觉感知与形态形式密切相关，而现有的机器人视觉触觉传感器仅限于简单的平面几何形状，缺乏生物形态设计的探索。

Method: SimTac包含粒子基的形变建模、光场渲染用于生成逼真的触觉图像，以及预测机械响应的神经网络，支持对多种几何和材料的准确高效模拟。

Result: 提出了SimTac，一个基于物理的模拟框架，用于生物形态触觉传感器的设计和验证，展示了其在多种几何形状和材料下的有效性，能够设计出灵感来自生物触觉结构的传感器原型，并在多个Sim2Real任务中有效应用。

Conclusion: SimTac桥接了仿生设计与实际实现之间的鸿沟，拓展了触觉传感器的设计空间，为在非结构化环境中实现坚固的交互奠定了基础。

Abstract: Tactile sensing in biological organisms is deeply intertwined with morphological form, such as human fingers, cat paws, and elephant trunks, which enables rich and adaptive interactions through a variety of geometrically complex structures. In contrast, vision-based tactile sensors in robotics have been limited to simple planar geometries, with biomorphic designs remaining underexplored. To address this gap, we present SimTac, a physics-based simulation framework for the design and validation of biomorphic tactile sensors. SimTac consists of particle-based deformation modeling, light-field rendering for photorealistic tactile image generation, and a neural network for predicting mechanical responses, enabling accurate and efficient simulation across a wide range of geometries and materials. We demonstrate the versatility of SimTac by designing and validating physical sensor prototypes inspired by biological tactile structures and further demonstrate its effectiveness across multiple Sim2Real tactile tasks, including object classification, slip detection, and contact safety assessment. Our framework bridges the gap between bio-inspired design and practical realisation, expanding the design space of tactile sensors and paving the way for tactile sensing systems that integrate morphology and sensing to enable robust interaction in unstructured environments.

</details>


### [27] [Rethinking Progression of Memory State in Robotic Manipulation: An Object-Centric Perspective](https://arxiv.org/abs/2511.11478)
*Nhat Chung,Taisei Hanyu,Toan Nguyen,Huy Le,Frederick Bumgarner,Duy Minh Ho Nguyen,Khoa Vo,Kashu Yamazaki,Chase Rainwater,Tung Kieu,Anh Nguyen,Ngan Le*

Main category: cs.RO

TL;DR: LIBERO-Mem是一个非马尔可夫任务套件，挑战机器人在对象级部分可观测性下的操作，Embodied-SlotSSM提供了一种可扩展的解决方案。


<details>
  <summary>Details</summary>
Motivation: 在复杂环境中，机器人需要识别、跟踪并推理各个对象实例，特别是在需要顺序交互的任务中。

Method: 提出了以插槽为中心的视觉-语言-动作框架（Embodied-SlotSSM），用于时间可扩展性，结合了插槽状态空间建模和关系编码器。

Result: Embodied-SlotSSM能够实现时域基础、上下文感知的动作预测，并在机器人操作的非马尔可夫任务中展现出良好的基准表现。

Conclusion: Embodied-SlotSSM在LIBERO-Mem和其他一般任务上的基准表现显示出其在对象中心机器人策略中非马尔可夫推理的可扩展性解决方案。

Abstract: As embodied agents operate in increasingly complex environments, the ability to perceive, track, and reason about individual object instances over time becomes essential, especially in tasks requiring sequenced interactions with visually similar objects. In these non-Markovian settings, key decision cues are often hidden in object-specific histories rather than the current scene. Without persistent memory of prior interactions (what has been interacted with, where it has been, or how it has changed) visuomotor policies may fail, repeat past actions, or overlook completed ones. To surface this challenge, we introduce LIBERO-Mem, a non-Markovian task suite for stress-testing robotic manipulation under object-level partial observability. It combines short- and long-horizon object tracking with temporally sequenced subgoals, requiring reasoning beyond the current frame. However, vision-language-action (VLA) models often struggle in such settings, with token scaling quickly becoming intractable even for tasks spanning just a few hundred frames. We propose Embodied-SlotSSM, a slot-centric VLA framework built for temporal scalability. It maintains spatio-temporally consistent slot identities and leverages them through two mechanisms: (1) slot-state-space modeling for reconstructing short-term history, and (2) a relational encoder to align the input tokens with action decoding. Together, these components enable temporally grounded, context-aware action prediction. Experiments show Embodied-SlotSSM's baseline performance on LIBERO-Mem and general tasks, offering a scalable solution for non-Markovian reasoning in object-centric robotic policies.

</details>


### [28] [A Comparative Evaluation of Prominent Methods in Autonomous Vehicle Certification](https://arxiv.org/abs/2511.11484)
*Mustafa Erdem Kırmızıgül,Hasan Feyzi Doğruyol,Haluk Bayram*

Main category: cs.RO

TL;DR: 本文探讨了瑞典实施的“零死亡”政策下，自主驾驶汽车的认证过程及其主要方法的比较评估。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在填补自主驾驶汽车安全性验证和认证方法上的空白，以支持“零死亡”政策的目标。

Method: 通过比较评估计划用于自主驾驶汽车认证过程的主要方法，构建了认证流程的管道。

Result: 为自主驾驶汽车的认证过程提供了明确的流程和方法应用场景。

Conclusion: 研究提出了一套自主驾驶汽车的认证流程，包括各个阶段和相关方法的应用。

Abstract: The "Vision Zero" policy, introduced by the Swedish Parliament in 1997, aims to eliminate fatalities and serious injuries resulting from traffic accidents. To achieve this goal, the use of self-driving vehicles in traffic is envisioned and a roadmap for the certification of self-driving vehicles is aimed to be determined. However, it is still unclear how the basic safety requirements that autonomous vehicles must meet will be verified and certified, and which methods will be used. This paper focuses on the comparative evaluation of the prominent methods planned to be used in the certification process of autonomous vehicles. It examines the prominent methods used in the certification process, develops a pipeline for the certification process of autonomous vehicles, and determines the stages, actors, and areas where the addressed methods can be applied.

</details>


### [29] [Collaborative Representation Learning for Alignment of Tactile, Language, and Vision Modalities](https://arxiv.org/abs/2511.11512)
*Yiyun Zhou,Mingjing Xu,Jingwei Shi,Quanjiang Li,Jingyuan Chen*

Main category: cs.RO

TL;DR: TLV-CoRe是一种新颖的多模态触觉表示学习方法，通过统一触觉特征和增强模态间互动，提升了跨模态学习效果。


<details>
  <summary>Details</summary>
Motivation: 现有触觉传感器缺乏标准化，导致冗余特征阻碍跨传感器泛化，同时现有方法未能充分整合触觉、语言和视觉模态之间的中间交流。

Method: TLV-CoRe是一种基于CLIP的触觉-语言-视觉协同表示学习方法，引入传感器感知调制器和统一桥接适配器来增强三模态交互。

Result: 通过引入传感器感知调制器和分离无关触觉特征的学习，TLV-CoRe有效地统一了不同传感器的触觉特征，并通过RSS评估框架评估模型效果。

Conclusion: TLV-CoRe显著提高了传感器无关的表示学习和跨模态对齐，开启了多模态触觉表示的新方向。

Abstract: Tactile sensing offers rich and complementary information to vision and language, enabling robots to perceive fine-grained object properties. However, existing tactile sensors lack standardization, leading to redundant features that hinder cross-sensor generalization. Moreover, existing methods fail to fully integrate the intermediate communication among tactile, language, and vision modalities. To address this, we propose TLV-CoRe, a CLIP-based Tactile-Language-Vision Collaborative Representation learning method. TLV-CoRe introduces a Sensor-Aware Modulator to unify tactile features across different sensors and employs tactile-irrelevant decoupled learning to disentangle irrelevant tactile features. Additionally, a Unified Bridging Adapter is introduced to enhance tri-modal interaction within the shared representation space. To fairly evaluate the effectiveness of tactile models, we further propose the RSS evaluation framework, focusing on Robustness, Synergy, and Stability across different methods. Experimental results demonstrate that TLV-CoRe significantly improves sensor-agnostic representation learning and cross-modal alignment, offering a new direction for multimodal tactile representation.

</details>


### [30] [Scalable Coverage Trajectory Synthesis on GPUs as Statistical Inference](https://arxiv.org/abs/2511.11514)
*Max M. Sun,Jueun Kwon,Todd Murphey*

Main category: cs.RO

TL;DR: 本研究提出了一种新的基于流匹配的覆盖运动规划方法，显著提升了计算效率和可扩展性，解决了传统方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 应对传统运动规划方法在处理覆盖运动规划时的计算效率低和不易并行化的问题。

Method: 将覆盖运动规划问题构建为统计推断问题，运用流匹配流行的生成建模技术。

Result: 提出的方法通过解耦轨迹梯度生成和控制合成，实现显著加速，特别适用于GPU架构。

Conclusion: 这种基于统计推断的覆盖运动规划方法显示出在可扩展性和计算效率方面的明显优势，特别是在使用现代计算架构时。

Abstract: Coverage motion planning is essential to a wide range of robotic tasks. Unlike conventional motion planning problems, which reason over temporal sequences of states, coverage motion planning requires reasoning over the spatial distribution of entire trajectories, making standard motion planning methods limited in computational efficiency and less amenable to modern parallelization frameworks. In this work, we formulate the coverage motion planning problem as a statistical inference problem from the perspective of flow matching, a generative modeling technique that has gained significant attention in recent years. The proposed formulation unifies commonly used statistical discrepancy measures, such as Kullback-Leibler divergence and Sinkhorn divergence, with a standard linear quadratic regulator problem. More importantly, it decouples the generation of trajectory gradients for coverage from the synthesis of control under nonlinear system dynamics, enabling significant acceleration through parallelization on modern computational architectures, particularly Graphics Processing Units (GPUs). This paper focuses on the advantages of this formulation in terms of scalability through parallelization, highlighting its computational benefits compared to conventional methods based on waypoint tracking.

</details>


### [31] [Scalable Policy Evaluation with Video World Models](https://arxiv.org/abs/2511.11520)
*Wei-Cheng Tseng,Jinwei Gu,Qinsheng Zhang,Hanzi Mao,Ming-Yu Liu,Florian Shkurti,Lin Yen-Chen*

Main category: cs.RO

TL;DR: 该论文提出使用动作条件的视频生成模型为机器人操作策略评估学习世界模型，从而避免现实世界测试的高成本和风险。


<details>
  <summary>Details</summary>
Motivation: 训练通用策略以进行机器人操作具有巨大潜力，但其评估困难，原因在于现实世界测试成本高、耗时且人工密集，同时还存在安全风险。

Method: 论文探讨了如何将动作条件集成到现有的预训练视频生成模型中，利用互联网规模的在线视频进行预训练，以降低收集数据的成本。

Result: 研究表明，利用基于动作条件的视频生成模型可以有效学习用于策略评估的世界模型，降低对现实世界交互的需求。

Conclusion: 通过各种指标的实验结果表明，所提方法在策略排名及实际政策值与预测政策值之间的相关性上，有助于评估策略，而无需现实世界的互动。

Abstract: Training generalist policies for robotic manipulation has shown great promise, as they enable language-conditioned, multi-task behaviors across diverse scenarios. However, evaluating these policies remains difficult because real-world testing is expensive, time-consuming, and labor-intensive. It also requires frequent environment resets and carries safety risks when deploying unproven policies on physical robots. Manually creating and populating simulation environments with assets for robotic manipulation has not addressed these issues, primarily due to the significant engineering effort required and the often substantial sim-to-real gap, both in terms of physics and rendering. In this paper, we explore the use of action-conditional video generation models as a scalable way to learn world models for policy evaluation. We demonstrate how to incorporate action conditioning into existing pre-trained video generation models. This allows leveraging internet-scale in-the-wild online videos during the pre-training stage, and alleviates the need for a large dataset of paired video-action data, which is expensive to collect for robotic manipulation. Our paper examines the effect of dataset diversity, pre-trained weight and common failure cases for the proposed evaluation pipeline.Our experiments demonstrate that, across various metrics, including policy ranking and the correlation between actual policy values and predicted policy values, these models offer a promising approach for evaluating policies without requiring real-world interactions.

</details>


### [32] [Terrain Costmap Generation via Scaled Preference Conditioning](https://arxiv.org/abs/2511.11529)
*Luisa Mao,Garret Warnell,Peter Stone,Joydeep Biswas*

Main category: cs.RO

TL;DR: SPACER是一种新的地形成本图生成方法，能在新地形中良好泛化，允许快速适应相对成本，测试表明其表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在越野领域的自主机器人导航中，需要生成高质量的地形成本图，这些成本图不仅要能广泛地适应多种地形，还要能在测试时根据特定任务需求迅速调整相对成本。

Method: 提出了一种名为SPACER的方法，通过利用合成数据进行训练，以更好地生成适应新地形的成本图，同时允许在测试时快速适应相对成本。

Result: SPACER方法在生成地形导航成本图方面优于其他方法，在七个环境中五个环境中对于全局路径规划测得的遗憾值最低。

Conclusion: SPACER利用合成数据和用户指定的偏好上下文，成功生成高质量的成本图，证明了在复杂地形导航中的有效性。

Abstract: Successful autonomous robot navigation in off-road domains requires the ability to generate high-quality terrain costmaps that are able to both generalize well over a wide variety of terrains and rapidly adapt relative costs at test time to meet mission-specific needs. Existing approaches for costmap generation allow for either rapid test-time adaptation of relative costs (e.g., semantic segmentation methods) or generalization to new terrain types (e.g., representation learning methods), but not both. In this work, we present scaled preference conditioned all-terrain costmap generation (SPACER), a novel approach for generating terrain costmaps that leverages synthetic data during training in order to generalize well to new terrains, and allows for rapid test-time adaptation of relative costs by conditioning on a user-specified scaled preference context. Using large-scale aerial maps, we provide empirical evidence that SPACER outperforms other approaches at generating costmaps for terrain navigation, with the lowest measured regret across varied preferences in five of seven environments for global path planning.

</details>


### [33] [Volumetric Ergodic Control](https://arxiv.org/abs/2511.11533)
*Jueun Kwon,Max M. Sun,Todd Murphey*

Main category: cs.RO

TL;DR: 提出了一种新的有利于非线性系统的体积状态表示的遍历控制方法，优化空间覆盖，显著提高覆盖效率。


<details>
  <summary>Details</summary>
Motivation: 解决现有遍历控制方法中，机器人被简化为无体积点而无法反映实际物理交互的问题。

Method: 引入基于体积状态表示的遍历控制，其计算开销最小，并支持任意样本基础的体积模型。

Result: 在搜索和操作任务中，新方法显著提高覆盖效率，并在机械擦除任务中成功应用。

Conclusion: 新方法在多任务实验中展现出超过两倍的覆盖效率提升，并保持100%的任务完成率，优于传统的遍历控制方法。

Abstract: Ergodic control synthesizes optimal coverage behaviors over spatial distributions for nonlinear systems. However, existing formulations model the robot as a non-volumetric point, but in practice a robot interacts with the environment through its body and sensors with physical volume. In this work, we introduce a new ergodic control formulation that optimizes spatial coverage using a volumetric state representation. Our method preserves the asymptotic coverage guarantees of ergodic control, adds minimal computational overhead for real-time control, and supports arbitrary sample-based volumetric models. We evaluate our method across search and manipulation tasks -- with multiple robot dynamics and end-effector geometries or sensor models -- and show that it improves coverage efficiency by more than a factor of two while maintaining a 100% task completion rate across all experiments, outperforming the standard ergodic control method. Finally, we demonstrate the effectiveness of our method on a robot arm performing mechanical erasing tasks.

</details>
