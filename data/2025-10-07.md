<div id=toc></div>

# Table of Contents

- [cs.HC](#cs.HC) [Total: 19]
- [cs.RO](#cs.RO) [Total: 55]


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [1] [Immersive Mixed Reality Simulator for CT Scan Preparation: Enhancing Patient Emotional and Physical Readiness](https://arxiv.org/abs/2510.03526)
*Alex Smith,Priya Patel,Hu Guo,Marco Ruiz*

Main category: cs.HC

TL;DR: 通过使用混合现实模拟器，首次CT扫描患者的预扫描焦虑降低，符合度提高。


<details>
  <summary>Details</summary>
Motivation: 首次进行CT扫描的患者常常感到焦虑和不确定，影响扫描结果和患者福祉。

Method: 开发了一种沉浸式混合现实模拟器，结合虚拟CT扫描室演练、引导放松训练、真实扫描模拟及互动反馈。

Result: 一项小型研究显示，使用模拟器的患者在扫描前焦虑显著降低，并在实际CT过程中符合度提高。

Conclusion: 这样的工具有助于改善患者中心护理，但在临床应用中存在整合挑战，未来需探讨进一步提升患者体验的方向。

Abstract: First-time patients undergoing diagnostic computed tomography (CT) scans
often experience significant anxiety and uncertainty, which can negatively
impact scan results and patient well-being. We present an immersive mixed
reality (MR) simulator designed to prepare adult patients for their first CT
scan, aiming to improve both emotional and physical preparedness. In this
paper, we review existing methods for reducing scan-related anxiety -- from
educational materials to virtual reality exposure -- and identify their
limitations. We then detail the design and technical implementation of our MR
simulator, which combines a virtual CT suite walkthrough, guided relaxation
training, realistic scan simulation (including audiovisual cues and breath-hold
practice), and interactive feedback. The inclusion of these features is
grounded in evidence-based rationale drawn from prior studies in patient
anxiety reduction and compliance. We report results from a pilot study ($n=50$)
demonstrating that patients who used the simulator had significantly lower
pre-scan anxiety levels and improved compliance during the actual CT procedure,
compared to controls. Patient feedback was overwhelmingly positive, indicating
high satisfaction and perceived utility. We discuss the clinical implications
of deploying such a tool, challenges in integration, and future directions for
improving patient-centered care using mixed reality technologies.

</details>


### [2] [Mixed Reality Guidance of a Surgical Scalpel Using Magic Leap: Evaluation on a 3D-Printed Liver Phantom](https://arxiv.org/abs/2510.03617)
*Alice Yang,Michael Beasley,Catherine Taylor,Hu Guo*

Main category: cs.HC

TL;DR: 本研究展示了一种利用Magic Leap进行肝脏手术的混合现实指导系统，结果表明这种系统能显著提高外科手术的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 探索增强和混合现实系统在外科手术中通过提供数字化指导，从而提高手术精度的潜力。

Method: 使用Magic Leap头戴显示器进行的混合现实指导系统，结合术前建模和虚拟内容的实时可视化。

Result: MR指导使切割准确性从5.0毫米提高到2.0毫米，任务时间从55秒减少到32秒，准确性提高约60%，速度提高约40%。

Conclusion: Magic Leap-based MR指导显著提高外科手术的切割准确性和效率，为肝脏手术的安全与精确性铺平了道路。

Abstract: Augmented and mixed reality (MR) systems have the potential to improve
surgical precision by overlaying digital guidance directly onto the operative
field. This paper presents a novel MR guidance system using the Magic Leap
head-mounted display to assist surgeons in executing precise scalpel movements
during liver surgery. The system projects holographic cues onto a
patient-specific 3D-printed liver phantom, guiding resection along a
predetermined path. We describe the system design, including preoperative
modeling, registration of virtual content to the phantom, and real-time
visualization through the Magic Leap device. In a controlled phantom study,
surgical trainees performed resection tasks with and without MR guidance.
Quantitative results demonstrated that MR guidance improved cutting accuracy
(mean deviation from planned path was reduced from 5.0 mm without AR to 2.0 mm
with AR guidance) and efficiency (mean task time decreased from 55 s to 32 s).
These improvements of approximately 60% in accuracy and 40% in speed underscore
the potential benefit of MR in surgical navigation. Participants reported that
the Magic Leap visualization enhanced depth perception and confidence in
locating tumor boundaries. This work provides a comprehensive evaluation of an
MR-assisted surgical guidance approach, highlighting its feasibility on a
realistic organ phantom. We discuss the technical challenges (registration
accuracy, line-of-sight, user ergonomics) and outline future steps toward
clinical translation. The results suggest that Magic Leap-based MR guidance can
significantly augment a surgeon's performance in delicate resection tasks,
paving the way for safer and more precise liver surgery.

</details>


### [3] [Invisible Saboteurs: Sycophantic LLMs Mislead Novices in Problem-Solving Tasks](https://arxiv.org/abs/2510.03667)
*Jessica Y. Bo,Majeed Kazemitabaar,Mengqing Deng,Michael Inzlicht,Ashton Anderson*

Main category: cs.HC

TL;DR: 高谄媚性聊天机器人会削弱用户的理解能力和判断力，导致他们无法有效纠正误解。


<details>
  <summary>Details</summary>
Motivation: 随着LLM聊天机器人的出现，谄媚性已成为人机交互中一个重要的风险，尤其是在复杂问题解决任务中。

Method: 通过创建高谄媚性和低谄媚性的两个LLM聊天机器人，并进行了一项以用户为主体的实验（n=24），研究它们对用户心理模型、工作流程、依赖行为和对聊天机器人的感知的影响。

Result: 结果显示，高谄媚性聊天机器人的用户更不容易纠正他们的误解，并倾向于过度依赖无用的LLM响应。

Conclusion: 高谄媚性的聊天机器人会导致用户更难纠正误解，并过度依赖无帮助的LLM响应，而大多数用户无法察觉这种谄媚性。

Abstract: Sycophancy, the tendency of LLM-based chatbots to express excessive
enthusiasm, agreement, flattery, and a lack of disagreement, is emerging as a
significant risk in human-AI interactions. However, the extent to which this
affects human-LLM collaboration in complex problem-solving tasks is not well
quantified, especially among novices who are prone to misconceptions. We
created two LLM chatbots, one with high sycophancy and one with low sycophancy,
and conducted a within-subjects experiment (n=24) in the context of debugging
machine learning models to isolate the effect of LLM sycophancy on users'
mental models, their workflows, reliance behaviors, and their perceptions of
the chatbots. Our findings show that users of the high sycophancy chatbot were
less likely to correct their misconceptions and spent more time over-relying on
unhelpful LLM responses. Despite these impaired outcomes, a majority of users
were unable to detect the presence of excessive sycophancy.

</details>


### [4] [Bridging the Gap: Enhancing Gaze-Performance Link in Children with ASD through Dual-Level Visual Guidance in MR-DMT](https://arxiv.org/abs/2510.03724)
*Weiying Liu,Yanran Yuan,Zhiqiang Sheng,Dandan Lian,Sheng Li,Yufan Zhang,Yulong Bian,Juan Liu*

Main category: cs.HC

TL;DR: 本研究提出了一种新颖的双层视觉引导系统，使自闭症儿童在混合现实舞蹈运动治疗中的表现得到提升。


<details>
  <summary>Details</summary>
Motivation: 改善自闭症谱系障碍（ASD）儿童的模仿学习能力和视动整合能力

Method: 通过实验验证并提出双层视觉引导系统

Result: 提出的视觉引导系统有效提升了注视与表现之间的关系

Conclusion: 该研究为更精准的自闭症多动疗法干预奠定了基础，表明需要优化注视与表现之间的关系。

Abstract: Autism Spectrum Disorder (ASD) is marked by action imitation deficits
stemming from visuomotor integration impairments, posing challenges to
imitation-based learning, such as dance movement therapy in mixed reality
(MR-DMT). Previous gaze-guiding interventions in ASD have mainly focused on
optimizing gaze in isolation, neglecting the crucial "gaze-performance link".
This study investigates enhancing this link in MR-DMT for children with ASD.
Initially, we experimentally confirmed the weak link: longer gaze durations
didn't translate to better performance. Then, we proposed and validated a novel
dual-level visual guidance system that operates on both perceptual and
transformational levels: not only directing attention to task-relevant areas
but also explicitly scaffolding the translation from gaze perception to
performance execution. Our results demonstrate its effectiveness in boosting
the gaze-performance link, laying key foundations for more precisely tailored
and effective MR-DMT interventions for ASD.

</details>


### [5] [Teaching with AI: A Systematic Review of Chatbots, Generative Tools, and Tutoring Systems in Programming Education](https://arxiv.org/abs/2510.03884)
*Said Elnaffar,Farzad Rashidi,Abedallah Zaid Abualkishik*

Main category: cs.HC

TL;DR: 综述研究了AI在编程教育中的应用，分析其对学习成果的影响，并识别了相关优势和挑战，呼吁建立教学框架以促进AI的有效整合。


<details>
  <summary>Details</summary>
Motivation: 探讨AI代理在编程教育中的整合及其对学生学习的影响，旨在提供数据支持以指导教育实践。

Method: 对2022年至2025年间58篇同行评审研究的分析，识别AI代理的类别及其在编程教育中的效果。

Result: 本综述研究了人工智能（AI）代理在编程教育中的作用，强调这些工具如何整合到教育实践中及其对学生学习成果的影响。分析了2022年至2025年间发表的58篇同行评审研究，识别出三种主要的AI代理类别：聊天机器人、生成性人工智能（GenAI）和智能辅导系统（ITS），其中GenAI的研究最为广泛。主要教学目标包括增强编程支持（94.83%）、提升动机和情感福利（18.96%）、以及提高教育工作者的效率（6.90%）。报告的好处包括个性化反馈、改善学习成果和节省时间。综述还凸显了一些挑战，例如93.10%的研究记录了设置障碍，65.52%过度依赖导致表面学习，及对于AI错误和学术诚信的担忧。这些发现表明，迫切需要优先开发提示工程技能和人类监督的教学框架，以解决这些问题。本综述为教育工作者和课程设计者提供了将AI在编程教育中进行实际和伦理整合的循证基础。

Conclusion: 本综述为AI在编程教育的实用和伦理整合提供了循证基础，并呼吁教育者重视人机协作，提升教学效果。

Abstract: This review examines the role of artificial intelligence (AI) agents in
programming education, focusing on how these tools are being integrated into
educational practice and their impact on student learning outcomes. An analysis
of fifty-eight peer-reviewed studies published between 2022 and 2025 identified
three primary categories of AI agents: chatbots, generative AI (GenAI), and
intelligent tutoring systems (ITS), with GenAI being the most frequently
studied. The primary instructional objectives reported include enhanced
programming support in 94.83% of studies, motivational and emotional benefits
in 18.96%, and increased efficiency for educators in 6.90%. Reported benefits
include personalized feedback, improved learning outcomes, and time savings.
The review also highlights challenges, such as setup barriers documented in
93.10% of studies, overreliance resulting in superficial learning in 65.52%,
and concerns regarding AI errors and academic integrity. These findings suggest
the need for instructional frameworks that prioritize the development of prompt
engineering skills and human oversight to address these issues. This review
provides educators and curriculum designers with an evidence-based foundation
for the practical and ethical integration of AI in programming education.

</details>


### [6] [AI-Driven Grading and Moderation for Collaborative Projects in Computer Science Education](https://arxiv.org/abs/2510.03998)
*Songmei Yu,Andrew Zagula*

Main category: cs.HC

TL;DR: 本文提出了一种半自动化的AI评分系统，旨在改进计算机科学教育中的团队项目评估，证实系统有效性并讨论实施建议。


<details>
  <summary>Details</summary>
Motivation: 在计算机科学教育中，传统的团队项目评估方式存在公平性、客观性和可扩展性方面的不足，因此需要一种新的评估方法。

Method: 利用代码库挖掘、沟通分析和机器学习模型组成的评分系统，包含项目评估、贡献分析和成绩计算模块。

Result: 在高级课程中的试点部署显示，该系统与教师评估高一致性，提升了学生满意度，减少了教师评分工作量。

Conclusion: 本文提出的半自动化AI辅助评分系统在评估项目质量和个人贡献方面取得了显著效果，并强调实现时的伦理考虑和未来扩展的建议。

Abstract: Collaborative group projects are integral to computer science education, as
they foster teamwork, problem-solving skills, and industry-relevant
competencies. However, assessing individual contributions within group settings
has long been a challenge. Traditional assessment strategies, such as the equal
distribution of grades or subjective peer assessments, often fall short in
terms of fairness, objectivity, and scalability, particularly in large
classrooms. This paper introduces a semi-automated, AI-assisted grading system
that evaluates both project quality and individual effort using repository
mining, communication analytics, and machine learning models. The system
comprises modules for project evaluation, contribution analysis, and grade
computation, integrating seamlessly with platforms like GitHub. A pilot
deployment in a senior-level course demonstrated high alignment with instructor
assessments, increased student satisfaction, and reduced instructor grading
effort. We conclude by discussing implementation considerations, ethical
implications, and proposed enhancements to broaden applicability.

</details>


### [7] [Wrist2Finger: Sensing Fingertip Force for Force-Aware Hand Interaction with a Ring-Watch Wearable](https://arxiv.org/abs/2510.04122)
*Yingjing Xiao,Zhichao Huang,Junbin Ren,Haichuan Song,Yang Gao,Yuting Bai,Zhanpeng Jin*

Main category: cs.HC

TL;DR: 提出了一种新型便携手势追踪系统，结合IMU和EMG数据，实现3D手势重建和手指力量估计。


<details>
  <summary>Details</summary>
Motivation: 为了解决当前视觉和可穿戴设备在便携性和实用性方面的局限性。

Method: 使用双支路变换器网络融合IMU与EMG数据，开发自定义损失函数实现顺畅的力量变化与实际力量饱和度。

Result: 通过20位参与者的评估，手指关节位置误差平均为0.57 cm，指尖力量估计均方根误差为0.213，相关性r为0.76。

Conclusion: 该系统在虚拟现实/增强现实和辅助假肢等领域具有广泛应用前景。

Abstract: Hand pose tracking is essential for advancing applications in human-computer
interaction. Current approaches, such as vision-based systems and wearable
devices, face limitations in portability, usability, and practicality. We
present a novel wearable system that reconstructs 3D hand pose and estimates
per-finger forces using a minimal ring-watch sensor setup. A ring worn on the
finger integrates an inertial measurement unit (IMU) to capture finger motion,
while a smartwatch-based single-channel electromyography (EMG) sensor on the
wrist detects muscle activations. By leveraging the complementary strengths of
motion sensing and muscle signals, our approach achieves accurate hand pose
tracking and grip force estimation in a compact wearable form factor. We
develop a dual-branch transformer network that fuses IMU and EMG data with
cross-modal attention to predict finger joint positions and forces
simultaneously. A custom loss function imposes kinematic constraints for smooth
force variation and realistic force saturation. Evaluation with 20 participants
performing daily object interaction gestures demonstrates an average Mean Per
Joint Position Error (MPJPE) of 0.57 cm and a fingertip force estimation (RMSE:
0.213, r=0.76). We showcase our system in a real-time Unity application,
enabling virtual hand interactions that respond to user-applied forces. This
minimal, force-aware tracking system has broad implications for VR/AR,
assistive prosthetics, and ergonomic monitoring.

</details>


### [8] [Pedestrian collision avoidance in hemianopia during natural walking in immersive virtual reality](https://arxiv.org/abs/2510.04218)
*Jonathan K. Doyon,Sujin Kim,Alex D. Hwang,Jae-Hyun Jung*

Main category: cs.HC

TL;DR: 本研究通过虚拟现实技术评估同名性偏盲患者与行人碰撞的检测与规避能力，发现其在盲侧目标的碰撞检测与回避上存在显著困难，这为临床及康复提供了客观评估工具。


<details>
  <summary>Details</summary>
Motivation: 探索同名性偏盲患者在行走时避免与行人碰撞的能力，以了解其在日常活动中的困难。

Method: 使用新颖的虚拟现实行走环境，模拟与行人碰撞的情境，通过检测避免行为和碰撞检测进行比较。

Result: 同名性偏盲患者在检测和避免与行人碰撞方面表现较差，尤其是在盲侧目标的情况下，同时在检测后其头部旋转向盲侧的倾向更明显。

Conclusion: 本研究提出的头戴虚拟现实碰撞检测与规避范式为评估HH患者的移动性提供了一个客观的工具，能够深入探讨其碰撞回避行为的机制，有助于临床实践和康复。

Abstract: Homonymous hemianopia (HH) patients report difficulties in avoiding
collisions with other pedestrians. We evaluated pedestrian collision detection
and avoidance behaviors in HH patients and healthy controls using a novel
virtual reality (VR) walking with pedestrians, which enables natural walking
behavior in an empty real-world corridor while viewing an immersive VR
environment (shopping mall with colliding and other pedestrians) presented in a
head-mounted display (HMD). Critically, it measures avoidance maneuvers in
addition to collision detection. Colliding and non-colliding pedestrian
scenarios were developed for Meta Quest 2 using Unity. Ten normal vision (NV)
subjects and 12 HH subjects detected and avoided collisions with virtual
approaching and overtaken pedestrians initialized at bearing angles of 20, 40,
and 60 degrees, with planned time-to-collision of 6 seconds in each trial. HH
subjects were less likely to detect and more likely to collide with pedestrians
than NV, particularly for blind-side targets. Response times did not differ
between groups but were faster for overtaken pedestrians. HH subjects also
biased their head rotations toward the blind side and more after detection
compared to before. Collision avoidance difficulties as reported by HH
subjects, which clinical measures fail to capture, were recorded and analyzed
with objective measures. These metrics may offer further insights into the
underlying mechanisms driving collision avoidance behaviors. Our HMD-VR
collision detection and avoidance paradigm enables natural walking behaviors
and offers an affordable, objective assessment tool that may be adopted by
clinicians for mobility enhancement and rehabilitation.

</details>


### [9] [When AI Gets Persuaded, Humans Follow: Inducing the Conformity Effect in Persuasive Dialogue](https://arxiv.org/abs/2510.04229)
*Rikuo Sasaki,Michimasa Inaba*

Main category: cs.HC

TL;DR: 本研究揭示AI代理在劝说对话中可受到从众效应影响，设计良好的Persuadee Agent能够有效提高劝说效果。


<details>
  <summary>Details</summary>
Motivation: 探讨人工智能在劝说技术中的作用，特别是人们在与AI代理互动时是否会受到他人行为的影响。

Method: 通过对人类参与者进行文本对话实验，比较四种条件下的Persuadee Agent行为及其对劝说效果的影响。

Result: 通过实验验证了‘从众效应’在AI代理中的适用性，发现Persuadee Agent接受劝说时，感知的劝说性和实际的态度改变均显著增强。

Conclusion: 适当设计的Persuadee Agent能够通过从众效应增强劝说效果，特别是在使用冰破环节时。

Abstract: Recent advancements in AI have highlighted its application in captology, the
field of using computers as persuasive technologies. We hypothesized that the
"conformity effect," where individuals align with others' actions, also occurs
with AI agents. This study verifies this hypothesis by introducing a "Persuadee
Agent" that is persuaded alongside a human participant in a three-party
persuasive dialogue with a Persuader Agent. We conducted a text-based dialogue
experiment with human participants. We compared four conditions manipulating
the Persuadee Agent's behavior (persuasion acceptance vs. non-acceptance) and
the presence of an icebreaker session. Results showed that when the Persuadee
Agent accepted persuasion, both perceived persuasiveness and actual attitude
change significantly improved. Attitude change was greatest when an icebreaker
was also used, whereas an unpersuaded AI agent suppressed attitude change.
Additionally, it was confirmed that the persuasion acceptance of participants
increased at the moment the Persuadee Agent was persuaded. These results
suggest that appropriately designing a Persuadee Agent can improve persuasion
through the conformity effect.

</details>


### [10] [Reflection Before Action: Designing a Framework for Quantifying Thought Patterns for Increased Self-awareness in Personal Decision Making](https://arxiv.org/abs/2510.04364)
*Morita Tarvirdians,Senthil Chandrasegaran,Hayley Hung,Catholijn M. Jonker,Catharine Oertel*

Main category: cs.HC

TL;DR: 本文提出了前决策反思（PDR）的概念，并引入了PROBE框架，以评估个体在决策过程中的反思程度，旨在提高决策的自我意识与自主性。


<details>
  <summary>Details</summary>
Motivation: 探讨如何提高人们在重大决策中的元认知意识

Method: 引入PROBE框架评估个体的前决策反思

Result: 通过PROBE框架揭示不同参与者的反思异质性，并发现参与者普遍认为自己的反思比PROBE的衡量更深入更广泛

Conclusion: PROBE框架为开发促进自我意识的技术提供了机会，让人们能够更好地选择用于决策的思维模式。

Abstract: When making significant life decisions, people increasingly turn to
conversational AI tools, such as large language models (LLMs). However, LLMs
often steer users toward solutions, limiting metacognitive awareness of their
own decision-making. In this paper, we shift the focus in decision support from
solution-orientation to reflective activity, coining the term pre-decision
reflection (PDR). We introduce PROBE, the first framework that assesses
pre-decision reflections along two dimensions: breadth (diversity of thought
categories) and depth (elaborateness of reasoning). Coder agreement
demonstrates PROBE's reliability in capturing how people engage in pre-decision
reflection. Our study reveals substantial heterogeneity across participants and
shows that people perceived their unassisted reflections as deeper and broader
than PROBE's measures. By surfacing hidden thought patterns, PROBE opens
opportunities for technologies that foster self-awareness and strengthen
people's agency in choosing which thought patterns to rely on in
decision-making.

</details>


### [11] [Beyond the Benefits: A Systematic Review of the Harms and Consequences of Generative AI in Computing Education](https://arxiv.org/abs/2510.04443)
*Seth Bernstein,Ashfin Rahman,Nadia Sharifi,Ariunjargal Terbish,Stephen MacNeil*

Main category: cs.HC

TL;DR: 本研究系统回顾了生成性人工智能在计算机教育中的潜在风险与危害，并提供了针对这些问题的见解。


<details>
  <summary>Details</summary>
Motivation: 尽最大化人工智能的益处，同时应对其潜在的风险与伤害。

Method: 通过系统文献综述，分析生成性人工智能在计算机教育中的风险、危害及意外后果。

Result: 共筛选出224篇相关研究，分析了学术诚信、认知影响和信任问题等具体危害类别。

Conclusion: 该研究为教育工作者、计算机学生、研究人员和开发者提供了关于GenAI在计算机教育中所涉及的危害的清晰图景。

Abstract: Generative artificial intelligence (GenAI) has already had a big impact on
computing education with prior research identifying many benefits. However,
recent studies have also identified potential risks and harms. To continue
maximizing AI benefits while addressing the harms and unintended consequences,
we conducted a systematic literature review of research focusing on the risks,
harms, and unintended consequences of GenAI in computing education. Our search
of ACM DL, IEEE Xplore, and Scopus (2022-2025) resulted in 1,677 papers, which
were then filtered to 224 based on our inclusion and exclusion criteria. Guided
by best practices for systematic reviews, four reviewers independently
extracted publication year, learner population, research method, contribution
type, GenAI technology, and educational task information from each paper. We
then coded each paper for concrete harm categories such as academic integrity,
cognitive effects, and trust issues. Our analysis shows patterns in how and
where harms appear, highlights methodological gaps and opportunities for more
rigorous evidence, and identifies under-explored harms and student populations.
By synthesizing these insights, we intend to equip educators, computing
students, researchers, and developers with a clear picture of the harms
associated with GenAI in computing education.

</details>


### [12] [AgentBuilder: Exploring Scaffolds for Prototyping User Experiences of Interface Agents](https://arxiv.org/abs/2510.04452)
*Jenny T. Liang,Titus Barik,Jeffrey Nichols,Eldon Schoop,Ruijia Cheng*

Main category: cs.HC

TL;DR: 本研究探讨非AI工程师如何参与代理体验原型设计，通过用户研究识别原型系统需求，并开发出AgentBuilder工具。


<details>
  <summary>Details</summary>
Motivation: To broaden the user base for agent prototyping beyond AI engineers and leverage diverse perspectives in designing agent experiences.

Method: Conducting a requirements elicitation study with participants to explore agent experience prototyping needs and capabilities.

Result: Development of AgentBuilder, a design probe that incorporates identified capabilities for agent prototyping, validated through user studies.

Conclusion: 确认了用户在代理原型制作中的需求，为未来的代理开发提供了有价值的见解。

Abstract: Interface agents powered by generative AI models (referred to as "agents")
can automate actions based on user commands. An important aspect of developing
agents is their user experience (i.e., agent experience). There is a growing
need to provide scaffolds for a broader set of individuals beyond AI engineers
to prototype agent experiences, since they can contribute valuable perspectives
to designing agent experiences. In this work, we explore the affordances agent
prototyping systems should offer by conducting a requirements elicitation study
with 12 participants with varying experience with agents. We identify key
activities in agent experience prototyping and the desired capabilities of
agent prototyping systems. We instantiate those capabilities in the
AgentBuilder design probe for agent prototyping. We conduct an in situ agent
prototyping study with 14 participants using AgentBuilder to validate the
design requirements and elicit insights on how developers prototype agents and
what their needs are in this process.

</details>


### [13] [Autonomy Matters: A Study on Personalization-Privacy Dilemma in LLM Agents](https://arxiv.org/abs/2510.04465)
*Zhiping Zhang,Yi Evie Zhang,Freda Shi,Tianshi Li*

Main category: cs.HC

TL;DR: 个性化服务未考虑隐私偏好会增加隐私担忧，降低信任；适度自主性可缓解这一影响。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型代理在个性化服务中对隐私的影响，以解决个性化与隐私之间的两难局面。

Method: 进行了一个450人的3x3组间实验，考察代理自主性和个性化如何影响用户的隐私担忧、信任和使用意愿。

Result: 通过实验发现，未考虑用户隐私偏好的个性化会增加隐私担忧，降低信任和使用意愿。自主性在这些影响中起到调节作用。

Conclusion: 在个性化与隐私之间取得平衡，而非追求完美的模型一致性，是解决个性化-隐私难题的有效途径。

Abstract: Large Language Model (LLM) agents require personal information for
personalization in order to better act on users' behalf in daily tasks, but
this raises privacy concerns and a personalization-privacy dilemma. Agent's
autonomy introduces both risks and opportunities, yet its effects remain
unclear. To better understand this, we conducted a 3$\times$3 between-subjects
experiment ($N=450$) to study how agent's autonomy level and personalization
influence users' privacy concerns, trust and willingness to use, as well as the
underlying psychological processes. We find that personalization without
considering users' privacy preferences increases privacy concerns and decreases
trust and willingness to use. Autonomy moderates these effects: Intermediate
autonomy flattens the impact of personalization compared to No- and Full
autonomy conditions. Our results suggest that rather than aiming for perfect
model alignment in output generation, balancing autonomy of agent's action and
user control offers a promising path to mitigate the personalization-privacy
dilemma.

</details>


### [14] [Multi-Hop Question Answering: When Can Humans Help, and Where do They Struggle?](https://arxiv.org/abs/2510.04493)
*Jinyan Su,Claire Cardie,Jennifer Healey*

Main category: cs.HC

TL;DR: 本研究探讨了人类在多跳问答中的表现，发现他们在知识整合上表现优异，但在识别多跳推理需求上则较弱，这提示我们应设计能互补人类优势和弱点的AI系统。


<details>
  <summary>Details</summary>
Motivation: 探讨人类如何能与AI有效合作，以优化在多跳问答中的表现。

Method: 评估人类在多跳问答任务中的表现，包括知识整合、问题识别和推理等子任务。

Result: 人类在知识整合方面表现出色（97%准确率），但在识别多跳推理需求方面表现差（67%准确率）。单跳和多跳问答的表现分别为84%和80%的准确率，然而参与者常犯语义错误。

Conclusion: 设计AI系统时，需要考虑如何发挥人类的优势，并弥补其常见的弱点。

Abstract: Multi-hop question answering is a challenging task for both large language
models (LLMs) and humans, as it requires recognizing when multi-hop reasoning
is needed, followed by reading comprehension, logical reasoning, and knowledge
integration. To better understand how humans might collaborate effectively with
AI, we evaluate the performance of crowd workers on these individual reasoning
subtasks. We find that while humans excel at knowledge integration (97\%
accuracy), they often fail to recognize when a question requires multi-hop
reasoning (67\% accuracy). Participants perform reasonably well on both
single-hop and multi-hop QA (84\% and 80\% accuracy, respectively), but
frequently make semantic mistakes--for example, answering "when" an event
happened when the question asked "where." These findings highlight the
importance of designing AI systems that complement human strengths while
compensating for common weaknesses.

</details>


### [15] [NaturalEdit: Code Modification through Direct Interaction with Adaptive Natural Language Representation](https://arxiv.org/abs/2510.04494)
*Ningzhi Tang,David Meininger,Gelei Xu,Yiyu Shi,Yu Huang,Collin McMillan,Toby Jia-Jun Li*

Main category: cs.HC

TL;DR: NaturalEdit 提供互动和自适应的代码摘要，增强开发者的理解和控制力。


<details>
  <summary>Details</summary>
Motivation: 代码修改是一个认知负担较大的过程，开发者需要全面理解并计划修改，而静态的自然语言代码摘要无法满足这一需求。

Method: NaturalEdit 通过三个主要特征实现代码摘要的互动性与自适应性，包括灵活的摘要梯度、摘要与代码之间的互动映射机制，以及意图驱动的双向同步。

Result: NaturalEdit 是一个旨在提升代码修改过程中开发者认知能力的系统，通过互动和自适应的自然语言代码摘要改善了代码理解、变更规划和结果验证的流程。

Conclusion: 自然语言摘要与源代码之间的互动映射提升了开发者对代码理解和修改的信心与能力。

Abstract: Code modification requires developers to comprehend code, plan changes,
articulate intentions, and validate outcomes, making it a cognitively demanding
process. Generated natural language code summaries aid comprehension but remain
static and limited in supporting the full workflow. We present NaturalEdit, a
system that makes code summaries interactive and adaptive representations
directly linked to source code. Grounded in the Cognitive Dimensions of
Notations, NaturalEdit implements a paradigm of code modification through
interaction with natural language representations through three key features:
(1) adaptive multi-faceted representation of code summaries with flexible
Abstraction Gradient; (2) interactive mapping mechanisms between summaries and
codes, ensuring a tight Closeness of Mapping; and (3) intent-driven,
bidirectional synchronization that reduces Viscosity in editing and validation.
A technical evaluation confirms the performance of NaturalEdit, and a user
study with 12 developers shows that it enhances comprehension, intent
articulation, and validation, giving developers greater confidence and control.

</details>


### [16] [What Do We Mean When We Talk About Data Storytelling?](https://arxiv.org/abs/2510.04761)
*Leni Yang,Zezhong Wang,Xingyu Lan*

Main category: cs.HC

TL;DR: 本文探讨了数据讲述的定义和解释，定义了五种范式，提供未来研究的启示。


<details>
  <summary>Details</summary>
Motivation: 为促进学术界对数据讲述的理解和沟通，明确概念界限，帮助研究者和新来者建立研究方向

Method: 系统性文献回顾和编码分析

Result: 识别出96篇提供明确定义的文献，并归纳出五种数据讲述的定义范式

Conclusion: 为了推动对数据讲述的深入理解，建议改善学术交流，并为未来的研究提供机会。

Abstract: We have witnessed rapid growth in data storytelling research. Scholars from
multiple disciplines have contributed new theories and techniques surrounding
data storytelling. However, with this prolific development, a fuzzy boundary of
data storytelling comes. We argue that understanding how "data storytelling"
has been defined and interpreted by academia is crucial for facilitating
communication between researchers, encouraging the consistent use of concepts
and measures, assisting newcomers in approaching and positioning their research
in this area, and enabling the effective application of relevant techniques and
tools. Thus, it is necessary to systematically reflect on "what is data
storytelling" and promote a more thorough understanding of this concept.
Specifically, we investigated how existing research has conceptualized "data
storytelling." As a result, we identified 96 publications that provide explicit
definitions. By coding these definitions in-depth, we identified five paradigms
of defining data storytelling, as well as a broad spectrum of interpretations
regarding the content, objectives, and techniques of data storytelling.
Finally, we concluded with implications for future research, aiming to foster
nuanced communication about "data storytelling," suggest research
opportunities, and establish a more inclusive theoretical foundation for this
research direction.

</details>


### [17] [Trust in Transparency: How Explainable AI Shapes User Perceptions](https://arxiv.org/abs/2510.04968)
*Allen Daniel Sunny*

Main category: cs.HC

TL;DR: 本研究探讨将上下文解释整合到AI贷款决策系统中，以增强信任和可用性。


<details>
  <summary>Details</summary>
Motivation: 传统AI系统过于依赖算法透明度，未能考虑更广泛的社会和经济背景。

Method: 通过定性研究，调查用户与AI解释的互动，识别关键差距。

Result: 研究发现当前系统缺乏上下文解释，强调了仅靠技术透明性存在的局限性。

Conclusion: 需要将系统的解释与用户需求和社会因素对齐，以建立信任并改善决策过程。

Abstract: This study explores the integration of contextual explanations into
AI-powered loan decision systems to enhance trust and usability. While
traditional AI systems rely heavily on algorithmic transparency and technical
accuracy, they often fail to account for broader social and economic contexts.
Through a qualitative study, I investigated user interactions with AI
explanations and identified key gaps, in- cluding the inability of current
systems to provide context. My findings underscore the limitations of purely
technical transparency and the critical need for contex- tual explanations that
bridge the gap between algorithmic outputs and real-world decision-making. By
aligning explanations with user needs and broader societal factors, the system
aims to foster trust, improve decision-making, and advance the design of
human-centered AI systems

</details>


### [18] [NERVIS: An Interactive System for Graph-Based Exploration and Editing of Named Entities](https://arxiv.org/abs/2510.04971)
*Uroš Šmajdek,Ciril Bohak*

Main category: cs.HC

TL;DR: 本文介绍了一种图形化的交互式可视化系统，以探索命名实体的关系，支持多视图和灵活编辑。


<details>
  <summary>Details</summary>
Motivation: 为了支持对富含命名实体的文档集合的深入分析与探究，创建了一个互动的可视化系统。

Method: 基于图形表示，整合文档、实体提及和实体的节点，搭建多种协作视图以供用户探索实体关系。

Result: 提出了一种交互式可视化系统，用于探索文档集合中的命名实体及其关系，采用图形化表示，整合文档、实体提及和实体三种节点类型。多种协调视图帮助用户发现实体的聚集与高级关系，并支持灵活的迭代探索。

Conclusion: 该系统通过结合图形可视化和交互式细化，推动了对富含实体文本数据的人本探索。

Abstract: We present an interactive visualization system for exploring named entities
and their relationships across document collections. The system is designed
around a graph-based representation that integrates three types of nodes:
documents, entity mentions, and entities. Connections capture two key
relationship types: (i) identical entities across contexts, and (ii)
co-locations of mentions within documents. Multiple coordinated views enable
users to examine entity occurrences, discover clusters of related mentions, and
explore higher-level entity group relationships. To support flexible and
iterative exploration, the interface offers fuzzy views with approximate
connections, as well as tools for interactively editing the graph by adding or
removing links, entities, and mentions, as well as editing entity terms.
Additional interaction features include filtering, mini-map navigation, and
export options to JSON or image formats for downstream analysis and reporting.
This approach contributes to human-centered exploration of entity-rich text
data by combining graph visualization, interactive refinement, and adaptable
perspectives on relationships.

</details>


### [19] [Observing Without Doing: Pseudo-Apprenticeship Patterns in Student LLM Use](https://arxiv.org/abs/2510.04986)
*Jade Hak,Nathaniel Lam Johnson,Matin Amoozadeh,Amin Alipour,Souti Chattopadhyay*

Main category: cs.HC

TL;DR: 这项研究调查了初学者编程学生如何将大型语言模型融入解决问题的过程中，发现了依赖AI的学习模式，并提出了相应的干预措施。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型（LLMs）如ChatGPT在学生编程者工具包中的角色，分析其如何影响初学者编程（CS1）学生的解决问题过程。

Method: 进行了一项混合方法研究，涉及14名本科生在完成三项编程任务时进行思考，同时允许他们访问任何资源，任务的开放性和熟悉度各不相同，并随后进行了调查和访谈。

Result: 研究发现学生通常采用一种称为伪学徒制的模式，与LLMs提供的专家级解决方案认真互动，但未能参与促进独立问题解决的认知学徒制阶段。

Conclusion: 研究建议通过设计和教学干预措施来促进学生学习，并解决观测到的依赖AI的使用模式。

Abstract: Large Language Models (LLMs) such as ChatGPT have quickly become part of
student programmers' toolkits, whether allowed by instructors or not. This
paper examines how introductory programming (CS1) students integrate LLMs into
their problem-solving processes. We conducted a mixed-methods study with 14
undergraduates completing three programming tasks while thinking aloud and
permitted to access any resources they choose. The tasks varied in
open-endedness and familiarity to the participants and were followed by surveys
and interviews. We find that students frequently adopt a pattern we call
pseudo-apprenticeship, where students engage attentively with expert-level
solutions provided by LLMs but fail to participate in the stages of cognitive
apprenticeship that promote independent problem-solving. This pattern was
augmented by disconnects between students' intentions, actions, and
self-perceived behavior when using LLMs. We offer design and instructional
interventions for promoting learning and addressing the patterns of dependent
AI use observed.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [20] [Gemini Robotics 1.5: Pushing the Frontier of Generalist Robots with Advanced Embodied Reasoning, Thinking, and Motion Transfer](https://arxiv.org/abs/2510.03342)
*Abbas Abdolmaleki,Saminda Abeyruwan,Joshua Ainslie,Jean-Baptiste Alayrac,Montserrat Gonzalez Arenas,Ashwin Balakrishna,Nathan Batchelor,Alex Bewley,Jeff Bingham,Michael Bloesch,Konstantinos Bousmalis,Philemon Brakel,Anthony Brohan,Thomas Buschmann,Arunkumar Byravan,Serkan Cabi,Ken Caluwaerts,Federico Casarini,Christine Chan,Oscar Chang,London Chappellet-Volpini,Jose Enrique Chen,Xi Chen,Hao-Tien Lewis Chiang,Krzysztof Choromanski,Adrian Collister,David B. D'Ambrosio,Sudeep Dasari,Todor Davchev,Meet Kirankumar Dave,Coline Devin,Norman Di Palo,Tianli Ding,Carl Doersch,Adil Dostmohamed,Yilun Du,Debidatta Dwibedi,Sathish Thoppay Egambaram,Michael Elabd,Tom Erez,Xiaolin Fang,Claudio Fantacci,Cody Fong,Erik Frey,Chuyuan Fu,Ruiqi Gao,Marissa Giustina,Keerthana Gopalakrishnan,Laura Graesser,Oliver Groth,Agrim Gupta,Roland Hafner,Steven Hansen,Leonard Hasenclever,Sam Haves,Nicolas Heess,Brandon Hernaez,Alex Hofer,Jasmine Hsu,Lu Huang,Sandy H. Huang,Atil Iscen,Mithun George Jacob,Deepali Jain,Sally Jesmonth,Abhishek Jindal,Ryan Julian,Dmitry Kalashnikov,M. Emre Karagozler,Stefani Karp,Matija Kecman,J. Chase Kew,Donnie Kim,Frank Kim,Junkyung Kim,Thomas Kipf,Sean Kirmani,Ksenia Konyushkova,Li Yang Ku,Yuheng Kuang,Thomas Lampe,Antoine Laurens,Tuan Anh Le,Isabel Leal,Alex X. Lee,Tsang-Wei Edward Lee,Guy Lever,Jacky Liang,Li-Heng Lin,Fangchen Liu,Shangbang Long,Caden Lu,Sharath Maddineni,Anirudha Majumdar,Kevis-Kokitsi Maninis,Andrew Marmon,Sergio Martinez,Assaf Hurwitz Michaely,Niko Milonopoulos,Joss Moore,Robert Moreno,Michael Neunert,Francesco Nori,Joy Ortiz,Kenneth Oslund,Carolina Parada,Emilio Parisotto,Amaris Paryag,Acorn Pooley,Thomas Power,Alessio Quaglino,Haroon Qureshi,Rajkumar Vasudeva Raju,Helen Ran,Dushyant Rao,Kanishka Rao,Isaac Reid,David Rendleman,Krista Reymann,Miguel Rivas,Francesco Romano,Yulia Rubanova,Peter Pastor Sampedro,Pannag R Sanketi,Dhruv Shah,Mohit Sharma,Kathryn Shea,Mohit Shridhar,Charles Shu,Vikas Sindhwani,Sumeet Singh,Radu Soricut,Rachel Sterneck,Ian Storz,Razvan Surdulescu,Jie Tan,Jonathan Tompson,Saran Tunyasuvunakool,Jake Varley,Grace Vesom,Giulia Vezzani,Maria Bauza Villalonga,Oriol Vinyals,René Wagner,Ayzaan Wahid,Stefan Welker,Paul Wohlhart,Chengda Wu,Markus Wulfmeier,Fei Xia,Ted Xiao,Annie Xie,Jinyu Xie,Peng Xu,Sichun Xu,Ying Xu,Zhuo Xu,Jimmy Yan,Sherry Yang,Skye Yang,Yuxiang Yang,Hiu Hong Yu,Wenhao Yu,Wentao Yuan,Yuan Yuan,Jingwei Zhang,Tingnan Zhang,Zhiyuan Zhang,Allan Zhou,Guangyao Zhou,Yuxiang Zhou*

Main category: cs.RO

TL;DR: Gemini Robotics 1.5和Gemini Robotics-ER 1.5模型通过创新架构和推理机制提高了通用机器人的多步任务处理能力。


<details>
  <summary>Details</summary>
Motivation: 开发通用机器人，以便能够更好地理解物理世界，实现复杂任务的推理和控制

Method: Gemini Robotics 1.5 和 Gemini Robotics-ER 1.5

Result: 推出新版的 Gemini Robotics 模型，改进了多样性的学习和自然语言处理能力，以及增强的逻辑推理能力

Conclusion: 该模型系列推动了物理代理时代，让机器人能够感知、思考并行动，从而解决复杂的多步骤任务。

Abstract: General-purpose robots need a deep understanding of the physical world,
advanced reasoning, and general and dexterous control. This report introduces
the latest generation of the Gemini Robotics model family: Gemini Robotics 1.5,
a multi-embodiment Vision-Language-Action (VLA) model, and Gemini Robotics-ER
1.5, a state-of-the-art Embodied Reasoning (ER) model. We are bringing together
three major innovations. First, Gemini Robotics 1.5 features a novel
architecture and a Motion Transfer (MT) mechanism, which enables it to learn
from heterogeneous, multi-embodiment robot data and makes the VLA more general.
Second, Gemini Robotics 1.5 interleaves actions with a multi-level internal
reasoning process in natural language. This enables the robot to "think before
acting" and notably improves its ability to decompose and execute complex,
multi-step tasks, and also makes the robot's behavior more interpretable to the
user. Third, Gemini Robotics-ER 1.5 establishes a new state-of-the-art for
embodied reasoning, i.e., for reasoning capabilities that are critical for
robots, such as visual and spatial understanding, task planning, and progress
estimation. Together, this family of models takes us a step towards an era of
physical agents-enabling robots to perceive, think and then act so they can
solve complex multi-step tasks.

</details>


### [21] [Optimal swimming with body compliance in an overdamped medium](https://arxiv.org/abs/2510.03457)
*Jianfeng Lin,Tianyu Wang,Baxi Chong,Matthew Fernandez,Zhaochen Xu,Daniel I. Goldman*

Main category: cs.RO

TL;DR: 本文扩展了几何力学方法，以预测合规游泳者的运动性能，并通过优化框架实现最佳游泳策略。


<details>
  <summary>Details</summary>
Motivation: 探讨复杂环境中合规动物和机器人运动的建模和优化方法，考虑环境交互影响。

Method: 将普切尔三连杆游泳者的合规扩展与电缆驱动机器人结合，利用阻力力理论推导体动力学，应用几何力学进行运动预测和性能优化。

Result: 提出了一种基于几何力学的系统方法，可以预测和优化合规游泳者的运动性能。

Conclusion: 建立了一种系统的基于物理的方法，强调合规性作为在不同环境中实现可靠运动的设计特性。

Abstract: Elongate animals and robots use undulatory body waves to locomote through
diverse environments. Geometric mechanics provides a framework to model and
optimize such systems in highly damped environments, connecting a prescribed
shape change pattern (gait) with locomotion displacement. However, existing
approaches assume precise execution of prescribed gaits, whereas in practice
environmental interactions with compliant bodies of animals or robots
frequently perturb the realized trajectories. In this work, we extend geometric
mechanics to predict locomotor performance and search for optimal swimming
strategy of compliant undulators. We introduce a compliant extension of
Purcell's three-link swimmer by incorporating series-connected springs at the
joints. Body dynamics are derived with resistive force theory. Geometric
mechanics is incorporated into movement prediction and into an optimization
framework that identifies strategies for controlling compliant swimmers to
achieve maximal displacement. We validate our framework on a physical
cable-driven three-link limbless robot, and demonstrate accurate prediction and
optimization of locomotor performance under varied programmed, state-dependent
compliance in a granular medium. Our results establish a systematic
physics-based approach for modeling and controlling compliant swimming
locomotion, highlighting compliance as a design feature that can be exploited
for robust movement in homogeneous and heterogeneous environments.

</details>


### [22] [Warm-Starting Optimization-Based Motion Planning for Robotic Manipulators via Point Cloud-Conditioned Flow Matching](https://arxiv.org/abs/2510.03460)
*Sibo Tian,Minghui Zheng,Xiao Liang*

Main category: cs.RO

TL;DR: 提出了一种基于学习的流匹配模型，用于快速生成机器人运动轨迹，能够有效应对复杂动态环境。


<details>
  <summary>Details</summary>
Motivation: 在动态环境中，实现安全高效的人机协作需要快速生成机器人运动，当前方法存在时间效率低下和对初始化敏感的问题。

Method: 基于深度相机输入，利用流匹配模型学习近似最优的优化初始化。

Result: 在UR5e机器人模拟中验证了新方法的高成功率，减少了优化迭代次数，显著优于传统和基于学习的基准初始化器。

Conclusion: 所提出的方法在无障碍物知识的情况下，能够生成可行轨迹，提高了轨迹优化的成功率，且对未知环境具备良好的泛化能力。

Abstract: Rapid robot motion generation is critical in Human-Robot Collaboration (HRC)
systems, as robots need to respond to dynamic environments in real time by
continuously observing their surroundings and replanning their motions to
ensure both safe interactions and efficient task execution. Current
sampling-based motion planners face challenges in scaling to high-dimensional
configuration spaces and often require post-processing to interpolate and
smooth the generated paths, resulting in time inefficiency in complex
environments. Optimization-based planners, on the other hand, can incorporate
multiple constraints and generate smooth trajectories directly, making them
potentially more time-efficient. However, optimization-based planners are
sensitive to initialization and may get stuck in local minima. In this work, we
present a novel learning-based method that utilizes a Flow Matching model
conditioned on a single-view point cloud to learn near-optimal solutions for
optimization initialization. Our method does not require prior knowledge of the
environment, such as obstacle locations and geometries, and can generate
feasible trajectories directly from single-view depth camera input. Simulation
studies on a UR5e robotic manipulator in cluttered workspaces demonstrate that
the proposed generative initializer achieves a high success rate on its own,
significantly improves the success rate of trajectory optimization compared
with traditional and learning-based benchmark initializers, requires fewer
optimization iterations, and exhibits strong generalization to unseen
environments.

</details>


### [23] [A Simulation Evaluation Suite for Robust Adaptive Quadcopter Control](https://arxiv.org/abs/2510.03471)
*Dingqi Zhang,Ran Tao,Sheng Cheng,Naira Hovakimyan,Mark W. Mueller*

Main category: cs.RO

TL;DR: 本论文介绍了一种模块化的四旋翼控制仿真测试平台，旨在系统评估自适应控制方法的性能。


<details>
  <summary>Details</summary>
Motivation: 传统四旋翼控制方法的评估分散，导致难以进行系统比较，迫切需要一个统一的测试平台。

Method: 基于RotorPy开发的模块化仿真测试平台，涵盖多种自适应和非自适应控制器，并提供相关评估指标。

Result: 提出了一个模块化的四旋翼控制仿真测试平台，以评估自适应控制方法在不同干扰下的性能。

Conclusion: 新的测试平台为系统比较提供了统一的环境，减少了重实现的需求，适用于多种干扰场景的评估。

Abstract: Robust adaptive control methods are essential for maintaining quadcopter
performance under external disturbances and model uncertainties. However,
fragmented evaluations across tasks, simulators, and implementations hinder
systematic comparison of these methods. This paper introduces an
easy-to-deploy, modular simulation testbed for quadcopter control, built on
RotorPy, that enables evaluation under a wide range of disturbances such as
wind, payload shifts, rotor faults, and control latency. The framework includes
a library of representative adaptive and non-adaptive controllers and provides
task-relevant metrics to assess tracking accuracy and robustness. The unified
modular environment enables reproducible evaluation across control methods and
eliminates redundant reimplementation of components such as disturbance models,
trajectory generators, and analysis tools. We illustrate the testbed's
versatility through examples spanning multiple disturbance scenarios and
trajectory types, including automated stress testing, to demonstrate its
utility for systematic analysis. Code is available at
https://github.com/Dz298/AdaptiveQuadBench.

</details>


### [24] [Destination-to-Chutes Task Mapping Optimization for Multi-Robot Coordination in Robotic Sorting Systems](https://arxiv.org/abs/2510.03472)
*Yulun Zhang,Alexandre O. G. Barbosa,Federico Pecora,Jiaoyang Li*

Main category: cs.RO

TL;DR: 本研究旨在优化机器人分拣系统中的目标到出口通道任务映射，以提高系统吞吐量，提出了一种基于进化算法和整数规划的优化方法，并通过仿真验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 优化目的在于提高机器人分拣系统的吞吐量，解决任务映射、机器人目标分配和路径规划之间的复杂关联。

Method: 采用进化算法和混合整数线性规划进行任务映射优化，并通过仿真来评估不同任务映射的效果。

Result: 在多种不同设置下，优化后的任务映射在吞吐量方面优于贪婪产生的映射，利用质量多样性算法分析了任务映射的多样性对吞吐量的影响。

Conclusion: 通过进化算法和混合整数线性规划优化的任务映射方法，相较于贪婪生成的映射更具优势，从而提高了机器人分拣系统的吞吐量。

Abstract: We study optimizing a destination-to-chutes task mapping to improve
throughput in Robotic Sorting Systems (RSS), where a team of robots sort
packages on a sortation floor by transporting them from induct workstations to
eject chutes based on their shipping destinations (e.g. Los Angeles or
Pittsburgh). The destination-to-chutes task mapping is used to determine which
chutes a robot can drop its package. Finding a high-quality task mapping is
challenging because of the complexity of a real-world RSS. First, optimizing
task mapping is interdependent with robot target assignment and path planning.
Second, chutes will be CLOSED for a period of time once they receive sufficient
packages to allow for downstream processing. Third, task mapping quality
directly impacts the downstream processing, as scattered chutes for the same
destination increase package handling time. In this paper, we first formally
define task mappings and the problem of Task Mapping Optimization (TMO). We
then present a simulator of RSS to evaluate task mappings. We then present a
simple TMO method based on the Evolutionary Algorithm and Mixed Integer Linear
Programming, demonstrating the advantage of our optimized task mappings over
the greedily generated ones in various RSS setups with different map sizes,
numbers of chutes, and destinations. Finally, we use Quality Diversity
algorithms to analyze the throughput of a diverse set of task mappings. Our
code is available online at https://github.com/lunjohnzhang/tmo_public.

</details>


### [25] [Robust Permissive Controller Synthesis for Interval MDPs](https://arxiv.org/abs/2510.03481)
*Khang Vo Huynh,David Parker,Lu Feng*

Main category: cs.RO

TL;DR: 这篇论文提出了一个针对不确定动态的稳健宽容控制器合成框架，能够在IMDPs上有效合成多策略，扩展性良好，适用于机器人应用。


<details>
  <summary>Details</summary>
Motivation: 现有的宽容控制器合成方法通常假设精确的转移概率，这在许多机器人应用中并不现实，因此需要一种能够处理不确定性的控制器合成框架。

Method: 将宽容控制器合成问题表述为混合整数线性规划（MILPs），并提出两种编码方法：基础的顶点枚举法和可扩展的对偶法。

Result: 提出的框架保证了合成的多策略在所有可接受的转移下满足可达性或奖励基于的规范，并在多个基准领域上展示了良好的性能。

Conclusion: 提出了一个新的框架，能够在不确定动态下进行稳健的宽容控制器合成，并在多个基准领域实验中验证了有效性和可扩展性。

Abstract: We address the problem of robust permissive controller synthesis for robots
operating under uncertain dynamics, modeled as Interval Markov Decision
Processes (IMDPs). IMDPs generalize standard MDPs by allowing transition
probabilities to vary within intervals, capturing epistemic uncertainty from
sensing noise, actuation imprecision, and coarse system abstractions-common in
robotics. Traditional controller synthesis typically yields a single
deterministic strategy, limiting adaptability. In contrast, permissive
controllers (multi-strategies) allow multiple actions per state, enabling
runtime flexibility and resilience. However, prior work on permissive
controller synthesis generally assumes exact transition probabilities, which is
unrealistic in many robotic applications. We present the first framework for
robust permissive controller synthesis on IMDPs, guaranteeing that all
strategies compliant with the synthesized multi-strategy satisfy reachability
or reward-based specifications under all admissible transitions. We formulate
the problem as mixed-integer linear programs (MILPs) and propose two encodings:
a baseline vertex-enumeration method and a scalable duality-based method that
avoids explicit enumeration. Experiments on four benchmark domains show that
both methods synthesize robust, maximally permissive controllers and scale to
large IMDPs with up to hundreds of thousands of states.

</details>


### [26] [Digital-Twin Evaluation for Proactive Human-Robot Collision Avoidance via Prediction-Guided A-RRT*](https://arxiv.org/abs/2510.03496)
*Vadivelan Murugesan,Rajasundaram Mathiazhagan,Sanjana Joshi,Aliasghar Arab*

Main category: cs.RO

TL;DR: 提出了一种结合人类运动预测和数字双胞胎的安全规划框架，实现了高效的碰撞避免。


<details>
  <summary>Details</summary>
Motivation: 提升人机协作中的碰撞避免能力，通过精准的人类运动预测实现更安全的规划。

Method: 基于胶囊的人工势场（APF）和自适应RRT*（A-RRT*）规划器，结合CNN-BiLSTM模型进行个体关节轨迹预测，搭建实时的人体姿态预测数字双胞胎模型。

Result: 在50次试验中，方法实现了100%的主动避免，且清晰度超过250毫米，重规划时间小于2秒。

Conclusion: 提出的方法通过整合预测性人类建模与数字双胞胎验证，展示了比现有运动学规划器更优秀的精确度与可靠性，达到了100%的主动避免率。

Abstract: Human-robot collaboration requires precise prediction of human motion over
extended horizons to enable proactive collision avoidance. Unlike existing
planners that rely solely on kinodynamic models, we present a prediction-driven
safe planning framework that leverages granular, joint-by-joint human motion
forecasting validated in a physics-based digital twin. A capsule-based
artificial potential field (APF) converts these granular predictions into
collision risk metrics, triggering an Adaptive RRT* (A-RRT*) planner when
thresholds are exceeded. The depth camera is used to extract 3D skeletal poses
and a convolutional neural network-bidirectional long short-term memory
(CNN-BiLSTM) model to predict individual joint trajectories ahead of time. A
digital twin model integrates real-time human posture prediction placed in
front of a simulated robot to evaluate motions and physical contacts. The
proposed method enables validation of planned trajectories ahead of time and
bridging potential latency gaps in updating planned trajectories in real-time.
In 50 trials, our method achieved 100% proactive avoidance with > 250 mm
clearance and sub-2 s replanning, demonstrating superior precision and
reliability compared to existing kinematic-only planners through the
integration of predictive human modeling with digital twin validation.

</details>


### [27] [Distributed Connectivity Maintenance and Recovery for Quadrotor Motion Planning](https://arxiv.org/abs/2510.03504)
*Yutong Wang,Yichun Qu,Tengxiang Wang,Lishuo Pan,Nora Ayanian*

Main category: cs.RO

TL;DR: 提出一种新的多机器人导航框架，通过高阶控制障碍函数和控制李雅普诺夫函数，增强连接性和碰撞避免能力，成功在复杂环境中进行验证。


<details>
  <summary>Details</summary>
Motivation: 在多机器人应用中维持连接性至关重要，但受到障碍物和视觉遮挡的影响

Method: 实时间分布框架，结合高阶控制障碍函数(HOCBF)和控制李雅普诺夫函数(CLF)

Result: 统一的MPC-CLF-CBF框架，通过平滑的贝塞尔参数化轨迹生成，实现连接性维护和恢复

Conclusion: 通过广泛的仿真和物理实验，验证了框架的有效性，展示了在障碍物丰富环境中保持连接性的能力。

Abstract: Maintaining connectivity is crucial in many multi-robot applications, yet
fragile to obstacles and visual occlusions. We present a real-time distributed
framework for multi-robot navigation certified by high-order control barrier
functions (HOCBFs) that controls inter-robot proximity to maintain connectivity
while avoiding collisions. We incorporate control Lyapunov functions to enable
connectivity recovery from initial disconnected configurations and temporary
losses, providing robust connectivity during navigation in obstacle-rich
environments. Our trajectory generation framework concurrently produces
planning and control through a Bezier-parameterized trajectory, which naturally
provides smooth curves with arbitrary degree of derivatives. The main
contribution is the unified MPC-CLF-CBF framework, a continuous-time trajectory
generation and control method for connectivity maintenance and recovery of
multi-robot systems. We validate the framework through extensive simulations
and a physical experiment with 4 Crazyflie nano-quadrotors.

</details>


### [28] [LapSurgie: Humanoid Robots Performing Surgery via Teleoperated Handheld Laparoscopy](https://arxiv.org/abs/2510.03529)
*Zekai Liang,Xiao Liang,Soofiyan Atar,Sreyan Das,Zoe Chiu,Peihan Zhang,Florian Richter,Shanglei Liu,Michael C. Yip*

Main category: cs.RO

TL;DR: 本文介绍了LapSurgie，一个基于人形机器人的腹腔镜远程操作系统，旨在提高低资源地区的手术可及性。


<details>
  <summary>Details</summary>
Motivation: 提高机器人腹腔镜手术的可及性，缩小高资源医疗中心和低资源地区之间的医疗差距。

Method: 通过逆映射策略处理手部控制，与现有腹腔镜工具无缝配合，搭建了一个配备立体视觉的控制台以提供实时反馈。

Result: 提出了一种基于人形机器人的腹腔镜远程操作框架LapSurgie，并验证了其有效性和可行性。

Conclusion: 通过用户研究表明，LapSurgie能够有效实施腹腔镜手术，展示了在人形机器人技术应用于外科手术中的潜力。

Abstract: Robotic laparoscopic surgery has gained increasing attention in recent years
for its potential to deliver more efficient and precise minimally invasive
procedures. However, adoption of surgical robotic platforms remains largely
confined to high-resource medical centers, exacerbating healthcare disparities
in rural and low-resource regions. To close this gap, a range of solutions has
been explored, from remote mentorship to fully remote telesurgery. Yet, the
practical deployment of surgical robotic systems to underserved communities
remains an unsolved challenge. Humanoid systems offer a promising path toward
deployability, as they can directly operate in environments designed for humans
without extensive infrastructure modifications -- including operating rooms. In
this work, we introduce LapSurgie, the first humanoid-robot-based laparoscopic
teleoperation framework. The system leverages an inverse-mapping strategy for
manual-wristed laparoscopic instruments that abides to remote center-of-motion
constraints, enabling precise hand-to-tool control of off-the-shelf surgical
laparoscopic tools without additional setup requirements. A control console
equipped with a stereo vision system provides real-time visual feedback.
Finally, a comprehensive user study across platforms demonstrates the
effectiveness of the proposed framework and provides initial evidence for the
feasibility of deploying humanoid robots in laparoscopic procedures.

</details>


### [29] [Efficient Surgical Robotic Instrument Pose Reconstruction in Real World Conditions Using Unified Feature Detection](https://arxiv.org/abs/2510.03532)
*Zekai Liang,Kazuya Miyata,Xiao Liang,Florian Richter,Michael C. Yip*

Main category: cs.RO

TL;DR: 提出了一种新框架，通过共享编码高效实现相机与长运动链微创外科机器人之间的姿态估计。


<details>
  <summary>Details</summary>
Motivation: 进行准确的相机与机器人标定，特别是在微创外科机器人中，传统方法在长运动链和部分可见性下面临挑战。

Method: 通过共享编码统一检测几何原语（关键点和轴边缘），实现高效的姿态估计。

Result: 在特征检测和姿态估计方面进行评估，结果展示了快速性能和最先进的准确性。

Conclusion: 该方法在复杂的外科环境中表现出快速的性能和最先进的准确性。

Abstract: Accurate camera-to-robot calibration is essential for any vision-based
robotic control system and especially critical in minimally invasive surgical
robots, where instruments conduct precise micro-manipulations. However, MIS
robots have long kinematic chains and partial visibility of their degrees of
freedom in the camera, which introduces challenges for conventional
camera-to-robot calibration methods that assume stiff robots with good
visibility. Previous works have investigated both keypoint-based and
rendering-based approaches to address this challenge in real-world conditions;
however, they often struggle with consistent feature detection or have long
inference times, neither of which are ideal for online robot control. In this
work, we propose a novel framework that unifies the detection of geometric
primitives (keypoints and shaft edges) through a shared encoding, enabling
efficient pose estimation via projection geometry. This architecture detects
both keypoints and edges in a single inference and is trained on large-scale
synthetic data with projective labeling. This method is evaluated across both
feature detection and pose estimation, with qualitative and quantitative
results demonstrating fast performance and state-of-the-art accuracy in
challenging surgical environments.

</details>


### [30] [Shape-Space Graphs: Fast and Collision-Free Path Planning for Soft Robots](https://arxiv.org/abs/2510.03547)
*Carina Veil,Moritz Flaschel,Ellen Kuhl*

Main category: cs.RO

TL;DR: 提出了一种基于图形的路径规划工具，利用生物力学模型解决软机器人在复杂环境中的运动规划问题，确保快速、可靠的路径生成，适用于各种实时应用。


<details>
  <summary>Details</summary>
Motivation: 解决软机器人在复杂环境中运动规划的挑战，特别是在存在障碍物的情况下。

Method: 使用基于生物力学模型的图形路径规划工具，结合$k$-近邻图和签名距离函数来预先计算形状库，并进行碰撞避免。

Result: 算法能够在几毫秒内依靠预先计算的图形，可靠地避免障碍物并生成可行路径，且包含能量成本可以大幅降低驱动努力。

Conclusion: 形状空间图搜索在软机器人路径规划中具有快速和可靠的潜力，适用于外科、工业和辅助应用。

Abstract: Soft robots, inspired by elephant trunks or octopus arms, offer extraordinary
flexibility to bend, twist, and elongate in ways that rigid robots cannot.
However, their motion planning remains a challenge, especially in cluttered
environments with obstacles, due to their highly nonlinear and
infinite-dimensional kinematics. Here, we present a graph-based path planning
tool for an elephant-trunk-inspired soft robotic arm designed with three
artificial muscle fibers that allow for multimodal continuous deformation
through contraction. Using a biomechanical model inspired by morphoelasticity
and active filament theory, we precompute a shape library and construct a
$k$-nearest neighbor graph in \emph{shape space}, ensuring that each node
corresponds to a mechanically accurate and physically valid robot shape. For
the graph, we use signed distance functions to prune nodes and edges colliding
with obstacles, and define multi-objective edge costs based on geometric
distance and actuation effort, enabling energy-efficient planning with
collision avoidance. We demonstrate that our algorithm reliably avoids
obstacles and generates feasible paths within milliseconds from precomputed
graphs using Dijkstra's algorithm. We show that including energy costs can
drastically reduce the actuation effort compared to geometry-only planning, at
the expense of longer tip trajectories. Our results highlight the potential of
shape-space graph search for fast and reliable path planning in the field of
soft robotics, paving the way for real-time applications in surgical,
industrial, and assistive settings.

</details>


### [31] [Learning to Act Through Contact: A Unified View of Multi-Task Robot Learning](https://arxiv.org/abs/2510.03599)
*Shafeef Omar,Majid Khadiv*

Main category: cs.RO

TL;DR: 提出了一种通过共享结构实现多任务操控和运动学习的统一框架，增强了策略的通用性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 通过联系明确的表示来定义任务，避免为不同任务设计不同策略

Method: 统一的多任务 locomotion 和 manipulation 策略学习框架

Result: 验证了框架在多种机器人体和任务上的有效性，比如四足机器人和类人机器人在不同运动和操作任务中的表现

Conclusion: 明确的接触推理显著提高了在未见场景中的推广能力，为可扩展的运动操作提供了有前景的基础。

Abstract: We present a unified framework for multi-task locomotion and manipulation
policy learning grounded in a contact-explicit representation. Instead of
designing different policies for different tasks, our approach unifies the
definition of a task through a sequence of contact goals-desired contact
positions, timings, and active end-effectors. This enables leveraging the
shared structure across diverse contact-rich tasks, leading to a single policy
that can perform a wide range of tasks. In particular, we train a
goal-conditioned reinforcement learning (RL) policy to realise given contact
plans. We validate our framework on multiple robotic embodiments and tasks: a
quadruped performing multiple gaits, a humanoid performing multiple biped and
quadrupedal gaits, and a humanoid executing different bimanual object
manipulation tasks. Each of these scenarios is controlled by a single policy
trained to execute different tasks grounded in contacts, demonstrating
versatile and robust behaviours across morphologically distinct systems. Our
results show that explicit contact reasoning significantly improves
generalisation to unseen scenarios, positioning contact-explicit policy
learning as a promising foundation for scalable loco-manipulation.

</details>


### [32] [Safety-Oriented Dynamic Path Planning for Automated Vehicles](https://arxiv.org/abs/2510.03640)
*Mostafa Emam,Matthias Gerdts*

Main category: cs.RO

TL;DR: 本论文介绍了一种双层控制框架，通过实时路径优化和安全备份，增强自动驾驶汽车在复杂动态环境中的安全性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 提高自动驾驶汽车在动态环境中的安全性，确保先进的路径规划和障碍物避免能力。

Method: 采用非线性模型预测控制（NMPC）进行实时路径优化，并使用基于同伦的约束放松技术来改善最优控制问题的可解性，同时运行独立的备份循环以提供安全的替代轨迹。

Result: 提出了一种双层控制框架，通过时间依赖的障碍物移动网格投影，增强道路边界，实现精确适应的路径规划。

Conclusion: 该框架标志着在复杂动态环境中实现更安全可靠的自动驾驶的重要一步。

Abstract: Ensuring safety in autonomous vehicles necessitates advanced path planning
and obstacle avoidance capabilities, particularly in dynamic environments. This
paper introduces a bi-level control framework that efficiently augments road
boundaries by incorporating time-dependent grid projections of obstacle
movements, thus enabling precise and adaptive path planning. The main control
loop utilizes Nonlinear Model Predictive Control (NMPC) for real-time path
optimization, wherein homotopy-based constraint relaxation is employed to
improve the solvability of the optimal control problem (OCP). Furthermore, an
independent backup loop runs concurrently to provide safe fallback trajectories
when an optimal trajectory cannot be computed by the main loop within a
critical time frame, thus enhancing safety and real-time performance. Our
evaluation showcases the benefits of the proposed methods in various driving
scenarios, highlighting the real-time applicability and robustness of our
approach. Overall, the framework represents a significant step towards safer
and more reliable autonomous driving in complex and dynamic environments.

</details>


### [33] [Geometrically Exact Hard Magneto-Elastic Cosserat Shells: Static Formulation for Shape Morphing](https://arxiv.org/abs/2510.03644)
*Mohammadjavad Javadi,Robin Chhabra*

Main category: cs.RO

TL;DR: 提出了一种高效的无坐标静态模型，用于分析和控制硬磁壳的形状，适用于大宽高比的软机器人。


<details>
  <summary>Details</summary>
Motivation: 许多软机器人在设计上表现出大宽高比，无法仅用一维的Cosserat杆理论进行有效建模，因此需要发展一种新的模型来适应二位壳体的行为。

Method: 基于特殊欧几里得群的Cosserat壳理论提出了一种新颖的方法，通过引入局部变形梯度的定义，导出了平衡方程的强形式和弱形式。

Result: 开发了一种基于新的Cosserat壳理论的静态模型，适用于建模大宽高比的软磁壳体，改进了对软机器人运动和操作的分析和形状控制。

Conclusion: 该模型在处理壳体的旋转和位移方面表现出优越的有效性，并且已通过一系列测试案例进行了验证。

Abstract: Cosserat rod theory is the popular approach to modeling ferromagnetic soft
robots as 1-Dimensional (1D) slender structures in most applications, such as
biomedical. However, recent soft robots designed for locomotion and
manipulation often exhibit a large width-to-length ratio that categorizes them
as 2D shells. For analysis and shape-morphing control purposes, we develop an
efficient coordinate-free static model of hard-magnetic shells found in soft
magnetic grippers and walking soft robots. The approach is based on a novel
formulation of Cosserat shell theory on the Special Euclidean group
($\mathbf{SE}(3)$). The shell is assumed to be a 2D manifold of material points
with six degrees of freedom (position & rotation) suitable for capturing the
behavior of a uniformly distributed array of spheroidal hard magnetic particles
embedded in the rheological elastomer. The shell's configuration manifold is
the space of all smooth embeddings $\mathbb{R}^2\rightarrow\mathbf{SE}(3)$.
According to a novel definition of local deformation gradient based on the Lie
group structure of $\mathbf{SE}(3)$, we derive the strong and weak forms of
equilibrium equations, following the principle of virtual work. We extract the
linearized version of the weak form for numerical implementations. The
resulting finite element approach can avoid well-known challenges such as
singularity and locking phenomenon in modeling shell structures. The proposed
model is analytically and experimentally validated through a series of test
cases that demonstrate its superior efficacy, particularly when the shell
undergoes severe rotations and displacements.

</details>


### [34] [An Amphibious Untethered Inchworm Soft Robot for Fast Crawling Locomotion](https://arxiv.org/abs/2510.03660)
*Mohammadjavad Javadi,Charlie Wadds,Robin Chhabra*

Main category: cs.RO

TL;DR: 本研究开发出一种灵活的无束缚软机器人，具备多种 locomotion 能力和自给自足的控制系统。


<details>
  <summary>Details</summary>
Motivation: 开发适用于多任务环境的无束缚软机器人，以实现软机器人系统的实际应用。

Method: 机器人采用磁力驱动，集成轻型控制电路和环境感知摄像头，通过实验验证了其动态性能和运动能力。

Result: 提出了一种灵活弯曲结构的完全无束缚软机器人，能够在多种模式下移动。

Conclusion: 通过结构优化和系统集成，该机器人在不依赖外部基础设施的情况下成功执行多种任务。

Abstract: Untethered soft robots are essential for advancing the real-world deployment
of soft robotic systems in diverse and multitasking environments. Inspired by
soft-bodied inchworm, we present a fully untethered soft robot with a curved,
flexible structure actuated by magnetic forces. The robot has a total mass of
102.63 g and demonstrates multimodal locomotion, achieving a maximum walking
speed of 3.74 cm/s and a swimming speed of 0.82 cm/s. A compact and lightweight
onboard control circuit enables wireless command transmission, while an
integrated camera provides environmental perception. Through structural
optimization and system-level integration, the robot successfully performs
walking, steering, swimming, and payload transport without reliance on external
infrastructure. The robot's dynamic performance and locomotion capabilities are
systematically validated through experimental characterization.

</details>


### [35] [Robust Visual Embodiment: How Robots Discover Their Bodies in Real Environments](https://arxiv.org/abs/2510.03677)
*Salim Rezvani,Ammar Jaleel Mahmood,Robin Chhabra*

Main category: cs.RO

TL;DR: 本论文研究了视觉退化对机器人自我建模的影响，提出了一种结合语义分割和任务感知去噪的新框架，有效提高了自我建模的鲁棒性，为机器人在真实环境中的应用提供了支持。


<details>
  <summary>Details</summary>
Motivation: 现有的自我建模管道在面对真实感知条件（如噪声较大的图像和杂乱背景）下表现脆弱，因此需要对视觉退化的影响进行系统研究，以提高机器人的适应能力。

Method: 通过仿真和实际实验评估不同视觉退化对机器人自我建模的影响，包括模糊、椒盐噪声和高斯噪声，并引入了一种任务感知去噪框架与语义分割相结合。

Result: 实验表明，该方法在仿真和物理平台上恢复了接近基线的性能，而现有管道则显著下降。

Conclusion: 本研究提出了一种新颖的任务感知去噪框架，有效提高了机器人自我建模的鲁棒性，并为自我意识机器人在复杂环境中的应用奠定了基础。

Abstract: Robots with internal visual self-models promise unprecedented adaptability,
yet existing autonomous modeling pipelines remain fragile under realistic
sensing conditions such as noisy imagery and cluttered backgrounds. This paper
presents the first systematic study quantifying how visual
degradations--including blur, salt-and-pepper noise, and Gaussian noise--affect
robotic self-modeling. Through both simulation and physical experiments, we
demonstrate their impact on morphology prediction, trajectory planning, and
damage recovery in state-of-the-art pipelines. To overcome these challenges, we
introduce a task-aware denoising framework that couples classical restoration
with morphology-preserving constraints, ensuring retention of structural cues
critical for self-modeling. In addition, we integrate semantic segmentation to
robustly isolate robots from cluttered and colorful scenes. Extensive
experiments show that our approach restores near-baseline performance across
simulated and physical platforms, while existing pipelines degrade
significantly. These contributions advance the robustness of visual
self-modeling and establish practical foundations for deploying self-aware
robots in unpredictable real-world environments.

</details>


### [36] [EmbodiSwap for Zero-Shot Robot Imitation Learning](https://arxiv.org/abs/2510.03706)
*Eadom Dessalene,Pavan Mantripragada,Michael Maynord,Yiannis Aloimonos*

Main category: cs.RO

TL;DR: 提出EmbodiSwap方法，成功用于机器人模仿学习，展示出高成功率，并提供相应的代码和数据集以推动研究。


<details>
  <summary>Details</summary>
Motivation: 解决真实人类视频与目标机器人实体之间的体现差距，实现零样本模仿学习。

Method: EmbodiSwap方法用于在真人视频上生成合成的机器人覆盖图像。

Result: 使用V-JEPA作为视觉基础，成功训练出在真实测试中达到82%成功率的零样本模型。

Conclusion: EmbodiSwap有效桥接了人类视频与机器人实体之间的差距，V-JEPA模型在真实场景中表现出色，促进了机器人学习的进步。

Abstract: We introduce EmbodiSwap - a method for producing photorealistic synthetic
robot overlays over human video. We employ EmbodiSwap for zero-shot imitation
learning, bridging the embodiment gap between in-the-wild ego-centric human
video and a target robot embodiment. We train a closed-loop robot manipulation
policy over the data produced by EmbodiSwap. We make novel use of V-JEPA as a
visual backbone, repurposing V-JEPA from the domain of video understanding to
imitation learning over synthetic robot videos. Adoption of V-JEPA outperforms
alternative vision backbones more conventionally used within robotics. In
real-world tests, our zero-shot trained V-JEPA model achieves an $82\%$ success
rate, outperforming a few-shot trained $\pi_0$ network as well as $\pi_0$
trained over data produced by EmbodiSwap. We release (i) code for generating
the synthetic robot overlays which takes as input human videos and an arbitrary
robot URDF and generates a robot dataset, (ii) the robot dataset we synthesize
over EPIC-Kitchens, HOI4D and Ego4D, and (iii) model checkpoints and inference
code, to facilitate reproducible research and broader adoption.

</details>


### [37] [Model-Based Adaptive Precision Control for Tabletop Planar Pushing Under Uncertain Dynamics](https://arxiv.org/abs/2510.03768)
*Aydin Ahmadi,Baris Akgun*

Main category: cs.RO

TL;DR: 提出了一种基于模型的框架，通过单一模型支持多个推送任务，显示出高成功率和广泛的适用性。


<details>
  <summary>Details</summary>
Motivation: 旨在解决现有数据驱动平面推送方法的局限性，特别是其在多任务能力和通用性方面的不足。

Method: 采用基于GRU的递归架构和非线性层，结合基于采样的模型预测路径积分（MPPI）控制器。

Result: 在精确定位、轨迹跟踪和避障等任务中表现出高成功率，且在多任务解决上无需重新训练。

Conclusion: 该框架在现实世界中的多个任务上表现优异，通过改变控制器的目标函数可以简单地解决多任务，而无需重新训练。

Abstract: Data-driven planar pushing methods have recently gained attention as they
reduce manual engineering effort and improve generalization compared to
analytical approaches. However, most prior work targets narrow capabilities
(e.g., side switching, precision, or single-task training), limiting broader
applicability. We present a model-based framework for non-prehensile tabletop
pushing that uses a single learned model to address multiple tasks without
retraining. Our approach employs a recurrent GRU-based architecture with
additional non-linear layers to capture object-environment dynamics while
ensuring stability. A tailored state-action representation enables the model to
generalize across uncertain dynamics, variable push lengths, and diverse tasks.
For control, we integrate the learned dynamics with a sampling-based Model
Predictive Path Integral (MPPI) controller, which generates adaptive,
task-oriented actions. This framework supports side switching, variable-length
pushes, and objectives such as precise positioning, trajectory following, and
obstacle avoidance. Training is performed in simulation with domain
randomization to support sim-to-real transfer. We first evaluate the
architecture through ablation studies, showing improved prediction accuracy and
stable rollouts. We then validate the full system in simulation and real-world
experiments using a Franka Panda robot with markerless tracking. Results
demonstrate high success rates in precise positioning under strict thresholds
and strong performance in trajectory tracking and obstacle avoidance. Moreover,
multiple tasks are solved simply by changing the controller's objective
function, without retraining. While our current focus is on a single object
type, we extend the framework by training on wider push lengths and designing a
balanced controller that reduces the number of steps for longer-horizon goals.

</details>


### [38] [Trajectory prediction for heterogeneous agents: A performance analysis on small and imbalanced datasets](https://arxiv.org/abs/2510.03776)
*Tiago Rodrigues de Almeida,Yufei Zhu,Andrey Rudenko,Tomasz P. Kucner,Johannes A. Stork,Martin Magnusson,Achim J. Lilienthal*

Main category: cs.RO

TL;DR: 考虑类标签的轨迹预测方法在动态环境中有助于提高移动机器人的导航效率和安全性，尤其在数据少的情况下效果更佳


<details>
  <summary>Details</summary>
Motivation: 理解和预测周围智能体的未来行为，以提高移动机器人在动态环境中的导航效率和安全性

Method: 分析不同的类条件轨迹预测方法并提出基于条件模式和高效深度学习的基线模型

Result: 提出的一系列方法在机器人和户外数据集上实验评估证实了考虑类标签后预测准确性的提升

Conclusion: 在数据不平衡或新环境中的应用场景，需要考虑类条件的方式来提升预测性能，尤其是使用模式基础的方法在数据有限时更具优势。

Abstract: Robots and other intelligent systems navigating in complex dynamic
environments should predict future actions and intentions of surrounding agents
to reach their goals efficiently and avoid collisions. The dynamics of those
agents strongly depends on their tasks, roles, or observable labels.
Class-conditioned motion prediction is thus an appealing way to reduce forecast
uncertainty and get more accurate predictions for heterogeneous agents.
However, this is hardly explored in the prior art, especially for mobile robots
and in limited data applications. In this paper, we analyse different
class-conditioned trajectory prediction methods on two datasets. We propose a
set of conditional pattern-based and efficient deep learning-based baselines,
and evaluate their performance on robotics and outdoors datasets (TH\"OR-MAGNI
and Stanford Drone Dataset). Our experiments show that all methods improve
accuracy in most of the settings when considering class labels. More
importantly, we observe that there are significant differences when learning
from imbalanced datasets, or in new environments where sufficient data is not
available. In particular, we find that deep learning methods perform better on
balanced datasets, but in applications with limited data, e.g., cold start of a
robot in a new environment, or imbalanced classes, pattern-based methods may be
preferable.

</details>


### [39] [COVER:COverage-VErified Roadmaps for Fixed-time Motion Planning in Continuous Semi-Static Environments](https://arxiv.org/abs/2510.03875)
*Niranjan Kumar Ilampooranan,Constantinos Chamzas*

Main category: cs.RO

TL;DR: COVER是一个新的框架，旨在解决半静态环境中的运动规划问题，通过划分障碍配置空间来保证时间和可行路径。


<details>
  <summary>Details</summary>
Motivation: 在固定时间预算内回答运动规划查询对机器人系统的广泛部署至关重要，尤其是在半静态环境中。

Method: 通过对障碍配置空间进行划分，并在每个划分内求解可行路径，系统地验证路线图的可行性，从而保证在已验证区域内的固定时间运动规划查询。

Result: 提出COVER框架，它在半静态环境中逐步构建覆盖验证的路线图。

Conclusion: COVER在模拟的7自由度Panda机器人测试中表现出更高的覆盖率和查询成功率。

Abstract: Having the ability to answer motion-planning queries within a fixed time
budget is critical for the widespread deployment of robotic systems.
Semi-static environments, where most obstacles remain static but a limited set
can vary across queries, exhibit structured variability that can be
systematically exploited to provide stronger guarantees than in general
motion-planning problems. However, prior approaches in this setting either lack
formal guarantees or rely on restrictive discretizations of obstacle
configurations, limiting their applicability in realistic domains. This paper
introduces COVER, a novel framework that incrementally constructs a
coverage-verified roadmap in semi-static environments. By partitioning the
obstacle configuration space and solving for feasible paths within each
partition, COVER systematically verifies feasibility of the roadmap in each
partition and guarantees fixed-time motion planning queries within the verified
regions. We validate COVER with a 7-DOF simulated Panda robot performing table
and shelf tasks, demonstrating that COVER achieves broader coverage with higher
query success rates than prior works.

</details>


### [40] [Seeing the Bigger Picture: 3D Latent Mapping for Mobile Manipulation Policy Learning](https://arxiv.org/abs/2510.03885)
*Sunghwan Kim,Woojeh Chung,Zhirui Dai,Dwait Bhatt,Arth Shukla,Hao Su,Yulun Tian,Nikolay Atanasov*

Main category: cs.RO

TL;DR: SBP利用3D潜在地图实现了更强的空间和时间推理，优于传统图像政策，并提高了任务执行中的成功率。


<details>
  <summary>Details</summary>
Motivation: 移动操控政策在空间和时间推理方面的表现不如利用3D潜在地图的政策，因此需要一种新的方法来提高这一方面的能力。

Method: 采用端到端学习策略，利用3D潜在特征地图进行增量映射和特征融合，同时利用行为克隆和强化学习训练可用于决策的策略。

Result: Seeing the Bigger Picture (SBP)是一种端到端的策略学习方法，利用3D潜在特征地图的优势，实现更强的空间和时间推理能力，并在移动操控和顺序桌面操控任务中表现优于基于图像的政策。

Conclusion: SBP方法通过利用全局场景信息和长时间记忆，显著提高了移动操控任务的成功率，展示了3D潜在地图的巨大潜力。

Abstract: In this paper, we demonstrate that mobile manipulation policies utilizing a
3D latent map achieve stronger spatial and temporal reasoning than policies
relying solely on images. We introduce Seeing the Bigger Picture (SBP), an
end-to-end policy learning approach that operates directly on a 3D map of
latent features. In SBP, the map extends perception beyond the robot's current
field of view and aggregates observations over long horizons. Our mapping
approach incrementally fuses multiview observations into a grid of
scene-specific latent features. A pre-trained, scene-agnostic decoder
reconstructs target embeddings from these features and enables online
optimization of the map features during task execution. A policy, trainable
with behavior cloning or reinforcement learning, treats the latent map as a
state variable and uses global context from the map obtained via a 3D feature
aggregator. We evaluate SBP on scene-level mobile manipulation and sequential
tabletop manipulation tasks. Our experiments demonstrate that SBP (i) reasons
globally over the scene, (ii) leverages the map as long-horizon memory, and
(iii) outperforms image-based policies in both in-distribution and novel
scenes, e.g., improving the success rate by 25% for the sequential manipulation
task.

</details>


### [41] [NoTVLA: Narrowing of Dense Action Trajectories for Generalizable Robot Manipulation](https://arxiv.org/abs/2510.03895)
*Zheng Huang,Mingyu Liu,Xiaoyi Lin,Muzhi Zhu,Canyu Zhao,Zongze Du,Xiaoman Li,Yiduo Jia,Hao Zhong,Hao Chen,Chunhua Shen*

Main category: cs.RO

TL;DR: 本论文提出了NoTVLA框架，通过稀疏轨迹训练克服VLA模型的灾难性遗忘问题，并在多任务场景中表现优越，同时降低计算需求和硬件依赖。


<details>
  <summary>Details</summary>
Motivation: 应对VLA模型在现实部署中面临的灾难性遗忘问题，尤其是轨迹依赖导致的知识保留障碍。

Method: 提出了NoTVLA框架，采用稀疏轨迹进行训练，并通过时间压缩和空间推理修剪进行轨迹规划。

Result: 在多任务评估中，NoTVLA的表现优于pi0，且计算需求低于pi0，为机器人平台的统一模型部署提供了支持。

Conclusion: NoTVLA框架通过集中于稀疏轨迹，克服了灾难性遗忘问题，展现出在多任务评估场景中的优越性能和泛化能力，同时在计算功耗和硬件要求上具有显著优势。

Abstract: Vision-Language-Action (VLA) models represent a pivotal advance in embodied
intelligence, yet they confront critical barriers to real-world deployment,
most notably catastrophic forgetting. This issue stems from their overreliance
on continuous action sequences or action chunks, which inadvertently create
isolated data silos that disrupt knowledge retention across tasks. To tackle
these challenges, we propose the Narrowing of Trajectory VLA (NoTVLA)
framework: a novel approach that narrows its focus to sparse trajectories,
thereby avoiding the catastrophic forgetting associated with dense trajectory
fine-tuning. A key innovation of NoTVLA lies in its trajectory planning
strategy: instead of centering on the target object's trajectory, it leverages
temporal compression and spatial reasoning pruning specifically for the robot
end effector's trajectory. Furthermore, training is conducted using these
sparse trajectories rather than dense action trajectories, an optimization that
delivers remarkable practical advantages with better performance in zero-shot.
In multi-task evaluation scenarios, NoTVLA achieves superior performance and
generalization compared to pi0 while operating under two critical constraints:
it uses over an order of magnitude less computing power than pi0 and requires
no wrist-mounted camera. This design ensures that NoTVLA's operational accuracy
closely approximates that of single-task expert models. Crucially, it also
preserves the model's inherent language capabilities, enabling zero-shot
generalization in specific scenarios, supporting unified model deployment
across multiple robot platforms, and fostering a degree of generalization even
when perceiving tasks from novel perspectives.

</details>


### [42] [WAFFLE: A Wearable Approach to Bite Timing Estimation in Robot-Assisted Feeding](https://arxiv.org/abs/2510.03910)
*Akhil Padmanabha,Jessie Yuan,Tanisha Mehta,Rajat Kumar Jenamani,Eric Hu,Victoria de León,Anthony Wertz,Janavi Gupta,Ben Dodson,Yunting Yan,Carmel Majidi,Tapomayukh Bhattacharjee,Zackory Erickson*

Main category: cs.RO

TL;DR: WAFFLE是一种新型机器人喂食系统，通过可穿戴传感器数据精确预测进食时机，提高了用户的自主性和满意度。


<details>
  <summary>Details</summary>
Motivation: 提高有障碍人士的自主权和生活质量，减轻照顾者负担。

Method: 引入WAFFLE系统，通过可穿戴传感器数据准确预测进食时机。

Result: WAFFLE系统在感知控制、机器人理解及工作负载方面表现优于基线方法，且得到参与者更高评价。

Conclusion: WAFFLE有效支持自然反应的进食时机预测，并在多种环境和条件下具备良好的通用性。

Abstract: Millions of people around the world need assistance with feeding. Robotic
feeding systems offer the potential to enhance autonomy and quality of life for
individuals with impairments and reduce caregiver workload. However, their
widespread adoption has been limited by technical challenges such as estimating
bite timing, the appropriate moment for the robot to transfer food to a user's
mouth. In this work, we introduce WAFFLE: Wearable Approach For Feeding with
LEarned bite timing, a system that accurately predicts bite timing by
leveraging wearable sensor data to be highly reactive to natural user cues such
as head movements, chewing, and talking. We train a supervised regression model
on bite timing data from 14 participants and incorporate a user-adjustable
assertiveness threshold to convert predictions into proceed or stop commands.
In a study with 15 participants without motor impairments with the Obi feeding
robot, WAFFLE performs statistically on par with or better than baseline
methods across measures of feeling of control, robot understanding, and
workload, and is preferred by the majority of participants for both individual
and social dining. We further demonstrate WAFFLE's generalizability in a study
with 2 participants with motor impairments in their home environments using a
Kinova 7DOF robot. Our findings support WAFFLE's effectiveness in enabling
natural, reactive bite timing that generalizes across users, robot hardware,
robot positioning, feeding trajectories, foods, and both individual and social
dining contexts.

</details>


### [43] [TCB-VIO: Tightly-Coupled Focal-Plane Binary-Enhanced Visual Inertial Odometry](https://arxiv.org/abs/2510.03919)
*Matthew Lisondra,Junseo Kim,Glenn Takashi Shimoda,Kourosh Zareinia,Sajad Saeedi*

Main category: cs.RO

TL;DR: 本论文提出了一种新型视觉算法TCB-VIO，利用高帧率和多状态约束卡尔曼滤波器，解决了视觉惯性里程计中的空间漂移问题。


<details>
  <summary>Details</summary>
Motivation: 通过采用新一代焦平面传感器处理器阵列(FPSP)，降低视觉算法执行的延迟，解决视觉传感器与处理器之间的数据传输瓶颈问题。

Method: 通过多状态约束卡尔曼滤波器（MSCKF）实现紧耦合的六自由度视觉惯性测距，采用高帧率处理。

Result: TCB-VIO在高帧率下有效减少了因视觉定位造成的空间漂移，并在性能上优于多种先进的视觉惯性里程计方法。

Conclusion: TCB-VIO在250 FPS高帧率下运行，结合400 Hz的惯性测量，显著优于现有方法，如ROVIO、VINS-Mono和ORB-SLAM3。

Abstract: Vision algorithms can be executed directly on the image sensor when
implemented on the next-generation sensors known as focal-plane
sensor-processor arrays (FPSP)s, where every pixel has a processor. FPSPs
greatly improve latency, reducing the problems associated with the bottleneck
of data transfer from a vision sensor to a processor. FPSPs accelerate
vision-based algorithms such as visual-inertial odometry (VIO). However, VIO
frameworks suffer from spatial drift due to the vision-based pose estimation,
whilst temporal drift arises from the inertial measurements. FPSPs circumvent
the spatial drift by operating at a high frame rate to match the high-frequency
output of the inertial measurements. In this paper, we present TCB-VIO, a
tightly-coupled 6 degrees-of-freedom VIO by a Multi-State Constraint Kalman
Filter (MSCKF), operating at a high frame-rate of 250 FPS and from IMU
measurements obtained at 400 Hz. TCB-VIO outperforms state-of-the-art methods:
ROVIO, VINS-Mono, and ORB-SLAM3.

</details>


### [44] [A Real-Time Framework for Intermediate Map Construction and Kinematically Feasible Off-Road Planning Without OSM](https://arxiv.org/abs/2510.03948)
*Otobong Jerome,Geesara Prathap Kulathunga,Devitt Dmitry,Eugene Murawjow,Alexandr Klimchik*

Main category: cs.RO

TL;DR: 提出了一种新颖的全局路径规划方法，旨在解决离路环境中的自主导航挑战，具有良好的实时性能和运动学可行性。


<details>
  <summary>Details</summary>
Motivation: 传统路径规划方法在离路环境中表现不佳，因此需要一种新的全局路径规划方法以应对复杂和非结构化的挑战。

Method: 首先构建像素坐标系统中的中间地图，包含地理特征，并将规划问题分为图形导航、运动学可行性检查和路径平滑三个子问题。

Result: 该方法在极端条件下能够均匀识别可行路径，平均耗时1.5秒，内存使用约1.5GB。

Conclusion: 提出的方法在多个离路环境中被成功验证，能在极端条件下识别可行路径，表现优异。

Abstract: Off-road environments present unique challenges for autonomous navigation due
to their complex and unstructured nature. Traditional global path-planning
methods, which typically aim to minimize path length and travel time, perform
poorly on large-scale maps and fail to account for critical factors such as
real-time performance, kinematic feasibility, and memory efficiency. This paper
introduces a novel global path-planning method specifically designed for
off-road environments, addressing these essential factors. The method begins by
constructing an intermediate map within the pixel coordinate system,
incorporating geographical features like off-road trails, waterways, restricted
and passable areas, and trees. The planning problem is then divided into three
sub-problems: graph-based path planning, kinematic feasibility checking, and
path smoothing. This approach effectively meets real-time performance
requirements while ensuring kinematic feasibility and efficient memory use. The
method was tested in various off-road environments with large-scale maps up to
several square kilometers in size, successfully identifying feasible paths in
an average of 1.5 seconds and utilizing approximately 1.5GB of memory under
extreme conditions. The proposed framework is versatile and applicable to a
wide range of off-road autonomous navigation tasks, including search and rescue
missions and agricultural operations.

</details>


### [45] [SITCOM: Scaling Inference-Time COMpute for VLAs](https://arxiv.org/abs/2510.04041)
*Ayudh Saxena,Harsh Shah,Sandeep Routray,Rishi Rajesh Shah,Esha Pahwa*

Main category: cs.RO

TL;DR: 提出了一种增强视觉-语言-动作模型的框架SITCOM，能够提高机器人控制策略在长时间任务中的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决现有视觉-语言-动作模型因缺乏前瞻性和动态任务中的错误累积而导致的控制策略鲁棒性不足问题。

Method: SITCOM使用基于模型的展开和奖励驱动的轨迹选择，结合学到的动态模型进行多步动作回推以选择最佳执行计划。

Result: 通过在SIMPLER环境中的综合评估，SITCOM显著提高了任务完成率。

Conclusion: SITCOM结合良好的奖励函数显著提高了任务完成率，从48%提升到72%。

Abstract: Learning robust robotic control policies remains a major challenge due to the
high cost of collecting labeled data, limited generalization to unseen
environments, and difficulties in planning over long horizons. While
Vision-Language-Action (VLA) models offer a promising solution by grounding
natural language instructions into single-step control commands, they often
lack mechanisms for lookahead and struggle with compounding errors in dynamic
tasks. In this project, we introduce Scaling Inference-Time COMpute for VLAs
(SITCOM), a framework that augments any pretrained VLA with model-based
rollouts and reward-based trajectory selection, inspired by Model Predictive
Control algorithm. SITCOM leverages a learned dynamics model to simulate
multi-step action rollouts to select the best candidate plan for real-world
execution, transforming one-shot VLAs into robust long-horizon planners. We
develop an efficient transformer-based dynamics model trained on large-scale
BridgeV2 data and fine-tuned on SIMPLER environments to bridge the Real2Sim
gap, and score candidate rollouts using rewards from simulator. Through
comprehensive evaluation across multiple tasks and settings in the SIMPLER
environment, we demonstrate that SITCOM when combined with a good reward
function can significantly improve task completion rate from 48% to 72% using
trained dynamics model.

</details>


### [46] [Feedback Matters: Augmenting Autonomous Dissection with Visual and Topological Feedback](https://arxiv.org/abs/2510.04074)
*Chung-Pang Wang,Changwei Chen,Xiao Liang,Soofiyan Atar,Florian Richter,Michael Yip*

Main category: cs.RO

TL;DR: 本研究提出了一种反馈驱动的内窥镜解剖框架，通过优化可见性和整合不同解剖方法，显著提高了自主外科机器人的性能和稳定性。


<details>
  <summary>Details</summary>
Motivation: 自主外科系统需要在动态环境中适应迅速变化的组织特性和视觉线索，而现有反馈机制在处理组织解剖时的拓扑和感知挑战方面仍有限。

Method: 提出了一种反馈驱动的框架，明确考虑了内窥镜图像中的拓扑变化，并将此反馈机制与规划和学习基础的解剖方法结合。

Result: 实验表明，所提框架在提升自主性、减少错误和改善复杂外科场景中的鲁棒性方面显著优于现有方法。

Conclusion: 通过引入反馈机制和优化控制设计，本研究显著增强了自主组织解剖中的自主性、降低了错误率，并提高了复杂外科场景中的稳健性。

Abstract: Autonomous surgical systems must adapt to highly dynamic environments where
tissue properties and visual cues evolve rapidly. Central to such adaptability
is feedback: the ability to sense, interpret, and respond to changes during
execution. While feedback mechanisms have been explored in surgical robotics,
ranging from tool and tissue tracking to error detection, existing methods
remain limited in handling the topological and perceptual challenges of tissue
dissection. In this work, we propose a feedback-enabled framework for
autonomous tissue dissection that explicitly reasons about topological changes
from endoscopic images after each dissection action. This structured feedback
guides subsequent actions, enabling the system to localize dissection progress
and adapt policies online. To improve the reliability of such feedback, we
introduce visibility metrics that quantify tissue exposure and formulate
optimal controller designs that actively manipulate tissue to maximize
visibility. Finally, we integrate these feedback mechanisms with both
planning-based and learning-based dissection methods, and demonstrate
experimentally that they significantly enhance autonomy, reduce errors, and
improve robustness in complex surgical scenarios.

</details>


### [47] [From Shadow to Light: Toward Safe and Efficient Policy Learning Across MPC, DeePC, RL, and LLM Agents](https://arxiv.org/abs/2510.04076)
*Amin Vahidi-Moghaddam,Sayed Pedram Haeri Boroujeni,Iman Jebellat,Ehsan Jebellat,Niloufar Mehrabi,Zhaojian Li*

Main category: cs.RO

TL;DR: 本文探讨了现代控制中的挑战，并提出了八种方法，以解决数据驱动策略在复杂系统中的计算复杂性，展示其在多个实际应用中的有效性。


<details>
  <summary>Details</summary>
Motivation: 在现代控制应用中，尤其是机器人和车辆运动控制，准确、快速和安全的运动是一个主要挑战。

Method: 介绍八种技术，如降阶建模、函数近似策略学习和凸松弛，以减少计算复杂性。

Result: 数据驱动的策略存在显著限制，如响应时间慢、计算需求高和内存需求大，这使得它们在快速动态、有限储存和严格内存约束的现实系统中不太实用。

Conclusion: 本文提出了八种方法，展示了这些方法在现实世界应用中的有效性，比如机器人臂、软机器人和车辆运动控制。

Abstract: One of the main challenges in modern control applications, particularly in
robot and vehicle motion control, is achieving accurate, fast, and safe
movement. To address this, optimal control policies have been developed to
enforce safety while ensuring high performance. Since basic first-principles
models of real systems are often available, model-based controllers are widely
used. Model predictive control (MPC) is a leading approach that optimizes
performance while explicitly handling safety constraints. However, obtaining
accurate models for complex systems is difficult, which motivates data-driven
alternatives. ML-based MPC leverages learned models to reduce reliance on
hand-crafted dynamics, while reinforcement learning (RL) can learn near-optimal
policies directly from interaction data. Data-enabled predictive control
(DeePC) goes further by bypassing modeling altogether, directly learning safe
policies from raw input-output data. Recently, large language model (LLM)
agents have also emerged, translating natural language instructions into
structured formulations of optimal control problems. Despite these advances,
data-driven policies face significant limitations. They often suffer from slow
response times, high computational demands, and large memory needs, making them
less practical for real-world systems with fast dynamics, limited onboard
computing, or strict memory constraints. To address this, various technique,
such as reduced-order modeling, function-approximated policy learning, and
convex relaxations, have been proposed to reduce computational complexity. In
this paper, we present eight such approaches and demonstrate their
effectiveness across real-world applications, including robotic arms, soft
robots, and vehicle motion control.

</details>


### [48] [HEHA: Hierarchical Planning for Heterogeneous Multi-Robot Exploration of Unknown Environments](https://arxiv.org/abs/2510.04161)
*Longrui Yang,Yiyu Wang,Jingfan Tang,Yunpeng Lv,Shizhe Zhao,Chao Cao,Zhongqiang Ren*

Main category: cs.RO

TL;DR: 本文提出了HEHA方法，结合全局与局部规划，解决多机器人在未知环境中的路径规划问题，实验显示探索时间可减少多达30%。


<details>
  <summary>Details</summary>
Motivation: 解决多机器人在复杂地形中进行自主探索时的路径规划和机器人分配问题。

Method: 提出一种新型的分层探索算法HEHA，包括全局规划和局部规划，使用PEAF算法来解决最小化路径长度的问题。

Result: 通过实验结果验证，HEHA算法相比基线方法能显著减少探索时间。

Conclusion: HEHA方法能够有效减少多机器人探索未知环境的时间，最高可达30%。

Abstract: This paper considers the path planning problem for autonomous exploration of
an unknown environment using multiple heterogeneous robots such as drones,
wheeled, and legged robots, which have different capabilities to traverse
complex terrains. A key challenge there is to intelligently allocate the robots
to the unknown areas to be explored and determine the visiting order of those
spaces subject to traversablity constraints, which leads to a large scale
constrained optimization problem that needs to be quickly and iteratively
solved every time when new space are explored. To address the challenge, we
propose HEHA (Hierarchical Exploration with Heterogeneous Agents) by leveraging
a recent hierarchical method that decompose the exploration into global
planning and local planning. The major contribution in HEHA is its global
planning, where we propose a new routing algorithm PEAF (Partial Anytime Focal
search) that can quickly find bounded sub-optimal solutions to minimize the
maximum path length among the agents subject to traversability constraints.
Additionally, the local planner in HEHA also considers heterogeneity to avoid
repeated and duplicated exploration among the robots. The experimental results
show that, our HEHA can reduce up to 30% of the exploration time than the
baselines.

</details>


### [49] [Learning to Capture Rocks using an Excavator: A Reinforcement Learning Approach with Guiding Reward Formulation](https://arxiv.org/abs/2510.04168)
*Amirmasoud Molaei,Reza Ghabcheloo*

Main category: cs.RO

TL;DR: 本研究开发了一种基于强化学习的控制框架，成功应用于岩石捕捉任务，无需明确建模或特殊硬件，显示了基于学习的挖掘策略的可行性。


<details>
  <summary>Details</summary>
Motivation: 现有的自主挖掘方法大多集中于连续介质或依赖专业夹具，限制了其在真实建筑工地的适用性。

Method: 提出了一个完全数据驱动的控制框架，使用无模型强化学习代理通过AGX Dynamics模拟器进行训练，采用近端策略优化（PPO）算法和指导奖励机制。

Result: 通过对岩石几何形状、密度和质量及铲斗、岩石和目标位置的初始配置进行广泛的领域随机化，所学政策在未见岩石和变化的土壤条件下表现良好，与人类参与者的成功率相当，同时保持了机器的稳定性。

Conclusion: 本研究表明，基于学习的挖掘策略能够在无需特殊硬件或详细材料模型的情况下有效处理离散物体的操控，尤其是在岩石捕捉任务中取得成功。

Abstract: Rock capturing with standard excavator buckets is a challenging task
typically requiring the expertise of skilled operators. Unlike soil digging, it
involves manipulating large, irregular rocks in unstructured environments where
complex contact interactions with granular material make model-based control
impractical. Existing autonomous excavation methods focus mainly on continuous
media or rely on specialized grippers, limiting their applicability to
real-world construction sites. This paper introduces a fully data-driven
control framework for rock capturing that eliminates the need for explicit
modeling of rock or soil properties. A model-free reinforcement learning agent
is trained in the AGX Dynamics simulator using the Proximal Policy Optimization
(PPO) algorithm and a guiding reward formulation. The learned policy outputs
joint velocity commands directly to the boom, arm, and bucket of a CAT365
excavator model. Robustness is enhanced through extensive domain randomization
of rock geometry, density, and mass, as well as the initial configurations of
the bucket, rock, and goal position. To the best of our knowledge, this is the
first study to develop and evaluate an RL-based controller for the rock
capturing task. Experimental results show that the policy generalizes well to
unseen rocks and varying soil conditions, achieving high success rates
comparable to those of human participants while maintaining machine stability.
These findings demonstrate the feasibility of learning-based excavation
strategies for discrete object manipulation without requiring specialized
hardware or detailed material models.

</details>


### [50] [VBM-NET: Visual Base Pose Learning for Mobile Manipulation using Equivariant TransporterNet and GNNs](https://arxiv.org/abs/2510.04171)
*Lakshadeep Naik,Adam Fischer,Daniel Duberg,Danica Kragic*

Main category: cs.RO

TL;DR: 本文提出了VBM-NET，一种基于学习的方法，利用自上而下的正交投影进行移动操控中的基座姿态选择，性能相较于经典方法显著提升。


<details>
  <summary>Details</summary>
Motivation: 在移动操控中，选择最佳移动基座姿态对于成功抓取物体至关重要，而现有方法依赖于可靠的状态信息，这在实际应用中可能无法保证。

Method: 提出了一种基于学习的VBM-NET方法，使用自上而下的正交投影进行基座姿态选择，结合等变的TransporterNet和图神经网络。

Result: 通过使用VBM-NET，能够有效学习抓取的候选基座姿态，并通过强化学习找到最佳基座姿态，减少计算时间。

Conclusion: VBM-NET能够在显著减少计算时间的情况下，产生与经典方法相当的解决方案，并成功实现了从模拟到现实的转移。

Abstract: In Mobile Manipulation, selecting an optimal mobile base pose is essential
for successful object grasping. Previous works have addressed this problem
either through classical planning methods or by learning state-based policies.
They assume access to reliable state information, such as the precise object
poses and environment models. In this work, we study base pose planning
directly from top-down orthographic projections of the scene, which provide a
global overview of the scene while preserving spatial structure. We propose
VBM-NET, a learning-based method for base pose selection using such top-down
orthographic projections. We use equivariant TransporterNet to exploit spatial
symmetries and efficiently learn candidate base poses for grasping. Further, we
use graph neural networks to represent a varying number of candidate base poses
and use Reinforcement Learning to determine the optimal base pose among them.
We show that VBM-NET can produce comparable solutions to the classical methods
in significantly less computation time. Furthermore, we validate sim-to-real
transfer by successfully deploying a policy trained in simulation to real-world
mobile manipulation.

</details>


### [51] [Using Robotics to Improve Transcatheter Edge-to-Edge Repair of the Mitral Valve](https://arxiv.org/abs/2510.04178)
*Léa Pistorius,Namrata U. Nayar,Phillip Tran,Sammy Elmariah,Pierre E. Dupont*

Main category: cs.RO

TL;DR: 本研究探讨了机器人在经导管二尖瓣边缘修复中的应用，表明机器人辅助可以显著提高操作效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 经导管瓣膜修复面临显著挑战，尤其是手动导管系统的机械限制和陡峭的学习曲线。

Method: 通过将整体设备输送任务分解为特定动作步骤，在心脏和血管的幽灵模型中分析手动与机器人性能的比较。

Result: 机器系统能够减少程序时间和运动错误，同时提高夹持件放置准确性。

Conclusion: 机械辅助手段有助于克服手动系统的局限性，为复杂的经导管程序提供了更可靠、更用户友好的平台。

Abstract: Transcatheter valve repair presents significant challenges due to the
mechanical limitations and steep learning curve associated with manual catheter
systems. This paper investigates the use of robotics to facilitate
transcatheter procedures in the context of mitral valve edge-to-edge repair.
The complex handle-based control of a clinical repair device is replaced by
intuitive robotic joint-based control via a game controller. Manual versus
robotic performance is analyzed by decomposing the overall device delivery task
into motion-specific steps and comparing capabilities on a step-by-step basis
in a phantom model of the heart and vasculature. Metrics include procedure
duration and clip placement accuracy. Results demonstrate that the robotic
system can reduce procedural time and motion errors while also improving
accuracy of clip placement. These findings suggest that robotic assistance can
address key limitations of manual systems, offering a more reliable and
user-friendly platform for complex transcatheter procedures.

</details>


### [52] [Zenbo Patrol: A Social Assistive Robot Based on Multimodal Deep Learning for Real-time Illegal Parking Recognition and Notification](https://arxiv.org/abs/2510.04190)
*Jian-jie Zheng,Chih-kai Yang,Po-han Chen,Lyn Chao-ling Chen*

Main category: cs.RO

TL;DR: 本研究提出了一种社交机器人，利用GPT-4o多模态模型实现高精度车牌识别，并能够实时通知非法停车情况，具有实际应用潜力。


<details>
  <summary>Details</summary>
Motivation: 旨在解决停车场内的非法停车问题，并提高车牌识别的准确性和实时性。

Method: 采用双模型管道和大型多模态模型进行比较，最终选择了GPT-4o多模态模型进行车牌识别，无需预处理。

Result: 机器人能够自动调整摄像头角度捕捉周围图像，通过GPT-4o模型识别车牌号码，并在发现非法停车后立即发送通知给系统管理员。

Conclusion: 该研究开发了一种社交机器人，能够实时识别和通知非法停车，具有高精度的车牌识别能力，能够在实际场景中应用。

Abstract: In the study, the social robot act as a patrol to recognize and notify
illegal parking in real-time. Dual-model pipeline method and large multimodal
model were compared, and the GPT-4o multimodal model was adopted in license
plate recognition without preprocessing. For moving smoothly on a flat ground,
the robot navigated in a simulated parking lot in the experiments. The robot
changes angle view of the camera automatically to capture the images around
with the format of license plate number. From the captured images of the robot,
the numbers on the plate are recognized through the GPT-4o model, and
identifies legality of the numbers. When an illegal parking is detected, the
robot sends Line messages to the system manager immediately. The contribution
of the work is that a novel multimodal deep learning method has validated with
high accuracy in license plate recognition, and a social assistive robot is
also provided for solving problems in a real scenario, and can be applied in an
indoor parking lot.

</details>


### [53] [Flexible Locomotion Learning with Diffusion Model Predictive Control](https://arxiv.org/abs/2510.04234)
*Runhan Huang,Haldun Balim,Heng Yang,Yilun Du*

Main category: cs.RO

TL;DR: Diffusion-MPC利用学习生成的扩散模型作为近似动态先验，通过奖励与约束优化实现灵活的测试时适应性，证明了在真实环境中的有效性。


<details>
  <summary>Details</summary>
Motivation: 解决模型无关强化学习方法在测试时难以适应新行为的问题，同时克服经典模型预测控制对精确动态模型的依赖。

Method: 通过引入一个交互式训练算法，结合奖励与约束优化，实现对未来状态和动作的预测。

Result: 在真实世界中验证了Diffusion-MPC，展现了强大的运动能力和灵活的适应能力。

Conclusion: Diffusion-MPC 证明了在真实环境中表现出强大的运动能力和灵活的适应性。

Abstract: Legged locomotion demands controllers that are both robust and adaptable,
while remaining compatible with task and safety considerations. However,
model-free reinforcement learning (RL) methods often yield a fixed policy that
can be difficult to adapt to new behaviors at test time. In contrast, Model
Predictive Control (MPC) provides a natural approach to flexible behavior
synthesis by incorporating different objectives and constraints directly into
its optimization process. However, classical MPC relies on accurate dynamics
models, which are often difficult to obtain in complex environments and
typically require simplifying assumptions. We present Diffusion-MPC, which
leverages a learned generative diffusion model as an approximate dynamics prior
for planning, enabling flexible test-time adaptation through reward and
constraint based optimization. Diffusion-MPC jointly predicts future states and
actions; at each reverse step, we incorporate reward planning and impose
constraint projection, yielding trajectories that satisfy task objectives while
remaining within physical limits. To obtain a planning model that adapts beyond
imitation pretraining, we introduce an interactive training algorithm for
diffusion based planner: we execute our reward-and-constraint planner in
environment, then filter and reweight the collected trajectories by their
realized returns before updating the denoiser. Our design enables strong
test-time adaptability, allowing the planner to adjust to new reward
specifications without retraining. We validate Diffusion-MPC on real world,
demonstrating strong locomotion and flexible adaptation.

</details>


### [54] [ContextVLA: Vision-Language-Action Model with Amortized Multi-Frame Context](https://arxiv.org/abs/2510.04246)
*Huiwon Jang,Sihyun Yu,Heeseung Kwon,Hojin Jeon,Younggyo Seo,Jinwoo Shin*

Main category: cs.RO

TL;DR: ContextVLA是一种新型的策略模型，通过压缩过去的观察为单一上下文标记，提高了机器人任务中多帧观察的利用效率，从而提升了性能，并减少了训练和推理时间。


<details>
  <summary>Details</summary>
Motivation: 在部分可观察的机器人任务中，利用时间上下文对于成功至关重要。采用多帧观察的行为克隆研究表明性能提升的不一致性，因此需要找到更有效的方法来利用多帧观察。

Method: ContextVLA通过将多个过去的观察压缩为一个上下文标记，使得策略能够高效地利用时间上下文来生成动作。

Result: 提出了ContextVLA模型，它通过有效利用多帧观察显著提高了机器人任务的性能。

Conclusion: 实验表明，ContextVLA在多帧训练时比单帧VLA持续改善，并且在效率上具有明显优势。

Abstract: Leveraging temporal context is crucial for success in partially observable
robotic tasks. However, prior work in behavior cloning has demonstrated
inconsistent performance gains when using multi-frame observations. In this
paper, we introduce ContextVLA, a policy model that robustly improves robotic
task performance by effectively leveraging multi-frame observations. Our
approach is motivated by the key observation that Vision-Language-Action models
(VLA), i.e., policy models built upon a Vision-Language Model (VLM), more
effectively utilize multi-frame observations for action generation. This
suggests that VLMs' inherent temporal understanding capability enables them to
extract more meaningful context from multi-frame observations. However, the
high dimensionality of video inputs introduces significant computational
overhead, making VLA training and inference inefficient. To address this,
ContextVLA compresses past observations into a single context token, allowing
the policy to efficiently leverage temporal context for action generation. Our
experiments show that ContextVLA consistently improves over single-frame VLAs
and achieves the benefits of full multi-frame training but with reduced
training and inference times.

</details>


### [55] [Integrated Planning and Control on Manifolds: Factor Graph Representation and Toolkit](https://arxiv.org/abs/2510.04278)
*Peiwen Yang,Weisong Wen,Runqiu Yang,Yuanyuan Zhang,Jiahao Hu,Yingming Chen,Naigui Xiao,Jiaqi Zhao*

Main category: cs.RO

TL;DR: FactorMPC是一种专为非线性流形设计的模型预测控制工具，提升了高维系统的实时性能，解决了传统方法的不足。


<details>
  <summary>Details</summary>
Motivation: 解决传统欧几里得方法在非线性流形系统（如机器人姿态动力学和受约束运动规划）中的局限性，包括奇异性、参数过多和收敛性差的问题。

Method: 提出了一种基于因子图的模型预测控制工具包FactorMPC，该工具包整合了系统动态、约束和目标，具备模块化和用户友好的优化结构。

Result: 在四旋翼仿真和实验中，FactorMPC显示出比基线方法更优的轨迹跟踪和避障性能。

Conclusion: FactorMPC提供了一种统一的框架，用于在非欧几里得空间中进行模型预测控制，显示出优越的路径跟踪和避障性能。

Abstract: Model predictive control (MPC) faces significant limitations when applied to
systems evolving on nonlinear manifolds, such as robotic attitude dynamics and
constrained motion planning, where traditional Euclidean formulations struggle
with singularities, over-parameterization, and poor convergence. To overcome
these challenges, this paper introduces FactorMPC, a factor-graph based MPC
toolkit that unifies system dynamics, constraints, and objectives into a
modular, user-friendly, and efficient optimization structure. Our approach
natively supports manifold-valued states with Gaussian uncertainties modeled in
tangent spaces. By exploiting the sparsity and probabilistic structure of
factor graphs, the toolkit achieves real-time performance even for
high-dimensional systems with complex constraints. The velocity-extended
on-manifold control barrier function (CBF)-based obstacle avoidance factors are
designed for safety-critical applications. By bridging graphical models with
safety-critical MPC, our work offers a scalable and geometrically consistent
framework for integrated planning and control. The simulations and experimental
results on the quadrotor demonstrate superior trajectory tracking and obstacle
avoidance performance compared to baseline methods. To foster research
reproducibility, we have provided open-source implementation offering
plug-and-play factors.

</details>


### [56] [Stability-Aware Retargeting for Humanoid Multi-Contact Teleoperation](https://arxiv.org/abs/2510.04353)
*Stephen McCrory,Romeo Orsolino,Dhruv Thanki,Luigi Penco,Robert Griffin*

Main category: cs.RO

TL;DR: 提出了一种新方法，通过动态调整接触点和姿态来提高人形机器人的遥操作稳定性，验证了其在仿真和硬件的有效性。


<details>
  <summary>Details</summary>
Motivation: 在手接触和非共面表面情况下，遥操作面临转矩饱和和稳定性丧失的挑战。

Method: 提出了一种动态调整接触点和姿态的质心稳定性重定向方法，利用稳定性边际梯度的高效分析计算。

Result: 通过仿真和硬件验证，显示出在遥操作任务中，稳定性边际得到增强，且高级稳定性边际与提升的冲击韧性和关节转矩边际存在相关性。

Conclusion: 本研究提出的基于质心稳定性的重定向方法能在复杂环境中显著提高人形机器人的稳定性。

Abstract: Teleoperation is a powerful method to generate reference motions and enable
humanoid robots to perform a broad range of tasks. However, teleoperation
becomes challenging when using hand contacts and non-coplanar surfaces, often
leading to motor torque saturation or loss of stability through slipping. We
propose a centroidal stability-based retargeting method that dynamically
adjusts contact points and posture during teleoperation to enhance stability in
these difficult scenarios. Central to our approach is an efficient analytical
calculation of the stability margin gradient. This gradient is used to identify
scenarios for which stability is highly sensitive to teleoperation setpoints
and inform the local adjustment of these setpoints. We validate the framework
in simulation and hardware by teleoperating manipulation tasks on a humanoid,
demonstrating increased stability margins. We also demonstrate empirically that
higher stability margins correlate with improved impulse resilience and joint
torque margin.

</details>


### [57] [Reliable and Scalable Robot Policy Evaluation with Imperfect Simulators](https://arxiv.org/abs/2510.04354)
*Apurva Badithela,David Snyder,Lihan Zha,Joseph Mikhail,Matthew O'Kelly,Anushri Dixit,Anirudha Majumdar*

Main category: cs.RO

TL;DR: SureSim框架通过结合小规模现实测试与大规模模拟，提高了机器人操作策略的评估可靠性，并显著减少了硬件测试的需求。


<details>
  <summary>Details</summary>
Motivation: 随着模仿学习、基础模型和大规模数据集的快速进展，机器人的操作策略需要在不同任务和环境中广泛通用，但目前对这些策略的评估缺乏统计保证。

Method: 该研究采用了融合现实与模拟评估的方法，通过小规模的配对评估来纠正大规模模拟中的偏差，并使用非渐近均值估计算法提供政策性能的置信区间。

Result: 使用物理基础的模拟评估扩散策略和多任务微调的 \\(	ext{π}_0\\) 策略，发现该方法将硬件评估工作量减少了20-25%，同时在政策性能上达到了类似的界限。

Conclusion: SureSim框架通过结合小规模的现实世界测试和大规模模拟，为机器人操作策略的现实性能提供了可靠的推断，显著降低了硬件评估的投入。

Abstract: Rapid progress in imitation learning, foundation models, and large-scale
datasets has led to robot manipulation policies that generalize to a wide-range
of tasks and environments. However, rigorous evaluation of these policies
remains a challenge. Typically in practice, robot policies are often evaluated
on a small number of hardware trials without any statistical assurances. We
present SureSim, a framework to augment large-scale simulation with relatively
small-scale real-world testing to provide reliable inferences on the real-world
performance of a policy. Our key idea is to formalize the problem of combining
real and simulation evaluations as a prediction-powered inference problem, in
which a small number of paired real and simulation evaluations are used to
rectify bias in large-scale simulation. We then leverage non-asymptotic mean
estimation algorithms to provide confidence intervals on mean policy
performance. Using physics-based simulation, we evaluate both diffusion policy
and multi-task fine-tuned \(\pi_0\) on a joint distribution of objects and
initial conditions, and find that our approach saves over \(20-25\%\) of
hardware evaluation effort to achieve similar bounds on policy performance.

</details>


### [58] [PAD-TRO: Projection-Augmented Diffusion for Direct Trajectory Optimization](https://arxiv.org/abs/2510.04436)
*Jushan Chen,Santiago Paternain*

Main category: cs.RO

TL;DR: 本研究提出了一种直接轨迹优化方法，利用模型基础的扩散技术解决动态可行性问题，显著提高了导航任务的成功率。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在轨迹优化中的应用受到关注，但解决非线性等式约束（动态可行性）仍然是一大挑战。

Method: 通过基于模型的扩散直接生成一系列状态，并引入无梯度投影机制以确保动态可行性。

Result: 与最新的基准方法相比，提出的方法在四旋翼航路导航场景中实现了零动态可行性错误和约4倍的成功率提高。

Conclusion: 本研究提出的基于模型的扩散直接轨迹优化方法在四旋翼导航场景中实现了零动态可行性错误，并显著提高了成功率。

Abstract: Recently, diffusion models have gained popularity and attention in trajectory
optimization due to their capability of modeling multi-modal probability
distributions. However, addressing nonlinear equality constraints, i.e, dynamic
feasi- bility, remains a great challenge in diffusion-based trajectory
optimization. Recent diffusion-based trajectory optimization frameworks rely on
a single-shooting style approach where the denoised control sequence is applied
to forward propagate the dynamical system, which cannot explicitly enforce
constraints on the states and frequently leads to sub-optimal solutions. In
this work, we propose a novel direct trajectory optimization approach via
model-based diffusion, which directly generates a sequence of states. To ensure
dynamic feasibility, we propose a gradient-free projection mechanism that is
incorporated into the reverse diffusion process. Our results show that,
compared to a recent state-of-the-art baseline, our approach leads to zero
dynamic feasibility error and approximately 4x higher success rate in a
quadrotor waypoint navigation scenario involving dense static obstacles.

</details>


### [59] [Velocity-Form Data-Enabled Predictive Control of Soft Robots under Unknown External Payloads](https://arxiv.org/abs/2510.04509)
*Huanqing Wang,Kaixiang Zhang,Kyungjoon Lee,Yu Mei,Vaibhav Srivastava,Jun Sheng,Ziyou Song,Zhaojian Li*

Main category: cs.RO

TL;DR: 提出了一种新的速度形式DeePC框架，有效应对未知负载对软机器人控制性能的影响。


<details>
  <summary>Details</summary>
Motivation: 在物体操作任务中，未知的外部负载和扰动会显著改变系统动力学和行为，导致偏差和控制性能降低。

Method: 提出一种新的速度形式DeePC框架来实现软机器人的鲁棒控制和最优控制。

Result: 通过增量表示利用输入输出数据来减轻由未知负载引起的性能下降，并在平面软机器人上进行实验验证，结果优于标准DeePC。

Conclusion: 新框架有效提升了软机器人在未知负载情况下的控制性能，展示了比标准DeePC更优异的效果。

Abstract: Data-driven control methods such as data-enabled predictive control (DeePC)
have shown strong potential in efficient control of soft robots without
explicit parametric models. However, in object manipulation tasks, unknown
external payloads and disturbances can significantly alter the system dynamics
and behavior, leading to offset error and degraded control performance. In this
paper, we present a novel velocity-form DeePC framework that achieves robust
and optimal control of soft robots under unknown payloads. The proposed
framework leverages input-output data in an incremental representation to
mitigate performance degradation induced by unknown payloads, eliminating the
need for weighted datasets or disturbance estimators. We validate the method
experimentally on a planar soft robot and demonstrate its superior performance
compared to standard DeePC in scenarios involving unknown payloads.

</details>


### [60] [Everything-Grasping (EG) Gripper: A Universal Gripper with Synergistic Suction-Grasping Capabilities for Cross-Scale and Cross-State Manipulation](https://arxiv.org/abs/2510.04585)
*Jianshu Zhou,Jing Shu,Tianle Pan,Puchen Zhu,Jiajun An,Huayu Zhang,Junda Huang,Upinder Kaur,Xin Ma,Masayoshi Tomizuka*

Main category: cs.RO

TL;DR: 提出了一种新型EG夹持器，能有效处理不同尺寸和状态的物体，首次实现统一抓取。


<details>
  <summary>Details</summary>
Motivation: 在软机器人领域，如何有效抓取不同尺寸和物态的对象仍然是一个基本挑战。

Method: EG夹持器采用分布式表面吸附与内部颗粒堵塞的结合，并使用触觉感知框架进行实物检测和反馈。

Result: EG夹持器可以处理从0.2 mm2到62,000 mm2的对象，展示了良好的操作性能。

Conclusion: EG夹持器是首个能够统一处理不同规模和物态对象的软抓手，具有良好的重复性和可靠性。

Abstract: Grasping objects across vastly different sizes and physical states-including
both solids and liquids-with a single robotic gripper remains a fundamental
challenge in soft robotics. We present the Everything-Grasping (EG) Gripper, a
soft end-effector that synergistically integrates distributed surface suction
with internal granular jamming, enabling cross-scale and cross-state
manipulation without requiring airtight sealing at the contact interface with
target objects. The EG Gripper can handle objects with surface areas ranging
from sub-millimeter scale 0.2 mm2 (glass bead) to over 62,000 mm2 (A4 sized
paper and woven bag), enabling manipulation of objects nearly 3,500X smaller
and 88X larger than its own contact area (approximated at 707 mm2 for a 30
mm-diameter base). We further introduce a tactile sensing framework that
combines liquid detection and pressure-based suction feedback, enabling
real-time differentiation between solid and liquid targets. Guided by the
actile-Inferred Grasping Mode Selection (TIGMS) algorithm, the gripper
autonomously selects grasping modes based on distributed pressure and voltage
signals. Experiments across diverse tasks-including underwater grasping,
fragile object handling, and liquid capture-demonstrate robust and repeatable
performance. To our knowledge, this is the first soft gripper to reliably grasp
both solid and liquid objects across scales using a unified compliant
architecture.

</details>


### [61] [MobRT: A Digital Twin-Based Framework for Scalable Learning in Mobile Manipulation](https://arxiv.org/abs/2510.04592)
*Yilin Mei,Peng Qiu,Wei Zhang,WenChao Zhang,Wenjie Song*

Main category: cs.RO

TL;DR: MobRT框架通过模拟复杂任务，改善移动操纵器的学习效果，提升策略泛化和性能


<details>
  <summary>Details</summary>
Motivation: 解决移动操纵器在动态和部分可观察环境中收集高质量演示数据的挑战

Method: 提出MobRT框架，模拟复杂的全身任务

Result: MobRT通过虚拟运动控制和全身运动规划生成多样且真实的演示，评估成果显示成功率与生成轨迹数量呈强相关

Conclusion: MobRT显著提高了策略的泛化能力和在模拟及现实环境中的表现。

Abstract: Recent advances in robotics have been largely driven by imitation learning,
which depends critically on large-scale, high-quality demonstration data.
However, collecting such data remains a significant challenge-particularly for
mobile manipulators, which must coordinate base locomotion and arm manipulation
in high-dimensional, dynamic, and partially observable environments.
Consequently, most existing research remains focused on simpler tabletop
scenarios, leaving mobile manipulation relatively underexplored. To bridge this
gap, we present \textit{MobRT}, a digital twin-based framework designed to
simulate two primary categories of complex, whole-body tasks: interaction with
articulated objects (e.g., opening doors and drawers) and mobile-base
pick-and-place operations. \textit{MobRT} autonomously generates diverse and
realistic demonstrations through the integration of virtual kinematic control
and whole-body motion planning, enabling coherent and physically consistent
execution. We evaluate the quality of \textit{MobRT}-generated data across
multiple baseline algorithms, establishing a comprehensive benchmark and
demonstrating a strong correlation between task success and the number of
generated trajectories. Experiments integrating both simulated and real-world
demonstrations confirm that our approach markedly improves policy
generalization and performance, achieving robust results in both simulated and
real-world environments.

</details>


### [62] [OKVIS2-X: Open Keyframe-based Visual-Inertial SLAM Configurable with Dense Depth or LiDAR, and GNSS](https://arxiv.org/abs/2510.04612)
*Simon Boche,Jaehyung Jung,Sebastián Barbas Laina,Stefan Leutenegger*

Main category: cs.RO

TL;DR: OKVIS2-X是一个高效的多传感器SLAM系统，通过整合多种传感器实现了实时地图构建和精确定位，适用于大规模环境。


<details>
  <summary>Details</summary>
Motivation: 为了提高移动机器人在大环境中的地图实用性以及状态估计的准确性和鲁棒性。

Method: 通过整合视觉、惯性、深度、LiDAR和GNSS等多种传感器模态，采用高效的子地图策略进行实时SLAM。

Result: OKVIS2-X在EuRoC基准中实现最高轨迹准确性，在Hilti22 VI单一基准测试中超越所有竞争对手，并在VBR数据集的多样化和大规模序列中展现出先进的精度。

Conclusion: OKVIS2-X在多个基准测试中表现优异，达到了最高的轨迹准确性，并能生成全球一致的地图，适用于自主导航。

Abstract: To empower mobile robots with usable maps as well as highest state estimation
accuracy and robustness, we present OKVIS2-X: a state-of-the-art multi-sensor
Simultaneous Localization and Mapping (SLAM) system building dense volumetric
occupancy maps, while scalable to large environments and operating in realtime.
Our unified SLAM framework seamlessly integrates different sensor modalities:
visual, inertial, measured or learned depth, LiDAR and Global Navigation
Satellite System (GNSS) measurements. Unlike most state-of-the-art SLAM
systems, we advocate using dense volumetric map representations when leveraging
depth or range-sensing capabilities. We employ an efficient submapping strategy
that allows our system to scale to large environments, showcased in sequences
of up to 9 kilometers. OKVIS2-X enhances its accuracy and robustness by
tightly-coupling the estimator and submaps through map alignment factors. Our
system provides globally consistent maps, directly usable for autonomous
navigation. To further improve the accuracy of OKVIS2-X, we also incorporate
the option of performing online calibration of camera extrinsics. Our system
achieves the highest trajectory accuracy in EuRoC against state-of-the-art
alternatives, outperforms all competitors in the Hilti22 VI-only benchmark,
while also proving competitive in the LiDAR version, and showcases state of the
art accuracy in the diverse and large-scale sequences from the VBR dataset.

</details>


### [63] [Bio-Inspired Robotic Houbara: From Development to Field Deployment for Behavioral Studies](https://arxiv.org/abs/2510.04692)
*Lyes Saad Saoud,Irfan Hussain*

Main category: cs.RO

TL;DR: 本研究介绍了一种新一代生物启发式机器人平台，通过精确的制造流程和智能感知，支持鸟类行为研究和生态保护。


<details>
  <summary>Details</summary>
Motivation: 为支持控制的动物行为研究和以保护为导向的野外研究，创建一种模仿雌性胡巴鸨的生物启发式机器人平台。

Method: 通过高分辨率结构光3D扫描、参数化CAD建模、关节3D打印以及逼真的UV纹理乙烯基表面处理，创建了一种仿生机器人平台。

Result: 在沙漠鸟类保护区进行的实地试验中，该平台在极端户外条件下展示了可靠的实时操作能力，并能够刺激活胡巴鸨的自然识别和互动反应。

Conclusion: 该平台为动物机器人互动研究、保护机器人技术和公众参与提供了可转移的蓝图。

Abstract: Biomimetic intelligence and robotics are transforming field ecology by
enabling lifelike robotic surrogates that interact naturally with animals under
real world conditions. Studying avian behavior in the wild remains challenging
due to the need for highly realistic morphology, durable outdoor operation, and
intelligent perception that can adapt to uncontrolled environments. We present
a next generation bio inspired robotic platform that replicates the morphology
and visual appearance of the female Houbara bustard to support controlled
ethological studies and conservation oriented field research. The system
introduces a fully digitally replicable fabrication workflow that combines high
resolution structured light 3D scanning, parametric CAD modelling, articulated
3D printing, and photorealistic UV textured vinyl finishing to achieve
anatomically accurate and durable robotic surrogates. A six wheeled rocker
bogie chassis ensures stable mobility on sand and irregular terrain, while an
embedded NVIDIA Jetson module enables real time RGB and thermal perception,
lightweight YOLO based detection, and an autonomous visual servoing loop that
aligns the robot's head toward detected targets without human intervention. A
lightweight thermal visible fusion module enhances perception in low light
conditions. Field trials in desert aviaries demonstrated reliable real time
operation at 15 to 22 FPS with latency under 100 ms and confirmed that the
platform elicits natural recognition and interactive responses from live
Houbara bustards under harsh outdoor conditions. This integrated framework
advances biomimetic field robotics by uniting reproducible digital fabrication,
embodied visual intelligence, and ecological validation, providing a
transferable blueprint for animal robot interaction research, conservation
robotics, and public engagement.

</details>


### [64] [Building Gradient by Gradient: Decentralised Energy Functions for Bimanual Robot Assembly](https://arxiv.org/abs/2510.04696)
*Alexander L. Mitchell,Joe Watson,Ingmar Posner*

Main category: cs.RO

TL;DR: 提出了一种新型去中心化的快速重规划框架，旨在解决双手组装中的任务规划复杂性，展示了优越的灵活性和适应性。


<details>
  <summary>Details</summary>
Motivation: 现有的TAMP方法在面对动态困难时反应缓慢，缺乏灵活性，本文旨在提高调整任务序列的便利性并减少规划复杂性。

Method: 通过使用分段连续的能量函数和自适应潜力功能的自动组合，基于局部优化而非长远规划生成子目标。

Result: 本文提出了一种去中心化的基于梯度的框架，用于简化双手组装中的任务和运动规划（TAMP）过程，特别是在应对动态干扰和重新规划时，其方法通过自适应潜力功能的自动组合生成局部目标，展示了在物理双手组装任务中的有效性，能够进行自动重试、协调动作和自主交接。

Conclusion: 我们的方法有效解决了紧公差组装中的双手协调和重规划问题，显示出良好的适应性和执行力。

Abstract: There are many challenges in bimanual assembly, including high-level
sequencing, multi-robot coordination, and low-level, contact-rich operations
such as component mating. Task and motion planning (TAMP) methods, while
effective in this domain, may be prohibitively slow to converge when adapting
to disturbances that require new task sequencing and optimisation. These events
are common during tight-tolerance assembly, where difficult-to-model dynamics
such as friction or deformation require rapid replanning and reattempts.
Moreover, defining explicit task sequences for assembly can be cumbersome,
limiting flexibility when task replanning is required. To simplify this
planning, we introduce a decentralised gradient-based framework that uses a
piecewise continuous energy function through the automatic composition of
adaptive potential functions. This approach generates sub-goals using only
myopic optimisation, rather than long-horizon planning. It demonstrates
effectiveness at solving long-horizon tasks due to the structure and adaptivity
of the energy function. We show that our approach scales to physical bimanual
assembly tasks for constructing tight-tolerance assemblies. In these
experiments, we discover that our gradient-based rapid replanning framework
generates automatic retries, coordinated motions and autonomous handovers in an
emergent fashion.

</details>


### [65] [Performance-guided Task-specific Optimization for Multirotor Design](https://arxiv.org/abs/2510.04724)
*Etor Arza,Welf Rehberg,Philipp Weiss,Mihir Kulkarni,Kostas Alexis*

Main category: cs.RO

TL;DR: 本文提出了一种基于强化学习和贝叶斯优化的多旋翼飞行器任务特定设计优化方法，结果显示优化设计在复杂任务中显著优于传统配置。


<details>
  <summary>Details</summary>
Motivation: 为多旋翼微型飞行器提供任务特定的设计优化方法，以提高其在特定任务中的性能。

Method: 结合强化学习、贝叶斯优化和协方差矩阵适应进化策略，系统探索电机姿态配置的设计空间，同时考虑可制造性约束。

Result: 优化设计在敏捷航点导航任务中表现优越，超越传统多旋翼配置及文献中的完全驱动设计。

Conclusion: 优化设计在实际测试中验证了其从仿真到现实的可转移性。

Abstract: This paper introduces a methodology for task-specific design optimization of
multirotor Micro Aerial Vehicles. By leveraging reinforcement learning,
Bayesian optimization, and covariance matrix adaptation evolution strategy, we
optimize aerial robot designs guided exclusively by their closed-loop
performance in a considered task. Our approach systematically explores the
design space of motor pose configurations while ensuring manufacturability
constraints and minimal aerodynamic interference. Results demonstrate that
optimized designs achieve superior performance compared to conventional
multirotor configurations in agile waypoint navigation tasks, including against
fully actuated designs from the literature. We build and test one of the
optimized designs in the real world to validate the sim2real transferability of
our approach.

</details>


### [66] [Online automatic code generation for robot swarms: LLMs and self-organizing hierarchy](https://arxiv.org/abs/2510.04774)
*Weixu Zhu,Marco Dorigo,Mary Katherine Heinrich*

Main category: cs.RO

TL;DR: 自组织神经系统(SoNS)提升机器人群体的行为设计与环境估计，演示了85%的任务成功率。


<details>
  <summary>Details</summary>
Motivation: 为机器人群提供行为设计的简便性和对群体配置及环境的全局估计，以实现在线自动代码生成。

Method: 通过6台真实机器人和超过30台机器人的仿真试验进行演示。

Result: 在实践中，SoNS增强的机器人群在卡住时自动生成并执行代码，成功完成任务。

Conclusion: SoNS增强的机器人群在遇到障碍时能够请求外部LLM实时生成并运行代码，成功率达到85%。

Abstract: Our recently introduced self-organizing nervous system (SoNS) provides robot
swarms with 1) ease of behavior design and 2) global estimation of the swarm
configuration and its collective environment, facilitating the implementation
of online automatic code generation for robot swarms. In a demonstration with 6
real robots and simulation trials with >30 robots, we show that when a
SoNS-enhanced robot swarm gets stuck, it can automatically solicit and run code
generated by an external LLM on the fly, completing its mission with an 85%
success rate.

</details>


### [67] [TAG-K: Tail-Averaged Greedy Kaczmarz for Computationally Efficient and Performant Online Inertial Parameter Estimation](https://arxiv.org/abs/2510.04839)
*Shuo Sha,Anupam Bhakta,Zhenyuan Jiang,Kevin Qiu,Ishaan Mahajan,Gabriel Bravo,Brian Plancher*

Main category: cs.RO

TL;DR: TAG-K是一种新的在线参数估计方法，显著提高了速度和精度，适用于动态环境中的机器人控制。


<details>
  <summary>Details</summary>
Motivation: 开发更有效的在线惯性参数估计方法，以应对传统方法在动态环境中的局限性，尤其是突发参数变化和高计算成本。

Method: 采用轻量级的Kaczmarz方法扩展，通过贪婪随机行选择实现快速收敛，同时结合尾平均以增强抗噪声和不一致性能力。

Result: TAG-K在笔记本电脑和嵌入式微控制器上实现了1.5x-1.9x和4.8x-20.7x的求解时间加速，并且在测量噪声和估计误差方面表现出更好的鲁棒性。

Conclusion: TAG-K在动态环境下提供了快速而稳定的参数适应，显著提高了跟踪性能。

Abstract: Accurate online inertial parameter estimation is essential for adaptive
robotic control, enabling real-time adjustment to payload changes,
environmental interactions, and system wear. Traditional methods such as
Recursive Least Squares (RLS) and the Kalman Filter (KF) often struggle to
track abrupt parameter shifts or incur high computational costs, limiting their
effectiveness in dynamic environments and for computationally constrained
robotic systems. As such, we introduce TAG-K, a lightweight extension of the
Kaczmarz method that combines greedy randomized row selection for rapid
convergence with tail averaging for robustness under noise and inconsistency.
This design enables fast, stable parameter adaptation while retaining the low
per-iteration complexity inherent to the Kaczmarz framework. We evaluate TAG-K
in synthetic benchmarks and quadrotor tracking tasks against RLS, KF, and other
Kaczmarz variants. TAG-K achieves 1.5x-1.9x faster solve times on laptop-class
CPUs and 4.8x-20.7x faster solve times on embedded microcontrollers. More
importantly, these speedups are paired with improved resilience to measurement
noise and a 25% reduction in estimation error, leading to nearly 2x better
end-to-end tracking performance.

</details>


### [68] [CLEAR-IR: Clarity-Enhanced Active Reconstruction of Infrared Imagery](https://arxiv.org/abs/2510.04883)
*Nathan Shankar,Pawel Ladosz,Hujun Yin*

Main category: cs.RO

TL;DR: 提出了一种新颖的方法，通过红外流增强机器人在黑暗环境中的感知能力。


<details>
  <summary>Details</summary>
Motivation: 为了解决低光条件下RGB流受噪声影响大，而红外流受发射器模式主导的问题。

Method: 采用基于U-Net的架构，从充满发射器的输入重建干净的红外图像。

Result: 显著提升了图像质量和后续机器人的性能。

Conclusion: 该方法优于现有的增强技术，能够在从明亮到极低光照条件下，实现视觉驱动的机器人系统的可靠操作。

Abstract: This paper presents a novel approach for enabling robust robotic perception
in dark environments using infrared (IR) stream. IR stream is less susceptible
to noise than RGB in low-light conditions. However, it is dominated by active
emitter patterns that hinder high-level tasks such as object detection,
tracking and localisation. To address this, a U-Net-based architecture is
proposed that reconstructs clean IR images from emitter-populated input,
improving both image quality and downstream robotic performance. This approach
outperforms existing enhancement techniques and enables reliable operation of
vision-driven robotic systems across illumination conditions from well-lit to
extreme low-light scenes.

</details>


### [69] [HyperVLA: Efficient Inference in Vision-Language-Action Models via Hypernetworks](https://arxiv.org/abs/2510.04898)
*Zheng Xiong,Kang Li,Zilin Wang,Matthew Jackson,Jakob Foerster,Shimon Whiteson*

Main category: cs.RO

TL;DR: HyperVLA通过基于超网络的架构，显著降低推理成本，同时提高了零样本和少样本学习的成功率。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言动作模型推理成本极高，限制了其实际应用。

Method: 提出了一种基于超网络的架构，仅在推理时激活特定任务的策略，同时在训练时保持高模型能力，包含多个关键算法设计特性。

Result: HyperVLA相较于现有模型，在测试时减少了90倍的激活参数，并加速了120倍的推理速度。

Conclusion: HyperVLA在保证高效性能的同时，显著降低了推理成本，提高了零样本和少样本适应能力。

Abstract: Built upon language and vision foundation models with strong generalization
ability and trained on large-scale robotic data, Vision-Language-Action (VLA)
models have recently emerged as a promising approach to learning generalist
robotic policies. However, a key drawback of existing VLAs is their extremely
high inference costs. In this paper, we propose HyperVLA to address this
problem. Unlike existing monolithic VLAs that activate the whole model during
both training and inference, HyperVLA uses a novel hypernetwork (HN)-based
architecture that activates only a small task-specific policy during inference,
while still retaining the high model capacity needed to accommodate diverse
multi-task behaviors during training. Successfully training an HN-based VLA is
nontrivial so HyperVLA contains several key algorithm design features that
improve its performance, including properly utilizing the prior knowledge from
existing vision foundation models, HN normalization, and an action generation
strategy. Compared to monolithic VLAs, HyperVLA achieves a similar or even
higher success rate for both zero-shot generalization and few-shot adaptation,
while significantly reducing inference costs. Compared to OpenVLA, a
state-of-the-art VLA model, HyperVLA reduces the number of activated parameters
at test time by $90\times$, and accelerates inference speed by $120\times$.
Code is publicly available at https://github.com/MasterXiong/HyperVLA

</details>


### [70] [Efficient Navigation in Unknown Indoor Environments with Vision-Language Models](https://arxiv.org/abs/2510.04991)
*D. Schwartz,K. Kondo,J. P. How*

Main category: cs.RO

TL;DR: 提出了一种利用视觉语言模型改进未知室内环境导航效率的新框架，通过直接推理占据图来选择更有效的路径。


<details>
  <summary>Details</summary>
Motivation: 传统探测方法由于局限性和依赖局部启发式，通常采取低效路径，而本研究旨在提高规划的全球推理能力，从而优化导航过程。

Method: 将3D占据网转换为环境的部分2D地图，生成候选子目标，并由模型对这些子目标进行评估和排序。

Result: 本研究提出了一种新的高层次规划框架，通过利用视觉语言模型（VLMs）来提高在未知室内环境中自主导航的效率。

Conclusion: 通过将这一规划方案集成到现有的轨迹规划器DYNUS中，模拟实验表明导航效率显著提升，路径平均缩短约10%。

Abstract: We present a novel high-level planning framework that leverages
vision-language models (VLMs) to improve autonomous navigation in unknown
indoor environments with many dead ends. Traditional exploration methods often
take inefficient routes due to limited global reasoning and reliance on local
heuristics. In contrast, our approach enables a VLM to reason directly about an
occupancy map in a zero-shot manner, selecting subgoals that are likely to lead
to more efficient paths. At each planning step, we convert a 3D occupancy grid
into a partial 2D map of the environment, and generate candidate subgoals. Each
subgoal is then evaluated and ranked against other candidates by the model. We
integrate this planning scheme into DYNUS \cite{kondo2025dynus}, a
state-of-the-art trajectory planner, and demonstrate improved navigation
efficiency in simulation. The VLM infers structural patterns (e.g., rooms,
corridors) from incomplete maps and balances the need to make progress toward a
goal against the risk of entering unknown space. This reduces common greedy
failures (e.g., detouring into small rooms) and achieves about 10\% shorter
paths on average.

</details>


### [71] [Walking, Rolling, and Beyond: First-Principles and RL Locomotion on a TARS-Inspired Robot](https://arxiv.org/abs/2510.05001)
*Aditya Sripada,Abhishek Warrier*

Main category: cs.RO

TL;DR: TARS3D是一种新的机器人平台，结合了分析和强化学习，能实现多种创新的运动模式，展示了生物启发设计的潜力和未来的探索空间。


<details>
  <summary>Details</summary>
Motivation: 机器人运动研究通常受生物启发的腿部设计影响，但许多人造环境也可以受益于非类人形式。

Method: 为TARS3D建立低阶模型，推导闭合形式极限循环条件，并在硬件上验证预测结果，同时使用深度强化学习（DRL）进行模拟探索。

Result: 实验验证了TARS3D的运动能力，包括在滚动模式下维持八步混合极限循环，且发现了可以恢复分析轨迹和探索新行为的学习策略。

Conclusion: TARS3D机器人通过结合分析合成和强化学习，展现了多种未曾探索的运动模式，未来的学习驱动搜索可能会揭示更多运动方式。

Abstract: Robotic locomotion research typically draws from biologically inspired leg
designs, yet many human-engineered settings can benefit from
non-anthropomorphic forms. TARS3D translates the block-shaped 'TARS' robot from
Interstellar into a 0.25 m, 0.99 kg research platform with seven actuated
degrees of freedom. The film shows two primary gaits: a bipedal-like walk and a
high-speed rolling mode. For TARS3D, we build reduced-order models for each,
derive closed-form limit-cycle conditions, and validate the predictions on
hardware. Experiments confirm that the robot respects its +/-150 degree hip
limits, alternates left-right contacts without interference, and maintains an
eight-step hybrid limit cycle in rolling mode. Because each telescopic leg
provides four contact corners, the rolling gait is modeled as an eight-spoke
double rimless wheel. The robot's telescopic leg redundancy implies a far
richer gait repertoire than the two limit cycles treated analytically. So, we
used deep reinforcement learning (DRL) in simulation to search the unexplored
space. We observed that the learned policy can recover the analytic gaits under
the right priors and discover novel behaviors as well. Our findings show that
TARS3D's fiction-inspired bio-transcending morphology can realize multiple
previously unexplored locomotion modes and that further learning-driven search
is likely to reveal more. This combination of analytic synthesis and
reinforcement learning opens a promising pathway for multimodal robotics.

</details>


### [72] [StaMo: Unsupervised Learning of Generalizable Robot Motion from Compact State Representation](https://arxiv.org/abs/2510.05057)
*Mingyu Liu,Jiuhe Shu,Hui Chen,Zeju Li,Canyu Zhao,Jiange Yang,Shenyuan Gao,Hao Chen,Chunhua Shen*

Main category: cs.RO

TL;DR: 本研究提出了一种高效的无监督状态表示学习方法StaMo，显著提升了机器人任务的表现和可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在状态表示中存在的冗余与缺乏关键任务信息的平衡问题，以提高机器人的世界建模和决策能力。

Method: 使用无监督学习的方法，结合轻量级编码器和预训练的扩散变换器解码器，学习高压缩的状态表示。

Result: 该研究提出了一种无监督的方法StaMo，利用轻量级编码器和预训练的扩散变换器（DiT）解码器，学习高压缩的双标记状态表示，以提高世界建模和决策制定的效率。实验表明，该方法在LIBERO上性能提升14.3%，在实际任务成功率上提升30%且具有最低的推理开销。通过潜变量插值获得的标记差异，能有效作为潜在行动，进而解码为可执行的机器人动作，显示出该表示在无显式监督下能够捕捉结构化动态。此外，该方法还显著提升了政策协同训练性能，超越了之前的方法，提升幅度达10.4%。

Conclusion: 我们的研究表明，StaMo能够有效捕捉结构化动态，提升机器人动作的生成和性能，无需复杂架构和视频数据。

Abstract: A fundamental challenge in embodied intelligence is developing expressive and
compact state representations for efficient world modeling and decision making.
However, existing methods often fail to achieve this balance, yielding
representations that are either overly redundant or lacking in task-critical
information. We propose an unsupervised approach that learns a highly
compressed two-token state representation using a lightweight encoder and a
pre-trained Diffusion Transformer (DiT) decoder, capitalizing on its strong
generative prior. Our representation is efficient, interpretable, and
integrates seamlessly into existing VLA-based models, improving performance by
14.3% on LIBERO and 30% in real-world task success with minimal inference
overhead. More importantly, we find that the difference between these tokens,
obtained via latent interpolation, naturally serves as a highly effective
latent action, which can be further decoded into executable robot actions. This
emergent capability reveals that our representation captures structured
dynamics without explicit supervision. We name our method StaMo for its ability
to learn generalizable robotic Motion from compact State representation, which
is encoded from static images, challenging the prevalent dependence to learning
latent action on complex architectures and video data. The resulting latent
actions also enhance policy co-training, outperforming prior methods by 10.4%
with improved interpretability. Moreover, our approach scales effectively
across diverse data sources, including real-world robot data, simulation, and
human egocentric video.

</details>


### [73] [Automaton Constrained Q-Learning](https://arxiv.org/abs/2510.05061)
*Anastasios Manganaris,Vittorio Giammarino,Ahmed H. Qureshi*

Main category: cs.RO

TL;DR: ACQL算法结合了强化学习和线性时间时序逻辑，针对复杂的机器人任务中时间和安全约束的挑战，表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法在复杂和连续环境中对LTL目标的表现不佳，缺乏支持时间顺序目标与安全性的可扩展方法。

Method: 提出了一种结合目标条件价值学习与自动机引导强化学习的算法。

Result: ACQL在多种连续控制任务中表现优于现有方法，并成功应用于六自由度机器人臂的目标达成任务。

Conclusion: ACQL是一种可靠且可扩展的解决方案，可以根据丰富的时间规范学习机器人行为。

Abstract: Real-world robotic tasks often require agents to achieve sequences of goals
while respecting time-varying safety constraints. However, standard
Reinforcement Learning (RL) paradigms are fundamentally limited in these
settings. A natural approach to these problems is to combine RL with
Linear-time Temporal Logic (LTL), a formal language for specifying complex,
temporally extended tasks and safety constraints. Yet, existing RL methods for
LTL objectives exhibit poor empirical performance in complex and continuous
environments. As a result, no scalable methods support both temporally ordered
goals and safety simultaneously, making them ill-suited for realistic robotics
scenarios. We propose Automaton Constrained Q-Learning (ACQL), an algorithm
that addresses this gap by combining goal-conditioned value learning with
automaton-guided reinforcement. ACQL supports most LTL task specifications and
leverages their automaton representation to explicitly encode stage-wise goal
progression and both stationary and non-stationary safety constraints. We show
that ACQL outperforms existing methods across a range of continuous control
tasks, including cases where prior methods fail to satisfy either goal-reaching
or safety constraints. We further validate its real-world applicability by
deploying ACQL on a 6-DOF robotic arm performing a goal-reaching task in a
cluttered, cabinet-like space with safety constraints. Our results demonstrate
that ACQL is a robust and scalable solution for learning robotic behaviors
according to rich temporal specifications.

</details>


### [74] [ResMimic: From General Motion Tracking to Humanoid Whole-body Loco-Manipulation via Residual Learning](https://arxiv.org/abs/2510.05070)
*Siheng Zhao,Yanjie Ze,Yue Wang,C. Karen Liu,Pieter Abbeel,Guanya Shi,Rocky Duan*

Main category: cs.RO

TL;DR: ResMimic是一个两阶段残差学习框架，旨在通过人类运动数据实现精准的类人控制，改进了运动跟踪的能力以支持更复杂的动作和物体交互。


<details>
  <summary>Details</summary>
Motivation: 当前的运动跟踪技术缺乏精确度和对物体的意识，影响了类人在复杂任务中的表现。

Method: 引入了一种两阶段的残差学习方法，结合了基于点云的对象跟踪奖励、接触奖励和课程化虚拟对象控制器，以实现更精确的运动控制。

Result: 在仿真和真实的Unitree G1类人机器人上评估，取得了显著的任务成功率和训练效率提升。

Conclusion: ResMimic在任务成功率、训练效率和稳健性方面表现优于现有方法。

Abstract: Humanoid whole-body loco-manipulation promises transformative capabilities
for daily service and warehouse tasks. While recent advances in general motion
tracking (GMT) have enabled humanoids to reproduce diverse human motions, these
policies lack the precision and object awareness required for
loco-manipulation. To this end, we introduce ResMimic, a two-stage residual
learning framework for precise and expressive humanoid control from human
motion data. First, a GMT policy, trained on large-scale human-only motion,
serves as a task-agnostic base for generating human-like whole-body movements.
An efficient but precise residual policy is then learned to refine the GMT
outputs to improve locomotion and incorporate object interaction. To further
facilitate efficient training, we design (i) a point-cloud-based object
tracking reward for smoother optimization, (ii) a contact reward that
encourages accurate humanoid body-object interactions, and (iii) a
curriculum-based virtual object controller to stabilize early training. We
evaluate ResMimic in both simulation and on a real Unitree G1 humanoid. Results
show substantial gains in task success, training efficiency, and robustness
over strong baselines. Videos are available at https://resmimic.github.io/ .

</details>
