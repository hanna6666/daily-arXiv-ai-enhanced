<div id=toc></div>

# Table of Contents

- [cs.HC](#cs.HC) [Total: 26]
- [cs.RO](#cs.RO) [Total: 55]


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [1] [From customer to product: design tools for the visually impaired](https://arxiv.org/abs/2511.11577)
*Eduardo Augusto Monteiro de Almeida,Guillaume Thomann,Angelina Dias Leão Costa*

Main category: cs.HC

TL;DR: 研究旨在提升视障人士在设计中的参与，分析7种相关工具以实现更具包容性的设计方法


<details>
  <summary>Details</summary>
Motivation: 增强视障人士在设计过程中的参与感和可达性

Method: 系统性回顾与工具分析

Result: 识别和分析7种工具，揭示它们之间的相关性和应用

Conclusion: 研究为创造更具包容性和可达性的设计方法奠定了基础，呼吁在设计过程中更好地与残疾用户合作。

Abstract: Navigation in new or unknown environments is vital, especially for visually impaired individuals. While many solutions exist, few are tailored to specific disabilities, often due to limited collaboration with handicap users in the design process. This article examines 7 tools that enable visually impaired users to participate in design, selected through a systematic review and analyzed for affinities, differences, and applications. The study suggests correlations among the tools, offering a foundation for a methodology that enhances inclusive design and accessibility.

</details>


### [2] [Social and Physical Attributes-Defined Trust Evaluation for Effective Collaborator Selection in Human-Device Coexistence Systems](https://arxiv.org/abs/2511.11578)
*Botao Zhu,Xianbin Wang*

Main category: cs.HC

TL;DR: 本文提出HSLCCA方法，通过超图和自监督学习有效整合多维属性以评估设备间信任，实验表明其性能优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 在人机共存系统中，设备间的合作不仅受物理属性影响，也受人类用户的社会属性影响，因此准确的信任评估至关重要。

Method: 采用关系超图和自监督学习框架，通过参数共享的超图神经网络学习设备嵌入，利用CCA方法提升嵌入质量。

Result: 通过构建关系超图和自监督学习，成功整合多维度属性，生成富含关系语义的设备嵌入，并计算设备的可信度。

Conclusion: 提出的HSLCCA方法在有效识别可信设备方面显著优于基线算法。

Abstract: In human-device coexistence systems, collaborations among devices are determined by not only physical attributes such as network topology but also social attributes among human users. Consequently, trust evaluation of potential collaborators based on these multifaceted attributes becomes critical for ensuring the eventual outcome. However, due to the high heterogeneity and complexity of physical and social attributes, efficiently integrating them for accurate trust evaluation remains challenging. To overcome this difficulty, a canonical correlation analysis-enhanced hypergraph self-supervised learning (HSLCCA) method is proposed in this research. First, by treating all attributes as relationships among connected devices, a relationship hypergraph is constructed to comprehensively capture inter-device relationships across three dimensions: spatial attribute-related, device attribute-related, and social attribute-related. Next, a self-supervised learning framework is developed to integrate these multi-dimensional relationships and generate device embeddings enriched with relational semantics. In this learning framework, the relationship hypergraph is augmented into two distinct views to enhance semantic information. A parameter-sharing hypergraph neural network is then utilized to learn device embeddings from both views. To further enhance embedding quality, a CCA approach is applied, allowing the comparison of data between the two views. Finally, the trustworthiness of devices is calculated based on the learned device embeddings. Extensive experiments demonstrate that the proposed HSLCCA method significantly outperforms the baseline algorithm in effectively identifying trusted devices.

</details>


### [3] [MedBuild AI: An Agent-Based Hybrid Intelligence Framework for Reshaping Agency in Healthcare Infrastructure Planning through Generative Design for Medical Architecture](https://arxiv.org/abs/2511.11587)
*Yiming Zhang,Yuejia Xu,Ziyao Wang,Xin Yan,Xiaosai Hao*

Main category: cs.HC

TL;DR: MedBuild AI是一个混合智能框架，旨在为缺乏医疗基础设施的地区提供低成本医疗建筑设计指导，并通过三个代理实现更公平的医疗规划。


<details>
  <summary>Details</summary>
Motivation: 面对全球医疗基础设施不平等现象，急需一种快速、低成本的设计解决方案，以应对满足社区基本医疗服务的迫切需求。

Method: 通过三个功能代理进行操作：收集当地健康情报，转换为建筑功能程序，并生成设计模型，形成一个协作设计过程。

Result: 本文介绍了MedBuild AI，这是一个融合了大型语言模型（LLMs）和确定性专家系统的混合智能框架，旨在改善医疗基础设施设计和规划。该平台面向任何拥有卫星互联网的地区，为其提供模块化、低技术、低成本的医疗建筑设计指导。MedBuild AI通过三个代理运作，分别收集当地健康信息、将其转化为建筑功能程序，并生成布局和3D模型，从而实现医疗规划的公平性和包容性。

Conclusion: MedBuild AI通过引入计算协商，重塑了医疗建筑设计的权利与能力，为全球医疗体系的公平性和可及性提供了新的解决方案。

Abstract: Globally, disparities in healthcare infrastructure remain stark, leaving countless communities without access to even basic services. Traditional infrastructure planning is often slow and inaccessible, and although many architects are actively delivering humanitarian and aid-driven hospital projects worldwide, these vital efforts still fall far short of the sheer scale and urgency of demand. This paper introduces MedBuild AI, a hybrid-intelligence framework that integrates large language models (LLMs) with deterministic expert systems to rebalance the early design and conceptual planning stages. As a web-based platform, it enables any region with satellite internet access to obtain guidance on modular, low-tech, low-cost medical building designs. The system operates through three agents: the first gathers local health intelligence via conversational interaction; the second translates this input into an architectural functional program through rule-based computation; and the third generates layouts and 3D models. By embedding computational negotiation into the design process, MedBuild AI fosters a reciprocal, inclusive, and equitable approach to healthcare planning, empowering communities and redefining agency in global healthcare architecture.

</details>


### [4] [ARise: an Augmented Reality Mobile Application to Improve Cultural Heritage Resilience](https://arxiv.org/abs/2511.11610)
*Angelica Urbanelli,Marina Nadalin,Mario Chiesa,Rojin Bayat,Massimo Migliorini,Claudio Rossi*

Main category: cs.HC

TL;DR: ARise是一款增强现实移动应用，旨在通过促进公众参与与提高气候变化影响意识来保护文化遗产。


<details>
  <summary>Details</summary>
Motivation: 面对气候变化和环境威胁，对文化遗产的保护迫在眉睫，需要创新的解决方案来提高公众意识和韧性。

Method: 使用用户中心的共同创作方法，整合多个数据源，包括众包聊天机器人、社交媒体数据分析工具和基于人工智能的艺术作品生成模块。

Result: ARise应用展示了增强现实技术如何支持教育和增强对气候变化影响的认识。

Conclusion: ARise原型展示了增强现实在教育、文化可持续性和气候适应中的潜力。

Abstract: The preservation of cultural heritage faces increasing threats from climate change effects and environmental hazards, demanding innovative solutions that can promote awareness and resilience. This paper presents ARise, an Augmented Reality mobile application designed to enhance public engagement with cultural sites while raising awareness about the local impacts of climate change. Based on a user-centered co-creative methodology involving stakeholders from five European regions, ARise integrates multiple data sourcess - a Crowdsourcing Chatbot, a Social Media Data Analysis tool, and an AI-based Artwork Generation module - to deliver immersive and emotionally engaging experiences. Although formal user testing is forthcoming, this prototype demonstrates the potential of AR to support education, cultural sustainability, and climate adaptation.

</details>


### [5] [Lessons Learned from Developing a Privacy-Preserving Multimodal Wearable for Local Voice-and-Vision Inference](https://arxiv.org/abs/2511.11811)
*Yonatan Tussa,Andy Heredia,Nirupam Roy*

Main category: cs.HC

TL;DR: 本论文探讨了一种耳挂式多模态可穿戴设备，解决隐私问题并实现本地AI推断。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态可穿戴设备有潜在应用，但用户因隐私问题而拒绝使用，因此需要开发隐私保护的解决方案。

Method: 通过硬件和软件的共同设计，构建了一个隐私保护的耳挂式设备，利用配对智能手机进行本地AI推断。

Result: 初步评估表明，在普通移动硬件上可以实现完全本地的多模态推理，且具备互动延迟。

Conclusion: 为开发平衡隐私、响应性和易用性的嵌入式AI系统的研究人员提供设计经验。

Abstract: Many promising applications of multimodal wearables require continuous sensing and heavy computation, yet users reject such devices due to privacy concerns. This paper shares our experiences building an ear-mounted voice-and-vision wearable that performs local AI inference using a paired smartphone as a trusted personal edge. We describe the hardware--software co-design of this privacy-preserving system, including challenges in integrating a camera, microphone, and speaker within a 30-gram form factor, enabling wake word-triggered capture, and running quantized vision-language and large-language models entirely offline. Through iterative prototyping, we identify key design hurdles in power budgeting, connectivity, latency, and social acceptability. Our initial evaluation shows that fully local multimodal inference is feasible on commodity mobile hardware with interactive latency. We conclude with design lessons for researchers developing embedded AI systems that balance privacy, responsiveness, and usability in everyday settings.

</details>


### [6] [CollaClassroom: An AI-Augmented Collaborative Learning Platform with LLM Support in the Context of Bangladeshi University Students](https://arxiv.org/abs/2511.11823)
*Salman Sayeed,Bijoy Ahmed Saiem,Al-Amin Sany,Sadia Sharmin,A. B. M. Alim Al Islam*

Main category: cs.HC

TL;DR: CollaClassroom是一个AI平台，通过LLMs支持实时学习，孟加拉国大学生对其使用态度积极，体验良好，LLMs可提升学习参与度与成果。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探讨如何在全球南方的高等教育环境中，通过AI优化学习协作，提升学习体验。

Method: 通过对12名孟加拉国大学生进行小组学习会话和前后对比调查，评估CollaClassroom的效果。

Result: 本研究探讨了CollaClassroom，一个将大型语言模型（LLMs）嵌入个人与小组学习面板中的人工智能增强平台，以支持实时协作。在孟加拉国的大学生中进行评估，发现参与者对LLMs辅助学习持积极态度，95%的参与者表示支持其使用，并且对可用性评估的评分也很高。相关分析表明，认为LLM支持平等参与的参与者也认为它对讨论有意义的贡献。这表明，LLMs的设计应促进公平的发言机会，以提升学习参与感和知识获取感。

Conclusion: 本研究提供了一个实证案例，表明大型语言模型能够在高等教育中促进公平的人工智能辅助协作，并给出设计建议。

Abstract: CollaClassroom is an AI-enhanced platform that embeds large language models (LLMs) into both individual and group study panels to support real-time collaboration. We evaluate CollaClassroom with Bangladeshi university students (N = 12) through a small-group study session and a pre-post survey. Participants have substantial prior experience with collaborative learning and LLMs and express strong receptivity to LLM-assisted study (92% agree/strongly agree). Usability ratings are positive, including high learnability(67% "easy"), strong reliability (83% "reliable"), and low frustration (83% "not at all"). Correlational analyses show that participants who perceive the LLM as supporting equal participation also view it as a meaningful contributor to discussions (r = 0.86). Moreover, their pre-use expectations of LLM value align with post-use assessments (r = 0.61). These findings suggest that LLMs can enhance engagement and perceived learning when designed to promote equitable turn-taking and transparency across individual and shared spaces. The paper contributes an empirically grounded account of AI-mediated collaboration in a Global South higher-education context, with design implications for fairness-aware orchestration of human-AI teamwork.

</details>


### [7] [Enhancing XR Auditory Realism via Multimodal Scene-Aware Acoustic Rendering](https://arxiv.org/abs/2511.11930)
*Tianyu Xu,Jihan Li,Penghe Zu,Pranav Sahay,Maruchi Kim,Jack Obeng-Marnu,Farley Miller,Xun Qian,Katrina Passarella,Mahitha Rachumalla,Rajeev Nongpiur,D. Shin*

Main category: cs.HC

TL;DR: 提出了一种名为SAMOSA的系统，能够在XR中实时渲染空间音频，提升用户沉浸感。


<details>
  <summary>Details</summary>
Motivation: 提升XR中听觉体验的真实感，克服现有空间音频渲染方法在实时适应物理环境方面的不足。

Method: 整合实时的房间几何、表面材料和语义驱动的声学上下文，使用场景先验进行高效的声学校准，合成真实的房间脉冲响应。

Result: SAMOSA是一种新型的设备上系统，通过动态适应物理环境来实现空间准确的声音渲染，从而增强XR环境中的听觉真实感。

Conclusion: SAMOSA展示了在多种房间配置和声音类型下，实现真实音响效果的可行性和有效性。

Abstract: In Extended Reality (XR), rendering sound that accurately simulates real-world acoustics is pivotal in creating lifelike and believable virtual experiences. However, existing XR spatial audio rendering methods often struggle with real-time adaptation to diverse physical scenes, causing a sensory mismatch between visual and auditory cues that disrupts user immersion. To address this, we introduce SAMOSA, a novel on-device system that renders spatially accurate sound by dynamically adapting to its physical environment. SAMOSA leverages a synergistic multimodal scene representation by fusing real-time estimations of room geometry, surface materials, and semantic-driven acoustic context. This rich representation then enables efficient acoustic calibration via scene priors, allowing the system to synthesize a highly realistic Room Impulse Response (RIR). We validate our system through technical evaluation using acoustic metrics for RIR synthesis across various room configurations and sound types, alongside an expert evaluation (N=12). Evaluation results demonstrate SAMOSA's feasibility and efficacy in enhancing XR auditory realism.

</details>


### [8] ["Power of Words": Stealthy and Adaptive Private Information Elicitation via LLM Communication Strategies](https://arxiv.org/abs/2511.11961)
*Shuning Zhang,Jiaqi Bai,Linzhi Wang,Shixuan Li,Xin Yi,Hewu Li*

Main category: cs.HC

TL;DR: 本研究提出了一种新颖的适应性攻击框架，能够通过实时心理画像与优化沟通策略有效获取用户私人信息，且用户未能察觉其操控。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型（LLM）的沟通策略可能被用于隐秘攻击以获取私人信息的风险，填补这一领域的研究空白。

Method: 通过用户研究（样本量为84），验证了所提出框架的有效性和广泛适用性。

Result: 针对性攻击比没有策略的隐秘互动成功提取目标信息的能力提高了205.4%，即使是在没有具体策略的隐秘互动中，54.8%的案例也成功获取了私人信息。

Conclusion: 本研究提出的适应性攻击框架在多个场景下有效提高了从用户处获取私密信息的能力，且用户难以察觉到操控的存在。

Abstract: While communication strategies of Large Language Models (LLMs) are crucial for human-LLM interactions, they can also be weaponized to elicit private information, yet such stealthy attacks remain under-explored. This paper introduces the first adaptive attack framework for stealthy and targeted private information elicitation via communication strategies. Our framework operates in a dynamic closed-loop: it first performs real-time psychological profiling of the users' state, then adaptively selects an optimized communication strategy, and finally maintains stealthiness through prompt-based rewriting. We validated this framework through a user study (N=84), demonstrating its generalizability across 3 distinct LLMs and 3 scenarios. The targeted attacks achieved a 205.4% increase in eliciting specific targeted information compared to stealthy interactions without strategies. Even stealthy interactions without specific strategies successfully elicited private information in 54.8% cases. Notably, users not only failed to detect the manipulation but paradoxically rated the attacking chatbot as more empathetic and trustworthy. Finally, we advocate for mitigations, encouraging developers to integrate adaptive, just-in-time alerts, users to build literacy against specific manipulative tactics, and regulators to define clear ethical boundaries distinguishing benign persuasion from coercion.

</details>


### [9] [A Study of Performance and Interaction Patterns in Hand and Tangible Interaction in Tabletop Mixed Reality](https://arxiv.org/abs/2511.11962)
*Carlos Mosquera,Neven Elsayed,Ernst Kruijff,Joseph Newman,Eduardo Veas*

Main category: cs.HC

TL;DR: 本研究探讨了混合现实中基于手和实体交互的虚拟3D对象 四维操作，评估其在不同任务下的性能和精度。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是了解不同交互方式在混合现实中的表现差异，从而为设计者提供参考。

Method: 通过评估基于手和实体的交互在不同维度任务中的表现，分析了它们的准确性和时间效率。

Result: 手部交互在复合任务中需要重复校正，整体完成时间较长，而实体交互在稳定性和输入方面表现优秀，特别是在精度上显著优于手部交互。

Conclusion: 在4DoF操作中，实体交互在精度上优于手部交互，但在复合任务中表现出更大的错误，而手部交互虽然完成时间长，但在旋转错误上表现更好。

Abstract: This paper presents a comprehensive study of virtual 3D object manipulation along 4DoF on real surfaces in mixed reality (MR), using hand-based and tangible interactions. A custom cylindrical tangible proxy leverages affordances of physical knobs and tabletop support for stable input. We evaluate both modalities across isolated tasks (2DoF translation, 1DoF rotation scaling), semicombined (3DoF translation rotation), and full 4DoF compound manipulation.
  We offer analyses of hand interactions, tangible interactions, and their comparison in MR tasks. For hand interactions, compound tasks required repetitive corrections, increasing completion times yet surprisingly, rotation errors were smaller in compound tasks than in rotation only tasks. Tangible interactions exhibited significantly larger errors in translation, rotation, and scaling during compound tasks compared to isolated tasks. Crucially, tangible interactions outperformed hand interactions in precision, likely due to tabletop support and constrained 4DoF design. These findings inform designers opting for hand-only interaction (highlighting tradeoffs in compound tasks) and those leveraging tangibles (emphasizing precision gains despite compound-task challenges).

</details>


### [10] [From Play to Detection: Mini-SPACE as a Serious Game for Unsupervised Cognitive Impairment Screening](https://arxiv.org/abs/2511.12068)
*Nana Tian,Giorgio Colombo,Victor Schinazi*

Main category: cs.HC

TL;DR: mini-SPACE是一个短小的iPad游戏，适合用于早期认知障碍的筛查，显示出良好的可靠性和可用性，且适合各年龄段使用。


<details>
  <summary>Details</summary>
Motivation: 早期检测认知障碍对于及时干预和减轻痴呆负担至关重要，但现有筛查工具过于漫长且不适合大规模无监督部署。

Method: 评估mini-SPACE在早期认知障碍检测中的测试-重测可靠性、有效性和可用性

Result: mini-SPACE在无监督环境中表现出良好的测试-重测可靠性，参与者在所有年龄段均能完成任务，且报告的可用性良好、认知负荷低。

Conclusion: mini-SPACE是一种促进可扩展和年龄敏感筛查的有前景的数字标记，能够用于认知障碍的潜在长期跟踪。

Abstract: Early detection of Cognitive Impairment (CI) is critical for timely intervention, preservation of independence, and reducing the burden of dementia. Yet, most screening tools remain lengthy, clinic-based, and poorly suited for large-scale unsupervised deployment. This paper evaluates the test-retest reliability, validity, and usability of mini-SPACE, a short iPad-based serious game for detecting early signs of CI. Participants played mini-SPACE at home without supervision once a week for three weeks, with a longer version of the game in the final week. Mini-SPACE showed good test-retest reliability in unsupervised settings. While younger age was the primary predictor of performance, usability, and cognitive load, participants of all ages were able to complete the tasks and reported good usability and low cognitive load. Importantly, the prediction of scores in the Montreal Cognitive Assessment (MoCA) improved with repeated measures. These findings highlight mini-SPACE as a promising digital marker for scalable, age-sensitive screening and potential longitudinal tracking of CI.

</details>


### [11] [Multi-Domain EEG Representation Learning with Orthogonal Mapping and Attention-based Fusion for Cognitive Load Classification](https://arxiv.org/abs/2511.12394)
*Prithila Angkan,Amin Jalali,Paul Hungler,Ali Etemad*

Main category: cs.HC

TL;DR: 该研究提出了一种新颖的认知负荷分类方法，结合时间和频率域特征，通过多域注意力模块和正交投影约束，提高分类精度和抗干扰能力。


<details>
  <summary>Details</summary>
Motivation: 为了提高认知负荷分类的准确性和稳定性，研究者结合时间和频率域的信息，探索新的特征表示学习方法。

Method: 科研团队采用卷积编码器处理原始EEG信号以提取时间域特征，并结合五个频率带的功率谱密度生成的多光谱地形图，使用多域注意力模块来聚焦在重要的领域间关系，以及引入正交投影约束来优化类间距离和类内聚类。

Result: 研究在两个公开EEG数据集上进行验证，结果显示所提模型在认知负荷分类任务上表现优越，同时通过消融和敏感性分析评估了各组件的影响。

Conclusion: 本文提出的多域学习方法在认知负荷分类上优于传统单域技术，并在多次实验中验证了其有效性和稳定性。

Abstract: We propose a new representation learning solution for the classification of cognitive load based on Electroencephalogram (EEG). Our method integrates both time and frequency domains by first passing the raw EEG signals through the convolutional encoder to obtain the time domain representations. Next, we measure the Power Spectral Density (PSD) for all five EEG frequency bands and generate the channel power values as 2D images referred to as multi-spectral topography maps. These multi-spectral topography maps are then fed to a separate encoder to obtain the representations in frequency domain. Our solution employs a multi-domain attention module that maps these domain-specific embeddings onto a shared embedding space to emphasize more on important inter-domain relationships to enhance the representations for cognitive load classification. Additionally, we incorporate an orthogonal projection constraint during the training of our method to effectively increase the inter-class distances while improving intra-class clustering. This enhancement allows efficient discrimination between different cognitive states and aids in better grouping of similar states within the feature space. We validate the effectiveness of our model through extensive experiments on two public EEG datasets, CL-Drive and CLARE for cognitive load classification. Our results demonstrate the superiority of our multi-domain approach over the traditional single-domain techniques. Moreover, we conduct ablation and sensitivity analyses to assess the impact of various components of our method. Finally, robustness experiments on different amounts of added noise demonstrate the stability of our method compared to other state-of-the-art solutions.

</details>


### [12] [Detecting LLM-Assisted Academic Dishonesty using Keystroke Dynamics](https://arxiv.org/abs/2511.12468)
*Atharva Mehta,Rajesh Kumar,Aman Singla,Kartik Bisht,Yaman Kumar Singla,Rajiv Ratn Shah*

Main category: cs.HC

TL;DR: 本研究通过击键动态检测AI辅助写作，展示了其在识别学术抄袭方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 随着生成性AI工具的普及，传统的抄袭检测方法难以识别AI辅助写作的文本，迫切需要新的解决方案来维护学术诚信。

Method: 研究基于扩展的击键数据集，比较多种机器学习模型，包括TypeNet、LightGBM和CatBoost，并利用对抗训练增强检测器的鲁棒性。

Result: 本研究提出了一种基于击键动态的检测器，通过分析个体写作方式来区分真实与辅助写作，显著提高了对AI辅助抄袭的检测能力。

Conclusion: 击键动态检测器在识别AI辅助抄袭方面表现出色，优于传统文本匹配方法，支持学术诚信评估的多模态特征使用。

Abstract: The rapid adoption of generative AI tools has intensified the challenge of maintaining academic integrity. Conventional plagiarism detectors, which rely on text-matching or text-intrinsic features, often fail to identify submissions that have been AI-assisted or paraphrased. To address this limitation, we introduce keystroke-dynamics-based detectors that analyze how, rather than what, a person writes to distinguish genuine from assisted writing. Building on our earlier study, which collected keystroke data from 40 participants and trained a modified TypeNet model to detect assisted text, we expanded the dataset by adding 90 new participants and introducing a paraphrasing-based plagiarism-detection mode. We then benchmarked two additional gradient-boosting classifiers, LightGBM and CatBoost, alongside TypeNet, and compared their performance with DetectGPT, LLaMA 3.3 70B Instruct, and the results of 44 human evaluators. To further assess and improve robustness, we proposed a deception-based threat model simulating forged keystrokes and applied adversarial training as a countermeasure. Results show that the machine learning models achieve F1 scores above 97% in structured settings, while TypeNet performs best in detecting paraphrasing, with an F1 score of 86.9%. In contrast, text-only detectors and human evaluators perform near-chance, demonstrating that keystroke dynamics provide a strong behavioral signal for identifying AI-assisted plagiarism and support the use of multimodal behavioral features for reliable academic integrity assessment.

</details>


### [13] [A Proxy-Based Method for Mapping Discrete Emotions onto VAD model](https://arxiv.org/abs/2511.12521)
*Michal R. Wrobel*

Main category: cs.HC

TL;DR: 本文提出了一种新的人本导向的代理方法，旨在解决情感呈现中离散模型与维度模型之间的不兼容，通过用户生成的几何动画在离散情感标签和连续的VAD空间之间建立对应关系。


<details>
  <summary>Details</summary>
Motivation: 解决情感科学与计算中离散模型与维度模型之间的不兼容性，以便整合更有价值的数据集，提升机器学习模型的训练效果。

Method: 采用网络调查，通过用户生成的几何动画在离散情感和连续VAD空间之间建立联系，分为编码和评估两个阶段。

Result: 经过两轮用户研究，验证和优化了该方法的有效性，成功构建了离散情感标签与VAD维度之间的映射关系。

Conclusion: 结合两个研究的数据，最终形成了一套完整的离散与维度模型之间的映射，验证了该方法的有效性。

Abstract: Mapping discrete and dimensional models of emotion remains a persistent challenge in affective science and computing. This incompatibility hinders the combination of valuable data sets, creating a significant bottleneck for training robust machine learning models. To bridge this gap, this paper presents a novel, human-centric, proxy-based approach that transcends purely computational or direct mapping techniques. Implemented through a web-based survey, the method utilizes simple, user-generated geometric animations as intermediary artifacts to establish a correspondence between discrete emotion labels and the continuous valence-arousal-dominance (VAD) space. The approach involves a two-phase process: first, each participant creates an animation to represent a given emotion label (encoding); then, they immediately assess their own creation on the three VAD dimensions. The method was empirically validated and refined through two iterative user studies. The results confirmed the method's robustness. Combining the data from both studies generated a final, comprehensive mapping between discrete and dimensional models.

</details>


### [14] [Accepted with Minor Revisions: Value of AI-Assisted Scientific Writing](https://arxiv.org/abs/2511.12529)
*Sanchaita Hazra,Doeun Lee,Bodhisattwa Prasad Majumder,Sachin Kumar*

Main category: cs.HC

TL;DR: 本文探讨了大型语言模型在科学写作中的应用，尤其是摘要撰写。研究表明人类撰写摘要编辑更多，源信息披露后编辑效果趋同，AI生成摘要可达到相似的接受度。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型在科学写作中作为辅助工具的有效性，特别关注摘要撰写以指导作者和审稿人更好地理解其应用及其影响。

Method: 采用激励随机对照试验，设计为一个虚拟会议场景，参与者分为作者和审稿人，检验编辑行为与信息披露的关系。

Result: 本文研究了大型语言模型（LLMs）作为科学写作辅助工具的潜力，特别是在摘要撰写方面。通过一个激励随机对照试验，发现作者在编辑人类撰写的摘要时比编辑AI生成的摘要时进行更多修改，并且这种情况与阅读性有关。信息披露后，编辑的数量在不同来源的摘要之间趋于相等，审核人员的决定与编辑数量具有显著相关性。作者的细致风格编辑在AI生成摘要中能够提高被接受的可能性。最后，AI生成的摘要在经过最小修改后也能够达到与人类撰写摘要相当的接受水平。

Conclusion: 研究结果强调了源信息披露在科学协作写作中的重要性，并显示AI生成摘要具有潜力，在经过适度修订后可以与人类撰写的摘要相媲美。

Abstract: Large Language Models have seen expanding application across domains, yet their effectiveness as assistive tools for scientific writing -- an endeavor requiring precision, multimodal synthesis, and domain expertise -- remains insufficiently understood. We examine the potential of LLMs to support domain experts in scientific writing, with a focus on abstract composition. We design an incentivized randomized controlled trial with a hypothetical conference setup where participants with relevant expertise are split into an author and reviewer pool. Inspired by methods in behavioral science, our novel incentive structure encourages authors to edit the provided abstracts to an acceptable quality for a peer-reviewed submission. Our 2x2 between-subject design expands into two dimensions: the implicit source of the provided abstract and the disclosure of it. We find authors make most edits when editing human-written abstracts compared to AI-generated abstracts without source attribution, often guided by higher perceived readability in AI generation. Upon disclosure of source information, the volume of edits converges in both source treatments. Reviewer decisions remain unaffected by the source of the abstract, but bear a significant correlation with the number of edits made. Careful stylistic edits, especially in the case of AI-generated abstracts, in the presence of source information, improve the chance of acceptance. We find that AI-generated abstracts hold potential to reach comparable levels of acceptability to human-written ones with minimal revision, and that perceptions of AI authorship, rather than objective quality, drive much of the observed editing behavior. Our findings reverberate the significance of source disclosure in collaborative scientific writing.

</details>


### [15] [Designing-with More-than-Human Through Human Augmentation](https://arxiv.org/abs/2511.12533)
*Botao 'Amber' Hu,Danlin Huang*

Main category: cs.HC

TL;DR: 本研究提出了一种新的设计方法，通过人类增强技术促进对生态和非人类物种的感知，旨在增强生态意识。


<details>
  <summary>Details</summary>
Motivation: 在设计中与其他物种和生态系统共同创造，克服人类经验的局限性，实现更深层次的生态理解和共生关系。

Method: 通过人类增强技术，创建体感的临时体验，以调节人类的环境意识，增强对多元超人类感知的敏感性。

Result: 本论文提出了一种设计方法，即通过人类增强技术来实现超人类的设计，这种方法旨在增强对非人类物种的感知和理解，并促进生态意识和跨物种的关怀责任。

Conclusion: 这种体验式的设计能够增强生态意识、同理心以及跨物种的关怀责任。

Abstract: The recent more-than-human turn in design calls for "designing-with" other species and ecologies beyond humans. Yet-as Thomas Nagel's famous "What is it like to be a bat?" thought experiment highlights-human experience is constrained by our own sensorium and an irreducible gap in phenomenal access to nonhuman lifeworlds. This paper proposes More-than-Human through Human Augmentation (MtHtHA, denoted ">HtH+") as a design approach that repurposes human augmentation technologies-typically aimed at enhancing human capabilities-away from human optimization and exceptionalism but toward eco-phenomenological awareness. Grounded in somaesthetic design and eco-somatics, MtHtHA entails creating temporary, embodied experiences that modulate the human Umwelt to re-sensitize us to pluriversal more-than-human perceptions. We articulate seven design principles and report five design cases-EchoVision (bat-like echolocation), FeltSight (star-nosed-mole tactile navigation), FungiSync (fungal network attunement), TentacUs (octopus-like distributed agency), and City of Sparkles (urban data from AI's perspective). We demonstrate that such experiential "designing-with" can cultivate ecological awareness, empathy and obligations of care across species boundaries.

</details>


### [16] [BeautyGuard: Designing a Multi-Agent Roundtable System for Proactive Beauty Tech Compliance through Stakeholder Collaboration](https://arxiv.org/abs/2511.12645)
*Junwei Li,Wenqing Wang,Huiliu Mao,Jiazhe Ni,Zuyu Xiong*

Main category: cs.HC

TL;DR: 研究开发了一个多代理系统，旨在提升美容科技行业合规性，通过专家评估进行可用性测试。


<details>
  <summary>Details</summary>
Motivation: 随着生成性人工智能在企业工作流程中的应用，美容科技行业面临着法律和伦理合规的紧迫挑战，传统检查方法存在手动、分散和反应式的问题。

Method: 通过与六位专家的形成性研究探讨合规审查中的挑战，并使用系统可用性量表和NASA任务负荷指数对原型进行了评估。

Result: 该研究提出了一个基于大语言模型的多代理“圆桌”系统，以解决美容科技行业中合规检查的挑战。

Conclusion: 研究表明，多代理系统具有出色的可用性和低认知负荷，能够有效地支持法律合规审查，并为其他受监管行业提供设计原则。

Abstract: As generative AI enters enterprise workflows, ensuring compliance with legal, ethical, and reputational standards becomes a pressing challenge. In beauty tech, where biometric and personal data are central, traditional reviews are often manual, fragmented, and reactive. To examine these challenges, we conducted a formative study with six experts (four IT managers, two legal managers) at a multinational beauty company. The study revealed pain points in rule checking, precedent use, and the lack of proactive guidance.
  Motivated by these findings, we designed a multi-agent "roundtable" system powered by a large language model. The system assigns role-specialized agents for legal interpretation, checklist review, precedent search, and risk mitigation, synthesizing their perspectives into structured compliance advice.
  We evaluated the prototype with the same experts using System Usability Scale(SUS), The Official NASA Task Load Index(NASA-TLX), and interviews. Results show exceptional usability (SUS: 77.5/100) and minimal cognitive workload, with three key findings: (1) multi-agent systems can preserve tacit knowledge into standardized workflows, (2) information augmentation achieves higher acceptance than decision automation, and (3) successful enterprise AI should mirror organizational structures. This work contributes design principles for human-AI collaboration in compliance review, with broader implications for regulated industries beyond beauty tech.

</details>


### [17] [Maximizing the efficiency of human feedback in AI alignment: a comparative analysis](https://arxiv.org/abs/2511.12796)
*Andreas Chouliaras,Dimitris Chatzopoulos*

Main category: cs.HC

TL;DR: 提出Swiss InfoGain方法，通过瑞士锦标赛系统优化偏好推断，降低冗余，提高稳健性，显著改善标注效率。


<details>
  <summary>Details</summary>
Motivation: 提高RLHF中偏好建模的效率和有效性，尤其是在有限的标注预算下

Method: 探索替代的采样和评估策略以进行偏好推断

Result: Swiss InfoGain方法显著优于其他方法，并在高资源设置中识别出比Bradley-Terry基线更好的替代方案

Conclusion: 在RLHF管道中平衡对齐质量和人类工作负载的重要性。

Abstract: Reinforcement Learning from Human Feedback (RLHF) relies on preference modeling to align machine learning systems with human values, yet the popular approach of random pair sampling with Bradley-Terry modeling is statistically limited and inefficient under constrained annotation budgets. In this work, we explore alternative sampling and evaluation strategies for preference inference in RLHF, drawing inspiration from areas such as game theory, statistics, and social choice theory. Our best-performing method, Swiss InfoGain, employs a Swiss tournament system with a proxy mutual-information-gain pairing rule, which significantly outperforms all other methods in constrained annotation budgets while also being more sample-efficient. Even in high-resource settings, we can identify superior alternatives to the Bradley-Terry baseline. Our experiments demonstrate that adaptive, resource-aware strategies reduce redundancy, enhance robustness, and yield statistically significant improvements in preference learning, highlighting the importance of balancing alignment quality with human workload in RLHF pipelines.

</details>


### [18] [SoK: Synthesizing Smart Home Privacy Protection Mechanisms Across Academic Proposals and Commercial Documentations](https://arxiv.org/abs/2511.12841)
*Shuning Zhang,Yijing Liu,Yuyu Liu,Ying Ma,Shixuan Li,Xin Yi,Qian Wu,Hewu Li*

Main category: cs.HC

TL;DR: 本研究分析了智能家居设备的隐私保护机制，发现学术界关注新颖机制的理论与算法，但缺乏实际应用；而商业界则以合规为重，提供有限的实践措施。


<details>
  <summary>Details</summary>
Motivation: 随着智能家居设备数据收集的普遍化，亟需建立有效的隐私保护机制，但学术与商业界的研究和文档存在明显差异，需深入探讨。

Method: 研究包括两阶段：系统综述117篇学术文献和对86款SHDs的公开文档进行实证分析。

Result: 本研究探讨了智能家居设备（SHDs）的隐私保护机制（PPMs），分析了学术界与商业文献对这些机制的关注与差异。

Conclusion: 呼吁开展更多针对实际挑战的研究，以创造可部署的隐私保护框架，并验证其在真实环境中的有效性。

Abstract: Pervasive data collection by Smart Home Devices (SHDs) demands robust Privacy Protection Mechanisms (PPMs). The effectiveness of many PPMs, particularly user-facing controls, depends on user awareness and adoption, which are shaped by manufacturers' public documentations. However, the landscape of academic proposals and commercial disclosures remains underexplored. To address this gap, we investigate: (1) What PPMs have academics proposed, and how are these PPMs evaluated? (2) What PPMs do manufacturers document and what factors affect these documentation? To address these questions, we conduct a two-phase study, synthesizing a systematic review of 117 academic papers with an empirical analysis of 86 SHDs' publicly disclosed documentations. Our review of academic literature reveals a strong focus on novel system- and algorithm-based PPMs. However, these proposals neglect deployment barriers (e.g., cost, interoperability), and lack real-world field validation and legal analysis. Concurrently, our analysis of commercial SHDs finds that advanced academic proposals are absent from public discourse. Industry postures are fundamentally reactive, prioritizing compliance via post-hoc data management (e.g., deletion options), rather than the preventative controls favored by academia. The documented protections correspondingly converge on a small set of practical mechanisms, such as physical buttons and localized processing. By synthesizing these findings, we advocate for research to analyze challenges, provide deployable frameworks, real-world field validation, and interoperability solutions to advance practical PPMs.

</details>


### [19] [Design and Evaluation of an AI-DrivenPersonalized Mobile App to Provide MultifacetedHealth Support for Type 2 Diabetes Patients inChina](https://arxiv.org/abs/2511.12952)
*Yibo Meng,Zhiming Liu,Xiaochen Qin*

Main category: cs.HC

TL;DR: 设计并评估了一款名为T2MD Health的AI驱动移动应用，旨在改善中国2型糖尿病患者的沟通及自我管理。


<details>
  <summary>Details</summary>
Motivation: 应对中国2型糖尿病患者在患者-医生沟通和自我管理中面临的重大挑战。

Method: 进行定性访谈和混合方法对照实验，分别采访40名参与者以了解需求，并对60名参与者评估应用效果。

Result: 应用显著改善了患者和医生之间的沟通效率和患者自我管理能力，且在城乡医疗服务接入方面展现出一定的潜力。

Conclusion: 该应用有效提升了患者与医务人员的沟通效率、自我管理能力和知识保留，显示出缩小城乡医疗咨询服务差距的潜力。

Abstract: Type 2 diabetes patients in China face many significant challenges in patient-provider communication and self management In light of this, this work designed,implemented,and evaluated an AI-driven, personalized, multi-functional mobile app system named T2MD Health. The appintegrates real-time patient- provider conversation transcription,medical terminology interpretation, daily health tracking, and adata-driven feedback loop. We conducted qualitative interviewswith 40 participants to study key user needs before systemdevelopment and a mixed- method controlled experiment with 60participants after to evaluate the effectiveness and usability ofthe app. Evaluation results showed that the app was effective inimproving patient-provider communication efficiency, patientunderstanding and knowledge retention,and patient selfmanagement, Patient feedback also revealed that the app has thepotential to address the urban-rural gap in the access to medica!consultation services to some extent, Findings ofthis study couldinform future studies that seek to utilize mobile apps andartificial intelligence to support patients with chronic diseases.

</details>


### [20] [Knowing Ourselves Through Others: Reflecting with AI in Digital Human Debates](https://arxiv.org/abs/2511.13046)
*Ichiro Matsuda,Komichi Takezawa,Katsuhito Muroi,Kensuke Katori,Ryosuke Hyakuta,Jingjing Li,Yoichi Ochiai*

Main category: cs.HC

TL;DR: 本研究探讨了个性化数字人类在自我与他人之间的动态关系，发现参与者在设计和使用数字人类时加深了对AI的理解，并培养了反思自我认知的能力。


<details>
  <summary>Details</summary>
Motivation: 随着大规模语言模型（LLMs）的发展，探讨其在自我与他人之间的角色和影响变得至关重要，尤其是个性化的数字人类（Digital Humans）如何帮助用户反思自我认知和价值观。

Method: 采用设计驱动研究的方法，九名中学生以团队形式设计数字人类并参与辩论，通过生成性人工智能素养测试、访谈和日志分析进行数据收集与分析。

Result: 研究显示，参与者通过设计和观察自己的数字人类进行辩论，增强了对人工智能能力的理解，同时培养了反思态度。

Conclusion: 我们提出将‘与AI反思’作为一种新的生成性人工智能素养，补充传统的理解、应用、批评与伦理观念。

Abstract: LLMs can act as an impartial other, drawing on vast knowledge, or as personalized self-reflecting user prompts. These personalized LLMs, or Digital Humans, occupy an intermediate position between self and other. This research explores the dynamic of self and other mediated by these Digital Humans. Using a Research Through Design approach, nine junior and senior high school students, working in teams, designed Digital Humans and had them debate. Each team built a unique Digital Human using prompt engineering and RAG, then observed their autonomous debates. Findings from generative AI literacy tests, interviews, and log analysis revealed that participants deepened their understanding of AI's capabilities. Furthermore, experiencing their own creations as others prompted a reflective attitude, enabling them to objectively view their own cognition and values. We propose "Reflecting with AI" - using AI to re-examine the self - as a new generative AI literacy, complementing the conventional understanding, applying, criticism and ethics.

</details>


### [21] [F.A.C.U.L.: Language-Based Interaction with AI Companions in Gaming](https://arxiv.org/abs/2511.13112)
*Wenya Wei,Sipeng Yang,Qixian Zhou,Ruochen Liu,Xuelei Zhang,Yifu Yuan,Yan Jiang,Yongle Luo,Hailong Wang,Tianzhou Wang,Peipei Jin,Wangtong Liu,Zhou Zhao,Xiaogang Jin,Elvis S. Liu*

Main category: cs.HC

TL;DR: F.A.C.U.L.是一个创新的AI系统，允许玩家通过自然语言指挥AI伙伴，从而改善合作视频游戏的游戏体验。


<details>
  <summary>Details</summary>
Motivation: 传统的AI伙伴交互方式限制了玩家发出复杂战术指令的能力，影响了游戏体验。

Method: 采用自然语言处理和基于信心的框架，F.A.C.U.L.解析复杂命令，并实现动态实体检索以增强环境意识。

Result: 这篇论文提出了一种名为F.A.C.U.L.的实时AI系统，允许玩家使用自然语言与AI伙伴进行沟通和协作。

Conclusion: F.A.C.U.L.能够有效地提升玩家与AI伙伴间的互动质量，增强游戏的沉浸感与战术协作能力。

Abstract: In cooperative video games, traditional AI companions are deployed to assist players, who control them using hotkeys or command wheels to issue predefined commands such as ``attack'', ``defend'', or ``retreat''. Despite their simplicity, these methods, which lack target specificity, limit players' ability to give complex tactical instructions and hinder immersive gameplay experiences. To address this problem, we propose the FPS AI Companion who Understands Language (F.A.C.U.L.), the first real-time AI system that enables players to communicate and collaborate with AI companions using natural language. By integrating natural language processing with a confidence-based framework, F.A.C.U.L. efficiently decomposes complex commands and interprets player intent. It also employs a dynamic entity retrieval method for environmental awareness, aligning human intentions with decision-making. Unlike traditional rule-based systems, our method supports real-time language interactions, enabling players to issue complex commands such as ``clear the second floor'', ``take cover behind that tree'', or ``retreat to the river''. The system provides real-time behavioral responses and vocal feedback, ensuring seamless tactical collaboration. Using the popular FPS game \textit{Arena Breakout: Infinite} as a case study, we present comparisons demonstrating the efficacy of our approach and discuss the advantages and limitations of AI companions based on real-world user feedback.

</details>


### [22] [Agent-Oriented Visual Programming for the Web of Things](https://arxiv.org/abs/2511.13158)
*Samuele Burattini,Alessandro Ricci,Simon Mayer,Danai Vachtsevanou,Jeremy Lemee,Andrei Ciortea,Angelo Croatti*

Main category: cs.HC

TL;DR: 本文提出了一种面向多智能体的视觉编程方法，旨在帮助没有编程经验的用户设计自主软件，通过基于区块的开发环境使编程变得简单。


<details>
  <summary>Details</summary>
Motivation: 为了使没有编程经验但具备特定目标领域知识的个人能够设计和重新配置自主软件，提出了一种面向多智能体的视觉编程方法。

Method: 基于JaCaMo平台设计并实现了一个视觉编程系统，集成Web of Things以支持用户在物理设备的组合上创建自主行为。

Result: 该视觉编程系统能够让初学者创建多智能体系统以解决简单的自动化任务。

Conclusion: 用户研究表明，初学者可以使用这种开发环境创建多智能体系统。

Abstract: In this paper we introduce and discuss an approach for multi-agent-oriented visual programming. This aims at enabling individuals without programming experience but with knowledge in specific target domains to design and (re)configure autonomous software. We argue that, compared to procedural programming, it should be simpler for users to create programs when agent abstractions are employed. The underlying rationale is that these abstractions, and specifically the belief-desire-intention architecture that is aligned with human practical reasoning, match more closely with people's everyday experience in interacting with other agents and artifacts in the real world. On top of this, we designed and implemented a visual programming system for agents that hides the technicalities of agent-oriented programming using a blocks-based visual development environment that is built on the JaCaMo platform. To further validate the proposed solution, we integrate the Web of Things (WoT) to let users create autonomous behaviour on top of physical mashups of devices, following the trends in industrial end-user programming. Finally, we report on a pilot user study where we verified that novice users are indeed able to make use of this development environment to create multi-agent systems to solve simple automation tasks.

</details>


### [23] [Trust in Vision-Language Models: Insights from a Participatory User Workshop](https://arxiv.org/abs/2511.13458)
*Agnese Chiatti,Lara Piccolo,Sara Bernardini,Matteo Matteucci,Viola Schiaffonati*

Main category: cs.HC

TL;DR: 论文研究用户对视觉-语言模型的信任建立过程，通过用户中心方法的一次工作坊获得初步结果。


<details>
  <summary>Details</summary>
Motivation: 随着视觉-语言模型的广泛部署，用户对这些系统的信任问题日益重要。

Method: 采用用户中心的方法，通过与潜在 VLM 用户的工作坊收集初步数据。

Result: 这篇论文探讨了用户在使用视觉-语言模型（VLMs）过程中的信任建立与发展，尤其关注如何确保用户能够判断何时可以信任这些系统。

Conclusion: 调研结果将为未来研究提供基础，以更好地 contextualize信任测量和参与者的互动策略。

Abstract: With the growing deployment of Vision-Language Models (VLMs), pre-trained on large image-text and video-text datasets, it is critical to equip users with the tools to discern when to trust these systems. However, examining how user trust in VLMs builds and evolves remains an open problem. This problem is exacerbated by the increasing reliance on AI models as judges for experimental validation, to bypass the cost and implications of running participatory design studies directly with users. Following a user-centred approach, this paper presents preliminary results from a workshop with prospective VLM users. Insights from this pilot workshop inform future studies aimed at contextualising trust metrics and strategies for participants' engagement to fit the case of user-VLM interaction.

</details>


### [24] [The Quick Red Fox gets the best Data Driven Classroom Interviews: A manual for an interview app and its associated methodology](https://arxiv.org/abs/2511.13466)
*Jaclyn Ocumpaugh,Luc Paquette,Ryan S. Baker,Amanda Barany,Jeff Ginger,Nathan Casano,Andres F. Zambrano,Xiner Liu,Zhanlan Wei,Yiqui Zhou,Qianhui Liu,Stephen Hutt,Alexandra M. A. Andres,Nidhi Nasiar,Camille Giordano,Martin van Velsen,Micheal Mogessi*

Main category: cs.HC

TL;DR: 本研究介绍了一种数据驱动的访谈技术，利用快速红狐工具提升研究效率并减少学生学习中断。


<details>
  <summary>Details</summary>
Motivation: 促进研究者在学生与数字学习环境互动时，在最小化干扰学习的情况下，获取关键信息。

Method: 数据驱动课堂访谈（DDCIs）是一种利用技术发展的访谈技术，使用了名为快速红狐（QRF）的工具助力进行访谈。

Result: 通过整合学生建模技术，QRF能在学生表现出有趣行为时提醒研究者，从而优化访谈过程。

Conclusion: 本文档不仅描述了相关技术，还提供了开发触发器和访谈技巧的培训，并建议了分析方法。

Abstract: Data Driven Classroom Interviews (DDCIs) are an interviewing technique that is facilitated by recent technological developments in the learning analytics community. DDCIs are short, targeted interviews that allow researchers to contextualize students' interactions with a digital learning environment (e.g., intelligent tutoring systems or educational games) while minimizing the amount of time that the researcher interrupts that learning experience, and focusing researcher time on the events they most want to focus on DDCIs are facilitated by a research tool called the Quick Red Fox (QRF)--an open-source server-client Android app that optimizes researcher time by directing interviewers to users that have just displayed an interesting behavior (previously defined by the research team). QRF integrates with existing student modeling technologies (e.g., behavior-sensing, affect-sensing, detection of self-regulated learning) to alert researchers to key moments in a learner's experience. This manual documents the tech while providing training on the processes involved in developing triggers and interview techniques; it also suggests methods of analyses.

</details>


### [25] [A Lexical Analysis of online Reviews on Human-AI Interactions](https://arxiv.org/abs/2511.13480)
*Parisa Arbab,Xiaowen Fang*

Main category: cs.HC

TL;DR: 通过对在线评论的词汇分析，该研究揭示了影响人机交互的关键因素，旨在为用户中心的人工智能系统提供更深入的见解。


<details>
  <summary>Details</summary>
Motivation: 理解人类与人工智能系统之间复杂的动态关系，特别是用户面临的具体担忧和挑战。

Method: 采用词汇分析和因子分析方法，对来自G2.com、Producthunt.com和Trustpilot.com的用户评论进行分析。

Result: 对55,968条在线评论进行词汇分析，识别影响人机交互的关键因素。

Conclusion: 研究结果将增强我们对人机交互的理解，促进未来人工智能技术和用户体验的改善。

Abstract: This study focuses on understanding the complex dynamics between humans and AI systems by analyzing user reviews. While previous research has explored various aspects of human-AI interaction, such as user perceptions and ethical considerations, there remains a gap in understanding the specific concerns and challenges users face. By using a lexical approach to analyze 55,968 online reviews from G2.com, Producthunt.com, and Trustpilot.com, this preliminary research aims to analyze human-AI interaction. Initial results from factor analysis reveal key factors influencing these interactions. The study aims to provide deeper insights into these factors through content analysis, contributing to the development of more user-centric AI systems. The findings are expected to enhance our understanding of human-AI interaction and inform future AI technology and user experience improvements.

</details>


### [26] [Person-AI Bidirectional Fit - A Proof-Of-Concept Case Study Of Augmented Human-Ai Symbiosis In Management Decision-Making Process](https://arxiv.org/abs/2511.13670)
*Agnieszka Bieńkowska,Jacek Małecki,Alexander Mathiesen-Ohman,Katarzyna Tworek*

Main category: cs.HC

TL;DR: 本文提出人-AI双向匹配的概念，研究其在管理决策中的作用，通过案例研究比较传统评估与增强人-AI智能系统的效果。


<details>
  <summary>Details</summary>
Motivation: 旨在发展人-AI双向匹配的概念，并探讨其在管理决策中的作用。

Method: 通过真实的高级AI领导者招聘过程案例研究，比较了三条决策路径的效果。

Result: 研究发现人类判断存在显著的角色基础分歧，H3LIX-LAIZA与CEO隐性决策模型之间具有高度对齐，而通用大型语言模型则存在关键的假阳性推荐。

Conclusion: 研究结果表明，较高的人-AI匹配度（以CEO与H3LIX-LAIZA的关系为例）作为环节，将增强的共生智能与准确、可靠和具上下文感知的决策联系起来。

Abstract: This article develops the concept of Person-AI bidirectional fit, defined as the continuously evolving, context-sensitive alignment-primarily cognitive, but also emotional and behavioral-between a human decision-maker and an artificial intelligence system. Grounded in contingency theory and quality theory, the study examines the role of P-AI fit in managerial decision-making through a proof-of-concept case study involving a real hiring process for a Senior AI Lead. Three decision pathways are compared: (1) independent evaluations by a CEO, CTO, and CSO; (2) an evaluation produced by an augmented human-AI symbiotic intelligence system (H3LIX-LAIZA); and (3) an assessment generated by a general-purpose large language model. The results reveal substantial role-based divergence in human judgments, high alignment between H3LIX-LAIZA and the CEOs implicit decision model-including ethical disqualification of a high-risk candidate and a critical false-positive recommendation from the LLMr. The findings demonstrate that higher P-AI fit, exemplified by the CEO H3LIX-LAIZA relationship, functions as a mechanism linking augmented symbiotic intelligence to accurate, trustworthy, and context-sensitive decisions. The study provides an initial verification of the P-AI fit construct and a proof-of-concept for H3LIX-LAIZA as an augmented human-AI symbiotic intelligence system.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [27] [Hierarchical Federated Graph Attention Networks for Scalable and Resilient UAV Collision Avoidance](https://arxiv.org/abs/2511.11616)
*Rathin Chandra Shit,Sharmila Subudhi*

Main category: cs.RO

TL;DR: 本研究提出了一种三层分层框架，用于在大规模多无人机系统中实现高效的碰撞避免，成功平衡了实时性、对抗性和隐私保护。


<details>
  <summary>Details</summary>
Motivation: 在大规模多无人机系统中，实时性能、对抗恢复能力和隐私保护是碰撞避免需要平衡的重要指标。

Method: 分层架构包括局部层、区域层和全局层，各自运用不同的注意力机制和学习方式，同时引入了一种自适应差分隐私机制。

Result: 采用该架构，在500架无人机的场景中，碰撞率保持在2.0%以下，并实现了拜占庭容错。

Conclusion: 提出的三层架构可以有效平衡实时性能、对抗性和隐私保护，实现大规模多无人机系统中的碰撞避免。

Abstract: The real-time performance, adversarial resiliency, and privacy preservation are the most important metrics that need to be balanced to practice collision avoidance in large-scale multi-UAV (Unmanned Aerial Vehicle) systems. Current frameworks tend to prescribe monolithic solutions that are not only prohibitively computationally complex with a scaling cost of $O(n^2)$ but simply do not offer Byzantine fault tolerance. The proposed hierarchical framework presented in this paper tries to eliminate such trade-offs by stratifying a three-layered architecture. We spread the intelligence into three layers: an immediate collision avoiding local layer running on dense graph attention with latency of $<10 ms$, a regional layer using sparse attention with $O(nk)$ computational complexity and asynchronous federated learning with coordinate-wise trimmed mean aggregation, and lastly, a global layer using a lightweight Hashgraph-inspired protocol. We have proposed an adaptive differential privacy mechanism, wherein the noise level $(ε\in [0.1, 1.0])$ is dynamically reduced based on an evaluation of the measured real-time threat that in turn maximized the privacy-utility tradeoff. Through the use of Distributed Hash Table (DHT)-based lightweight audit logging instead of heavyweight blockchain consensus, the median cost of getting a $95^{th}$ percentile decision within 50ms is observed across all tested swarm sizes. This architecture provides a scalable scenario of 500 UAVs with a collision rate of $< 2.0\%$ and the Byzantine fault tolerance of $f < n/3$.

</details>


### [28] [Tactile Data Recording System for Clothing with Motion-Controlled Robotic Sliding](https://arxiv.org/abs/2511.11634)
*Michikuni Eguchi,Takekazu Kitagishi,Yuichi Hiroi,Takefumi Hiraki*

Main category: cs.RO

TL;DR: 本研究提出了一种基于机器人手臂的系统，用于系统性地收集衣物的触觉数据，以探讨影响穿着舒适度的物理特性。


<details>
  <summary>Details</summary>
Motivation: 为了揭示影响衣物舒适度的物理特性，需要系统性收集在滑动过程中产生的触觉数据。

Method: 采用机器人手臂进行滑动触觉数据采集，模拟指尖进行测量，控制速度和方向，创造运动标记的多模态触觉数据库。

Result: 机器学习评估表明，包含运动相关参数提高了音频和加速度数据的识别准确性，证明了运动相关标签在表征衣物触觉感知中的有效性.

Conclusion: 该系统为获取衣物触觉数据提供了一种可扩展且无损的方法，有助于未来的面料感知和再现研究。

Abstract: The tactile sensation of clothing is critical to wearer comfort. To reveal physical properties that make clothing comfortable, systematic collection of tactile data during sliding motion is required. We propose a robotic arm-based system for collecting tactile data from intact garments. The system performs stroking measurements with a simulated fingertip while precisely controlling speed and direction, enabling creation of motion-labeled, multimodal tactile databases. Machine learning evaluation showed that including motion-related parameters improved identification accuracy for audio and acceleration data, demonstrating the efficacy of motion-related labels for characterizing clothing tactile sensation. This system provides a scalable, non-destructive method for capturing tactile data of clothing, contributing to future studies on fabric perception and reproduction.

</details>


### [29] [Image-based Morphological Characterization of Filamentous Biological Structures with Non-constant Curvature Shape Feature](https://arxiv.org/abs/2511.11639)
*Jie Fan,Francesco Visentin,Barbara Mazzolai,Emanuela Del Dottore*

Main category: cs.RO

TL;DR: 该研究提出一种新方法，通过图像分析腺卷的形态变化，提高了植物生物力学研究的理解，并为智能机器人设计提供依据。


<details>
  <summary>Details</summary>
Motivation: 尽管攀缘植物的研究历史悠久，但提取形态变化、触发事件和接触位置之间的关系仍然具有挑战性。

Method: 利用3D分段Clothoid模型重建腺卷在机械摩擦后的配置，采用几何方法分析形态变化。

Result: 通过本方法分析腺卷在不同部位受到机械刺激后的形态变化，结果显示该方法具有高鲁棒性和可靠性，准确度达到R2 > 0.99，并揭示腺卷顶端段的响应性更强。

Conclusion: 本研究提出了一种基于图像的方法，揭示了攀缘植物的腺卷在受机械刺激时的形态变化及其响应特点，为植物生物力学研究和智能机器人系统的设计提供了基础。

Abstract: Tendrils coil their shape to anchor the plant to supporting structures, allowing vertical growth toward light. Although climbing plants have been studied for a long time, extracting information regarding the relationship between the temporal shape change, the event that triggers it, and the contact location is still challenging. To help build this relation, we propose an image-based method by which it is possible to analyze shape changes over time in tendrils when mechano-stimulated in different portions of their body. We employ a geometric approach using a 3D Piece-Wise Clothoid-based model to reconstruct the configuration taken by a tendril after mechanical rubbing. The reconstruction shows high robustness and reliability with an accuracy of R2 > 0.99. This method demonstrates distinct advantages over deep learning-based approaches, including reduced data requirements, lower computational costs, and interpretability. Our analysis reveals higher responsiveness in the apical segment of tendrils, which might correspond to higher sensitivity and tissue flexibility in that region of the organs. Our study provides a methodology for gaining new insights into plant biomechanics and offers a foundation for designing and developing novel intelligent robotic systems inspired by climbing plants.

</details>


### [30] [ExpertAD: Enhancing Autonomous Driving Systems with Mixture of Experts](https://arxiv.org/abs/2511.11740)
*Haowen Jiang,Xinyu Huang,You Lu,Dingji Wang,Yuheng Cao,Chaofeng Sha,Bihuan Chen,Keyu Chen,Xin Peng*

Main category: cs.RO

TL;DR: 提出ExpertAD框架，利用Mixture of Experts架构和Perception Adapter，提高自主驾驶系统在复杂情境中的性能，显著降低碰撞率与推理延迟。


<details>
  <summary>Details</summary>
Motivation: 改善自主驾驶系统在复杂驾驶场景中的感知与规划能力，解决语义模糊、任务干扰及推理延迟等问题

Method: ExpertAD框架，结合Mixture of Experts (MoE)架构和Perception Adapter (PA)

Result: ExpertAD框架相比于之前的方法，平均碰撞率降低至20%，推理延迟降低25%。在稀有场景中的多技能规划也表现良好，展现了对未知城市环境的强泛化能力

Conclusion: ExpertAD在复杂驾驶场景中的决策过程展示了其有效性，提高了决策的可靠性，增强了整体的驾驶安全性。

Abstract: Recent advancements in end-to-end autonomous driving systems (ADSs) underscore their potential for perception and planning capabilities. However, challenges remain. Complex driving scenarios contain rich semantic information, yet ambiguous or noisy semantics can compromise decision reliability, while interference between multiple driving tasks may hinder optimal planning. Furthermore, prolonged inference latency slows decision-making, increasing the risk of unsafe driving behaviors. To address these challenges, we propose ExpertAD, a novel framework that enhances the performance of ADS with Mixture of Experts (MoE) architecture. We introduce a Perception Adapter (PA) to amplify task-critical features, ensuring contextually relevant scene understanding, and a Mixture of Sparse Experts (MoSE) to minimize task interference during prediction, allowing for effective and efficient planning. Our experiments show that ExpertAD reduces average collision rates by up to 20% and inference latency by 25% compared to prior methods. We further evaluate its multi-skill planning capabilities in rare scenarios (e.g., accidents, yielding to emergency vehicles) and demonstrate strong generalization to unseen urban environments. Additionally, we present a case study that illustrates its decision-making process in complex driving scenarios.

</details>


### [31] [Large Language Models and 3D Vision for Intelligent Robotic Perception and Autonomy: A Review](https://arxiv.org/abs/2511.11777)
*Vinit Mehta,Charu Sharma,Karthick Thiyagarajan*

Main category: cs.RO

TL;DR: 综述LLMs与3D视觉结合的技术进展及未来挑战，助力智能机器人感知系统的发展


<details>
  <summary>Details</summary>
Motivation: 探讨人工智能与机器人技术的整合，以提升机器的感知能力

Method: 综述现有的LLMs与3D视觉结合的技术

Result: 分析了LLMs与3D视觉交叉领域的先进方法、应用及挑战，提供未来研究方向

Conclusion: 提出了未来研究的关键挑战和方向，如模型架构的适应性、跨模态对齐等，以促进智能机器人感知技术的进步。

Abstract: With the rapid advancement of artificial intelligence and robotics, the integration of Large Language Models (LLMs) with 3D vision is emerging as a transformative approach to enhancing robotic sensing technologies. This convergence enables machines to perceive, reason and interact with complex environments through natural language and spatial understanding, bridging the gap between linguistic intelligence and spatial perception. This review provides a comprehensive analysis of state-of-the-art methodologies, applications and challenges at the intersection of LLMs and 3D vision, with a focus on next-generation robotic sensing technologies. We first introduce the foundational principles of LLMs and 3D data representations, followed by an in-depth examination of 3D sensing technologies critical for robotics. The review then explores key advancements in scene understanding, text-to-3D generation, object grounding and embodied agents, highlighting cutting-edge techniques such as zero-shot 3D segmentation, dynamic scene synthesis and language-guided manipulation. Furthermore, we discuss multimodal LLMs that integrate 3D data with touch, auditory and thermal inputs, enhancing environmental comprehension and robotic decision-making. To support future research, we catalog benchmark datasets and evaluation metrics tailored for 3D-language and vision tasks. Finally, we identify key challenges and future research directions, including adaptive model architectures, enhanced cross-modal alignment and real-time processing capabilities, which pave the way for more intelligent, context-aware and autonomous robotic sensing systems.

</details>


### [32] [LAVQA: A Latency-Aware Visual Question Answering Framework for Shared Autonomy in Self-Driving Vehicles](https://arxiv.org/abs/2511.11840)
*Shuangyu Xie,Kaiyuan Chen,Wenjing Chen,Chengyuan Qian,Christian Juette,Liu Ren,Dezhen Song,Ken Goldberg*

Main category: cs.RO

TL;DR: 提出了一种名为LAVQA的延迟感知共享自治框架，以提升自驾车在高不确定性情况下的安全性，能有效减少碰撞率。


<details>
  <summary>Details</summary>
Motivation: 在不确定性高的情况下，自驾车需要确保安全，并依靠远程人类操作员提供指导。

Method: 结合视觉问答（VQA）和时空风险可视化，使用延迟诱导碰撞图（LICOM）来辅助决策。

Result: 在CARLA仿真中，LAVQA的碰撞率比延迟无关基线降低超过8倍。

Conclusion: LAVQA框架能够显著降低碰撞率，提升自驾车在复杂情况下的决策能力。

Abstract: When uncertainty is high, self-driving vehicles may halt for safety and benefit from the access to remote human operators who can provide high-level guidance. This paradigm, known as {shared autonomy}, enables autonomous vehicle and remote human operators to jointly formulate appropriate responses. To address critical decision timing with variable latency due to wireless network delays and human response time, we present LAVQA, a latency-aware shared autonomy framework that integrates Visual Question Answering (VQA) and spatiotemporal risk visualization. LAVQA augments visual queries with Latency-Induced COllision Map (LICOM), a dynamically evolving map that represents both temporal latency and spatial uncertainty. It enables remote operator to observe as the vehicle safety regions vary over time in the presence of dynamic obstacles and delayed responses. Closed-loop simulations in CARLA, the de-facto standard for autonomous vehicle simulator, suggest that that LAVQA can reduce collision rates by over 8x compared to latency-agnostic baselines.

</details>


### [33] [Autonomous Underwater Cognitive System for Adaptive Navigation: A SLAM-Integrated Cognitive Architecture](https://arxiv.org/abs/2511.11845)
*K. A. I. N Jayarathne,R. M. N. M. Rathnayaka,D. P. S. S. Peiris*

Main category: cs.RO

TL;DR: 本文介绍的自主水下认知系统（AUCS）利用SLAM和认知架构提高了深海探索的导航能力，融合了多种传感器数据，增强了安全性和自主性。


<details>
  <summary>Details</summary>
Motivation: 深海探索面临导航失灵、通信中断和动态环境的挑战，因此需要一个能够智能适应各种海洋条件的系统。

Method: AUCS结合SLAM技术与认知模块，通过多传感器数据融合与语义理解，实现了自适应导航。

Result: 提出了一种自主水下认知系统（AUCS）来应对深海勘探中面临的挑战，结合了同时定位与地图构建（SLAM）与基于Soar的认知架构，增强了在复杂海洋条件下的自适应导航能力。

Conclusion: 提出的AUCS架构为未来的认知潜水系统奠定了基础，有助于提升深海探测的安全性、可靠性和自主性。

Abstract: Deep-sea exploration poses significant challenges, including disorientation, communication loss, and navigational failures in dynamic underwater environments. This paper presents an Autonomous Underwater Cognitive System (AUCS) that integrates Simultaneous Localization and Mapping (SLAM) with a Soar-based cognitive architecture to enable adaptive navigation in complex oceanic conditions. The system fuses multi-sensor data from SONAR, LiDAR, IMU, and DVL with cognitive reasoning modules for perception, attention, planning, and learning. Unlike conventional SLAM systems, AUCS incorporates semantic understanding, adaptive sensor management, and memory-based learning to differentiate between dynamic and static objects, reducing false loop closures and enhancing long-term map consistency. The proposed architecture demonstrates a complete perception-cognition-action-learning loop, allowing autonomous underwater vehicles to sense, reason, and adapt intelligently. This work lays a foundation for next-generation cognitive submersible systems, improving safety, reliability, and autonomy in deep-sea exploration.

</details>


### [34] [MATT-Diff: Multimodal Active Target Tracking by Diffusion Policy](https://arxiv.org/abs/2511.11931)
*Saida Liu,Nikolay Atanasov,Shumon Koga*

Main category: cs.RO

TL;DR: 提出一种多模态主动目标跟踪策略MATT-Diff，能够在无先验知识的情况下有效跟踪多个目标。


<details>
  <summary>Details</summary>
Motivation: 实现无需先验知识的多目标跟踪，平衡目标探索与跟踪，适应复杂环境中的动态变化。

Method: MATT-Diff控制策略

Result: MATT-Diff在多种目标运动下表现出优越的跟踪性能，相比于专家和行为克隆基准有显著优势。

Conclusion: 评估结果验证了MATT-Diff在目标跟踪方面的优势，尤其在应对复杂动态情况下的表现。

Abstract: This paper proposes MATT-Diff: Multi-Modal Active Target Tracking by Diffusion Policy, a control policy that captures multiple behavioral modes - exploration, dedicated tracking, and target reacquisition - for active multi-target tracking. The policy enables agent control without prior knowledge of target numbers, states, or dynamics. Effective target tracking demands balancing exploration for undetected or lost targets with following the motion of detected but uncertain ones. We generate a demonstration dataset from three expert planners including frontier-based exploration, an uncertainty-based hybrid planner switching between frontier-based exploration and RRT* tracking based on target uncertainty, and a time-based hybrid planner switching between exploration and tracking based on target detection time. We design a control policy utilizing a vision transformer for egocentric map tokenization and an attention mechanism to integrate variable target estimates represented by Gaussian densities. Trained as a diffusion model, the policy learns to generate multi-modal action sequences through a denoising process. Evaluations demonstrate MATT-Diff's superior tracking performance against expert and behavior cloning baselines across multiple target motions, empirically validating its advantages in target tracking.

</details>


### [35] [Characterization and Evaluation of Screw-Based Locomotion Across Aquatic, Granular, and Transitional Media](https://arxiv.org/abs/2511.11958)
*Derek Chen,Zoe Samuels,Lizzie Peiros,Sujaan Mukherjee,Michael C. Yip*

Main category: cs.RO

TL;DR: 本研究探讨了螺旋推进系统在水、干沙、湿沙和饱和沙中运动性能，发现关键参数对性能的影响，以及如何设计螺旋外壳以改善其在多种环境下的适应性运动策略。


<details>
  <summary>Details</summary>
Motivation: 螺旋推进系统在两栖移动过程中面临在不同介质中优化运动的挑战，本研究旨在解决这一难题。

Method: 通过原则优先的方法系统分析不同螺旋配置在多种介质中（如干沙、湿沙、饱和沙和水）的运动表现。

Result: 研究发现某些参数对螺旋推进系统的性能有主导影响，并提出了基于热沉设计优化的派生参数以分类不同介质中的性能。

Conclusion: 研究结果为螺旋推进系统的设计提供了具体的见解，有助于提升其在多样化两栖应用中的性能。

Abstract: Screw-based propulsion systems offer promising capabilities for amphibious mobility, yet face significant challenges in optimizing locomotion across water, granular materials, and transitional environments. This study presents a systematic investigation into the locomotion performance of various screw configurations in media such as dry sand, wet sand, saturated sand, and water. Through a principles-first approach to analyze screw performance, it was found that certain parameters are dominant in their impact on performance. Depending on the media, derived parameters inspired from optimizing heat sink design help categorize performance within the dominant design parameters. Our results provide specific insights into screw shell design and adaptive locomotion strategies to enhance the performance of screw-based propulsion systems for versatile amphibious applications.

</details>


### [36] [Bootstrapped LLM Semantics for Context-Aware Path Planning](https://arxiv.org/abs/2511.11967)
*Mani Amani,Behrad Beheshti,Reza Akhavian*

Main category: cs.RO

TL;DR: 本研究提出了一种框架，使大型语言模型能够作为随机语义传感器，从而在复杂的人类中心环境中实现安全高效的任务执行。


<details>
  <summary>Details</summary>
Motivation: 研究现有的自然语言提示机器人任务执行的局限性，关注在复杂环境中如何安全高效地执行任务。

Method: 将大型语言模型的输出与经典规划器结合，通过贝叶斯自助法近似每类风险的后验分布，进而形成路径规划问题。

Result: 在模拟环境和数字双胞胎中展示了定性和定量的结果，证明了所提方法的有效性。

Conclusion: 实验表明该方法在模拟环境和数字双胞胎中有效地调整了机器人运动，能够响应明确提示与隐含上下文信息。

Abstract: Prompting robots with natural language (NL) has largely been studied as what task to execute (goal selection, skill sequencing) rather than how to execute that task safely and efficiently in semantically rich, human-centric spaces. We address this gap with a framework that turns a large language model (LLM) into a stochastic semantic sensor whose outputs modulate a classical planner. Given a prompt and a semantic map, we draw multiple LLM "danger" judgments and apply a Bayesian bootstrap to approximate a posterior over per-class risk. Using statistics from the posterior, we create a potential cost to formulate a path planning problem. Across simulated environments and a BIM-backed digital twin, our method adapts how the robot moves in response to explicit prompts and implicit contextual information. We present qualitative and quantitative results.

</details>


### [37] [ARCSnake V2: An Amphibious Multi-Domain Screw-Propelled Snake-Like Robot](https://arxiv.org/abs/2511.11970)
*Sara Wickenhiser,Lizzie Peiros,Calvin Joyce,Peter Gavrilrov,Sujaan Mukherjee,Syler Sylvester,Junrong Zhou,Mandy Cheung,Jason Lim,Florian Richter,Michael C. Yip*

Main category: cs.RO

TL;DR: 本论文提出的ARCSnake V2机器人具有多种运动模式，能在极端环境中灵活适应，并有望广泛应用于探索与环境监测。


<details>
  <summary>Details</summary>
Motivation: 极端环境下的机器人探索面临挑战，传统机器人难以适应多样地形，急需新型机器人满足多域探测需求

Method: ARCSnake V2的水密机械设计、串联螺旋和关节驱动、集成浮力控制系统，以及通过手持控制器的遥控操作

Result: ARCSnake V2展示了先进的在多种环境中自如运动的能力，验证了其在水下灵活性、通信可靠性及力控驱动的有效性

Conclusion: ARCSnake V2的设计与控制架构使其成为探索、救援及环境监测的多功能平台，具有显著的应用潜力。

Abstract: Robotic exploration in extreme environments such as caves, oceans, and planetary surfaces pose significant challenges, particularly in locomotion across diverse terrains. Conventional wheeled or legged robots often struggle in these contexts due to surface variability. This paper presents ARCSnake V2, an amphibious, screw propelled, snake like robot designed for teleoperated or autonomous locomotion across land, granular media, and aquatic environments. ARCSnake V2 combines the high mobility of hyper redundant snake robots with the terrain versatility of Archimedean screw propulsion. Key contributions include a water sealed mechanical design with serially linked screw and joint actuation, an integrated buoyancy control system, and teleoperation via a kinematically matched handheld controller. The robots design and control architecture enable multiple locomotion modes screwing, wheeling, and sidewinding with smooth transitions between them. Extensive experiments validate its underwater maneuverability, communication robustness, and force regulated actuation. These capabilities position ARCSnake V2 as a versatile platform for exploration, search and rescue, and environmental monitoring in multi domain settings.

</details>


### [38] [SBAMP: Sampling Based Adaptive Motion Planning](https://arxiv.org/abs/2511.12022)
*Anh-Quan Pham,Kabir Ram Puri,Shreyas Raorane*

Main category: cs.RO

TL;DR: SBAMP结合了全局路径规划和局部控制，能够在动态环境中实时适应，而无需预先训练的数据集。


<details>
  <summary>Details</summary>
Motivation: 自主机器人系统需在复杂动态环境中实时导航，面对不可预见的障碍和快速变化的条件，现有方法存在局限性。

Method: 将传统的RRT*与基于SEDS的局部控制器相结合，确保路径平滑过渡和稳定性。

Result: 提出了一种新框架SBAMP，将RRT*与SEDS结合，实现动态适应性轨迹调整。

Conclusion: SBAMP在动态障碍场景中表现优异，能够快速恢复并处理急转弯，提供有效的解决方案。

Abstract: Autonomous robotic systems must navigate complex, dynamic environments in real time, often facing unpredictable obstacles and rapidly changing conditions. Traditional sampling-based methods, such as RRT*, excel at generating collision-free paths but struggle to adapt to sudden changes without extensive replanning. Conversely, learning-based dynamical systems, such as the Stable Estimator of Dynamical Systems (SEDS), offer smooth, adaptive trajectory tracking but typically rely on pre-collected demonstration data, limiting their generalization to novel scenarios. This paper introduces Sampling-Based Adaptive Motion Planning (SBAMP), a novel framework that overcomes these limitations by integrating RRT* for global path planning with a SEDS-based local controller for continuous, adaptive trajectory adjustment. Our approach requires no pre-trained datasets and ensures smooth transitions between planned waypoints, maintaining stability through Lyapunov-based guarantees. We validate SBAMP in both simulated environments and real hardware using the RoboRacer platform, demonstrating superior performance in dynamic obstacle scenarios, rapid recovery from perturbations, and robust handling of sharp turns. Experimental results highlight SBAMP's ability to adapt in real time without sacrificing global path optimality, providing a scalable solution for dynamic, unstructured environments.

</details>


### [39] [Decoupled Action Head: Confining Task Knowledge to Conditioning Layers](https://arxiv.org/abs/2511.12101)
*Jian Zhou,Sihao Lin,Shuai Fu,Qi WU*

Main category: cs.RO

TL;DR: 提出了一种新的解耦训练策略，显著提高了行为克隆模型的效率和速度，且通过引入更简单的模型结构，降低了参数数量。


<details>
  <summary>Details</summary>
Motivation: 受到语言和视觉领域扩展法则成功的启发，旨在解决行为克隆（BC）方法中数据稀缺性和模型透明度不足的问题。

Method: 提出了一种解耦训练方法，利用几乎无成本的运动学生成轨迹作为无观察数据来预训练通用动作头（动作生成器）。

Result: 通过实验证明该方法在分布内和分布外场景中的可行性，且DP-C训练速度提高了41%。引入DP-MLP替代DP-C的U-Net后，训练速度分别提升了83.9%和89.1%。

Conclusion: 解耦训练方法更有效，简化的DP-MLP结构在训练速度上表现优异，表明动作生成的基础结构对机器人操控的作用有限。

Abstract: Behavior Cloning (BC) is a data-driven supervised learning approach that has gained increasing attention with the success of scaling laws in language and vision domains. Among its implementations in robotic manipulation, Diffusion Policy (DP), with its two variants DP-CNN (DP-C) and DP-Transformer (DP-T), is one of the most effective and widely adopted models, demonstrating the advantages of predicting continuous action sequences. However, both DP and other BC methods remain constrained by the scarcity of paired training data, and the internal mechanisms underlying DP's effectiveness remain insufficiently understood, leading to limited generalization and a lack of principled design in model development. In this work, we propose a decoupled training recipe that leverages nearly cost-free kinematics-generated trajectories as observation-free data to pretrain a general action head (action generator). The pretrained action head is then frozen and adapted to novel tasks through feature modulation. Our experiments demonstrate the feasibility of this approach in both in-distribution and out-of-distribution scenarios. As an additional benefit, decoupling improves training efficiency; for instance, DP-C achieves up to a 41% speedup. Furthermore, the confinement of task-specific knowledge to the conditioning components under decoupling, combined with the near-identical performance of DP-C in both normal and decoupled training, indicates that the action generation backbone plays a limited role in robotic manipulation. Motivated by this observation, we introduce DP-MLP, which replaces the 244M-parameter U-Net backbone of DP-C with only 4M parameters of simple MLP blocks, achieving a 83.9% faster training speed under normal training and 89.1% under decoupling.

</details>


### [40] [Towards Obstacle-Avoiding Control of Planar Snake Robots Exploring Neuro-Evolution of Augmenting Topologies](https://arxiv.org/abs/2511.12148)
*Advik Sinha,Akshay Arjun,Abhijit Das,Joyjit Mukherjee*

Main category: cs.RO

TL;DR: 本研究旨在为平面蛇形机器人在障碍物密集环境中的避障跟踪控制开发一种资源高效的解决方案，使用NEAT算法生成动态步态参数，并在模拟中表现出优于现有方法的计算效率。


<details>
  <summary>Details</summary>
Motivation: 随着机器人在复杂环境中的应用需求增加，开发一种高效的动态控制方法显得尤为重要。

Method: 使用NEAT算法为蛇形机器人的关节角度生成动态步态参数，通过最大化奖励函数来优化控制。

Result: 实验结果显示，所提出的方法在计算效率上优于现有技术，并在PyBullet模拟中取得了良好效果。

Conclusion: 该方法在复杂环境中展示了优越的计算效率和适应性，验证了其有效性。

Abstract: This work aims to develop a resource-efficient solution for obstacle-avoiding tracking control of a planar snake robot in a densely cluttered environment with obstacles. Particularly, Neuro-Evolution of Augmenting Topologies (NEAT) has been employed to generate dynamic gait parameters for the serpenoid gait function, which is implemented on the joint angles of the snake robot, thus controlling the robot on a desired dynamic path. NEAT is a single neural-network based evolutionary algorithm that is known to work extremely well when the input layer is of significantly higher dimension and the output layer is of a smaller size. For the planar snake robot, the input layer consists of the joint angles, link positions, head link position as well as obstacle positions in the vicinity. However, the output layer consists of only the frequency and offset angle of the serpenoid gait that control the speed and heading of the robot, respectively. Obstacle data from a LiDAR and the robot data from various sensors, along with the location of the end goal and time, are employed to parametrize a reward function that is maximized over iterations by selective propagation of superior neural networks. The implementation and experimental results showcase that the proposed approach is computationally efficient, especially for large environments with many obstacles. The proposed framework has been verified through a physics engine simulation study on PyBullet. The approach shows superior results to existing state-of-the-art methodologies and comparable results to the very recent CBRL approach with significantly lower computational overhead. The video of the simulation can be found here: https://sites.google.com/view/neatsnakerobot

</details>


### [41] [Game-Theoretic Safe Multi-Agent Motion Planning with Reachability Analysis for Dynamic and Uncertain Environments (Extended Version)](https://arxiv.org/abs/2511.12160)
*Wenbin Mai,Minghui Liwang,Xinlei Yi,Xiaoyu Xia,Seyyedali Hosseinalipour,Xianbin Wang*

Main category: cs.RO

TL;DR: 提出RE-DPG框架，结合游戏理论和可达性分析，解决多智能体系统在复杂环境中的运动规划问题，并通过实验验证其有效性


<details>
  <summary>Details</summary>
Motivation: 解决多智能体系统在动态和不确定环境中运动规划的安全性、鲁棒性和可扩展性问题

Method: 提出一个结合游戏理论协调与可达性分析的RE-DPG框架

Result: 通过模拟和实际实验验证了RE-DPG在不同操作场景下的有效性

Conclusion: RE-DPG框架通过多智能体前向可达集机制增强了安全性，同时确保了计算的可扩展性和收敛性。

Abstract: Ensuring safe, robust, and scalable motion planning for multi-agent systems in dynamic and uncertain environments is a persistent challenge, driven by complex inter-agent interactions, stochastic disturbances, and model uncertainties. To overcome these challenges, particularly the computational complexity of coupled decision-making and the need for proactive safety guarantees, we propose a Reachability-Enhanced Dynamic Potential Game (RE-DPG) framework, which integrates game-theoretic coordination into reachability analysis. This approach formulates multi-agent coordination as a dynamic potential game, where the Nash equilibrium (NE) defines optimal control strategies across agents. To enable scalability and decentralized execution, we develop a Neighborhood-Dominated iterative Best Response (ND-iBR) scheme, built upon an iterated $\varepsilon$-BR (i$\varepsilon$-BR) process that guarantees finite-step convergence to an $\varepsilon$-NE. This allows agents to compute strategies based on local interactions while ensuring theoretical convergence guarantees. Furthermore, to ensure safety under uncertainty, we integrate a Multi-Agent Forward Reachable Set (MA-FRS) mechanism into the cost function, explicitly modeling uncertainty propagation and enforcing collision avoidance constraints. Through both simulations and real-world experiments in 2D and 3D environments, we validate the effectiveness of RE-DPG across diverse operational scenarios.

</details>


### [42] [Variable Impedance Control for Floating-Base Supernumerary Robotic Leg in Walking Assistance](https://arxiv.org/abs/2511.12184)
*Jun Huo,Kehan Xu,Chengyao Li,Yu Cao,Jie Zuo,Xinxing Chen,Jian Huang*

Main category: cs.RO

TL;DR: 本研究针对超余机器人腿(SRL)系统中的安全性挑战，提出了一种混合阻抗控制方案，通过动态调整阻抗参数，提升了在外部扰动情况下的适应性和安全性。


<details>
  <summary>Details</summary>
Motivation: 在人机系统中，确保在内部和外部扰动下的安全是至关重要的，尤其对于松散耦合的浮动基机器人系统如超余机器人腿(SRL)系统，容易受到强烈的内部扰动影响。

Method: 研究了SRL的动力学模型，并设计了一种混合位置/力阻抗控制器，开发了高效的变阻抗控制方法，以应对不同状态下的未知环境扰动。

Result: 提出了一种混合位置/力阻抗控制器和高效的变阻抗控制(VIC)方法，以增强人机交互并适应不同的环境扰动。

Conclusion: 通过仿真和实验验证了该系统的有效性，证明其在灵活状态下保持平滑信号过渡的能力，并在刚性状态下提供强有力的支持。该方法显著提高了人机系统的安全性和适应性。

Abstract: In human-robot systems, ensuring safety during force control in the presence of both internal and external disturbances is crucial. As a typical loosely coupled floating-base robot system, the supernumerary robotic leg (SRL) system is particularly susceptible to strong internal disturbances. To address the challenge posed by floating base, we investigated the dynamics model of the loosely coupled SRL and designed a hybrid position/force impedance controller to fit dynamic torque input. An efficient variable impedance control (VIC) method is developed to enhance human-robot interaction, particularly in scenarios involving external force disturbances. By dynamically adjusting impedance parameters, VIC improves the dynamic switching between rigidity and flexibility, so that it can adapt to unknown environmental disturbances in different states. An efficient real-time stability guaranteed impedance parameters generating network is specifically designed for the proposed SRL, to achieve shock mitigation and high rigidity supporting. Simulations and experiments validate the system's effectiveness, demonstrating its ability to maintain smooth signal transitions in flexible states while providing strong support forces in rigid states. This approach provides a practical solution for accommodating individual gait variations in interaction, and significantly advances the safety and adaptability of human-robot systems.

</details>


### [43] [Innovative Design of Multi-functional Supernumerary Robotic Limbs with Ellipsoid Workspace Optimization](https://arxiv.org/abs/2511.12186)
*Jun Huo,Jian Huang,Jie Zuo,Bo Yang,Zhongzheng Fu,Xi Li,Samer Mohammed*

Main category: cs.RO

TL;DR: 本文提出了一种多目标优化设计理论，旨在解决超数机器人肢体（SRL）设备的复杂功能要求，通过几何向量量化方法和改进的萤火虫算法优化SRL的设计，实验证明优化后性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 设计通用的超数机器人肢体设备面临多样化功能要求的挑战，需在设计过程中考虑抓取和行走的工作空间等多个因素。

Method: 使用多目标优化设计理论，结合几何向量量化和多子种群修正萤火虫算法，以优化SRL的功能和性能。

Result: 实验结果显示优化后抓取成功率提高7.2%，行走和坐立转变任务中的肌肉活动分别减少12.7%和25.1%。

Conclusion: 提出的设计理论为设计多功能超数机器人肢体机制提供了有效方案，优化后实验结果显示性能有显著改善。

Abstract: Supernumerary robotic limbs (SRLs) offer substantial potential in both the rehabilitation of hemiplegic patients and the enhancement of functional capabilities for healthy individuals. Designing a general-purpose SRL device is inherently challenging, particularly when developing a unified theoretical framework that meets the diverse functional requirements of both upper and lower limbs. In this paper, we propose a multi-objective optimization (MOO) design theory that integrates grasping workspace similarity, walking workspace similarity, braced force for sit-to-stand (STS) movements, and overall mass and inertia. A geometric vector quantification method is developed using an ellipsoid to represent the workspace, aiming to reduce computational complexity and address quantification challenges. The ellipsoid envelope transforms workspace points into ellipsoid attributes, providing a parametric description of the workspace. Furthermore, the STS static braced force assesses the effectiveness of force transmission. The overall mass and inertia restricts excessive link length. To facilitate rapid and stable convergence of the model to high-dimensional irregular Pareto fronts, we introduce a multi-subpopulation correction firefly algorithm. This algorithm incorporates a strategy involving attractive and repulsive domains to effectively handle the MOO task. The optimized solution is utilized to redesign the prototype for experimentation to meet specified requirements. Six healthy participants and two hemiplegia patients participated in real experiments. Compared to the pre-optimization results, the average grasp success rate improved by 7.2%, while the muscle activity during walking and STS tasks decreased by an average of 12.7% and 25.1%, respectively. The proposed design theory offers an efficient option for the design of multi-functional SRL mechanisms.

</details>


### [44] [Locally Optimal Solutions to Constraint Displacement Problems via Path-Obstacle Overlaps](https://arxiv.org/abs/2511.12203)
*Antony Thomas,Fulvio Mastrogiovanni,Marco Baglietto*

Main category: cs.RO

TL;DR: 本文提出一种统一的方法来处理机器人约束位移问题，包含两阶段的选择以实现可行路径。


<details>
  <summary>Details</summary>
Motivation: 解决机器人路径规划中的约束位移问题，保证机器人能够找到可行路径。

Method: 第一阶段计算最优轨迹，第二阶段通过位移障碍物使轨迹可行。

Result: 提出了一种两阶段的过程，返回局部最优的障碍物位移，以使机器人路径可行。

Conclusion: 通过多个案例成功展示了所提方法在两类约束位移问题上的有效性。

Abstract: We present a unified approach for constraint displacement problems in which a robot finds a feasible path by displacing constraints or obstacles. To this end, we propose a two stage process that returns locally optimal obstacle displacements to enable a feasible path for the robot. The first stage proceeds by computing a trajectory through the obstacles while minimizing an appropriate objective function. In the second stage, these obstacles are displaced to make the computed robot trajectory feasible, that is, collision-free. Several examples are provided that successfully demonstrate our approach on two distinct classes of constraint displacement problems.

</details>


### [45] [SocialNav-Map: Dynamic Mapping with Human Trajectory Prediction for Zero-Shot Social Navigation](https://arxiv.org/abs/2511.12232)
*Lingfeng Zhang,Erjia Xiao,Xiaoshuai Hao,Haoxiang Fu,Zeying Gong,Long Chen,Xiaojun Liang,Renjing Xu,Hangjun Ye,Wenbo Ding*

Main category: cs.RO

TL;DR: SocialNav-Map是一个新的社交导航框架，通过动态人类轨迹预测和占用图映射，实现无需环境特定训练的安全导航，显著减少碰撞率。


<details>
  <summary>Details</summary>
Motivation: 解决自主移动机器人在密集动态环境中导航难题，以及现有强化学习方法的训练时间过长和泛化能力弱的问题。

Method: 将任务目标位置转换为地图坐标系统，创建动态占用图并使用历史预测和方向预测的两种方法来预测人类轨迹，从而避免潜在的碰撞。

Result: 提出了一种名为SocialNav-Map的零-shot社交导航框架，能够在不进行环境特定训练的情况下实现安全、高效的导航。

Conclusion: SocialNav-Map在多样人类行为环境中展示了出色的导航表现，为社交导航系统的实际应用奠定了基础。

Abstract: Social navigation in densely populated dynamic environments poses a significant challenge for autonomous mobile robots, requiring advanced strategies for safe interaction. Existing reinforcement learning (RL)-based methods require over 2000+ hours of extensive training and often struggle to generalize to unfamiliar environments without additional fine-tuning, limiting their practical application in real-world scenarios. To address these limitations, we propose SocialNav-Map, a novel zero-shot social navigation framework that combines dynamic human trajectory prediction with occupancy mapping, enabling safe and efficient navigation without the need for environment-specific training. Specifically, SocialNav-Map first transforms the task goal position into the constructed map coordinate system. Subsequently, it creates a dynamic occupancy map that incorporates predicted human movements as dynamic obstacles. The framework employs two complementary methods for human trajectory prediction: history prediction and orientation prediction. By integrating these predicted trajectories into the occupancy map, the robot can proactively avoid potential collisions with humans while efficiently navigating to its destination. Extensive experiments on the Social-HM3D and Social-MP3D datasets demonstrate that SocialNav-Map significantly outperforms state-of-the-art (SOTA) RL-based methods, which require 2,396 GPU hours of training. Notably, it reduces human collision rates by over 10% without necessitating any training in novel environments. By eliminating the need for environment-specific training, SocialNav-Map achieves superior navigation performance, paving the way for the deployment of social navigation systems in real-world environments characterized by diverse human behaviors. The code is available at: https://github.com/linglingxiansen/SocialNav-Map.

</details>


### [46] [Intermittent Rendezvous Plans with Mixed Integer Linear Program for Large-Scale Multi-Robot Exploration](https://arxiv.org/abs/2511.12237)
*Alysson Ribeiro da Silva,Luiz Chaimowicz*

Main category: cs.RO

TL;DR: 研究了在通信约束下的多机器人探索问题，提出了一种混合整数线性规划(MILP)模型和根据RTUS机制跟随计划的策略，以应对不确定性。


<details>
  <summary>Details</summary>
Motivation: 旨在解决在不确定环境和通信限制下，多机器人系统的有效任务执行问题，增强其在实际部署中的适用性。

Method: 采用混合整数线性规划(MILP)模型生成会合计划，并基于RTUS机制跟踪执行计划。

Result: 提出了一种新的多机器人探索(MRE)框架，能够在通信约束和不确定环境下生成有效的会合计划，并使机器人能够跟随该计划进行探索。

Conclusion: 所提出的方法在大规模环境中显示出有效的计划跟随能力和任务完成效率，具有实际应用潜力。

Abstract: Multi-Robot Exploration (MRE) systems with communication constraints have proven efficient in accomplishing a variety of tasks, including search-and-rescue, stealth, and military operations. While some works focus on opportunistic approaches for efficiency, others concentrate on pre-planned trajectories or scheduling for increased interpretability. However, scheduling usually requires knowledge of the environment beforehand, which prevents its deployment in several domains due to related uncertainties (e.g., underwater exploration). In our previous work, we proposed an intermittent communications framework for MRE under communication constraints that uses scheduled rendezvous events to mitigate such limitations. However, the system was unable to generate optimal plans and had no mechanisms to follow the plan considering realistic trajectories, which is not suited for real-world deployments. In this work, we further investigate the problem by formulating the Multi-Robot Exploration with Communication Constraints and Intermittent Connectivity (MRE-CCIC) problem. We propose a Mixed-Integer Linear Program (MILP) formulation to generate rendezvous plans and a policy to follow them based on the Rendezvous Tracking for Unknown Scenarios (RTUS) mechanism. The RTUS is a simple rule to allow robots to follow the assigned plan, considering unknown conditions. Finally, we evaluated our method in a large-scale environment configured in Gazebo simulations. The results suggest that our method can follow the plan promptly and accomplish the task efficiently. We provide an open-source implementation of both the MILP plan generator and the large-scale MRE-CCIC.

</details>


### [47] [SAC-MoE: Reinforcement Learning with Mixture-of-Experts for Control of Hybrid Dynamical Systems with Uncertainty](https://arxiv.org/abs/2511.12361)
*Leroy D'Souza,Akash Karthikeyan,Yash Vardhan Pant,Sebastian Fischmeister*

Main category: cs.RO

TL;DR: SAC-MoE通过混合专家和课程训练策略提高了混合动力系统在不确定环境下的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 混合动力系统的复杂性与不确定性，包括不可观察的参数和事件，给模型控制和强化学习方法带来了挑战。

Method: 通过将Soft Actor-Critic框架的actor建模为混合专家，同时采用自适应选择的学习路由器，结合课程训练算法优先数据收集。

Result: 提出了一种名为SAC-MoE的模型，该模型通过混合专家方法解决可观察性和模式切换带来的问题。

Conclusion: SAC-MoE在混合自主赛车和四足步态任务中表现优于基线，显示出良好的零-shot 泛化能力，且课程训练策略有效提升了所有评估策略的性能。

Abstract: Hybrid dynamical systems result from the interaction of continuous-variable dynamics with discrete events and encompass various systems such as legged robots, vehicles and aircrafts. Challenges arise when the system's modes are characterized by unobservable (latent) parameters and the events that cause system dynamics to switch between different modes are also unobservable. Model-based control approaches typically do not account for such uncertainty in the hybrid dynamics, while standard model-free RL methods fail to account for abrupt mode switches, leading to poor generalization.
  To overcome this, we propose SAC-MoE which models the actor of the Soft Actor-Critic (SAC) framework as a Mixture-of-Experts (MoE) with a learned router that adaptively selects among learned experts. To further improve robustness, we develop a curriculum-based training algorithm to prioritize data collection in challenging settings, allowing better generalization to unseen modes and switching locations. Simulation studies in hybrid autonomous racing and legged locomotion tasks show that SAC-MoE outperforms baselines (up to 6x) in zero-shot generalization to unseen environments. Our curriculum strategy consistently improves performance across all evaluated policies. Qualitative analysis shows that the interpretable MoE router activates different experts for distinct latent modes.

</details>


### [48] [Multilaminate piezoelectric PVDF actuators to enhance performance of soft micro robots](https://arxiv.org/abs/2511.12380)
*Nicholas Gunter,Heiko Kabutz,Kaushik Jayaram*

Main category: cs.RO

TL;DR: 开发了一种多层PVDF驱动器，提升了软微型机器人系统的性能，并展示了其设计空间及应用潜力。


<details>
  <summary>Details</summary>
Motivation: 提升软微型机器人系统的性能，填补脆性高强度PZT堆与柔性低带宽聚合物驱动器之间的设计空间。

Method: 通过改变驱动器的层厚和层数，使用第一性模型对其性能进行表征。

Result: 实现了超过3毫米的自由偏转、超过20毫牛的阻力和>=500赫兹的频率，且工作电压仅为150伏特。

Conclusion: 多层PVDF驱动器在软微型机器人中表现出色，具备高自由偏转、力量及频率，同时低工作电压。

Abstract: Multilayer piezoelectric polyvinylidene fluoride (PVDF) actuators are a promising approach to enhance performance of soft microrobotic systems. In this work, we develop and characterize multilayer PVDF actuators with parallel voltage distribution across each layer, bridging a unique design space between brittle high-force PZT stacks and compliant but lower-bandwidth soft polymer actuators. We show the effects of layer thickness and number of layers in actuator performance and their agreement with a first principles model. By varying these parameters, we demonstrate actuators capable of >3 mm of free deflection, >20 mN of blocked force, and >=500 Hz, while operating at voltages as low as 150 volts. To illustrate their potential for robotic integration, we integrate our actuators into a planar, translating microrobot that leverages resonance to achieve locomotion with robustness to large perturbations.

</details>


### [49] [Evaluating Model-Agnostic Meta-Learning on MetaWorld ML10 Benchmark: Fast Adaptation in Robotic Manipulation Tasks](https://arxiv.org/abs/2511.12383)
*Sanjar Atamuradov*

Main category: cs.RO

TL;DR: 该研究评估了MAML与TRPO结合的算法在多样化机器人操作任务中的表现，发现该方法在一次性适应上存在显著进步，但在不同任务之间的有效性存在较大差异。


<details>
  <summary>Details</summary>
Motivation: 快速适应新任务的能力是实际机器人系统的关键需求

Method: 结合模型无关元学习（MAML）和信任区域策略优化（TRPO）评估元世界ML10基准任务

Result: MAML-TRPO在现有任务上实现了一次性适应，并在训练和测试任务中显示了不同程度的成功率

Conclusion: 虽然MAML-TRPO展示了良好的一次性适应能力，但元训练期间的泛化差距揭示了该方法在多样化操作中的局限性，并为未来的任务感知适应和结构化策略架构的研究提供了建议。

Abstract: Meta-learning algorithms enable rapid adaptation to new tasks with minimal data, a critical capability for real-world robotic systems. This paper evaluates Model-Agnostic Meta-Learning (MAML) combined with Trust Region Policy Optimization (TRPO) on the MetaWorld ML10 benchmark, a challenging suite of ten diverse robotic manipulation tasks. We implement and analyze MAML-TRPO's ability to learn a universal initialization that facilitates few-shot adaptation across semantically different manipulation behaviors including pushing, picking, and drawer manipulation. Our experiments demonstrate that MAML achieves effective one-shot adaptation with clear performance improvements after a single gradient update, reaching final success rates of 21.0% on training tasks and 13.2% on held-out test tasks. However, we observe a generalization gap that emerges during meta-training, where performance on test tasks plateaus while training task performance continues to improve. Task-level analysis reveals high variance in adaptation effectiveness, with success rates ranging from 0% to 80% across different manipulation skills. These findings highlight both the promise and current limitations of gradient-based meta-learning for diverse robotic manipulation, and suggest directions for future work in task-aware adaptation and structured policy architectures.

</details>


### [50] [Learning Adaptive Neural Teleoperation for Humanoid Robots: From Inverse Kinematics to End-to-End Control](https://arxiv.org/abs/2511.12390)
*Sanjar Atamuradov*

Main category: cs.RO

TL;DR: 本研究提出了一种基于学习的神经遥操作框架，通过强化学习替代传统的逆运动学和PD控制器，显著提升了人形机器人遥操作的自然性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统遥操作系统在应对外部力量和用户适应性方面存在不足，因此亟需改进以提升操控效果。

Method: 采用强化学习训练的学习策略，直接将VR控制器输入映射到机器人关节命令，同时处理外部扰动，促进平滑轨迹生成。

Result: 实验表明，学习策略在跟踪精度、运动平滑性和力量适应性方面优于传统IK基线，同时保持实时性能。

Conclusion: 基于学习的方法显著提高了人形机器人遥操作系统的自然性和鲁棒性。

Abstract: Virtual reality (VR) teleoperation has emerged as a promising approach for controlling humanoid robots in complex manipulation tasks. However, traditional teleoperation systems rely on inverse kinematics (IK) solvers and hand-tuned PD controllers, which struggle to handle external forces, adapt to different users, and produce natural motions under dynamic conditions. In this work, we propose a learning-based neural teleoperation framework that replaces the conventional IK+PD pipeline with learned policies trained via reinforcement learning. Our approach learns to directly map VR controller inputs to robot joint commands while implicitly handling force disturbances, producing smooth trajectories, and adapting to user preferences. We train our policies in simulation using demonstrations collected from IK-based teleoperation as initialization, then fine-tune them with force randomization and trajectory smoothness rewards. Experiments on the Unitree G1 humanoid robot demonstrate that our learned policies achieve 34% lower tracking error, 45% smoother motions, and superior force adaptation compared to the IK baseline, while maintaining real-time performance (50Hz control frequency). We validate our approach on manipulation tasks including object pick-and-place, door opening, and bimanual coordination. These results suggest that learning-based approaches can significantly improve the naturalness and robustness of humanoid teleoperation systems.

</details>


### [51] [RoboAfford++: A Generative AI-Enhanced Dataset for Multimodal Affordance Learning in Robotic Manipulation and Navigation](https://arxiv.org/abs/2511.12436)
*Xiaoshuai Hao,Yingbo Tang,Lingfeng Zhang,Yanbiao Ma,Yunfeng Diao,Ziyu Jia,Wenbo Ding,Hangjun Ye,Long Chen*

Main category: cs.RO

TL;DR: RoboAfford++是一个用于机器人操作和导航的多模态可用性学习的数据集，解决了视觉语言模型在物体及空间可用性推断中的不足。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在物体和空间可用性的推断上存在不足，缺乏细致的标注数据

Method: 提出RoboAfford++数据集并进行基准测试

Result: RoboAfford++数据集及RoboAfford-Eval基准大幅提高VLM在可用性学习方面的表现

Conclusion: RoboAfford++的数据集有效提升了现有模型对物体和空间可用性的推理能力，验证了该数据集的重要性。

Abstract: Robotic manipulation and navigation are fundamental capabilities of embodied intelligence, enabling effective robot interactions with the physical world. Achieving these capabilities requires a cohesive understanding of the environment, including object recognition to localize target objects, object affordances to identify potential interaction areas and spatial affordances to discern optimal areas for both object placement and robot movement. While Vision-Language Models (VLMs) excel at high-level task planning and scene understanding, they often struggle to infer actionable positions for physical interaction, such as functional grasping points and permissible placement regions. This limitation stems from the lack of fine-grained annotations for object and spatial affordances in their training datasets. To tackle this challenge, we introduce RoboAfford++, a generative AI-enhanced dataset for multimodal affordance learning for both robotic manipulation and navigation. Our dataset comprises 869,987 images paired with 2.0 million question answering (QA) annotations, covering three critical tasks: object affordance recognition to identify target objects based on attributes and spatial relationships, object affordance prediction to pinpoint functional parts for manipulation, and spatial affordance localization to identify free space for object placement and robot navigation. Complementing this dataset, we propose RoboAfford-Eval, a comprehensive benchmark for assessing affordance-aware prediction in real-world scenarios, featuring 338 meticulously annotated samples across the same three tasks. Extensive experimental results reveal the deficiencies of existing VLMs in affordance learning, while fine-tuning on the RoboAfford++ dataset significantly enhances their ability to reason about object and spatial affordances, validating the dataset's effectiveness.

</details>


### [52] [ClutterNav: Gradient-Guided Search for Efficient 3D Clutter Removal with Learned Costmaps](https://arxiv.org/abs/2511.12479)
*Navin Sriram Ravie,Keerthi Vasan M,Bijo Sebastian*

Main category: cs.RO

TL;DR: ClutterNav是一个新颖的决策框架，通过将去除物体的问题视为连续强化学习任务，能够在有效移除物体的同时实现目标物体的高效访问。


<details>
  <summary>Details</summary>
Motivation: 密集的杂乱物品去除是一项具有挑战性的任务，尤其是当目标嵌入在密集配置中时。因此，在尽量减少杂乱配置变化的同时访问目标物品显得尤为重要。

Method: 该方法通过一个移除性批评者进行训练，此批评者根据几何和空间特征评估去除任一物体的成本，并使用集成梯度来评估周围物体的存在或去除对目标可达性的影响。

Result: ClutterNav展示了在部分可观察环境中实时且考虑遮挡的决策能力，能够有效地识别下一个最佳移除物体以访问目标物体。

Conclusion: 通过在模拟和实世界实验中的广泛验证，ClutterNav实现了人类般的战略序列化，能在复杂环境中高效决策。

Abstract: Dense clutter removal for target object retrieval presents a challenging problem, especially when targets are embedded deep within densely-packed configurations. It requires foresight to minimize overall changes to the clutter configuration while accessing target objects, avoiding stack destabilization and reducing the number of object removals required. Rule-based planners when applied to this problem, rely on rigid heuristics, leading to high computational overhead. End-to-end reinforcement learning approaches struggle with interpretability and generalizability over different conditions. To address these issues, we present ClutterNav, a novel decision-making framework that can identify the next best object to be removed so as to access a target object in a given clutter, while minimising stack disturbances. ClutterNav formulates the problem as a continuous reinforcement learning task, where each object removal dynamically updates the understanding of the scene. A removability critic, trained from demonstrations, estimates the cost of removing any given object based on geometric and spatial features. This learned cost is complemented by integrated gradients that assess how the presence or removal of surrounding objects influences the accessibility of the target. By dynamically prioritizing actions that balance immediate removability against long-term target exposure, ClutterNav achieves near human-like strategic sequencing, without predefined heuristics. The proposed approach is validated extensively in simulation and over real-world experiments. The results demonstrate real-time, occlusion-aware decision-making in partially observable environments.

</details>


### [53] [Botany Meets Robotics in Alpine Scree Monitoring](https://arxiv.org/abs/2511.12526)
*Davide De Benedittis,Giovanni Di Lorenzo,Franco Angelini,Barbara Valle,Marina Serena Borgatti,Paolo Remagnino,Marco Caccianiga,Manolo Garabini*

Main category: cs.RO

TL;DR: 本研究提出了一种新方法，通过使用腿部机器人辅助植物学家进行石砾栖息地监测，利用深度学习提高植物物种识别的效率，推动可持续生态监测。


<details>
  <summary>Details</summary>
Motivation: 鉴于生物多样性丧失和环境退化问题的加剧，栖息地监测在应对这些挑战中至关重要，而传统监测方法资源密集且耗时。

Method: 通过在意大利阿尔卑斯生物区的两次实地考察中，使用ANYmal C机器人结合深度学习技术，收集和识别关键植物物种的数据。

Result: 研究结果显示灵活的腿部机器人能够在困难地形中导航，提高石砾栖息地监测的频率和效率，并与植物学家进行传统的植物群落调查相结合，优化现场操作。

Conclusion: 该研究表明，腿部机器人能够有效提高石砾栖息地监测的效率和频率，促进数据的获取和使用，推动生态监测的可持续发展。

Abstract: According to the European Union's Habitat Directive, habitat monitoring plays a critical role in response to the escalating problems posed by biodiversity loss and environmental degradation. Scree habitats, hosting unique and often endangered species, face severe threats from climate change due to their high-altitude nature. Traditionally, their monitoring has required highly skilled scientists to conduct extensive fieldwork in remote, potentially hazardous locations, making the process resource-intensive and time-consuming. This paper presents a novel approach for scree habitat monitoring using a legged robot to assist botanists in data collection and species identification. Specifically, we deployed the ANYmal C robot in the Italian Alpine bio-region in two field campaigns spanning two years and leveraged deep learning to detect and classify key plant species of interest. Our results demonstrate that agile legged robots can navigate challenging terrains and increase the frequency and efficiency of scree monitoring. When paired with traditional phytosociological surveys performed by botanists, this robotics-assisted protocol not only streamlines field operations but also enhances data acquisition, storage, and usage. The outcomes of this research contribute to the evolving landscape of robotics in environmental science, paving the way for a more comprehensive and sustainable approach to habitat monitoring and preservation.

</details>


### [54] [EcoFlight: Finding Low-Energy Paths Through Obstacles for Autonomous Sensing Drones](https://arxiv.org/abs/2511.12618)
*Jordan Leyva,Nahim J. Moran Vera,Yihan Xu,Adrien Durasno,Christopher U. Romero,Tendai Chimuka,Gabriel O. Huezo Ramirez,Ziqian Dong,Roberto Rojas-Cessa*

Main category: cs.RO

TL;DR: EcoFlight是一种新型的能效路径规划算法，能够在复杂障碍环境中提供低能耗的飞行路径，相较于传统算法表现更佳。


<details>
  <summary>Details</summary>
Motivation: 目前大多数飞行路径规划方案未充分考虑障碍物的影响，而障碍物会显著增加能耗，因此有必要开发一种新的路径规划算法以提高能效。

Method: 提出了一种新的EcoFlight算法，通过模型化无人机的推进系统和飞行动力学，来确定在3D空间中最低能量消耗的飞行路径。

Result: 经过广泛评估，EcoFlight在不同障碍密度下与直接飞行和最短距离方案进行比较，结果显示EcoFlight在能耗上具有优势，特别是在障碍物密度高的环境中。还发现合适的飞行速度可以进一步提高能量节省。

Conclusion: EcoFlight算法在存在障碍的情况下，能够有效找到能耗更低的飞行路径，尤其在障碍密集的环境中表现优异。

Abstract: Obstacle avoidance path planning for uncrewed aerial vehicles (UAVs), or drones, is rarely addressed in most flight path planning schemes, despite obstacles being a realistic condition. Obstacle avoidance can also be energy-intensive, making it a critical factor in efficient point-to-point drone flights. To address these gaps, we propose EcoFlight, an energy-efficient pathfinding algorithm that determines the lowest-energy route in 3D space with obstacles. The algorithm models energy consumption based on the drone propulsion system and flight dynamics. We conduct extensive evaluations, comparing EcoFlight with direct-flight and shortest-distance schemes. The simulation results across various obstacle densities show that EcoFlight consistently finds paths with lower energy consumption than comparable algorithms, particularly in high-density environments. We also demonstrate that a suitable flying speed can further enhance energy savings.

</details>


### [55] [Task-Aware Morphology Optimization of Planar Manipulators via Reinforcement Learning](https://arxiv.org/abs/2511.12650)
*Arvind Kumar Mishra,Sohom Chakrabarty*

Main category: cs.RO

TL;DR: 本研究表明，强化学习可以有效地用于机器人操控器的形态优化，无需解析解，特别适用于高维空间。


<details>
  <summary>Details</summary>
Motivation: 大多数形态设计任务没有封闭解析解，随着维度增加，网格搜索或启发式搜索代价昂贵，因此探索强化学习作为可扩展替代方案。

Method: 利用Yoshikawa的可操控性指数，采用强化学习方法优化平面机器人操控器的形态，比较三种RL算法与网格搜索及黑箱优化器的表现。

Result: 所有方法都收敛至解析解，在无解析结构情况下，数值恢复最优解是可能的，而在非解析设置下，强化学习仍然可靠收敛。

Conclusion: 强化学习在已知最优解的恢复和无解析解的形态优化问题中表现出有效性。

Abstract: In this work, Yoshikawa's manipulability index is used to investigate reinforcement learning (RL) as a framework for morphology optimization in planar robotic manipulators. A 2R manipulator tracking a circular end-effector path is first examined because this case has a known analytical optimum: equal link lengths and the second joint orthogonal to the first. This serves as a validation step to test whether RL can rediscover the optimum using reward feedback alone, without access to the manipulability expression or the Jacobian. Three RL algorithms (SAC, DDPG, and PPO) are compared with grid search and black-box optimizers, with morphology represented by a single action parameter phi that maps to the link lengths. All methods converge to the analytical solution, showing that numerical recovery of the optimum is possible without supplying analytical structure.
  Most morphology design tasks have no closed-form solutions, and grid or heuristic search becomes expensive as dimensionality increases. RL is therefore explored as a scalable alternative. The formulation used for the circular path is extended to elliptical and rectangular paths by expanding the action space to the full morphology vector (L1, L2, theta2). In these non-analytical settings, RL continues to converge reliably, whereas grid and black-box methods require far larger evaluation budgets. These results indicate that RL is effective for both recovering known optima and solving morphology optimization problems without analytical solutions.

</details>


### [56] [Prompt-Driven Domain Adaptation for End-to-End Autonomous Driving via In-Context RL](https://arxiv.org/abs/2511.12755)
*Aleesha Khurram,Amir Moeini,Shangtong Zhang,Rohan Chandra*

Main category: cs.RO

TL;DR:  本文提出了一种新的推理时少-shot 提示驱动领域适应方法，用于解决恶劣天气条件下的自主驾驶问题，采用了上下文强化学习，实验效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation:  解决自主驾驶系统在恶劣天气下的领域适应问题，克服传统领域适应策略的局限性。

Method:  inference-time few-shot prompt-driven domain adaptation using in-context reinforcement learning (ICRL)

Result:  实验表明，ICRL在CARLA模拟器中优于现有的提示驱动领域适应基线，提供更安全、高效和舒适的驾驶策略。

Conclusion:  通过扩展提示驱动领域适应到封闭驾驶并使用一般轨迹，ICRL在应对挑战性驾驶环境方面取得了显著进展。

Abstract: Despite significant progress and advances in autonomous driving, many end-to-end systems still struggle with domain adaptation (DA), such as transferring a policy trained under clear weather to adverse weather conditions. Typical DA strategies in the literature include collecting additional data in the target domain or re-training the model, or both. Both these strategies quickly become impractical as we increase scale and complexity of driving. These limitations have encouraged investigation into few-shot and zero-shot prompt-driven DA at inference time involving LLMs and VLMs. These methods work by adding a few state-action trajectories during inference to the prompt (similar to in-context learning). However, there are two limitations of such an approach: $(i)$ prompt-driven DA methods are currently restricted to perception tasks such as detection and segmentation and $(ii)$ they require expert few-shot data. In this work, we present a new approach to inference-time few-shot prompt-driven DA for closed-loop autonomous driving in adverse weather condition using in-context reinforcement learning (ICRL). Similar to other prompt-driven DA methods, our approach does not require any updates to the model parameters nor does it require additional data collection in adversarial weather regime. Furthermore, our approach advances the state-of-the-art in prompt-driven DA by extending to closed driving using general trajectories observed during inference. Our experiments using the CARLA simulator show that ICRL results in safer, more efficient, and more comfortable driving policies in the target domain compared to state-of-the-art prompt-driven DA baselines.

</details>


### [57] [DR. Nav: Semantic-Geometric Representations for Proactive Dead-End Recovery and Navigation](https://arxiv.org/abs/2511.12778)
*Vignesh Rajagopal,Kasun Weerakoon Kulathun Mudiyanselage,Gershom Devake Seneviratne,Pon Aswin Sankaralingam,Mohamed Elnoor,Jing Liang,Rohan Chandra,Dinesh Manocha*

Main category: cs.RO

TL;DR: DR. Nav 是一种新型自主导航方法，结合死胡同检测与恢复，通过实时语义成本地图和 RGB-LiDAR 融合来提升导航性能。


<details>
  <summary>Details</summary>
Motivation: 在复杂和未映射的环境中，机器人需要高效的死胡同检测与恢复策略，以保证导航的安全性和效率。

Method: DR. Nav 结合 RGB-LiDAR 融合与贝叶斯推断，生成实时更新的语义成本地图，预测死胡同及恢复点。

Result: DR. Nav 是一种创新的自主导航方法，专注于死胡同检测和恢复，尤其适合复杂环境。该方法通过生成实时语义成本地图，结合 RGB-LiDAR 融合技术，并通过贝叶斯推断不断更新，提高了导航的鲁棒性。

Conclusion: DR. Nav 在多个室内外场景中的测试结果表明，其有效性显著高于现有的规划方法，准确率提高 83.33%，路径效率提高 52.4%。

Abstract: We present DR. Nav (Dead-End Recovery-aware Navigation), a novel approach to autonomous navigation in scenarios where dead-end detection and recovery are critical, particularly in unstructured environments where robots must handle corners, vegetation occlusions, and blocked junctions. DR. Nav introduces a proactive strategy for navigation in unmapped environments without prior assumptions. Our method unifies dead-end prediction and recovery by generating a single, continuous, real-time semantic cost map. Specifically, DR. Nav leverages cross-modal RGB-LiDAR fusion with attention-based filtering to estimate per-cell dead-end likelihoods and recovery points, which are continuously updated through Bayesian inference to enhance robustness. Unlike prior mapping methods that only encode traversability, DR. Nav explicitly incorporates recovery-aware risk into the navigation cost map, enabling robots to anticipate unsafe regions and plan safer alternative trajectories. We evaluate DR. Nav across multiple dense indoor and outdoor scenarios and demonstrate an increase of 83.33% in accuracy in detection, a 52.4% reduction in time-to-goal (path efficiency), compared to state-of-the-art planners such as DWA, MPPI, and Nav2 DWB. Furthermore, the dead-end classifier functions

</details>


### [58] [ActiveGrasp: Information-Guided Active Grasping with Calibrated Energy-based Model](https://arxiv.org/abs/2511.12795)
*Boshu Lei,Wen Jiang,Kostas Daniilidis*

Main category: cs.RO

TL;DR: 该研究提出了一种新模型，通过优化抓取姿态生成和主动视角选择，解决了机器人在拥挤环境中抓取物体的难题，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 针对机器人在拥挤环境中抓取物体的挑战，改善信息增益估计与抓取分布的关联。

Method: 提出了一种能量基础模型用于抓取姿态生成，并通过估计抓取分布的信息增益选择主动视角。

Result: 实验结果表明，模型在模拟环境和真实机器人设置中能够高效地抓取物体，且提供了可再生的实验平台。

Conclusion: 本模型能够在有限视角预算下，在拥挤环境中成功抓取物体，优于现有的模型。

Abstract: Grasping in a densely cluttered environment is a challenging task for robots. Previous methods tried to solve this problem by actively gathering multiple views before grasp pose generation. However, they either overlooked the importance of the grasp distribution for information gain estimation or relied on the projection of the grasp distribution, which ignores the structure of grasp poses on the SE(3) manifold. To tackle these challenges, we propose a calibrated energy-based model for grasp pose generation and an active view selection method that estimates information gain from grasp distribution. Our energy-based model captures the multi-modality nature of grasp distribution on the SE(3) manifold. The energy level is calibrated to the success rate of grasps so that the predicted distribution aligns with the real distribution. The next best view is selected by estimating the information gain for grasp from the calibrated distribution conditioned on the reconstructed environment, which could efficiently drive the robot to explore affordable parts of the target object. Experiments on simulated environments and real robot setups demonstrate that our model could successfully grasp objects in a cluttered environment with limited view budgets compared to previous state-of-the-art models. Our simulated environment can serve as a reproducible platform for future research on active grasping. The source code of our paper will be made public when the paper is released to the public.

</details>


### [59] [Structured Imitation Learning of Interactive Policies through Inverse Games](https://arxiv.org/abs/2511.12848)
*Max M. Sun,Todd Murphey*

Main category: cs.RO

TL;DR: 提出了一种新的模仿学习框架，通过将个体行为模式学习与多智能体交互依赖结构学习结合，有效提升了在交互环境下的策略学习。


<details>
  <summary>Details</summary>
Motivation: 在共享空间中与人类协调的交互策略的模仿学习仍然具有挑战性，尤其是在多智能体交互中的行为复杂性高于非交互任务。

Method: 结合生成单智能体策略学习与灵活表现的博弈论结构的有结构的模仿学习框架

Result: 在一个合成的5智能体社交导航任务中，方法显著提升了非交互策略，并且在仅使用50个演示的情况下，表现与真实的交互策略相当。

Conclusion: 结构化模仿学习在交互环境下显示出潜力，能够显著改善策略学习的效果。

Abstract: Generative model-based imitation learning methods have recently achieved strong results in learning high-complexity motor skills from human demonstrations. However, imitation learning of interactive policies that coordinate with humans in shared spaces without explicit communication remains challenging, due to the significantly higher behavioral complexity in multi-agent interactions compared to non-interactive tasks. In this work, we introduce a structured imitation learning framework for interactive policies by combining generative single-agent policy learning with a flexible yet expressive game-theoretic structure. Our method explicitly separates learning into two steps: first, we learn individual behavioral patterns from multi-agent demonstrations using standard imitation learning; then, we structurally learn inter-agent dependencies by solving an inverse game problem. Preliminary results in a synthetic 5-agent social navigation task show that our method significantly improves non-interactive policies and performs comparably to the ground truth interactive policy using only 50 demonstrations. These results highlight the potential of structured imitation learning in interactive settings.

</details>


### [60] [Towards High-Consistency Embodied World Model with Multi-View Trajectory Videos](https://arxiv.org/abs/2511.12882)
*Taiyi Su,Jian Zhu,Yaxuan Li,Chong Ma,Zitai Huang,Yichen Zhu,Hanli Wang,Yi Xu*

Main category: cs.RO

TL;DR: MTV-World通过多视角轨迹视频控制优化机器人在物理世界中的视觉运动预测，提高了交互的一致性和精度。


<details>
  <summary>Details</summary>
Motivation: 现有的身体世界模型在将低级动作转化为机器人运动时存在不一致，旨在通过MTV-World解决精确交互中的限制。

Method: 该方法使用通过相机内外参数和笛卡尔空间变换获得的轨迹视频作为控制信号，采用多视图框架来弥补空间信息损失，确保与物理世界的高度一致性。

Result: MTV-World模型引入了多视角轨迹视频控制，改进了身体世界模型在精确视觉运动预测和物理交互中的表现，特别是在复杂的双臂机器人场景中，表现出高精度的控制执行和交互建模能力。

Conclusion: MTV-World在复杂的机器人的双臂场景中表现出色，实现了精确的控制和物理交互建模。

Abstract: Embodied world models aim to predict and interact with the physical world through visual observations and actions. However, existing models struggle to accurately translate low-level actions (e.g., joint positions) into precise robotic movements in predicted frames, leading to inconsistencies with real-world physical interactions. To address these limitations, we propose MTV-World, an embodied world model that introduces Multi-view Trajectory-Video control for precise visuomotor prediction. Specifically, instead of directly using low-level actions for control, we employ trajectory videos obtained through camera intrinsic and extrinsic parameters and Cartesian-space transformation as control signals. However, projecting 3D raw actions onto 2D images inevitably causes a loss of spatial information, making a single view insufficient for accurate interaction modeling. To overcome this, we introduce a multi-view framework that compensates for spatial information loss and ensures high-consistency with physical world. MTV-World forecasts future frames based on multi-view trajectory videos as input and conditioning on an initial frame per view. Furthermore, to systematically evaluate both robotic motion precision and object interaction accuracy, we develop an auto-evaluation pipeline leveraging multimodal large models and referring video object segmentation models. To measure spatial consistency, we formulate it as an object location matching problem and adopt the Jaccard Index as the evaluation metric. Extensive experiments demonstrate that MTV-World achieves precise control execution and accurate physical interaction modeling in complex dual-arm scenarios.

</details>


### [61] [Air-Chamber Based Soft Six-Axis Force/Torque Sensor for Human-Robot Interaction](https://arxiv.org/abs/2511.12896)
*Jun Huo,Hongge Ru,Bo Yang,Xingjian Chen,Xi Li,Jian Huang*

Main category: cs.RO

TL;DR: 本文提出了一种软气室六轴力/扭矩传感器，通过有效解耦方法解决了六轴耦合问题，实验表明其在保持柔性的同时具有良好的传感性能。


<details>
  <summary>Details</summary>
Motivation: 基于软多轴力/扭矩传感器的应用需求，开发一种能够实现准确六轴力测量的传感器，克服交叉轴耦合带来的校准问题和精度下降。

Method: 开发了一种带有16通道气压计的软气室六轴力/扭矩传感器，并提出了一种基于刚柔分级结构的有效解耦方法。

Result: 原型传感器的静态负载响应、动态负载响应和动态响应特性经过量化测量，具有50 N的测量范围和1 Nm的扭矩，平均偏差、重复性、不线性和滞后分别为4.9%、2.7%、5.8%和6.7%。

Conclusion: 原型传感器在保持软性的同时表现出令人满意的传感性能。

Abstract: Soft multi-axis force/torque sensors provide safe and precise force interaction. Capturing the complete degree-of-freedom of force is imperative for accurate force measurement with six-axis force/torque sensors. However, cross-axis coupling can lead to calibration issues and decreased accuracy. In this instance, developing a soft and accurate six-axis sensor is a challenging task. In this paper, a soft air-chamber type six-axis force/torque sensor with 16-channel barometers is introduced, which housed in hyper-elastic air chambers made of silicone rubber. Additionally, an effective decoupling method is proposed, based on a rigid-soft hierarchical structure, which reduces the six-axis decoupling problem to two three-axis decoupling problems. Finite element model simulation and experiments demonstrate the compatibility of the proposed approach with reality. The prototype's sensing performance is quantitatively measured in terms of static load response, dynamic load response and dynamic response characteristic. It possesses a measuring range of 50 N force and 1 Nm torque, and the average deviation, repeatability, non-linearity and hysteresis are 4.9$\%$, 2.7$\%$, 5.8$\%$ and 6.7$\%$, respectively. The results indicate that the prototype exhibits satisfactory sensing performance while maintaining its softness due to the presence of soft air chambers.

</details>


### [62] [TOPP-DWR: Time-Optimal Path Parameterization of Differential-Driven Wheeled Robots Considering Piecewise-Constant Angular Velocity Constraints](https://arxiv.org/abs/2511.12910)
*Yong Li,Yujun Huang,Yi Chen,Hui Cheng*

Main category: cs.RO

TL;DR: 提出了一种名为TOPP-DWR的算法，解决了现有移动机器人路径参数化中的约束问题，实现时间最优路径，同时在实际应用中表现出良好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的移动机器人任务时间最优路径参数化研究通常忽视了角速度和关节速度约束，这会降低控制性能，因此需要一个系统的、实用的算法来解决这个问题。

Method: 使用非均匀B样条表示初始轨迹，整合角速度、关节速度、线速度和线加速度约束，并将问题转化为二阶锥规划(SOCP)，以提高计算效率。

Result: 通过比较实验和真实世界中的自主导航实验，表明TOPP-DWR相比于传统方法具有更强的性能，能在满足约束的情况下实现时间最优路径。

Conclusion: TOPP-DWR 算法在遵循所有约束的同时实现了时间最优路径参数化，验证了其在实际应用中的可行性和有效性。

Abstract: Differential-driven wheeled robots (DWR) represent the quintessential type of mobile robots and find extensive appli- cations across the robotic field. Most high-performance control approaches for DWR explicitly utilize the linear and angular velocities of the trajectory as control references. However, existing research on time-optimal path parameterization (TOPP) for mobile robots usually neglects the angular velocity and joint vel- ocity constraints, which can result in degraded control perfor- mance in practical applications. In this article, a systematic and practical TOPP algorithm named TOPP-DWR is proposed for DWR and other mobile robots. First, the non-uniform B-spline is adopted to represent the initial trajectory in the task space. Second, the piecewise-constant angular velocity, as well as joint velocity, linear velocity, and linear acceleration constraints, are incorporated into the TOPP problem. During the construction of the optimization problem, the aforementioned constraints are uniformly represented as linear velocity constraints. To boost the numerical computational efficiency, we introduce a slack variable to reformulate the problem into second-order-cone programming (SOCP). Subsequently, comparative experiments are conducted to validate the superiority of the proposed method. Quantitative performance indexes show that TOPP-DWR achieves TOPP while adhering to all constraints. Finally, field autonomous navigation experiments are carried out to validate the practicability of TOPP-DWR in real-world applications.

</details>


### [63] [DiffuDepGrasp: Diffusion-based Depth Noise Modeling Empowers Sim2Real Robotic Grasping](https://arxiv.org/abs/2511.12912)
*Yingting Zhou,Wenbo Cui,Weiheng Liu,Guixing Chen,Haoran Li,Dongbin Zhao*

Main category: cs.RO

TL;DR: DiffuDepGrasp提出了一种通过仿真训练来零-shot 转移至物理机器人的抓取策略，克服数据效率低下和部署复杂性问题。


<details>
  <summary>Details</summary>
Motivation: 解决在将深度基础的策略从模拟转移到物理机器人中面临的重大sim2real差距和数据效率及部署复杂性问题。

Method: 提出DiffuDepGrasp框架，包括Diffusion Depth Generator的两个模块，分别是能捕捉复杂传感器噪声分布的Diffusion Depth Module和保持度量准确性的Noise Grafting Module。

Result: DiffuDepGrasp是一种有效且鲁棒的抓取策略，使得在没有额外训练的情况下将模拟中的策略转移到物理机器人上成为可能，通过将几何上完美的模拟深度与学习得到的传感器真实噪声结合，从而解决了数据效率和部署复杂性两大挑战。

Conclusion: DiffuDepGrasp架构实现了高效的零-shot 策略传递，具有显著的成功率和良好的泛化能力，能够在部署时仅使用原始深度输入，消除计算开销。

Abstract: Transferring the depth-based end-to-end policy trained in simulation to physical robots can yield an efficient and robust grasping policy, yet sensor artifacts in real depth maps like voids and noise establish a significant sim2real gap that critically impedes policy transfer. Training-time strategies like procedural noise injection or learned mappings suffer from data inefficiency due to unrealistic noise simulation, which is often ineffective for grasping tasks that require fine manipulation or dependency on paired datasets heavily. Furthermore, leveraging foundation models to reduce the sim2real gap via intermediate representations fails to mitigate the domain shift fully and adds computational overhead during deployment. This work confronts dual challenges of data inefficiency and deployment complexity. We propose DiffuDepGrasp, a deploy-efficient sim2real framework enabling zero-shot transfer through simulation-exclusive policy training. Its core innovation, the Diffusion Depth Generator, synthesizes geometrically pristine simulation depth with learned sensor-realistic noise via two synergistic modules. The first Diffusion Depth Module leverages temporal geometric priors to enable sample-efficient training of a conditional diffusion model that captures complex sensor noise distributions, while the second Noise Grafting Module preserves metric accuracy during perceptual artifact injection. With only raw depth inputs during deployment, DiffuDepGrasp eliminates computational overhead and achieves a 95.7% average success rate on 12-object grasping with zero-shot transfer and strong generalization to unseen objects.Project website: https://diffudepgrasp.github.io/.

</details>


### [64] [GUIDE: Gaussian Unified Instance Detection for Enhanced Obstacle Perception in Autonomous Driving](https://arxiv.org/abs/2511.12941)
*Chunyong Hu,Qi Luo,Jianyun Xu,Song Wang,Qiang Li,Sheng Yang*

Main category: cs.RO

TL;DR: GUIDE是一个新的自主驾驶框架，使用3D高斯方法进行障碍物检测和占用预测，相比传统方法在性能和效率上有显著提升。


<details>
  <summary>Details</summary>
Motivation: 传统方法无法有效处理不规则形状的障碍物，因此需要一种新的方法来提升检测和追踪能力。

Method: GUIDE框架利用3D高斯进行实例检测和占用预测，采用稀疏表示策略，实现高效且精确的场景理解。

Result: 在nuScenes数据集上的实验验证显示，GUIDE的实例占用mAP达到21.61，性能提升50%，且追踪能力具竞争力。

Conclusion: GUIDE为自主感知系统设立了新的基准，有助于更好地处理复杂的真实世界驾驶环境。

Abstract: In the realm of autonomous driving, accurately detecting surrounding obstacles is crucial for effective decision-making. Traditional methods primarily rely on 3D bounding boxes to represent these obstacles, which often fail to capture the complexity of irregularly shaped, real-world objects. To overcome these limitations, we present GUIDE, a novel framework that utilizes 3D Gaussians for instance detection and occupancy prediction. Unlike conventional occupancy prediction methods, GUIDE also offers robust tracking capabilities. Our framework employs a sparse representation strategy, using Gaussian-to-Voxel Splatting to provide fine-grained, instance-level occupancy data without the computational demands associated with dense voxel grids. Experimental validation on the nuScenes dataset demonstrates GUIDE's performance, with an instance occupancy mAP of 21.61, marking a 50\% improvement over existing methods, alongside competitive tracking capabilities. GUIDE establishes a new benchmark in autonomous perception systems, effectively combining precision with computational efficiency to better address the complexities of real-world driving environments.

</details>


### [65] [SplatSearch: Instance Image Goal Navigation for Mobile Robots using 3D Gaussian Splatting and Diffusion Models](https://arxiv.org/abs/2511.12972)
*Siddarth Narasimhan,Matthew Lisondra,Haitong Wang,Goldie Nejat*

Main category: cs.RO

TL;DR: 本文提出SplatSearch，解决移动机器人在未知环境中仅依赖单个参考目标图像进行导航的挑战，通过稀疏视图3D重建和多视角扩散模型显著提高了性能。


<details>
  <summary>Details</summary>
Motivation: 解决移动机器人在未知环境中仅靠单个参考目标图像搜索特定物体或人的挑战，尤其是在参考图像取自任意视角且使用稀疏视图场景重建的情况下。

Method: 提出了一种新颖的架构SplatSearch，结合稀疏视图的3D高斯点云重建，通过多视角扩散模型完成图像缺失区域，并引入了一种新型前沿探索策略。

Result: 通过SplatSearch架构，机器人能够更有效地结合视觉和语义信息，优先探索与目标图像相关的前沿位置，提升了搜索任务的成功率和效率。

Conclusion: SplatSearch在成功率和成功路径长度上优于当前的最先进方法，验证了其有效性。

Abstract: The Instance Image Goal Navigation (IIN) problem requires mobile robots deployed in unknown environments to search for specific objects or people of interest using only a single reference goal image of the target. This problem can be especially challenging when: 1) the reference image is captured from an arbitrary viewpoint, and 2) the robot must operate with sparse-view scene reconstructions. In this paper, we address the IIN problem, by introducing SplatSearch, a novel architecture that leverages sparse-view 3D Gaussian Splatting (3DGS) reconstructions. SplatSearch renders multiple viewpoints around candidate objects using a sparse online 3DGS map, and uses a multi-view diffusion model to complete missing regions of the rendered images, enabling robust feature matching against the goal image. A novel frontier exploration policy is introduced which uses visual context from the synthesized viewpoints with semantic context from the goal image to evaluate frontier locations, allowing the robot to prioritize frontiers that are semantically and visually relevant to the goal image. Extensive experiments in photorealistic home and real-world environments validate the higher performance of SplatSearch against current state-of-the-art methods in terms of Success Rate and Success Path Length. An ablation study confirms the design choices of SplatSearch.

</details>


### [66] [CUTE-Planner: Confidence-aware Uneven Terrain Exploration Planner](https://arxiv.org/abs/2511.12984)
*Miryeong Park,Dongjin Cho,Sanghyun Kim,Younggun Cho*

Main category: cs.RO

TL;DR: 本文提出一种新的框架来解决行星探测机器人的高度不确定性问题，实现了显著的任务成功率和不确定性减少。


<details>
  <summary>Details</summary>
Motivation: 现有方法未能有效处理复杂特征附近的高度不确定性，且未考虑降低不确定性的探索策略，影响导航安全性和地图质量

Method: 提出一个集成安全路径生成、自适应置信度更新和基于置信度的探索策略的框架

Result: 通过模拟月球实验，使用新颖的低置信区域比例指标，取得69%的不确定性减少，任务成功率达到100%；而基线GBP为0%。

Conclusion: 提出的框架在探索安全性和地图可靠性方面取得了显著改善，适用于未来的航天任务。

Abstract: Planetary exploration robots must navigate uneven terrain while building reliable maps for space missions. However, most existing methods incorporate traversability constraints but may not handle high uncertainty in elevation estimates near complex features like craters, do not consider exploration strategies for uncertainty reduction, and typically fail to address how elevation uncertainty affects navigation safety and map quality. To address the problems, we propose a framework integrating safe path generation, adaptive confidence updates, and confidence-aware exploration strategies. Using Kalman-based elevation estimation, our approach generates terrain traversability and confidence scores, then incorporates them into Graph-Based exploration Planner (GBP) to prioritize exploration of traversable low-confidence regions. We evaluate our framework through simulated lunar experiments using a novel low-confidence region ratio metric, achieving 69% uncertainty reduction compared to baseline GBP. In terms of mission success rate, our method achieves 100% while baseline GBP achieves 0%, demonstrating improvements in exploration safety and map reliability.

</details>


### [67] [APP: A* Post-Processing Algorithm for Robots with Bidirectional Shortcut and Path Perturbation](https://arxiv.org/abs/2511.13042)
*Yong Li,Hui Cheng*

Main category: cs.RO

TL;DR: 为A*及其他图搜索规划器提出了APP后处理算法，显著优化了路径规划效果


<details>
  <summary>Details</summary>
Motivation: 现有的A*及图搜索规划器生成的路径通常不够短，且存在不必要的转向，缺乏人类直觉中的直线路径特征

Method: 提出了一种通用的后处理算法APP，基于成本地图，结合双向顶点减少和迭代路径扰动算法

Result: APP在规划时间、路径长度和不必要的转向次数方面优于现有的方法，并通过实地导航实验验证其实用性

Conclusion: APP算法能够有效减少路径长度和不必要的转向，提升路径平滑性，在实际应用中表现出良好的效果

Abstract: Paths generated by A* and other graph-search-based planners are widely used in the robotic field. Due to the restricted node-expansion directions, the resulting paths are usually not the shortest. Besides, unnecessary heading changes, or zig-zag patterns, exist even when no obstacle is nearby, which is inconsistent with the human intuition that the path segments should be straight in wide-open space due to the absence of obstacles. This article puts forward a general and systematic post-processing algorithm for A* and other graph-search-based planners. The A* post-processing algorithm, called APP, is developed based on the costmap, which is widely used in commercial service robots. First, a bidirectional vertices reduction algorithm is proposed to tackle the asymm- etry of the path and the environments. During the forward and backward vertices reduction, a thorough shortcut strategy is put forward to improve the path-shortening performance and avoid unnecessary heading changes. Second, an iterative path perturbation algorithm is adopted to locally reduce the number of unnecessary heading changes and improve the path smooth- ness. Comparative experiments are then carried out to validate the superiority of the proposed method. Quantitative performance indexes show that APP outperforms the existing methods in planning time, path length as well as the number of unnecessary heading changes. Finally, field navigation experiments are carried out to verify the practicability of APP.

</details>


### [68] [Unidirectional-Road-Network-Based Global Path Planning for Cleaning Robots in Semi-Structured Environments](https://arxiv.org/abs/2511.13048)
*Yong Li,Hui Cheng*

Main category: cs.RO

TL;DR: 本文提出了一种针对半结构化环境的全球路径规划新方法，平衡路径长度与交通规则，提高效率。


<details>
  <summary>Details</summary>
Motivation: 现有的路径规划方法主要关注路径长度而忽视交通规则，导致高频重规划和碰撞风险，迫切需要改进。

Method: 构建单向道路网络表示交通约束，通过混合策略和双层势能图来保证规划结果，实现路径优化。

Result: 本文提出了一种在半结构化环境中改进全球路径规划性能的系统方法。通过构建单向道路网络表示交通约束，并采用混合策略实现规划结果的保证。

Conclusion: 比较实验结果表明，所提方法在路径长度与道路网络一致性之间具有更好的平衡，验证了其有效性。

Abstract: Practical global path planning is critical for commercializing cleaning robots working in semi-structured environments. In the literature, global path planning methods for free space usually focus on path length and neglect the traffic rule constraints of the environments, which leads to high-frequency re-planning and increases collision risks. In contrast, those for structured environments are developed mainly by strictly complying with the road network representing the traffic rule constraints, which may result in an overlong path that hinders the overall navigation efficiency. This article proposes a general and systematic approach to improve global path planning performance in semi-structured environments. A unidirectional road network is built to represent the traffic constraints in semi-structured environments and a hybrid strategy is proposed to achieve a guaranteed planning result.Cutting across the road at the starting and the goal points are allowed to achieve a shorter path. Especially, a two-layer potential map is proposed to achieve a guaranteed performance when the starting and the goal points are in complex intersections. Comparative experiments are carried out to validate the effectiveness of the proposed method. Quantitative experimental results show that, compared with the state-of-art, the proposed method guarantees a much better balance between path length and the consistency with the road network.

</details>


### [69] [Orientation-Free Neural Network-Based Bias Estimation for Low-Cost Stationary Accelerometers](https://arxiv.org/abs/2511.13071)
*Michal Levin,Itzik Klein*

Main category: cs.RO

TL;DR: 提出了一种无需传感器方向和旋转的学习型校准方法，提高了低成本加速度计的性能，适用于快速现场部署。


<details>
  <summary>Details</summary>
Motivation: 低成本微电机械加速度计在导航、机器人和消费设备中广泛应用，但其性能常因偏差误差而降低，传统校准方法往往要求特殊的条件。

Method: 一种基于无模型学习的校准方法，无需传感器方向知识或旋转传感器即可在静态条件下估计加速度计偏差。

Result: 实验验证表明，该方法在六个加速度计收集的13.39小时数据集上，误差水平比传统技术低52%以上。

Conclusion: 所提出的方法显著提升了低成本惯性传感器的可靠性，并消除了对水平校准的需求。

Abstract: Low-cost micro-electromechanical accelerometers are widely used in navigation, robotics, and consumer devices for motion sensing and position estimation. However, their performance is often degraded by bias errors. To eliminate deterministic bias terms a calibration procedure is applied under stationary conditions. It requires accelerom- eter leveling or complex orientation-dependent calibration procedures. To overcome those requirements, in this paper we present a model-free learning-based calibration method that estimates accelerometer bias under stationary conditions, without requiring knowledge of the sensor orientation and without the need to rotate the sensors. The proposed approach provides a fast, practical, and scalable solution suitable for rapid field deployment. Experimental validation on a 13.39-hour dataset collected from six accelerometers shows that the proposed method consistently achieves error levels more than 52% lower than traditional techniques. On a broader scale, this work contributes to the advancement of accurate calibration methods in orientation-free scenarios. As a consequence, it improves the reliability of low-cost inertial sensors in diverse scientific and industrial applications and eliminates the need for leveled calibration.

</details>


### [70] [ResAlignNet: A Data-Driven Approach for INS/DVL Alignment](https://arxiv.org/abs/2511.13096)
*Guy Damari,Itzik Klein*

Main category: cs.RO

TL;DR: 本研究提出ResAlignNet，一种基于数据驱动的方法，通过1D ResNet-18架构快速实现水下传感器的对齐，显著提高导航准确性和灵活性。


<details>
  <summary>Details</summary>
Motivation: Overcome limitations of standard model-based sensor alignment methods, such as lengthy convergence times and dependence on external aids.

Method: ResAlignNet, a data-driven approach using 1D ResNet-18 architecture for sensor alignment

Result: Achieves alignment accuracy within 0.8° in 25 seconds, with a 65% reduction in convergence time compared to standard methods.

Conclusion: ResAlignNet显著改善了水下导航能力，通过快速、传感器无关的对齐方案，适用于不同的操作场景和传感器规格。

Abstract: Autonomous underwater vehicles rely on precise navigation systems that combine the inertial navigation system and the Doppler velocity log for successful missions in challenging environments where satellite navigation is unavailable. The effectiveness of this integration critically depends on accurate alignment between the sensor reference frames. Standard model-based alignment methods between these sensor systems suffer from lengthy convergence times, dependence on prescribed motion patterns, and reliance on external aiding sensors, significantly limiting operational flexibility. To address these limitations, this paper presents ResAlignNet, a data-driven approach using the 1D ResNet-18 architecture that transforms the alignment problem into deep neural network optimization, operating as an in-situ solution that requires only sensors on board without external positioning aids or complex vehicle maneuvers, while achieving rapid convergence in seconds. Additionally, the approach demonstrates the learning capabilities of Sim2Real transfer, enabling training in synthetic data while deploying in operational sensor measurements. Experimental validation using the Snapir autonomous underwater vehicle demonstrates that ResAlignNet achieves alignment accuracy within 0.8° using only 25 seconds of data collection, representing a 65\% reduction in convergence time compared to standard velocity-based methods. The trajectory-independent solution eliminates motion pattern requirements and enables immediate vehicle deployment without lengthy pre-mission procedures, advancing underwater navigation capabilities through robust sensor-agnostic alignment that scales across different operational scenarios and sensor specifications.

</details>


### [71] [Count Every Rotation and Every Rotation Counts: Exploring Drone Dynamics via Propeller Sensing](https://arxiv.org/abs/2511.13100)
*Xuecheng Chen,Jingao Xu,Wenhua Ding,Haoyang Wang,Xinyu Luo,Ruiyang Duan,Jialong Chen,Xueqian Wang,Yunhao Liu,Xinlei Chen*

Main category: cs.RO

TL;DR: 本研究主要通过事件相机和算法改进无人机的非接触感知，提升了螺旋桨转速估计和动态推断能力。


<details>
  <summary>Details</summary>
Motivation: 随着无人机应用的不断增加，地面对无人机的非接触式感知变得愈发重要。

Method: 利用事件相机和新提出的算法来估计无人机的螺旋桨转速和推断无人机内部及外部动态。

Result: 	extit{sysname} 在实际无人机送货场景中的评估显示，感知延迟为 3 毫秒，转速估计误差仅为 0.23%，指令推断的精准度为 96.5%，且与其他传感手段结合后跟踪精度提高了 22%。

Conclusion: 本研究提出的 	extit{Count Every Rotation} 及 	extit{Every Rotation Counts} 方法在无人机传感性能上实现了显著提升，具有极高的精准度和低延迟。

Abstract: As drone-based applications proliferate, paramount contactless sensing of airborne drones from the ground becomes indispensable. This work demonstrates concentrating on propeller rotational speed will substantially improve drone sensing performance and proposes an event-camera-based solution, \sysname. \sysname features two components: \textit{Count Every Rotation} achieves accurate, real-time propeller speed estimation by mitigating ultra-high sensitivity of event cameras to environmental noise. \textit{Every Rotation Counts} leverages these speeds to infer both internal and external drone dynamics. Extensive evaluations in real-world drone delivery scenarios show that \sysname achieves a sensing latency of 3$ms$ and a rotational speed estimation error of merely 0.23\%. Additionally, \sysname infers drone flight commands with 96.5\% precision and improves drone tracking accuracy by over 22\% when combined with other sensing modalities. \textit{ Demo: {\color{blue}https://eventpro25.github.io/EventPro/.} }

</details>


### [72] [Monolithic Units: Actuation, Sensing, and Simulation for Integrated Soft Robot Design](https://arxiv.org/abs/2511.13120)
*Trevor Exley,Anderson Brazil Nardin,Petr Trunin,Diana Cafiso,Lucia Beccai*

Main category: cs.RO

TL;DR: 本文介绍了单片单元（MU），作为软机器人中的新型执行器-格子-传感器构建块。


<details>
  <summary>Details</summary>
Motivation: 在软机器人领域，需要将执行、感知和结构集成到一个可重复和可扩展的设计中。

Method: 建立了参数化设计框架，以确定执行器腔体尺寸与格子单元尺寸之间的关系，并通过有限元模拟优化传感器布置。

Result: 优化模型经过实验验证，确认其机械性能保持不变，同时实现嵌入式传感。

Conclusion: 该研究推动了单片软机器人的设计，结合了可重复的共设计规则与基于模拟的传感器集成。

Abstract: This work introduces the Monolithic Unit (MU), an actuator-lattice-sensor building block for soft robotics. The MU integrates pneumatic actuation, a compliant lattice envelope, and candidate sites for optical waveguide sensing into a single printed body. In order to study reproducibility and scalability, a parametric design framework establishes deterministic rules linking actuator chamber dimensions to lattice unit cell size. Experimental homogenization of lattice specimens provides effective material properties for finite element simulation. Within this simulation environment, sensor placement is treated as a discrete optimization problem, where a finite set of candidate waveguide paths derived from lattice nodes is evaluated by introducing local stiffening, and the configuration minimizing deviation from baseline mechanical response is selected. Optimized models are fabricated and experimentally characterized, validating the preservation of mechanical performance while enabling embedded sensing. The workflow is further extended to scaled units and a two-finger gripper, demonstrating generality of the MU concept. This approach advances monolithic soft robotic design by combining reproducible co-design rules with simulation-informed sensor integration.

</details>


### [73] [Collision-Free Navigation of Mobile Robots via Quadtree-Based Model Predictive Control](https://arxiv.org/abs/2511.13188)
*Osama Al Sheikh Ali,Sotiris Koutsoftas,Ze Zhang,Knut Akesson,Emmanuel Dean*

Main category: cs.RO

TL;DR: 本文提出了一种新的集成导航框架，用于自主移动机器人，通过四叉树生成无碰撞区域，提升导航性能。


<details>
  <summary>Details</summary>
Motivation: 自动移动机器人（AMRs）的导航需求日益增加，目前的技术往往无法有效整合环境表示、轨迹生成和模型预测控制（MPC）。

Method: 通过四叉树方法，从占用地图生成安全区域，并将其用于MPC公式中的线性约束，整合安全区域提取、连通性图构建、轨迹生成和B样条平滑。

Result: 提出了一种集成导航框架，通过四叉树方法生成结构化且轴对齐的无碰撞区域，显著提高了导航的效率和可靠性。

Conclusion: 实验结果表明，该方法在复杂环境中表现出优越的性能，成功度高于基线方法。

Abstract: This paper presents an integrated navigation framework for Autonomous Mobile Robots (AMRs) that unifies environment representation, trajectory generation, and Model Predictive Control (MPC). The proposed approach incorporates a quadtree-based method to generate structured, axis-aligned collision-free regions from occupancy maps. These regions serve as both a basis for developing safe corridors and as linear constraints within the MPC formulation, enabling efficient and reliable navigation without requiring direct obstacle encoding. The complete pipeline combines safe-area extraction, connectivity graph construction, trajectory generation, and B-spline smoothing into one coherent system. Experimental results demonstrate consistent success and superior performance compared to baseline approaches across complex environments.

</details>


### [74] [PIGEON: VLM-Driven Object Navigation via Points of Interest Selection](https://arxiv.org/abs/2511.13207)
*Cheng Peng,Zhenzhe Zhang,Cheng Chi,Xiaobao Wei,Yanhao Zhang,Heng Wang,Pengwei Wang,Zhongyuan Wang,Jing Liu,Shanghang Zhang*

Main category: cs.RO

TL;DR: 本研究提出PIGEON，通过视觉语言模型改进对象导航，表现出色且具备深度推理能力。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在决策频率与智能性之间的平衡困难，旨在提升目标导航的能力。

Method: 提出PIGEON方法，结合视觉语言模型进行对象导航，并通过轻量级的语义快照记忆提高探索策略。

Result: 在经典对象导航基准测试中，零样本迁移方法实现了最新的性能，RLVR进一步增强了模型的语义引导能力。

Conclusion: PIGEON方法提供了一种有效的对象导航策略，展示了在未知环境中高效决策的潜力。

Abstract: Navigating to a specified object in an unknown environment is a fundamental yet challenging capability of embodied intelligence. However, current methods struggle to balance decision frequency with intelligence, resulting in decisions lacking foresight or discontinuous actions. In this work, we propose PIGEON: Point of Interest Guided Exploration for Object Navigation with VLM, maintaining a lightweight and semantically aligned snapshot memory during exploration as semantic input for the exploration strategy. We use a large Visual-Language Model (VLM), named PIGEON-VL, to select Points of Interest (PoI) formed during exploration and then employ a lower-level planner for action output, increasing the decision frequency. Additionally, this PoI-based decision-making enables the generation of Reinforcement Learning with Verifiable Reward (RLVR) data suitable for simulators. Experiments on classic object navigation benchmarks demonstrate that our zero-shot transfer method achieves state-of-the-art performance, while RLVR further enhances the model's semantic guidance capabilities, enabling deep reasoning during real-time navigation.

</details>


### [75] [GaRLILEO: Gravity-aligned Radar-Leg-Inertial Enhanced Odometry](https://arxiv.org/abs/2511.13216)
*Chiyun Noh,Sangwoo Jung,Hanjun Kim,Yafei Hu,Laura Herlant,Ayoung Kim*

Main category: cs.RO

TL;DR: GaRLILEO是一种新兴的雷达-腿-惯性里程计框架，能够准确估计重力向量并改善垂直姿态准确性，特别适用于腿足机器人在复杂地形下的导航。


<details>
  <summary>Details</summary>
Motivation: 针对腿足机器人在挑战性地形中导航时的精确里程计估计需求，尤其是在常规方法面临的垂直漂移问题。

Method: 提出了一种新颖的重力对齐连续时间雷达-腿-惯性里程计框架，结合了SoC雷达多普勒和腿运动学信息，构建连续时间自我速度样条，以实现无缝传感器融合。

Result: 在自收集的真实世界数据集上评估，GaRLILEO展示出先进的准确性，特别是在垂直里程计估计中表现出色，特别是在楼梯和斜坡上。

Conclusion: GaRLILEO在垂直里程计估计上显示出先进的准确性，特别是在楼梯和斜坡上，并且开源数据集与算法以促进后续的研究。

Abstract: Deployment of legged robots for navigating challenging terrains (e.g., stairs, slopes, and unstructured environments) has gained increasing preference over wheel-based platforms. In such scenarios, accurate odometry estimation is a preliminary requirement for stable locomotion, localization, and mapping. Traditional proprioceptive approaches, which rely on leg kinematics sensor modalities and inertial sensing, suffer from irrepressible vertical drift caused by frequent contact impacts, foot slippage, and vibrations, particularly affected by inaccurate roll and pitch estimation. Existing methods incorporate exteroceptive sensors such as LiDAR or cameras. Further enhancement has been introduced by leveraging gravity vector estimation to add additional observations on roll and pitch, thereby increasing the accuracy of vertical pose estimation. However, these approaches tend to degrade in feature-sparse or repetitive scenes and are prone to errors from double-integrated IMU acceleration. To address these challenges, we propose GaRLILEO, a novel gravity-aligned continuous-time radar-leg-inertial odometry framework. GaRLILEO decouples velocity from the IMU by building a continuous-time ego-velocity spline from SoC radar Doppler and leg kinematics information, enabling seamless sensor fusion which mitigates odometry distortion. In addition, GaRLILEO can reliably capture accurate gravity vectors leveraging a novel soft S2-constrained gravity factor, improving vertical pose accuracy without relying on LiDAR or cameras. Evaluated on a self-collected real-world dataset with diverse indoor-outdoor trajectories, GaRLILEO demonstrates state-of-the-art accuracy, particularly in vertical odometry estimation on stairs and slopes. We open-source both our dataset and algorithm to foster further research in legged robot odometry and SLAM. https://garlileo.github.io/GaRLILEO

</details>


### [76] [EL3DD: Extended Latent 3D Diffusion for Language Conditioned Multitask Manipulation](https://arxiv.org/abs/2511.13312)
*Jonas Bode,Raphael Memmesheimer,Sven Behnke*

Main category: cs.RO

TL;DR: 本研究通过扩散模型结合视觉和文本输入，提高了机器人执行操作任务的能力。


<details>
  <summary>Details</summary>
Motivation: 提高机器人在自然语言指令下执行物理任务的能力

Method: 采用扩散模型融入视觉运动策略框架

Result: 在CALVIN数据集上表现出色，提升了多种操作任务的成功率，尤其是在顺序执行多个任务时

Conclusion: 该方法证明了扩散模型在多任务操作中的有效性，通过增强嵌入和适应图像生成技术，推动了机器人的发展。

Abstract: Acting in human environments is a crucial capability for general-purpose robots, necessitating a robust understanding of natural language and its application to physical tasks. This paper seeks to harness the capabilities of diffusion models within a visuomotor policy framework that merges visual and textual inputs to generate precise robotic trajectories. By employing reference demonstrations during training, the model learns to execute manipulation tasks specified through textual commands within the robot's immediate environment. The proposed research aims to extend an existing model by leveraging improved embeddings, and adapting techniques from diffusion models for image generation. We evaluate our methods on the CALVIN dataset, proving enhanced performance on various manipulation tasks and an increased long-horizon success rate when multiple tasks are executed in sequence. Our approach reinforces the usefulness of diffusion models and contributes towards general multitask manipulation.

</details>


### [77] [ZeroDexGrasp: Zero-Shot Task-Oriented Dexterous Grasp Synthesis with Prompt-Based Multi-Stage Semantic Reasoning](https://arxiv.org/abs/2511.13327)
*Juntao Jian,Yi-Lin Wei,Chengjie Mou,Yuhao Lin,Xing Zhu,Yujun Shen,Wei-Shi Zheng,Ruizhen Hu*

Main category: cs.RO

TL;DR: ZeroDexGrasp是一个零-shot的抓取框架，能够应对多样化的对象和任务指令，显著提高机器人抓取的通用性和智能性。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖昂贵的标注数据，导致其在不同对象和任务指令上的泛化能力不足，亟需一种更通用、智能的抓取方法。

Method: 采用基于提示的多阶段语义推理推导初始抓取配置，再通过接触引导的抓取优化调整以确保物理可行性和任务一致性。

Result: 提出了一种新的零-shot任务导向灵巧抓取框架ZeroDexGrasp，它将多模态大型语言模型与抓取优化结合，通过初步抓取配置推理和接触引导优化，实现了对未见对象类别和复杂任务要求的高质量抓取。

Conclusion: ZeroDexGrasp通过结合多模态语言模型和抓取优化，显著提升了机器人在复杂任务和多样目标上的抓取能力，朝着更智能化的抓取方向迈进。

Abstract: Task-oriented dexterous grasping holds broad application prospects in robotic manipulation and human-object interaction. However, most existing methods still struggle to generalize across diverse objects and task instructions, as they heavily rely on costly labeled data to ensure task-specific semantic alignment. In this study, we propose \textbf{ZeroDexGrasp}, a zero-shot task-oriented dexterous grasp synthesis framework integrating Multimodal Large Language Models with grasp refinement to generate human-like grasp poses that are well aligned with specific task objectives and object affordances. Specifically, ZeroDexGrasp employs prompt-based multi-stage semantic reasoning to infer initial grasp configurations and object contact information from task and object semantics, then exploits contact-guided grasp optimization to refine these poses for physical feasibility and task alignment. Experimental results demonstrate that ZeroDexGrasp enables high-quality zero-shot dexterous grasping on diverse unseen object categories and complex task requirements, advancing toward more generalizable and intelligent robotic grasping.

</details>


### [78] [Contact-Safe Reinforcement Learning with ProMP Reparameterization and Energy Awareness](https://arxiv.org/abs/2511.13459)
*Bingkun Huang,Yuhe Gong,Zewen Yang,Tianyu Ren,Luis Figueredo*

Main category: cs.RO

TL;DR: 本文提出了一种基于任务空间的强化学习框架，用于解决接触丰富的操控任务，表现出比传统方法更优的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的强化学习方法在处理3D环境中的接触丰富操控任务时，往往忽略了接触信息的安全性和鲁棒性。

Method: 通过结合近端策略优化（PPO）和运动原语，生成可靠且安全的任务空间轨迹，并引入能量意识的笛卡尔阻抗控制器。

Result: 所提出的框架在各种3D环境的任务执行中，表现出了较高的成功率和平滑的轨迹，确保了与环境的安全交互。

Conclusion: 实验结果表明，所提出的框架在处理复杂的接触丰富任务时，表现优于现有方法，达到高成功率和安全的平滑轨迹。

Abstract: Reinforcement learning (RL) approaches based on Markov Decision Processes (MDPs) are predominantly applied in the robot joint space, often relying on limited task-specific information and partial awareness of the 3D environment. In contrast, episodic RL has demonstrated advantages over traditional MDP-based methods in terms of trajectory consistency, task awareness, and overall performance in complex robotic tasks. Moreover, traditional step-wise and episodic RL methods often neglect the contact-rich information inherent in task-space manipulation, especially considering the contact-safety and robustness. In this work, contact-rich manipulation tasks are tackled using a task-space, energy-safe framework, where reliable and safe task-space trajectories are generated through the combination of Proximal Policy Optimization (PPO) and movement primitives. Furthermore, an energy-aware Cartesian Impedance Controller objective is incorporated within the proposed framework to ensure safe interactions between the robot and the environment. Our experimental results demonstrate that the proposed framework outperforms existing methods in handling tasks on various types of surfaces in 3D environments, achieving high success rates as well as smooth trajectories and energy-safe interactions.

</details>


### [79] [Towards Affect-Adaptive Human-Robot Interaction: A Protocol for Multimodal Dataset Collection on Social Anxiety](https://arxiv.org/abs/2511.13530)
*Vesna Poprcova,Iulia Lefter,Matthias Wieser,Martijn Warnier,Frances Brazier*

Main category: cs.RO

TL;DR: 本文提出了一种新协议，旨在收集多模态数据集，以研究人机交互中的社会焦虑，为情感适应的人机交互研究提供支持。


<details>
  <summary>Details</summary>
Motivation: 社会焦虑影响人际互动和社交功能，人工智能和社交机器人为研究提供了新机遇，但缺乏多模态数据集限制了研究进展。

Method: 设计用于反映社会焦虑的人机交互背景的多模态数据集收集协议

Result: 构建一个包含至少70个参与者的多模态数据集，涵盖同步音频、视频和生理记录，及情境数据，支持社会焦虑的多模态检测。

Conclusion: 该工作对情感适应的人机交互研究有重要贡献，通过建立多模态数据集促进社会焦虑的准确检测。

Abstract: Social anxiety is a prevalent condition that affects interpersonal interactions and social functioning. Recent advances in artificial intelligence and social robotics offer new opportunities to examine social anxiety in the human-robot interaction context. Accurate detection of affective states and behaviours associated with social anxiety requires multimodal datasets, where each signal modality provides complementary insights into its manifestations. However, such datasets remain scarce, limiting progress in both research and applications. To address this, this paper presents a protocol for multimodal dataset collection designed to reflect social anxiety in a human-robot interaction context. The dataset will consist of synchronised audio, video, and physiological recordings acquired from at least 70 participants, grouped according to their level of social anxiety, as they engage in approximately 10-minute interactive Wizard-of-Oz role-play scenarios with the Furhat social robot under controlled experimental conditions. In addition to multimodal data, the dataset will be enriched with contextual data providing deeper insight into individual variability in social anxiety responses. This work can contribute to research on affect-adaptive human-robot interaction by providing support for robust multimodal detection of social anxiety.

</details>


### [80] [OpenRoboCare: A Multimodal Multi-Task Expert Demonstration Dataset for Robot Caregiving](https://arxiv.org/abs/2511.13707)
*Xiaoyu Liang,Ziang Liu,Kelvin Lin,Edward Gu,Ruolin Ye,Tam Nguyen,Cynthia Hsu,Zhanxin Wu,Xiaoman Yang,Christy Sum Yu Cheung,Harold Soh,Katherine Dimitropoulou,Tapomayukh Bhattacharjee*

Main category: cs.RO

TL;DR: OpenRoboCare是一个针对机器人护理的多模态数据集，包含护理专家的15项日常生活活动数据，提供了丰富的多模态信息并分析了护理策略。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏大型、多样且由专家驱动的护理数据集，以支持机器人学习和人机交互研究，因此亟需一个能够捕捉真实护理场景的多模态数据集。

Method: 通过记录21名职业治疗师在两个人形模型上执行15项日常生活活动，收集了RGB-D视频、姿态跟踪、眼动跟踪、任务和动作注释以及触觉感知等五种模态的数据。

Result: 创建了一个名为OpenRoboCare的多模态数据集，涵盖了护理专业人员对日常生活活动的表演，并分析了护理原则与策略。

Conclusion: OpenRoboCare对现有机器视觉和人类活动识别方法提出挑战，强调了其在发展安全、自适应助残机器人的重要性和价值。

Abstract: We present OpenRoboCare, a multimodal dataset for robot caregiving, capturing expert occupational therapist demonstrations of Activities of Daily Living (ADLs). Caregiving tasks involve complex physical human-robot interactions, requiring precise perception under occlusions, safe physical contact, and long-horizon planning. While recent advances in robot learning from demonstrations have shown promise, there is a lack of a large-scale, diverse, and expert-driven dataset that captures real-world caregiving routines. To address this gap, we collect data from 21 occupational therapists performing 15 ADL tasks on two manikins. The dataset spans five modalities: RGB-D video, pose tracking, eye-gaze tracking, task and action annotations, and tactile sensing, providing rich multimodal insights into caregiver movement, attention, force application, and task execution strategies. We further analyze expert caregiving principles and strategies, offering insights to improve robot efficiency and task feasibility. Additionally, our evaluations demonstrate that OpenRoboCare presents challenges for state-of-the-art robot perception and human activity recognition methods, both critical for developing safe and adaptive assistive robots, highlighting the value of our contribution. See our website for additional visualizations: https://emprise.cs.cornell.edu/robo-care/.

</details>


### [81] [From Power to Precision: Learning Fine-grained Dexterity for Multi-fingered Robotic Hands](https://arxiv.org/abs/2511.13710)
*Jianglong Ye,Lai Wei,Guangqi Jiang,Changwei Jing,Xueyan Zou,Xiaolong Wang*

Main category: cs.RO

TL;DR: 本论文提出一种联合优化多指灵巧手的方法，使其能够同时实现力量抓握和精确操作，通过轻量化指尖几何修改和动态控制策略，显著提升抓握性能。


<details>
  <summary>Details</summary>
Motivation: 现有机器人手在力量抓握上效果显著，但在需要精确操作的任务中仍以平行抓取器为主，揭示了当前设计的主要局限性。

Method: 联合优化多指灵巧手的控制与硬件设计，以实现力量和精确操作。

Result: 本方法在看不见的物体精确抓取中实现82.5%的零-shot成功率，并在涉及面包夹拾的复杂任务中取得93.3%的成功率。

Conclusion: 我们的共同设计框架在不降低力量抓握能力的情况下，显著提升了多指手的精细操作能力。

Abstract: Human grasps can be roughly categorized into two types: power grasps and precision grasps. Precision grasping enables tool use and is believed to have influenced human evolution. Today's multi-fingered robotic hands are effective in power grasps, but for tasks requiring precision, parallel grippers are still more widely adopted. This contrast highlights a key limitation in current robotic hand design: the difficulty of achieving both stable power grasps and precise, fine-grained manipulation within a single, versatile system. In this work, we bridge this gap by jointly optimizing the control and hardware design of a multi-fingered dexterous hand, enabling both power and precision manipulation. Rather than redesigning the entire hand, we introduce a lightweight fingertip geometry modification, represent it as a contact plane, and jointly optimize its parameters along with the corresponding control. Our control strategy dynamically switches between power and precision manipulation and simplifies precision control into parallel thumb-index motions, which proves robust for sim-to-real transfer. On the design side, we leverage large-scale simulation to optimize the fingertip geometry using a differentiable neural-physics surrogate model. We validate our approach through extensive experiments in both sim-to-real and real-to-real settings. Our method achieves an 82.5% zero-shot success rate on unseen objects in sim-to-real precision grasping, and a 93.3% success rate in challenging real-world tasks involving bread pinching. These results demonstrate that our co-design framework can significantly enhance the fine-grained manipulation ability of multi-fingered hands without reducing their ability for power grasps. Our project page is at https://jianglongye.com/power-to-precision

</details>
