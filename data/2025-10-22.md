<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 25]
- [cs.HC](#cs.HC) [Total: 7]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Studying the Effects of Robot Intervention on School Shooters in Virtual Reality](https://arxiv.org/abs/2510.17948)
*Christopher A McClurg,Alan R Wagner*

Main category: cs.RO

TL;DR: 本研究探讨了机器人在高风险场景中对学校枪手的干预潜力，发现主动干扰的机器人可以显著减少受害者数量。


<details>
  <summary>Details</summary>
Motivation: 提升对机器人在高风险情况下的干预能力的理解，尤其是在学校安全领域。

Method: 通过虚拟现实研究，150名大学参与者模拟学校枪手，评估不同类型的机器人干扰策略。

Result: 主动、高干扰的机器人使受害者数量减少了46.6%，相较于不开启机器人的控制组。

Conclusion: 机器人干预能够有效提升安全性，但在学校环境中使用需考虑伦理问题。

Abstract: We advance the understanding of robotic intervention in high-risk scenarios
by examining their potential to distract and impede a school shooter. To
evaluate this concept, we conducted a virtual reality study with 150 university
participants role-playing as a school shooter. Within the simulation, an
autonomous robot predicted the shooter's movements and positioned itself
strategically to interfere and distract. The strategy the robot used to
approach the shooter was manipulated -- either moving directly in front of the
shooter (aggressive) or maintaining distance (passive) -- and the distraction
method, ranging from no additional cues (low), to siren and lights (medium), to
siren, lights, and smoke to impair visibility (high). An aggressive,
high-distraction robot reduced the number of victims by 46.6% relative to a
no-robot control. This outcome underscores both the potential of robotic
intervention to enhance safety and the pressing ethical questions surrounding
their use in school environments.

</details>


### [2] [RoboChallenge: Large-scale Real-robot Evaluation of Embodied Policies](https://arxiv.org/abs/2510.17950)
*Adina Yakefu,Bin Xie,Chongyang Xu,Enwen Zhang,Erjin Zhou,Fan Jia,Haitao Yang,Haoqiang Fan,Haowei Zhang,Hongyang Peng,Jing Tan,Junwen Huang,Kai Liu,Kaixin Liu,Kefan Gu,Qinglun Zhang,Ruitao Zhang,Saike Huang,Shen Cheng,Shuaicheng Liu,Tiancai Wang,Tiezhen Wang,Wei Sun,Wenbin Tang,Yajun Wei,Yang Chen,Youqiang Gui,Yucheng Zhao,Yunchao Ma,Yunfei Wei,Yunhuan Yang,Yutong Guo,Ze Chen,Zhengyuan Du,Ziheng Zhang,Ziming Liu,Ziwei Yan*

Main category: cs.RO

TL;DR: 本文介绍了一种在线评估系统RoboChallenge，用于测试机器人控制算法，尤其是大规模评估学习型算法的需求愈发迫切。


<details>
  <summary>Details</summary>
Motivation: 随着对大规模评估的需求增加，尤其是在学习型算法领域，我们需要一个可靠的系统来保证测试的可扩展性和可重现性。

Method: 本文描述了RoboChallenge的构建方法，强调了在线评估系统在机器人控制算法测试中的重要性。

Result: 我们通过初步基准Table30对最近的先进VLA模型进行了调查和评估。

Conclusion: 通过RoboChallenge，我们能够更有效地测试和评估最新的VLA模型。

Abstract: Testing on real machines is indispensable for robotic control algorithms. In
the context of learning-based algorithms, especially VLA models, demand for
large-scale evaluation, i.e. testing a large number of models on a large number
of tasks, is becoming increasingly urgent. However, doing this right is highly
non-trivial, especially when scalability and reproducibility is taken into
account. In this report, we describe our methodology for constructing
RoboChallenge, an online evaluation system to test robotic control algorithms,
and our survey of recent state-of-the-art VLA models using our initial
benchmark Table30.

</details>


### [3] [Humanoid Goalkeeper: Learning from Position Conditioned Task-Motion Constraints](https://arxiv.org/abs/2510.18002)
*Junli Ren,Junfeng Long,Tao Huang,Huayi Wang,Zirui Wang,Feiyu Jia,Wentao Zhang,Jingbo Wang,Ping Luo,Jiangmiao Pang*

Main category: cs.RO

TL;DR: 该研究提出的强化学习框架使人形机器人在真实场景中能够自主、灵活地进行守门及其他相关任务，推动了机器人与动态物体交互的实现。


<details>
  <summary>Details</summary>
Motivation: 解决人形机器人守门任务中涉及的自然动作生成和快速反应范围覆盖等关键挑战，推动机器人在现实世界中的应用。

Method: 通过整合多个人体运动先验，利用对抗性方案将其条件化于感知输入，实现单一端到端的强化学习策略，进行自主动态控制。

Result: 通过实验证明，所提出的方法使人形机器人能够成功实现灵活、自然的快速球拦截，并能够推广至其他任务如球逃避和抓取。

Conclusion: 本研究提出了一种用于人形机器人的自主守门的强化学习框架，展示了在动态互动中实现人类般行为的有效性。

Abstract: We present a reinforcement learning framework for autonomous goalkeeping with
humanoid robots in real-world scenarios. While prior work has demonstrated
similar capabilities on quadrupedal platforms, humanoid goalkeeping introduces
two critical challenges: (1) generating natural, human-like whole-body motions,
and (2) covering a wider guarding range with an equivalent response time.
Unlike existing approaches that rely on separate teleoperation or fixed motion
tracking for whole-body control, our method learns a single end-to-end RL
policy, enabling fully autonomous, highly dynamic, and human-like robot-object
interactions. To achieve this, we integrate multiple human motion priors
conditioned on perceptual inputs into the RL training via an adversarial
scheme. We demonstrate the effectiveness of our method through real-world
experiments, where the humanoid robot successfully performs agile, autonomous,
and naturalistic interceptions of fast-moving balls. In addition to
goalkeeping, we demonstrate the generalization of our approach through tasks
such as ball escaping and grabbing. Our work presents a practical and scalable
solution for enabling highly dynamic interactions between robots and moving
objects, advancing the field toward more adaptive and lifelike robotic
behaviors.

</details>


### [4] [MOFM-Nav: On-Manifold Ordering-Flexible Multi-Robot Navigation](https://arxiv.org/abs/2510.18063)
*Bin-Bin Hu,Weijia Yao,Ming Cao*

Main category: cs.RO

TL;DR: 该论文聚焦于多机器人在高维空间中导航的问题，提出了一种改进的协调算法以实现灵活的排序和高效的机器人运动协调。


<details>
  <summary>Details</summary>
Motivation: 研究多机器人协调在高维流形上的导航问题，尤其是在欧几里得度量计算复杂时，探索新的解决方案以提升灵活性和协调性。

Method: 通过识别辅助向量的可行解，重新设计协调GVF算法，使得机器人运动能够有效解耦，并共享虚拟坐标以简化计算。

Result: 本论文提出了一种多机器人导航的方法，旨在解决机器人在高维流形上灵活排序的问题。通过非欧几里得度量实现多机器人协调，并提出改进的协调GVF算法以增强灵活性和鲁棒性。

Conclusion: 通过广泛的仿真，验证了所提算法在不同初始位置、高维流形及机器人故障情况下的灵活性、适应性和鲁棒性。

Abstract: This paper addresses the problem of multi-robot navigation where robots
maneuver on a desired \(m\)-dimensional (i.e., \(m\)-D) manifold in the
$n$-dimensional Euclidean space, and maintain a {\it flexible spatial
ordering}. We consider $ m\geq 2$, and the multi-robot coordination is achieved
via non-Euclidean metrics. However, since the $m$-D manifold can be
characterized by the zero-level sets of $n$ implicit functions, the last $m$
entries of the GVF propagation term become {\it strongly coupled} with the
partial derivatives of these functions if the auxiliary vectors are not
appropriately chosen. These couplings not only influence the on-manifold
maneuvering of robots, but also pose significant challenges to the further
design of the ordering-flexible coordination via non-Euclidean metrics.
  To tackle this issue, we first identify a feasible solution of auxiliary
vectors such that the last $m$ entries of the propagation term are effectively
decoupled to be the same constant. Then, we redesign the coordinated GVF (CGVF)
algorithm to {\it boost} the advantages of singularities elimination and global
convergence by treating $m$ manifold parameters as additional $m$ virtual
coordinates. Furthermore, we enable the on-manifold ordering-flexible motion
coordination by allowing each robot to share $m$ virtual coordinates with its
time-varying neighbors and a virtual target robot, which {\it circumvents} the
possible complex calculation if Euclidean metrics were used instead. Finally,
we showcase the proposed algorithm's flexibility, adaptability, and robustness
through extensive simulations with different initial positions,
higher-dimensional manifolds, and robot breakdown, respectively.

</details>


### [5] [R2BC: Multi-Agent Imitation Learning from Single-Agent Demonstrations](https://arxiv.org/abs/2510.18085)
*Connor Mattson,Varun Raveendra,Ellen Novoseller,Nicholas Waytowich,Vernon J. Lawhern,Daniel S. Brown*

Main category: cs.RO

TL;DR: R2BC是一种新的模仿学习方法，允许单人有效训练多个机器人，通过轮流示范实现优异的训练效果。


<details>
  <summary>Details</summary>
Motivation: 探讨如何将模仿学习扩展至多代理系统，尤其在单一人类为多个协作机器人提供示范的背景下。

Method: 通过轮流示范，单一人类操作员逐个训练机器人，实现多机器人系统行为的增量教学。

Result: R2BC在四个多代理模拟任务中展示了与传统行为克隆方法相当的表现，还在两个实际机器人任务中成功应用。

Conclusion: R2BC方法在多代理系统上有效地进行训练，且在某些情况下超越了传统的行为克隆方法。

Abstract: Imitation Learning (IL) is a natural way for humans to teach robots,
particularly when high-quality demonstrations are easy to obtain. While IL has
been widely applied to single-robot settings, relatively few studies have
addressed the extension of these methods to multi-agent systems, especially in
settings where a single human must provide demonstrations to a team of
collaborating robots. In this paper, we introduce and study Round-Robin
Behavior Cloning (R2BC), a method that enables a single human operator to
effectively train multi-robot systems through sequential, single-agent
demonstrations. Our approach allows the human to teleoperate one agent at a
time and incrementally teach multi-agent behavior to the entire system, without
requiring demonstrations in the joint multi-agent action space. We show that
R2BC methods match, and in some cases surpass, the performance of an oracle
behavior cloning approach trained on privileged synchronized demonstrations
across four multi-agent simulated tasks. Finally, we deploy R2BC on two
physical robot tasks trained using real human demonstrations.

</details>


### [6] [ANGEL: A Novel Gripper for Versatile and Light-touch Fruit Harvesting](https://arxiv.org/abs/2510.18127)
*Dharmik Patel,Antonio Rafael Vazquez Pantoja,Jiuzhou Lei,Kiju Lee,Xiao Liang,Minghui Zheng*

Main category: cs.RO

TL;DR: 本研究提出了一种新型的软式果实采摘抓手，具有高适应性和低损伤率，采用简单的设计和轻量化结构，适用于不同规格的水果。


<details>
  <summary>Details</summary>
Motivation: 传统的果实采摘依赖劳动力，现有抓手在设计复杂性与能耗上存在问题，现有抓手缺乏对不同水果尺寸的适应性。

Method: 引入一种启发自拉绳的、基于电缆驱动的软式抓手

Result: 采用3D打印热塑性聚氨酯（TPU）口袋与集成钢丝的设计，抓手实现了对水果的温和采摘，并在试验中显示出对西红柿的0%即时损伤率和低于9%的压伤率。

Conclusion: 实验验证显示，该软抓手在采摘过程中能够有效防止水果损伤，适合于果实采摘。

Abstract: Fruit harvesting remains predominantly a labor-intensive process, motivating
the development of research for robotic grippers. Conventional rigid or
vacuum-driven grippers require complex mechanical design or high energy
consumption. Current enveloping-based fruit harvesting grippers lack
adaptability to fruits of different sizes. This paper introduces a
drawstring-inspired, cable-driven soft gripper for versatile and gentle fruit
harvesting. The design employs 3D-printed Thermoplastic Polyurethane (TPU)
pockets with integrated steel wires that constrict around the fruit when
actuated, distributing pressure uniformly to minimize bruising and allow
versatility to fruits of varying sizes. The lightweight structure, which
requires few components, reduces mechanical complexity and cost compared to
other grippers. Actuation is achieved through servo-driven cable control, while
motor feedback provides autonomous grip adjustment with tunable grip strength.
Experimental validation shows that, for tomatoes within the gripper's effective
size range, harvesting was achieved with a 0% immediate damage rate and a
bruising rate of less than 9% after five days, reinforcing the gripper's
suitability for fruit harvesting.

</details>


### [7] [Quality Over Quantity: Curating Contact-Based Robot Datasets Improves Learning](https://arxiv.org/abs/2510.18137)
*Hrishikesh Sathyanarayan,Victor Vantilborgh,Ian Abraham*

Main category: cs.RO

TL;DR: 研究接触数据在机器人学习中的效用，发现更少但信息丰富的数据能加速学习。


<details>
  <summary>Details</summary>
Motivation: 研究数据集的效用，评估更多数据与‘正确’数据对机器人学习的优势。

Method: 开发接触感知的目标函数，并利用Fisher信息度量对接触数据进行排名和筛选。

Result: 提出基于接触的目标函数用于学习物体动态和形状，并开发了接触感知的Fisher信息度量。

Conclusion: 接触数据的精简选择可以改善学习任务，同时使学习过程更具确定性。

Abstract: In this paper, we investigate the utility of datasets and whether more data
or the 'right' data is advantageous for robot learning. In particular, we are
interested on quantifying the utility of contact-based data as contact holds
significant information for robot learning. Our approach derives a
contact-aware objective function for learning object dynamics and shape from
pose and contact data. We show that the contact-aware Fisher-information metric
can be used to rank and curate contact-data based on how informative data is
for learning. In addition, we find that selecting a reduced dataset based on
this ranking improves the learning task while also making learning a
deterministic process. Interestingly, our results show that more data is not
necessarily advantageous, and rather, less but informative data can accelerate
learning, especially depending on the contact interactions. Last, we show how
our metric can be used to provide initial guidance on data curation for
contact-based robot learning.

</details>


### [8] [MoMaGen: Generating Demonstrations under Soft and Hard Constraints for Multi-Step Bimanual Mobile Manipulation](https://arxiv.org/abs/2510.18316)
*Chengshu Li,Mengdi Xu,Arpit Bahety,Hang Yin,Yunfan Jiang,Huang Huang,Josiah Wong,Sujay Garlanka,Cem Gokmen,Ruohan Zhang,Weiyu Liu,Jiajun Wu,Roberto Martín-Martín,Li Fei-Fei*

Main category: cs.RO

TL;DR: MoMaGen通过约束优化方法生成多样化的训练数据，有效提升机器人的模仿学习能力。


<details>
  <summary>Details</summary>
Motivation: 现有的数据生成框架在移动双手操作中面临挑战，因此需要新的方法来有效收集训练数据。

Method: 将数据生成问题形式化为一个具有硬约束（如可达性）和软约束（如导航过程中的可视性）的约束优化问题。

Result: MoMaGen在四个多步骤的双手移动操作任务上表现卓越，生成的数据集比现有方法显著多样。

Conclusion: MoMaGen能够生成比现有方法更具多样性的数据集，并成功训练模仿学习策略，更具可部署性。

Abstract: Imitation learning from large-scale, diverse human demonstrations has proven
effective for training robots, but collecting such data is costly and
time-consuming. This challenge is amplified for multi-step bimanual mobile
manipulation, where humans must teleoperate both a mobile base and two
high-degree-of-freedom arms. Prior automated data generation frameworks have
addressed static bimanual manipulation by augmenting a few human demonstrations
in simulation, but they fall short for mobile settings due to two key
challenges: (1) determining base placement to ensure reachability, and (2)
positioning the camera to provide sufficient visibility for visuomotor
policies. To address these issues, we introduce MoMaGen, which formulates data
generation as a constrained optimization problem that enforces hard constraints
(e.g., reachability) while balancing soft constraints (e.g., visibility during
navigation). This formulation generalizes prior approaches and provides a
principled foundation for future methods. We evaluate MoMaGen on four
multi-step bimanual mobile manipulation tasks and show that it generates
significantly more diverse datasets than existing methods. Leveraging this
diversity, MoMaGen can train successful imitation learning policies from a
single source demonstration, and these policies can be fine-tuned with as few
as 40 real-world demonstrations to achieve deployment on physical robotic
hardware. More details are available at our project page: momagen.github.io.

</details>


### [9] [MoTVLA: A Vision-Language-Action Model with Unified Fast-Slow Reasoning](https://arxiv.org/abs/2510.18337)
*Wenhui Huang,Changhe Chen,Han Qi,Chen Lv,Yilun Du,Heng Yang*

Main category: cs.RO

TL;DR: MoTVLA模型通过结合快速和慢速推理，提高了机器人在处理视觉-语言指令时的效率和灵活性。


<details>
  <summary>Details</summary>
Motivation: 提升机器人学习中视觉语言指令的整合，以增强开放世界的泛化能力，解决现有方法在推理时的语言可引导性和推理延迟问题。

Method: 基于混合转换器的视觉-语言-动作模型 (MoTVLA)

Result: MoTVLA通过整合快速与慢速的统一推理，提高了政策执行效率，同时增强了语言的可操作性。

Conclusion: 大量评估表明，MoTVLA在快速-慢速推理和操控任务性能方面优于现有方法。

Abstract: Integrating visual-language instructions into visuomotor policies is gaining
momentum in robot learning for enhancing open-world generalization. Despite
promising advances, existing approaches face two challenges: limited language
steerability when no generated reasoning is used as a condition, or significant
inference latency when reasoning is incorporated.In this work, we introduce
MoTVLA, a mixture-of-transformers (MoT)-based vision-language-action (VLA)
model that integrates fast-slow unified reasoning with behavior policy
learning. MoTVLA preserves the general intelligence of pre-trained VLMs
(serving as the generalist) for tasks such as perception, scene understanding,
and semantic planning, while incorporating a domain expert, a second
transformer that shares knowledge with the pretrained VLM, to generate
domain-specific fast reasoning (e.g., robot motion decomposition), thereby
improving policy execution efficiency. By conditioning the action expert on
decomposed motion instructions, MoTVLA can learn diverse behaviors and
substantially improve language steerability. Extensive evaluations across
natural language processing benchmarks, robotic simulation environments, and
real-world experiments confirm the superiority of MoTVLA in both fast-slow
reasoning and manipulation task performance.

</details>


### [10] [Coverage-Recon: Coordinated Multi-Drone Image Sampling with Online Map Feedback](https://arxiv.org/abs/2510.18347)
*Muhammad Hanif,Reiji Terunuma,Takumi Sumino,Kelvin Cheng,Takeshi Hatanaka*

Main category: cs.RO

TL;DR: 本文提出了一种名为Coverage-Recon的新算法，通过多架无人机协作和在线地图反馈，提高了3D地图重建的质量。


<details>
  <summary>Details</summary>
Motivation: 多架无人机进行协作3D地图重建，需要从不同角度拍摄关键点图像，覆盖控制提供了有效的框架来满足这一需求。

Method: 通过基于二次规划的角度感知覆盖控制器协调无人机的运动，并使用NeuralRecon算法实时处理捕获的图像生成3D网格。

Result: 模拟和实验验证了Coverage-Recon的有效性，表明与传统方法相比，结合在线地图反馈可以实现更完整和准确的3D重建。

Conclusion: Coverage-Recon通过在线地图反馈，显著提高了3D重建的完整性和准确性。

Abstract: This article addresses collaborative 3D map reconstruction using multiple
drones. Achieving high-quality reconstruction requires capturing images of
keypoints within the target scene from diverse viewing angles, and coverage
control offers an effective framework to meet this requirement. Meanwhile,
recent advances in real-time 3D reconstruction algorithms make it possible to
render an evolving map during flight, enabling immediate feedback to guide
drone motion. Building on this, we present Coverage-Recon, a novel coordinated
image sampling algorithm that integrates online map feedback to improve
reconstruction quality on-the-fly. In Coverage-Recon, the coordinated motion of
drones is governed by a Quadratic Programming (QP)-based angle-aware coverage
controller, which ensures multi-viewpoint image capture while enforcing safety
constraints. The captured images are processed in real time by the NeuralRecon
algorithm to generate an evolving 3D mesh. Mesh changes across the scene are
interpreted as indicators of reconstruction uncertainty and serve as feedback
to update the importance index of the coverage control as the map evolves. The
effectiveness of Coverage-Recon is validated through simulation and
experiments, demonstrating both qualitatively and quantitatively that
incorporating online map feedback yields more complete and accurate 3D
reconstructions than conventional methods. Project page:
https://htnk-lab.github.io/coverage-recon/

</details>


### [11] [PGTT: Phase-Guided Terrain Traversal for Perceptive Legged Locomotion](https://arxiv.org/abs/2510.18348)
*Alexandros Ntagkas,Chairi Kiourt,Konstantinos Chatzilygeroudis*

Main category: cs.RO

TL;DR: PGTT是一种新提出的深度强化学习算法，通过奖励塑造来实现步态结构，克服传统方法的局限性，增强腿部机器人的适应性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有腿部机器人控制方法存在行动空间受限、对噪声敏感等问题，需要一种更灵活、鲁棒的应对策略。

Method: PGTT通过奖励塑造引入步态结构，使用立方Hermite样条编码运动阶段，适应当地高度图统计，支持形态无关的策略学习。

Result: 提出了一种新的深度强化学习方法PGTT，旨在解决现有腿部机器人控制器的缺陷，改善适应性与鲁棒性。

Conclusion: 通过实验证明，PGTT在不同地形下表现优越，适用于多种机器人平台，展现了其在感知步态控制方面的前景。

Abstract: State-of-the-art perceptive Reinforcement Learning controllers for legged
robots either (i) impose oscillator or IK-based gait priors that constrain the
action space, add bias to the policy optimization and reduce adaptability
across robot morphologies, or (ii) operate "blind", which struggle to
anticipate hind-leg terrain, and are brittle to noise. In this paper, we
propose Phase-Guided Terrain Traversal (PGTT), a perception-aware deep-RL
approach that overcomes these limitations by enforcing gait structure purely
through reward shaping, thereby reducing inductive bias in policy learning
compared to oscillator/IK-conditioned action priors. PGTT encodes per-leg phase
as a cubic Hermite spline that adapts swing height to local heightmap
statistics and adds a swing-phase contact penalty, while the policy acts
directly in joint space supporting morphology-agnostic deployment. Trained in
MuJoCo (MJX) on procedurally generated stair-like terrains with curriculum and
domain randomization, PGTT achieves the highest success under push disturbances
(median +7.5% vs. the next best method) and on discrete obstacles (+9%), with
comparable velocity tracking, and converging to an effective policy roughly 2x
faster than strong end-to-end baselines. We validate PGTT on a Unitree Go2
using a real-time LiDAR elevation-to-heightmap pipeline, and we report
preliminary results on ANYmal-C obtained with the same hyperparameters. These
findings indicate that terrain-adaptive, phase-guided reward shaping is a
simple and general mechanism for robust perceptive locomotion across platforms.

</details>


### [12] [MMRHP: A Miniature Mixed-Reality HIL Platform for Auditable Closed-Loop Evaluation](https://arxiv.org/abs/2510.18371)
*Mingxin Li,Haibo Hu,Jinghuai Deng,Yuchen Xi,Xinhong Chen,Jianping Wang*

Main category: cs.RO

TL;DR: 本论文提出了一种名为MMRHP的迷你混合现实硬件在环(HIL)平台，旨在提升自动驾驶系统的验证过程，通过系统的方法和实验验证，实现可重复、可量化的测试，符合安全意图功能(SOTIF)标准。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统验证需要在测试逼真性、成本和可扩展性之间进行权衡，现有的迷你HIL平台缺乏系统的定量分析框架。

Method: 提出了一种系统的三阶段测试过程，并设计和实现了一个以统一时空测量核心为中心的HIL平台，以支持这一过程，确保物理运动和系统时序的量化一致性和可追溯性。

Result: 实验表明，该平台的空间精度达到10.27 mm RMSE，闭环延迟基线约为45 ms，并且在Autoware案例研究中确认了在40 ms注入延迟下的关键性能悬崖。

Conclusion: 本研究表明，结合结构化流程和统一时空基准的平台，能够实现自动驾驶系统的可重复、可解释和定量的闭环评估。

Abstract: Validation of autonomous driving systems requires a trade-off between test
fidelity, cost, and scalability. While miniaturized hardware-in-the-loop (HIL)
platforms have emerged as a promising solution, a systematic framework
supporting rigorous quantitative analysis is generally lacking, limiting their
value as scientific evaluation tools. To address this challenge, we propose
MMRHP, a miniature mixed-reality HIL platform that elevates miniaturized
testing from functional demonstration to rigorous, reproducible quantitative
analysis. The core contributions are threefold. First, we propose a systematic
three-phase testing process oriented toward the Safety of the Intended
Functionality(SOTIF)standard, providing actionable guidance for identifying the
performance limits and triggering conditions of otherwise correctly functioning
systems. Second, we design and implement a HIL platform centered around a
unified spatiotemporal measurement core to support this process, ensuring
consistent and traceable quantification of physical motion and system timing.
Finally, we demonstrate the effectiveness of this solution through
comprehensive experiments. The platform itself was first validated, achieving a
spatial accuracy of 10.27 mm RMSE and a stable closed-loop latency baseline of
approximately 45 ms. Subsequently, an in-depth Autoware case study leveraged
this validated platform to quantify its performance baseline and identify a
critical performance cliff at an injected latency of 40 ms. This work shows
that a structured process, combined with a platform offering a unified
spatio-temporal benchmark, enables reproducible, interpretable, and
quantitative closed-loop evaluation of autonomous driving systems.

</details>


### [13] [Biomechanically consistent real-time action recognition for human-robot interaction](https://arxiv.org/abs/2510.18373)
*Wanchen Li,Kahina Chalabi,Sabbah Maxime,Thomas Bousquet,Robin Passama,Sofiane Ramdani,Andrea Cherubini,Vincent Bonnet*

Main category: cs.RO

TL;DR: 本文提出了一种新的框架，用于工业背景下的实时人类动作识别，利用标准2D相机。


<details>
  <summary>Details</summary>
Motivation: 提高工业环境中的人类动作识别的精确性和实时性，解决传统方法的局限性。

Method: 通过一个包含11个受试者执行多种动作的新数据集进行评估，利用生物力学先验（如关节角度）实现快速和鲁棒的实时识别。

Result: 在不面向摄像机的对象上，模型达到了88%的准确率并展示了良好的泛化能力。

Conclusion: 我们的学习模型在各种指标上优于最佳基线模型，并具备良好的泛化能力，适用于不同的环境和对象。

Abstract: This paper presents a novel framework for real-time human action recognition
in industrial contexts, using standard 2D cameras. We introduce a complete
pipeline for robust and real-time estimation of human joint kinematics, input
to a temporally smoothed Transformer-based network, for action recognition. We
rely on a new dataset including 11 subjects performing various actions, to
evaluate our approach. Unlike most of the literature that relies on joint
center positions (JCP) and is offline, ours uses biomechanical prior, eg. joint
angles, for fast and robust real-time recognition. Besides, joint angles make
the proposed method agnostic to sensor and subject poses as well as to
anthropometric differences, and ensure robustness across environments and
subjects. Our proposed learning model outperforms the best baseline model,
running also in real-time, along various metrics. It achieves 88% accuracy and
shows great generalization ability, for subjects not facing the cameras.
Finally, we demonstrate the robustness and usefulness of our technique, through
an online interaction experiment, with a simulated robot controlled in
real-time via the recognized actions.

</details>


### [14] [MPC-based motion planning for non-holonomic systems in non-convex domains](https://arxiv.org/abs/2510.18402)
*Matthias Lorenzen,Teodoro Alamo,Martina Mammarella,Fabrizio Dabbene*

Main category: cs.RO

TL;DR: 研究了适用于非完整系统的MPC，提出了一种新的形式，确保在真实条件下收敛到目标。


<details>
  <summary>Details</summary>
Motivation: 探讨将模型预测控制应用于自主移动机器人运动规划的必要性。

Method: 研究了适用于非完整系统和非凸约束的输出跟踪MPC形式。

Result: 在现实条件下，保证了所提出的MPC在运动规划中的有效性。

Conclusion: 提出了一种新的MPC形式，确保在现实条件下收敛到期望目标。

Abstract: Motivated by the application of using model predictive control (MPC) for
motion planning of autonomous mobile robots, a form of output tracking MPC for
non-holonomic systems and with non-convex constraints is studied. Although the
advantages of using MPC for motion planning have been demonstrated in several
papers, in most of the available fundamental literature on output tracking MPC
it is assumed, often implicitly, that the model is holonomic and generally the
state or output constraints must be convex. Thus, in application-oriented
publications, empirical results dominate and the topic of proving completeness,
in particular under which assumptions the target is always reached, has
received comparatively little attention. To address this gap, we present a
novel MPC formulation that guarantees convergence to the desired target under
realistic assumptions, which can be verified in relevant real-world scenarios.

</details>


### [15] [Efficient Model-Based Reinforcement Learning for Robot Control via Online Learning](https://arxiv.org/abs/2510.18518)
*Fang Nan,Hao Ma,Qinghua Guan,Josie Hughes,Michael Muehlebach,Marco Hutter*

Main category: cs.RO

TL;DR: 提出了一种在线模型基础的强化学习算法，通过实时互动数据构建动力学模型，显著提高样本效率，并在真实环境中直接训练控制策略。


<details>
  <summary>Details</summary>
Motivation: 为了直接在真实世界中控制复杂的机器人系统，解决现有的仿真到现实的瓶颈

Method: 在线基于模型的强化学习算法

Result: 在液压挖掘臂和软体机器人臂上的实验展示了强大的样本效率，相比于无模型强化学习方法，能够在数小时内达到可比的性能

Conclusion: 该方法为高效可靠的机器人学习开辟了新的路径，适用于多种复杂的控制任务。

Abstract: We present an online model-based reinforcement learning algorithm suitable
for controlling complex robotic systems directly in the real world. Unlike
prevailing sim-to-real pipelines that rely on extensive offline simulation and
model-free policy optimization, our method builds a dynamics model from
real-time interaction data and performs policy updates guided by the learned
dynamics model. This efficient model-based reinforcement learning scheme
significantly reduces the number of samples to train control policies, enabling
direct training on real-world rollout data. This significantly reduces the
influence of bias in the simulated data, and facilitates the search for
high-performance control policies. We adopt online learning analysis to derive
sublinear regret bounds under standard stochastic online optimization
assumptions, providing formal guarantees on performance improvement as more
interaction data are collected. Experimental evaluations were performed on a
hydraulic excavator arm and a soft robot arm, where the algorithm demonstrates
strong sample efficiency compared to model-free reinforcement learning methods,
reaching comparable performance within hours. Robust adaptation to shifting
dynamics was also observed when the payload condition was randomized. Our
approach paves the way toward efficient and reliable on-robot learning for a
broad class of challenging control tasks.

</details>


### [16] [EfficientNav: Towards On-Device Object-Goal Navigation with Navigation Map Caching and Retrieval](https://arxiv.org/abs/2510.18546)
*Zebin Yang,Sunjian Zheng,Tong Xie,Tianshi Xu,Bo Yu,Fan Wang,Jie Tang,Shaoshan Liu,Meng Li*

Main category: cs.RO

TL;DR: EfficientNav通过引入新的记忆管理技术，使小型LLM能够有效实现对象目标导航，并显著提升成功率及减少延迟。


<details>
  <summary>Details</summary>
Motivation: 现有依赖于云端大型语言模型的智能体在转向小型LLM时，成功率显著下降，且导航图的长提示增加了本地设备的规划延迟。

Method: 提出了语义感知的记忆检索、离散记忆缓存和基于注意力的记忆聚类，以提高小型LLM在目标导航任务中的表现。

Result: 在HM3D基准上的实验表明EfficientNav的成功率提高了11.1%，实时延迟减少了6.7倍，端到端延迟减少了4.7倍。

Conclusion: EfficientNav在HM3D基准上比基于GPT-4的基线取得了11.1%的成功率提升，并实现了显著的实时延迟和端到端延迟减少。

Abstract: Object-goal navigation (ObjNav) tasks an agent with navigating to the
location of a specific object in an unseen environment. Embodied agents
equipped with large language models (LLMs) and online constructed navigation
maps can perform ObjNav in a zero-shot manner. However, existing agents heavily
rely on giant LLMs on the cloud, e.g., GPT-4, while directly switching to small
LLMs, e.g., LLaMA3.2-11b, suffer from significant success rate drops due to
limited model capacity for understanding complex navigation maps, which
prevents deploying ObjNav on local devices. At the same time, the long prompt
introduced by the navigation map description will cause high planning latency
on local devices. In this paper, we propose EfficientNav to enable on-device
efficient LLM-based zero-shot ObjNav. To help the smaller LLMs better
understand the environment, we propose semantics-aware memory retrieval to
prune redundant information in navigation maps. To reduce planning latency, we
propose discrete memory caching and attention-based memory clustering to
efficiently save and re-use the KV cache. Extensive experimental results
demonstrate that EfficientNav achieves 11.1% improvement in success rate on
HM3D benchmark over GPT-4-based baselines, and demonstrates 6.7x real-time
latency reduction and 4.7x end-to-end latency reduction over GPT-4 planner. Our
code will be released soon.

</details>


### [17] [Flexbee: A Grasping and Perching UAV Based on Soft Vector-Propulsion Nozzle](https://arxiv.org/abs/2510.18558)
*Yue Wang,Lixian Zhang,Yimin Zhu,Yangguang Liu,Xuwei Yang*

Main category: cs.RO

TL;DR: Flexbee是一种新型的无人机，集成了飞行、抓取和栖息功能，经过验证展示了其运动能力和控制策略的有效性。


<details>
  <summary>Details</summary>
Motivation: To create a versatile UAV that integrates flight, grasping, and perching functionalities for improved performance.

Method: Development of a dynamics model, resolution of nonlinear coupling issues, and implementation of a hierarchical control strategy.

Result: Flexbee successfully integrates multiple functionalities and exhibits effective control, as proven by experimental validation.

Conclusion: Flexbee demonstrates enhanced operational capabilities in flight, grasping, and perching, validated by conducted experiments.

Abstract: The aim of this paper is to design a new type of grasping and perching
unmanned aerial vehicle (UAV), called Flexbee, which features a soft
vector-propulsion nozzle (SVPN). Compared to previous UAVs, Flexbee integrates
flight, grasping, and perching functionalities into the four SVPNs. This
integration offers advantages including decoupled position and attitude
control, high structural reuse, and strong adaptability strong adaptability for
grasping and perching. A dynamics model of Flexbee has been developed, and the
nonlinear coupling issue of the moment has been resolved through linearization
of the equivalent moment model. A hierarchical control strategy was used to
design controllers for the two operational modes of Flexbee. Finally, flight,
grasping, and perching experiments were conducted to validate Flexbee's
kinematic capabilities and the effectiveness of the control strategy.

</details>


### [18] [Quadrupeds for Planetary Exploration: Field Testing Control Algorithms on an Active Volcano](https://arxiv.org/abs/2510.18600)
*Shubham Vyas,Franek Stark,Rohit Kumar,Hannah Isermann,Jonas Haack,Mihaela Popescu,Jakob Middelberg,Dennis Mronga,Frank Kirchner*

Main category: cs.RO

TL;DR: 本研究展示了四足机器人在复杂地形中的应用，验证了在类月球和火星表面工作的新控制算法。


<details>
  <summary>Details</summary>
Motivation: 探索行星的任务需要更高效的移动方式，四足机器人能在复杂地形中表现出优势。

Method: 通过在意大利的火山进行系列实地实验，评估四足机器人在复杂地形中的适应性和控制算法。

Result: 成功验证了新开发的自适应最优控制算法在四足机器人运动中的有效性。

Conclusion: 实验结果表明，四足机器人可以提升行星探索任务的能力和有效性。

Abstract: Missions such as the Ingenuity helicopter have shown the advantages of using
novel locomotion modes to increase the scientific return of planetary
exploration missions. Legged robots can further expand the reach and capability
of future planetary missions by traversing more difficult terrain than wheeled
rovers, such as jumping over cracks on the ground or traversing rugged terrain
with boulders. To develop and test algorithms for using quadruped robots, the
AAPLE project was carried out at DFKI. As part of the project, we conducted a
series of field experiments on the Volcano on the Aeolian island of Vulcano, an
active stratovolcano near Sicily, Italy. The experiments focused on validating
newly developed state-of-the-art adaptive optimal control algorithms for
quadrupedal locomotion in a high-fidelity analog environment for Lunar and
Martian surfaces. This paper presents the technical approach, test plan,
software architecture, field deployment strategy, and evaluation results from
the Vulcano campaign.

</details>


### [19] [A Compositional Paradigm for Foundation Models: Towards Smarter Robotic Agents](https://arxiv.org/abs/2510.18608)
*Luigi Quarantiello,Elia Piccoli,Jack Bell,Malio Li,Giacomo Carfì,Eric Nuertey Coleman,Gerlando Gramaglia,Lanpei Li,Mauro Madeddu,Irene Testa,Vincenzo Lomonaco*

Main category: cs.RO

TL;DR: 基础模型虽然表现出色，但在实际应用中需改进适应性，本文提出利用持续学习与组合性原则来提升AI系统的灵活性与效率。


<details>
  <summary>Details</summary>
Motivation: 目前基础模型在多个领域中取得了显著成果，但在动态、现实场景中适应性不足，而需要从头开始重训练的问题依然存在。

Method: 通过持续学习和组合性的原则推动AI模型在不同任务之间的迁移与适应。

Result: 提出应用持续学习和组合性原则，可以促进更灵活、高效和智能的AI解决方案的开发。

Conclusion: 采用持续学习和组合性原则有助于开发更加灵活和高效的人工智能解决方案，以应对现实世界中的动态变化。

Abstract: The birth of Foundation Models brought unprecedented results in a wide range
of tasks, from language to vision, to robotic control. These models are able to
process huge quantities of data, and can extract and develop rich
representations, which can be employed across different domains and modalities.
However, they still have issues in adapting to dynamic, real-world scenarios
without retraining the entire model from scratch. In this work, we propose the
application of Continual Learning and Compositionality principles to foster the
development of more flexible, efficient and smart AI solutions.

</details>


### [20] [Least Restrictive Hyperplane Control Barrier Functions](https://arxiv.org/abs/2510.18643)
*Mattias Trende,Petter Ögren*

Main category: cs.RO

TL;DR: 本文提出了一种新方法，通过优化CBFs和安全控制的组合，减少对控制的限制，同时保持安全性保障。


<details>
  <summary>Details</summary>
Motivation: CBFs在动态系统中提供安全保障，但寻找有效的CBFs往往困难，尤其是在不安全区域复杂时。

Method: 优化CBFs和安全控制的组合，生成最少限制的Hyperplane-CBF，同时为CBF家族创建光滑参数化。

Result: 在双重积分动态系统中应用此方法，展示了在有障碍物的环境中安全控制的有效性。

Conclusion: 提出的最少限制Hyperplane-CBF能够有效应对具有复杂不安全区域的动态系统，并提供安全控制。

Abstract: Control Barrier Functions (CBFs) can provide provable safety guarantees for
dynamic systems. However, finding a valid CBF for a system of interest is often
non-trivial, especially if the shape of the unsafe region is complex and the
CBFs are of higher order. A common solution to this problem is to make a
conservative approximation of the unsafe region in the form of a
line/hyperplane, and use the corresponding conservative Hyperplane-CBF when
deciding on safe control actions. In this letter, we note that conservative
constraints are only a problem if they prevent us from doing what we want.
Thus, instead of first choosing a CBF and then choosing a safe control with
respect to the CBF, we optimize over a combination of CBFs and safe controls to
get as close as possible to our desired control, while still having the safety
guarantee provided by the CBF. We call the corresponding CBF the least
restrictive Hyperplane-CBF. Finally, we also provide a way of creating a smooth
parameterization of the CBF-family for the optimization, and illustrate the
approach on a double integrator dynamical system with acceleration constraints,
moving through a group of arbitrarily shaped static and moving obstacles.

</details>


### [21] [Towards An Adaptive Locomotion Strategy For Quadruped Rovers: Quantifying When To Slide Or Walk On Planetary Slopes](https://arxiv.org/abs/2510.18678)
*Alberto Sanchez-Delgado,João Carlos Virgolino Soares,David Omar Al Tawil,Alessia Li Noce,Matteo Villa,Victor Barasuol,Paolo Arena,Claudio Semini*

Main category: cs.RO

TL;DR: 本文比较了四足机器人在不同条件下的步态与滑动方式的能量效率，为未来自适应移动策略奠定基础。


<details>
  <summary>Details</summary>
Motivation: 提高行走机器人在不平坦和陡峭行星表面上的移动能力，而传统腿部运动可能不够高效且存在风险。

Method: 结合了Isaac Sim中的基于物理的模拟和ANSYS-Rocky中的粒子互动验证。

Result: 比较了四足机器人在不同坡度、摩擦条件和速度下，步态与躯干滑动的运输成本。

Conclusion: 提出了阈值条件，以帮助判断在行走与滑动之间的切换，推动未来的自适应运动策略。

Abstract: Legged rovers provide enhanced mobility compared to wheeled platforms,
enabling navigation on steep and irregular planetary terrains. However,
traditional legged locomotion might be energetically inefficient and
potentially dangerous to the rover on loose and inclined surfaces, such as
crater walls and cave slopes. This paper introduces a preliminary study that
compares the Cost of Transport (CoT) of walking and torso-based sliding
locomotion for quadruped robots across different slopes, friction conditions
and speed levels. By identifying intersections between walking and sliding CoT
curves, we aim to define threshold conditions that may trigger transitions
between the two strategies. The methodology combines physics-based simulations
in Isaac Sim with particle interaction validation in ANSYS-Rocky. Our results
represent an initial step towards adaptive locomotion strategies for planetary
legged rovers.

</details>


### [22] [Event-Grounding Graph: Unified Spatio-Temporal Scene Graph from Robotic Observations](https://arxiv.org/abs/2510.18697)
*Phuoc Nguyen,Francesco Verdoja,Ville Kyrki*

Main category: cs.RO

TL;DR: 本文提出了一种新框架EGG，可以将事件与空间特征关联，提升机器人对环境的理解和响应能力。


<details>
  <summary>Details</summary>
Motivation: 构建能够执行复杂时空查询的智能自主机器人，增强其环境理解能力。

Method: 提出事件基础图（EGG），将事件交互连接到场景的空间特征。

Result: EGG能够准确检索有关环境和事件的信息，并对人类询问做出响应。

Conclusion: EGG框架有效提高了机器人对复杂环境查询的处理能力，并已开源。

Abstract: A fundamental aspect for building intelligent autonomous robots that can
assist humans in their daily lives is the construction of rich environmental
representations. While advances in semantic scene representations have enriched
robotic scene understanding, current approaches lack a connection between
spatial features and dynamic events; e.g., connecting the blue mug to the event
washing a mug. In this work, we introduce the event-grounding graph (EGG), a
framework grounding event interactions to spatial features of a scene. This
representation allows robots to perceive, reason, and respond to complex
spatio-temporal queries. Experiments using real robotic data demonstrate EGG's
capability to retrieve relevant information and respond accurately to human
inquiries concerning the environment and events within. Furthermore, the EGG
framework's source code and evaluation dataset are released as open-source at:
https://github.com/aalto-intelligent-robotics/EGG.

</details>


### [23] [Sharing the Load: Distributed Model-Predictive Control for Precise Multi-Rover Cargo Transport](https://arxiv.org/abs/2510.18766)
*Alexander Krawciw,Sven Lilge,Luka Antonyshyn,Timothy D. Barfoot*

Main category: cs.RO

TL;DR: 本文提出了一种基于共享地图的分布式模型预测控制器(MPC)一用于多个移动机器人进行货运操作，显示出在路径跟踪和车辆间距方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 由于多个移动机器人能提供比单个大型机器人更高的操作灵活性，因此在自主货物运输中需要改进车辆间的距离和路径跟踪精度。

Method: 开发了基于 lidar 教学和重复的分布式模型预测控制器(MPC)。

Result: 分布式MPC在10公里训练中表现出与中央MPC相当的性能；在近距离场景中，直接测量的相对距离跟踪性能更佳，但在远距离偏移时存在困难。

Conclusion: 分布式MPC在多车辆货运操作中显示出与集中式MPC相当的性能，适用于实时部署。

Abstract: For autonomous cargo transportation, teams of mobile robots can provide more
operational flexibility than a single large robot. In these scenarios,
precision in both inter-vehicle distance and path tracking is key. With this
motivation, we develop a distributed model-predictive controller (MPC) for
multi-vehicle cargo operations that builds on the precise path-tracking of
lidar teach and repeat. To carry cargo, a following vehicle must maintain a
Euclidean distance offset from a lead vehicle regardless of the path curvature.
Our approach uses a shared map to localize the robots relative to each other
without GNSS or direct observations. We compare our approach to a centralized
MPC and a baseline approach that directly measures the inter-vehicle distance.
The distributed MPC shows equivalent nominal performance to the more complex
centralized MPC. Using a direct measurement of the relative distance between
the leader and follower shows improved tracking performance in close-range
scenarios but struggles with long-range offsets. The operational flexibility
provided by distributing the computation makes it well suited for real
deployments. We evaluate four types of convoyed path trackers with over 10 km
of driving in a coupled convoy. With convoys of two and three rovers, the
proposed distributed MPC method works in real-time to allow map-based convoying
to maintain maximum spacing within 20 cm of the target in various conditions.

</details>


### [24] [Online Object-Level Semantic Mapping for Quadrupeds in Real-World Environments](https://arxiv.org/abs/2510.18776)
*Emad Razavi,Angelo Bratta,João Carlos Virgolino Soares,Carmine Recchiuto,Claudio Semini*

Main category: cs.RO

TL;DR: 提出了一种用于四足机器人的在线语义物体映射系统，能够在真实室内环境中将传感器检测转化为全球图中的命名物体。


<details>
  <summary>Details</summary>
Motivation: 在复杂环境中准确识别和持久跟踪对象，以实现更复杂的自主导航和任务执行。

Method: 系统通过整合距离几何信息与摄像头检测，合并同帧内的共存检测，并将重复检测关联为持续的物体实例。

Result: 测试表明，该物体层在视角变化时保持稳定，能够被规划器读取。

Conclusion: 该系统能够稳定地在视角变化下保持物体映射的稳定性，并有效整合不同传感器数据。

Abstract: We present an online semantic object mapping system for a quadruped robot
operating in real indoor environments, turning sensor detections into named
objects in a global map. During a run, the mapper integrates range geometry
with camera detections, merges co-located detections within a frame, and
associates repeated detections into persistent object instances across frames.
Objects remain in the map when they are out of view, and repeated sightings
update the same instance rather than creating duplicates. The output is a
compact object layer that can be queried (class, pose, and confidence), is
integrated with the occupancy map and readable by a planner. In on-robot tests,
the layer remained stable across viewpoint changes.

</details>


### [25] [MADR: MPC-guided Adversarial DeepReach](https://arxiv.org/abs/2510.18845)
*Ryan Teoh,Sander Tonkens,William Sharpless,Aijia Yang,Zeyuan Feng,Somil Bansal,Sylvia Herbert*

Main category: cs.RO

TL;DR: MADR框架结合MPC与深度学习，有效解决高维对抗博弈中的策略和安全问题，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 虽然HJ可达性能够生成安全值函数，但面临维数诅咒，而物理信息深度学习在收敛性上相对较慢且不准确，因此需要一种新的方法来解决这些问题。

Method: 引入MADR：基于MPC引导的对抗深度Reach，通过增强自我监督与常规监督结合来逼近两人零和微分游戏的价值函数。

Result: MADR在多个高维仿真及实际机器人任务中测试，显著超越现有最优基线，并取得令人印象深刻的硬件结果。

Conclusion: MADR在高维复杂环境中表现优异，提供了健壮的零和博弈策略和安全政策。

Abstract: Hamilton-Jacobi (HJ) Reachability offers a framework for generating safe
value functions and policies in the face of adversarial disturbance, but is
limited by the curse of dimensionality. Physics-informed deep learning is able
to overcome this infeasibility, but itself suffers from slow and inaccurate
convergence, primarily due to weak PDE gradients and the complexity of
self-supervised learning. A few works, recently, have demonstrated that
enriching the self-supervision process with regular supervision (based on the
nature of the optimal control problem), greatly accelerates convergence and
solution quality, however, these have been limited to single player problems
and simple games. In this work, we introduce MADR: MPC-guided Adversarial
DeepReach, a general framework to robustly approximate the two-player, zero-sum
differential game value function. In doing so, MADR yields the corresponding
optimal strategies for both players in zero-sum games as well as safe policies
for worst-case robustness. We test MADR on a multitude of high-dimensional
simulated and real robotic agents with varying dynamics and games, finding that
our approach significantly out-performs state-of-the-art baselines in
simulation and produces impressive results in hardware.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [26] [Presenting Large Language Models as Companions Affects What Mental Capacities People Attribute to Them](https://arxiv.org/abs/2510.18039)
*Allison Chen,Sunnie S. Y. Kim,Angel Franyutti,Amaya Dharmasiri,Kushin Mukherjee,Olga Russakovsky,Judith E. Fan*

Main category: cs.HC

TL;DR: 此研究探讨关于大型语言模型的信息传达如何影响人们对它们的看法和使用，发现将LLMs视为‘伴侣’会增强人们对其心理能力的信念。


<details>
  <summary>Details</summary>
Motivation: 研究公共话语中关于大型语言模型（LLMs）的信息如何影响人们对这些模型的看法和互动方式。

Method: 随机分配参与者观看不同类型的视频（机器、工具、伴侣）或不观看视频，随后评估他们对LLMs心理能力的信念。

Result: 观看伴侣视频的参与者认为LLMs更具备意图或记忆等心理能力。

Conclusion: 信息传达方式对人们对AI的看法有显著影响，超越了技术进步对社会的影响。

Abstract: How does messaging about about large language models (LLMs) in public
discourse influence the way people think about and interact with these models?
To answer this question, we randomly assigned participants (N = 470) to watch a
short informational video presenting LLMs as either machines, tools, or
companions -- or to watch no video. We then assessed how strongly they believed
LLMs to possess various mental capacities, such as the ability have intentions
or remember things. We found that participants who watched the companion video
reported believing that LLMs more fully possessed these capacities than did
participants in other groups. In a follow-up study (N = 604), we replicated
these findings and found nuanced effects on how these videos impact people's
reliance on LLM-generated responses when seeking out factual information.
Together, these studies highlight the impact of messaging about AI -- beyond
technical advances in AI -- to generate broad societal impact.

</details>


### [27] [Design and Challenges of Mental Health Assessment Tools Based on Natural Language Interaction](https://arxiv.org/abs/2510.18158)
*Yixue Cai,Xiyan Su,Dongpeng Yao,Rongduo Han,Nan Gao,Haining Zhang*

Main category: cs.HC

TL;DR: 本研究探讨了利用自然语言交互的AI心理健康评估工具的设计机会与挑战，提升了自我报告数据的可靠性，但同时也揭示了隐私及偏见等问题。


<details>
  <summary>Details</summary>
Motivation: 传统心理健康评估方法受主观性、回忆偏差及可达性等因素影响，研究旨在改善这一现状，探索AI在心理健康评估中的应用。

Method: 通过开发一个基于会话AI的互动原型系统，并与心理健康专业人员进行半结构访谈来评估该系统。

Result: 本研究探讨了基于大语言模型的自然语言交互的心理健康评估工具的设计机会与挑战。通过与11名心理健康专业人员的半结构访谈，开发了一个互动原型系统。结果显示，AI驱动的自适应提问可能提升自我报告数据的可靠性，但也面临隐私保护、算法偏见和跨文化适用性等关键挑战。

Conclusion: 该研究为心理健康技术创新提供了实证基础，展示了自然语言交互在心理健康评估中的潜力与局限性。

Abstract: Mental health assessments are of central importance to individuals'
well-being. Conventional assessment methodologies predominantly depend on
clinical interviews and standardised self-report questionnaires. Nevertheless,
the efficacy of these methodologies is frequently impeded by factors such as
subjectivity, recall bias, and accessibility issues. Furthermore, concerns
regarding bias and privacy may result in misreporting in data collected through
self-reporting in mental health research. The present study examined the design
opportunities and challenges inherent in the development of a mental health
assessment tool based on natural language interaction with large language
models (LLMs). An interactive prototype system was developed using
conversational AI for non-invasive mental health assessment, and was evaluated
through semi-structured interviews with 11 mental health professionals (six
counsellors and five psychiatrists). The analysis identified key design
considerations for future development, highlighting how AI-driven adaptive
questioning could potentially enhance the reliability of self-reported data
while identifying critical challenges, including privacy protection,
algorithmic bias, and cross-cultural applicability. This study provides an
empirical foundation for mental health technology innovation by demonstrating
the potential and limitations of natural language interaction in mental health
assessment.

</details>


### [28] [Enhancing Urban Data Exploration: Layer Toggling and Visibility-Preserving Lenses for Multi-Attribute Spatial Analysis](https://arxiv.org/abs/2510.18185)
*Karelia Salinas,Luis Gustavo Nonato,Jean-Daniel Fekete,Fernanda Bartolo dos Santos Saran*

Main category: cs.HC

TL;DR: 本论文提出两种创新的互动技术，旨在改善城市数据的可视化和探索，减少认知负担并提升分析效率。


<details>
  <summary>Details</summary>
Motivation: 在城市规划中，理解犯罪、流动性及居民行为等复杂现象至关重要，但数据重叠会导致认知过载与视觉杂乱。

Method: 通过用户研究测量性能、认知负载和交互效率，对可视化工具进行验证。

Result: 通过真人实测的研究结果，展示了所提出技术如何改善探索性和分析性任务。

Conclusion: 提出的互动技术有效促进了城市数据的探究与分析，降低了认知负担，并为未来交互系统提供指导。

Abstract: We propose two novel interaction techniques for visualization-assisted
exploration of urban data: Layer Toggling and Visibility-Preserving Lenses.
Layer Toggling mitigates visual overload by organizing information into
separate layers while enabling comparisons through controlled overlays. This
technique supports focused analysis without losing spatial context and allows
users to switch layers using a dedicated button. Visibility-Preserving Lenses
adapt their size and transparency dynamically, enabling detailed inspection of
dense spatial regions and temporal attributes. These techniques facilitate
urban data exploration and improve prediction. Understanding complex phenomena
related to crime, mobility, and residents' behavior is crucial for informed
urban planning. Yet navigating such data often causes cognitive overload and
visual clutter due to overlapping layers. We validate our visualization tool
through a user study measuring performance, cognitive load, and interaction
efficiency. Using real-world data from Sao Paulo, we demonstrate how our
approach enhances exploratory and analytical tasks and provides guidelines for
future interactive systems.

</details>


### [29] [Relief or displacement? How teachers are negotiating generative AI's role in their professional practice](https://arxiv.org/abs/2510.18296)
*Aayushi Dangol,Smriti Kotiyal,Robert Wolfe,Alex J. Bowers,Antonio Vigil,Jason Yip,Julie A. Kientz,Suleman Shahid,Tom Yeh,Vincent Cho,Katie Davis*

Main category: cs.HC

TL;DR: 研究表明，生成型人工智能在教育中的应用需要重新思考传统的采用与培训模式，特别是需要关注其在教师培训和资源支持上的不平等。


<details>
  <summary>Details</summary>
Motivation: 探讨生成型人工智能在教育中的应用，了解教师的采用动机和抵制因素。

Method: 对22位来自早期采用生成型人工智能的大型美国学区的教师进行了半结构化访谈。

Result: 研究揭示了教师在采用生成型人工智能时的动机、抵制及其在社会技术动态中的作用。

Conclusion: 教师在使用生成型人工智能时面临的动机、抵制因素和社会技术动态影响了其价值观的对齐。

Abstract: As generative AI (genAI) rapidly enters classrooms, accompanied by
district-level policy rollouts and industry-led teacher trainings, it is
important to rethink the canonical ``adopt and train'' playbook. Decades of
educational technology research show that tools promising personalization and
access often deepen inequities due to uneven resources, training, and
institutional support. Against this backdrop, we conducted semi-structured
interviews with 22 teachers from a large U.S. school district that was an early
adopter of genAI. Our findings reveal the motivations driving adoption, the
factors underlying resistance, and the boundaries teachers negotiate to align
genAI use with their values. We further contribute by unpacking the
sociotechnical dynamics -- including district policies, professional norms, and
relational commitments -- that shape how teachers navigate the promises and
risks of these tools.

</details>


### [30] [Reimagining Disassembly Interfaces with Visualization: Combining Instruction Tracing and Control Flow with DisViz](https://arxiv.org/abs/2510.18311)
*Shadmaan Hye,Matthew P. LeGendre,Katherine E. Isaacs*

Main category: cs.HC

TL;DR: 我们设计了一种新型的反汇编可视化工具，名为DisViz，帮助开发者理解和分析反汇编代码。


<details>
  <summary>Details</summary>
Motivation: 在效率至关重要的应用中，开发者需要分析编译后的二进制文件以理解编译器对源代码的变换及其性能影响，但由于反汇编指令数量庞大及其与源代码的复杂映射关系，这一分析任务变得极具挑战性。

Method: 通过设计研究方法论与程序分析专家合作开发DisViz，进行的评估会话得到了十名来自四个机构的参与者的反馈。

Result: 本文提出了一种新的反汇编代码可视化界面DisViz，旨在帮助开发者更好地理解和分析反汇编代码。该界面结合了执行顺序和控制流结构，采用直观的基本块布局，以展示循环结构，同时引入一个基于块的迷你地图，显示数千条反汇编指令的上下文。

Conclusion: 我们的评估表明，新的集成视图有助于应用程序开发者理解和导航反汇编代码。

Abstract: In applications where efficiency is critical, developers may examine their
compiled binaries, seeking to understand how the compiler transformed their
source code and what performance implications that transformation may have.
This analysis is challenging due to the vast number of disassembled binary
instructions and the many-to-many mappings between them and the source code.
These problems are exacerbated as source code size increases, giving the
compiler more freedom to map and disperse binary instructions across the
disassembly space. Interfaces for disassembly typically display instructions as
an unstructured listing or sacrifice the order of execution. We design a new
visual interface for disassembly code that combines execution order with
control flow structure, enabling analysts to both trace through code and
identify familiar aspects of the computation. Central to our approach is a
novel layout of instructions grouped into basic blocks that displays a looping
structure in an intuitive way. We add to this disassembly representation a
unique block-based mini-map that leverages our layout and shows context across
thousands of disassembly instructions. Finally, we embed our disassembly
visualization in a web-based tool, DisViz, which adds dynamic linking with
source code across the entire application. DizViz was developed in
collaboration with program analysis experts following design study methodology
and was validated through evaluation sessions with ten participants from four
institutions. Participants successfully completed the evaluation tasks,
hypothesized about compiler optimizations, and noted the utility of our new
disassembly view. Our evaluation suggests that our new integrated view helps
application developers in understanding and navigating disassembly code.

</details>


### [31] [Khelte Khelte Shikhi: A Proposed HCI Framework for Gamified Interactive Learning with Minecraft in Bangladeshi Education Systems](https://arxiv.org/abs/2510.18385)
*Mohd Ruhul Ameen,Akif Islam,Momen Khandokar Ope*

Main category: cs.HC

TL;DR: 提出了在孟加拉国实施Minecraft教育版的框架，针对不同学校环境设计了三种方案，并包含本地化课程


<details>
  <summary>Details</summary>
Motivation: 在缺乏可靠互联网和计算机资源的情况下提高孟加拉国学校的学生参与度

Method: 提出一套实施Minecraft教育版的框架

Result: 设计了三种针对不同环境的部署方案，并提供了本地化的课程内容

Conclusion: 该框架未经过实证验证，但基于游戏学习理论、HCI原则和情境分析，将为资源受限的环境提供可实施的规范。

Abstract: Game-based learning shows real promise for engaging students in well-funded
schools, but what about everyone else? We propose a practical framework for
implementing Minecraft Education Edition in Bangladesh's 130,000 schools where
55 percent lack reliable internet, rural areas experience 12-16 hour daily
power availability, only 8 percent of rural schools have computer access, and
student-teacher ratios reach 52:1. Our approach tackles these constraints
head-on with three deployment tiers: cloud-based multiplayer for urban schools
with stable infrastructure (15 percent), local area network solutions with
solar power for semi-urban contexts (30 percent), and offline turn-based modes
using refurbished hardware for rural settings (55 percent). We provide eight
pre-built curriculum-aligned worlds with complete Bangla localization covering
topics from Lalbagh Fort reconstruction to monsoon flood simulation. The
interface accommodates first-time users through progressive complexity,
culturally familiar metaphors using local farming and architecture, and
accessibility features including keyboard-only controls and 200 percent text
scaling. Teacher training spans 48 hours across digital literacy, pedagogical
integration, and content creation. We detail evaluation protocols with specific
benchmarks: 15 percent learning gains, 70 percent transfer task mastery, System
Usability Scale scores above 70, and sub-two-dollar cost per student-hour. This
framework has not been empirically validated; it synthesizes game-based
learning theory, HCI principles, and contextual analysis to provide
implementable specifications for pilot testing in resource-constrained
settings.

</details>


### [32] [Effects of Virtual Controller Representation and Virtuality on Selection Performance in Extended Reality](https://arxiv.org/abs/2510.18625)
*Eric DeDeMarbre,Jay Henderson,J. Felipe Gonzalez,Rob Teather*

Main category: cs.HC

TL;DR: 该研究探讨了控制器虚拟表现对MR和VR上下文目标获取的影响，发现通过控制器表现的现实模仿增强了两者模式下的表现。


<details>
  <summary>Details</summary>
Motivation: 探索控制器的虚拟表现如何影响MR和VR环境中的目标获取性能

Method: 实验比较四种视觉配置下的目标获取性能

Result: 发现VR和MR之间的性能相当，控制器的现实模仿提高了性能，而用户在MR中感知性能有所不同

Conclusion: 在MR设计中需要考虑用户的空间意识，以进一步优化体验。

Abstract: We present an experiment exploring how the controller's virtual
representation impacts target acquisition performance across MR and VR
contexts. Participants performed selection tasks comparing four visual
configurations: a virtual controller, a virtual hand, both the controller and
the hand, and neither representation. We found performance comparable between
VR and MR, and switching between them did not impact the user's ability to
perform basic tasks. Controller representations mimicking reality enhanced
performance across both modes. However, users perceived performance differently
in MR, indicating the need for unique MR design considerations, particularly
regarding spatial awareness.

</details>
