<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 32]
- [cs.HC](#cs.HC) [Total: 15]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Multi-Agent Reinforcement Learning and Real-Time Decision-Making in Robotic Soccer for Virtual Environments](https://arxiv.org/abs/2512.03166)
*Aya Taourirte,Md Sohag Mia*

Main category: cs.RO

TL;DR: 本论文提出了一种统一的多智能体强化学习框架，利用分层结构和平均场理论，显著提升了智能体在对抗环境中的决策能力，展示了有效的协作与控制能力。


<details>
  <summary>Details</summary>
Motivation: 在动态对抗环境中，现有的强化学习方法面临任务多粒度和大规模智能体交互的挑战，亟需一种新的框架来解决这些问题。

Method: 基于近端策略优化（PPO）建立基线，结合分层强化学习（HRL）和平均场理论进行多智能体协作的决策制定。

Result: 通过引入分层结构和平均场理论，最终实现了显著的性能提升，包括平均目标得分达到5.93，球控率89.1%，传球准确率92.3%。

Conclusion: 该研究提出的统一多智能体强化学习框架在复杂的多智能体环境中表现出了出色的性能，尤其是在时间调度和策略规划方面显著提升了目标得分和控制能力。

Abstract: The deployment of multi-agent systems in dynamic, adversarial environments like robotic soccer necessitates real-time decision-making, sophisticated cooperation, and scalable algorithms to avoid the curse of dimensionality. While Reinforcement Learning (RL) offers a promising framework, existing methods often struggle with the multi-granularity of tasks (long-term strategy vs. instant actions) and the complexity of large-scale agent interactions. This paper presents a unified Multi-Agent Reinforcement Learning (MARL) framework that addresses these challenges. First, we establish a baseline using Proximal Policy Optimization (PPO) within a client-server architecture for real-time action scheduling, with PPO demonstrating superior performance (4.32 avg. goals, 82.9% ball control). Second, we introduce a Hierarchical RL (HRL) structure based on the options framework to decompose the problem into a high-level trajectory planning layer (modeled as a Semi-Markov Decision Process) and a low-level action execution layer, improving global strategy (avg. goals increased to 5.26). Finally, to ensure scalability, we integrate mean-field theory into the HRL framework, simplifying many-agent interactions into a single agent vs. the population average. Our mean-field actor-critic method achieves a significant performance boost (5.93 avg. goals, 89.1% ball control, 92.3% passing accuracy) and enhanced training stability. Extensive simulations of 4v4 matches in the Webots environment validate our approach, demonstrating its potential for robust, scalable, and cooperative behavior in complex multi-agent domains.

</details>


### [2] [GRAND: Guidance, Rebalancing, and Assignment for Networked Dispatch in Multi-Agent Path Finding](https://arxiv.org/abs/2512.03194)
*Johannes Gaber,Meshal Alharbi,Daniele Gammelli,Gioele Zardini*

Main category: cs.RO

TL;DR: 本文提出一种结合图神经网络和优化算法的混合任务调度方法，能在大型机器人队伍中提升调度效率。


<details>
  <summary>Details</summary>
Motivation: 在仓库和物流环境中，大规模机器人队伍的使用日益普遍，小的控制增益会对操作产生大的影响，因此提高多智能体任务调度效率是非常重要的。

Method: 使用强化学习训练的图神经网络生成期望的机器人分布信号，并通过最小成本流进行区域间的再平衡，最后通过小规模的本地分配问题完成调度。

Result: 提出了一种混合方法，结合了学习基础的全局指导和轻量优化，显著提高了调度效率。

Conclusion: 将图结构的学习指导与可处理的求解器结合，能够有效降低拥堵，提供高吞吐量的大规模调度蓝图。

Abstract: Large robot fleets are now common in warehouses and other logistics settings, where small control gains translate into large operational impacts. In this article, we address task scheduling for lifelong Multi-Agent Pickup-and-Delivery (MAPD) and propose a hybrid method that couples learning-based global guidance with lightweight optimization. A graph neural network policy trained via reinforcement learning outputs a desired distribution of free agents over an aggregated warehouse graph. This signal is converted into region-to-region rebalancing through a minimum-cost flow, and finalized by small, local assignment problems, preserving accuracy while keeping per-step latency within a 1 s compute budget. On congested warehouse benchmarks from the League of Robot Runners (LRR) with up to 500 agents, our approach improves throughput by up to 10% over the 2024 winning scheduler while maintaining real-time execution. The results indicate that coupling graph-structured learned guidance with tractable solvers reduces congestion and yields a practical, scalable blueprint for high-throughput scheduling in large fleets.

</details>


### [3] [KALIKO: Kalman-Implicit Koopman Operator Learning For Prediction of Nonlinear Dynamical Systems](https://arxiv.org/abs/2512.03256)
*Albert H. Li,Ivan Dario Jimenez Rodriguez,Joel W. Burdick,Yisong Yue,Aaron D. Ames*

Main category: cs.RO

TL;DR: KALIKO学习利用卡尔曼滤波器隐式学习潜在动力学，实现了高质量的系统预测，超越了多个基准。


<details>
  <summary>Details</summary>
Motivation: 针对复杂系统难以建模的问题，如非线性、混沌和高维现象，提出一种新的建模方法。

Method: Kalman-Implicit Koopman Operator (KALIKO) Learning

Result: KALIKO方法利用卡尔曼滤波器隐式学习对应于潜在动力学的嵌入，能够产生高质量的重构和全球线性的潜在动力学。

Conclusion: KALIKO在不要求显式编码器的情况下，成功稳定了在强波动作用下的欠驱动操纵器的负载。

Abstract: Long-horizon dynamical prediction is fundamental in robotics and control, underpinning canonical methods like model predictive control. Yet, many systems and disturbance phenomena are difficult to model due to effects like nonlinearity, chaos, and high-dimensionality. Koopman theory addresses this by modeling the linear evolution of embeddings of the state under an infinite-dimensional linear operator that can be approximated with a suitable finite basis of embedding functions, effectively trading model nonlinearity for representational complexity. However, explicitly computing a good choice of basis is nontrivial, and poor choices may cause inaccurate forecasts or overfitting. To address this, we present Kalman-Implicit Koopman Operator (KALIKO) Learning, a method that leverages the Kalman filter to implicitly learn embeddings corresponding to latent dynamics without requiring an explicit encoder. KALIKO produces interpretable representations consistent with both theory and prior works, yielding high-quality reconstructions and inducing a globally linear latent dynamics. Evaluated on wave data generated by a high-dimensional PDE, KALIKO surpasses several baselines in open-loop prediction and in a demanding closed-loop simulated control task: stabilizing an underactuated manipulator's payload by predicting and compensating for strong wave disturbances.

</details>


### [4] [GOMP: Grasped Object Manifold Projection for Multimodal Imitation Learning of Manipulation](https://arxiv.org/abs/2512.03347)
*William van den Bogert,Gregory Linkowski,Nima Fazeli*

Main category: cs.RO

TL;DR: 本研究提出GOMP方法，通过将非刚性抓取对象限制到较低维流形，有效减少模仿学习中的错误叠加问题，提高工业组装任务中的精确性。


<details>
  <summary>Details</summary>
Motivation: 研究驱动源于模仿学习在重复操纵任务中的潜力，但面临的挑战是由于错误叠加导致的轨迹精度不足。

Method: GOMP结合了基于n臂老虎机的交互组件，通过限制非刚性抓取对象到较低维流形来改进模仿学习。

Result: 在四个精确组装任务中运用GOMP，展示了该框架在利用触觉反馈方面的有效性，并保持了模态无关性。

Conclusion: GOMP显著提高了模仿学习在工业组装任务中的精确性，减少了由于错误叠加造成的轨迹不准确性。

Abstract: Imitation Learning (IL) holds great potential for learning repetitive manipulation tasks, such as those in industrial assembly. However, its effectiveness is often limited by insufficient trajectory precision due to compounding errors. In this paper, we introduce Grasped Object Manifold Projection (GOMP), an interactive method that mitigates these errors by constraining a non-rigidly grasped object to a lower-dimensional manifold. GOMP assumes a precise task in which a manipulator holds an object that may shift within the grasp in an observable manner and must be mated with a grounded part. Crucially, all GOMP enhancements are learned from the same expert dataset used to train the base IL policy, and are adjusted with an n-arm bandit-based interactive component. We propose a theoretical basis for GOMP's improvement upon the well-known compounding error bound in IL literature. We demonstrate the framework on four precise assembly tasks using tactile feedback, and note that the approach remains modality-agnostic. Data and videos are available at williamvdb.github.io/GOMPsite.

</details>


### [5] [Surfel-LIO: Fast LiDAR-Inertial Odometry with Pre-computed Surfels and Hierarchical Z-order Voxel Hashing](https://arxiv.org/abs/2512.03397)
*Seungwon Choi,Dong-Gyu Park,Seo-Yeon Hwang,Tae-Wan Kim*

Main category: cs.RO

TL;DR: 该论文提出了一种新的LiDAR-惯性测程（LIO）方法Surfel-LIO，通过采用层次体素结构和预计算的surfels表示，显著提高了效率和速度。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于改善LIO系统在邻近搜索和平面参数重算方面的效率问题。

Method: 本研究提出的Surfel-LIO利用层次体素结构（hVox）和Z-order曲线编码实现O(1)的对应获取，避免了运行时的邻近枚举和平面拟合。

Result: 在M3DGR数据集上的实验结果表明，该方法的处理速度显著快于最近的先进方法，同时维持了相当的状态估计精度。

Conclusion: Surfel-LIO方法在保持精确的状态估计的同时，显著加快了处理速度，展示了在GPS缺失环境下LIO系统的优越性。

Abstract: LiDAR-inertial odometry (LIO) is an active research area, as it enables accurate real-time state estimation in GPS-denied environments. Recent advances in map data structures and spatial indexing have significantly improved the efficiency of LIO systems. Nevertheless, we observe that two aspects may still leave room for improvement: (1) nearest neighbor search often requires examining multiple spatial units to gather sufficient points for plane fitting, and (2) plane parameters are typically recomputed at every iteration despite unchanged map geometry. Motivated by these observations, we propose Surfel-LIO, which employs a hierarchical voxel structure (hVox) with pre-computed surfel representation. This design enables O(1) correspondence retrieval without runtime neighbor enumeration or plane fitting, combined with Z-order curve encoding for cache-friendly spatial indexing. Experimental results on the M3DGR dataset demonstrate that our method achieves significantly faster processing speed compared to recent state-of-the-art methods while maintaining comparable state estimation accuracy. Our implementation is publicly available at https://github.com/93won/lidar_inertial_odometry.

</details>


### [6] [What Is The Best 3D Scene Representation for Robotics? From Geometric to Foundation Models](https://arxiv.org/abs/2512.03422)
*Tianchen Deng,Yue Pan,Shenghai Yuan,Dong Li,Chen Wang,Mingrui Li,Long Chen,Lihua Xie,Danwei Wang,Jingchuan Wang,Javier Civera,Hesheng Wang,Weidong Chen*

Main category: cs.RO

TL;DR: 本文综述了机器人领域中的场景表示方法，包括传统的点云、体素及新兴的神经表示。


<details>
  <summary>Details</summary>
Motivation: 探讨哪种3D场景表示方法最适合机器人，旨在为研究人员提供资源。

Method: 比较不同场景表示方法的优缺点，并将机器人核心模块分为感知、映射、定位、导航和操控五个部分。

Result: 对现有场景表示方法进行全面比较，并讨论未来的发展趋势。

Conclusion: 未来的3D基础模型有潜力成为机器人应用中的统一解决方案，但仍面临一些挑战。

Abstract: In this paper, we provide a comprehensive overview of existing scene representation methods for robotics, covering traditional representations such as point clouds, voxels, signed distance functions (SDF), and scene graphs, as well as more recent neural representations like Neural Radiance Fields (NeRF), 3D Gaussian Splatting (3DGS), and the emerging Foundation Models. While current SLAM and localization systems predominantly rely on sparse representations like point clouds and voxels, dense scene representations are expected to play a critical role in downstream tasks such as navigation and obstacle avoidance. Moreover, neural representations such as NeRF, 3DGS, and foundation models are well-suited for integrating high-level semantic features and language-based priors, enabling more comprehensive 3D scene understanding and embodied intelligence. In this paper, we categorized the core modules of robotics into five parts (Perception, Mapping, Localization, Navigation, Manipulation). We start by presenting the standard formulation of different scene representation methods and comparing the advantages and disadvantages of scene representation across different modules. This survey is centered around the question: What is the best 3D scene representation for robotics? We then discuss the future development trends of 3D scene representations, with a particular focus on how the 3D Foundation Model could replace current methods as the unified solution for future robotic applications. The remaining challenges in fully realizing this model are also explored. We aim to offer a valuable resource for both newcomers and experienced researchers to explore the future of 3D scene representations and their application in robotics. We have published an open-source project on GitHub and will continue to add new works and technologies to this project.

</details>


### [7] [World Models for Autonomous Navigation of Terrestrial Robots from LIDAR Observations](https://arxiv.org/abs/2512.03429)
*Raul Steinmetz,Fabio Demo Rosa,Victor Augusto Kich,Jair Augusto Bottega,Ricardo Bedin Grando,Daniel Fernando Tello Gamarra*

Main category: cs.RO

TL;DR: 提出了一种新的基于DreamerV3的模型驱动强化学习框架，能够更有效地处理高维激光雷达数据，实现高成功率的自主导航。


<details>
  <summary>Details</summary>
Motivation: 应对高维激光雷达数据的处理和模型无关方法的样本效率问题，实现更鲁棒的自主导航能力

Method: 基于DreamerV3算法的模型驱动强化学习框架，结合多层感知器变分自编码器（MLP-VAE）和学习的动态预测器

Result: 在模拟TurtleBot3导航任务中，提出的方法比模型无关基线（如SAC，DDPG和TD3）收敛更快，成功率更高，而DreamerV3代理在360个激光雷达读取数据上取得100%的成功率

Conclusion: 将预测世界模型与学习的潜在表示结合能够有效提升来自高维传感器数据的导航性能，确保了在各个评估环境中的高成功率。

Abstract: Autonomous navigation of terrestrial robots using Reinforcement Learning (RL) from LIDAR observations remains challenging due to the high dimensionality of sensor data and the sample inefficiency of model-free approaches. Conventional policy networks struggle to process full-resolution LIDAR inputs, forcing prior works to rely on simplified observations that reduce spatial awareness and navigation robustness. This paper presents a novel model-based RL framework built on top of the DreamerV3 algorithm, integrating a Multi-Layer Perceptron Variational Autoencoder (MLP-VAE) within a world model to encode high-dimensional LIDAR readings into compact latent representations. These latent features, combined with a learned dynamics predictor, enable efficient imagination-based policy optimization. Experiments on simulated TurtleBot3 navigation tasks demonstrate that the proposed architecture achieves faster convergence and higher success rate compared to model-free baselines such as SAC, DDPG, and TD3. It is worth emphasizing that the DreamerV3-based agent attains a 100% success rate across all evaluated environments when using the full dataset of the Turtlebot3 LIDAR (360 readings), while model-free methods plateaued below 85%. These findings demonstrate that integrating predictive world models with learned latent representations enables more efficient and robust navigation from high-dimensional sensory data.

</details>


### [8] [PerFACT: Motion Policy with LLM-Powered Dataset Synthesis and Fusion Action-Chunking Transformers](https://arxiv.org/abs/2512.03444)
*Davood Soleymanzadeh,Xiao Liang,Minghui Zheng*

Main category: cs.RO

TL;DR: 本研究提出一种新的运动规划框架，通过大型语言模型生成多样工作空间，并引入融合动作块变换器提升规划速度和精度，实验表明相比现有方法，规划速度显著提升。


<details>
  <summary>Details</summary>
Motivation: 提升机器人手臂的运动规划效率，解决现有神经运动规划器在小数据集和单一网络架构下的局限性。

Method: 利用大型语言模型(MotionGeneralizer)进行工作空间生成，并通过Fusion Motion Policy Networks (MpiNetsFusion)提升规划信号编码和多特征模态的关注。

Result: 提出了Motion Policy与通过大型语言模型（LLM）和Fusion Action-Chunking Transformers（PerFACT）驱动的数据集生成方法，从而增强运动规划能力。

Conclusion: MpiNetsFusion 战胜了现有最先进的规划器，在多项任务中展示了更快的规划速度，验证了该方法的有效性。

Abstract: Deep learning methods have significantly enhanced motion planning for robotic manipulators by leveraging prior experiences within planning datasets. However, state-of-the-art neural motion planners are primarily trained on small datasets collected in manually generated workspaces, limiting their generalizability to out-of-distribution scenarios. Additionally, these planners often rely on monolithic network architectures that struggle to encode critical planning information. To address these challenges, we introduce Motion Policy with Dataset Synthesis powered by large language models (LLMs) and Fusion Action-Chunking Transformers (PerFACT), which incorporates two key components. Firstly, a novel LLM-powered workspace generation method, MotionGeneralizer, enables large-scale planning data collection by producing a diverse set of semantically feasible workspaces. Secondly, we introduce Fusion Motion Policy Networks (MpiNetsFusion), a generalist neural motion planner that uses a fusion action-chunking transformer to better encode planning signals and attend to multiple feature modalities. Leveraging MotionGeneralizer, we collect 3.5M trajectories to train and evaluate MpiNetsFusion against state-of-the-art planners, which shows that the proposed MpiNetsFusion can plan several times faster on the evaluated tasks.

</details>


### [9] [MSG-Loc: Multi-Label Likelihood-based Semantic Graph Matching for Object-Level Global Localization](https://arxiv.org/abs/2512.03522)
*Gihyeon Lee,Jungwoo Lee,Juwon Kim,Young-Sik Shin,Younggun Cho*

Main category: cs.RO

TL;DR: 本研究提出了一种多标签似然语义图匹配框架，以提高机器人在高语义歧义环境中的全局定位性能。


<details>
  <summary>Details</summary>
Motivation: 在高语义歧义的环境中，物体的误分类和不正确关联可能导致机器人定位错误，因此需要更有效的全局定位方法。

Method: 提出了一种基于多标签似然的语义图匹配框架，通过图节点的似然性与邻居节点的最大似然性结合进行上下文感知的似然传播。

Result: 利用闭集和开集检测配置对数据关联和位姿估计性能进行评估，表明该方法在大型词汇物体分类中具有良好的扩展性。

Conclusion: 我们的方法通过多标签图匹配框架有效提升了机器人在未知类物体环境中的全局定位精度。

Abstract: Robots are often required to localize in environments with unknown object classes and semantic ambiguity. However, when performing global localization using semantic objects, high semantic ambiguity intensifies object misclassification and increases the likelihood of incorrect associations, which in turn can cause significant errors in the estimated pose. Thus, in this letter, we propose a multi-label likelihood-based semantic graph matching framework for object-level global localization. The key idea is to exploit multi-label graph representations, rather than single-label alternatives, to capture and leverage the inherent semantic context of object observations. Based on these representations, our approach enhances semantic correspondence across graphs by combining the likelihood of each node with the maximum likelihood of its neighbors via context-aware likelihood propagation. For rigorous validation, data association and pose estimation performance are evaluated under both closed-set and open-set detection configurations. In addition, we demonstrate the scalability of our approach to large-vocabulary object categories in both real-world indoor scenes and synthetic environments.

</details>


### [10] [AdaPower: Specializing World Foundation Models for Predictive Manipulation](https://arxiv.org/abs/2512.03538)
*Yuhang Huang,Shilong Zou,Jiazhao Zhang,Xinwang Liu,Ruizhen Hu,Kai Xu*

Main category: cs.RO

TL;DR: AdaPower框架通过两个新颖的组件改善WFM在机器人控制中的应用，取得了显著的任务成功率提升。


<details>
  <summary>Details</summary>
Motivation: 解决WFMs在精准机器人控制应用中的局限性，旨在提升控制精度和利用率。

Method: 采用了时间-空间测试时训练（TS-TTT）和记忆持续性（MP）两个新机制，集成于模型预测控制框架中。

Result: 提出了一种名为AdaPower的轻量级适应框架，用于将通用的世界基础模型（WFM）转变为专门的世界模型，改善了机器人控制中的生成现实和控制精度之间的鸿沟。

Conclusion: AdaPower使预训练的VLAs在LIBERO基准测试中任务成功率提高超过41%，且无需重新训练策略，同时保持计算效率与通用性。

Abstract: World Foundation Models (WFMs) offer remarkable visual dynamics simulation capabilities, yet their application to precise robotic control remains limited by the gap between generative realism and control-oriented precision. While existing approaches use WFMs as synthetic data generators, they suffer from high computational costs and underutilization of pre-trained VLA policies. We introduce \textbf{AdaPower} (\textbf{Ada}pt and Em\textbf{power}), a lightweight adaptation framework that transforms general-purpose WFMs into specialist world models through two novel components: Temporal-Spatial Test-Time Training (TS-TTT) for inference-time adaptation and Memory Persistence (MP) for long-horizon consistency. Integrated within a Model Predictive Control framework, our adapted world model empowers pre-trained VLAs, achieving over 41\% improvement in task success rates on LIBERO benchmarks without policy retraining, while preserving computational efficiency and generalist capabilities.

</details>


### [11] [A Learning-based Control Methodology for Transitioning VTOL UAVs](https://arxiv.org/abs/2512.03548)
*Zexin Lin,Yebin Zhong,Hanwen Wan,Jiu Cheng,Zhenglong Sun,Xiaoqiang Ji*

Main category: cs.RO

TL;DR: 为VTOL无人机过渡控制提出了一种基于强化学习的耦合方法，有效减少振动并提升轨迹跟踪能力。


<details>
  <summary>Details</summary>
Motivation: 解决VTOL无人机在过渡控制中的振动问题及限于现有控制方法的适应性不足。

Method: 基于强化学习的耦合过渡控制方法，应用于VTOL无人机的模拟和真实环境中。

Result: 验证了所提方法在模拟和现实环境中的可行性，实现了高效的控制器开发和迁移，准确控制无人机的位置和姿态。

Conclusion: 提出了一种新颖的基于强化学习的耦合过渡控制方法，有效减少了过渡过程中的振动并提升了轨迹跟踪能力。

Abstract: Transition control poses a critical challenge in Vertical Take-Off and Landing Unmanned Aerial Vehicle (VTOL UAV) development due to the tilting rotor mechanism, which shifts the center of gravity and thrust direction during transitions. Current control methods' decoupled control of altitude and position leads to significant vibration, and limits interaction consideration and adaptability. In this study, we propose a novel coupled transition control methodology based on reinforcement learning (RL) driven controller. Besides, contrasting to the conventional phase-transition approach, the ST3M method demonstrates a new perspective by treating cruise mode as a special case of hover. We validate the feasibility of applying our method in simulation and real-world environments, demonstrating efficient controller development and migration while accurately controlling UAV position and attitude, exhibiting outstanding trajectory tracking and reduced vibrations during the transition process.

</details>


### [12] [RoboScape-R: Unified Reward-Observation World Models for Generalizable Robotics Training via RL](https://arxiv.org/abs/2512.03556)
*Yinzhou Tang,Yu Shang,Yinuo Chen,Bingwen Wei,Xin Zhang,Shu'ang Yu,Liangzhi Shi,Chao Yu,Chen Gao,Wei Wu,Yong Li*

Main category: cs.RO

TL;DR: 本文提出RoboScape-R框架，利用世界模型解决传统RL方法的局限性，显著增强策略的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统的模仿学习和强化学习方法难以实现策略的通用性，尤其在多场景中缺乏统一的奖励信号。

Method: 提出一种名为RoboScape-R的框架，利用世界模型作为强化学习中的通用代理，并引入基于世界模型的奖励机制。

Result: RoboScape-R通过生成内生奖励，有效提升了嵌入式策略的泛化能力，在域外场景下平均性能提高了37.5%。

Conclusion: RoboScape-R有效利用世界模型作为在线训练策略，提供了一个高效且通用的训练环境，显著提升了嵌入式政策的表现。

Abstract: Achieving generalizable embodied policies remains a key challenge. Traditional policy learning paradigms, including both Imitation Learning (IL) and Reinforcement Learning (RL), struggle to cultivate generalizability across diverse scenarios. While IL policies often overfit to specific expert trajectories, RL suffers from the inherent lack of a unified and general reward signal necessary for effective multi-scene generalization. We posit that the world model is uniquely capable of serving as a universal environment proxy to address this limitation. However, current world models primarily focus on their ability to predict observations and still rely on task-specific, handcrafted reward functions, thereby failing to provide a truly general training environment. Toward this problem, we propose RoboScape-R, a framework leveraging the world model to serve as a versatile, general-purpose proxy for the embodied environment within the RL paradigm. We introduce a novel world model-based general reward mechanism that generates ''endogenous'' rewards derived from the model's intrinsic understanding of real-world state transition dynamics. Extensive experiments demonstrate that RoboScape-R effectively addresses the limitations of traditional RL methods by providing an efficient and general training environment that substantially enhances the generalization capability of embodied policies. Our approach offers critical insights into utilizing the world model as an online training strategy and achieves an average 37.5% performance improvement over baselines under out-of-domain scenarios.

</details>


### [13] [Multimodal Control of Manipulators: Coupling Kinematics and Vision for Self-Driving Laboratory Operations](https://arxiv.org/abs/2512.03630)
*Shifa Sulaiman,Amarnath H,Simon Bogh,Naresh Marturi*

Main category: cs.RO

TL;DR: 本文提出了三种基于雅可比方法的运动规划方案，用于控制冗余机械手和夹爪沿预定轨迹运动，并比较不同雅可比逆解方法的优缺点。


<details>
  <summary>Details</summary>
Motivation: 为了实现冗余机械手与夹爪的高效、平滑的运动规划，比较不同的逆解方法以找到最优的解决方案。

Method: 实施基于雅可比法的三种运动规划方案，使用RRT*算法进行轨迹规划，并独立计算雅可比逆解。

Result: 生成的轨迹的平滑度和均方根误差（RMSE）进行了分析，同时评估了关节运动的速度连续性、加速度、颤振和瞬态值。

Conclusion: 通过仿真研究分析了三种雅可比法的优缺点，确定适合特定任务的逆解技术。

Abstract: Motion planning schemes are used for planning motions of a manipulator from an initial pose to a final pose during a task execution. A motion planning scheme generally comprises of a trajectory planning method and an inverse kinematic solver to determine trajectories and joints solutions respectively. In this paper, 3 motion planning schemes developed based on Jacobian methods are implemented to traverse a redundant manipulator with a coupled finger gripper through given trajectories. RRT* algorithm is used for planning trajectories and screw theory based forward kinematic equations are solved for determining joint solutions of the manipulator and gripper. Inverse solutions are computed separately using 3 Jacobian based methods such as Jacobian Transpose (JT), Pseudo Inverse (PI), and Damped Least Square (DLS) methods. Space Jacobian and manipulability measurements of the manipulator and gripper are obtained using screw theory formulations. Smoothness and RMSE error of generated trajectories and velocity continuity, acceleration profile, jerk, and snap values of joint motions are analysed for determining an efficient motion planning method for a given task. Advantages and disadvantages of the proposed motion planning schemes mentioned above are analysed using simulation studies to determine a suitable inverse solution technique for the tasks.

</details>


### [14] [Context-Triggered Contingency Games for Strategic Multi-Agent Interaction](https://arxiv.org/abs/2512.03639)
*Kilian Schweppe,Anne-Kathrin Schmuck*

Main category: cs.RO

TL;DR: 介绍了一种结合时序逻辑和动态应急游戏的双层架构，旨在提高自主多智能体系统的交互效率和可靠性。


<details>
  <summary>Details</summary>
Motivation: 解决自主多智能体系统中长期战略目标与短期动态适应之间的平衡问题，提高智能体之间的交互效率和可靠性。

Method: 使用基于因子图的求解器，结合战略模板，进行动态交互的模型预测控制。

Result: 提出了一种新颖的框架，结合了基于时序逻辑的战略游戏与实时动态应急游戏，旨在提高自主多智能体系统中交互的可靠性与效率，特别是在自动驾驶和机器人导航中取得良好效果。

Conclusion: 框架在动态不确定环境中保证了安全性和进展，通过模拟和硬件实验验证了其有效性。

Abstract: We address the challenge of reliable and efficient interaction in autonomous multi-agent systems, where agents must balance long-term strategic objectives with short-term dynamic adaptation. We propose context-triggered contingency games, a novel integration of strategic games derived from temporal logic specifications with dynamic contingency games solved in real time. Our two-layered architecture leverages strategy templates to guarantee satisfaction of high-level objectives, while a new factor-graph-based solver enables scalable, real-time model predictive control of dynamic interactions. The resulting framework ensures both safety and progress in uncertain, interactive environments. We validate our approach through simulations and hardware experiments in autonomous driving and robotic navigation, demonstrating efficient, reliable, and adaptive multi-agent interaction.

</details>


### [15] [A Novel Approach to Tomato Harvesting Using a Hybrid Gripper with Semantic Segmentation and Keypoint Detection](https://arxiv.org/abs/2512.03684)
*Shahid Ansari,Mahendra Kumar Gohil,Yusuke Maeda,Bishakh Bhattacharya*

Main category: cs.RO

TL;DR: 本论文提出了一种混合型机器人抓手的自主番茄收割系统，结合了软性指头和刚性外骨骼，配备视觉控制管道，实现可靠的收割。


<details>
  <summary>Details</summary>
Motivation: 发展一种自主的番茄收割系统，以提高在复杂环境下的收割效率和准确性。

Method: 采用六个软性助拉手指、伺服驱动的机制、RGB-D摄像机进行感知，以及基于反馈的闭环抓握力调节等技术。

Result: 系统实现了完整的采摘周期，平均周期时间为24.34秒，成功率约为80%。

Conclusion: 所提出的混合抓手和集成视觉控制管道验证了其在复杂环境中的可靠性，具有潜在的农业应用前景。

Abstract: This paper presents an autonomous tomato-harvesting system built around a hybrid robotic gripper that combines six soft auxetic fingers with a rigid exoskeleton and a latex basket to achieve gentle, cage-like grasping. The gripper is driven by a servo-actuated Scotch--yoke mechanism, and includes separator leaves that form a conical frustum for fruit isolation, with an integrated micro-servo cutter for pedicel cutting. For perception, an RGB--D camera and a Detectron2-based pipeline perform semantic segmentation of ripe/unripe tomatoes and keypoint localization of the pedicel and fruit center under occlusion and variable illumination. An analytical model derived using the principle of virtual work relates servo torque to grasp force, enabling design-level reasoning about actuation requirements. During execution, closed-loop grasp-force regulation is achieved using a proportional--integral--derivative controller with feedback from force-sensitive resistors mounted on selected fingers to prevent slip and bruising. Motion execution is supported by Particle Swarm Optimization (PSO)--based trajectory planning for a 5-DOF manipulator. Experiments demonstrate complete picking cycles (approach, separation, cutting, grasping, transport, release) with an average cycle time of 24.34~s and an overall success rate of approximately 80\%, while maintaining low grasp forces (0.20--0.50~N). These results validate the proposed hybrid gripper and integrated vision--control pipeline for reliable harvesting in cluttered environments.

</details>


### [16] [ContactRL: Safe Reinforcement Learning based Motion Planning for Contact based Human Robot Collaboration](https://arxiv.org/abs/2512.03707)
*Sundas Rafat Mulkana,Ronyu Yu,Tanaya Guha,Emma Li*

Main category: cs.RO

TL;DR: ContactRL框架通过强化学习实现了安全的物理接触和高效的人机协作，并在模拟和现实中取得出色的成果。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是确保人机协作中不仅避免碰撞，还要确保安全的、故意的物理接触。

Method: 通过强化学习框架，ContactRL将接触安全直接整合到奖励函数中，并通过动力学能量控制屏障函数增强策略的安全性。

Result: ContactRL是一个基于强化学习的框架，旨在确保人机协作中的安全接触。通过引入接触安全的奖励函数，猫车可以适应性地降低接触力，从而保持任务效率。同时，该框架还结合了控制屏障函数来保障部署安全，并在实际测试中验证了其效能。

Conclusion: ContactRL展示了在接触丰富的任务中，协作机器人可以安全且高效地执行任务，推动了人机协作机器人的应用。

Abstract: In collaborative human-robot tasks, safety requires not only avoiding collisions but also ensuring safe, intentional physical contact. We present ContactRL, a reinforcement learning (RL) based framework that directly incorporates contact safety into the reward function through force feedback. This enables a robot to learn adaptive motion profiles that minimize human-robot contact forces while maintaining task efficiency. In simulation, ContactRL achieves a low safety violation rate of 0.2\% with a high task success rate of 87.7\%, outperforming state-of-the-art constrained RL baselines. In order to guarantee deployment safety, we augment the learned policy with a kinetic energy based Control Barrier Function (eCBF) shield. Real-world experiments on an UR3e robotic platform performing small object handovers from a human hand across 360 trials confirm safe contact, with measured normal forces consistently below 10N. These results demonstrate that ContactRL enables safe and efficient physical collaboration, thereby advancing the deployment of collaborative robots in contact-rich tasks.

</details>


### [17] [Autonomous Planning In-space Assembly Reinforcement-learning free-flYer (APIARY) International Space Station Astrobee Testing](https://arxiv.org/abs/2512.03729)
*Samantha Chapin,Kenneth Stewart,Roxana Leontie,Carl Glen Henshaw*

Main category: cs.RO

TL;DR: 这项研究展示了在国际空间站上使用强化学习控制自由飞行机器人的首次尝试，验证了其在太空应用中的有效性。


<details>
  <summary>Details</summary>
Motivation: 为了在太空探索、物流和实时任务需求中提高机器人的自主性，快速开发和部署定制化行为。

Method: 使用强化学习（RL）控制在零重力环境中的自由飞行机器人，采用Proximal Policy Optimization (PPO)网络进行训练和测试。

Result: 在国际空间站上成功实现了基于RL的首个自由飞行机器人控制实验，验证了RL在提高机器人自主性方面的变革潜力。

Conclusion: 该实验表明，强化学习能够显著提升太空机器人自主性，支撑未来复杂任务的执行。

Abstract: The US Naval Research Laboratory's (NRL's) Autonomous Planning In-space Assembly Reinforcement-learning free-flYer (APIARY) experiment pioneers the use of reinforcement learning (RL) for control of free-flying robots in the zero-gravity (zero-G) environment of space. On Tuesday, May 27th 2025 the APIARY team conducted the first ever, to our knowledge, RL control of a free-flyer in space using the NASA Astrobee robot on-board the International Space Station (ISS). A robust 6-degrees of freedom (DOF) control policy was trained using an actor-critic Proximal Policy Optimization (PPO) network within the NVIDIA Isaac Lab simulation environment, randomizing over goal poses and mass distributions to enhance robustness. This paper details the simulation testing, ground testing, and flight validation of this experiment. This on-orbit demonstration validates the transformative potential of RL for improving robotic autonomy, enabling rapid development and deployment (in minutes to hours) of tailored behaviors for space exploration, logistics, and real-time mission needs.

</details>


### [18] [Crossing the Sim2Real Gap Between Simulation and Ground Testing to Space Deployment of Autonomous Free-flyer Control](https://arxiv.org/abs/2512.03736)
*Kenneth Stewart,Samantha Chapin,Roxana Leontie,Carl Glen Henshaw*

Main category: cs.RO

TL;DR: 本文在国际空间站首次展示了基于强化学习的机器人自主控制，表明了强化学习在空间应用中的潜力和可行性。


<details>
  <summary>Details</summary>
Motivation: 利用强化学习在微重力环境中提高机器人的自主导航能力。

Method: 将深度神经网络训练用于自主控制自由飞行机器人 Astrobee，以替代标准姿态和位移控制。

Result: 首次在国际空间站上成功演示基于RL的Astrobee自由飞行控制，验证了一种新的训练流程，缩小了模拟到现实的差距。

Conclusion: 成功的实验为未来的在轨服务、组装和制造工作提供了基础，使机器人能够迅速适应动态任务需求。

Abstract: Reinforcement learning (RL) offers transformative potential for robotic control in space. We present the first on-orbit demonstration of RL-based autonomous control of a free-flying robot, the NASA Astrobee, aboard the International Space Station (ISS). Using NVIDIA's Omniverse physics simulator and curriculum learning, we trained a deep neural network to replace Astrobee's standard attitude and translation control, enabling it to navigate in microgravity. Our results validate a novel training pipeline that bridges the simulation-to-reality (Sim2Real) gap, utilizing a GPU-accelerated, scientific-grade simulation environment for efficient Monte Carlo RL training. This successful deployment demonstrates the feasibility of training RL policies terrestrially and transferring them to space-based applications. This paves the way for future work in In-Space Servicing, Assembly, and Manufacturing (ISAM), enabling rapid on-orbit adaptation to dynamic mission requirements.

</details>


### [19] [Cross-embodied Co-design for Dexterous Hands](https://arxiv.org/abs/2512.03743)
*Kehlani Fay,Darin Anthony Djapri,Anya Zorin,James Clinton,Ali El Lahib,Hao Su,Michael T. Tolley,Sha Yi,Xiaolong Wang*

Main category: cs.RO

TL;DR: 文章提出了一个共同设计框架，能够快速设计、训练和制造新的机器人手，适用于多种灵巧任务。


<details>
  <summary>Details</summary>
Motivation: 探索如何设计和控制最优的机器人操纵器以实现灵巧任务。

Method: 提出了一个共同设计框架，学习任务特定的手部形态和互补的灵巧控制策略。

Result: 该框架支持扩展的形态搜索空间，能够进行跨身体控制的可扩展评估，并实现现实世界的制造，且在多种灵巧任务中进行了评估。

Conclusion: 该框架能够在24小时内完成机器人手的设计、训练、制造和部署，并将在网站上开源。

Abstract: Dexterous manipulation is limited by both control and design, without consensus as to what makes manipulators best for performing dexterous tasks. This raises a fundamental challenge: how should we design and control robot manipulators that are optimized for dexterity? We present a co-design framework that learns task-specific hand morphology and complementary dexterous control policies. The framework supports 1) an expansive morphology search space including joint, finger, and palm generation, 2) scalable evaluation across the wide design space via morphology-conditioned cross-embodied control, and 3) real-world fabrication with accessible components. We evaluate the approach across multiple dexterous tasks, including in-hand rotation with simulation and real deployment. Our framework enables an end-to-end pipeline that can design, train, fabricate, and deploy a new robotic hand in under 24 hours. The full framework will be open-sourced and available on our website.

</details>


### [20] [Prediction-Driven Motion Planning: Route Integration Strategies in Attention-Based Prediction Models](https://arxiv.org/abs/2512.03756)
*Marlon Steiner,Royden Wagner,Ömer Sahin Tas,Christoph Stiller*

Main category: cs.RO

TL;DR: 本论文提出了一种将运动预测与运动规划结合的新框架，通过传入导航信息来改善自动驾驶汽车与交通参与者之间的交互。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决运动预测在导航目标条件下的稳定性和运动规划的可行性问题，实现多智能体运动预测与目标导向运动规划的桥接。

Method: 本研究通过扩展基于注意力的运动预测模型，将车辆的期望路线和目标位置纳入模型架构中，并在nuPlan数据集上评估不同的集成策略。

Result: 实验结果表明，基于预测驱动的运动规划具有良好的性能，导航信息显著提升了预测和规划任务的效果。

Conclusion: 整合导航信息能够有效提升运动预测和规划的性能，为自动驾驶领域提供新的视角和方法。

Abstract: Combining motion prediction and motion planning offers a promising framework for enhancing interactions between automated vehicles and other traffic participants. However, this introduces challenges in conditioning predictions on navigation goals and ensuring stable, kinematically feasible trajectories. Addressing the former challenge, this paper investigates the extension of attention-based motion prediction models with navigation information. By integrating the ego vehicle's intended route and goal pose into the model architecture, we bridge the gap between multi-agent motion prediction and goal-based motion planning. We propose and evaluate several architectural navigation integration strategies to our model on the nuPlan dataset. Our results demonstrate the potential of prediction-driven motion planning, highlighting how navigation information can enhance both prediction and planning tasks. Our implementation is at: https://github.com/KIT-MRT/future-motion.

</details>


### [21] [Bayesian Optimization for Automatic Tuning of Torque-Level Nonlinear Model Predictive Control](https://arxiv.org/abs/2512.03772)
*Gabriele Fadini,Deepak Ingole,Tong Duy Son,Alisa Rupenyan*

Main category: cs.RO

TL;DR: 本研究提出了一种自调优框架，通过贝叶斯优化提高了机器人模型预测控制的性能，实现了显著的轨迹跟踪改进。


<details>
  <summary>Details</summary>
Motivation: 提高机器人在执行任务时的轨迹跟踪性能，特别是在使用非线性模型预测控制（nMPC）时。

Method: 使用高维贝叶斯优化技术优化模型预测控制器参数，以实现UR10e机器人手臂的最佳关节扭矩指令。

Result: 通过使用数字孪生技术优化的参数相比手动调优，实现了41.9%的跟踪性能提升和2.5%的求解时间缩短；实际实验也显示出25.8%的性能改善。

Conclusion: 数字孪生技术支持的自动化参数优化是提高机器人操作性能的重要因素。

Abstract: This paper presents an auto-tuning framework for torque-based Nonlinear Model Predictive Control (nMPC), where the MPC serves as a real-time controller for optimal joint torque commands. The MPC parameters, including cost function weights and low-level controller gains, are optimized using high-dimensional Bayesian Optimization (BO) techniques, specifically Sparse Axis-Aligned Subspace (SAASBO) with a digital twin (DT) to achieve precise end-effector trajectory real-time tracking on an UR10e robot arm. The simulation model allows efficient exploration of the high-dimensional parameter space, and it ensures safe transfer to hardware. Our simulation results demonstrate significant improvements in tracking performance (+41.9%) and reduction in solve times (-2.5%) compared to manually-tuned parameters. Moreover, experimental validation on the real robot follows the trend (with a +25.8% improvement), emphasizing the importance of digital twin-enabled automated parameter optimization for robotic operations.

</details>


### [22] [Safety Reinforced Model Predictive Control (SRMPC): Improving MPC with Reinforcement Learning for Motion Planning in Autonomous Driving](https://arxiv.org/abs/2512.03774)
*Johannes Fischer,Marlon Steiner,Ömer Sahin Tas,Christoph Stiller*

Main category: cs.RO

TL;DR: 结合安全强化学习与模型预测控制，提高自动驾驶中的运动规划安全性和性能。


<details>
  <summary>Details</summary>
Motivation: 现有的模型预测控制（MPC）在自动驾驶中的运动规划应用受限于凸近似，无法寻找全局最优解。

Method: 采用安全强化学习（SRL）和约束强化学习（CRL），引入手工设计的能量函数作为安全约束，以解决CRL问题。

Result: 提出结合安全强化学习（SRL）与MPC，利用新的安全参考轨迹改善运动规划。

Conclusion: 实验结果表明，该方法在安全性和性能方面优于传统的MPC和SRL。

Abstract: Model predictive control (MPC) is widely used for motion planning, particularly in autonomous driving. Real-time capability of the planner requires utilizing convex approximation of optimal control problems (OCPs) for the planner. However, such approximations confine the solution to a subspace, which might not contain the global optimum. To address this, we propose using safe reinforcement learning (SRL) to obtain a new and safe reference trajectory within MPC. By employing a learning-based approach, the MPC can explore solutions beyond the close neighborhood of the previous one, potentially finding global optima. We incorporate constrained reinforcement learning (CRL) to ensure safety in automated driving, using a handcrafted energy function-based safety index as the constraint objective to model safe and unsafe regions. Our approach utilizes a state-dependent Lagrangian multiplier, learned concurrently with the safe policy, to solve the CRL problem. Through experimentation in a highway scenario, we demonstrate the superiority of our approach over both MPC and SRL in terms of safety and performance measures.

</details>


### [23] [MPCFormer: A physics-informed data-driven approach for explainable socially-aware autonomous driving](https://arxiv.org/abs/2512.03795)
*Jia Hu,Zhexi Lian,Xuerun Yan,Ruiang Bi,Dou Shen,Yu Ruan,Haoran Wang*

Main category: cs.RO

TL;DR: MPCFormer是一个基于物理与数据的社会交互动态建模的自动驾驶方法，能够生成更符合人类行为的交互，并在多项指标上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 提高自动驾驶车辆在动态交通场景中的人类行为表现，尤其是在与周围车辆的交互方面。

Method: MPCFormer，一种具有物理知识和数据驱动的社会交互动态建模的自动驾驶方法。

Result: MPCFormer在NGSIM数据集上的开环评估显示，轨迹预测误差最低，ADE为0.86米。闭环实验中，规划成功率为94.67%，驾驶效率提高15.75%，碰撞率从21.25%降至0.5%。

Conclusion: MPCFormer通过显式建模多车辆社会交互的动态，显著提高了自动驾驶车辆在复杂交通场景中的表现，降低了安全风险。

Abstract: Autonomous Driving (AD) vehicles still struggle to exhibit human-like behavior in highly dynamic and interactive traffic scenarios. The key challenge lies in AD's limited ability to interact with surrounding vehicles, largely due to a lack of understanding the underlying mechanisms of social interaction. To address this issue, we introduce MPCFormer, an explainable socially-aware autonomous driving approach with physics-informed and data-driven coupled social interaction dynamics. In this model, the dynamics are formulated into a discrete space-state representation, which embeds physics priors to enhance modeling explainability. The dynamics coefficients are learned from naturalistic driving data via a Transformer-based encoder-decoder architecture. To the best of our knowledge, MPCFormer is the first approach to explicitly model the dynamics of multi-vehicle social interactions. The learned social interaction dynamics enable the planner to generate manifold, human-like behaviors when interacting with surrounding traffic. By leveraging the MPC framework, the approach mitigates the potential safety risks typically associated with purely learning-based methods. Open-looped evaluation on NGSIM dataset demonstrates that MPCFormer achieves superior social interaction awareness, yielding the lowest trajectory prediction errors compared with other state-of-the-art approach. The prediction achieves an ADE as low as 0.86 m over a long prediction horizon of 5 seconds. Close-looped experiments in highly intense interaction scenarios, where consecutive lane changes are required to exit an off-ramp, further validate the effectiveness of MPCFormer. Results show that MPCFormer achieves the highest planning success rate of 94.67%, improves driving efficiency by 15.75%, and reduces the collision rate from 21.25% to 0.5%, outperforming a frontier Reinforcement Learning (RL) based planner.

</details>


### [24] [IM HERE: Interaction Model for Human Effort Based Robot Engagement](https://arxiv.org/abs/2512.03828)
*Dominykas Strazdas,Magnus Jung,Jan Marquenie,Ingo Siegert,Ayoub Al-Hamadi*

Main category: cs.RO

TL;DR: IM HERE是一个新框架，用于建模人类和机器人互动中的参与度，强调双边关系和社会行为。


<details>
  <summary>Details</summary>
Motivation: 目前关于参与度的定义和模型存在模糊性，无法广泛应用于各种场景，因此需要一个有效的框架来解决这一问题.

Method: 采用基于努力的描述，分析不同实体间的双边关系，重点关注参与度和四个关键状态。

Result: 本研究提出了IM HERE框架，旨在有效建模人类与机器人间的互动中的参与度。

Conclusion: IM HERE框架为自主系统提供了遵循社会规范的明确指令，有助于它们实现社会整合并追求自身目标。

Abstract: The effectiveness of human-robot interaction often hinges on the ability to cultivate engagement - a dynamic process of cognitive involvement that supports meaningful exchanges. Many existing definitions and models of engagement are either too vague or lack the ability to generalize across different contexts. We introduce IM HERE, a novel framework that models engagement effectively in human-human, human-robot, and robot-robot interactions. By employing an effort-based description of bilateral relationships between entities, we provide an accurate breakdown of relationship patterns, simplifying them to focus placement and four key states. This framework captures mutual relationships, group behaviors, and actions conforming to social norms, translating them into specific directives for autonomous systems. By integrating both subjective perceptions and objective states, the model precisely identifies and describes miscommunication. The primary objective of this paper is to automate the analysis, modeling, and description of social behavior, and to determine how autonomous systems can behave in accordance with social norms for full social integration while simultaneously pursuing their own social goals.

</details>


### [25] [OmniDexVLG: Learning Dexterous Grasp Generation from Vision Language Model-Guided Grasp Semantics, Taxonomy and Functional Affordance](https://arxiv.org/abs/2512.03874)
*Lei Zhang,Diwen Zheng,Kaixin Bai,Zhenshan Bing,Zoltan-Csaba Marton,Zhaopeng Chen,Alois Christian Knoll,Jianwei Zhang*

Main category: cs.RO

TL;DR: OmniDexVLG是一个新型的语义感知抓取生成框架，能够根据自然语言指令生成多样化且一致的灵巧抓取。


<details>
  <summary>Details</summary>
Motivation: 实现语义可控的灵巧抓取合成由于缺乏多语义维度的统一建模而面临挑战，如抓取分类、接触语义和功能赋权。

Method: 该框架通过OmniDexDataGen生成语义丰富的抓取数据集，并引入OmniDexReasoner进行多模态语义推理，最终构建了一个统一的视觉语言抓取生成模型。

Result: 提交了一个多模态、语义感知的抓取生成框架OmniDexVLG，能够在语言和视觉指导下生成结构多样且语义一致的灵巧抓取。

Conclusion: 大量实验证明，该方法在抓取多样性、接触语义多样性、功能赋权多样性和语义一致性方面显著优于现有方法。

Abstract: Dexterous grasp generation aims to produce grasp poses that align with task requirements and human interpretable grasp semantics. However, achieving semantically controllable dexterous grasp synthesis remains highly challenging due to the lack of unified modeling of multiple semantic dimensions, including grasp taxonomy, contact semantics, and functional affordance. To address these limitations, we present OmniDexVLG, a multimodal, semantics aware grasp generation framework capable of producing structurally diverse and semantically coherent dexterous grasps under joint language and visual guidance. Our approach begins with OmniDexDataGen, a semantic rich dexterous grasp dataset generation pipeline that integrates grasp taxonomy guided configuration sampling, functional affordance contact point sampling, taxonomy aware differential force closure grasp sampling, and physics based optimization and validation, enabling systematic coverage of diverse grasp types. We further introduce OmniDexReasoner, a multimodal grasp type semantic reasoning module that leverages multi agent collaboration, retrieval augmented generation, and chain of thought reasoning to infer grasp related semantics and generate high quality annotations that align language instructions with task specific grasp intent. Building upon these components, we develop a unified Vision Language Grasping generation model that explicitly incorporates grasp taxonomy, contact structure, and functional affordance semantics, enabling fine grained control over grasp synthesis from natural language instructions. Extensive experiments in simulation and real world object grasping and ablation studies demonstrate that our method substantially outperforms state of the art approaches in terms of grasp diversity, contact semantic diversity, functional affordance diversity, and semantic consistency.

</details>


### [26] [A Modular Architecture Design for Autonomous Driving Racing in Controlled Environments](https://arxiv.org/abs/2512.03886)
*Brais Fontan-Costas,M. Diaz-Cacho,Ruben Fernandez-Boullon,Manuel Alonso-Carracedo,Javier Perez-Robles*

Main category: cs.RO

TL;DR: 本文提出了一种用于封闭电路车辆的自主系统架构，集成多种技术实现精确导航和控制。


<details>
  <summary>Details</summary>
Motivation: 研究旨在提升车辆在封闭电路中的自主导航能力，以实现精确任务执行。

Method: 采用计算机视觉、定位和地图绘制、路径规划以及控制等子系统进行操作。

Result: 通过先进的技术组合，该系统能够在受控环境中实现实时自主导航。

Conclusion: 该研究提出了一种模块化的自主系统架构，能够实现精确的车辆控制和实时导航。

Abstract: This paper presents an Autonomous System (AS) architecture for vehicles in a closed circuit. The AS performs precision tasks including computer vision for environment perception, positioning and mapping for accurate localization, path planning for optimal trajectory generation, and control for precise vehicle actuation. Each subsystem operates independently while connecting data through a cohesive pipeline architecture. The system implements a modular design that combines state-of-the-art technologies for real-time autonomous navigation in controlled environments.

</details>


### [27] [Digital Twin-based Control Co-Design of Full Vehicle Active Suspensions via Deep Reinforcement Learning](https://arxiv.org/abs/2512.03891)
*Ying-Kuan Tsai,Yi-Ping Chen,Vispi Karkaria,Wei Chen*

Main category: cs.RO

TL;DR: 提出了一个基于数字双胞胎的控制协同设计框架，通过深度强化学习在不确定环境中优化全车主动悬挂系统。


<details>
  <summary>Details</summary>
Motivation: 提升车辆舒适性、安全性和稳定性，同时克服固定硬件设计和控制策略的限制。

Method: DT-based control co-design (CCD) framework for active suspensions

Result: 优化的悬挂系统在两种驾驶条件下（温和和激进）实现了更平稳的行驶轨迹，并将控制努力分别减少约43%和52%。

Conclusion: 该框架为全车主动悬挂系统的优化提供了一种新方法，结合了DRL和不确定性感知模型更新，有助于在变化的驾驶行为和环境条件下实现个性化优化。

Abstract: Active suspension systems are critical for enhancing vehicle comfort, safety, and stability, yet their performance is often limited by fixed hardware designs and control strategies that cannot adapt to uncertain and dynamic operating conditions. Recent advances in digital twins (DTs) and deep reinforcement learning (DRL) offer new opportunities for real-time, data-driven optimization across a vehicle's lifecycle. However, integrating these technologies into a unified framework remains an open challenge. This work presents a DT-based control co-design (CCD) framework for full-vehicle active suspensions using multi-generation design concepts. By integrating automatic differentiation into DRL, we jointly optimize physical suspension components and control policies under varying driver behaviors and environmental uncertainties. DRL also addresses the challenge of partial observability, where only limited states can be sensed and fed back to the controller, by learning optimal control actions directly from available sensor information. The framework incorporates model updating with quantile learning to capture data uncertainty, enabling real-time decision-making and adaptive learning from digital-physical interactions. The approach demonstrates personalized optimization of suspension systems under two distinct driving settings (mild and aggressive). Results show that the optimized systems achieve smoother trajectories and reduce control efforts by approximately 43% and 52% for mild and aggressive, respectively, while maintaining ride comfort and stability. Contributions include: developing a DT-enabled CCD framework integrating DRL and uncertainty-aware model updating for full-vehicle active suspensions, introducing a multi-generation design strategy for self-improving systems, and demonstrating personalized optimization of active suspension systems for distinct driver types.

</details>


### [28] [Autonomous Reinforcement Learning Robot Control with Intel's Loihi 2 Neuromorphic Hardware](https://arxiv.org/abs/2512.03911)
*Kenneth Stewart,Roxana Leontie,Samantha Chapin,Joe Hays,Sumit Bam Shrestha,Carl Glen Henshaw*

Main category: cs.RO

TL;DR: 本文介绍了一种将强化学习训练的ANN转化为适用于神经形态硬件SDNN的端到端流程，展示在Astrobee机器人上的应用，提升了能效和实时性。


<details>
  <summary>Details</summary>
Motivation: 探讨如何将强化学习训练的人工神经网络有效地部署到神经形态硬件上，以实现低延迟和高能效的推理操作。

Method: 通过将在模拟中训练的ANN政策转化为脉冲Sigma-Delta神经网络，部署于Intel Loihi 2上，并在NVIDIA的Omniverse Isaac Lab环境中进行闭环控制评估。

Result: 成功将训练的ANN政策转化为兼容Intel Loihi 2架构的脉冲Sigma-Delta神经网络，并在模拟环境中验证了其执行性能。

Conclusion: 研究结果显示，利用神经形态平台进行机器人控制是可行的，为未来的空间与地面机器人应用提供了能效高、实时的神经形态计算路径。

Abstract: We present an end-to-end pipeline for deploying reinforcement learning (RL) trained Artificial Neural Networks (ANNs) on neuromorphic hardware by converting them into spiking Sigma-Delta Neural Networks (SDNNs). We demonstrate that an ANN policy trained entirely in simulation can be transformed into an SDNN compatible with Intel's Loihi 2 architecture, enabling low-latency and energy-efficient inference. As a test case, we use an RL policy for controlling the Astrobee free-flying robot, similar to a previously hardware in space-validated controller. The policy, trained with Rectified Linear Units (ReLUs), is converted to an SDNN and deployed on Intel's Loihi 2, then evaluated in NVIDIA's Omniverse Isaac Lab simulation environment for closed-loop control of Astrobee's motion. We compare execution performance between GPU and Loihi 2. The results highlight the feasibility of using neuromorphic platforms for robotic control and establish a pathway toward energy-efficient, real-time neuromorphic computation in future space and terrestrial robotics applications.

</details>


### [29] [Hierarchical Vision Language Action Model Using Success and Failure Demonstrations](https://arxiv.org/abs/2512.03913)
*Jeongeun Park,Jihwan Yoon,Byungwoo Jeon,Juhan Park,Jinwoo Shin,Namhoon Cho,Kyungjae Lee,Sangdoo Yun,Sungjoon Choi*

Main category: cs.RO

TL;DR: VINE是一个层次化的视觉-语言-动作模型，利用失败数据提升规划和执行过程的鲁棒性。在层次化强化学习框架下，它将高层推理与低层控制分离，通过对数据集中的成功与失败进行充分利用，显著提升了机器人在复杂操作任务中的成功率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 利用失败示例中的信息来改善视觉-语言-动作模型的脆弱性，从而提升系统的鲁棒性。

Method: 该模型在层次化强化学习框架下运作，高层进行可行性引导的树搜索，结合成功与失败的概率预测，低层则执行具体动作。

Result: 在复杂的操作任务中，通过引入失败数据，VINE模型显著提升了成功率和鲁棒性。

Conclusion: 通过有效利用失败数据，VINE展示了在复杂操作任务中提升成功率和鲁棒性的潜力，证明了失败信息的价值。

Abstract: Prior Vision-Language-Action (VLA) models are typically trained on teleoperated successful demonstrations, while discarding numerous failed attempts that occur naturally during data collection. However, these failures encode where and how policies can be fragile, information that can be exploited to improve robustness. We address this problem by leveraging mixed-quality datasets to learn failure-aware reasoning at planning time. We introduce VINE, a hierarchical vision-language-action model that separates high-level reasoning (System 2) from low-level control (System 1) under a hierarchical reinforcement learning formalism, making failures usable as a structured learning signal rather than noisy supervision. System 2 performs feasibility-guided tree search over a 2D scene-graph abstraction: it proposes subgoal transitions, predicts success probabilities from both successes and failures, and prunes brittle branches before execution, effectively casting plan evaluation as feasibility scoring. The selected subgoal sequence is then passed to System 1, which executes low-level actions without modifying the agent's core skills. Trained entirely from offline teleoperation data, VINE integrates negative experience directly into the decision loop. Across challenging manipulation tasks, this approach consistently improves success rates and robustness, demonstrating that failure data is an essential resource for converting the broad competence of VLAs into robust execution.

</details>


### [30] [Driving is a Game: Combining Planning and Prediction with Bayesian Iterative Best Response](https://arxiv.org/abs/2512.03936)
*Aron Distelzweig,Yiwei Wang,Faris Janjoš,Marcel Hallgarten,Mihai Dobre,Alexander Langmann,Joschka Boedecker,Johannes Betz*

Main category: cs.RO

TL;DR: 本研究提出了一种新的自主驾驶规划框架BIBeR，结合了运动预测和博弈理论规划，显著提高了在复杂城市交通场景中的表现。


<details>
  <summary>Details</summary>
Motivation: 当前自主驾驶系统在密集城市交通中面临挑战，尤其是在变化车道和合并过程中，需要更好地预测和影响其他交通参与者。

Method: BIBeR通过将先进的运动预测器整合进一个迭代最佳响应循环中，反复优化自我车辆及周围代理的策略。

Result: 实验表明，BIBeR在高度互动的车道变换场景上比最先进的规划者提高了11%的性能，并且在nuPlan基准上也表现优越。

Conclusion: BIBeR框架在高度互动的交通场景中展示了优越的性能，提升了自主驾驶系统的决策能力。

Abstract: Autonomous driving planning systems perform nearly perfectly in routine scenarios using lightweight, rule-based methods but still struggle in dense urban traffic, where lane changes and merges require anticipating and influencing other agents. Modern motion predictors offer highly accurate forecasts, yet their integration into planning is mostly rudimental: discarding unsafe plans. Similarly, end-to-end models offer a one-way integration that avoids the challenges of joint prediction and planning modeling under uncertainty. In contrast, game-theoretic formulations offer a principled alternative but have seen limited adoption in autonomous driving. We present Bayesian Iterative Best Response (BIBeR), a framework that unifies motion prediction and game-theoretic planning into a single interaction-aware process. BIBeR is the first to integrate a state-of-the-art predictor into an Iterative Best Response (IBR) loop, repeatedly refining the strategies of the ego vehicle and surrounding agents. This repeated best-response process approximates a Nash equilibrium, enabling bidirectional adaptation where the ego both reacts to and shapes the behavior of others. In addition, our proposed Bayesian confidence estimation quantifies prediction reliability and modulates update strength, more conservative under low confidence and more decisive under high confidence. BIBeR is compatible with modern predictors and planners, combining the transparency of structured planning with the flexibility of learned models. Experiments show that BIBeR achieves an 11% improvement over state-of-the-art planners on highly interactive interPlan lane-change scenarios, while also outperforming existing approaches on standard nuPlan benchmarks.

</details>


### [31] [MDE-AgriVLN: Agricultural Vision-and-Language Navigation with Monocular Depth Estimation](https://arxiv.org/abs/2512.03958)
*Xiaobei Zhao,Xingqi Lyu,Xiang Li*

Main category: cs.RO

TL;DR: 本研究提出了MDE-AgriVLN方法，通过单目深度估计增强农业机器人在自然语言指令下的导航能力，显著提高性能。


<details>
  <summary>Details</summary>
Motivation: 农业机器人在各种农业任务中发挥着重要作用，但仍然依赖人工操作或铁路系统进行移动。

Method: 提出了一种农业视觉与语言导航方法，结合单目深度估计模块，从RGB图像生成深度特征。

Result: MDE-AgriVLN方法在A2A基准测试中成功将成功率从0.23提高到0.32，导航误差从4.43米降低到4.08米。

Conclusion: 该方法在农业视觉-语言导航领域展示了最先进的性能，推动了农业机器人的发展。

Abstract: Agricultural robots are serving as powerful assistants across a wide range of agricultural tasks, nevertheless, still heavily relying on manual operations or railway systems for movement. The AgriVLN method and the A2A benchmark pioneeringly extend Vision-and-Language Navigation (VLN) to the agricultural domain, enabling a robot to navigate to a target position following a natural language instruction. Unlike human binocular vision, most agricultural robots are only given a single camera for monocular vision, which results in limited spatial perception. To bridge this gap, we present the method of Agricultural Vision-and-Language Navigation with Monocular Depth Estimation (MDE-AgriVLN), in which we propose the MDE module generating depth features from RGB images, to assist the decision-maker on reasoning. When evaluated on the A2A benchmark, our MDE-AgriVLN method successfully increases Success Rate from 0.23 to 0.32 and decreases Navigation Error from 4.43m to 4.08m, demonstrating the state-of-the-art performance in the agricultural VLN domain. Code: https://github.com/AlexTraveling/MDE-AgriVLN.

</details>


### [32] [Artificial Microsaccade Compensation: Stable Vision for an Ornithopter](https://arxiv.org/abs/2512.03995)
*Levi Burner,Guido de Croon,Yiannis Aloimonos*

Main category: cs.RO

TL;DR: 本研究开发了一种新的视频稳定技术，能有效补偿高速震动导致的抖动，实时处理，效果优于现有软件。


<details>
  <summary>Details</summary>
Motivation: 受动物微颤动现象启发，我们希望改善视频稳定性，尤其是在高速震动环境下。

Method: 通过优化SO(3)表示的3D旋转，最小化图像强度变化，实现实时稳定视频。

Result: 发展了一种新的“人工微颤动补偿”方法，能实现实时视频稳定处理，效果超越当前最佳商业软件。

Conclusion: 该方法在定向稳定视频，同时能够处理偶尔的快速运动，显著降低帧间运动，效果理想。

Abstract: Animals with foveated vision, including humans, experience microsaccades, small, rapid eye movements that they are not aware of. Inspired by this phenomenon, we develop a method for "Artificial Microsaccade Compensation". It can stabilize video captured by a tailless ornithopter that has resisted attempts to use camera-based sensing because it shakes at 12-20 Hz. Our approach minimizes changes in image intensity by optimizing over 3D rotation represented in SO(3). This results in a stabilized video, computed in real time, suitable for human viewing, and free from distortion. When adapted to hold a fixed viewing orientation, up to occasional saccades, it can dramatically reduce inter-frame motion while also benefiting from an efficient recursive update. When compared to Adobe Premier Pro's warp stabilizer, which is widely regarded as the best commercial video stabilization software available, our method achieves higher quality results while also running in real time.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [33] [Smartphone Vibrometric Force Estimation for Grip Related Strength Measurements](https://arxiv.org/abs/2512.03186)
*Colin Barry,Edward Jay Wang*

Main category: cs.HC

TL;DR: 本研究提出了一种利用智能手机内置传感器估算握力的新方法，显示了智能手机在功能健康评估中的可行性。


<details>
  <summary>Details</summary>
Motivation: 握力是与移动性、虚弱、手术结果及整体健康相关的重要临床生物标志物，研究旨在探索一种便捷的手机估算握力的方法。

Method: 利用智能手机的振动电机和惯性测量单元，通过振动来调节高频加速度计和陀螺仪信号的幅度，实现握力估算。

Result: 在15折交叉验证中，绝对劲力量测量的平均绝对误差为1.88磅，相对劲力量测量的平均误差为10.1%。

Conclusion: 虽然所测量的是捏握力，而非标准的全掌握力，但此方法展示了使用智能手机进行力量评估的潜力。

Abstract: Hand grip strength is a widely used clinical biomarker linked to mobility, frailty, surgical outcomes, and overall health. This work explores a novel, phone only approach for estimating grip related force using a smartphone's built in vibration motor and inertial measurement unit. When the phone vibrates, applied finger force modulates the amplitude of high frequency accelerometer and gyroscope signals through Vibrometric Force Estimation. We profiled a Google Pixel 4 using synchronized IMU data and ground truth force measurements across varied force trajectories, then trained ridge regression models for both absolute and relative force prediction. In 15 fold hold one out validation, absolute force estimation achieved a mean absolute error of 1.88 lbs, while relative force estimation achieved a mean error of 10.1%. Although the method captures pinch type force rather than standardized full hand HGS, the results demonstrate the feasibility of smartphone based strength assessment using only on device sensors. This approach may enable large scale, low burden functional health measurements once profiling is completed for major smartphone models.

</details>


### [34] [DAWZY: A New Addition to AI powered "Human in the Loop" Music Co-creation](https://arxiv.org/abs/2512.03289)
*Aaron C Elkins,Sanchit Singh,Adrian Kieback,Sawyer Blankenship,Uyiosa Philip Amadasun,Aman Chadha*

Main category: cs.HC

TL;DR: DAWZY是一个开源助手，通过自然语言将请求转化为REAPER中的可逆动作，提升了DAW的创作体验。


<details>
  <summary>Details</summary>
Motivation: 解决高层意图与低层编辑之间的映射难题，减少用户对复杂界面的熟悉时间。

Method: 使用基于语言模型的代码生成和模型上下文协议工具实现自然语言请求的可逆动作。

Result: DAWZY在常见生产任务中表现可靠，用户在可用性、控制性、学习性、协作性和乐趣上给予积极评价。

Conclusion: DAWZY有效提升了数字音频工作站 (DAW) 的创作效率，用户评价积极。

Abstract: Digital Audio Workstations (DAWs) offer fine control, but mapping high-level intent (e.g., "warm the vocals") to low-level edits breaks creative flow. Existing artificial intelligence (AI) music generators are typically one-shot, limiting opportunities for iterative development and human contribution. We present DAWZY, an open-source assistant that turns natural-language (text/voice/hum) requests into reversible actions in REAPER. DAWZY keeps the DAW as the creative hub with a minimal GUI and voice-first interface. DAWZY uses LLM-based code generation as a novel way to significantly reduce the time users spend familiarizing themselves with large interfaces, replacing hundreds of buttons and drop-downs with a chat box. DAWZY also uses three Model Context Protocol tools for live state queries, parameter adjustment, and AI beat generation. It maintains grounding by refreshing state before mutation and ensures safety and reversibility with atomic scripts and undo. In evaluations, DAWZY performed reliably on common production tasks and was rated positively by users across Usability, Control, Learning, Collaboration, and Enjoyment.

</details>


### [35] [Teacher, But Also Student: Challenges and Tech Needs of Adult Braille Learners with Sight](https://arxiv.org/abs/2512.03398)
*Quan Zhou,Cameron Cassidy,Alyson Yin,Stacy Branham*

Main category: cs.HC

TL;DR: 本研究关注成人视觉障碍教师学习盲文的挑战，通过访谈揭示了他们面临的缺乏接触和练习时间的问题，并指出设计有效学习工具的必要性。


<details>
  <summary>Details</summary>
Motivation: 强调盲文读写能力对盲人独立和生活质量的重要性，并指出看似被忽视的成人盲文学习者的需求。

Method: 通过对14名接受过盲文培训的教育工作者进行访谈，探讨他们的学习经历和挑战。

Result: 研究发现，这些教师在学习盲文时，缺乏一致的盲文接触、有限的练习时间，并希望找到有趣且高效的学习工具。

Conclusion: 本研究揭示了成人视觉障碍教师学习盲文的挑战，并指出了设计有效学习工具的机会。

Abstract: Braille literacy is critical for blind individuals' independence and quality of life, yet literacy rates continue to decline. Though braille instructors in integrated K-12 classrooms play a central role in literacy development in blind youth, prior research on braille learning almost exclusively focuses on blind adolescent students. As a result, we still know little about how sighted adult teachers learn braille. To address this, we interviewed 14 educators, including 13 certificated Teachers of Students with Visual Impairments (TVIs) and 1 paraeducator, who learned braille as adults. We found that they: (1) lack consistent braille exposure to reinforce knowledge and skill; (2) have limited time to practice due to myriad responsibilities of adulthood; and thus, (3) seek learning tools that are engaging and efficient. Our research draws attention to the needs of a group of braille learners who have been overlooked and identifies new design opportunities to facilitate braille literacy.

</details>


### [36] [Why Some Seek AI, Others Seek Therapists: Mental Health in the Age of Generative AI](https://arxiv.org/abs/2512.03406)
*Junsang Park,Sarah Brown,Sharon Lynn Chu*

Main category: cs.HC

TL;DR: 本研究探讨心理健康领域中个体对GAI和治疗师的使用意图，发现情感利益和个性化是使用GAI的关键因素，采用模式因群体而异。


<details>
  <summary>Details</summary>
Motivation: 探讨在心理健康领域中，个体如何平衡使用生成性人工智能工具与人类治疗师。

Method: 通过对大学样本(N=1,155)和全国代表性成人样本(N=651)的研究，采用重复测量ANOVA和LASSO回归分析。

Result: 研究发现，治疗师在情感、关系和个性化利益方面受到重视，而GAI在可获取性和经济性上更具优势。

Conclusion: 研究扩展了健康信念模型(HBM)在多模态背景下的应用，强调了设计可信、情感共鸣的数字心理健康工具的意义。

Abstract: As generative artificial intelligence (GAI) enters the mental health landscape, questions arise about how individuals weigh AI tools against human therapists. Drawing on the Health Belief Model (HBM), this study examined belief-based predictors of intention to use GAI and therapists across two populations: a university sample (N = 1,155) and a nationally representative adult sample (N = 651). Using repeated-measures ANOVA and LASSO regression, we found that therapists were consistently valued for emotional, relational, and personalization benefits, while GAI was favored for accessibility and affordability. Yet structural advantages alone did not predict adoption; emotional benefit and personalization emerged as decisive factors. Adoption patterns diverged across groups: students treated GAI as a complement, whereas national adults approached it as a substitute. Concerns about privacy and reliability constrained GAI use in both groups. These findings extend HBM to multi-modality contexts and highlight design implications for trustworthy, emotionally resonant digital mental health tools.

</details>


### [37] [CellScout: Visual Analytics for Mining Biomarkers in Cell State Discovery](https://arxiv.org/abs/2512.03485)
*Rui Sheng,Zelin Zang,Jiachen Wang,Yan Luo,Zixin Chen,Yan Zhou,Shaolun Ruan,Huamin Qu*

Main category: cs.HC

TL;DR: 本论文设计了一种机器学习算法和一个视觉分析系统以帮助生物学家有效发现细胞状态及其生物标志物。


<details>
  <summary>Details</summary>
Motivation: 细胞状态的发现对理解生物系统和改善医疗结果至关重要，而识别特定细胞状态的独特生物标志物是这一过程的关键。

Method: 首先设计了一种基于Mixture-of-Experts的机器学习算法，然后开发了名为CellScout的视觉分析系统。

Result: 通过设计基于Mixture-of-Experts技术的机器学习算法和开发名为CellScout的视觉分析系统，我们成功地揭示了细胞群体和生物标志物之间的关联关系，并验证了系统的有效性。

Conclusion: 研究表明，CellScout系统在发现新的细胞状态方面有效，并能帮助生物学家探索和细化细胞群体与生物标志物之间的关联关系。

Abstract: Cell state discovery is crucial for understanding biological systems and enhancing medical outcomes. A key aspect of this process is identifying distinct biomarkers that define specific cell states. However, difficulties arise from the co-discovery process of cell states and biomarkers: biologists often use dimensionality reduction to visualize cells in a two- dimensional space. Then they usually interpret visually clustered cells as distinct states, from which they seek to identify unique biomarkers. However, this assumption is often invalid due to internal inconsistencies in a cluster, making the process trial-and-error and highly uncertain. Therefore, biologists urgently need effective tools to help uncover the hidden association relationships between different cell populations and their potential biomarkers. To address this problem, we first designed a machine-learning algorithm based on the Mixture-of-Experts (MoE) technique to identify meaningful associations between cell populations and biomarkers. We further developed a visual analytics system, CellScout, in collaboration with biologists, to help them explore and refine these association relationships to advance cell state discovery. We validated our system through expert interviews, from which we further selected a representative case to demonstrate its effectiveness in discovering new cell states.

</details>


### [38] [EMINDS: Understanding User Behavior Progression for Mental Health Exploration on Social Media](https://arxiv.org/abs/2512.03495)
*Rui Sheng,Yifang Wang,Xingbo Wang,Shun Dai,Qingyu Guo,Tai-Quan Peng,Huamin Qu,Dongyu Liu*

Main category: cs.HC

TL;DR: 本论文介绍了EMINDS，一个用于分析在线心理健康社区用户行为的可视化分析系统，旨在识别不同行为阶段及其对心理健康的影响。


<details>
  <summary>Details</summary>
Motivation: 针对心理健康日益严重的社会问题，研究人员希望通过在线心理健康社区的数据分析实现早期干预。

Method: 建立了一个新的自动挖掘流程，利用交互式可视化展示和Sankey图表来分析用户行为变化和阶段模式的长期影响。

Result: 提出了EMINDS，一个新的可视分析系统，能够提取不同行为阶段并评估行为模式对心理健康的潜在长期影响。

Conclusion: 通过案例研究和专家访谈评估了EMINDS的有效性和可用性，展示了其在了解用户行为对长期心理健康影响方面的应用。

Abstract: Mental health is an urgent societal issue, and social scientists are increasingly turning to online mental health communities (OMHCs) to analyze user behavior data for early intervention. However, existing sequence mining techniques fall short of the urgent need to explore the behavior progression of different groups (e.g., recovery or deterioration groups) and track the potential long-term impact of behaviors on mental health status. To address this issue, we introduce EMINDS, a visual analytics system built on a novel automatic mining pipeline that extracts distinct behavior stages and assesses the potential impact of frequent stage patterns on mental health status over time. The system includes a set of interactive visualizations that summarize the meaning of each behavior stage and the evolution of different stage patterns. We feature a pattern-centric Sankey diagram to reveal contextual information about the impact of stage patterns on mental health, helping experts understand the specific changes in sequences before and after a stage pattern. We evaluated the effectiveness and usability of EMINDS through two case studies and expert interviews, which examined the potential stage patterns impacting long-term mental health by analyzing user behaviors on Reddit.

</details>


### [39] [Left shifting analysis of Human-Autonomous Team interactions to analyse risks of autonomy in high-stakes AI systems](https://arxiv.org/abs/2512.03519)
*Ben Larwood,Oliver J. Sutton,Callum Cockburn*

Main category: cs.HC

TL;DR: 为了加强AI在高风险自主系统中的应用，本文提出了一种框架，用于在设计阶段及早分析AI失败模式和相关风险。


<details>
  <summary>Details</summary>
Motivation: 开发高风险自主系统的复杂性与人为操作员在紧张决策时的风险相关，缺乏对AI失败模式的理解妨碍了AI在智能系统中的强健实施。

Method: 基于LaMonica et al. (2022)的人机自主团队建模，系统性地分析人类与自主系统之间的交互，识别所有操作域内的风险。

Result: 提出了一种新的框架，能够在系统生命周期的设计阶段早期识别人机协作中的AI失败模式及相关风险。

Conclusion: 通过理解新兴行为，可以提高系统的鲁棒性，确保在整个操作设计领域进行全面的分析。

Abstract: Developing high-stakes autonomous systems that include Artificial Intelligence (AI) components is complex; the consequences of errors can be catastrophic, yet it is challenging to plan for all operational cases. In stressful scenarios for the human operator, such as short decision-making timescales, the risk of failures is exacerbated. A lack of understanding of AI failure modes obstructs this and so blocks the robust implementation of applications of AI in smart systems. This prevents early risk identification, leading to increased time, risk and cost of projects.
  A key tenet of Systems Engineering and acquisition engineering is centred around a "left-shift" in test and evaluation activities to earlier in the system lifecycle, to allow for "accelerated delivery of [systems] that work". We argue it is therefore essential that this shift includes the analysis of AI failure cases as part of the design stages of the system life cycle. Our proposed framework enables the early characterisation of risks emerging from human-autonomy teaming (HAT) in operational contexts. The cornerstone of this is a new analysis of AI failure modes, built on the seminal modelling of human-autonomy teams laid out by LaMonica et al., 2022. Using the analysis of the interactions between human and autonomous systems and exploring the failure modes within each aspect, our approach provides a way to systematically identify human-AI interactions risks across the operational domain of the system of interest. The understanding of the emergent behaviour enables increased robustness of the system, for which the analysis should be undertaken over the whole scope of its operational design domain. This approach is illustrated through an example use case for an AI assistant supporting a Command & Control (C2) System.

</details>


### [40] [Synthetic Cognitive Walkthrough: Aligning Large Language Model Performance with Human Cognitive Walkthrough](https://arxiv.org/abs/2512.03568)
*Ruican Zhong,David W. McDonald,Gary Hsieh*

Main category: cs.HC

TL;DR: 本研究探讨了大语言模型在可用性走查中的应用，发现它们在任务完成率和导航路径上优于人类，但在潜在失败点识别方面表现欠佳，然而经过提示后可改善表现。


<details>
  <summary>Details</summary>
Motivation: 寻找降低可用性测试成本的方法，以及利用LLMs的视觉推理和用户界面导航能力。

Method: 比较GPT-4和Gemini-2.5-pro等LLMs与人类参与者在认知走查（CW）中的表现。

Result: LLMs在接口导航和任务完成率上优于人类，但在识别潜在失败点时表现不如人类，经过额外提示后，LLMs能够预测人类识别的失败点。

Conclusion: 尽管大语言模型（LLMs）不能完全复制人类的行为，但它们可以在可用性测试中提供有价值的补充，尤其是在自动化和规模化可用性走查方面。

Abstract: Conducting usability testing like cognitive walkthrough (CW) can be costly. Recent developments in large language models (LLMs), with visual reasoning and UI navigation capabilities, present opportunities to automate CW. We explored whether LLMs (GPT-4 and Gemini-2.5-pro) can simulate human behavior in CW by comparing their walkthroughs with human participants. While LLMs could navigate interfaces and provide reasonable rationales, their behavior differed from humans. LLM-prompted CW achieved higher task completion rates than humans and followed more optimal navigation paths, while identifying fewer potential failure points. However, follow-up studies demonstrated that with additional prompting, LLMs can predict human-identified failure points, aligning their performance with human participants. Our work highlights that while LLMs may not replicate human behaviors exactly, they can be leveraged for scaling usability walkthroughs and providing UI insights, offering a valuable complement to traditional usability testing.

</details>


### [41] [Head, posture, and full-body gestures in interactive communication](https://arxiv.org/abs/2512.03636)
*Ľuboš Hládek,Bernhard U. Seeber*

Main category: cs.HC

TL;DR: 在噪声条件下进行的对话实验表明，背景噪声增加会导致手势频率和复杂性上升，但手与语音的同步性变化有限。


<details>
  <summary>Details</summary>
Motivation: 面对背景噪音或干扰者说话导致面对面沟通困难时，视觉线索在沟通中的重要性增加。

Method: 进行自由的双人对话实验，通过新开发的标记系统描述会话动作。

Result: 在更高的噪声水平下，手势复杂性增加，从而影响与说话和听力相关的动作，但头部动作相对说话有所减少。

Conclusion: 研究结果支持了肢体动作在沟通中的重要性，表明在面对挑战的沟通环境中，参与者会通过各种方式适应交谈需求。

Abstract: When face-to-face communication becomes effortful due to background noise or interfering talkers, the role of visual cues becomes increasingly important for communication success. While previous research has selectively examined head or hand movements, here we explore movements of the whole body in acoustically adverse conditions. We hypothesized that increasing background noise in conversations would lead to increased gesture frequency in hand, head, trunk, and leg movements typical of conversation. Increased use of hand movements should support the speaker's role, while increased head and trunk movements may help the listener. We conducted a free dyadic conversation experiment with normal-hearing participants (n=8) in a virtual acoustic environment. Conversational movements were described with a newly developed labeling system for typical conversational actions, and the frequency of individual types was analyzed. In addition, we analyzed gesture quality by assessing hand-speech synchrony, with the hypothesis that higher levels of background noise would lead to a loss of synchrony according to an interactive coupling model. Higher noise levels led to increased hand-gesture complexity during speaking and listening, more pronounced up-down head movements, and contrary to expectations, head movements during listening generally decreased relative to speaking. Synchrony and peak velocity were unaffected by noise, while gesture quality scaled only modestly. The results support previous findings regarding gesturing frequency, but we found only limited evidence for changes in speech-gesture synchrony. This work reveals communication patterns of the whole body and illustrates multimodal adaptation to communication demands.

</details>


### [42] [Sleep Modulation: The Challenge of Transitioning from Open Loop to Closed Loop](https://arxiv.org/abs/2512.03784)
*Guisong Liu,Jiansong Zhang,Yinpei Luo,Guoliang Wei,Shuqing Sun,Shiyang Deng,Pengfei Wei,Nanxi Chen*

Main category: cs.HC

TL;DR: 本研究探讨了睡眠调节从开放式向闭环系统转变的必要性，审查了现有方法的局限性，并提出了构建有效闭环系统的挑战和解决方案。


<details>
  <summary>Details</summary>
Motivation: 睡眠障碍已成为全球健康问题，亟需有效和广泛可及的干预技术。

Method: 通过回顾五种常用调节技术，评估其在闭环框架中的潜在整合，并识别在构建有效闭环调节系统时的主要挑战。

Result: 提出了睡眠闭环调节的概念，并识别了构建有效系统的主要挑战。

Conclusion: 本工作旨在推动睡眠调节的范式转变，从开放式系统发展到闭环系统。

Abstract: Sleep disorders have emerged as a critical global health issue, highlighting the urgent need for effective and widely accessible intervention technologies. Non-invasive brain stimulation has garnered attention as it enables direct or indirect modulation of neural activity, thereby promoting sleep enhancement in a safe and unobtrusive manner. This class of approaches is collectively referred to as sleep modulation. To date, the majority of sleep modulation research relies on open-loop paradigms with empirically determined parameters, while achieving individual adaptation and modulation accuracy remains a distant objective. The paradigm-specific constraints inherent to open-loop designs represent a major obstacle to clinical translation and large-scale deployment in home environments. In this paper, we delineate fundamental paradigms of sleep modulation, critically examine the intrinsic limitations of open-loop approaches, and formally conceptualize sleep closed-loop modulation. We further provide a comprehensive synthesis of prior studies involving five commonly employed modulation techniques, evaluating their potential integration within a closed-loop framework. Finally, we identify three primary challenges in constructing an effective sleep closed-loop modulation system: sensor solution selection, monitoring model design, and modulation strategy design, while also proposing potential solutions. Collectively, this work aims to advance the paradigm shift of sleep modulation from open-loop toward closed-loop systems.

</details>


### [43] [Adhera: A Human-Centered Health Informatics Solution for Reducing Informal Caregiver Burden through Improved Medication Adherence](https://arxiv.org/abs/2512.03878)
*Zhiyin Zhou*

Main category: cs.HC

TL;DR: 提出了一个名为Adhera的健康信息系统，旨在支持药物依从性同时减少照顾者负担。


<details>
  <summary>Details</summary>
Motivation: 应对老年人对药物管理的需求，减轻非正式照顾者的压力

Method: 混合方法研究设计，包括半结构化访谈、调查问卷和药剂师咨询

Result: Adhera系统通过传感器药丸组织器与移动应用程序提高了可视性并改善了照顾者的信心

Conclusion: 通过人本设计和协作框架，Adhera展示了技术创新与以同情为驱动的护理相结合的可能性。

Abstract: The growing global population of older adults, combined with ongoing healthcare workforce shortages, has increased reliance on informal caregivers, including family members and friends who provide unpaid support to individuals with chronic illnesses. Among their daily responsibilities, medication management remains one of the most demanding and error-prone tasks. Non-adherence to prescribed regimens not only undermines patient outcomes but also intensifies caregiver stress, anxiety, and fatigue. Although digital health technologies have proliferated to address adherence, most solutions focus exclusively on patients and neglect the informational and emotional needs of caregivers. This paper introduces Adhera, a caregiver-inclusive health informatics system designed to support medication adherence while reducing caregiver burden. Using a mixed-methods research design that included fifteen semi-structured caregiver interviews, sixty-five survey responses, and five pharmacist consultations, this study identified three primary challenges: caregiver stress related to uncertainty about medication intake, fragmented communication with healthcare professionals, and distrust in existing digital tools. Informed by the CeHRes Roadmap 2.0 and the Triple Bottom Line by Design and Culture (TBLD+C) framework, as well as recent co-design studies involving caregivers, Adhera integrates a sensor-equipped smart pill organizer with a mobile companion application that records intake events, sends real-time reminders, and provides caregivers with synchronized adherence data. Preliminary evaluation suggests that Adhera enhances visibility, improves caregiver confidence, and streamlines medication routines. This study contributes to the field of health informatics by demonstrating how human-centered design and collaborative frameworks can align technical innovation with empathy-driven care.

</details>


### [44] [Classification of User Satisfaction in HRI with Social Signals in the Wild](https://arxiv.org/abs/2512.03945)
*Michael Schiffmann,Sabina Jeschke,Anja Richert*

Main category: cs.HC

TL;DR: 本研究探讨通过分析社交信号自动分类用户满意度，以提升社会互动代理（SIA）的评估方法。


<details>
  <summary>Details</summary>
Motivation: 评估用户对SIA表现的满意度是设计用户与SIA互动的关键因素。

Method: 采用时间序列分类方法，分析来自身体姿势、面部表情与物理距离的社交信号指标。

Result: 实验结果证明，该方法无需手动标注数据集即能可靠识别低满意度互动。

Conclusion: 该方法有效识别低用户满意度的互动，具备提升SIA性能和用户体验的潜力。

Abstract: Socially interactive agents (SIAs) are being used in various scenarios and are nearing productive deployment. Evaluating user satisfaction with SIAs' performance is a key factor in designing the interaction between the user and SIA. Currently, subjective user satisfaction is primarily assessed manually through questionnaires or indirectly via system metrics. This study examines the automatic classification of user satisfaction through analysis of social signals, aiming to enhance both manual and autonomous evaluation methods for SIAs. During a field trial at the Deutsches Museum Bonn, a Furhat Robotics head was employed as a service and information hub, collecting an "in-the-wild" dataset. This dataset comprises 46 single-user interactions, including questionnaire responses and video data. Our method focuses on automatically classifying user satisfaction based on time series classification. We use time series of social signal metrics derived from the body pose, time series of facial expressions, and physical distance. This study compares three feature engineering approaches on different machine learning models. The results confirm the method's effectiveness in reliably identifying interactions with low user satisfaction without the need for manually annotated datasets. This approach offers significant potential for enhancing SIA performance and user experience through automated feedback mechanisms.

</details>


### [45] [HEART-Watch: A multimodal physiological dataset from a Google Pixel Watch across different physical states](https://arxiv.org/abs/2512.03988)
*Jathushan Kaetheeswaran,Boyi Ma,Ali Abedi,Milad Lankarany,Shehroz Khan*

Main category: cs.HC

TL;DR: 本论文介绍了HEART-Watch数据集，旨在提高智能手表心血管监测算法的可靠性和适用性，基于多样化的参与者数据。


<details>
  <summary>Details</summary>
Motivation: 社会上心血管疾病是主要的死亡原因，而消费级智能手表为个人健康监测提供了新选择，但缺乏多样化的生物信号数据

Method: 通过收集来自40名健康成年人的多模态生理信号，包括ECG、光电容积脉搏波和加速度信号，并进行了多种身体状态下的监测。

Result: 提出了HEART-Watch，一个包含多模态生理数据的数据集，用于心血管分析算法的开发与基准测试

Conclusion: HEART-Watch数据集将为心血管分析算法的开发提供支持，旨在减少算法开发中的偏差

Abstract: Consumer-grade smartwatches offer a new personalized health monitoring option for general consumers globally as cardiovascular diseases continue to prevail as the leading cause of global mortality. The development and validation of reliable cardiovascular monitoring algorithms for these consumer-grade devices requires realistic biosignal data from diverse sets of participants. However, the availability of public consumer-grade smartwatch datasets with synchronized cardiovascular biosignals is limited, and existing datasets do not offer rich demographic diversity in their participant cohorts, leading to potentially biased algorithm development. This paper presents HEART-Watch, a multimodal physiological dataset collected from temporally synchronized wrist-worn Google Pixel Watch 2 electrocardiogram (ECG), photoplethysmography, and accelerometer signals from a diverse cohort of 40 healthy adults across three physical states - sitting, standing and walking with reference chest ECG. Intermittent upper arm blood pressure measurements and concurrent biosignals were collected as an additional biomarker for future research. The motivation, methodology, and initial analyses of results are presented. HEART-Watch is intended to support the development and benchmarking of robust algorithms for cardiovascular analyses on consumer-grade smartwatches across diverse populations.

</details>


### [46] [When to Say "Hi" - Learn to Open a Conversation with an in-the-wild Dataset](https://arxiv.org/abs/2512.03991)
*Michael Schiffmann,Felix Struth,Sabina Jeschke,Anja Richert*

Main category: cs.HC

TL;DR: 本研究探讨社交互动代理（SIA）如何通过用户的肢体语言训练交互开启，以确保顺利的对话开始，提出了交互启动系统（IIS），通过实地测试验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 社交互动代理的社交能力是用户与其顺畅互动的关键，而成功的对话开启是提高用户满意度的重要因素。

Method: 使用用户的肢体语言作为输入，通过机器学习训练交互启动系统，并在真实环境中进行数据收集和模型验证。

Result: IIS系统在实地测试中表现出能够准确判断问候时机和对话开启者，从而提升交互体验。

Conclusion: 交互启动系统（IIS）能够有效识别对话的开启和问候时机，提升SIA与用户的交互质量。

Abstract: The social capabilities of socially interactive agents (SIA) are a key to successful and smooth interactions between the user and the SIA. A successful start of the interaction is one of the essential factors for satisfying SIA interactions. For a service and information task in which the SIA helps with information, e.g. about the location, it is an important skill to master the opening of the conversation and to recognize which interlocutor opens the conversation and when. We are therefore investigating the extent to which the opening of the conversation can be trained using the user's body language as an input for machine learning to ensure smooth conversation starts for the interaction. In this paper we propose the Interaction Initiation System (IIS) which we developed, trained and validated using an in-the-wild data set. In a field test at the Deutsches Museum Bonn, a Furhat robot from Furhat Robotics was used as a service and information point. Over the period of use we collected the data of \textit{N} = 201 single user interactions for the training of the algorithms. We can show that the IIS, achieves a performance that allows the conclusion that this system is able to determine the greeting period and the opener of the interaction.

</details>


### [47] [Affordances of Digital and Blockchain-based Community Currencies: The Case of Sarafu Network in Kenya](https://arxiv.org/abs/2512.04030)
*Patricia Marcella Evite*

Main category: cs.HC

TL;DR: 本论文研究了肯尼亚Sarafu网络的数字化转型，揭示区块链技术在促进社区经济活动方面的优势与挑战。


<details>
  <summary>Details</summary>
Motivation: 探讨社区货币在实施纸币时所面临的挑战，以及数字化转型的必要性和创新性。

Method: 采用定性研究方法，分析Sarafu网络及其前身的案例。

Result: 研究显示，数字化和区块链技术改善了当地社区的经济活动 facilitation。

Conclusion: 平衡区块链的创新优势与用户界面的复杂性是社区货币数字化的主要挑战。

Abstract: Community currencies (CCs) have been adopting innovative systems to overcome implementational hurdles from issuing paper currencies. Using a qualitative approach, this paper examined this digital transition of Sarafu Network in Kenya and its predecessor CCs as a case study. From the original vouchers launched in 2010, the foundation Grassroots Economics introduced a digital interface in 2016 that operates on a feature phone, and then integrated blockchain technology starting in 2018, undergoing several migrations before becoming settling on its current iteration called Community Asset Vouchers on the Celo blockchain since 2023. Using affordances from human-computer interaction, the research shows that digitalization and blockchain improved the facilitation of economic activities of the local communities, both their typical market transactions as well as traditional reciprocal labor exchanges, by offering more functionalities compared to the analog version of Sarafu. The unique contributions of blockchain include enabling automation of holding tax calculations and linking the vouchers to the mainstream monetary system via stablecoins facilitated by a series of smart contracts also known as the liquidity pool. The study also finds that there is an inherent trade-off between blockchain benefits and user interface complexity. Hence, balancing innovation and community needs remains a challenge.

</details>
