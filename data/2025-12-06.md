<div id=toc></div>

# Table of Contents

- [cs.HC](#cs.HC) [Total: 6]
- [cs.RO](#cs.RO) [Total: 25]


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [1] [ConsentDiff at Scale: Longitudinal Audits of Web Privacy Policy Changes and UI Frictions](https://arxiv.org/abs/2512.04316)
*Haoze Guo*

Main category: cs.HC

TL;DR: 本研究开发了一个可重复的管道，旨在提供网站政策文本和用户同意界面的长期变化视角，探究二者之间的一致性与变化。


<details>
  <summary>Details</summary>
Motivation: 我们希望填补对用户隐私同意界面和政策文本之间变化缺乏的纵向数据的空白，评估这些界面是否真正执行了所承诺的政策。

Method: 使用定期的网站快照，通过语义对齐政策条款，跟踪条款级别的变化，同时运用截图提供的线索分类同意用户界面模式，构建了一个新的权重声明-用户界面对齐分数。

Result: 通过我们的测量，发现政策持续变化，显著改变消除了高摩擦的横幅设计，并且当拒绝选项可见且摩擦降低时，它们之间的对齐度显著提高。

Conclusion: 我们的研究表明，政策持续变化、系统性变化导致较高摩擦的横幅设计被消除，并且在拒绝选项可见且摩擦较低时，政策与用户界面之间的对齐度显著提高。

Abstract: Web privacy is experienced via two public artifacts: site utterances in policy texts, and the actions users are required to take during consent interfaces. In the extensive cross-section audits we've studied, there is a lack of longitudinal data detailing how these artifacts are changing together, and if interfaces are actually doing what they promise in policy. ConsentDiff provides that longitudinal view. We build a reproducible pipeline that snapshots sites every month, semantically aligns policy clauses to track clause-level churn, and classifies consent-UI patterns by pulling together DOM signals with cues provided by screenshots. We introduce a novel weighted claim-UI alignment score, connecting common policy claims to observable predicates, and enabling comparisons over time, regions, and verticals. Our measurements suggest continued policy churn, systematic changes to eliminate a higher-friction banner design, and significantly higher alignment where rejecting is visible and lower friction.

</details>


### [2] [Human-controllable AI: Meaningful Human Control](https://arxiv.org/abs/2512.04334)
*Chengke Liu,Wei Xu*

Main category: cs.HC

TL;DR: 此章探讨了人类可控AI的意义与要求，强调人类控制、技术设计和治理之间的统一，呼吁加强跨学科研究以推动人本导向的人工智能发展。


<details>
  <summary>Details</summary>
Motivation: 开发可控的人类人工智能（AI），以确保伦理一致性和有效治理，已成为应对挑战的重要原则。

Method: 系统审查人工智能中的人类控制，阐明其基础原则和未来发展方向。

Result: 人类控制不仅仅是操作权，而是人类理解、干预和责任可追溯性的统一，要求技术设计、AI治理与人类共同参与。

Conclusion: 未来AI系统需以人类可控性为前提，强调技术架构、人机交互及AI系统的演变，以实现人类与AI之间的和谐发展，推动人本导向的人工智能治理政策。

Abstract: Developing human-controllable artificial intelligence (AI) and achieving meaningful human control (MHC) has become a vital principle to address these challenges, ensuring ethical alignment and effective governance in AI. MHC is also a critical focus in human-centered AI (HCAI) research and application. This chapter systematically examines MHC in AI, articulating its foundational principles and future trajectory. MHC is not simply the right to operate, but the unity of human understanding, intervention, and the traceablity of responsibility in AI decision-making, which requires technological design, AI governance, and humans to play a role together. MHC ensures AI autonomy serves humans without constraining technological progress. The mode of human control needs to match the levels of technology, and human supervision should balance the trust and doubt of AI. For future AI systems, MHC mandates human controllability as a prerequisite, requiring: (1) technical architectures with embedded mechanisms for human control; (2) human-AI interactions optimized for better access to human understanding; and (3) the evolution of AI systems harmonizing intelligence and human controllability. Governance must prioritize HCAI strategies: policies balancing innovation and risk mitigation, human-centered participatory frameworks transcending technical elite dominance, and global promotion of MHC as a universal governance paradigm to safeguard HCAI development. Looking ahead, there is a need to strengthen interdisciplinary research on the controllability of AI systems, enhance ethical and legal awareness among stakeholders, moving beyond simplistic technology design perspectives, focus on the knowledge construction, complexity interpretation, and influencing factors surrounding human control. By fostering MHC, the development of human-controllable AI can be further advanced, delivering HCAI systems.

</details>


### [3] [What is Beyond Presence? Dimensionality, Control, and Information Spaces](https://arxiv.org/abs/2512.04398)
*E. Ch'ng*

Main category: cs.HC

TL;DR: 随着虚拟现实的发展，沉浸体验必须超越技术维度，建立一个新的框架以提升体验，并鼓励跨学科创作者的合作。


<details>
  <summary>Details</summary>
Motivation: 虚拟现实正从一种技术系统转变为文化和社会媒介，现有理论无法完全解释新兴的体验形式，因此需要新的理论框架来适应这一下变化。

Method: 提出一种新框架以指导沉浸环境的设计和评估

Result: 提出了空间、场所性、时间、社会、文化、认知和心理等维度作为虚拟世界的关键参数，从而提升用户体验。

Conclusion: 沉浸环境的设计应超越技术维度，利用丰富的信息通道来塑造用户体验，强调跨学科的创作者在设计和评估有意义的沉浸世界方面的参与。

Abstract: What is after presence? Spatial presence, the sense of "being there", is becoming less of a primary objective and more of a baseline expectation of virtual reality. More than six decades after its invention, VR is shifting from a technical system into a cultural, social, and phenomenological medium, offering experiences that function as distinct modes of reality. Existing theories that focus primarily on perceptual illusions are no longer sufficient to account for these emerging forms of experience. A new framework is needed to guide the design and evaluation of immersive environments by identifying the key technical and abstract dimensions afforded by virtual worlds. These dimensions include spatial, placeness, temporal, social, cultural, cognitive, and psychological parameters. The central argument is that immersive environments must move beyond the technical dimension to leverage richer information channels that shape user experience. This shift from presence to experience orchestration invites creators across disciplines to contribute to the design and assessment of meaningful immersive worlds.

</details>


### [4] [Interactive Communication -- cross-disciplinary perspectives from psychology, acoustics, and media technology](https://arxiv.org/abs/2512.04692)
*Mareike Daeglau,Stephan Getzmann,Moritz Bender,Janina Fels,Rainer Martin,Alexander Raake,Isabel S. Schiller,Sabine J. Schlittmeier,Katrin Schoenenberg,Felix Stärz,Leon O. H. Kroczek*

Main category: cs.HC

TL;DR: 本文综述了互动沟通的心理机制、声学和媒体技术限制，跨学科整合理论、测量和应用。


<details>
  <summary>Details</summary>
Motivation: 探讨互动沟通的各个方面和其重要性，整合不同学科的研究成果。

Method: 概述互动沟通的理论框架、方法学方法及应用，涵盖面谈和计算机媒介的沟通区分。

Result: 总结了行为、认知和体验测量的关键方法，并讨论辅助听力技术、对话代理等应用及伦理考量。

Conclusion: 强调人类能力与技术系统如何共同塑造互动沟通，并整合了不同研究线的概念、发现和挑战。

Abstract: Interactive communication (IC), i.e., the reciprocal exchange of information between two or more interactive partners, is a fundamental part of human nature. As such, it has been studied across multiple scientific disciplines with different goals and methods. This article provides a cross-disciplinary primer on contemporary IC that integrates psychological mechanisms with acoustic and media-technological constraints across theory, measurement, and applications. First, we outline theoretical frameworks that account for verbal, nonverbal and multimodal aspects of IC, including distinctions between face-to-face and computer-mediated communication. Second, we summarize key methodological approaches, including behavioral, cognitive, and experiential measures of communicative synchrony and acoustic signal quality. Third, we discuss selected applications, i.e. assistive listening technologies, conversational agents, alongside ethical considerations. Taken together, this review highlights how human capacities and technical systems jointly shape IC, consolidating concepts, findings, and challenges that have often been discussed in separate lines of research.

</details>


### [5] [From Symptoms to Systems: An Expert-Guided Approach to Understanding Risks of Generative AI for Eating Disorders](https://arxiv.org/abs/2512.04843)
*Amy Winecoff,Kevin Klyman*

Main category: cs.HC

TL;DR: 研究表明，生成式AI系统在与饮食失调相关的用户互动中可能加重风险，需针对其特点设计更有效的风险管理策略。


<details>
  <summary>Details</summary>
Motivation: 现有的保护措施未能充分识别影响饮食失调者的潜在风险，因此亟需深入了解这些风险的性质。

Method: 通过与15位饮食失调领域的临床医生、研究人员和倡导者进行半结构化访谈，使用演绎性定性分析方法。

Result: 研究发现生成式AI系统与饮食失调的临床特征交叉，可能加剧风险，并提出了针对风险评估和保护设计的建议。

Conclusion: 生成式人工智能系统可能加剧饮食失调人群的风险，因此需要改进风险评估和保护措施设计。

Abstract: Generative AI systems may pose serious risks to individuals vulnerable to eating disorders. Existing safeguards tend to overlook subtle but clinically significant cues, leaving many risks unaddressed. To better understand the nature of these risks, we conducted semi-structured interviews with 15 clinicians, researchers, and advocates with expertise in eating disorders. Using abductive qualitative analysis, we developed an expert-guided taxonomy of generative AI risks across seven categories: (1) providing generalized health advice; (2) encouraging disordered behaviors; (3) supporting symptom concealment; (4) creating thinspiration; (5) reinforcing negative self-beliefs; (6) promoting excessive focus on the body; and (7) perpetuating narrow views about eating disorders. Our results demonstrate how certain user interactions with generative AI systems intersect with clinical features of eating disorders in ways that may intensify risk. We discuss implications of our work, including approaches for risk assessment, safeguard design, and participatory evaluation practices with domain experts.

</details>


### [6] [Perceptually-Minimal Color Optimization for Web Accessibility: A Multi-Phase Constrained Approach](https://arxiv.org/abs/2512.05067)
*Lalitha A R*

Main category: cs.HC

TL;DR: 提出了一种新颖的多阶段优化方法，自动生成符合WCAG标准的颜色，同时尽量减少对原始设计的视觉变化。


<details>
  <summary>Details</summary>
Motivation: 解决网页可访问性指南对文本与背景之间的颜色对比要求，同时保持品牌美学不受破坏。

Method: 将问题建模为一个有约束的非线性优化问题，利用OKLCH颜色空间，通过二分搜索、梯度下降和逐步约束松弛的三阶段序列进行处理。

Result: 在1万对程序生成的颜色对中，算法成功解决77.22%的可访问性违例，其中88.51%的成功修正表现为不明显的颜色差异，感知变化中位数为0.76 ΔE_{2000}。

Conclusion: 该方法实现了可访问性合规和视觉设计完整性的统一，且具有高效的计算和感知意识，公开实现于cm-colors Python库。

Abstract: Web accessibility guidelines require sufficient color contrast between text and backgrounds; yet, manually adjusting colors often necessitates significant visual deviation, compromising vital brand aesthetics. We present a novel, multi-phase optimization approach for automatically generating WCAG-compliant colors while minimizing perceptual change to original design choices.
  Our method treats this as a constrained, non-linear optimization problem, utilizing the modern perceptually uniform OKLCH color space. Crucially, the optimization is constrained to preserve the original hue ($\text{H}$) of the color, ensuring that modifications are strictly limited to necessary adjustments in lightness ($\text{L}$) and chroma ($\text{C}$). This is achieved through a three-phase sequence: binary search, gradient descent, and progressive constraint relaxation.
  Evaluation on a dataset of 10,000 procedurally generated color pairs demonstrates that the algorithm successfully resolves accessibility violations in $77.22\%$ of cases, with $88.51\%$ of successful corrections exhibiting imperceptible color difference ($ΔE_{2000} < 2.0$) as defined by standard perceptibility thresholds. The median perceptual change for successful adjustments is only $0.76\ ΔE_{2000}$, and the algorithm achieves this with a median processing time of $0.876\text{ms}$ per color pair.
  The approach demonstrates that accessibility compliance and visual design integrity can be achieved simultaneously through a computationally efficient, perceptually-aware optimization that respects brand identity. The algorithm is publicly implemented in the open-source cm-colors Python library.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [7] [CRAFT-E: A Neuro-Symbolic Framework for Embodied Affordance Grounding](https://arxiv.org/abs/2512.04231)
*Zhou Chen,Joe Lin,Carson Bulgin,Sathyanarayanan N. Aakur*

Main category: cs.RO

TL;DR: CRAFT-E是一个模块化的神经符号框架，通过结构化的知识图谱和视觉语言对齐，改善了助理机器人在复杂环境中的对象选择能力，并实现了高效的抓取推理。


<details>
  <summary>Details</summary>
Motivation: 辅助机器人需要理解物体的功能以及如何在不确定环境中物理地获取这些物体，以提高人机交互的透明性和可靠性。

Method: CRAFT-E结合了一个结构化的动词-属性-对象知识图谱与视觉-语言对齐和基于能量的抓取推理，从而构建可解释的对象选择路径。

Result: CRAFT-E在静态场景、基于ImageNet的功能检索和实际环境测试中，表现出色，能在感知噪声干扰下保持鲁棒性，并提供了组件级的透明诊断。

Conclusion: CRAFT-E提供了一种可解释和可定制的替代方案，用于基于可用性选择对象，有助于在辅助机器人系统中支持可信的决策制定。

Abstract: Assistive robots operating in unstructured environments must understand not only what objects are, but what they can be used for. This requires grounding language-based action queries to objects that both afford the requested function and can be physically retrieved. Existing approaches often rely on black-box models or fixed affordance labels, limiting transparency, controllability, and reliability for human-facing applications. We introduce CRAFT-E, a modular neuro-symbolic framework that composes a structured verb-property-object knowledge graph with visual-language alignment and energy-based grasp reasoning. The system generates interpretable grounding paths that expose the factors influencing object selection and incorporates grasp feasibility as an integral part of affordance inference. We further construct a benchmark dataset with unified annotations for verb-object compatibility, segmentation, and grasp candidates, and deploy the full pipeline on a physical robot. CRAFT-E achieves competitive performance in static scenes, ImageNet-based functional retrieval, and real-world trials involving 20 verbs and 39 objects. The framework remains robust under perceptual noise and provides transparent, component-level diagnostics. By coupling symbolic reasoning with embodied perception, CRAFT-E offers an interpretable and customizable alternative to end-to-end models for affordance-grounded object selection, supporting trustworthy decision-making in assistive robotic systems.

</details>


### [8] [Sliding Mode Control and Subspace Stabilization Methodology for the Orbital Stabilization of Periodic Trajectories](https://arxiv.org/abs/2512.04249)
*Maksim Surov,Leonid Freidovich*

Main category: cs.RO

TL;DR: 本文提出了一种结合滑模控制和子空间稳定化的方法，以实现欠驱动机械系统中周期轨迹的稳定，并在蝴蝶机器人上进行实验验证。


<details>
  <summary>Details</summary>
Motivation: 在具有一个欠驱动度的欠驱动机械系统中稳定周期性轨迹是一个具有挑战性的任务。

Method: 结合滑模控制和子空间稳定化方法，通过部分反馈线性化和稳定化，计算沿参考轨道的横向线性化，形成一个具有稳定子空间的周期线性时变系统。

Result: 滑模控制能够将轨迹引导至该稳定子空间，避免了求解计算密集的周期LQR问题，同时提升了对匹配干扰的鲁棒性。

Conclusion: 所提出的方法已在蝴蝶机器人上通过实验验证。

Abstract: This paper presents a combined sliding-mode control and subspace stabilization methodology for orbital stabilization of periodic trajectories in underactuated mechanical systems with one degree of underactuation. The approach starts with partial feedback linearization and stabilization. Then, transverse linearization along the reference orbit is computed, resulting in a periodic linear time-varying system with a stable subspace. Sliding-mode control drives trajectories toward this subspace. The proposed design avoids solving computationally intensive periodic LQR problems and improves robustness to matched disturbances. The methodology is validated through experiments on the Butterfly robot.

</details>


### [9] [Driving Beyond Privilege: Distilling Dense-Reward Knowledge into Sparse-Reward Policies](https://arxiv.org/abs/2512.04279)
*Feeza Khan Khanzada,Jaerock Kwon*

Main category: cs.RO

TL;DR: 研究利用模拟器密集奖励在视觉基础的自主驾驶中提升性能，同时避免与部署目标不一致的问题。


<details>
  <summary>Details</summary>
Motivation: 在现实的模拟器（如CARLA）中，密集奖励有助于加速模型训练，但直接基于这些奖励训练的策略在稀疏目标上表现不佳。

Method: 提出一种两阶段的奖励特权世界模型蒸馏框架，首先用密集奖励训练教师代理，然后用稀疏任务奖励训练学生代理。

Result: 在CARLA的车道跟随和超车基准测试中，稀疏奖励的学生在未见车道上成功率提高约23%，超车时在未见路线上的成功率提高至27倍。

Conclusion: 密集奖励可以有效地用于学习动态模型，同时保证策略优化与稀疏目标一致。

Abstract: We study how to exploit dense simulator-defined rewards in vision-based autonomous driving without inheriting their misalignment with deployment metrics. In realistic simulators such as CARLA, privileged state (e.g., lane geometry, infractions, time-to-collision) can be converted into dense rewards that stabilize and accelerate model-based reinforcement learning, but policies trained directly on these signals often overfit and fail to generalize when evaluated on sparse objectives such as route completion and collision-free overtaking. We propose reward-privileged world model distillation, a two-stage framework in which a teacher DreamerV3-style agent is first trained with a dense privileged reward, and only its latent dynamics are distilled into a student trained solely on sparse task rewards. Teacher and student share the same observation space (semantic bird's-eye-view images); privileged information enters only through the teacher's reward, and the student does not imitate the teacher's actions or value estimates. Instead, the student's world model is regularized to match the teacher's latent dynamics while its policy is learned from scratch on sparse success/failure signals. In CARLA lane-following and overtaking benchmarks, sparse-reward students outperform both dense-reward teachers and sparse-from-scratch baselines. On unseen lane-following routes, reward-privileged distillation improves success by about 23 percent relative to the dense teacher while maintaining comparable or better safety. On overtaking, students retain near-perfect performance on training routes and achieve up to a 27x improvement in success on unseen routes, with improved lane keeping. These results show that dense rewards can be leveraged to learn richer dynamics models while keeping the deployed policy optimized strictly for sparse, deployment-aligned objectives.

</details>


### [10] [ResponsibleRobotBench: Benchmarking Responsible Robot Manipulation using Multi-modal Large Language Models](https://arxiv.org/abs/2512.04308)
*Lei Zhang,Ju Dong,Kaixin Bai,Minheng Ni,Zoltan-Csaba Marton,Zhaopeng Chen,Jianwei Zhang*

Main category: cs.RO

TL;DR: 新推出的ResponsibleRobotBench基准为评估和推动责任感强的机器人操作提供了系统化工具，涉及多种风险类型和复杂度，旨在提高机器人在真实世界中的应用和安全性。


<details>
  <summary>Details</summary>
Motivation: 随着多模态模型的进步，机器人操控领域涌现出新的机遇，必须增强机器人在实际环境中的安全性和可靠性。

Method: ResponsibleRobotBench包含23个涉及多种风险类型的多阶段任务，涉及风险检测、推理及行动规划等关键能力，并提供多模态评估框架及丰富的数据集。

Result: ResponsibleRobotBench基准评估系统在负责的机器人操控方面的进展，将模拟与真实世界的教学结合，以确保机器人能够理解复杂的风险并进行有效的决策。

Conclusion: 通过负责机器人基准，研究者和开发者可以在真实环境中评估和提升机器人的表现，确保其在高风险环境中做出安全和道德的决策。

Abstract: Recent advances in large multimodal models have enabled new opportunities in embodied AI, particularly in robotic manipulation. These models have shown strong potential in generalization and reasoning, but achieving reliable and responsible robotic behavior in real-world settings remains an open challenge. In high-stakes environments, robotic agents must go beyond basic task execution to perform risk-aware reasoning, moral decision-making, and physically grounded planning. We introduce ResponsibleRobotBench, a systematic benchmark designed to evaluate and accelerate progress in responsible robotic manipulation from simulation to real world. This benchmark consists of 23 multi-stage tasks spanning diverse risk types, including electrical, chemical, and human-related hazards, and varying levels of physical and planning complexity. These tasks require agents to detect and mitigate risks, reason about safety, plan sequences of actions, and engage human assistance when necessary. Our benchmark includes a general-purpose evaluation framework that supports multimodal model-based agents with various action representation modalities. The framework integrates visual perception, context learning, prompt construction, hazard detection, reasoning and planning, and physical execution. It also provides a rich multimodal dataset, supports reproducible experiments, and includes standardized metrics such as success rate, safety rate, and safe success rate. Through extensive experimental setups, ResponsibleRobotBench enables analysis across risk categories, task types, and agent configurations. By emphasizing physical reliability, generalization, and safety in decision-making, this benchmark provides a foundation for advancing the development of trustworthy, real-world responsible dexterous robotic systems. https://sites.google.com/view/responsible-robotbench

</details>


### [11] [Vertical Planetary Landing on Sloped Terrain Using Optical Flow Divergence Estimates](https://arxiv.org/abs/2512.04373)
*Hann Woei Ho,Ye Zhou*

Main category: cs.RO

TL;DR: 针对小型航天器在坡面着陆的挑战，本文提出了一种非线性控制策略，基于不同局部流发散估计来调节推力和姿态，确保平稳着陆。


<details>
  <summary>Details</summary>
Motivation: 小型航天器如旋翼机和着陆器在坡面着陆时面临重大挑战，传统的深度学习方法和重型传感器不切实际，因此需要一种低资源的解决方案。

Method: 提出了一种非线性控制策略，利用两个不同的局部流发散估计来调节垂直着陆时的推力和姿态，该控制法基于增量非线性动态反演。

Result: 通过对简化的二维航天器模型在不同坡度和发散设定点上的数值模拟评估，该方法在保持推力控制稳定性的同时，实现了速度和高度的指数衰减。

Conclusion: 该方法提供了一种强大且低资源的着陆策略，增强了小型航天器自主行星任务的可行性。

Abstract: Autonomous landing on sloped terrain poses significant challenges for small, lightweight spacecraft, such as rotorcraft and landers. These vehicles have limited processing capability and payload capacity, which makes advanced deep learning methods and heavy sensors impractical. Flying insects, such as bees, achieve remarkable landings with minimal neural and sensory resources, relying heavily on optical flow. By regulating flow divergence, a measure of vertical velocity divided by height, they perform smooth landings in which velocity and height decay exponentially together. However, adapting this bio-inspired strategy for spacecraft landings on sloped terrain presents two key challenges: global flow-divergence estimates obscure terrain inclination, and the nonlinear nature of divergence-based control can lead to instability when using conventional controllers. This paper proposes a nonlinear control strategy that leverages two distinct local flow divergence estimates to regulate both thrust and attitude during vertical landings. The control law is formulated based on Incremental Nonlinear Dynamic Inversion to handle the nonlinear flow divergence. The thrust control ensures a smooth vertical descent by keeping a constant average of the local flow divergence estimates, while the attitude control aligns the vehicle with the inclined surface at touchdown by exploiting their difference. The approach is evaluated in numerical simulations using a simplified 2D spacecraft model across varying slopes and divergence setpoints. Results show that regulating the average divergence yields stable landings with exponential decay of velocity and height, and using the divergence difference enables effective alignment with inclined terrain. Overall, the method offers a robust, low-resource landing strategy that enhances the feasibility of autonomous planetary missions with small spacecraft.

</details>


### [12] [FALCON: Actively Decoupled Visuomotor Policies for Loco-Manipulation with Foundation-Model-Based Coordination](https://arxiv.org/abs/2512.04381)
*Chengyang He,Ge Sun,Yue Bai,Junkai Lu,Jiadong Zhao,Guillaume Sartoretti*

Main category: cs.RO

TL;DR: FALCON结合模组扩散策略和视觉-语言模型，通过解耦步态与操控策略提升鲁棒性，超越现有基线。


<details>
  <summary>Details</summary>
Motivation: 提出一种有效的框架来结合步态和操控能力，解决单一策略性能下降的问题。

Method: 利用模组扩散策略和视觉-语言基础模型作为协调者，将步态和操控策略显式解耦，并通过相互兼容的对比损失结构化潜在空间。

Result: 在两个具有挑战性的步态操控任务上进行评估，超越了集中和分散基线，表现出更好的鲁棒性和推广能力。

Conclusion: FALCON在复杂任务中展示了其优势，并缓解了因异构观察而导致的性能下降。

Abstract: We present FoundAtion-model-guided decoupled LoCO-maNipulation visuomotor policies (FALCON), a framework for loco-manipulation that combines modular diffusion policies with a vision-language foundation model as the coordinator. Our approach explicitly decouples locomotion and manipulation into two specialized visuomotor policies, allowing each subsystem to rely on its own observations. This mitigates the performance degradation that arise when a single policy is forced to fuse heterogeneous, potentially mismatched observations from locomotion and manipulation. Our key innovation lies in restoring coordination between these two independent policies through a vision-language foundation model, which encodes global observations and language instructions into a shared latent embedding conditioning both diffusion policies. On top of this backbone, we introduce a phase-progress head that uses textual descriptions of task stages to infer discrete phase and continuous progress estimates without manual phase labels. To further structure the latent space, we incorporate a coordination-aware contrastive loss that explicitly encodes cross-subsystem compatibility between arm and base actions. We evaluate FALCON on two challenging loco-manipulation tasks requiring navigation, precise end-effector placement, and tight base-arm coordination. Results show that it surpasses centralized and decentralized baselines while exhibiting improved robustness and generalization to out-of-distribution scenarios.

</details>


### [13] [Development of a 15-Degree-of-Freedom Bionic Hand with Cable-Driven Transmission and Distributed Actuation](https://arxiv.org/abs/2512.04399)
*Haoqi Han,Yi Yang,Yifei Yu,Yixuan Zhou,Xiaohan Zhu,Hesheng Wang*

Main category: cs.RO

TL;DR: 本研究提出一种新型15自由度仿生机器人手，采用腱驱动机制，减少电机数量，性能优越，具有良好的灵活性和抓取能力。


<details>
  <summary>Details</summary>
Motivation: 在机器人手部研究中，减少伺服器数量同时保持与人手相一致的尺寸和自由度是一项基本挑战。

Method: 提出了一种新型的15自由度灵巧机器人手，分析了其机械结构、电气系统和控制系统，采用新的腱驱动机制，减少了所需电机数量，同时提高了运动性能和简化了机械结构。

Result: 实验中，该仿生手展示了卓越的灵活性和强大的抓取能力，证明了其在机器人操作任务中的重大潜力。

Conclusion: 该设计结合了轻量化和高性能，整个系统重量仅为1.4kg，具有广泛的应用前景。

Abstract: In robotic hand research, minimizing the number of actuators while maintaining human-hand-consistent dimensions and degrees of freedom constitutes a fundamental challenge. Drawing bio-inspiration from human hand kinematic configurations and muscle distribution strategies, this work proposes a novel 15-DoF dexterous robotic hand, with detailed analysis of its mechanical architecture, electrical system, and control system. The bionic hand employs a new tendon-driven mechanism, significantly reducing the number of motors required by traditional tendon-driven systems while enhancing motion performance and simplifying the mechanical structure. This design integrates five motors in the forearm to provide strong gripping force, while ten small motors are installed in the palm to support fine manipulation tasks. Additionally, a corresponding joint sensing and motor driving electrical system was developed to ensure efficient control and feedback. The entire system weighs only 1.4kg, combining lightweight and high-performance features. Through experiments, the bionic hand exhibited exceptional dexterity and robust grasping capabilities, demonstrating significant potential for robotic manipulation tasks.

</details>


### [14] [Bridging Probabilistic Inference and Behavior Trees: An Interactive Framework for Adaptive Multi-Robot Cooperation](https://arxiv.org/abs/2512.04404)
*Chaoran Wang,Jingyuan Sun,Yanhui Zhang,Changju Wu*

Main category: cs.RO

TL;DR: 本文提出IIBT框架，通过结合行为树和主动推理，提升了多机器人系统的决策与合作能力，且有效降低了复杂度。


<details>
  <summary>Details</summary>
Motivation: 解决多机器人决策制定中的合作与适应性问题，提升行为树的应用效率。

Method: 提出一种交互式推理行为树(IIBT)框架，将行为树与主动推理通过自由能原则结合，支持在线联合规划与执行。

Result: 通过仿真和实际实验验证IIBT框架的有效性，在多机器人迷宫导航和协作操作任务中效果显著。

Conclusion: IIBT框架在保持强健、可解释和适应性合作行为的同时，BT节点复杂度降低了70%以上。

Abstract: This paper proposes an Interactive Inference Behavior Tree (IIBT) framework that integrates behavior trees (BTs) with active inference under the free energy principle for distributed multi-robot decision-making. The proposed IIBT node extends conventional BTs with probabilistic reasoning, enabling online joint planning and execution across multiple robots. It remains fully compatible with standard BT architectures, allowing seamless integration into existing multi-robot control systems. Within this framework, multi-robot cooperation is formulated as a free-energy minimization process, where each robot dynamically updates its preference matrix based on perceptual inputs and peer intentions, thereby achieving adaptive coordination in partially observable and dynamic environments. The proposed approach is validated through both simulation and real-world experiments, including a multi-robot maze navigation and a collaborative manipulation task, compared against traditional BTs(https://youtu.be/KX_oT3IDTf4). Experimental results demonstrate that the IIBT framework reduces BT node complexity by over 70%, while maintaining robust, interpretable, and adaptive cooperative behavior under environmental uncertainty.

</details>


### [15] [RoboBPP: Benchmarking Robotic Online Bin Packing with Physics-based Simulation](https://arxiv.org/abs/2512.04415)
*Zhoufeng Wang,Hang Zhao,Juzhan Xu,Shishun Zhang,Zeyu Xiong,Ruizhen Hu,Chenyang Zhu,Kai Xu*

Main category: cs.RO

TL;DR: RoboBPP是一个针对机器人在线箱子包装的基准系统，集成物理模拟器，旨在解决工业物流中的物理可行性问题，提供真实数据集和评估指标。


<details>
  <summary>Details</summary>
Motivation: 解决传统在线箱子包装中的一致性问题及缺乏有效基准的挑战，以提升工业自动化的效率。

Method: 提出RoboBPP，一个集成物理基础模拟器的基准系统，用于评估机器人在线箱子包装的物理可行性。

Result: 通过收集来自真实工业工作流程的三种数据集并模拟实际工业应用的条件，确保算法可实际部署。

Conclusion: RoboBPP是一个开源的基准系统，提供可视化工具和在线排行榜，为未来的研究和工业应用提供一个可重复和可扩展的基础。

Abstract: Physical feasibility in 3D bin packing is a key requirement in modern industrial logistics and robotic automation. With the growing adoption of industrial automation, online bin packing has gained increasing attention. However, inconsistencies in problem settings, test datasets, and evaluation metrics have hindered progress in the field, and there is a lack of a comprehensive benchmarking system. Direct testing on real hardware is costly, and building a realistic simulation environment is also challenging. To address these limitations, we introduce RoboBPP, a benchmarking system designed for robotic online bin packing. RoboBPP integrates a physics-based simulator to assess physical feasibility. In our simulation environment, we introduce a robotic arm and boxes at real-world scales to replicate real industrial packing workflows. By simulating conditions that arise in real industrial applications, we ensure that evaluated algorithms are practically deployable. In addition, prior studies often rely on synthetic datasets whose distributions differ from real-world industrial data. To address this issue, we collect three datasets from real industrial workflows, including assembly-line production, logistics packing, and furniture manufacturing. The benchmark comprises three carefully designed test settings and extends existing evaluation metrics with new metrics for structural stability and operational safety. We design a scoring system and derive a range of insights from the evaluation results. RoboBPP is fully open-source and is equipped with visualization tools and an online leaderboard, providing a reproducible and extensible foundation for future research and industrial applications (https://robot-bin-packing-benchmark.github.io).

</details>


### [16] [Vision-Language-Action Models for Selective Robotic Disassembly: A Case Study on Critical Component Extraction from Desktops](https://arxiv.org/abs/2512.04446)
*Chang Liu,Sibo Tian,Sara Behdad,Xiao Liang,Minghui Zheng*

Main category: cs.RO

TL;DR: 本研究探讨了利用视觉-语言-动作模型进行电子废弃物拆解的可能性，结果显示这些模型在简单步骤中表现良好，却在关键子任务中遇到困难。


<details>
  <summary>Details</summary>
Motivation: 随着电子废弃物的增加，自动拆解高价值和敏感组件的需求不断上升，然而因产品的多样性和复杂性，现有的拆解技术存在明显不足。

Method: 收集定制数据集来微调两种视觉-语言-动作模型（OpenVLA和OpenVLA-OFT），并将整个拆解任务拆分为多个小步骤进行实验。

Result: 实验结果表明，微调后的VLA模型能够完成多个早期步骤，但在某些关键子任务中表现不佳，最终结合基于规则的控制器则能成功执行拆解。

Conclusion: 当前的VLA模型在处理拆解工作中的灵活性和精确度方面存在局限性，但结合基于规则的控制器可以成功完成整个拆解操作。

Abstract: Automating disassembly of critical components from end-of-life (EoL) desktops, such as high-value items like RAM modules and CPUs, as well as sensitive parts like hard disk drives, remains challenging due to the inherent variability and uncertainty of these products. Moreover, their disassembly requires sequential, precise, and dexterous operations, further increasing the complexity of automation. Current robotic disassembly processes are typically divided into several stages: perception, sequence planning, task planning, motion planning, and manipulation. Each stage requires explicit modeling, which limits generalization to unfamiliar scenarios. Recent development of vision-language-action (VLA) models has presented an end-to-end approach for general robotic manipulation tasks. Although VLAs have demonstrated promising performance on simple tasks, the feasibility of applying such models to complex disassembly remains largely unexplored. In this paper, we collected a customized dataset for robotic RAM and CPU disassembly and used it to fine-tune two well-established VLA approaches, OpenVLA and OpenVLA-OFT, as a case study. We divided the whole disassembly task into several small steps, and our preliminary experimental results indicate that the fine-tuned VLA models can faithfully complete multiple early steps but struggle with certain critical subtasks, leading to task failure. However, we observed that a simple hybrid strategy that combines VLA with a rule-based controller can successfully perform the entire disassembly operation. These findings highlight the current limitations of VLA models in handling the dexterity and precision required for robotic EoL product disassembly. By offering a detailed analysis of the observed results, this study provides insights that may inform future research to address current challenges and advance end-to-end robotic automated disassembly.

</details>


### [17] [Open-Ended Goal Inference through Actions and Language for Human-Robot Collaboration](https://arxiv.org/abs/2512.04453)
*Debasmita Ghose,Oz Gitelson,Marynel Vazquez,Brian Scassellati*

Main category: cs.RO

TL;DR: BALI是一种集成自然语言偏好与观察到的人类行为的目标预测方法，在合作任务中表现出色，能够减少错误。


<details>
  <summary>Details</summary>
Motivation: 机器人与人类协作时，需要有效推测模糊和复杂的目标，而现有方法在这方面存在局限性。

Method: BALI结合了自然语言和行动线索，通过递归规划树进行目标推断，并在信息增益大于中断成本时询问澄清问题。

Result: BALI在合作烹饪任务中相较于基线方法提供了更稳定的目标预测，错误率显著降低。

Conclusion: BALI方法在合作烹饪任务中实现了更稳定的目标预测和显著更少的错误，证明了其优越性。

Abstract: To collaborate with humans, robots must infer goals that are often ambiguous, difficult to articulate, or not drawn from a fixed set. Prior approaches restrict inference to a predefined goal set, rely only on observed actions, or depend exclusively on explicit instructions, making them brittle in real-world interactions. We present BALI (Bidirectional Action-Language Inference) for goal prediction, a method that integrates natural language preferences with observed human actions in a receding-horizon planning tree. BALI combines language and action cues from the human, asks clarifying questions only when the expected information gain from the answer outweighs the cost of interruption, and selects supportive actions that align with inferred goals. We evaluate the approach in collaborative cooking tasks, where goals may be novel to the robot and unbounded. Compared to baselines, BALI yields more stable goal predictions and significantly fewer mistakes.

</details>


### [18] [One Ring to Rule Them All: Constrained Distributional Control for Massive-Scale Heterogeneous Robotic Ensemble Systems](https://arxiv.org/abs/2512.04502)
*Andres Arias,Wei Zhang,Haoyu Qian,Jr-Shin Li,Chuangchuang Sun*

Main category: cs.RO

TL;DR: 提出了一种新颖的约束集群控制框架，实现了对异质机器人群体的安全控制。


<details>
  <summary>Details</summary>
Motivation: 为了在存在障碍物和状态约束的环境中高效地控制异质机器人群体。

Method: 提出了一种约束的集群控制框架，通过动库空间映射集群动力学到矩系统，以实现群体行为的表征。

Result: 在约束环境中，利用共享控制输入高效控制异质机器人系统，确保安全的任务执行。

Conclusion: 通过约束的集群控制方法，可以在复杂环境中高效、安全地控制机器人集群。

Abstract: Ensemble control aims to steer a population of dynamical systems using a shared control input. This paper introduces a constrained ensemble control framework for parameterized, heterogeneous robotic systems operating under state and environmental constraints, such as obstacle avoidance. We develop a moment kernel transform that maps the parameterized ensemble dynamics to the moment system in a kernel space, enabling the characterization of population-level behavior. The state-space constraints, such as polyhedral waypoints to be visited and obstacles to be avoided, are also transformed into the moment space, leading to a unified formulation for safe, large-scale ensemble control. Expressive signal temporal logic specifications are employed to encode complex visit-avoid tasks, which are achieved through a single shared controller synthesized from our constrained ensemble control formulation. Simulation and hardware experiments demonstrate the effectiveness of the proposed approach in safely and efficiently controlling robotic ensembles within constrained environments.

</details>


### [19] [Bridging Simulation and Reality: Cross-Domain Transfer with Semantic 2D Gaussian Splatting](https://arxiv.org/abs/2512.04731)
*Jian Tang,Pu Pang,Haowen Sun,Chengzhong Ma,Xingyu Chen,Hua Huang,Xuguang Lan*

Main category: cs.RO

TL;DR: 该论文提出了一种新的表示方法S2GS，通过提取对象中心的、领域不变的空间特征，有效地弥补了仿真与现实世界之间的领域差距，并改善了策略概化能力。


<details>
  <summary>Details</summary>
Motivation: 在机器人操作中，仿真与现实世界之间的领域差距导致了现有方法的局限性，如领域随机化和适应性。

Method: 提出了一种新的表示方法S2GS，通过构建多视角的2D语义场，并通过特征级高斯散射将其投影到统一的3D空间中，同时采用语义过滤机制去除不相关的背景内容。

Result: 实验结果表明，S2GS在ManiSkill仿真环境中增强了策略的仿真到现实转移能力。

Conclusion: S2GS显著提高了仿真到实际转移的能力，并在现实场景中保持了高和稳定的任务表现。

Abstract: Cross-domain transfer in robotic manipulation remains a longstanding challenge due to the significant domain gap between simulated and real-world environments. Existing methods such as domain randomization, adaptation, and sim-real calibration often require extensive tuning or fail to generalize to unseen scenarios. To address this issue, we observe that if domain-invariant features are utilized during policy training in simulation, and the same features can be extracted and provided as the input to policy during real-world deployment, the domain gap can be effectively bridged, leading to significantly improved policy generalization. Accordingly, we propose Semantic 2D Gaussian Splatting (S2GS), a novel representation method that extracts object-centric, domain-invariant spatial features. S2GS constructs multi-view 2D semantic fields and projects them into a unified 3D space via feature-level Gaussian splatting. A semantic filtering mechanism removes irrelevant background content, ensuring clean and consistent inputs for policy learning. To evaluate the effectiveness of S2GS, we adopt Diffusion Policy as the downstream learning algorithm and conduct experiments in the ManiSkill simulation environment, followed by real-world deployment. Results demonstrate that S2GS significantly improves sim-to-real transferability, maintaining high and stable task performance in real-world scenarios.

</details>


### [20] [Embodied Co-Design for Rapidly Evolving Agents: Taxonomy, Frontiers, and Challenges](https://arxiv.org/abs/2512.04770)
*Yuxing Wang,Zhiyu Chen,Tiantian Zhang,Qiyue Yin,Yongzhe Chang,Zhiheng Li,Liang Wang,Xueqian Wang*

Main category: cs.RO

TL;DR: 身体现象共设计（ECD）通过优化智能体的形态和控制器，增强了环境交互和任务表现。本调查提供了ECD的系统概述，提出了分层分类法，回顾了相关研究、基准和应用，并讨论了未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 探讨动物在环境中复杂行为的形成机制，以及如何通过生物启示来改进智能体的设计。

Method: 通过建立一个分层的分类法，定义并阐述了身体现象共设计(ECD)，并评估了相关领域的研究进展。

Result: 对ECD的组成部分进行系统化分类，并回顾了超过一百项相关研究的见解。

Conclusion: 总结了当前ECD领域的挑战与未来的研究方向，同时还提供了相关项目的链接。

Abstract: Brain-body co-evolution enables animals to develop complex behaviors in their environments. Inspired by this biological synergy, embodied co-design (ECD) has emerged as a transformative paradigm for creating intelligent agents-from virtual creatures to physical robots-by jointly optimizing their morphologies and controllers rather than treating control in isolation. This integrated approach facilitates richer environmental interactions and robust task performance. In this survey, we provide a systematic overview of recent advances in ECD. We first formalize the concept of ECD and position it within related fields. We then introduce a hierarchical taxonomy: a lower layer that breaks down agent design into three fundamental components-controlling brain, body morphology, and task environment-and an upper layer that integrates these components into four major ECD frameworks: bi-level, single-level, generative, and open-ended. This taxonomy allows us to synthesize insights from more than one hundred recent studies. We further review notable benchmarks, datasets, and applications in both simulated and real-world scenarios. Finally, we identify significant challenges and offer insights into promising future research directions. A project associated with this survey has been created at https://github.com/Yuxing-Wang-THU/SurveyBrainBody.

</details>


### [21] [TEMPO-VINE: A Multi-Temporal Sensor Fusion Dataset for Localization and Mapping in Vineyards](https://arxiv.org/abs/2512.04772)
*Mauro Martini,Marco Ambrosio,Judith Vilella-Cantos,Alessandro Navone,Marcello Chiaberge*

Main category: cs.RO

TL;DR: 本研究推出了TEMPO-VINE数据集，旨在解决农业领域现有数据集的不足，主要关注于传感器融合和SLAM技术在葡萄园中的应用。


<details>
  <summary>Details</summary>
Motivation: 由于对真实复杂农业条件下的鲁棒自主系统的需求日益增加，尤其是在动态的葡萄园环境中，研究人员急需一个真实的基准数据集。

Method: 建立TEMPO-VINE数据集，采集不同价格级别的LiDAR、AHRS、RTK-GPS和摄像头的数据，覆盖多个生长阶段和气候条件。

Result: TEMPO-VINE是首个多模态公共数据集，提供真实作业环境的数据，用于促进农业领域传感器融合、定位和映射技术的发展。

Conclusion: TEMPO-VINE数据集填补了农业领域缺乏真实复杂环境基准的空白，为机器人和自动化技术的研究提供了重要支持。

Abstract: In recent years, precision agriculture has been introducing groundbreaking innovations in the field, with a strong focus on automation. However, research studies in robotics and autonomous navigation often rely on controlled simulations or isolated field trials. The absence of a realistic common benchmark represents a significant limitation for the diffusion of robust autonomous systems under real complex agricultural conditions. Vineyards pose significant challenges due to their dynamic nature, and they are increasingly drawing attention from both academic and industrial stakeholders interested in automation. In this context, we introduce the TEMPO-VINE dataset, a large-scale multi-temporal dataset specifically designed for evaluating sensor fusion, simultaneous localization and mapping (SLAM), and place recognition techniques within operational vineyard environments. TEMPO-VINE is the first multi-modal public dataset that brings together data from heterogeneous LiDARs of different price levels, AHRS, RTK-GPS, and cameras in real trellis and pergola vineyards, with multiple rows exceeding 100 m in length. In this work, we address a critical gap in the landscape of agricultural datasets by providing researchers with a comprehensive data collection and ground truth trajectories in different seasons, vegetation growth stages, terrain and weather conditions. The sequence paths with multiple runs and revisits will foster the development of sensor fusion, localization, mapping and place recognition solutions for agricultural fields. The dataset, the processing tools and the benchmarking results will be available at the dedicated webpage upon acceptance.

</details>


### [22] [Using Machine Learning to Take Stay-or-Go Decisions in Data-driven Drone Missions](https://arxiv.org/abs/2512.04773)
*Giorgos Polychronis,Foivos Pournaropoulos,Christos D. Antonopoulos,Spyros Lalis*

Main category: cs.RO

TL;DR: 本研究提出了基于机器学习的决策方法，提高了无人机在动态事件发生概率变化下的任务执行效率，结果显示在多个场景中有显著改善。


<details>
  <summary>Details</summary>
Motivation: 随着无人机在数据驱动任务中的应用日益增多，如何更有效地处理实时数据并作出决策成为关键问题。

Method: 提出了不同的机器学习方法，具体包括基于分支预测和强化学习，评估这些方法在多种时间变化情境下的表现。

Result: 实验结果表明，所提出的方法在性能上超越了文献中基于回归的方法，最坏情况下的任务时间提高了4.1倍，而中位任务时间仅比完美知识的方法高出2.7%。

Conclusion: 通过使用基于分支预测和强化学习的方法，我们的研究显著提高了无人机在数据驱动任务中的决策效率，减少了任务完成时间。

Abstract: Drones are becoming indispensable in many application domains. In data-driven missions, besides sensing, the drone must process the collected data at runtime to decide whether additional action must be taken on the spot, before moving to the next point of interest. If processing does not reveal an event or situation that requires such an action, the drone has waited in vain instead of moving to the next point. If, however, the drone starts moving to the next point and it turns out that a follow-up action is needed at the previous point, it must spend time to fly-back. To take this decision, we propose different machine-learning methods based on branch prediction and reinforcement learning. We evaluate these methods for a wide range of scenarios where the probability of event occurrence changes with time. Our results show that the proposed methods consistently outperform the regression-based method proposed in the literature and can significantly improve the worst-case mission time by up to 4.1x. Also, the achieved median mission time is very close, merely up to 2.7% higher, to that of a method with perfect knowledge of the current underlying event probability at each point of interest.

</details>


### [23] [MOVE: A Simple Motion-Based Data Collection Paradigm for Spatial Generalization in Robotic Manipulation](https://arxiv.org/abs/2512.04813)
*Huanqian Wang,Chi Bene Chen,Yang Yue,Danhua Tao,Tong Guo,Shaoxuan Xie,Denghang Huang,Shiji Song,Guocai Yao,Gao Huang*

Main category: cs.RO

TL;DR: 本研究提出一种新颖的数据收集方法，MOtion-Based Variability Enhancement (MOVE)，通过向演示中的可移动对象注入运动，提高数据的空间多样性，从而提高机器人操作的学习效率和成功率。


<details>
  <summary>Details</summary>
Motivation: 现有的模仿学习方法在机器人操作中的应用受到数据稀缺的限制，而静态环境配置导致收集的数据缺乏空间多样性。

Method: 通过在演示中引入运动，使环境中的可移动对象变得动态，从而生成更丰富和多样的空间配置，提高数据的有效性和机器人学习能力。

Result: MOtion-Based Variability Enhancement (MOVE) 是一种数据收集范式，通过在每次演示中向环境中的可移动对象注入运动，从而提高了空间信息的丰富性。

Conclusion: MOVE 显著改善了模拟任务中的空间泛化能力，取得了39.1%的成功率，相比静态数据收集方法提升了76.1%。

Abstract: Imitation learning method has shown immense promise for robotic manipulation, yet its practical deployment is fundamentally constrained by the data scarcity. Despite prior work on collecting large-scale datasets, there still remains a significant gap to robust spatial generalization. We identify a key limitation: individual trajectories, regardless of their length, are typically collected from a \emph{single, static spatial configuration} of the environment. This includes fixed object and target spatial positions as well as unchanging camera viewpoints, which significantly restricts the diversity of spatial information available for learning. To address this critical bottleneck in data efficiency, we propose \textbf{MOtion-Based Variability Enhancement} (\emph{MOVE}), a simple yet effective data collection paradigm that enables the acquisition of richer spatial information from dynamic demonstrations. Our core contribution is an augmentation strategy that injects motion into any movable objects within the environment for each demonstration. This process implicitly generates a dense and diverse set of spatial configurations within a single trajectory. We conduct extensive experiments in both simulation and real-world environments to validate our approach. For example, in simulation tasks requiring strong spatial generalization, \emph{MOVE} achieves an average success rate of 39.1\%, a 76.1\% relative improvement over the static data collection paradigm (22.2\%), and yields up to 2--5$\times$ gains in data efficiency on certain tasks. Our code is available at https://github.com/lucywang720/MOVE.

</details>


### [24] [Hoi! -- A Multimodal Dataset for Force-Grounded, Cross-View Articulated Manipulation](https://arxiv.org/abs/2512.04884)
*Tim Engelbracht,René Zurbrügg,Matteo Wohlrapp,Martin Büchner,Abhinav Valada,Marc Pollefeys,Hermann Blum,Zuria Bauer*

Main category: cs.RO

TL;DR: 我们创建了一个包含3048个交互序列的多模态数据集，结合视觉和力感知，以支持机器人与人类视角间的研究


<details>
  <summary>Details</summary>
Motivation: 推动人机交互理解，通过结合视觉和动态力数据，研究人类与机器人之间的交互方式

Method: 构建了一个数据集，涵盖3048个序列，涉及381个关节物体及38个环境，使用多种工具操作并同步感知力和触觉

Result: 数据集提供了从视频中理解交互的整体视角，支持研究者评估人类与机器人视角间的方法迁移

Conclusion: 该数据集为力基础的跨视角关节操作提供了新的研究平台，拓展了力感知与预测的研究领域

Abstract: We present a dataset for force-grounded, cross-view articulated manipulation that couples what is seen with what is done and what is felt during real human interaction. The dataset contains 3048 sequences across 381 articulated objects in 38 environments. Each object is operated under four embodiments - (i) human hand, (ii) human hand with a wrist-mounted camera, (iii) handheld UMI gripper, and (iv) a custom Hoi! gripper - where the tool embodiment provides synchronized end-effector forces and tactile sensing. Our dataset offers a holistic view of interaction understanding from video, enabling researchers to evaluate how well methods transfer between human and robotic viewpoints, but also investigate underexplored modalities such as force sensing and prediction.

</details>


### [25] [On Disturbance-Aware Minimum-Time Trajectory Planning: Evidence from Tests on a Dynamic Driving Simulator](https://arxiv.org/abs/2512.04917)
*Matteo Masoni,Vincenzo Palermo,Marco Gabiccini,Martino Gulisano,Giorgio Previati,Massimiliano Gobbi,Francesco Comolli,Gianpiero Mastinu,Massimo Guiggiani*

Main category: cs.RO

TL;DR: 研究了干扰感知的参考轨迹对专业驾驶员在动态模拟器中驾驶性能的影响，比较了三种参考轨迹和自由驾驶基线，结果显示参考轨迹能有效提高驾驶效率。


<details>
  <summary>Details</summary>
Motivation: 探讨在动态模拟环境中，如何通过设计干扰感知和稳健性的参考轨迹来提升驾驶性能。

Method: 比较了三种参考轨迹（NOM, TLC, FLC）与自由驾驶基线（NOREF），评估其在圈速和转向努力之间的权衡。

Result: 发现NOM圈速最短但转向努力最高，TLC在圈速与转向努力之间划分了良好的平衡，FLC在减少转向努力的同时保持了相对较短的圈速。

Conclusion: 研究表明，基于参考的干扰感知规划方法，特别是FLC，能够有效用于训练和实现快速稳定的驾驶轨迹。

Abstract: This work investigates how disturbance-aware, robustness-embedded reference trajectories translate into driving performance when executed by professional drivers in a dynamic simulator. Three planned reference trajectories are compared against a free-driving baseline (NOREF) to assess trade-offs between lap time (LT) and steering effort (SE): NOM, the nominal time-optimal trajectory; TLC, a track-limit-robust trajectory obtained by tightening margins to the track edges; and FLC, a friction-limit-robust trajectory obtained by tightening against axle and tire saturation. All trajectories share the same minimum lap-time objective with a small steering-smoothness regularizer and are evaluated by two professional drivers using a high-performance car on a virtual track. The trajectories derive from a disturbance-aware minimum-lap-time framework recently proposed by the authors, where worst-case disturbance growth is propagated over a finite horizon and used to tighten tire-friction and track-limit constraints, preserving performance while providing probabilistic safety margins. LT and SE are used as performance indicators, while RMS lateral deviation, speed error, and drift angle characterize driving style. Results show a Pareto-like LT-SE trade-off: NOM yields the shortest LT but highest SE; TLC minimizes SE at the cost of longer LT; FLC lies near the efficient frontier, substantially reducing SE relative to NOM with only a small LT increase. Removing trajectory guidance (NOREF) increases both LT and SE, confirming that reference trajectories improve pace and control efficiency. Overall, the findings highlight reference-based and disturbance-aware planning, especially FLC, as effective tools for training and for achieving fast yet stable trajectories.

</details>


### [26] [Hybrid-Diffusion Models: Combining Open-loop Routines with Visuomotor Diffusion Policies](https://arxiv.org/abs/2512.04960)
*Jonne Van Haastregt,Bastian Orthmann,Michael C. Welle,Yuchong Zhang,Danica Kragic*

Main category: cs.RO

TL;DR: 提出了一种混合扩散模型，有效结合视觉运动策略和预定义操作程序，提升复杂操作任务的精度和速度。


<details>
  <summary>Details</summary>
Motivation: 尽管基于视觉运动的模仿学习策略在复杂操作任务中表现良好，但它们通常无法与传统控制方法在精度和速度上匹敌。

Method: 提出混合扩散模型，结合开放循环程序和视觉运动扩散策略，开发了远程操作增强原语 TAPs，使得操作员能够在演示过程中无缝执行预定义的例程。

Result: 在具有挑战性的真实世界任务中进行验证，包括试管抽取、开放容器液体转移和容器拧松。

Conclusion: 混合扩散方法通过学习在推理过程中触发 TAPs，从而提升了操作任务的性能。

Abstract: Despite the fact that visuomotor-based policies obtained via imitation learning demonstrate good performances in complex manipulation tasks, they usually struggle to achieve the same accuracy and speed as traditional control based methods. In this work, we introduce Hybrid-Diffusion models that combine open-loop routines with visuomotor diffusion policies. We develop Teleoperation Augmentation Primitives (TAPs) that allow the operator to perform predefined routines, such as locking specific axes, moving to perching waypoints, or triggering task-specific routines seamlessly during demonstrations. Our Hybrid-Diffusion method learns to trigger such TAPs during inference. We validate the method on challenging real-world tasks: Vial Aspiration, Open-Container Liquid Transfer, and container unscrewing. All experimental videos are available on the project's website: https://hybriddiffusion.github.io/

</details>


### [27] [Preliminary Analysis and Simulation of a Compact Variable Stiffness Wrist](https://arxiv.org/abs/2512.04973)
*Giuseppe Milazzo,Manuel G. Catalano,Antonio Bicchi,Giorgio Grioli*

Main category: cs.RO

TL;DR: 本文提出了一种新型三自由度并行腕，利用冗余弹性驱动实现可变刚度，适合假肢和类人机器人，经过仿真验证控制精度和抗干扰能力。


<details>
  <summary>Details</summary>
Motivation: 可变刚度驱动器在非结构化环境中的机器人应用中至关重要，但其机械设计导致结构更大更重。

Method: 介绍一种新型的三自由度并行腕传动装置，通过冗余弹性驱动实现可变刚度。

Result: 通过使用仅四个电机，该设备在并行架构下实现了紧凑和轻量化的设计，适用于假肢或类人机器人应用。

Conclusion: 该控制器经过仿真验证，系统动力学分析表明，设备在刚性配置下具备高精度和抗干扰能力，同时以其柔性行为最小化了交互力。

Abstract: Variable Stiffness Actuators prove invaluable for robotics applications in unstructured environments, fostering safe interactions and enhancing task adaptability. Nevertheless, their mechanical design inevitably results in larger and heavier structures compared to classical rigid actuators. This paper introduces a novel 3 Degrees of Freedom (DoFs) parallel wrist that achieves variable stiffness through redundant elastic actuation. Leveraging its parallel architecture, the device employs only four motors, rendering it compact and lightweight. This characteristic makes it particularly well-suited for applications in prosthetics or humanoid robotics. The manuscript delves into the theoretical model of the device and proposes a sophisticated control strategy for independent regulation of joint position and stiffness. Furthermore, it validates the proposed controller through simulation, utilizing a comprehensive analysis of the system dynamics. The reported results affirm the ability of the device to achieve high accuracy and disturbance rejection in rigid configurations while minimizing interaction forces with its compliant behavior.

</details>


### [28] [Introducing V-Soft Pro: a Modular Platform for a Transhumeral Prosthesis with Controllable Stiffness](https://arxiv.org/abs/2512.04998)
*Giuseppe Milazzo,Giorgio Grioli,Antonio Bicchi,Manuel G. Catalano*

Main category: cs.RO

TL;DR: 本文介绍了一种带有可变刚度致动器的肱骨假肢，旨在复制生物关节的可控顺应性，以提升假肢的自然移动和环境交互能力。


<details>
  <summary>Details</summary>
Motivation: 现有的上肢假肢在提升用户日常活动独立性方面存在局限，无法完全复制人类手臂的自然运动和交互能力。

Method: 开发了带有可变刚度致动器的肱骨假肢，采用模块化设计，支持不同的残肢形状和用户的生物信号控制。

Result: 假肢整合的弹性元件支持更自然的运动，促进安全的环境互动，并适应多样化的任务需求。

Conclusion: 所提出的可变刚度假肢具有模块化设计，能够适应各种残肢形状，并根据用户的生物信号进行独立控制，展示了在假肢领域的重要应用潜力。

Abstract: Current upper limb prostheses aim to enhance user independence in daily activities by incorporating basic motor functions. However, they fall short of replicating the natural movement and interaction capabilities of the human arm. In contrast, human limbs leverage intrinsic compliance and actively modulate joint stiffness, enabling adaptive responses to varying tasks, impact absorption, and efficient energy transfer during dynamic actions. Inspired by this adaptability, we developed a transhumeral prosthesis with Variable Stiffness Actuators (VSAs) to replicate the controllable compliance found in biological joints. The proposed prosthesis features a modular design, allowing customization for different residual limb shapes and accommodating a range of independent control signals derived from users' biological cues. Integrated elastic elements passively support more natural movements, facilitate safe interactions with the environment, and adapt to diverse task requirements. This paper presents a comprehensive overview of the platform and its functionalities, highlighting its potential applications in the field of prosthetics.

</details>


### [29] [Contact-Implicit Modeling and Simulation of a Snake Robot on Compliant and Granular Terrain](https://arxiv.org/abs/2512.05008)
*Haroon Hublikar*

Main category: cs.RO

TL;DR: 论文提出了一种统一建模与仿真框架，用于分析COBRA蛇形机器人在不同地形下的移动行为。


<details>
  <summary>Details</summary>
Motivation: 为了提高在复杂环境中机器人的行走能力，探索不同地形对机器运动的影响。

Method: 采用接触隐式公式进行摩擦交互建模，结合MATLAB Simscape和物理实验验证，同时集成了土壤接触模型以捕捉地形变形效应。

Result: 研究结果表明，刚性地面模型对短期运动预测精准，而对于柔软和动态复杂环境的可靠移动分析则需要连续体和粒子基础的地形建模。

Conclusion: 本研究建立了一个分层仿真管道，推动了机器人在挑战性非结构化环境中的稳健感知移动能力。

Abstract: This thesis presents a unified modeling and simulation framework for analyzing sidewinding and tumbling locomotion of the COBRA snake robot across rigid, compliant, and granular terrains. A contact-implicit formulation is used to model distributed frictional interactions during sidewinding, and validated through MATLAB Simscape simulations and physical experiments on rigid ground and loose sand. To capture terrain deformation effects, Project Chrono's Soil Contact Model (SCM) is integrated with the articulated multibody dynamics, enabling prediction of slip, sinkage, and load redistribution that reduce stride efficiency on deformable substrates. For high-energy rolling locomotion on steep slopes, the Chrono DEM Engine is used to simulate particle-resolved granular interactions, revealing soil failure, intermittent lift-off, and energy dissipation mechanisms not captured by rigid models. Together, these methods span real-time control-oriented simulation and high-fidelity granular physics. Results demonstrate that rigid-ground models provide accurate short-horizon motion prediction, while continuum and particle-based terrain modeling becomes necessary for reliable mobility analysis in soft and highly dynamic environments. This work establishes a hierarchical simulation pipeline that advances robust, terrain-aware locomotion for robots operating in challenging unstructured settings.

</details>


### [30] [From Generated Human Videos to Physically Plausible Robot Trajectories](https://arxiv.org/abs/2512.05094)
*James Ni,Zekai Wang,Wei Lin,Amir Bar,Yann LeCun,Trevor Darrell,Jitendra Malik,Roei Herzig*

Main category: cs.RO

TL;DR: 提出GenMimic，一个两阶段的机器人控制策略，能够在零-shot情况下从生成视频中模仿人类动作，无需微调，展现出良好的性能。


<details>
  <summary>Details</summary>
Motivation: 探索如何让类人机器人在零-shot情况下执行生成视频中的人类动作，以实现视频生成模型在机器人控制中的应用潜力。

Method: 引入一个两阶段流程：首先将视频像素提升为4D人类表示，然后对类人形态进行重定向；其次提出GenMimic，一个基于物理的强化学习策略，条件为3D关键点，并训练时使用对称正则化和关键点加权跟踪奖励。

Result: GenMimic能够从嘈杂的生成视频中模仿人类动作，使用的GenMimicBench数据集为零-shot泛化和策略鲁棒性评估建立了基准。

Conclusion: 通过广泛的实验，证明在模拟中相较于强基线有显著改进，并在Unitree G1类人机器人上实现一致、物理稳定的运动跟踪，无需微调，为实现视频生成模型作为机器人控制的高层策略提供了有希望的方向。

Abstract: Video generation models are rapidly improving in their ability to synthesize human actions in novel contexts, holding the potential to serve as high-level planners for contextual robot control. To realize this potential, a key research question remains open: how can a humanoid execute the human actions from generated videos in a zero-shot manner? This challenge arises because generated videos are often noisy and exhibit morphological distortions that make direct imitation difficult compared to real video. To address this, we introduce a two-stage pipeline. First, we lift video pixels into a 4D human representation and then retarget to the humanoid morphology. Second, we propose GenMimic-a physics-aware reinforcement learning policy conditioned on 3D keypoints, and trained with symmetry regularization and keypoint-weighted tracking rewards. As a result, GenMimic can mimic human actions from noisy, generated videos. We curate GenMimicBench, a synthetic human-motion dataset generated using two video generation models across a spectrum of actions and contexts, establishing a benchmark for assessing zero-shot generalization and policy robustness. Extensive experiments demonstrate improvements over strong baselines in simulation and confirm coherent, physically stable motion tracking on a Unitree G1 humanoid robot without fine-tuning. This work offers a promising path to realizing the potential of video generation models as high-level policies for robot control.

</details>


### [31] [STARE-VLA: Progressive Stage-Aware Reinforcement for Fine-Tuning Vision-Language-Action Models](https://arxiv.org/abs/2512.05107)
*Feng Xu,Guangyao Zhai,Xin Kong,Tingzhong Fu,Daniel F. N. Gordon,Xueli An,Benjamin Busam*

Main category: cs.RO

TL;DR: 本文提出STARE模块和IPI管道，显著提升了机器人操作的成功率，尤其是在长时间动作轨迹的优化中。


<details>
  <summary>Details</summary>
Motivation: 传统的长远动作优化方法在处理复杂的机器人操作时存在信用分配粗糙和训练不稳定的问题，因此需要采用逐步阶段优化的方法。

Method: 提出了STARE模块，将长时间动作轨迹分解为语义明确的阶段，并将其集成到TPO和PPO中，形成STA-TPO和STA-PPO。同时，设计了IPI的序列微调管道来提高动作准确性。

Result: 在SimplesEnv和ManiSkill3上的实验结果表明，经过改进的模型在这两个环境中的成功率分别达到了98.0%和96.4%。

Conclusion: 通过引入STARE模块并结合管道IPI，我们的模型在复杂的机器人操作任务中显著提升了成功率，展示了在逐步阶段优化下的强化学习的优势。

Abstract: Recent advances in Vision-Language-Action (VLA) models, powered by large language models and reinforcement learning-based fine-tuning, have shown remarkable progress in robotic manipulation. Existing methods often treat long-horizon actions as linguistic sequences and apply trajectory-level optimization methods such as Trajectory-wise Preference Optimization (TPO) or Proximal Policy Optimization (PPO), leading to coarse credit assignment and unstable training. However, unlike language, where a unified semantic meaning is preserved despite flexible sentence order, action trajectories progress through causally chained stages with different learning difficulties. This motivates progressive stage optimization. Thereby, we present Stage-Aware Reinforcement (STARE), a module that decomposes a long-horizon action trajectory into semantically meaningful stages and provides dense, interpretable, and stage-aligned reinforcement signals. Integrating STARE into TPO and PPO, we yield Stage-Aware TPO (STA-TPO) and Stage-Aware PPO (STA-PPO) for offline stage-wise preference and online intra-stage interaction, respectively. Further building on supervised fine-tuning as initialization, we propose the Imitation -> Preference -> Interaction (IPI), a serial fine-tuning pipeline for improving action accuracy in VLA models. Experiments on SimplerEnv and ManiSkill3 demonstrate substantial gains, achieving state-of-the-art success rates of 98.0 percent on SimplerEnv and 96.4 percent on ManiSkill3 tasks.

</details>
